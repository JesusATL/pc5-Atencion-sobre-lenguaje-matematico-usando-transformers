# Atención sobre lenguaje matemático usando transformers


## Equipo 1
   - [Jesús Andrés Torrejón León](https://github.com/JesusATL)
   - [Jordi Joel Bardales Rojas](https://github.com/jbardalesr)
   - [Walter Jesús Felipe Tolentino](https://github.com/felipeturing)


## Objetivo
El objetivo principal es comprobar la capacidad que tienen los modelos basados en arquitecturas transformers para poder resolver tareas relacionadas con el lenguaje matemático.

## Resumen

Los transformers son una de las arquitecturas de aprendizaje automático con mayor número de aplicaciones. En este trabajo buscamos comprobar la capacidad que tiene este tipo de modelos para poder realizar tareas que impliquen un cierto razonamiento matemático. Para ello implementamos 2 modelos, uno de ellos se encargará de resolver ecuaciones lineales de una variable y el segundo intenta resolver adiciones y sustracciones que le son expresadas en lenguaje natural sin mucho éxito.


## Resultados
### Predicciones realizadas por el modelo entrenado sobre algebra__linear_1d.txt (EASY)
<img src="imagenes/resultados_m1.png" align="center" />

### Predicciones realizadas por el modelo entrenado sobre algebra__linear_1d.txt (HARD)
<img src="arithmetic__add_or_sub" align="center" />
