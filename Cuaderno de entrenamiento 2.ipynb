{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import math_dataset \r\n",
    "from math_dataset import MathDatasetManager\r\n",
    "import torch\r\n",
    "import torch.optim as optim\r\n",
    "from torch.utils import data\r\n",
    "from math_dataset import (\r\n",
    "    question_answer_to_position_batch_collate_fn\r\n",
    ")\r\n",
    "import model_process\r\n",
    "\r\n",
    "\r\n",
    "import utils\r\n",
    "\r\n",
    "%matplotlib notebook  \r\n",
    "\r\n",
    "print(\"Torch Version\", torch.__version__)\r\n",
    "\r\n",
    "%load_ext autoreload\r\n",
    "%autoreload 2"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Torch Version 1.5.0+cu101\n"
     ]
    }
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "0m8YROdDpRAk",
    "outputId": "e6bb48eb-1c2b-4a99-9558-be452345ba23"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Math Dataset Manager\n",
    "\n",
    "Esta es una clase que nos permite cargar de manera sencilla cualquiera de los problemas disponilbles en el dataset de  problemas matematicos mathematics_dataset-v1.0 Disponible en este enlace https://console.cloud.google.com/storage/browser/_details/mathematics-dataset/mathematics_dataset-v1.0.tar.gz \n",
    "\n",
    "#### Es requerido descargar todo el dataset para poder realizar la ejecucion."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Indicamos donde se encuentra el data set\r\n",
    "mdsmgr = MathDatasetManager(\r\n",
    "  \"C:\\\\Users\\\\Jesús\\\\Documents\\\\PC5\\\\TorchDemo\\\\mathematics_dataset-v1.0\\\\mathematics_dataset-v1.0\\\\\"\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "initialized MultiFilesMathDataset with categories ['algebra', 'arithmetic', 'calculus', 'comparison', 'measurement', 'numbers', 'polynomials', 'probability'] and types ['train-easy', 'train-medium', 'train-hard', 'interpolate', 'extrapolate']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Los tipos de archivos de datos se clasifican por dificultad y grado de generalización."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "\r\n",
    "print(\"types\", list(mdsmgr.get_types()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "types ['train-easy', 'train-medium', 'train-hard', 'interpolate', 'extrapolate']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Existen problemas en multiples areas"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "print(\"categories\", list(mdsmgr.get_categories()))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "categories ['algebra', 'arithmetic', 'calculus', 'comparison', 'measurement', 'numbers', 'polynomials', 'probability']\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Inicilaizacion de pytorch"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "seed = 1\r\n",
    "torch.manual_seed(seed)\r\n",
    "device = torch.device(\"cuda\")\r\n",
    "print(\"device\", device)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "device cuda\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Entrenando  add_or_sub nivel \"Hard\""
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Create an experiment with a name and a unique ID"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "exp_name = \"add_or_sub\" # \"math_ds_algebra_linear_1d_easy\"\r\n",
    "unique_id = \"2021-07-25\" # \"2019-05-25_0900\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Construimos el dataset para entrenamiento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Usaremos 'add_or_sub', 'train-hard'"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "ds = mdsmgr.build_dataset_from_module(\r\n",
    "    'arithmetic', 'add_or_sub', 'train-hard'\r\n",
    ")\r\n",
    "print(\"train-easy dataset size\", len(ds))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train-easy dataset size 666666\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\Jesús\\Documents\\PC2\\TorchDemo\\hs-math-nlp\\torch\\lib\\site-packages\\pandas\\core\\frame.py:5042: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### El dataset de interpolacion nos servira como validacion."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "ds_interpolate = mdsmgr.build_dataset_from_module(\r\n",
    "    'arithmetic', 'add_or_sub', 'interpolate'\r\n",
    ")\r\n",
    "print(\"interpolate dataset size\", len(ds_interpolate))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "interpolate dataset size 10000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Creamos un modelo transformer \n",
    "\n",
    "La arquitectura de este modelo esta descrita con detalle en la seccion \n",
    "Here we test the best model found in the paper: a multi-head self-attention transformer to give a default sample.\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "model = utils.build_transformer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=6e-6, betas=(0.9, 0.995), eps=1e-9)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Dataloaders con multiples workers"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "# Se divide los datos en 90% entrenamiento y 10% validacion\n",
    "train_ds, val_ds = math_dataset.random_split_dataset(ds, split_rate=0.9)\n",
    "\n",
    "train_loader = data.DataLoader(\n",
    "    train_ds, batch_size=128, shuffle=True, num_workers=12,\n",
    "    collate_fn=question_answer_to_position_batch_collate_fn)\n",
    "\n",
    "val_loader = data.DataLoader(\n",
    "    val_ds, batch_size=128, shuffle=False, num_workers=12,\n",
    "    collate_fn=question_answer_to_position_batch_collate_fn)\n",
    "\n",
    "interpolate_loader = data.DataLoader(\n",
    "    ds_interpolate, batch_size=128, shuffle=False, num_workers=12,\n",
    "    collate_fn=question_answer_to_position_batch_collate_fn)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "# Celda para cargar un modelo a partir de un checkpoint\n",
    "\n",
    "#import checkpoints\n",
    "\n",
    "# build default transformer model\n",
    "#model = utils.build_transformer()\n",
    "\n",
    "#model_exp_name = \"linear_algebra\" # \"math_ds_algebra_linear_1d_easy\"\n",
    "#model_unique_id  = \"2020-07-22\" # \"2019-05-25_0900\"\n",
    "#model_exp_name = 'math_ds_algebra_linear_1d_easy'\n",
    "#model_unique_id = '2019-10-27_2300'\n",
    "# restore best validation model from checkpoint\n",
    "#_ = checkpoints.restore_checkpoint(\".\\\\checkpoints\\\\checkpoint_b37504_e7.pth\",\"\", model=model)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Ejecutamos el entrenamiento"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "model = model.to(device)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "model_process.train(\n",
    "    name = exp_name +\"-\" + unique_id,\n",
    "    model = model,\n",
    "    training_data= train_loader,\n",
    "    validation_data = val_loader,\n",
    "    interpolate_data=interpolate_loader,\n",
    "    optimizer = optimizer,\n",
    "    device = device,\n",
    "    epochs=8,\n",
    "    tb=None,\n",
    "    log_interval=100)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "~~~ Beginning Training ~~~~\n",
      "Start epoch: 0, Start batch: 0, Max batch: None\n",
      "[ Epoch: 0 / 8, Run Batch: 0 / None]\n",
      "Batch: 0. Acc: 0.011730. Loss: 5.227549. Batch_acc: 0.011730. Batch_loss: 5.227549 \n",
      "Batch: 1. Acc: 0.019573. Loss: 5.078589. Batch_acc: 0.027357. Batch_loss: 4.930756 \n",
      "Batch: 2. Acc: 0.036892. Loss: 4.888388. Batch_acc: 0.071765. Batch_loss: 4.505412 \n",
      "Batch: 3. Acc: 0.048684. Loss: 4.726118. Batch_acc: 0.083867. Batch_loss: 4.241954 \n",
      "Batch: 4. Acc: 0.055477. Loss: 4.584731. Batch_acc: 0.083037. Batch_loss: 4.011135 \n",
      "Batch: 5. Acc: 0.061344. Loss: 4.453219. Batch_acc: 0.090855. Batch_loss: 3.791699 \n",
      "Batch: 6. Acc: 0.064137. Loss: 4.332433. Batch_acc: 0.080271. Batch_loss: 3.634551 \n",
      "Batch: 7. Acc: 0.066735. Loss: 4.224350. Batch_acc: 0.084677. Batch_loss: 3.477855 \n",
      "Batch: 8. Acc: 0.069298. Loss: 4.123463. Batch_acc: 0.089647. Batch_loss: 3.322553 \n",
      "Batch: 9. Acc: 0.072976. Loss: 4.033534. Batch_acc: 0.106930. Batch_loss: 3.203272 \n",
      "Batch: 10. Acc: 0.075828. Loss: 3.952317. Batch_acc: 0.104734. Batch_loss: 3.129143 \n",
      "Batch: 11. Acc: 0.077447. Loss: 3.876167. Batch_acc: 0.094991. Batch_loss: 3.051150 \n",
      "Batch: 12. Acc: 0.078354. Loss: 3.805161. Batch_acc: 0.088990. Batch_loss: 2.972525 \n",
      "Batch: 13. Acc: 0.081757. Loss: 3.739774. Batch_acc: 0.125432. Batch_loss: 2.900469 \n",
      "Batch: 14. Acc: 0.081948. Loss: 3.682162. Batch_acc: 0.084571. Batch_loss: 2.890501 \n",
      "Batch: 15. Acc: 0.083040. Loss: 3.627576. Batch_acc: 0.099089. Batch_loss: 2.825670 \n",
      "Batch: 16. Acc: 0.084022. Loss: 3.578828. Batch_acc: 0.099597. Batch_loss: 2.805567 \n",
      "Batch: 17. Acc: 0.084876. Loss: 3.532390. Batch_acc: 0.099038. Batch_loss: 2.762635 \n",
      "Batch: 18. Acc: 0.085876. Loss: 3.490668. Batch_acc: 0.103889. Batch_loss: 2.738616 \n",
      "Batch: 19. Acc: 0.086915. Loss: 3.451001. Batch_acc: 0.106155. Batch_loss: 2.716803 \n",
      "Batch: 20. Acc: 0.087417. Loss: 3.414339. Batch_acc: 0.097230. Batch_loss: 2.698283 \n",
      "Batch: 21. Acc: 0.088043. Loss: 3.380179. Batch_acc: 0.100845. Batch_loss: 2.681187 \n",
      "Batch: 22. Acc: 0.088856. Loss: 3.349166. Batch_acc: 0.106955. Batch_loss: 2.658670 \n",
      "Batch: 23. Acc: 0.090144. Loss: 3.319563. Batch_acc: 0.119074. Batch_loss: 2.654581 \n",
      "Batch: 24. Acc: 0.090844. Loss: 3.291886. Batch_acc: 0.107183. Batch_loss: 2.646111 \n",
      "Batch: 25. Acc: 0.091328. Loss: 3.266957. Batch_acc: 0.103389. Batch_loss: 2.646103 \n",
      "Batch: 26. Acc: 0.092094. Loss: 3.243564. Batch_acc: 0.112281. Batch_loss: 2.626559 \n",
      "Batch: 27. Acc: 0.093487. Loss: 3.220639. Batch_acc: 0.131395. Batch_loss: 2.596725 \n",
      "Batch: 28. Acc: 0.094933. Loss: 3.197990. Batch_acc: 0.133963. Batch_loss: 2.587010 \n",
      "Batch: 29. Acc: 0.096036. Loss: 3.177657. Batch_acc: 0.128430. Batch_loss: 2.580240 \n",
      "Batch: 30. Acc: 0.097037. Loss: 3.158353. Batch_acc: 0.126785. Batch_loss: 2.584594 \n",
      "Batch: 31. Acc: 0.097757. Loss: 3.140400. Batch_acc: 0.120279. Batch_loss: 2.579252 \n",
      "Batch: 32. Acc: 0.098004. Loss: 3.123772. Batch_acc: 0.105869. Batch_loss: 2.592647 \n",
      "Batch: 33. Acc: 0.098646. Loss: 3.107148. Batch_acc: 0.119590. Batch_loss: 2.565127 \n",
      "Batch: 34. Acc: 0.099554. Loss: 3.091708. Batch_acc: 0.130662. Batch_loss: 2.562596 \n",
      "Batch: 35. Acc: 0.100639. Loss: 3.076741. Batch_acc: 0.138506. Batch_loss: 2.554373 \n",
      "Batch: 36. Acc: 0.101736. Loss: 3.062910. Batch_acc: 0.141691. Batch_loss: 2.559099 \n",
      "Batch: 37. Acc: 0.102715. Loss: 3.048988. Batch_acc: 0.137758. Batch_loss: 2.550601 \n",
      "Batch: 38. Acc: 0.103309. Loss: 3.036225. Batch_acc: 0.125495. Batch_loss: 2.560181 \n",
      "Batch: 39. Acc: 0.103924. Loss: 3.024493. Batch_acc: 0.128462. Batch_loss: 2.556134 \n",
      "Batch: 40. Acc: 0.104699. Loss: 3.013356. Batch_acc: 0.137243. Batch_loss: 2.545779 \n",
      "Batch: 41. Acc: 0.105413. Loss: 3.001610. Batch_acc: 0.133407. Batch_loss: 2.541222 \n",
      "Batch: 42. Acc: 0.106336. Loss: 2.990642. Batch_acc: 0.145078. Batch_loss: 2.530226 \n",
      "Batch: 43. Acc: 0.107185. Loss: 2.980021. Batch_acc: 0.143596. Batch_loss: 2.524638 \n",
      "Batch: 44. Acc: 0.108116. Loss: 2.969856. Batch_acc: 0.148827. Batch_loss: 2.525367 \n",
      "Batch: 45. Acc: 0.108952. Loss: 2.960121. Batch_acc: 0.146651. Batch_loss: 2.520941 \n",
      "Batch: 46. Acc: 0.109554. Loss: 2.951019. Batch_acc: 0.136986. Batch_loss: 2.536069 \n",
      "Batch: 47. Acc: 0.110123. Loss: 2.941847. Batch_acc: 0.136134. Batch_loss: 2.522453 \n",
      "Batch: 48. Acc: 0.110722. Loss: 2.933410. Batch_acc: 0.139710. Batch_loss: 2.525460 \n",
      "Batch: 49. Acc: 0.111219. Loss: 2.925583. Batch_acc: 0.136123. Batch_loss: 2.532930 \n",
      "Batch: 50. Acc: 0.111687. Loss: 2.917751. Batch_acc: 0.135435. Batch_loss: 2.520740 \n",
      "Batch: 51. Acc: 0.112295. Loss: 2.910062. Batch_acc: 0.143436. Batch_loss: 2.516305 \n",
      "Batch: 52. Acc: 0.112756. Loss: 2.902498. Batch_acc: 0.136185. Batch_loss: 2.518282 \n",
      "Batch: 53. Acc: 0.113246. Loss: 2.895576. Batch_acc: 0.139454. Batch_loss: 2.525326 \n",
      "Batch: 54. Acc: 0.113688. Loss: 2.888787. Batch_acc: 0.137791. Batch_loss: 2.518690 \n",
      "Batch: 55. Acc: 0.114302. Loss: 2.882056. Batch_acc: 0.148234. Batch_loss: 2.509855 \n",
      "Batch: 56. Acc: 0.114916. Loss: 2.875134. Batch_acc: 0.148779. Batch_loss: 2.493052 \n",
      "Batch: 57. Acc: 0.115499. Loss: 2.868593. Batch_acc: 0.148487. Batch_loss: 2.498854 \n",
      "Batch: 58. Acc: 0.116090. Loss: 2.862444. Batch_acc: 0.150229. Batch_loss: 2.507287 \n",
      "Batch: 59. Acc: 0.116584. Loss: 2.856376. Batch_acc: 0.145465. Batch_loss: 2.501632 \n",
      "Batch: 60. Acc: 0.117069. Loss: 2.850794. Batch_acc: 0.146714. Batch_loss: 2.509421 \n",
      "Batch: 61. Acc: 0.117759. Loss: 2.845268. Batch_acc: 0.159931. Batch_loss: 2.507264 \n",
      "Batch: 62. Acc: 0.118096. Loss: 2.840061. Batch_acc: 0.139344. Batch_loss: 2.511872 \n",
      "Batch: 63. Acc: 0.118701. Loss: 2.834664. Batch_acc: 0.156863. Batch_loss: 2.494231 \n",
      "Batch: 64. Acc: 0.119190. Loss: 2.829447. Batch_acc: 0.150519. Batch_loss: 2.495167 \n",
      "Batch: 65. Acc: 0.119524. Loss: 2.824431. Batch_acc: 0.141292. Batch_loss: 2.498072 \n",
      "Batch: 66. Acc: 0.120044. Loss: 2.819462. Batch_acc: 0.154514. Batch_loss: 2.489979 \n",
      "Batch: 67. Acc: 0.120409. Loss: 2.814670. Batch_acc: 0.144828. Batch_loss: 2.494402 \n",
      "Batch: 68. Acc: 0.120885. Loss: 2.809858. Batch_acc: 0.153356. Batch_loss: 2.481124 \n",
      "Batch: 69. Acc: 0.121065. Loss: 2.805313. Batch_acc: 0.133643. Batch_loss: 2.489035 \n",
      "Batch: 70. Acc: 0.121609. Loss: 2.800740. Batch_acc: 0.159815. Batch_loss: 2.479002 \n",
      "Batch: 71. Acc: 0.122100. Loss: 2.796305. Batch_acc: 0.157044. Batch_loss: 2.480841 \n",
      "Batch: 72. Acc: 0.122395. Loss: 2.792324. Batch_acc: 0.143944. Batch_loss: 2.501245 \n",
      "Batch: 73. Acc: 0.122874. Loss: 2.787815. Batch_acc: 0.156721. Batch_loss: 2.469330 \n",
      "Batch: 74. Acc: 0.123187. Loss: 2.783825. Batch_acc: 0.146597. Batch_loss: 2.485631 \n",
      "Batch: 75. Acc: 0.123634. Loss: 2.779584. Batch_acc: 0.156355. Batch_loss: 2.469099 \n",
      "Batch: 76. Acc: 0.124180. Loss: 2.775501. Batch_acc: 0.165800. Batch_loss: 2.464314 \n",
      "Batch: 77. Acc: 0.124564. Loss: 2.771830. Batch_acc: 0.154657. Batch_loss: 2.484356 \n",
      "Batch: 78. Acc: 0.125065. Loss: 2.767643. Batch_acc: 0.162356. Batch_loss: 2.455650 \n",
      "Batch: 79. Acc: 0.125318. Loss: 2.764091. Batch_acc: 0.145042. Batch_loss: 2.488014 \n",
      "Batch: 80. Acc: 0.125609. Loss: 2.760644. Batch_acc: 0.148851. Batch_loss: 2.485282 \n",
      "Batch: 81. Acc: 0.125856. Loss: 2.757273. Batch_acc: 0.145809. Batch_loss: 2.485020 \n",
      "Batch: 82. Acc: 0.126046. Loss: 2.753916. Batch_acc: 0.141696. Batch_loss: 2.476237 \n",
      "Batch: 83. Acc: 0.126339. Loss: 2.750676. Batch_acc: 0.151390. Batch_loss: 2.474414 \n",
      "Batch: 84. Acc: 0.126796. Loss: 2.747348. Batch_acc: 0.165598. Batch_loss: 2.464290 \n",
      "Batch: 85. Acc: 0.127101. Loss: 2.744158. Batch_acc: 0.152794. Batch_loss: 2.475795 \n",
      "Batch: 86. Acc: 0.127478. Loss: 2.740698. Batch_acc: 0.159015. Batch_loss: 2.451415 \n",
      "Batch: 87. Acc: 0.127870. Loss: 2.737533. Batch_acc: 0.161960. Batch_loss: 2.461869 \n",
      "Batch: 88. Acc: 0.128149. Loss: 2.734461. Batch_acc: 0.152738. Batch_loss: 2.463787 \n",
      "Batch: 89. Acc: 0.128454. Loss: 2.731576. Batch_acc: 0.155568. Batch_loss: 2.475598 \n",
      "Batch: 90. Acc: 0.128699. Loss: 2.728528. Batch_acc: 0.151142. Batch_loss: 2.449399 \n",
      "Batch: 91. Acc: 0.129046. Loss: 2.725570. Batch_acc: 0.159910. Batch_loss: 2.462351 \n",
      "Batch: 92. Acc: 0.129347. Loss: 2.722784. Batch_acc: 0.157284. Batch_loss: 2.464347 \n",
      "Batch: 93. Acc: 0.129593. Loss: 2.719877. Batch_acc: 0.151941. Batch_loss: 2.455626 \n",
      "Batch: 94. Acc: 0.129825. Loss: 2.717127. Batch_acc: 0.151995. Batch_loss: 2.453582 \n",
      "Batch: 95. Acc: 0.130110. Loss: 2.714246. Batch_acc: 0.157110. Batch_loss: 2.441609 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 96. Acc: 0.130339. Loss: 2.711562. Batch_acc: 0.152632. Batch_loss: 2.449801 \n",
      "Batch: 97. Acc: 0.130475. Loss: 2.708751. Batch_acc: 0.143503. Batch_loss: 2.441198 \n",
      "Batch: 98. Acc: 0.130731. Loss: 2.706103. Batch_acc: 0.155280. Batch_loss: 2.451573 \n",
      "Batch: 99. Acc: 0.130877. Loss: 2.703791. Batch_acc: 0.145821. Batch_loss: 2.468104 \n",
      "Batch: 100. Acc: 0.131144. Loss: 2.701082. Batch_acc: 0.156983. Batch_loss: 2.438200 \n",
      "Batch: 101. Acc: 0.131427. Loss: 2.698730. Batch_acc: 0.160279. Batch_loss: 2.459063 \n",
      "Batch: 102. Acc: 0.131773. Loss: 2.696201. Batch_acc: 0.167245. Batch_loss: 2.436856 \n",
      "Batch: 103. Acc: 0.132127. Loss: 2.693534. Batch_acc: 0.168682. Batch_loss: 2.418709 \n",
      "Batch: 104. Acc: 0.132377. Loss: 2.690947. Batch_acc: 0.158537. Batch_loss: 2.419548 \n",
      "Batch: 105. Acc: 0.132619. Loss: 2.688648. Batch_acc: 0.158107. Batch_loss: 2.446695 \n",
      "Batch: 106. Acc: 0.132711. Loss: 2.686417. Batch_acc: 0.142525. Batch_loss: 2.447489 \n",
      "Batch: 107. Acc: 0.132905. Loss: 2.684240. Batch_acc: 0.153670. Batch_loss: 2.452241 \n",
      "Batch: 108. Acc: 0.133026. Loss: 2.682116. Batch_acc: 0.146172. Batch_loss: 2.450958 \n",
      "Batch: 109. Acc: 0.133260. Loss: 2.679764. Batch_acc: 0.159224. Batch_loss: 2.418159 \n",
      "Batch: 110. Acc: 0.133445. Loss: 2.677513. Batch_acc: 0.154162. Batch_loss: 2.425469 \n",
      "Batch: 111. Acc: 0.133831. Loss: 2.675041. Batch_acc: 0.176879. Batch_loss: 2.399680 \n",
      "Batch: 112. Acc: 0.134065. Loss: 2.672797. Batch_acc: 0.160465. Batch_loss: 2.419069 \n",
      "Batch: 113. Acc: 0.134131. Loss: 2.670616. Batch_acc: 0.141700. Batch_loss: 2.423159 \n",
      "Batch: 114. Acc: 0.134435. Loss: 2.668457. Batch_acc: 0.170137. Batch_loss: 2.414231 \n",
      "Batch: 115. Acc: 0.134811. Loss: 2.666019. Batch_acc: 0.178098. Batch_loss: 2.385639 \n",
      "Batch: 116. Acc: 0.135172. Loss: 2.663633. Batch_acc: 0.176271. Batch_loss: 2.392212 \n",
      "Batch: 117. Acc: 0.135613. Loss: 2.661332. Batch_acc: 0.187392. Batch_loss: 2.391095 \n",
      "Batch: 118. Acc: 0.135929. Loss: 2.659165. Batch_acc: 0.173188. Batch_loss: 2.403776 \n",
      "Batch: 119. Acc: 0.136349. Loss: 2.656861. Batch_acc: 0.187207. Batch_loss: 2.377528 \n",
      "Batch: 120. Acc: 0.136730. Loss: 2.654545. Batch_acc: 0.182821. Batch_loss: 2.374616 \n",
      "Batch: 121. Acc: 0.137266. Loss: 2.651984. Batch_acc: 0.200676. Batch_loss: 2.348871 \n",
      "Batch: 122. Acc: 0.137494. Loss: 2.649837. Batch_acc: 0.165980. Batch_loss: 2.382291 \n",
      "Batch: 123. Acc: 0.137875. Loss: 2.647654. Batch_acc: 0.183986. Batch_loss: 2.383065 \n",
      "Batch: 124. Acc: 0.138305. Loss: 2.645354. Batch_acc: 0.190909. Batch_loss: 2.364104 \n",
      "Batch: 125. Acc: 0.138688. Loss: 2.643261. Batch_acc: 0.187537. Batch_loss: 2.376214 \n",
      "Batch: 126. Acc: 0.139132. Loss: 2.640819. Batch_acc: 0.193207. Batch_loss: 2.343487 \n",
      "Batch: 127. Acc: 0.139431. Loss: 2.638487. Batch_acc: 0.176273. Batch_loss: 2.350834 \n",
      "Batch: 128. Acc: 0.139903. Loss: 2.636114. Batch_acc: 0.199772. Batch_loss: 2.334998 \n",
      "Batch: 129. Acc: 0.140371. Loss: 2.633806. Batch_acc: 0.199661. Batch_loss: 2.341424 \n",
      "Batch: 130. Acc: 0.140850. Loss: 2.631557. Batch_acc: 0.204720. Batch_loss: 2.331921 \n",
      "Batch: 131. Acc: 0.141278. Loss: 2.629307. Batch_acc: 0.198473. Batch_loss: 2.328820 \n",
      "Batch: 132. Acc: 0.141782. Loss: 2.626902. Batch_acc: 0.207644. Batch_loss: 2.312442 \n",
      "Batch: 133. Acc: 0.142271. Loss: 2.624532. Batch_acc: 0.206602. Batch_loss: 2.313025 \n",
      "Batch: 134. Acc: 0.142617. Loss: 2.622442. Batch_acc: 0.189504. Batch_loss: 2.338878 \n",
      "Batch: 135. Acc: 0.143027. Loss: 2.620195. Batch_acc: 0.197398. Batch_loss: 2.322241 \n",
      "Batch: 136. Acc: 0.143418. Loss: 2.618095. Batch_acc: 0.197763. Batch_loss: 2.326267 \n",
      "Batch: 137. Acc: 0.143786. Loss: 2.615948. Batch_acc: 0.193131. Batch_loss: 2.328412 \n",
      "Batch: 138. Acc: 0.144156. Loss: 2.613730. Batch_acc: 0.195690. Batch_loss: 2.304079 \n",
      "Batch: 139. Acc: 0.144491. Loss: 2.611633. Batch_acc: 0.190368. Batch_loss: 2.324875 \n",
      "Batch: 140. Acc: 0.144828. Loss: 2.609656. Batch_acc: 0.193148. Batch_loss: 2.325724 \n",
      "Batch: 141. Acc: 0.145162. Loss: 2.607622. Batch_acc: 0.192486. Batch_loss: 2.319818 \n",
      "Batch: 142. Acc: 0.145490. Loss: 2.605713. Batch_acc: 0.191671. Batch_loss: 2.337183 \n",
      "Batch: 143. Acc: 0.145943. Loss: 2.603578. Batch_acc: 0.210436. Batch_loss: 2.299616 \n",
      "Batch: 144. Acc: 0.146422. Loss: 2.601344. Batch_acc: 0.215777. Batch_loss: 2.277386 \n",
      "Batch: 145. Acc: 0.146849. Loss: 2.599236. Batch_acc: 0.208214. Batch_loss: 2.296439 \n",
      "Batch: 146. Acc: 0.147270. Loss: 2.597220. Batch_acc: 0.208621. Batch_loss: 2.303451 \n",
      "Batch: 147. Acc: 0.147630. Loss: 2.595256. Batch_acc: 0.200114. Batch_loss: 2.308672 \n",
      "Batch: 148. Acc: 0.148012. Loss: 2.593394. Batch_acc: 0.204861. Batch_loss: 2.316449 \n",
      "Batch: 149. Acc: 0.148452. Loss: 2.591354. Batch_acc: 0.210989. Batch_loss: 2.301255 \n",
      "Batch: 150. Acc: 0.148797. Loss: 2.589533. Batch_acc: 0.200926. Batch_loss: 2.314876 \n",
      "Batch: 151. Acc: 0.149178. Loss: 2.587604. Batch_acc: 0.208831. Batch_loss: 2.285735 \n",
      "Batch: 152. Acc: 0.149647. Loss: 2.585592. Batch_acc: 0.221132. Batch_loss: 2.278827 \n",
      "Batch: 153. Acc: 0.150096. Loss: 2.583528. Batch_acc: 0.218161. Batch_loss: 2.270352 \n",
      "Batch: 154. Acc: 0.150594. Loss: 2.581522. Batch_acc: 0.227273. Batch_loss: 2.272876 \n",
      "Batch: 155. Acc: 0.151052. Loss: 2.579506. Batch_acc: 0.222158. Batch_loss: 2.266403 \n",
      "Batch: 156. Acc: 0.151464. Loss: 2.577718. Batch_acc: 0.217009. Batch_loss: 2.293654 \n",
      "Batch: 157. Acc: 0.151818. Loss: 2.575840. Batch_acc: 0.205833. Batch_loss: 2.288545 \n",
      "Batch: 158. Acc: 0.152219. Loss: 2.574022. Batch_acc: 0.215393. Batch_loss: 2.287492 \n",
      "Batch: 159. Acc: 0.152624. Loss: 2.572090. Batch_acc: 0.215941. Batch_loss: 2.270583 \n",
      "Batch: 160. Acc: 0.153037. Loss: 2.570258. Batch_acc: 0.218966. Batch_loss: 2.277638 \n",
      "Batch: 161. Acc: 0.153487. Loss: 2.568378. Batch_acc: 0.224478. Batch_loss: 2.271857 \n",
      "Batch: 162. Acc: 0.153875. Loss: 2.566646. Batch_acc: 0.216840. Batch_loss: 2.285497 \n",
      "Batch: 163. Acc: 0.154236. Loss: 2.564899. Batch_acc: 0.213581. Batch_loss: 2.277840 \n",
      "Batch: 164. Acc: 0.154728. Loss: 2.563018. Batch_acc: 0.235566. Batch_loss: 2.253631 \n",
      "Batch: 165. Acc: 0.155075. Loss: 2.561291. Batch_acc: 0.212000. Batch_loss: 2.278383 \n",
      "Batch: 166. Acc: 0.155481. Loss: 2.559571. Batch_acc: 0.224514. Batch_loss: 2.267301 \n",
      "Batch: 167. Acc: 0.155845. Loss: 2.557810. Batch_acc: 0.217063. Batch_loss: 2.261289 \n",
      "Batch: 168. Acc: 0.156246. Loss: 2.556136. Batch_acc: 0.223631. Batch_loss: 2.274608 \n",
      "Batch: 169. Acc: 0.156620. Loss: 2.554252. Batch_acc: 0.219303. Batch_loss: 2.238417 \n",
      "Batch: 170. Acc: 0.157126. Loss: 2.552384. Batch_acc: 0.240648. Batch_loss: 2.244395 \n",
      "Batch: 171. Acc: 0.157489. Loss: 2.550826. Batch_acc: 0.220597. Batch_loss: 2.280081 \n",
      "Batch: 172. Acc: 0.157850. Loss: 2.549136. Batch_acc: 0.222623. Batch_loss: 2.245297 \n",
      "Batch: 173. Acc: 0.158213. Loss: 2.547637. Batch_acc: 0.220387. Batch_loss: 2.291136 \n",
      "Batch: 174. Acc: 0.158600. Loss: 2.546084. Batch_acc: 0.226273. Batch_loss: 2.274493 \n",
      "Batch: 175. Acc: 0.158985. Loss: 2.544349. Batch_acc: 0.225641. Batch_loss: 2.243965 \n",
      "Batch: 176. Acc: 0.159436. Loss: 2.542696. Batch_acc: 0.238780. Batch_loss: 2.252008 \n",
      "Batch: 177. Acc: 0.159775. Loss: 2.541095. Batch_acc: 0.219610. Batch_loss: 2.258908 \n",
      "Batch: 178. Acc: 0.160085. Loss: 2.539521. Batch_acc: 0.215066. Batch_loss: 2.259685 \n",
      "Batch: 179. Acc: 0.160510. Loss: 2.538012. Batch_acc: 0.238376. Batch_loss: 2.261756 \n",
      "Batch: 180. Acc: 0.160883. Loss: 2.536354. Batch_acc: 0.227015. Batch_loss: 2.242289 \n",
      "Batch: 181. Acc: 0.161269. Loss: 2.534785. Batch_acc: 0.228508. Batch_loss: 2.261130 \n",
      "Batch: 182. Acc: 0.161686. Loss: 2.533236. Batch_acc: 0.238623. Batch_loss: 2.247580 \n",
      "Batch: 183. Acc: 0.162085. Loss: 2.531612. Batch_acc: 0.234822. Batch_loss: 2.235895 \n",
      "Batch: 184. Acc: 0.162411. Loss: 2.530210. Batch_acc: 0.223063. Batch_loss: 2.269296 \n",
      "Batch: 185. Acc: 0.162680. Loss: 2.528806. Batch_acc: 0.213201. Batch_loss: 2.265315 \n",
      "Batch: 186. Acc: 0.163001. Loss: 2.527360. Batch_acc: 0.221969. Batch_loss: 2.261527 \n",
      "Batch: 187. Acc: 0.163447. Loss: 2.525887. Batch_acc: 0.245209. Batch_loss: 2.256162 \n",
      "Batch: 188. Acc: 0.163757. Loss: 2.524445. Batch_acc: 0.221274. Batch_loss: 2.256598 \n",
      "Batch: 189. Acc: 0.164015. Loss: 2.523021. Batch_acc: 0.212766. Batch_loss: 2.254100 \n",
      "Batch: 190. Acc: 0.164306. Loss: 2.521599. Batch_acc: 0.219597. Batch_loss: 2.251136 \n",
      "Batch: 191. Acc: 0.164673. Loss: 2.520234. Batch_acc: 0.234384. Batch_loss: 2.260558 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 192. Acc: 0.165023. Loss: 2.518801. Batch_acc: 0.233100. Batch_loss: 2.240252 \n",
      "Batch: 193. Acc: 0.165337. Loss: 2.517332. Batch_acc: 0.224341. Batch_loss: 2.241188 \n",
      "Batch: 194. Acc: 0.165625. Loss: 2.515889. Batch_acc: 0.220957. Batch_loss: 2.238852 \n",
      "Batch: 195. Acc: 0.165971. Loss: 2.514502. Batch_acc: 0.234880. Batch_loss: 2.238497 \n",
      "Batch: 196. Acc: 0.166341. Loss: 2.513063. Batch_acc: 0.239420. Batch_loss: 2.229047 \n",
      "Batch: 197. Acc: 0.166680. Loss: 2.511684. Batch_acc: 0.233661. Batch_loss: 2.238823 \n",
      "Batch: 198. Acc: 0.166969. Loss: 2.510322. Batch_acc: 0.224267. Batch_loss: 2.240872 \n",
      "Batch: 199. Acc: 0.167245. Loss: 2.509036. Batch_acc: 0.223335. Batch_loss: 2.246944 \n",
      "Batch: 200. Acc: 0.167565. Loss: 2.507583. Batch_acc: 0.231926. Batch_loss: 2.215740 \n",
      "Batch: 201. Acc: 0.167877. Loss: 2.506270. Batch_acc: 0.230903. Batch_loss: 2.240991 \n",
      "Batch: 202. Acc: 0.168119. Loss: 2.505044. Batch_acc: 0.217926. Batch_loss: 2.253050 \n",
      "Batch: 203. Acc: 0.168430. Loss: 2.503738. Batch_acc: 0.231567. Batch_loss: 2.238489 \n",
      "Batch: 204. Acc: 0.168761. Loss: 2.502299. Batch_acc: 0.235127. Batch_loss: 2.213310 \n",
      "Batch: 205. Acc: 0.169086. Loss: 2.500957. Batch_acc: 0.234234. Batch_loss: 2.232049 \n",
      "Batch: 206. Acc: 0.169334. Loss: 2.499688. Batch_acc: 0.219581. Batch_loss: 2.242627 \n",
      "Batch: 207. Acc: 0.169532. Loss: 2.498494. Batch_acc: 0.210017. Batch_loss: 2.254074 \n",
      "Batch: 208. Acc: 0.169833. Loss: 2.497172. Batch_acc: 0.231029. Batch_loss: 2.228633 \n",
      "Batch: 209. Acc: 0.170131. Loss: 2.495939. Batch_acc: 0.233236. Batch_loss: 2.234879 \n",
      "Batch: 210. Acc: 0.170422. Loss: 2.494718. Batch_acc: 0.233412. Batch_loss: 2.230847 \n",
      "Batch: 211. Acc: 0.170666. Loss: 2.493582. Batch_acc: 0.223204. Batch_loss: 2.248205 \n",
      "Batch: 212. Acc: 0.171061. Loss: 2.492201. Batch_acc: 0.254744. Batch_loss: 2.199793 \n",
      "Batch: 213. Acc: 0.171263. Loss: 2.491080. Batch_acc: 0.214785. Batch_loss: 2.249689 \n",
      "Batch: 214. Acc: 0.171559. Loss: 2.489821. Batch_acc: 0.235706. Batch_loss: 2.216738 \n",
      "Batch: 215. Acc: 0.171835. Loss: 2.488565. Batch_acc: 0.232070. Batch_loss: 2.215079 \n",
      "Batch: 216. Acc: 0.172098. Loss: 2.487450. Batch_acc: 0.229912. Batch_loss: 2.242306 \n",
      "Batch: 217. Acc: 0.172292. Loss: 2.486422. Batch_acc: 0.214617. Batch_loss: 2.261650 \n",
      "Batch: 218. Acc: 0.172533. Loss: 2.485239. Batch_acc: 0.225173. Batch_loss: 2.226649 \n",
      "Batch: 219. Acc: 0.172860. Loss: 2.483924. Batch_acc: 0.242577. Batch_loss: 2.203692 \n",
      "Batch: 220. Acc: 0.173099. Loss: 2.482759. Batch_acc: 0.225676. Batch_loss: 2.226545 \n",
      "Batch: 221. Acc: 0.173287. Loss: 2.481762. Batch_acc: 0.217338. Batch_loss: 2.248164 \n",
      "Batch: 222. Acc: 0.173579. Loss: 2.480566. Batch_acc: 0.237635. Batch_loss: 2.218545 \n",
      "Batch: 223. Acc: 0.173814. Loss: 2.479402. Batch_acc: 0.225992. Batch_loss: 2.220145 \n",
      "Batch: 224. Acc: 0.174145. Loss: 2.478156. Batch_acc: 0.246094. Batch_loss: 2.207779 \n",
      "Batch: 225. Acc: 0.174446. Loss: 2.476984. Batch_acc: 0.243402. Batch_loss: 2.208242 \n",
      "Batch: 226. Acc: 0.174685. Loss: 2.475838. Batch_acc: 0.228473. Batch_loss: 2.217692 \n",
      "Batch: 227. Acc: 0.174917. Loss: 2.474693. Batch_acc: 0.228305. Batch_loss: 2.211879 \n",
      "Batch: 228. Acc: 0.175132. Loss: 2.473684. Batch_acc: 0.224680. Batch_loss: 2.241241 \n",
      "Batch: 229. Acc: 0.175317. Loss: 2.472635. Batch_acc: 0.218023. Batch_loss: 2.230140 \n",
      "Batch: 230. Acc: 0.175619. Loss: 2.471534. Batch_acc: 0.244432. Batch_loss: 2.220249 \n",
      "Batch: 231. Acc: 0.175817. Loss: 2.470507. Batch_acc: 0.222157. Batch_loss: 2.230505 \n",
      "Batch: 232. Acc: 0.176095. Loss: 2.469401. Batch_acc: 0.242192. Batch_loss: 2.206720 \n",
      "Batch: 233. Acc: 0.176345. Loss: 2.468245. Batch_acc: 0.233465. Batch_loss: 2.203878 \n",
      "Batch: 234. Acc: 0.176573. Loss: 2.467242. Batch_acc: 0.229238. Batch_loss: 2.235448 \n",
      "Batch: 235. Acc: 0.176795. Loss: 2.466113. Batch_acc: 0.228441. Batch_loss: 2.203137 \n",
      "Batch: 236. Acc: 0.177082. Loss: 2.465038. Batch_acc: 0.244432. Batch_loss: 2.213343 \n",
      "Batch: 237. Acc: 0.177343. Loss: 2.464048. Batch_acc: 0.240047. Batch_loss: 2.225526 \n",
      "Batch: 238. Acc: 0.177608. Loss: 2.463001. Batch_acc: 0.239660. Batch_loss: 2.217813 \n",
      "Batch: 239. Acc: 0.177864. Loss: 2.461956. Batch_acc: 0.238695. Batch_loss: 2.213726 \n",
      "Batch: 240. Acc: 0.178127. Loss: 2.460921. Batch_acc: 0.239022. Batch_loss: 2.221112 \n",
      "Batch: 241. Acc: 0.178381. Loss: 2.459914. Batch_acc: 0.241420. Batch_loss: 2.210551 \n",
      "Batch: 242. Acc: 0.178649. Loss: 2.458805. Batch_acc: 0.243259. Batch_loss: 2.191521 \n",
      "Batch: 243. Acc: 0.178845. Loss: 2.457867. Batch_acc: 0.226027. Batch_loss: 2.231937 \n",
      "Batch: 244. Acc: 0.179081. Loss: 2.456827. Batch_acc: 0.234802. Batch_loss: 2.210980 \n",
      "Batch: 245. Acc: 0.179289. Loss: 2.455829. Batch_acc: 0.230636. Batch_loss: 2.210471 \n",
      "Batch: 246. Acc: 0.179557. Loss: 2.454826. Batch_acc: 0.245940. Batch_loss: 2.206165 \n",
      "Batch: 247. Acc: 0.179801. Loss: 2.453832. Batch_acc: 0.240936. Batch_loss: 2.204519 \n",
      "Batch: 248. Acc: 0.180047. Loss: 2.452691. Batch_acc: 0.239374. Batch_loss: 2.177854 \n",
      "Batch: 249. Acc: 0.180279. Loss: 2.451702. Batch_acc: 0.237443. Batch_loss: 2.207464 \n",
      "Batch: 250. Acc: 0.180575. Loss: 2.450578. Batch_acc: 0.252667. Batch_loss: 2.176547 \n",
      "Batch: 251. Acc: 0.180844. Loss: 2.449538. Batch_acc: 0.249561. Batch_loss: 2.183904 \n",
      "Checkpointing on batch: 251. Accuracy: 0.18084352983103816. Loss per char: 2.449538187749582. Time: 1627202816.218363\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 18, 15, 20,  1, 12,  1,\n",
      "        19, 17, 23, 17, 22, 15, 25, 25, 18, 24, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "No existing model file found\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790396\n",
      "Batch: 252. Acc: 0.181053. Loss: 2.448614. Batch_acc: 0.234203. Batch_loss: 2.214108 \n",
      "Batch: 253. Acc: 0.181312. Loss: 2.447602. Batch_acc: 0.245219. Batch_loss: 2.197336 \n",
      "Batch: 254. Acc: 0.181479. Loss: 2.446731. Batch_acc: 0.225327. Batch_loss: 2.218452 \n",
      "Batch: 255. Acc: 0.181718. Loss: 2.445785. Batch_acc: 0.243448. Batch_loss: 2.201633 \n",
      "Batch: 256. Acc: 0.181883. Loss: 2.444936. Batch_acc: 0.224078. Batch_loss: 2.227595 \n",
      "Batch: 257. Acc: 0.182131. Loss: 2.443761. Batch_acc: 0.242756. Batch_loss: 2.156818 \n",
      "Batch: 258. Acc: 0.182340. Loss: 2.442928. Batch_acc: 0.236103. Batch_loss: 2.229074 \n",
      "Batch: 259. Acc: 0.182537. Loss: 2.442075. Batch_acc: 0.233661. Batch_loss: 2.220027 \n",
      "Batch: 260. Acc: 0.182789. Loss: 2.441087. Batch_acc: 0.249127. Batch_loss: 2.181545 \n",
      "Batch: 261. Acc: 0.183072. Loss: 2.440093. Batch_acc: 0.257077. Batch_loss: 2.179527 \n",
      "Batch: 262. Acc: 0.183256. Loss: 2.439335. Batch_acc: 0.232300. Batch_loss: 2.237582 \n",
      "Batch: 263. Acc: 0.183400. Loss: 2.438479. Batch_acc: 0.220705. Batch_loss: 2.215917 \n",
      "Batch: 264. Acc: 0.183607. Loss: 2.437656. Batch_acc: 0.238728. Batch_loss: 2.219508 \n",
      "Batch: 265. Acc: 0.183803. Loss: 2.436847. Batch_acc: 0.236780. Batch_loss: 2.218270 \n",
      "Batch: 266. Acc: 0.183969. Loss: 2.436089. Batch_acc: 0.228571. Batch_loss: 2.231712 \n",
      "Batch: 267. Acc: 0.184149. Loss: 2.435287. Batch_acc: 0.233061. Batch_loss: 2.218111 \n",
      "Batch: 268. Acc: 0.184346. Loss: 2.434481. Batch_acc: 0.237984. Batch_loss: 2.214690 \n",
      "Batch: 269. Acc: 0.184537. Loss: 2.433575. Batch_acc: 0.236353. Batch_loss: 2.187736 \n",
      "Batch: 270. Acc: 0.184672. Loss: 2.432768. Batch_acc: 0.221198. Batch_loss: 2.214612 \n",
      "Batch: 271. Acc: 0.184855. Loss: 2.431974. Batch_acc: 0.235467. Batch_loss: 2.212598 \n",
      "Batch: 272. Acc: 0.185014. Loss: 2.431134. Batch_acc: 0.228923. Batch_loss: 2.199027 \n",
      "Batch: 273. Acc: 0.185194. Loss: 2.430371. Batch_acc: 0.235053. Batch_loss: 2.218376 \n",
      "Batch: 274. Acc: 0.185441. Loss: 2.429468. Batch_acc: 0.253012. Batch_loss: 2.182936 \n",
      "Batch: 275. Acc: 0.185626. Loss: 2.428680. Batch_acc: 0.236479. Batch_loss: 2.212238 \n",
      "Batch: 276. Acc: 0.185776. Loss: 2.427928. Batch_acc: 0.227089. Batch_loss: 2.220224 \n",
      "Batch: 277. Acc: 0.185931. Loss: 2.427183. Batch_acc: 0.228702. Batch_loss: 2.222127 \n",
      "Batch: 278. Acc: 0.186086. Loss: 2.426465. Batch_acc: 0.230541. Batch_loss: 2.220641 \n",
      "Batch: 279. Acc: 0.186290. Loss: 2.425669. Batch_acc: 0.243088. Batch_loss: 2.203577 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.186494. Loss: 2.424831. Batch_acc: 0.243151. Batch_loss: 2.192437 \n",
      "Batch: 281. Acc: 0.186665. Loss: 2.424046. Batch_acc: 0.234152. Batch_loss: 2.205135 \n",
      "Batch: 282. Acc: 0.186832. Loss: 2.423288. Batch_acc: 0.233352. Batch_loss: 2.212170 \n",
      "Batch: 283. Acc: 0.187016. Loss: 2.422621. Batch_acc: 0.239080. Batch_loss: 2.234367 \n",
      "Batch: 284. Acc: 0.187215. Loss: 2.421842. Batch_acc: 0.243028. Batch_loss: 2.202984 \n",
      "Batch: 285. Acc: 0.187401. Loss: 2.421088. Batch_acc: 0.241481. Batch_loss: 2.202091 \n",
      "Batch: 286. Acc: 0.187581. Loss: 2.420349. Batch_acc: 0.239650. Batch_loss: 2.206257 \n",
      "Batch: 287. Acc: 0.187758. Loss: 2.419659. Batch_acc: 0.238754. Batch_loss: 2.221364 \n",
      "Batch: 288. Acc: 0.187961. Loss: 2.418887. Batch_acc: 0.245594. Batch_loss: 2.199306 \n",
      "Batch: 289. Acc: 0.188189. Loss: 2.418107. Batch_acc: 0.253273. Batch_loss: 2.195477 \n",
      "Batch: 290. Acc: 0.188399. Loss: 2.417289. Batch_acc: 0.247486. Batch_loss: 2.187320 \n",
      "Batch: 291. Acc: 0.188566. Loss: 2.416506. Batch_acc: 0.237054. Batch_loss: 2.188647 \n",
      "Batch: 292. Acc: 0.188760. Loss: 2.415726. Batch_acc: 0.245132. Batch_loss: 2.189266 \n",
      "Batch: 293. Acc: 0.188929. Loss: 2.415044. Batch_acc: 0.239181. Batch_loss: 2.212038 \n",
      "Batch: 294. Acc: 0.189080. Loss: 2.414295. Batch_acc: 0.233087. Batch_loss: 2.196914 \n",
      "Batch: 295. Acc: 0.189259. Loss: 2.413614. Batch_acc: 0.242215. Batch_loss: 2.212415 \n",
      "Batch: 296. Acc: 0.189443. Loss: 2.412809. Batch_acc: 0.242906. Batch_loss: 2.178144 \n",
      "Batch: 297. Acc: 0.189579. Loss: 2.412077. Batch_acc: 0.229296. Batch_loss: 2.199213 \n",
      "Batch: 298. Acc: 0.189795. Loss: 2.411253. Batch_acc: 0.253731. Batch_loss: 2.166441 \n",
      "Batch: 299. Acc: 0.189945. Loss: 2.410569. Batch_acc: 0.233613. Batch_loss: 2.211548 \n",
      "Batch: 300. Acc: 0.190147. Loss: 2.409792. Batch_acc: 0.250572. Batch_loss: 2.178384 \n",
      "Batch: 301. Acc: 0.190311. Loss: 2.409081. Batch_acc: 0.240351. Batch_loss: 2.191542 \n",
      "Batch: 302. Acc: 0.190493. Loss: 2.408362. Batch_acc: 0.245392. Batch_loss: 2.191306 \n",
      "Batch: 303. Acc: 0.190611. Loss: 2.407700. Batch_acc: 0.226307. Batch_loss: 2.207418 \n",
      "Batch: 304. Acc: 0.190737. Loss: 2.407056. Batch_acc: 0.229604. Batch_loss: 2.208856 \n",
      "Batch: 305. Acc: 0.190922. Loss: 2.406355. Batch_acc: 0.245920. Batch_loss: 2.197397 \n",
      "Batch: 306. Acc: 0.191047. Loss: 2.405720. Batch_acc: 0.230723. Batch_loss: 2.204145 \n",
      "Batch: 307. Acc: 0.191170. Loss: 2.405103. Batch_acc: 0.228620. Batch_loss: 2.217475 \n",
      "Batch: 308. Acc: 0.191351. Loss: 2.404340. Batch_acc: 0.246716. Batch_loss: 2.171185 \n",
      "Batch: 309. Acc: 0.191496. Loss: 2.403645. Batch_acc: 0.235795. Batch_loss: 2.191863 \n",
      "Batch: 310. Acc: 0.191658. Loss: 2.402914. Batch_acc: 0.242442. Batch_loss: 2.173796 \n",
      "Batch: 311. Acc: 0.191846. Loss: 2.402118. Batch_acc: 0.247920. Batch_loss: 2.163775 \n",
      "Batch: 312. Acc: 0.192027. Loss: 2.401349. Batch_acc: 0.247738. Batch_loss: 2.165552 \n",
      "Batch: 313. Acc: 0.192214. Loss: 2.400582. Batch_acc: 0.249717. Batch_loss: 2.164615 \n",
      "Batch: 314. Acc: 0.192347. Loss: 2.399932. Batch_acc: 0.233848. Batch_loss: 2.196970 \n",
      "Batch: 315. Acc: 0.192517. Loss: 2.399232. Batch_acc: 0.245304. Batch_loss: 2.181424 \n",
      "Batch: 316. Acc: 0.192652. Loss: 2.398535. Batch_acc: 0.236119. Batch_loss: 2.174753 \n",
      "Batch: 317. Acc: 0.192788. Loss: 2.397915. Batch_acc: 0.236427. Batch_loss: 2.198766 \n",
      "Batch: 318. Acc: 0.192911. Loss: 2.397302. Batch_acc: 0.232382. Batch_loss: 2.199997 \n",
      "Batch: 319. Acc: 0.193069. Loss: 2.396618. Batch_acc: 0.243538. Batch_loss: 2.178784 \n",
      "Batch: 320. Acc: 0.193293. Loss: 2.395861. Batch_acc: 0.263755. Batch_loss: 2.157097 \n",
      "Batch: 321. Acc: 0.193496. Loss: 2.395163. Batch_acc: 0.259453. Batch_loss: 2.168837 \n",
      "Batch: 322. Acc: 0.193605. Loss: 2.394586. Batch_acc: 0.228150. Batch_loss: 2.211347 \n",
      "Batch: 323. Acc: 0.193747. Loss: 2.393911. Batch_acc: 0.239679. Batch_loss: 2.176944 \n",
      "Batch: 324. Acc: 0.193895. Loss: 2.393277. Batch_acc: 0.240449. Batch_loss: 2.192698 \n",
      "Batch: 325. Acc: 0.194030. Loss: 2.392750. Batch_acc: 0.238040. Batch_loss: 2.221263 \n",
      "Batch: 326. Acc: 0.194140. Loss: 2.392172. Batch_acc: 0.229630. Batch_loss: 2.205455 \n",
      "Batch: 327. Acc: 0.194293. Loss: 2.391638. Batch_acc: 0.245173. Batch_loss: 2.214170 \n",
      "Batch: 328. Acc: 0.194395. Loss: 2.391064. Batch_acc: 0.227740. Batch_loss: 2.204439 \n",
      "Batch: 329. Acc: 0.194590. Loss: 2.390411. Batch_acc: 0.258138. Batch_loss: 2.177092 \n",
      "Batch: 330. Acc: 0.194702. Loss: 2.389863. Batch_acc: 0.232682. Batch_loss: 2.203839 \n",
      "Batch: 331. Acc: 0.194850. Loss: 2.389282. Batch_acc: 0.244718. Batch_loss: 2.193309 \n",
      "Batch: 332. Acc: 0.194974. Loss: 2.388654. Batch_acc: 0.236981. Batch_loss: 2.176677 \n",
      "Batch: 333. Acc: 0.195114. Loss: 2.388119. Batch_acc: 0.242001. Batch_loss: 2.208018 \n",
      "Batch: 334. Acc: 0.195259. Loss: 2.387534. Batch_acc: 0.243568. Batch_loss: 2.193481 \n",
      "Batch: 335. Acc: 0.195435. Loss: 2.386864. Batch_acc: 0.252649. Batch_loss: 2.169522 \n",
      "Batch: 336. Acc: 0.195574. Loss: 2.386280. Batch_acc: 0.241458. Batch_loss: 2.192215 \n",
      "Batch: 337. Acc: 0.195768. Loss: 2.385570. Batch_acc: 0.261194. Batch_loss: 2.146805 \n",
      "Batch: 338. Acc: 0.195917. Loss: 2.384950. Batch_acc: 0.247066. Batch_loss: 2.171329 \n",
      "Batch: 339. Acc: 0.196086. Loss: 2.384367. Batch_acc: 0.253594. Batch_loss: 2.186962 \n",
      "Batch: 340. Acc: 0.196233. Loss: 2.383772. Batch_acc: 0.245845. Batch_loss: 2.182478 \n",
      "Batch: 341. Acc: 0.196354. Loss: 2.383215. Batch_acc: 0.237929. Batch_loss: 2.191090 \n",
      "Batch: 342. Acc: 0.196518. Loss: 2.382673. Batch_acc: 0.252728. Batch_loss: 2.197911 \n",
      "Batch: 343. Acc: 0.196581. Loss: 2.382305. Batch_acc: 0.218330. Batch_loss: 2.254170 \n",
      "Batch: 344. Acc: 0.196706. Loss: 2.381766. Batch_acc: 0.238227. Batch_loss: 2.203321 \n",
      "Batch: 345. Acc: 0.196871. Loss: 2.381156. Batch_acc: 0.252394. Batch_loss: 2.175262 \n",
      "Batch: 346. Acc: 0.197026. Loss: 2.380609. Batch_acc: 0.250142. Batch_loss: 2.193913 \n",
      "Batch: 347. Acc: 0.197114. Loss: 2.380169. Batch_acc: 0.228070. Batch_loss: 2.225239 \n",
      "Batch: 348. Acc: 0.197239. Loss: 2.379599. Batch_acc: 0.241869. Batch_loss: 2.175565 \n",
      "Batch: 349. Acc: 0.197342. Loss: 2.379089. Batch_acc: 0.233547. Batch_loss: 2.199131 \n",
      "Batch: 350. Acc: 0.197461. Loss: 2.378529. Batch_acc: 0.238527. Batch_loss: 2.185675 \n",
      "Batch: 351. Acc: 0.197572. Loss: 2.377998. Batch_acc: 0.237119. Batch_loss: 2.188417 \n",
      "Batch: 352. Acc: 0.197764. Loss: 2.377370. Batch_acc: 0.266162. Batch_loss: 2.153741 \n",
      "Batch: 353. Acc: 0.197945. Loss: 2.376724. Batch_acc: 0.262850. Batch_loss: 2.145116 \n",
      "Batch: 354. Acc: 0.198052. Loss: 2.376211. Batch_acc: 0.236780. Batch_loss: 2.190943 \n",
      "Batch: 355. Acc: 0.198203. Loss: 2.375637. Batch_acc: 0.251576. Batch_loss: 2.172899 \n",
      "Batch: 356. Acc: 0.198340. Loss: 2.375071. Batch_acc: 0.246724. Batch_loss: 2.175620 \n",
      "Batch: 357. Acc: 0.198464. Loss: 2.374534. Batch_acc: 0.242424. Batch_loss: 2.184164 \n",
      "Batch: 358. Acc: 0.198553. Loss: 2.374101. Batch_acc: 0.230501. Batch_loss: 2.217266 \n",
      "Batch: 359. Acc: 0.198659. Loss: 2.373575. Batch_acc: 0.236395. Batch_loss: 2.187551 \n",
      "Batch: 360. Acc: 0.198819. Loss: 2.372924. Batch_acc: 0.256827. Batch_loss: 2.136278 \n",
      "Batch: 361. Acc: 0.198929. Loss: 2.372422. Batch_acc: 0.239412. Batch_loss: 2.187512 \n",
      "Batch: 362. Acc: 0.199025. Loss: 2.371892. Batch_acc: 0.233015. Batch_loss: 2.184605 \n",
      "Batch: 363. Acc: 0.199152. Loss: 2.371364. Batch_acc: 0.245911. Batch_loss: 2.176933 \n",
      "Batch: 364. Acc: 0.199261. Loss: 2.370849. Batch_acc: 0.238122. Batch_loss: 2.186714 \n",
      "Batch: 365. Acc: 0.199398. Loss: 2.370297. Batch_acc: 0.250000. Batch_loss: 2.167183 \n",
      "Batch: 366. Acc: 0.199477. Loss: 2.369880. Batch_acc: 0.227941. Batch_loss: 2.219907 \n",
      "Batch: 367. Acc: 0.199663. Loss: 2.369272. Batch_acc: 0.266106. Batch_loss: 2.152318 \n",
      "Batch: 368. Acc: 0.199783. Loss: 2.368732. Batch_acc: 0.243458. Batch_loss: 2.172106 \n",
      "Batch: 369. Acc: 0.199890. Loss: 2.368188. Batch_acc: 0.238336. Batch_loss: 2.172152 \n",
      "Batch: 370. Acc: 0.199984. Loss: 2.367687. Batch_acc: 0.234554. Batch_loss: 2.183465 \n",
      "Batch: 371. Acc: 0.200115. Loss: 2.367193. Batch_acc: 0.247743. Batch_loss: 2.187525 \n",
      "Batch: 372. Acc: 0.200237. Loss: 2.366662. Batch_acc: 0.245413. Batch_loss: 2.169862 \n",
      "Batch: 373. Acc: 0.200352. Loss: 2.366180. Batch_acc: 0.244145. Batch_loss: 2.183228 \n",
      "Batch: 374. Acc: 0.200453. Loss: 2.365716. Batch_acc: 0.238537. Batch_loss: 2.190806 \n",
      "Batch: 375. Acc: 0.200560. Loss: 2.365221. Batch_acc: 0.239932. Batch_loss: 2.182346 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.200684. Loss: 2.364721. Batch_acc: 0.247405. Batch_loss: 2.176139 \n",
      "Batch: 377. Acc: 0.200823. Loss: 2.364215. Batch_acc: 0.253303. Batch_loss: 2.174044 \n",
      "Batch: 378. Acc: 0.200938. Loss: 2.363721. Batch_acc: 0.243721. Batch_loss: 2.178491 \n",
      "Batch: 379. Acc: 0.201015. Loss: 2.363249. Batch_acc: 0.230199. Batch_loss: 2.186127 \n",
      "Batch: 380. Acc: 0.201114. Loss: 2.362784. Batch_acc: 0.238979. Batch_loss: 2.184648 \n",
      "Batch: 381. Acc: 0.201219. Loss: 2.362330. Batch_acc: 0.240847. Batch_loss: 2.190408 \n",
      "Batch: 382. Acc: 0.201287. Loss: 2.361905. Batch_acc: 0.227804. Batch_loss: 2.196945 \n",
      "Batch: 383. Acc: 0.201424. Loss: 2.361430. Batch_acc: 0.253586. Batch_loss: 2.180168 \n",
      "Batch: 384. Acc: 0.201530. Loss: 2.360897. Batch_acc: 0.242147. Batch_loss: 2.157825 \n",
      "Batch: 385. Acc: 0.201651. Loss: 2.360455. Batch_acc: 0.247991. Batch_loss: 2.190718 \n",
      "Batch: 386. Acc: 0.201767. Loss: 2.359987. Batch_acc: 0.246136. Batch_loss: 2.180077 \n",
      "Batch: 387. Acc: 0.201871. Loss: 2.359529. Batch_acc: 0.242111. Batch_loss: 2.182926 \n",
      "Batch: 388. Acc: 0.202016. Loss: 2.359064. Batch_acc: 0.258324. Batch_loss: 2.179032 \n",
      "Batch: 389. Acc: 0.202136. Loss: 2.358592. Batch_acc: 0.248565. Batch_loss: 2.175769 \n",
      "Batch: 390. Acc: 0.202285. Loss: 2.358065. Batch_acc: 0.259322. Batch_loss: 2.155961 \n",
      "Batch: 391. Acc: 0.202382. Loss: 2.357609. Batch_acc: 0.240838. Batch_loss: 2.177548 \n",
      "Batch: 392. Acc: 0.202497. Loss: 2.357097. Batch_acc: 0.247133. Batch_loss: 2.156922 \n",
      "Batch: 393. Acc: 0.202597. Loss: 2.356563. Batch_acc: 0.241991. Batch_loss: 2.148072 \n",
      "Batch: 394. Acc: 0.202699. Loss: 2.356135. Batch_acc: 0.242651. Batch_loss: 2.187154 \n",
      "Batch: 395. Acc: 0.202836. Loss: 2.355574. Batch_acc: 0.255593. Batch_loss: 2.140143 \n",
      "Batch: 396. Acc: 0.202963. Loss: 2.355103. Batch_acc: 0.253150. Batch_loss: 2.169458 \n",
      "Batch: 397. Acc: 0.203079. Loss: 2.354607. Batch_acc: 0.248996. Batch_loss: 2.158540 \n",
      "Batch: 398. Acc: 0.203190. Loss: 2.354153. Batch_acc: 0.247256. Batch_loss: 2.172667 \n",
      "Batch: 399. Acc: 0.203325. Loss: 2.353711. Batch_acc: 0.258159. Batch_loss: 2.175092 \n",
      "Batch: 400. Acc: 0.203427. Loss: 2.353247. Batch_acc: 0.244886. Batch_loss: 2.164839 \n",
      "Batch: 401. Acc: 0.203526. Loss: 2.352847. Batch_acc: 0.242702. Batch_loss: 2.193277 \n",
      "Batch: 402. Acc: 0.203601. Loss: 2.352441. Batch_acc: 0.233871. Batch_loss: 2.188789 \n",
      "Batch: 403. Acc: 0.203714. Loss: 2.352076. Batch_acc: 0.249711. Batch_loss: 2.204470 \n",
      "Batch: 404. Acc: 0.203873. Loss: 2.351541. Batch_acc: 0.267468. Batch_loss: 2.136205 \n",
      "Batch: 405. Acc: 0.203967. Loss: 2.351114. Batch_acc: 0.242690. Batch_loss: 2.175689 \n",
      "Batch: 406. Acc: 0.204061. Loss: 2.350678. Batch_acc: 0.242165. Batch_loss: 2.175126 \n",
      "Batch: 407. Acc: 0.204171. Loss: 2.350255. Batch_acc: 0.247348. Batch_loss: 2.183292 \n",
      "Batch: 408. Acc: 0.204251. Loss: 2.349879. Batch_acc: 0.238466. Batch_loss: 2.190011 \n",
      "Batch: 409. Acc: 0.204367. Loss: 2.349406. Batch_acc: 0.250847. Batch_loss: 2.159772 \n",
      "Batch: 410. Acc: 0.204468. Loss: 2.348900. Batch_acc: 0.245826. Batch_loss: 2.141094 \n",
      "Batch: 411. Acc: 0.204561. Loss: 2.348505. Batch_acc: 0.243180. Batch_loss: 2.184841 \n",
      "Batch: 412. Acc: 0.204655. Loss: 2.348086. Batch_acc: 0.242390. Batch_loss: 2.179223 \n",
      "Batch: 413. Acc: 0.204741. Loss: 2.347700. Batch_acc: 0.240390. Batch_loss: 2.188733 \n",
      "Batch: 414. Acc: 0.204837. Loss: 2.347325. Batch_acc: 0.245687. Batch_loss: 2.186826 \n",
      "Batch: 415. Acc: 0.204944. Loss: 2.346868. Batch_acc: 0.249711. Batch_loss: 2.156364 \n",
      "Batch: 416. Acc: 0.205032. Loss: 2.346455. Batch_acc: 0.241518. Batch_loss: 2.174671 \n",
      "Batch: 417. Acc: 0.205148. Loss: 2.346031. Batch_acc: 0.253295. Batch_loss: 2.169691 \n",
      "Batch: 418. Acc: 0.205238. Loss: 2.345638. Batch_acc: 0.244104. Batch_loss: 2.177586 \n",
      "Batch: 419. Acc: 0.205367. Loss: 2.345185. Batch_acc: 0.259688. Batch_loss: 2.154505 \n",
      "Batch: 420. Acc: 0.205496. Loss: 2.344751. Batch_acc: 0.259710. Batch_loss: 2.160816 \n",
      "Batch: 421. Acc: 0.205591. Loss: 2.344369. Batch_acc: 0.246616. Batch_loss: 2.180011 \n",
      "Batch: 422. Acc: 0.205697. Loss: 2.343964. Batch_acc: 0.251019. Batch_loss: 2.171105 \n",
      "Batch: 423. Acc: 0.205826. Loss: 2.343510. Batch_acc: 0.259009. Batch_loss: 2.155385 \n",
      "Batch: 424. Acc: 0.205915. Loss: 2.343071. Batch_acc: 0.242849. Batch_loss: 2.162029 \n",
      "Batch: 425. Acc: 0.206054. Loss: 2.342575. Batch_acc: 0.265815. Batch_loss: 2.129990 \n",
      "Batch: 426. Acc: 0.206136. Loss: 2.342160. Batch_acc: 0.240922. Batch_loss: 2.165062 \n",
      "Batch: 427. Acc: 0.206223. Loss: 2.341728. Batch_acc: 0.243259. Batch_loss: 2.157901 \n",
      "Batch: 428. Acc: 0.206303. Loss: 2.341382. Batch_acc: 0.240456. Batch_loss: 2.194682 \n",
      "Batch: 429. Acc: 0.206372. Loss: 2.340990. Batch_acc: 0.235361. Batch_loss: 2.174824 \n",
      "Batch: 430. Acc: 0.206442. Loss: 2.340642. Batch_acc: 0.236541. Batch_loss: 2.191842 \n",
      "Batch: 431. Acc: 0.206559. Loss: 2.340156. Batch_acc: 0.255631. Batch_loss: 2.135116 \n",
      "Batch: 432. Acc: 0.206663. Loss: 2.339737. Batch_acc: 0.252478. Batch_loss: 2.156365 \n",
      "Batch: 433. Acc: 0.206754. Loss: 2.339416. Batch_acc: 0.247337. Batch_loss: 2.196093 \n",
      "Batch: 434. Acc: 0.206834. Loss: 2.338990. Batch_acc: 0.240793. Batch_loss: 2.157313 \n",
      "Batch: 435. Acc: 0.206908. Loss: 2.338665. Batch_acc: 0.239469. Batch_loss: 2.196764 \n",
      "Batch: 436. Acc: 0.206998. Loss: 2.338252. Batch_acc: 0.245845. Batch_loss: 2.159100 \n",
      "Batch: 437. Acc: 0.207127. Loss: 2.337814. Batch_acc: 0.262415. Batch_loss: 2.149806 \n",
      "Batch: 438. Acc: 0.207241. Loss: 2.337376. Batch_acc: 0.258235. Batch_loss: 2.141563 \n",
      "Batch: 439. Acc: 0.207329. Loss: 2.337015. Batch_acc: 0.246906. Batch_loss: 2.174393 \n",
      "Batch: 440. Acc: 0.207437. Loss: 2.336590. Batch_acc: 0.255196. Batch_loss: 2.149263 \n",
      "Batch: 441. Acc: 0.207549. Loss: 2.336153. Batch_acc: 0.256734. Batch_loss: 2.144005 \n",
      "Batch: 442. Acc: 0.207647. Loss: 2.335730. Batch_acc: 0.251462. Batch_loss: 2.145792 \n",
      "Batch: 443. Acc: 0.207754. Loss: 2.335323. Batch_acc: 0.254066. Batch_loss: 2.159872 \n",
      "Batch: 444. Acc: 0.207862. Loss: 2.334901. Batch_acc: 0.255894. Batch_loss: 2.147498 \n",
      "Batch: 445. Acc: 0.207976. Loss: 2.334483. Batch_acc: 0.258960. Batch_loss: 2.147465 \n",
      "Batch: 446. Acc: 0.208075. Loss: 2.334049. Batch_acc: 0.251569. Batch_loss: 2.142534 \n",
      "Batch: 447. Acc: 0.208212. Loss: 2.333588. Batch_acc: 0.269540. Batch_loss: 2.127574 \n",
      "Batch: 448. Acc: 0.208315. Loss: 2.333184. Batch_acc: 0.254619. Batch_loss: 2.151833 \n",
      "Batch: 449. Acc: 0.208410. Loss: 2.332828. Batch_acc: 0.251594. Batch_loss: 2.171524 \n",
      "Batch: 450. Acc: 0.208523. Loss: 2.332400. Batch_acc: 0.258338. Batch_loss: 2.143302 \n",
      "Batch: 451. Acc: 0.208621. Loss: 2.332024. Batch_acc: 0.252887. Batch_loss: 2.161995 \n",
      "Batch: 452. Acc: 0.208696. Loss: 2.331635. Batch_acc: 0.242442. Batch_loss: 2.157435 \n",
      "Batch: 453. Acc: 0.208803. Loss: 2.331233. Batch_acc: 0.256077. Batch_loss: 2.152366 \n",
      "Batch: 454. Acc: 0.208876. Loss: 2.330873. Batch_acc: 0.242941. Batch_loss: 2.163398 \n",
      "Batch: 455. Acc: 0.208960. Loss: 2.330516. Batch_acc: 0.247262. Batch_loss: 2.168059 \n",
      "Batch: 456. Acc: 0.209054. Loss: 2.330147. Batch_acc: 0.252009. Batch_loss: 2.162056 \n",
      "Batch: 457. Acc: 0.209162. Loss: 2.329731. Batch_acc: 0.257679. Batch_loss: 2.141912 \n",
      "Batch: 458. Acc: 0.209247. Loss: 2.329343. Batch_acc: 0.247458. Batch_loss: 2.154711 \n",
      "Batch: 459. Acc: 0.209349. Loss: 2.328949. Batch_acc: 0.256160. Batch_loss: 2.149259 \n",
      "Batch: 460. Acc: 0.209442. Loss: 2.328556. Batch_acc: 0.253231. Batch_loss: 2.143775 \n",
      "Batch: 461. Acc: 0.209530. Loss: 2.328193. Batch_acc: 0.248879. Batch_loss: 2.165114 \n",
      "Batch: 462. Acc: 0.209618. Loss: 2.327791. Batch_acc: 0.249857. Batch_loss: 2.142692 \n",
      "Batch: 463. Acc: 0.209726. Loss: 2.327415. Batch_acc: 0.260242. Batch_loss: 2.153180 \n",
      "Batch: 464. Acc: 0.209829. Loss: 2.327076. Batch_acc: 0.257454. Batch_loss: 2.170009 \n",
      "Batch: 465. Acc: 0.209960. Loss: 2.326633. Batch_acc: 0.270581. Batch_loss: 2.120918 \n",
      "Batch: 466. Acc: 0.210000. Loss: 2.326342. Batch_acc: 0.229070. Batch_loss: 2.189152 \n",
      "Batch: 467. Acc: 0.210061. Loss: 2.326070. Batch_acc: 0.238841. Batch_loss: 2.197993 \n",
      "Batch: 468. Acc: 0.210140. Loss: 2.325722. Batch_acc: 0.247944. Batch_loss: 2.159389 \n",
      "Batch: 469. Acc: 0.210231. Loss: 2.325352. Batch_acc: 0.252589. Batch_loss: 2.151996 \n",
      "Batch: 470. Acc: 0.210317. Loss: 2.324991. Batch_acc: 0.251756. Batch_loss: 2.152545 \n",
      "Batch: 471. Acc: 0.210407. Loss: 2.324635. Batch_acc: 0.252595. Batch_loss: 2.156414 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.210488. Loss: 2.324299. Batch_acc: 0.250000. Batch_loss: 2.161367 \n",
      "Batch: 473. Acc: 0.210572. Loss: 2.324011. Batch_acc: 0.252263. Batch_loss: 2.181156 \n",
      "Batch: 474. Acc: 0.210664. Loss: 2.323607. Batch_acc: 0.254169. Batch_loss: 2.132104 \n",
      "Batch: 475. Acc: 0.210753. Loss: 2.323249. Batch_acc: 0.251973. Batch_loss: 2.156819 \n",
      "Batch: 476. Acc: 0.210853. Loss: 2.322837. Batch_acc: 0.257919. Batch_loss: 2.130198 \n",
      "Batch: 477. Acc: 0.210953. Loss: 2.322461. Batch_acc: 0.257336. Batch_loss: 2.146707 \n",
      "Batch: 478. Acc: 0.211045. Loss: 2.322093. Batch_acc: 0.255014. Batch_loss: 2.146756 \n",
      "Batch: 479. Acc: 0.211136. Loss: 2.321742. Batch_acc: 0.254902. Batch_loss: 2.153474 \n",
      "Batch: 480. Acc: 0.211245. Loss: 2.321342. Batch_acc: 0.264294. Batch_loss: 2.126476 \n",
      "Batch: 481. Acc: 0.211315. Loss: 2.321013. Batch_acc: 0.244571. Batch_loss: 2.163937 \n",
      "Batch: 482. Acc: 0.211407. Loss: 2.320647. Batch_acc: 0.255575. Batch_loss: 2.145590 \n",
      "Batch: 483. Acc: 0.211486. Loss: 2.320326. Batch_acc: 0.250000. Batch_loss: 2.163229 \n",
      "Batch: 484. Acc: 0.211551. Loss: 2.320032. Batch_acc: 0.243590. Batch_loss: 2.175896 \n",
      "Batch: 485. Acc: 0.211601. Loss: 2.319727. Batch_acc: 0.235530. Batch_loss: 2.172383 \n",
      "Batch: 486. Acc: 0.211701. Loss: 2.319338. Batch_acc: 0.259134. Batch_loss: 2.134605 \n",
      "Batch: 487. Acc: 0.211793. Loss: 2.318972. Batch_acc: 0.256780. Batch_loss: 2.140116 \n",
      "Batch: 488. Acc: 0.211916. Loss: 2.318557. Batch_acc: 0.272046. Batch_loss: 2.115710 \n",
      "Batch: 489. Acc: 0.211955. Loss: 2.318245. Batch_acc: 0.231352. Batch_loss: 2.163939 \n",
      "Batch: 490. Acc: 0.212045. Loss: 2.317864. Batch_acc: 0.255499. Batch_loss: 2.135080 \n",
      "Batch: 491. Acc: 0.212144. Loss: 2.317497. Batch_acc: 0.260870. Batch_loss: 2.135935 \n",
      "Batch: 492. Acc: 0.212260. Loss: 2.317126. Batch_acc: 0.270035. Batch_loss: 2.132728 \n",
      "Batch: 493. Acc: 0.212326. Loss: 2.316814. Batch_acc: 0.244193. Batch_loss: 2.165566 \n",
      "Batch: 494. Acc: 0.212427. Loss: 2.316456. Batch_acc: 0.262041. Batch_loss: 2.140312 \n",
      "Batch: 495. Acc: 0.212528. Loss: 2.316114. Batch_acc: 0.262342. Batch_loss: 2.146924 \n",
      "Batch: 496. Acc: 0.212638. Loss: 2.315722. Batch_acc: 0.266366. Batch_loss: 2.124995 \n",
      "Batch: 497. Acc: 0.212734. Loss: 2.315365. Batch_acc: 0.262492. Batch_loss: 2.129904 \n",
      "Batch: 498. Acc: 0.212833. Loss: 2.315048. Batch_acc: 0.262164. Batch_loss: 2.158083 \n",
      "Batch: 499. Acc: 0.212896. Loss: 2.314736. Batch_acc: 0.243875. Batch_loss: 2.160446 \n",
      "Batch: 500. Acc: 0.212946. Loss: 2.314404. Batch_acc: 0.238234. Batch_loss: 2.147032 \n",
      "Batch: 501. Acc: 0.213014. Loss: 2.314081. Batch_acc: 0.247393. Batch_loss: 2.151069 \n",
      "Batch: 502. Acc: 0.213126. Loss: 2.313665. Batch_acc: 0.269231. Batch_loss: 2.105406 \n",
      "Checkpointing on batch: 502. Accuracy: 0.2131263829680124. Loss per char: 2.313665134014177. Time: 1627203002.3915946\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 14, 22, 19, 15,\n",
      "        25, 20, 18,  1, 66, 79, 69,  1, 14, 18, 26, 20, 15, 18, 18, 25, 23, 23,\n",
      "        15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.213236. Loss: 2.313268. Batch_acc: 0.267304. Batch_loss: 2.118068 \n",
      "Batch: 504. Acc: 0.213331. Loss: 2.312944. Batch_acc: 0.261298. Batch_loss: 2.148232 \n",
      "Batch: 505. Acc: 0.213416. Loss: 2.312638. Batch_acc: 0.257396. Batch_loss: 2.154141 \n",
      "Batch: 506. Acc: 0.213506. Loss: 2.312334. Batch_acc: 0.259733. Batch_loss: 2.156850 \n",
      "Batch: 507. Acc: 0.213585. Loss: 2.311994. Batch_acc: 0.253931. Batch_loss: 2.137463 \n",
      "Batch: 508. Acc: 0.213685. Loss: 2.311640. Batch_acc: 0.263631. Batch_loss: 2.136045 \n",
      "Batch: 509. Acc: 0.213774. Loss: 2.311249. Batch_acc: 0.260000. Batch_loss: 2.107575 \n",
      "Batch: 510. Acc: 0.213841. Loss: 2.310908. Batch_acc: 0.247452. Batch_loss: 2.140154 \n",
      "Batch: 511. Acc: 0.213944. Loss: 2.310579. Batch_acc: 0.267092. Batch_loss: 2.141460 \n",
      "Batch: 512. Acc: 0.214049. Loss: 2.310219. Batch_acc: 0.267898. Batch_loss: 2.124937 \n",
      "Batch: 513. Acc: 0.214158. Loss: 2.309847. Batch_acc: 0.270161. Batch_loss: 2.118940 \n",
      "Batch: 514. Acc: 0.214279. Loss: 2.309443. Batch_acc: 0.276460. Batch_loss: 2.100624 \n",
      "Batch: 515. Acc: 0.214362. Loss: 2.309117. Batch_acc: 0.255866. Batch_loss: 2.146200 \n",
      "Batch: 516. Acc: 0.214483. Loss: 2.308802. Batch_acc: 0.277778. Batch_loss: 2.143844 \n",
      "Batch: 517. Acc: 0.214556. Loss: 2.308462. Batch_acc: 0.251843. Batch_loss: 2.134989 \n",
      "Batch: 518. Acc: 0.214662. Loss: 2.308067. Batch_acc: 0.269605. Batch_loss: 2.104870 \n",
      "Batch: 519. Acc: 0.214743. Loss: 2.307691. Batch_acc: 0.256586. Batch_loss: 2.113293 \n",
      "Batch: 520. Acc: 0.214830. Loss: 2.307345. Batch_acc: 0.258640. Batch_loss: 2.133070 \n",
      "Batch: 521. Acc: 0.214886. Loss: 2.307060. Batch_acc: 0.244226. Batch_loss: 2.157923 \n",
      "Batch: 522. Acc: 0.214982. Loss: 2.306745. Batch_acc: 0.263601. Batch_loss: 2.146598 \n",
      "Batch: 523. Acc: 0.215051. Loss: 2.306487. Batch_acc: 0.251455. Batch_loss: 2.170248 \n",
      "Batch: 524. Acc: 0.215138. Loss: 2.306204. Batch_acc: 0.260057. Batch_loss: 2.160003 \n",
      "Batch: 525. Acc: 0.215231. Loss: 2.305877. Batch_acc: 0.263188. Batch_loss: 2.136812 \n",
      "Batch: 526. Acc: 0.215306. Loss: 2.305572. Batch_acc: 0.254846. Batch_loss: 2.146724 \n",
      "Batch: 527. Acc: 0.215411. Loss: 2.305214. Batch_acc: 0.269778. Batch_loss: 2.118102 \n",
      "Batch: 528. Acc: 0.215483. Loss: 2.304915. Batch_acc: 0.253913. Batch_loss: 2.146285 \n",
      "Batch: 529. Acc: 0.215582. Loss: 2.304541. Batch_acc: 0.267816. Batch_loss: 2.106620 \n",
      "Batch: 530. Acc: 0.215674. Loss: 2.304227. Batch_acc: 0.262867. Batch_loss: 2.144148 \n",
      "Batch: 531. Acc: 0.215773. Loss: 2.303895. Batch_acc: 0.268237. Batch_loss: 2.128142 \n",
      "Batch: 532. Acc: 0.215872. Loss: 2.303566. Batch_acc: 0.269074. Batch_loss: 2.126187 \n",
      "Batch: 533. Acc: 0.215947. Loss: 2.303270. Batch_acc: 0.256041. Batch_loss: 2.145430 \n",
      "Batch: 534. Acc: 0.216041. Loss: 2.302930. Batch_acc: 0.266129. Batch_loss: 2.121583 \n",
      "Batch: 535. Acc: 0.216151. Loss: 2.302556. Batch_acc: 0.274019. Batch_loss: 2.104735 \n",
      "Batch: 536. Acc: 0.216252. Loss: 2.302254. Batch_acc: 0.272565. Batch_loss: 2.134883 \n",
      "Batch: 537. Acc: 0.216289. Loss: 2.302034. Batch_acc: 0.236248. Batch_loss: 2.183050 \n",
      "Batch: 538. Acc: 0.216376. Loss: 2.301715. Batch_acc: 0.262407. Batch_loss: 2.131879 \n",
      "Batch: 539. Acc: 0.216467. Loss: 2.301343. Batch_acc: 0.265074. Batch_loss: 2.102894 \n",
      "Batch: 540. Acc: 0.216541. Loss: 2.301070. Batch_acc: 0.257817. Batch_loss: 2.149871 \n",
      "Batch: 541. Acc: 0.216630. Loss: 2.300761. Batch_acc: 0.265342. Batch_loss: 2.131183 \n",
      "Batch: 542. Acc: 0.216708. Loss: 2.300456. Batch_acc: 0.257778. Batch_loss: 2.140626 \n",
      "Batch: 543. Acc: 0.216804. Loss: 2.300119. Batch_acc: 0.268223. Batch_loss: 2.119223 \n",
      "Batch: 544. Acc: 0.216909. Loss: 2.299768. Batch_acc: 0.273980. Batch_loss: 2.108925 \n",
      "Batch: 545. Acc: 0.216977. Loss: 2.299475. Batch_acc: 0.254366. Batch_loss: 2.138308 \n",
      "Batch: 546. Acc: 0.217050. Loss: 2.299163. Batch_acc: 0.257780. Batch_loss: 2.125338 \n",
      "Batch: 547. Acc: 0.217136. Loss: 2.298855. Batch_acc: 0.264757. Batch_loss: 2.127391 \n",
      "Batch: 548. Acc: 0.217219. Loss: 2.298561. Batch_acc: 0.263097. Batch_loss: 2.135640 \n",
      "Batch: 549. Acc: 0.217309. Loss: 2.298280. Batch_acc: 0.266974. Batch_loss: 2.144313 \n",
      "Batch: 550. Acc: 0.217411. Loss: 2.297958. Batch_acc: 0.273356. Batch_loss: 2.120472 \n",
      "Batch: 551. Acc: 0.217501. Loss: 2.297589. Batch_acc: 0.266553. Batch_loss: 2.097649 \n",
      "Batch: 552. Acc: 0.217589. Loss: 2.297240. Batch_acc: 0.265387. Batch_loss: 2.107970 \n",
      "Batch: 553. Acc: 0.217688. Loss: 2.296869. Batch_acc: 0.272412. Batch_loss: 2.090873 \n",
      "Batch: 554. Acc: 0.217766. Loss: 2.296550. Batch_acc: 0.261710. Batch_loss: 2.116396 \n",
      "Batch: 555. Acc: 0.217846. Loss: 2.296260. Batch_acc: 0.261986. Batch_loss: 2.136552 \n",
      "Batch: 556. Acc: 0.217910. Loss: 2.295949. Batch_acc: 0.254396. Batch_loss: 2.119776 \n",
      "Batch: 557. Acc: 0.217976. Loss: 2.295735. Batch_acc: 0.255108. Batch_loss: 2.174956 \n",
      "Batch: 558. Acc: 0.218079. Loss: 2.295364. Batch_acc: 0.274321. Batch_loss: 2.091714 \n",
      "Batch: 559. Acc: 0.218153. Loss: 2.295075. Batch_acc: 0.260290. Batch_loss: 2.132426 \n",
      "Batch: 560. Acc: 0.218245. Loss: 2.294767. Batch_acc: 0.268623. Batch_loss: 2.125698 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 561. Acc: 0.218310. Loss: 2.294466. Batch_acc: 0.254296. Batch_loss: 2.126526 \n",
      "Batch: 562. Acc: 0.218402. Loss: 2.294128. Batch_acc: 0.270930. Batch_loss: 2.101886 \n",
      "Batch: 563. Acc: 0.218471. Loss: 2.293828. Batch_acc: 0.258560. Batch_loss: 2.120948 \n",
      "Batch: 564. Acc: 0.218547. Loss: 2.293519. Batch_acc: 0.261547. Batch_loss: 2.118165 \n",
      "Batch: 565. Acc: 0.218633. Loss: 2.293194. Batch_acc: 0.266138. Batch_loss: 2.112931 \n",
      "Batch: 566. Acc: 0.218732. Loss: 2.292864. Batch_acc: 0.276084. Batch_loss: 2.102225 \n",
      "Batch: 567. Acc: 0.218814. Loss: 2.292552. Batch_acc: 0.266588. Batch_loss: 2.110359 \n",
      "Batch: 568. Acc: 0.218919. Loss: 2.292235. Batch_acc: 0.278286. Batch_loss: 2.113920 \n",
      "Batch: 569. Acc: 0.218995. Loss: 2.291904. Batch_acc: 0.262881. Batch_loss: 2.100243 \n",
      "Batch: 570. Acc: 0.219071. Loss: 2.291575. Batch_acc: 0.260966. Batch_loss: 2.110368 \n",
      "Batch: 571. Acc: 0.219146. Loss: 2.291253. Batch_acc: 0.262029. Batch_loss: 2.106079 \n",
      "Batch: 572. Acc: 0.219239. Loss: 2.290921. Batch_acc: 0.272727. Batch_loss: 2.099806 \n",
      "Batch: 573. Acc: 0.219280. Loss: 2.290666. Batch_acc: 0.243402. Batch_loss: 2.141893 \n",
      "Batch: 574. Acc: 0.219348. Loss: 2.290412. Batch_acc: 0.258440. Batch_loss: 2.142771 \n",
      "Batch: 575. Acc: 0.219423. Loss: 2.290126. Batch_acc: 0.263620. Batch_loss: 2.122588 \n",
      "Batch: 576. Acc: 0.219496. Loss: 2.289849. Batch_acc: 0.261521. Batch_loss: 2.130490 \n",
      "Batch: 577. Acc: 0.219568. Loss: 2.289580. Batch_acc: 0.261529. Batch_loss: 2.131835 \n",
      "Batch: 578. Acc: 0.219654. Loss: 2.289256. Batch_acc: 0.268087. Batch_loss: 2.106996 \n",
      "Batch: 579. Acc: 0.219756. Loss: 2.288939. Batch_acc: 0.277809. Batch_loss: 2.108551 \n",
      "Batch: 580. Acc: 0.219842. Loss: 2.288639. Batch_acc: 0.269832. Batch_loss: 2.114046 \n",
      "Batch: 581. Acc: 0.219919. Loss: 2.288335. Batch_acc: 0.265165. Batch_loss: 2.110606 \n",
      "Batch: 582. Acc: 0.220001. Loss: 2.288093. Batch_acc: 0.269529. Batch_loss: 2.142524 \n",
      "Batch: 583. Acc: 0.220074. Loss: 2.287826. Batch_acc: 0.262136. Batch_loss: 2.133124 \n",
      "Batch: 584. Acc: 0.220174. Loss: 2.287492. Batch_acc: 0.277339. Batch_loss: 2.096691 \n",
      "Batch: 585. Acc: 0.220274. Loss: 2.287135. Batch_acc: 0.279056. Batch_loss: 2.078327 \n",
      "Batch: 586. Acc: 0.220343. Loss: 2.286871. Batch_acc: 0.260669. Batch_loss: 2.131624 \n",
      "Batch: 587. Acc: 0.220425. Loss: 2.286536. Batch_acc: 0.268391. Batch_loss: 2.089979 \n",
      "Batch: 588. Acc: 0.220504. Loss: 2.286253. Batch_acc: 0.267401. Batch_loss: 2.118444 \n",
      "Batch: 589. Acc: 0.220577. Loss: 2.285959. Batch_acc: 0.263615. Batch_loss: 2.112087 \n",
      "Batch: 590. Acc: 0.220642. Loss: 2.285671. Batch_acc: 0.260306. Batch_loss: 2.111866 \n",
      "Batch: 591. Acc: 0.220725. Loss: 2.285392. Batch_acc: 0.269297. Batch_loss: 2.121243 \n",
      "Batch: 592. Acc: 0.220822. Loss: 2.285084. Batch_acc: 0.278226. Batch_loss: 2.102795 \n",
      "Batch: 593. Acc: 0.220902. Loss: 2.284808. Batch_acc: 0.269321. Batch_loss: 2.118465 \n",
      "Batch: 594. Acc: 0.221014. Loss: 2.284467. Batch_acc: 0.284845. Batch_loss: 2.089528 \n",
      "Batch: 595. Acc: 0.221074. Loss: 2.284235. Batch_acc: 0.257780. Batch_loss: 2.143632 \n",
      "Batch: 596. Acc: 0.221132. Loss: 2.284020. Batch_acc: 0.256903. Batch_loss: 2.150301 \n",
      "Batch: 597. Acc: 0.221227. Loss: 2.283711. Batch_acc: 0.277937. Batch_loss: 2.099725 \n",
      "Batch: 598. Acc: 0.221317. Loss: 2.283394. Batch_acc: 0.274011. Batch_loss: 2.097207 \n",
      "Batch: 599. Acc: 0.221402. Loss: 2.283090. Batch_acc: 0.273208. Batch_loss: 2.097561 \n",
      "Batch: 600. Acc: 0.221489. Loss: 2.282838. Batch_acc: 0.274249. Batch_loss: 2.131261 \n",
      "Batch: 601. Acc: 0.221586. Loss: 2.282530. Batch_acc: 0.278754. Batch_loss: 2.100021 \n",
      "Batch: 602. Acc: 0.221672. Loss: 2.282244. Batch_acc: 0.273303. Batch_loss: 2.110115 \n",
      "Batch: 603. Acc: 0.221762. Loss: 2.281933. Batch_acc: 0.273678. Batch_loss: 2.102429 \n",
      "Batch: 604. Acc: 0.221846. Loss: 2.281648. Batch_acc: 0.272884. Batch_loss: 2.109610 \n",
      "Batch: 605. Acc: 0.221939. Loss: 2.281330. Batch_acc: 0.277937. Batch_loss: 2.089566 \n",
      "Batch: 606. Acc: 0.222016. Loss: 2.281078. Batch_acc: 0.269388. Batch_loss: 2.126467 \n",
      "Batch: 607. Acc: 0.222087. Loss: 2.280819. Batch_acc: 0.265461. Batch_loss: 2.121766 \n",
      "Batch: 608. Acc: 0.222156. Loss: 2.280583. Batch_acc: 0.264282. Batch_loss: 2.136383 \n",
      "Batch: 609. Acc: 0.222209. Loss: 2.280274. Batch_acc: 0.253363. Batch_loss: 2.097373 \n",
      "Batch: 610. Acc: 0.222299. Loss: 2.279973. Batch_acc: 0.277019. Batch_loss: 2.098199 \n",
      "Batch: 611. Acc: 0.222389. Loss: 2.279666. Batch_acc: 0.276644. Batch_loss: 2.094728 \n",
      "Batch: 612. Acc: 0.222475. Loss: 2.279347. Batch_acc: 0.273649. Batch_loss: 2.088747 \n",
      "Batch: 613. Acc: 0.222531. Loss: 2.279041. Batch_acc: 0.256483. Batch_loss: 2.095077 \n",
      "Batch: 614. Acc: 0.222620. Loss: 2.278739. Batch_acc: 0.276888. Batch_loss: 2.094174 \n",
      "Batch: 615. Acc: 0.222714. Loss: 2.278420. Batch_acc: 0.280229. Batch_loss: 2.083039 \n",
      "Batch: 616. Acc: 0.222801. Loss: 2.278082. Batch_acc: 0.276932. Batch_loss: 2.066508 \n",
      "Batch: 617. Acc: 0.222893. Loss: 2.277788. Batch_acc: 0.278339. Batch_loss: 2.101073 \n",
      "Batch: 618. Acc: 0.222974. Loss: 2.277492. Batch_acc: 0.272831. Batch_loss: 2.095881 \n",
      "Batch: 619. Acc: 0.223051. Loss: 2.277225. Batch_acc: 0.271147. Batch_loss: 2.110615 \n",
      "Batch: 620. Acc: 0.223145. Loss: 2.276915. Batch_acc: 0.280226. Batch_loss: 2.088111 \n",
      "Batch: 621. Acc: 0.223221. Loss: 2.276593. Batch_acc: 0.269404. Batch_loss: 2.081339 \n",
      "Batch: 622. Acc: 0.223289. Loss: 2.276337. Batch_acc: 0.265040. Batch_loss: 2.119352 \n",
      "Batch: 623. Acc: 0.223378. Loss: 2.276035. Batch_acc: 0.277035. Batch_loss: 2.093476 \n",
      "Batch: 624. Acc: 0.223442. Loss: 2.275782. Batch_acc: 0.262472. Batch_loss: 2.120248 \n",
      "Batch: 625. Acc: 0.223541. Loss: 2.275494. Batch_acc: 0.285386. Batch_loss: 2.095472 \n",
      "Batch: 626. Acc: 0.223622. Loss: 2.275215. Batch_acc: 0.274600. Batch_loss: 2.102057 \n",
      "Batch: 627. Acc: 0.223680. Loss: 2.274975. Batch_acc: 0.259861. Batch_loss: 2.123160 \n",
      "Batch: 628. Acc: 0.223749. Loss: 2.274685. Batch_acc: 0.266591. Batch_loss: 2.095163 \n",
      "Batch: 629. Acc: 0.223817. Loss: 2.274482. Batch_acc: 0.267211. Batch_loss: 2.144659 \n",
      "Batch: 630. Acc: 0.223883. Loss: 2.274224. Batch_acc: 0.265446. Batch_loss: 2.112430 \n",
      "Batch: 631. Acc: 0.223950. Loss: 2.274006. Batch_acc: 0.265643. Batch_loss: 2.138239 \n",
      "Batch: 632. Acc: 0.224030. Loss: 2.273701. Batch_acc: 0.274175. Batch_loss: 2.083315 \n",
      "Batch: 633. Acc: 0.224089. Loss: 2.273465. Batch_acc: 0.261529. Batch_loss: 2.121941 \n",
      "Batch: 634. Acc: 0.224156. Loss: 2.273187. Batch_acc: 0.266179. Batch_loss: 2.100368 \n",
      "Batch: 635. Acc: 0.224218. Loss: 2.272910. Batch_acc: 0.264173. Batch_loss: 2.094414 \n",
      "Batch: 636. Acc: 0.224289. Loss: 2.272679. Batch_acc: 0.270334. Batch_loss: 2.123426 \n",
      "Batch: 637. Acc: 0.224387. Loss: 2.272419. Batch_acc: 0.286790. Batch_loss: 2.105589 \n",
      "Batch: 638. Acc: 0.224449. Loss: 2.272177. Batch_acc: 0.264335. Batch_loss: 2.118158 \n",
      "Batch: 639. Acc: 0.224506. Loss: 2.271933. Batch_acc: 0.260495. Batch_loss: 2.116027 \n",
      "Batch: 640. Acc: 0.224592. Loss: 2.271632. Batch_acc: 0.278305. Batch_loss: 2.085022 \n",
      "Batch: 641. Acc: 0.224684. Loss: 2.271367. Batch_acc: 0.285292. Batch_loss: 2.096936 \n",
      "Batch: 642. Acc: 0.224759. Loss: 2.271095. Batch_acc: 0.272105. Batch_loss: 2.097854 \n",
      "Batch: 643. Acc: 0.224800. Loss: 2.270849. Batch_acc: 0.250423. Batch_loss: 2.115559 \n",
      "Batch: 644. Acc: 0.224864. Loss: 2.270598. Batch_acc: 0.266361. Batch_loss: 2.109341 \n",
      "Batch: 645. Acc: 0.224954. Loss: 2.270310. Batch_acc: 0.282534. Batch_loss: 2.086500 \n",
      "Batch: 646. Acc: 0.225028. Loss: 2.270024. Batch_acc: 0.273095. Batch_loss: 2.084306 \n",
      "Batch: 647. Acc: 0.225111. Loss: 2.269752. Batch_acc: 0.278539. Batch_loss: 2.095156 \n",
      "Batch: 648. Acc: 0.225195. Loss: 2.269470. Batch_acc: 0.279403. Batch_loss: 2.087197 \n",
      "Batch: 649. Acc: 0.225248. Loss: 2.269262. Batch_acc: 0.259977. Batch_loss: 2.131362 \n",
      "Batch: 650. Acc: 0.225303. Loss: 2.268992. Batch_acc: 0.261095. Batch_loss: 2.093399 \n",
      "Batch: 651. Acc: 0.225392. Loss: 2.268685. Batch_acc: 0.282109. Batch_loss: 2.073644 \n",
      "Batch: 652. Acc: 0.225450. Loss: 2.268434. Batch_acc: 0.263339. Batch_loss: 2.105393 \n",
      "Batch: 653. Acc: 0.225522. Loss: 2.268204. Batch_acc: 0.273154. Batch_loss: 2.115217 \n",
      "Batch: 654. Acc: 0.225590. Loss: 2.267940. Batch_acc: 0.270459. Batch_loss: 2.093983 \n",
      "Batch: 655. Acc: 0.225682. Loss: 2.267651. Batch_acc: 0.286043. Batch_loss: 2.078542 \n",
      "Batch: 656. Acc: 0.225771. Loss: 2.267364. Batch_acc: 0.283126. Batch_loss: 2.081764 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 657. Acc: 0.225811. Loss: 2.267155. Batch_acc: 0.252018. Batch_loss: 2.129925 \n",
      "Batch: 658. Acc: 0.225866. Loss: 2.266922. Batch_acc: 0.262727. Batch_loss: 2.110526 \n",
      "Batch: 659. Acc: 0.225944. Loss: 2.266660. Batch_acc: 0.276427. Batch_loss: 2.097258 \n",
      "Batch: 660. Acc: 0.226010. Loss: 2.266436. Batch_acc: 0.269099. Batch_loss: 2.119660 \n",
      "Batch: 661. Acc: 0.226086. Loss: 2.266170. Batch_acc: 0.276278. Batch_loss: 2.090709 \n",
      "Batch: 662. Acc: 0.226144. Loss: 2.265948. Batch_acc: 0.265838. Batch_loss: 2.114531 \n",
      "Batch: 663. Acc: 0.226188. Loss: 2.265738. Batch_acc: 0.255828. Batch_loss: 2.124950 \n",
      "Batch: 664. Acc: 0.226259. Loss: 2.265504. Batch_acc: 0.273623. Batch_loss: 2.108867 \n",
      "Batch: 665. Acc: 0.226338. Loss: 2.265247. Batch_acc: 0.278868. Batch_loss: 2.094066 \n",
      "Batch: 666. Acc: 0.226425. Loss: 2.264975. Batch_acc: 0.282755. Batch_loss: 2.088660 \n",
      "Batch: 667. Acc: 0.226476. Loss: 2.264773. Batch_acc: 0.260672. Batch_loss: 2.131520 \n",
      "Batch: 668. Acc: 0.226535. Loss: 2.264579. Batch_acc: 0.265436. Batch_loss: 2.134424 \n",
      "Batch: 669. Acc: 0.226610. Loss: 2.264309. Batch_acc: 0.277233. Batch_loss: 2.083464 \n",
      "Batch: 670. Acc: 0.226676. Loss: 2.264056. Batch_acc: 0.270785. Batch_loss: 2.093863 \n",
      "Batch: 671. Acc: 0.226742. Loss: 2.263811. Batch_acc: 0.271619. Batch_loss: 2.097543 \n",
      "Batch: 672. Acc: 0.226783. Loss: 2.263631. Batch_acc: 0.254619. Batch_loss: 2.142220 \n",
      "Batch: 673. Acc: 0.226848. Loss: 2.263436. Batch_acc: 0.269252. Batch_loss: 2.135445 \n",
      "Batch: 674. Acc: 0.226926. Loss: 2.263166. Batch_acc: 0.279907. Batch_loss: 2.079508 \n",
      "Batch: 675. Acc: 0.227002. Loss: 2.262947. Batch_acc: 0.277778. Batch_loss: 2.117080 \n",
      "Batch: 676. Acc: 0.227061. Loss: 2.262722. Batch_acc: 0.267281. Batch_loss: 2.110816 \n",
      "Batch: 677. Acc: 0.227123. Loss: 2.262492. Batch_acc: 0.268640. Batch_loss: 2.108225 \n",
      "Batch: 678. Acc: 0.227165. Loss: 2.262251. Batch_acc: 0.255172. Batch_loss: 2.099221 \n",
      "Batch: 679. Acc: 0.227222. Loss: 2.262030. Batch_acc: 0.266436. Batch_loss: 2.111048 \n",
      "Batch: 680. Acc: 0.227294. Loss: 2.261784. Batch_acc: 0.276896. Batch_loss: 2.090968 \n",
      "Batch: 681. Acc: 0.227366. Loss: 2.261503. Batch_acc: 0.274017. Batch_loss: 2.080098 \n",
      "Batch: 682. Acc: 0.227465. Loss: 2.261233. Batch_acc: 0.293984. Batch_loss: 2.079873 \n",
      "Batch: 683. Acc: 0.227532. Loss: 2.261017. Batch_acc: 0.274985. Batch_loss: 2.109069 \n",
      "Batch: 684. Acc: 0.227597. Loss: 2.260758. Batch_acc: 0.272994. Batch_loss: 2.080232 \n",
      "Batch: 685. Acc: 0.227670. Loss: 2.260515. Batch_acc: 0.277940. Batch_loss: 2.090962 \n",
      "Batch: 686. Acc: 0.227718. Loss: 2.260298. Batch_acc: 0.259610. Batch_loss: 2.116160 \n",
      "Batch: 687. Acc: 0.227791. Loss: 2.260066. Batch_acc: 0.277904. Batch_loss: 2.102764 \n",
      "Batch: 688. Acc: 0.227850. Loss: 2.259856. Batch_acc: 0.268849. Batch_loss: 2.113120 \n",
      "Batch: 689. Acc: 0.227929. Loss: 2.259609. Batch_acc: 0.282496. Batch_loss: 2.088217 \n",
      "Batch: 690. Acc: 0.227984. Loss: 2.259379. Batch_acc: 0.265982. Batch_loss: 2.102043 \n",
      "Batch: 691. Acc: 0.228059. Loss: 2.259126. Batch_acc: 0.279403. Batch_loss: 2.084841 \n",
      "Batch: 692. Acc: 0.228125. Loss: 2.258876. Batch_acc: 0.275431. Batch_loss: 2.080244 \n",
      "Batch: 693. Acc: 0.228200. Loss: 2.258646. Batch_acc: 0.282297. Batch_loss: 2.092405 \n",
      "Batch: 694. Acc: 0.228272. Loss: 2.258388. Batch_acc: 0.278063. Batch_loss: 2.081504 \n",
      "Batch: 695. Acc: 0.228350. Loss: 2.258137. Batch_acc: 0.282272. Batch_loss: 2.084126 \n",
      "Batch: 696. Acc: 0.228415. Loss: 2.257931. Batch_acc: 0.274336. Batch_loss: 2.110725 \n",
      "Batch: 697. Acc: 0.228467. Loss: 2.257725. Batch_acc: 0.265414. Batch_loss: 2.111432 \n",
      "Batch: 698. Acc: 0.228523. Loss: 2.257514. Batch_acc: 0.268279. Batch_loss: 2.110269 \n",
      "Batch: 699. Acc: 0.228602. Loss: 2.257276. Batch_acc: 0.284302. Batch_loss: 2.088948 \n",
      "Batch: 700. Acc: 0.228670. Loss: 2.257066. Batch_acc: 0.275982. Batch_loss: 2.109428 \n",
      "Batch: 701. Acc: 0.228706. Loss: 2.256869. Batch_acc: 0.254023. Batch_loss: 2.118796 \n",
      "Batch: 702. Acc: 0.228774. Loss: 2.256622. Batch_acc: 0.276413. Batch_loss: 2.085003 \n",
      "Batch: 703. Acc: 0.228828. Loss: 2.256382. Batch_acc: 0.267333. Batch_loss: 2.083725 \n",
      "Batch: 704. Acc: 0.228885. Loss: 2.256159. Batch_acc: 0.269364. Batch_loss: 2.098138 \n",
      "Batch: 705. Acc: 0.228950. Loss: 2.255932. Batch_acc: 0.275043. Batch_loss: 2.095537 \n",
      "Batch: 706. Acc: 0.229028. Loss: 2.255672. Batch_acc: 0.283901. Batch_loss: 2.071574 \n",
      "Batch: 707. Acc: 0.229094. Loss: 2.255424. Batch_acc: 0.274554. Batch_loss: 2.084819 \n",
      "Batch: 708. Acc: 0.229172. Loss: 2.255181. Batch_acc: 0.284483. Batch_loss: 2.083554 \n",
      "Batch: 709. Acc: 0.229240. Loss: 2.254937. Batch_acc: 0.276897. Batch_loss: 2.084539 \n",
      "Batch: 710. Acc: 0.229350. Loss: 2.254617. Batch_acc: 0.305151. Batch_loss: 2.033893 \n",
      "Batch: 711. Acc: 0.229376. Loss: 2.254426. Batch_acc: 0.247953. Batch_loss: 2.116113 \n",
      "Batch: 712. Acc: 0.229449. Loss: 2.254156. Batch_acc: 0.281161. Batch_loss: 2.064321 \n",
      "Batch: 713. Acc: 0.229472. Loss: 2.254004. Batch_acc: 0.245748. Batch_loss: 2.142887 \n",
      "Batch: 714. Acc: 0.229543. Loss: 2.253748. Batch_acc: 0.279772. Batch_loss: 2.072892 \n",
      "Batch: 715. Acc: 0.229592. Loss: 2.253554. Batch_acc: 0.264790. Batch_loss: 2.115456 \n",
      "Batch: 716. Acc: 0.229659. Loss: 2.253338. Batch_acc: 0.276958. Batch_loss: 2.100288 \n",
      "Batch: 717. Acc: 0.229718. Loss: 2.253146. Batch_acc: 0.272516. Batch_loss: 2.114100 \n",
      "Batch: 718. Acc: 0.229789. Loss: 2.252906. Batch_acc: 0.281797. Batch_loss: 2.078201 \n",
      "Batch: 719. Acc: 0.229842. Loss: 2.252714. Batch_acc: 0.267581. Batch_loss: 2.115565 \n",
      "Batch: 720. Acc: 0.229908. Loss: 2.252488. Batch_acc: 0.275843. Batch_loss: 2.094090 \n",
      "Batch: 721. Acc: 0.229974. Loss: 2.252259. Batch_acc: 0.279248. Batch_loss: 2.083473 \n",
      "Batch: 722. Acc: 0.230041. Loss: 2.252030. Batch_acc: 0.278035. Batch_loss: 2.085413 \n",
      "Batch: 723. Acc: 0.230101. Loss: 2.251797. Batch_acc: 0.273618. Batch_loss: 2.083310 \n",
      "Batch: 724. Acc: 0.230173. Loss: 2.251522. Batch_acc: 0.281285. Batch_loss: 2.056509 \n",
      "Batch: 725. Acc: 0.230214. Loss: 2.251315. Batch_acc: 0.260102. Batch_loss: 2.103062 \n",
      "Batch: 726. Acc: 0.230297. Loss: 2.251066. Batch_acc: 0.290138. Batch_loss: 2.070784 \n",
      "Batch: 727. Acc: 0.230367. Loss: 2.250829. Batch_acc: 0.280963. Batch_loss: 2.079052 \n",
      "Batch: 728. Acc: 0.230452. Loss: 2.250596. Batch_acc: 0.292529. Batch_loss: 2.081088 \n",
      "Batch: 729. Acc: 0.230529. Loss: 2.250352. Batch_acc: 0.286705. Batch_loss: 2.071684 \n",
      "Batch: 730. Acc: 0.230582. Loss: 2.250137. Batch_acc: 0.269297. Batch_loss: 2.093814 \n",
      "Batch: 731. Acc: 0.230643. Loss: 2.249917. Batch_acc: 0.274276. Batch_loss: 2.091118 \n",
      "Batch: 732. Acc: 0.230715. Loss: 2.249676. Batch_acc: 0.283191. Batch_loss: 2.075228 \n",
      "Batch: 733. Acc: 0.230787. Loss: 2.249443. Batch_acc: 0.282880. Batch_loss: 2.081203 \n",
      "Batch: 734. Acc: 0.230830. Loss: 2.249249. Batch_acc: 0.262164. Batch_loss: 2.107533 \n",
      "Batch: 735. Acc: 0.230884. Loss: 2.249035. Batch_acc: 0.270534. Batch_loss: 2.092286 \n",
      "Batch: 736. Acc: 0.230935. Loss: 2.248831. Batch_acc: 0.268166. Batch_loss: 2.097712 \n",
      "Batch: 737. Acc: 0.230998. Loss: 2.248621. Batch_acc: 0.278555. Batch_loss: 2.091817 \n",
      "Batch: 738. Acc: 0.231056. Loss: 2.248415. Batch_acc: 0.274985. Batch_loss: 2.092383 \n",
      "Batch: 739. Acc: 0.231107. Loss: 2.248184. Batch_acc: 0.268571. Batch_loss: 2.078422 \n",
      "Batch: 740. Acc: 0.231166. Loss: 2.247966. Batch_acc: 0.273810. Batch_loss: 2.089545 \n",
      "Batch: 741. Acc: 0.231205. Loss: 2.247801. Batch_acc: 0.261025. Batch_loss: 2.120509 \n",
      "Batch: 742. Acc: 0.231255. Loss: 2.247595. Batch_acc: 0.268195. Batch_loss: 2.096026 \n",
      "Batch: 743. Acc: 0.231307. Loss: 2.247373. Batch_acc: 0.270426. Batch_loss: 2.082300 \n",
      "Batch: 744. Acc: 0.231367. Loss: 2.247170. Batch_acc: 0.275446. Batch_loss: 2.096073 \n",
      "Batch: 745. Acc: 0.231439. Loss: 2.246927. Batch_acc: 0.285714. Batch_loss: 2.065130 \n",
      "Batch: 746. Acc: 0.231484. Loss: 2.246742. Batch_acc: 0.266787. Batch_loss: 2.102360 \n",
      "Batch: 747. Acc: 0.231542. Loss: 2.246555. Batch_acc: 0.275924. Batch_loss: 2.101768 \n",
      "Batch: 748. Acc: 0.231610. Loss: 2.246373. Batch_acc: 0.281730. Batch_loss: 2.112295 \n",
      "Batch: 749. Acc: 0.231669. Loss: 2.246146. Batch_acc: 0.275470. Batch_loss: 2.077662 \n",
      "Batch: 750. Acc: 0.231728. Loss: 2.245966. Batch_acc: 0.276583. Batch_loss: 2.109774 \n",
      "Batch: 751. Acc: 0.231770. Loss: 2.245787. Batch_acc: 0.263218. Batch_loss: 2.111183 \n",
      "Batch: 752. Acc: 0.231835. Loss: 2.245543. Batch_acc: 0.280641. Batch_loss: 2.063263 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 753. Acc: 0.231863. Loss: 2.245381. Batch_acc: 0.252971. Batch_loss: 2.125078 \n",
      "Checkpointing on batch: 753. Accuracy: 0.2318634999168278. Loss per char: 2.2453808190020252. Time: 1627203181.4777737\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 19, 25, 23, 20, 19, 15, 21, 24,  1,\n",
      "        78, 74, 79, 86, 84,  1, 23, 19, 17, 23, 21, 18, 21, 22, 32,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.231917. Loss: 2.245205. Batch_acc: 0.272464. Batch_loss: 2.111274 \n",
      "Batch: 755. Acc: 0.231973. Loss: 2.245018. Batch_acc: 0.274453. Batch_loss: 2.104357 \n",
      "Batch: 756. Acc: 0.232041. Loss: 2.244793. Batch_acc: 0.282572. Batch_loss: 2.078081 \n",
      "Batch: 757. Acc: 0.232077. Loss: 2.244638. Batch_acc: 0.259174. Batch_loss: 2.127237 \n",
      "Batch: 758. Acc: 0.232141. Loss: 2.244435. Batch_acc: 0.281525. Batch_loss: 2.087933 \n",
      "Batch: 759. Acc: 0.232195. Loss: 2.244249. Batch_acc: 0.272416. Batch_loss: 2.103887 \n",
      "Batch: 760. Acc: 0.232248. Loss: 2.244051. Batch_acc: 0.271508. Batch_loss: 2.097733 \n",
      "Batch: 761. Acc: 0.232300. Loss: 2.243824. Batch_acc: 0.271696. Batch_loss: 2.073548 \n",
      "Batch: 762. Acc: 0.232351. Loss: 2.243610. Batch_acc: 0.271930. Batch_loss: 2.078017 \n",
      "Batch: 763. Acc: 0.232433. Loss: 2.243372. Batch_acc: 0.295271. Batch_loss: 2.061566 \n",
      "Batch: 764. Acc: 0.232497. Loss: 2.243146. Batch_acc: 0.280551. Batch_loss: 2.071088 \n",
      "Batch: 765. Acc: 0.232564. Loss: 2.242940. Batch_acc: 0.284880. Batch_loss: 2.082911 \n",
      "Batch: 766. Acc: 0.232611. Loss: 2.242774. Batch_acc: 0.269074. Batch_loss: 2.114166 \n",
      "Batch: 767. Acc: 0.232686. Loss: 2.242528. Batch_acc: 0.290583. Batch_loss: 2.053154 \n",
      "Batch: 768. Acc: 0.232748. Loss: 2.242332. Batch_acc: 0.280834. Batch_loss: 2.090774 \n",
      "Batch: 769. Acc: 0.232793. Loss: 2.242175. Batch_acc: 0.267049. Batch_loss: 2.121503 \n",
      "Batch: 770. Acc: 0.232861. Loss: 2.241987. Batch_acc: 0.285548. Batch_loss: 2.095926 \n",
      "Batch: 771. Acc: 0.232906. Loss: 2.241770. Batch_acc: 0.267315. Batch_loss: 2.075329 \n",
      "Batch: 772. Acc: 0.232941. Loss: 2.241593. Batch_acc: 0.260163. Batch_loss: 2.104013 \n",
      "Batch: 773. Acc: 0.233002. Loss: 2.241358. Batch_acc: 0.278900. Batch_loss: 2.064019 \n",
      "Batch: 774. Acc: 0.233059. Loss: 2.241156. Batch_acc: 0.277233. Batch_loss: 2.084634 \n",
      "Batch: 775. Acc: 0.233127. Loss: 2.240926. Batch_acc: 0.284594. Batch_loss: 2.067344 \n",
      "Batch: 776. Acc: 0.233183. Loss: 2.240739. Batch_acc: 0.277011. Batch_loss: 2.095714 \n",
      "Batch: 777. Acc: 0.233228. Loss: 2.240594. Batch_acc: 0.269095. Batch_loss: 2.125741 \n",
      "Batch: 778. Acc: 0.233281. Loss: 2.240421. Batch_acc: 0.274693. Batch_loss: 2.103726 \n",
      "Batch: 779. Acc: 0.233339. Loss: 2.240233. Batch_acc: 0.277904. Batch_loss: 2.095347 \n",
      "Batch: 780. Acc: 0.233389. Loss: 2.240070. Batch_acc: 0.272517. Batch_loss: 2.111819 \n",
      "Batch: 781. Acc: 0.233435. Loss: 2.239921. Batch_acc: 0.269143. Batch_loss: 2.124613 \n",
      "Batch: 782. Acc: 0.233487. Loss: 2.239733. Batch_acc: 0.274840. Batch_loss: 2.091404 \n",
      "Batch: 783. Acc: 0.233546. Loss: 2.239523. Batch_acc: 0.279070. Batch_loss: 2.077482 \n",
      "Batch: 784. Acc: 0.233601. Loss: 2.239332. Batch_acc: 0.276744. Batch_loss: 2.087622 \n",
      "Batch: 785. Acc: 0.233652. Loss: 2.239145. Batch_acc: 0.273190. Batch_loss: 2.094929 \n",
      "Batch: 786. Acc: 0.233705. Loss: 2.238941. Batch_acc: 0.275645. Batch_loss: 2.079525 \n",
      "Batch: 787. Acc: 0.233750. Loss: 2.238753. Batch_acc: 0.270190. Batch_loss: 2.085720 \n",
      "Batch: 788. Acc: 0.233790. Loss: 2.238590. Batch_acc: 0.265815. Batch_loss: 2.108976 \n",
      "Batch: 789. Acc: 0.233848. Loss: 2.238399. Batch_acc: 0.278345. Batch_loss: 2.090437 \n",
      "Batch: 790. Acc: 0.233909. Loss: 2.238220. Batch_acc: 0.282360. Batch_loss: 2.097092 \n",
      "Batch: 791. Acc: 0.233938. Loss: 2.238064. Batch_acc: 0.257143. Batch_loss: 2.112791 \n",
      "Batch: 792. Acc: 0.233976. Loss: 2.237878. Batch_acc: 0.263800. Batch_loss: 2.089011 \n",
      "Batch: 793. Acc: 0.234032. Loss: 2.237695. Batch_acc: 0.278990. Batch_loss: 2.093185 \n",
      "Batch: 794. Acc: 0.234085. Loss: 2.237506. Batch_acc: 0.275626. Batch_loss: 2.089281 \n",
      "Batch: 795. Acc: 0.234128. Loss: 2.237333. Batch_acc: 0.268012. Batch_loss: 2.099155 \n",
      "Batch: 796. Acc: 0.234196. Loss: 2.237121. Batch_acc: 0.288495. Batch_loss: 2.069562 \n",
      "Batch: 797. Acc: 0.234241. Loss: 2.236957. Batch_acc: 0.270006. Batch_loss: 2.106242 \n",
      "Batch: 798. Acc: 0.234286. Loss: 2.236790. Batch_acc: 0.270870. Batch_loss: 2.100842 \n",
      "Batch: 799. Acc: 0.234339. Loss: 2.236612. Batch_acc: 0.275921. Batch_loss: 2.097085 \n",
      "Batch: 800. Acc: 0.234394. Loss: 2.236422. Batch_acc: 0.277841. Batch_loss: 2.086378 \n",
      "Batch: 801. Acc: 0.234466. Loss: 2.236226. Batch_acc: 0.291011. Batch_loss: 2.083045 \n",
      "Batch: 802. Acc: 0.234533. Loss: 2.236011. Batch_acc: 0.287337. Batch_loss: 2.065422 \n",
      "Batch: 803. Acc: 0.234573. Loss: 2.235825. Batch_acc: 0.265837. Batch_loss: 2.089007 \n",
      "Batch: 804. Acc: 0.234627. Loss: 2.235624. Batch_acc: 0.279043. Batch_loss: 2.071821 \n",
      "Batch: 805. Acc: 0.234673. Loss: 2.235462. Batch_acc: 0.272673. Batch_loss: 2.101147 \n",
      "Batch: 806. Acc: 0.234726. Loss: 2.235298. Batch_acc: 0.277520. Batch_loss: 2.102368 \n",
      "Batch: 807. Acc: 0.234780. Loss: 2.235111. Batch_acc: 0.277001. Batch_loss: 2.087985 \n",
      "Batch: 808. Acc: 0.234832. Loss: 2.234952. Batch_acc: 0.277520. Batch_loss: 2.105726 \n",
      "Batch: 809. Acc: 0.234894. Loss: 2.234736. Batch_acc: 0.285714. Batch_loss: 2.058554 \n",
      "Batch: 810. Acc: 0.234945. Loss: 2.234579. Batch_acc: 0.276508. Batch_loss: 2.105543 \n",
      "Batch: 811. Acc: 0.235007. Loss: 2.234383. Batch_acc: 0.283731. Batch_loss: 2.080640 \n",
      "Batch: 812. Acc: 0.235070. Loss: 2.234171. Batch_acc: 0.285551. Batch_loss: 2.063718 \n",
      "Batch: 813. Acc: 0.235123. Loss: 2.234001. Batch_acc: 0.277937. Batch_loss: 2.096484 \n",
      "Batch: 814. Acc: 0.235194. Loss: 2.233770. Batch_acc: 0.292669. Batch_loss: 2.046227 \n",
      "Batch: 815. Acc: 0.235255. Loss: 2.233564. Batch_acc: 0.284576. Batch_loss: 2.067422 \n",
      "Batch: 816. Acc: 0.235302. Loss: 2.233393. Batch_acc: 0.273140. Batch_loss: 2.095927 \n",
      "Batch: 817. Acc: 0.235364. Loss: 2.233193. Batch_acc: 0.285959. Batch_loss: 2.070610 \n",
      "Batch: 818. Acc: 0.235454. Loss: 2.232965. Batch_acc: 0.307475. Batch_loss: 2.049544 \n",
      "Batch: 819. Acc: 0.235513. Loss: 2.232797. Batch_acc: 0.283838. Batch_loss: 2.096011 \n",
      "Batch: 820. Acc: 0.235575. Loss: 2.232604. Batch_acc: 0.287123. Batch_loss: 2.072997 \n",
      "Batch: 821. Acc: 0.235598. Loss: 2.232487. Batch_acc: 0.254662. Batch_loss: 2.135651 \n",
      "Batch: 822. Acc: 0.235646. Loss: 2.232324. Batch_acc: 0.275742. Batch_loss: 2.096449 \n",
      "Batch: 823. Acc: 0.235699. Loss: 2.232178. Batch_acc: 0.279765. Batch_loss: 2.109744 \n",
      "Batch: 824. Acc: 0.235768. Loss: 2.231946. Batch_acc: 0.289967. Batch_loss: 2.048747 \n",
      "Batch: 825. Acc: 0.235807. Loss: 2.231787. Batch_acc: 0.268519. Batch_loss: 2.099988 \n",
      "Batch: 826. Acc: 0.235851. Loss: 2.231644. Batch_acc: 0.271745. Batch_loss: 2.115190 \n",
      "Batch: 827. Acc: 0.235896. Loss: 2.231472. Batch_acc: 0.272520. Batch_loss: 2.090394 \n",
      "Batch: 828. Acc: 0.235918. Loss: 2.231342. Batch_acc: 0.254181. Batch_loss: 2.126592 \n",
      "Batch: 829. Acc: 0.235967. Loss: 2.231160. Batch_acc: 0.275626. Batch_loss: 2.081916 \n",
      "Batch: 830. Acc: 0.236003. Loss: 2.230948. Batch_acc: 0.265135. Batch_loss: 2.059378 \n",
      "Batch: 831. Acc: 0.236060. Loss: 2.230751. Batch_acc: 0.282572. Batch_loss: 2.070793 \n",
      "Batch: 832. Acc: 0.236101. Loss: 2.230616. Batch_acc: 0.270023. Batch_loss: 2.118515 \n",
      "Batch: 833. Acc: 0.236136. Loss: 2.230484. Batch_acc: 0.266990. Batch_loss: 2.114083 \n",
      "Batch: 834. Acc: 0.236199. Loss: 2.230287. Batch_acc: 0.288417. Batch_loss: 2.067070 \n",
      "Batch: 835. Acc: 0.236241. Loss: 2.230114. Batch_acc: 0.271889. Batch_loss: 2.085359 \n",
      "Batch: 836. Acc: 0.236296. Loss: 2.229932. Batch_acc: 0.281321. Batch_loss: 2.078890 \n",
      "Batch: 837. Acc: 0.236335. Loss: 2.229758. Batch_acc: 0.269430. Batch_loss: 2.084680 \n",
      "Batch: 838. Acc: 0.236391. Loss: 2.229572. Batch_acc: 0.282066. Batch_loss: 2.075275 \n",
      "Batch: 839. Acc: 0.236449. Loss: 2.229394. Batch_acc: 0.284897. Batch_loss: 2.081150 \n",
      "Batch: 840. Acc: 0.236512. Loss: 2.229206. Batch_acc: 0.290793. Batch_loss: 2.068825 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 841. Acc: 0.236569. Loss: 2.229033. Batch_acc: 0.284642. Batch_loss: 2.083010 \n",
      "Batch: 842. Acc: 0.236603. Loss: 2.228891. Batch_acc: 0.265130. Batch_loss: 2.108960 \n",
      "Batch: 843. Acc: 0.236641. Loss: 2.228745. Batch_acc: 0.268986. Batch_loss: 2.104736 \n",
      "Batch: 844. Acc: 0.236678. Loss: 2.228580. Batch_acc: 0.267468. Batch_loss: 2.090385 \n",
      "Batch: 845. Acc: 0.236719. Loss: 2.228419. Batch_acc: 0.271828. Batch_loss: 2.090645 \n",
      "Batch: 846. Acc: 0.236778. Loss: 2.228215. Batch_acc: 0.287623. Batch_loss: 2.053750 \n",
      "Batch: 847. Acc: 0.236817. Loss: 2.228077. Batch_acc: 0.268823. Batch_loss: 2.114770 \n",
      "Batch: 848. Acc: 0.236868. Loss: 2.227911. Batch_acc: 0.278819. Batch_loss: 2.089081 \n",
      "Batch: 849. Acc: 0.236912. Loss: 2.227750. Batch_acc: 0.275540. Batch_loss: 2.088746 \n",
      "Batch: 850. Acc: 0.236958. Loss: 2.227579. Batch_acc: 0.275723. Batch_loss: 2.081585 \n",
      "Batch: 851. Acc: 0.236992. Loss: 2.227423. Batch_acc: 0.266944. Batch_loss: 2.090703 \n",
      "Batch: 852. Acc: 0.237040. Loss: 2.227263. Batch_acc: 0.277556. Batch_loss: 2.091376 \n",
      "Batch: 853. Acc: 0.237059. Loss: 2.227194. Batch_acc: 0.253488. Batch_loss: 2.168164 \n",
      "Batch: 854. Acc: 0.237095. Loss: 2.227028. Batch_acc: 0.268717. Batch_loss: 2.083324 \n",
      "Batch: 855. Acc: 0.237155. Loss: 2.226839. Batch_acc: 0.287089. Batch_loss: 2.067852 \n",
      "Batch: 856. Acc: 0.237191. Loss: 2.226715. Batch_acc: 0.269117. Batch_loss: 2.117452 \n",
      "Batch: 857. Acc: 0.237250. Loss: 2.226535. Batch_acc: 0.288106. Batch_loss: 2.071749 \n",
      "Batch: 858. Acc: 0.237304. Loss: 2.226366. Batch_acc: 0.282254. Batch_loss: 2.084892 \n",
      "Batch: 859. Acc: 0.237349. Loss: 2.226214. Batch_acc: 0.276437. Batch_loss: 2.095403 \n",
      "Batch: 860. Acc: 0.237391. Loss: 2.226037. Batch_acc: 0.273830. Batch_loss: 2.072949 \n",
      "Batch: 861. Acc: 0.237467. Loss: 2.225828. Batch_acc: 0.302540. Batch_loss: 2.045139 \n",
      "Batch: 862. Acc: 0.237524. Loss: 2.225620. Batch_acc: 0.285714. Batch_loss: 2.050799 \n",
      "Batch: 863. Acc: 0.237559. Loss: 2.225463. Batch_acc: 0.267566. Batch_loss: 2.092475 \n",
      "Batch: 864. Acc: 0.237601. Loss: 2.225294. Batch_acc: 0.272676. Batch_loss: 2.081481 \n",
      "Batch: 865. Acc: 0.237650. Loss: 2.225101. Batch_acc: 0.278725. Batch_loss: 2.066200 \n",
      "Batch: 866. Acc: 0.237688. Loss: 2.224929. Batch_acc: 0.270115. Batch_loss: 2.075887 \n",
      "Batch: 867. Acc: 0.237742. Loss: 2.224756. Batch_acc: 0.284404. Batch_loss: 2.075002 \n",
      "Batch: 868. Acc: 0.237765. Loss: 2.224638. Batch_acc: 0.258480. Batch_loss: 2.120617 \n",
      "Batch: 869. Acc: 0.237811. Loss: 2.224486. Batch_acc: 0.277907. Batch_loss: 2.091235 \n",
      "Batch: 870. Acc: 0.237843. Loss: 2.224345. Batch_acc: 0.265651. Batch_loss: 2.103982 \n",
      "Batch: 871. Acc: 0.237903. Loss: 2.224179. Batch_acc: 0.289040. Batch_loss: 2.081445 \n",
      "Batch: 872. Acc: 0.237964. Loss: 2.223990. Batch_acc: 0.290525. Batch_loss: 2.060431 \n",
      "Batch: 873. Acc: 0.238011. Loss: 2.223839. Batch_acc: 0.278698. Batch_loss: 2.092651 \n",
      "Batch: 874. Acc: 0.238066. Loss: 2.223646. Batch_acc: 0.286449. Batch_loss: 2.056146 \n",
      "Batch: 875. Acc: 0.238104. Loss: 2.223516. Batch_acc: 0.271771. Batch_loss: 2.107834 \n",
      "Batch: 876. Acc: 0.238160. Loss: 2.223359. Batch_acc: 0.288066. Batch_loss: 2.082833 \n",
      "Batch: 877. Acc: 0.238230. Loss: 2.223165. Batch_acc: 0.300409. Batch_loss: 2.050316 \n",
      "Batch: 878. Acc: 0.238271. Loss: 2.222989. Batch_acc: 0.274019. Batch_loss: 2.069998 \n",
      "Batch: 879. Acc: 0.238314. Loss: 2.222808. Batch_acc: 0.274652. Batch_loss: 2.068687 \n",
      "Batch: 880. Acc: 0.238373. Loss: 2.222600. Batch_acc: 0.288988. Batch_loss: 2.045105 \n",
      "Batch: 881. Acc: 0.238418. Loss: 2.222460. Batch_acc: 0.279300. Batch_loss: 2.097272 \n",
      "Batch: 882. Acc: 0.238471. Loss: 2.222300. Batch_acc: 0.285131. Batch_loss: 2.078994 \n",
      "Batch: 883. Acc: 0.238521. Loss: 2.222167. Batch_acc: 0.282921. Batch_loss: 2.104456 \n",
      "Batch: 884. Acc: 0.238561. Loss: 2.222031. Batch_acc: 0.274408. Batch_loss: 2.101557 \n",
      "Batch: 885. Acc: 0.238596. Loss: 2.221882. Batch_acc: 0.269656. Batch_loss: 2.088112 \n",
      "Batch: 886. Acc: 0.238628. Loss: 2.221769. Batch_acc: 0.267763. Batch_loss: 2.119490 \n",
      "Batch: 887. Acc: 0.238668. Loss: 2.221604. Batch_acc: 0.273140. Batch_loss: 2.077380 \n",
      "Batch: 888. Acc: 0.238701. Loss: 2.221465. Batch_acc: 0.268418. Batch_loss: 2.099394 \n",
      "Batch: 889. Acc: 0.238749. Loss: 2.221310. Batch_acc: 0.280662. Batch_loss: 2.084652 \n",
      "Batch: 890. Acc: 0.238799. Loss: 2.221136. Batch_acc: 0.282782. Batch_loss: 2.067570 \n",
      "Batch: 891. Acc: 0.238839. Loss: 2.220939. Batch_acc: 0.274770. Batch_loss: 2.044785 \n",
      "Batch: 892. Acc: 0.238875. Loss: 2.220800. Batch_acc: 0.270797. Batch_loss: 2.097446 \n",
      "Batch: 893. Acc: 0.238919. Loss: 2.220647. Batch_acc: 0.278576. Batch_loss: 2.084164 \n",
      "Batch: 894. Acc: 0.238970. Loss: 2.220497. Batch_acc: 0.282998. Batch_loss: 2.089880 \n",
      "Batch: 895. Acc: 0.239004. Loss: 2.220395. Batch_acc: 0.269454. Batch_loss: 2.128155 \n",
      "Batch: 896. Acc: 0.239048. Loss: 2.220244. Batch_acc: 0.279017. Batch_loss: 2.085539 \n",
      "Batch: 897. Acc: 0.239094. Loss: 2.220070. Batch_acc: 0.280958. Batch_loss: 2.061980 \n",
      "Batch: 898. Acc: 0.239132. Loss: 2.219945. Batch_acc: 0.272934. Batch_loss: 2.108650 \n",
      "Batch: 899. Acc: 0.239178. Loss: 2.219780. Batch_acc: 0.279704. Batch_loss: 2.073469 \n",
      "Batch: 900. Acc: 0.239208. Loss: 2.219634. Batch_acc: 0.265945. Batch_loss: 2.089163 \n",
      "Batch: 901. Acc: 0.239258. Loss: 2.219451. Batch_acc: 0.284078. Batch_loss: 2.054887 \n",
      "Batch: 902. Acc: 0.239310. Loss: 2.219264. Batch_acc: 0.285393. Batch_loss: 2.055136 \n",
      "Batch: 903. Acc: 0.239351. Loss: 2.219131. Batch_acc: 0.276833. Batch_loss: 2.096492 \n",
      "Batch: 904. Acc: 0.239346. Loss: 2.219042. Batch_acc: 0.234634. Batch_loss: 2.136574 \n",
      "Batch: 905. Acc: 0.239376. Loss: 2.218910. Batch_acc: 0.266171. Batch_loss: 2.099847 \n",
      "Batch: 906. Acc: 0.239420. Loss: 2.218775. Batch_acc: 0.280162. Batch_loss: 2.094820 \n",
      "Batch: 907. Acc: 0.239467. Loss: 2.218643. Batch_acc: 0.283196. Batch_loss: 2.096491 \n",
      "Batch: 908. Acc: 0.239527. Loss: 2.218444. Batch_acc: 0.292711. Batch_loss: 2.039594 \n",
      "Batch: 909. Acc: 0.239569. Loss: 2.218304. Batch_acc: 0.278496. Batch_loss: 2.088212 \n",
      "Batch: 910. Acc: 0.239593. Loss: 2.218173. Batch_acc: 0.261089. Batch_loss: 2.101794 \n",
      "Batch: 911. Acc: 0.239627. Loss: 2.218044. Batch_acc: 0.269726. Batch_loss: 2.104326 \n",
      "Batch: 912. Acc: 0.239658. Loss: 2.217900. Batch_acc: 0.268805. Batch_loss: 2.084259 \n",
      "Batch: 913. Acc: 0.239711. Loss: 2.217730. Batch_acc: 0.288097. Batch_loss: 2.062316 \n",
      "Batch: 914. Acc: 0.239766. Loss: 2.217534. Batch_acc: 0.288183. Batch_loss: 2.043996 \n",
      "Batch: 915. Acc: 0.239811. Loss: 2.217369. Batch_acc: 0.281034. Batch_loss: 2.066403 \n",
      "Batch: 916. Acc: 0.239849. Loss: 2.217249. Batch_acc: 0.275304. Batch_loss: 2.107015 \n",
      "Batch: 917. Acc: 0.239889. Loss: 2.217108. Batch_acc: 0.277450. Batch_loss: 2.084297 \n",
      "Batch: 918. Acc: 0.239923. Loss: 2.216987. Batch_acc: 0.270056. Batch_loss: 2.108262 \n",
      "Batch: 919. Acc: 0.239954. Loss: 2.216850. Batch_acc: 0.268376. Batch_loss: 2.092235 \n",
      "Batch: 920. Acc: 0.240010. Loss: 2.216671. Batch_acc: 0.291096. Batch_loss: 2.053162 \n",
      "Batch: 921. Acc: 0.240060. Loss: 2.216494. Batch_acc: 0.284992. Batch_loss: 2.056541 \n",
      "Batch: 922. Acc: 0.240095. Loss: 2.216359. Batch_acc: 0.272834. Batch_loss: 2.089002 \n",
      "Batch: 923. Acc: 0.240135. Loss: 2.216226. Batch_acc: 0.278592. Batch_loss: 2.090946 \n",
      "Batch: 924. Acc: 0.240186. Loss: 2.216074. Batch_acc: 0.287544. Batch_loss: 2.074246 \n",
      "Batch: 925. Acc: 0.240230. Loss: 2.215910. Batch_acc: 0.280692. Batch_loss: 2.063504 \n",
      "Batch: 926. Acc: 0.240258. Loss: 2.215760. Batch_acc: 0.266589. Batch_loss: 2.075946 \n",
      "Batch: 927. Acc: 0.240304. Loss: 2.215590. Batch_acc: 0.282932. Batch_loss: 2.058701 \n",
      "Batch: 928. Acc: 0.240334. Loss: 2.215451. Batch_acc: 0.267685. Batch_loss: 2.087835 \n",
      "Batch: 929. Acc: 0.240371. Loss: 2.215318. Batch_acc: 0.274668. Batch_loss: 2.091263 \n",
      "Batch: 930. Acc: 0.240399. Loss: 2.215186. Batch_acc: 0.267943. Batch_loss: 2.088125 \n",
      "Batch: 931. Acc: 0.240434. Loss: 2.215032. Batch_acc: 0.272314. Batch_loss: 2.073374 \n",
      "Batch: 932. Acc: 0.240465. Loss: 2.214914. Batch_acc: 0.269841. Batch_loss: 2.102627 \n",
      "Batch: 933. Acc: 0.240510. Loss: 2.214786. Batch_acc: 0.283768. Batch_loss: 2.091599 \n",
      "Batch: 934. Acc: 0.240552. Loss: 2.214619. Batch_acc: 0.280207. Batch_loss: 2.058169 \n",
      "Batch: 935. Acc: 0.240593. Loss: 2.214461. Batch_acc: 0.278830. Batch_loss: 2.067521 \n",
      "Batch: 936. Acc: 0.240633. Loss: 2.214325. Batch_acc: 0.278422. Batch_loss: 2.085916 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 937. Acc: 0.240685. Loss: 2.214166. Batch_acc: 0.288059. Batch_loss: 2.067142 \n",
      "Batch: 938. Acc: 0.240715. Loss: 2.214031. Batch_acc: 0.268732. Batch_loss: 2.089836 \n",
      "Batch: 939. Acc: 0.240747. Loss: 2.213878. Batch_acc: 0.270715. Batch_loss: 2.072808 \n",
      "Batch: 940. Acc: 0.240795. Loss: 2.213721. Batch_acc: 0.285880. Batch_loss: 2.064743 \n",
      "Batch: 941. Acc: 0.240843. Loss: 2.213575. Batch_acc: 0.286290. Batch_loss: 2.075513 \n",
      "Batch: 942. Acc: 0.240865. Loss: 2.213453. Batch_acc: 0.261822. Batch_loss: 2.098753 \n",
      "Batch: 943. Acc: 0.240905. Loss: 2.213299. Batch_acc: 0.277716. Batch_loss: 2.071386 \n",
      "Batch: 944. Acc: 0.240932. Loss: 2.213173. Batch_acc: 0.266007. Batch_loss: 2.092701 \n",
      "Batch: 945. Acc: 0.240970. Loss: 2.213036. Batch_acc: 0.276826. Batch_loss: 2.084394 \n",
      "Batch: 946. Acc: 0.241025. Loss: 2.212846. Batch_acc: 0.292325. Batch_loss: 2.036957 \n",
      "Batch: 947. Acc: 0.241080. Loss: 2.212672. Batch_acc: 0.293811. Batch_loss: 2.047090 \n",
      "Batch: 948. Acc: 0.241133. Loss: 2.212516. Batch_acc: 0.290452. Batch_loss: 2.065583 \n",
      "Batch: 949. Acc: 0.241173. Loss: 2.212370. Batch_acc: 0.279284. Batch_loss: 2.072984 \n",
      "Batch: 950. Acc: 0.241198. Loss: 2.212246. Batch_acc: 0.264908. Batch_loss: 2.094499 \n",
      "Batch: 951. Acc: 0.241232. Loss: 2.212107. Batch_acc: 0.273789. Batch_loss: 2.078275 \n",
      "Batch: 952. Acc: 0.241277. Loss: 2.211931. Batch_acc: 0.285134. Batch_loss: 2.043181 \n",
      "Batch: 953. Acc: 0.241301. Loss: 2.211822. Batch_acc: 0.264988. Batch_loss: 2.103339 \n",
      "Batch: 954. Acc: 0.241344. Loss: 2.211688. Batch_acc: 0.282421. Batch_loss: 2.083855 \n",
      "Batch: 955. Acc: 0.241387. Loss: 2.211566. Batch_acc: 0.281948. Batch_loss: 2.094604 \n",
      "Batch: 956. Acc: 0.241426. Loss: 2.211425. Batch_acc: 0.279300. Batch_loss: 2.075494 \n",
      "Batch: 957. Acc: 0.241473. Loss: 2.211311. Batch_acc: 0.286701. Batch_loss: 2.102030 \n",
      "Batch: 958. Acc: 0.241517. Loss: 2.211133. Batch_acc: 0.282755. Batch_loss: 2.044905 \n",
      "Batch: 959. Acc: 0.241551. Loss: 2.210995. Batch_acc: 0.273349. Batch_loss: 2.080066 \n",
      "Batch: 960. Acc: 0.241608. Loss: 2.210850. Batch_acc: 0.296848. Batch_loss: 2.071972 \n",
      "Batch: 961. Acc: 0.241644. Loss: 2.210730. Batch_acc: 0.274565. Batch_loss: 2.098301 \n",
      "Batch: 962. Acc: 0.241691. Loss: 2.210589. Batch_acc: 0.287766. Batch_loss: 2.075154 \n",
      "Batch: 963. Acc: 0.241721. Loss: 2.210492. Batch_acc: 0.271217. Batch_loss: 2.113887 \n",
      "Batch: 964. Acc: 0.241761. Loss: 2.210330. Batch_acc: 0.279613. Batch_loss: 2.056246 \n",
      "Batch: 965. Acc: 0.241799. Loss: 2.210191. Batch_acc: 0.278698. Batch_loss: 2.076975 \n",
      "Batch: 966. Acc: 0.241846. Loss: 2.210058. Batch_acc: 0.287719. Batch_loss: 2.078776 \n",
      "Batch: 967. Acc: 0.241877. Loss: 2.209929. Batch_acc: 0.272460. Batch_loss: 2.083211 \n",
      "Batch: 968. Acc: 0.241930. Loss: 2.209765. Batch_acc: 0.292559. Batch_loss: 2.053767 \n",
      "Batch: 969. Acc: 0.241976. Loss: 2.209617. Batch_acc: 0.285878. Batch_loss: 2.067028 \n",
      "Batch: 970. Acc: 0.242015. Loss: 2.209480. Batch_acc: 0.280047. Batch_loss: 2.074590 \n",
      "Batch: 971. Acc: 0.242046. Loss: 2.209358. Batch_acc: 0.272781. Batch_loss: 2.088888 \n",
      "Batch: 972. Acc: 0.242076. Loss: 2.209246. Batch_acc: 0.272834. Batch_loss: 2.097550 \n",
      "Batch: 973. Acc: 0.242111. Loss: 2.209089. Batch_acc: 0.275961. Batch_loss: 2.056229 \n",
      "Batch: 974. Acc: 0.242163. Loss: 2.208962. Batch_acc: 0.292584. Batch_loss: 2.084745 \n",
      "Batch: 975. Acc: 0.242204. Loss: 2.208791. Batch_acc: 0.282139. Batch_loss: 2.043786 \n",
      "Batch: 976. Acc: 0.242248. Loss: 2.208670. Batch_acc: 0.285632. Batch_loss: 2.089656 \n",
      "Batch: 977. Acc: 0.242284. Loss: 2.208533. Batch_acc: 0.277199. Batch_loss: 2.074147 \n",
      "Batch: 978. Acc: 0.242325. Loss: 2.208396. Batch_acc: 0.282125. Batch_loss: 2.074703 \n",
      "Batch: 979. Acc: 0.242357. Loss: 2.208271. Batch_acc: 0.274109. Batch_loss: 2.084456 \n",
      "Batch: 980. Acc: 0.242388. Loss: 2.208145. Batch_acc: 0.273406. Batch_loss: 2.084413 \n",
      "Batch: 981. Acc: 0.242418. Loss: 2.208049. Batch_acc: 0.271925. Batch_loss: 2.112156 \n",
      "Batch: 982. Acc: 0.242451. Loss: 2.207921. Batch_acc: 0.275329. Batch_loss: 2.082380 \n",
      "Batch: 983. Acc: 0.242498. Loss: 2.207757. Batch_acc: 0.287422. Batch_loss: 2.048380 \n",
      "Batch: 984. Acc: 0.242530. Loss: 2.207619. Batch_acc: 0.274194. Batch_loss: 2.071645 \n",
      "Batch: 985. Acc: 0.242566. Loss: 2.207471. Batch_acc: 0.277715. Batch_loss: 2.064275 \n",
      "Batch: 986. Acc: 0.242607. Loss: 2.207355. Batch_acc: 0.282696. Batch_loss: 2.093422 \n",
      "Batch: 987. Acc: 0.242644. Loss: 2.207223. Batch_acc: 0.278846. Batch_loss: 2.079948 \n",
      "Batch: 988. Acc: 0.242681. Loss: 2.207087. Batch_acc: 0.278416. Batch_loss: 2.072969 \n",
      "Batch: 989. Acc: 0.242721. Loss: 2.206949. Batch_acc: 0.284279. Batch_loss: 2.066341 \n",
      "Batch: 990. Acc: 0.242761. Loss: 2.206836. Batch_acc: 0.282367. Batch_loss: 2.093045 \n",
      "Batch: 991. Acc: 0.242789. Loss: 2.206706. Batch_acc: 0.271765. Batch_loss: 2.075101 \n",
      "Batch: 992. Acc: 0.242830. Loss: 2.206556. Batch_acc: 0.283019. Batch_loss: 2.058430 \n",
      "Batch: 993. Acc: 0.242883. Loss: 2.206403. Batch_acc: 0.295390. Batch_loss: 2.055795 \n",
      "Batch: 994. Acc: 0.242922. Loss: 2.206268. Batch_acc: 0.281537. Batch_loss: 2.073046 \n",
      "Batch: 995. Acc: 0.242955. Loss: 2.206137. Batch_acc: 0.275198. Batch_loss: 2.077699 \n",
      "Batch: 996. Acc: 0.242989. Loss: 2.206011. Batch_acc: 0.276941. Batch_loss: 2.079605 \n",
      "Batch: 997. Acc: 0.243045. Loss: 2.205872. Batch_acc: 0.297994. Batch_loss: 2.067156 \n",
      "Batch: 998. Acc: 0.243094. Loss: 2.205715. Batch_acc: 0.292404. Batch_loss: 2.050446 \n",
      "Batch: 999. Acc: 0.243129. Loss: 2.205597. Batch_acc: 0.278200. Batch_loss: 2.086178 \n",
      "Batch: 1000. Acc: 0.243167. Loss: 2.205467. Batch_acc: 0.281682. Batch_loss: 2.075305 \n",
      "Batch: 1001. Acc: 0.243216. Loss: 2.205322. Batch_acc: 0.291954. Batch_loss: 2.059946 \n",
      "Batch: 1002. Acc: 0.243254. Loss: 2.205160. Batch_acc: 0.281413. Batch_loss: 2.042142 \n",
      "Batch: 1003. Acc: 0.243285. Loss: 2.205044. Batch_acc: 0.274578. Batch_loss: 2.087251 \n",
      "Batch: 1004. Acc: 0.243321. Loss: 2.204940. Batch_acc: 0.280325. Batch_loss: 2.099110 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.24332125459391796. Loss per char: 2.2049397417506764. Time: 1627203358.5797987\n",
      "Last question is tensor([ 2, 20, 18, 22, 25, 19, 12, 18, 17, 21, 21, 15, 20, 25, 26, 24,  3,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.243372. Loss: 2.204795. Batch_acc: 0.293817. Batch_loss: 2.061704 \n",
      "Batch: 1006. Acc: 0.243414. Loss: 2.204639. Batch_acc: 0.284576. Batch_loss: 2.048552 \n",
      "Batch: 1007. Acc: 0.243444. Loss: 2.204528. Batch_acc: 0.274764. Batch_loss: 2.090255 \n",
      "Batch: 1008. Acc: 0.243469. Loss: 2.204409. Batch_acc: 0.268545. Batch_loss: 2.084838 \n",
      "Batch: 1009. Acc: 0.243504. Loss: 2.204292. Batch_acc: 0.279232. Batch_loss: 2.084546 \n",
      "Batch: 1010. Acc: 0.243554. Loss: 2.204149. Batch_acc: 0.293682. Batch_loss: 2.061020 \n",
      "Batch: 1011. Acc: 0.243589. Loss: 2.204031. Batch_acc: 0.279343. Batch_loss: 2.082812 \n",
      "Batch: 1012. Acc: 0.243632. Loss: 2.203893. Batch_acc: 0.286937. Batch_loss: 2.065397 \n",
      "Batch: 1013. Acc: 0.243682. Loss: 2.203736. Batch_acc: 0.295799. Batch_loss: 2.041868 \n",
      "Batch: 1014. Acc: 0.243703. Loss: 2.203641. Batch_acc: 0.264434. Batch_loss: 2.107630 \n",
      "Batch: 1015. Acc: 0.243731. Loss: 2.203529. Batch_acc: 0.272833. Batch_loss: 2.088042 \n",
      "Batch: 1016. Acc: 0.243773. Loss: 2.203384. Batch_acc: 0.285237. Batch_loss: 2.061487 \n",
      "Batch: 1017. Acc: 0.243791. Loss: 2.203278. Batch_acc: 0.262041. Batch_loss: 2.095107 \n",
      "Batch: 1018. Acc: 0.243816. Loss: 2.203169. Batch_acc: 0.269611. Batch_loss: 2.091419 \n",
      "Batch: 1019. Acc: 0.243850. Loss: 2.203057. Batch_acc: 0.278727. Batch_loss: 2.085901 \n",
      "Batch: 1020. Acc: 0.243881. Loss: 2.202950. Batch_acc: 0.275761. Batch_loss: 2.092447 \n",
      "Batch: 1021. Acc: 0.243907. Loss: 2.202814. Batch_acc: 0.270953. Batch_loss: 2.063905 \n",
      "Batch: 1022. Acc: 0.243937. Loss: 2.202693. Batch_acc: 0.275029. Batch_loss: 2.078917 \n",
      "Batch: 1023. Acc: 0.243976. Loss: 2.202543. Batch_acc: 0.282547. Batch_loss: 2.051124 \n",
      "Batch: 1024. Acc: 0.244006. Loss: 2.202410. Batch_acc: 0.274103. Batch_loss: 2.069691 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1025. Acc: 0.244046. Loss: 2.202260. Batch_acc: 0.284746. Batch_loss: 2.050782 \n",
      "Batch: 1026. Acc: 0.244091. Loss: 2.202127. Batch_acc: 0.290780. Batch_loss: 2.061925 \n",
      "Batch: 1027. Acc: 0.244126. Loss: 2.201990. Batch_acc: 0.280551. Batch_loss: 2.061507 \n",
      "Batch: 1028. Acc: 0.244178. Loss: 2.201853. Batch_acc: 0.297564. Batch_loss: 2.059909 \n",
      "Batch: 1029. Acc: 0.244192. Loss: 2.201769. Batch_acc: 0.259281. Batch_loss: 2.113453 \n",
      "Batch: 1030. Acc: 0.244227. Loss: 2.201637. Batch_acc: 0.280692. Batch_loss: 2.065763 \n",
      "Batch: 1031. Acc: 0.244257. Loss: 2.201533. Batch_acc: 0.275132. Batch_loss: 2.091914 \n",
      "Batch: 1032. Acc: 0.244298. Loss: 2.201415. Batch_acc: 0.288427. Batch_loss: 2.075570 \n",
      "Batch: 1033. Acc: 0.244352. Loss: 2.201295. Batch_acc: 0.300756. Batch_loss: 2.075631 \n",
      "Batch: 1034. Acc: 0.244389. Loss: 2.201147. Batch_acc: 0.282286. Batch_loss: 2.049043 \n",
      "Batch: 1035. Acc: 0.244433. Loss: 2.201017. Batch_acc: 0.292088. Batch_loss: 2.062116 \n",
      "Batch: 1036. Acc: 0.244467. Loss: 2.200913. Batch_acc: 0.279651. Batch_loss: 2.091958 \n",
      "Batch: 1037. Acc: 0.244494. Loss: 2.200821. Batch_acc: 0.272781. Batch_loss: 2.104055 \n",
      "Batch: 1038. Acc: 0.244520. Loss: 2.200701. Batch_acc: 0.271986. Batch_loss: 2.073739 \n",
      "Batch: 1039. Acc: 0.244550. Loss: 2.200581. Batch_acc: 0.276571. Batch_loss: 2.073663 \n",
      "Batch: 1040. Acc: 0.244581. Loss: 2.200457. Batch_acc: 0.276852. Batch_loss: 2.071590 \n",
      "Batch: 1041. Acc: 0.244621. Loss: 2.200345. Batch_acc: 0.286382. Batch_loss: 2.082603 \n",
      "Batch: 1042. Acc: 0.244641. Loss: 2.200257. Batch_acc: 0.265866. Batch_loss: 2.108477 \n",
      "Batch: 1043. Acc: 0.244673. Loss: 2.200150. Batch_acc: 0.277434. Batch_loss: 2.091367 \n",
      "Batch: 1044. Acc: 0.244714. Loss: 2.200025. Batch_acc: 0.286844. Batch_loss: 2.071791 \n",
      "Batch: 1045. Acc: 0.244735. Loss: 2.199903. Batch_acc: 0.267180. Batch_loss: 2.068235 \n",
      "Batch: 1046. Acc: 0.244772. Loss: 2.199771. Batch_acc: 0.281651. Batch_loss: 2.065889 \n",
      "Batch: 1047. Acc: 0.244804. Loss: 2.199634. Batch_acc: 0.278481. Batch_loss: 2.057030 \n",
      "Batch: 1048. Acc: 0.244823. Loss: 2.199530. Batch_acc: 0.264893. Batch_loss: 2.089423 \n",
      "Batch: 1049. Acc: 0.244857. Loss: 2.199434. Batch_acc: 0.279932. Batch_loss: 2.099734 \n",
      "Batch: 1050. Acc: 0.244890. Loss: 2.199293. Batch_acc: 0.280396. Batch_loss: 2.049474 \n",
      "Batch: 1051. Acc: 0.244933. Loss: 2.199178. Batch_acc: 0.292088. Batch_loss: 2.073883 \n",
      "Batch: 1052. Acc: 0.244954. Loss: 2.199069. Batch_acc: 0.266974. Batch_loss: 2.084364 \n",
      "Batch: 1053. Acc: 0.244981. Loss: 2.198940. Batch_acc: 0.272883. Batch_loss: 2.064373 \n",
      "Batch: 1054. Acc: 0.244995. Loss: 2.198836. Batch_acc: 0.260290. Batch_loss: 2.088160 \n",
      "Batch: 1055. Acc: 0.245028. Loss: 2.198703. Batch_acc: 0.279310. Batch_loss: 2.058463 \n",
      "Batch: 1056. Acc: 0.245064. Loss: 2.198607. Batch_acc: 0.285024. Batch_loss: 2.091923 \n",
      "Batch: 1057. Acc: 0.245111. Loss: 2.198451. Batch_acc: 0.295167. Batch_loss: 2.033561 \n",
      "Batch: 1058. Acc: 0.245147. Loss: 2.198326. Batch_acc: 0.282910. Batch_loss: 2.066536 \n",
      "Batch: 1059. Acc: 0.245177. Loss: 2.198218. Batch_acc: 0.276524. Batch_loss: 2.085501 \n",
      "Batch: 1060. Acc: 0.245209. Loss: 2.198101. Batch_acc: 0.279150. Batch_loss: 2.074147 \n",
      "Batch: 1061. Acc: 0.245240. Loss: 2.197998. Batch_acc: 0.278481. Batch_loss: 2.089217 \n",
      "Batch: 1062. Acc: 0.245276. Loss: 2.197903. Batch_acc: 0.282373. Batch_loss: 2.097836 \n",
      "Batch: 1063. Acc: 0.245299. Loss: 2.197800. Batch_acc: 0.271318. Batch_loss: 2.083807 \n",
      "Batch: 1064. Acc: 0.245335. Loss: 2.197669. Batch_acc: 0.282869. Batch_loss: 2.060473 \n",
      "Batch: 1065. Acc: 0.245369. Loss: 2.197560. Batch_acc: 0.281321. Batch_loss: 2.082637 \n",
      "Batch: 1066. Acc: 0.245416. Loss: 2.197426. Batch_acc: 0.295742. Batch_loss: 2.054128 \n",
      "Batch: 1067. Acc: 0.245459. Loss: 2.197293. Batch_acc: 0.289871. Batch_loss: 2.059069 \n",
      "Batch: 1068. Acc: 0.245493. Loss: 2.197172. Batch_acc: 0.281963. Batch_loss: 2.068817 \n",
      "Batch: 1069. Acc: 0.245526. Loss: 2.197064. Batch_acc: 0.280207. Batch_loss: 2.082115 \n",
      "Batch: 1070. Acc: 0.245558. Loss: 2.196935. Batch_acc: 0.280325. Batch_loss: 2.058016 \n",
      "Batch: 1071. Acc: 0.245596. Loss: 2.196824. Batch_acc: 0.287048. Batch_loss: 2.075650 \n",
      "Batch: 1072. Acc: 0.245642. Loss: 2.196672. Batch_acc: 0.294385. Batch_loss: 2.035891 \n",
      "Batch: 1073. Acc: 0.245697. Loss: 2.196520. Batch_acc: 0.302809. Batch_loss: 2.037433 \n",
      "Batch: 1074. Acc: 0.245723. Loss: 2.196403. Batch_acc: 0.273956. Batch_loss: 2.067944 \n",
      "Batch: 1075. Acc: 0.245744. Loss: 2.196315. Batch_acc: 0.269643. Batch_loss: 2.098819 \n",
      "Batch: 1076. Acc: 0.245771. Loss: 2.196197. Batch_acc: 0.275219. Batch_loss: 2.067215 \n",
      "Batch: 1077. Acc: 0.245806. Loss: 2.196101. Batch_acc: 0.283776. Batch_loss: 2.090703 \n",
      "Batch: 1078. Acc: 0.245836. Loss: 2.195992. Batch_acc: 0.278351. Batch_loss: 2.078346 \n",
      "Batch: 1079. Acc: 0.245872. Loss: 2.195865. Batch_acc: 0.284742. Batch_loss: 2.061161 \n",
      "Batch: 1080. Acc: 0.245903. Loss: 2.195751. Batch_acc: 0.279070. Batch_loss: 2.071098 \n",
      "Batch: 1081. Acc: 0.245929. Loss: 2.195639. Batch_acc: 0.274100. Batch_loss: 2.073889 \n",
      "Batch: 1082. Acc: 0.245966. Loss: 2.195502. Batch_acc: 0.286211. Batch_loss: 2.046104 \n",
      "Batch: 1083. Acc: 0.245996. Loss: 2.195399. Batch_acc: 0.279420. Batch_loss: 2.082920 \n",
      "Batch: 1084. Acc: 0.246027. Loss: 2.195288. Batch_acc: 0.279420. Batch_loss: 2.073819 \n",
      "Batch: 1085. Acc: 0.246051. Loss: 2.195191. Batch_acc: 0.272937. Batch_loss: 2.089793 \n",
      "Batch: 1086. Acc: 0.246077. Loss: 2.195076. Batch_acc: 0.274476. Batch_loss: 2.068391 \n",
      "Batch: 1087. Acc: 0.246107. Loss: 2.194953. Batch_acc: 0.278736. Batch_loss: 2.061821 \n",
      "Batch: 1088. Acc: 0.246141. Loss: 2.194835. Batch_acc: 0.282609. Batch_loss: 2.067187 \n",
      "Batch: 1089. Acc: 0.246163. Loss: 2.194708. Batch_acc: 0.269540. Batch_loss: 2.056886 \n",
      "Batch: 1090. Acc: 0.246193. Loss: 2.194583. Batch_acc: 0.278438. Batch_loss: 2.060478 \n",
      "Batch: 1091. Acc: 0.246212. Loss: 2.194480. Batch_acc: 0.267092. Batch_loss: 2.081183 \n",
      "Batch: 1092. Acc: 0.246226. Loss: 2.194403. Batch_acc: 0.262192. Batch_loss: 2.110483 \n",
      "Batch: 1093. Acc: 0.246260. Loss: 2.194298. Batch_acc: 0.282731. Batch_loss: 2.081495 \n",
      "Batch: 1094. Acc: 0.246314. Loss: 2.194162. Batch_acc: 0.306832. Batch_loss: 2.041705 \n",
      "Batch: 1095. Acc: 0.246334. Loss: 2.194100. Batch_acc: 0.268578. Batch_loss: 2.125422 \n",
      "Batch: 1096. Acc: 0.246360. Loss: 2.193995. Batch_acc: 0.274757. Batch_loss: 2.079922 \n",
      "Batch: 1097. Acc: 0.246399. Loss: 2.193881. Batch_acc: 0.288825. Batch_loss: 2.069042 \n",
      "Batch: 1098. Acc: 0.246439. Loss: 2.193747. Batch_acc: 0.289937. Batch_loss: 2.047647 \n",
      "Batch: 1099. Acc: 0.246476. Loss: 2.193615. Batch_acc: 0.286862. Batch_loss: 2.049363 \n",
      "Batch: 1100. Acc: 0.246505. Loss: 2.193518. Batch_acc: 0.279481. Batch_loss: 2.083744 \n",
      "Batch: 1101. Acc: 0.246540. Loss: 2.193391. Batch_acc: 0.284091. Batch_loss: 2.055520 \n",
      "Batch: 1102. Acc: 0.246581. Loss: 2.193268. Batch_acc: 0.292398. Batch_loss: 2.055608 \n",
      "Batch: 1103. Acc: 0.246610. Loss: 2.193165. Batch_acc: 0.278221. Batch_loss: 2.080745 \n",
      "Batch: 1104. Acc: 0.246659. Loss: 2.193023. Batch_acc: 0.300910. Batch_loss: 2.037871 \n",
      "Batch: 1105. Acc: 0.246694. Loss: 2.192895. Batch_acc: 0.285223. Batch_loss: 2.052198 \n",
      "Batch: 1106. Acc: 0.246737. Loss: 2.192773. Batch_acc: 0.295537. Batch_loss: 2.051672 \n",
      "Batch: 1107. Acc: 0.246767. Loss: 2.192668. Batch_acc: 0.280905. Batch_loss: 2.075459 \n",
      "Batch: 1108. Acc: 0.246799. Loss: 2.192555. Batch_acc: 0.282953. Batch_loss: 2.064339 \n",
      "Batch: 1109. Acc: 0.246845. Loss: 2.192416. Batch_acc: 0.297126. Batch_loss: 2.039392 \n",
      "Batch: 1110. Acc: 0.246878. Loss: 2.192316. Batch_acc: 0.283979. Batch_loss: 2.080691 \n",
      "Batch: 1111. Acc: 0.246927. Loss: 2.192188. Batch_acc: 0.300795. Batch_loss: 2.051939 \n",
      "Batch: 1112. Acc: 0.246969. Loss: 2.192053. Batch_acc: 0.293642. Batch_loss: 2.041169 \n",
      "Batch: 1113. Acc: 0.246993. Loss: 2.191955. Batch_acc: 0.274074. Batch_loss: 2.083323 \n",
      "Batch: 1114. Acc: 0.247025. Loss: 2.191857. Batch_acc: 0.281918. Batch_loss: 2.082119 \n",
      "Batch: 1115. Acc: 0.247058. Loss: 2.191744. Batch_acc: 0.285883. Batch_loss: 2.062805 \n",
      "Batch: 1116. Acc: 0.247092. Loss: 2.191610. Batch_acc: 0.284734. Batch_loss: 2.043374 \n",
      "Batch: 1117. Acc: 0.247105. Loss: 2.191537. Batch_acc: 0.262004. Batch_loss: 2.106968 \n",
      "Batch: 1118. Acc: 0.247115. Loss: 2.191459. Batch_acc: 0.258353. Batch_loss: 2.101952 \n",
      "Batch: 1119. Acc: 0.247145. Loss: 2.191333. Batch_acc: 0.279704. Batch_loss: 2.050981 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1120. Acc: 0.247177. Loss: 2.191231. Batch_acc: 0.283401. Batch_loss: 2.076801 \n",
      "Batch: 1121. Acc: 0.247200. Loss: 2.191117. Batch_acc: 0.272675. Batch_loss: 2.065115 \n",
      "Batch: 1122. Acc: 0.247239. Loss: 2.190985. Batch_acc: 0.289977. Batch_loss: 2.045282 \n",
      "Batch: 1123. Acc: 0.247277. Loss: 2.190868. Batch_acc: 0.288988. Batch_loss: 2.063715 \n",
      "Batch: 1124. Acc: 0.247305. Loss: 2.190754. Batch_acc: 0.279043. Batch_loss: 2.063913 \n",
      "Batch: 1125. Acc: 0.247341. Loss: 2.190661. Batch_acc: 0.288416. Batch_loss: 2.083296 \n",
      "Batch: 1126. Acc: 0.247372. Loss: 2.190561. Batch_acc: 0.281787. Batch_loss: 2.078097 \n",
      "Batch: 1127. Acc: 0.247414. Loss: 2.190431. Batch_acc: 0.294658. Batch_loss: 2.044258 \n",
      "Batch: 1128. Acc: 0.247446. Loss: 2.190323. Batch_acc: 0.283607. Batch_loss: 2.070449 \n",
      "Batch: 1129. Acc: 0.247475. Loss: 2.190253. Batch_acc: 0.280069. Batch_loss: 2.110995 \n",
      "Batch: 1130. Acc: 0.247518. Loss: 2.190085. Batch_acc: 0.295313. Batch_loss: 2.004538 \n",
      "Batch: 1131. Acc: 0.247541. Loss: 2.189998. Batch_acc: 0.273256. Batch_loss: 2.090361 \n",
      "Batch: 1132. Acc: 0.247571. Loss: 2.189884. Batch_acc: 0.281918. Batch_loss: 2.060263 \n",
      "Batch: 1133. Acc: 0.247602. Loss: 2.189762. Batch_acc: 0.283626. Batch_loss: 2.049006 \n",
      "Batch: 1134. Acc: 0.247636. Loss: 2.189666. Batch_acc: 0.285880. Batch_loss: 2.080030 \n",
      "Batch: 1135. Acc: 0.247672. Loss: 2.189539. Batch_acc: 0.287896. Batch_loss: 2.048329 \n",
      "Batch: 1136. Acc: 0.247709. Loss: 2.189420. Batch_acc: 0.290063. Batch_loss: 2.054237 \n",
      "Batch: 1137. Acc: 0.247760. Loss: 2.189275. Batch_acc: 0.302732. Batch_loss: 2.032039 \n",
      "Batch: 1138. Acc: 0.247782. Loss: 2.189189. Batch_acc: 0.272727. Batch_loss: 2.090786 \n",
      "Batch: 1139. Acc: 0.247805. Loss: 2.189087. Batch_acc: 0.274713. Batch_loss: 2.073880 \n",
      "Batch: 1140. Acc: 0.247827. Loss: 2.188973. Batch_acc: 0.272156. Batch_loss: 2.059708 \n",
      "Batch: 1141. Acc: 0.247853. Loss: 2.188891. Batch_acc: 0.278669. Batch_loss: 2.091351 \n",
      "Batch: 1142. Acc: 0.247881. Loss: 2.188772. Batch_acc: 0.279885. Batch_loss: 2.053984 \n",
      "Batch: 1143. Acc: 0.247897. Loss: 2.188695. Batch_acc: 0.266055. Batch_loss: 2.101073 \n",
      "Batch: 1144. Acc: 0.247929. Loss: 2.188584. Batch_acc: 0.284404. Batch_loss: 2.061677 \n",
      "Batch: 1145. Acc: 0.247974. Loss: 2.188458. Batch_acc: 0.298196. Batch_loss: 2.046883 \n",
      "Batch: 1146. Acc: 0.247989. Loss: 2.188401. Batch_acc: 0.265306. Batch_loss: 2.121818 \n",
      "Batch: 1147. Acc: 0.248018. Loss: 2.188309. Batch_acc: 0.281503. Batch_loss: 2.083258 \n",
      "Batch: 1148. Acc: 0.248040. Loss: 2.188212. Batch_acc: 0.274259. Batch_loss: 2.075766 \n",
      "Batch: 1149. Acc: 0.248053. Loss: 2.188117. Batch_acc: 0.262192. Batch_loss: 2.078489 \n",
      "Batch: 1150. Acc: 0.248088. Loss: 2.188013. Batch_acc: 0.288087. Batch_loss: 2.069216 \n",
      "Batch: 1151. Acc: 0.248122. Loss: 2.187891. Batch_acc: 0.286356. Batch_loss: 2.051439 \n",
      "Batch: 1152. Acc: 0.248155. Loss: 2.187784. Batch_acc: 0.285633. Batch_loss: 2.065134 \n",
      "Batch: 1153. Acc: 0.248184. Loss: 2.187685. Batch_acc: 0.282876. Batch_loss: 2.072277 \n",
      "Batch: 1154. Acc: 0.248218. Loss: 2.187555. Batch_acc: 0.286279. Batch_loss: 2.039973 \n",
      "Batch: 1155. Acc: 0.248236. Loss: 2.187451. Batch_acc: 0.269120. Batch_loss: 2.067643 \n",
      "Batch: 1156. Acc: 0.248279. Loss: 2.187334. Batch_acc: 0.297680. Batch_loss: 2.053565 \n",
      "Batch: 1157. Acc: 0.248316. Loss: 2.187230. Batch_acc: 0.291375. Batch_loss: 2.065768 \n",
      "Batch: 1158. Acc: 0.248346. Loss: 2.187123. Batch_acc: 0.283171. Batch_loss: 2.063786 \n",
      "Batch: 1159. Acc: 0.248362. Loss: 2.187035. Batch_acc: 0.267531. Batch_loss: 2.082046 \n",
      "Batch: 1160. Acc: 0.248405. Loss: 2.186903. Batch_acc: 0.296400. Batch_loss: 2.037110 \n",
      "Batch: 1161. Acc: 0.248439. Loss: 2.186786. Batch_acc: 0.288078. Batch_loss: 2.052771 \n",
      "Batch: 1162. Acc: 0.248469. Loss: 2.186686. Batch_acc: 0.282167. Batch_loss: 2.072840 \n",
      "Batch: 1163. Acc: 0.248489. Loss: 2.186602. Batch_acc: 0.271986. Batch_loss: 2.087283 \n",
      "Batch: 1164. Acc: 0.248524. Loss: 2.186482. Batch_acc: 0.290493. Batch_loss: 2.044078 \n",
      "Batch: 1165. Acc: 0.248562. Loss: 2.186355. Batch_acc: 0.292994. Batch_loss: 2.037053 \n",
      "Batch: 1166. Acc: 0.248594. Loss: 2.186239. Batch_acc: 0.286211. Batch_loss: 2.050750 \n",
      "Batch: 1167. Acc: 0.248634. Loss: 2.186137. Batch_acc: 0.296060. Batch_loss: 2.065600 \n",
      "Batch: 1168. Acc: 0.248675. Loss: 2.186009. Batch_acc: 0.296404. Batch_loss: 2.036058 \n",
      "Batch: 1169. Acc: 0.248691. Loss: 2.185939. Batch_acc: 0.268293. Batch_loss: 2.102751 \n",
      "Batch: 1170. Acc: 0.248718. Loss: 2.185851. Batch_acc: 0.280630. Batch_loss: 2.082079 \n",
      "Batch: 1171. Acc: 0.248740. Loss: 2.185766. Batch_acc: 0.275029. Batch_loss: 2.083310 \n",
      "Batch: 1172. Acc: 0.248769. Loss: 2.185667. Batch_acc: 0.281993. Batch_loss: 2.071300 \n",
      "Batch: 1173. Acc: 0.248795. Loss: 2.185601. Batch_acc: 0.279588. Batch_loss: 2.108952 \n",
      "Batch: 1174. Acc: 0.248815. Loss: 2.185515. Batch_acc: 0.271739. Batch_loss: 2.085355 \n",
      "Batch: 1175. Acc: 0.248852. Loss: 2.185392. Batch_acc: 0.292683. Batch_loss: 2.038822 \n",
      "Batch: 1176. Acc: 0.248872. Loss: 2.185325. Batch_acc: 0.271940. Batch_loss: 2.106148 \n",
      "Batch: 1177. Acc: 0.248896. Loss: 2.185253. Batch_acc: 0.279635. Batch_loss: 2.096763 \n",
      "Batch: 1178. Acc: 0.248916. Loss: 2.185162. Batch_acc: 0.272245. Batch_loss: 2.074529 \n",
      "Batch: 1179. Acc: 0.248941. Loss: 2.185064. Batch_acc: 0.279164. Batch_loss: 2.068819 \n",
      "Batch: 1180. Acc: 0.248966. Loss: 2.185006. Batch_acc: 0.279138. Batch_loss: 2.115440 \n",
      "Batch: 1181. Acc: 0.249018. Loss: 2.184875. Batch_acc: 0.307018. Batch_loss: 2.037367 \n",
      "Batch: 1182. Acc: 0.249051. Loss: 2.184762. Batch_acc: 0.287774. Batch_loss: 2.051745 \n",
      "Batch: 1183. Acc: 0.249082. Loss: 2.184676. Batch_acc: 0.286203. Batch_loss: 2.083452 \n",
      "Batch: 1184. Acc: 0.249093. Loss: 2.184605. Batch_acc: 0.261688. Batch_loss: 2.101726 \n",
      "Batch: 1185. Acc: 0.249104. Loss: 2.184542. Batch_acc: 0.262908. Batch_loss: 2.107016 \n",
      "Batch: 1186. Acc: 0.249128. Loss: 2.184457. Batch_acc: 0.277306. Batch_loss: 2.085502 \n",
      "Batch: 1187. Acc: 0.249166. Loss: 2.184343. Batch_acc: 0.294664. Batch_loss: 2.047402 \n",
      "Batch: 1188. Acc: 0.249194. Loss: 2.184250. Batch_acc: 0.282609. Batch_loss: 2.072345 \n",
      "Batch: 1189. Acc: 0.249218. Loss: 2.184160. Batch_acc: 0.277364. Batch_loss: 2.077173 \n",
      "Batch: 1190. Acc: 0.249243. Loss: 2.184053. Batch_acc: 0.279632. Batch_loss: 2.056235 \n",
      "Batch: 1191. Acc: 0.249270. Loss: 2.183961. Batch_acc: 0.281268. Batch_loss: 2.074503 \n",
      "Batch: 1192. Acc: 0.249302. Loss: 2.183865. Batch_acc: 0.287888. Batch_loss: 2.067524 \n",
      "Batch: 1193. Acc: 0.249327. Loss: 2.183771. Batch_acc: 0.279883. Batch_loss: 2.070155 \n",
      "Batch: 1194. Acc: 0.249353. Loss: 2.183678. Batch_acc: 0.280236. Batch_loss: 2.070307 \n",
      "Batch: 1195. Acc: 0.249379. Loss: 2.183582. Batch_acc: 0.281824. Batch_loss: 2.065253 \n",
      "Batch: 1196. Acc: 0.249407. Loss: 2.183474. Batch_acc: 0.282869. Batch_loss: 2.055266 \n",
      "Batch: 1197. Acc: 0.249437. Loss: 2.183383. Batch_acc: 0.285217. Batch_loss: 2.074623 \n",
      "Batch: 1198. Acc: 0.249469. Loss: 2.183282. Batch_acc: 0.287174. Batch_loss: 2.063754 \n",
      "Batch: 1199. Acc: 0.249496. Loss: 2.183194. Batch_acc: 0.282051. Batch_loss: 2.076034 \n",
      "Batch: 1200. Acc: 0.249512. Loss: 2.183117. Batch_acc: 0.269209. Batch_loss: 2.090039 \n",
      "Batch: 1201. Acc: 0.249539. Loss: 2.183034. Batch_acc: 0.282787. Batch_loss: 2.082248 \n",
      "Batch: 1202. Acc: 0.249549. Loss: 2.182971. Batch_acc: 0.260920. Batch_loss: 2.105724 \n",
      "Batch: 1203. Acc: 0.249575. Loss: 2.182863. Batch_acc: 0.281087. Batch_loss: 2.052831 \n",
      "Batch: 1204. Acc: 0.249601. Loss: 2.182753. Batch_acc: 0.280543. Batch_loss: 2.052657 \n",
      "Batch: 1205. Acc: 0.249636. Loss: 2.182649. Batch_acc: 0.292442. Batch_loss: 2.056207 \n",
      "Batch: 1206. Acc: 0.249662. Loss: 2.182558. Batch_acc: 0.280411. Batch_loss: 2.072872 \n",
      "Batch: 1207. Acc: 0.249691. Loss: 2.182450. Batch_acc: 0.285548. Batch_loss: 2.051267 \n",
      "Batch: 1208. Acc: 0.249721. Loss: 2.182346. Batch_acc: 0.286288. Batch_loss: 2.057716 \n",
      "Batch: 1209. Acc: 0.249740. Loss: 2.182251. Batch_acc: 0.272163. Batch_loss: 2.068807 \n",
      "Batch: 1210. Acc: 0.249764. Loss: 2.182144. Batch_acc: 0.278641. Batch_loss: 2.052880 \n",
      "Batch: 1211. Acc: 0.249799. Loss: 2.182034. Batch_acc: 0.291908. Batch_loss: 2.048786 \n",
      "Batch: 1212. Acc: 0.249821. Loss: 2.181932. Batch_acc: 0.276256. Batch_loss: 2.058687 \n",
      "Batch: 1213. Acc: 0.249845. Loss: 2.181836. Batch_acc: 0.279906. Batch_loss: 2.062284 \n",
      "Batch: 1214. Acc: 0.249869. Loss: 2.181771. Batch_acc: 0.279499. Batch_loss: 2.100622 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1215. Acc: 0.249886. Loss: 2.181677. Batch_acc: 0.272033. Batch_loss: 2.065346 \n",
      "Batch: 1216. Acc: 0.249925. Loss: 2.181564. Batch_acc: 0.296045. Batch_loss: 2.046174 \n",
      "Batch: 1217. Acc: 0.249956. Loss: 2.181464. Batch_acc: 0.286678. Batch_loss: 2.062533 \n",
      "Batch: 1218. Acc: 0.249989. Loss: 2.181354. Batch_acc: 0.290379. Batch_loss: 2.045523 \n",
      "Batch: 1219. Acc: 0.250010. Loss: 2.181256. Batch_acc: 0.276081. Batch_loss: 2.061839 \n",
      "Batch: 1220. Acc: 0.250047. Loss: 2.181132. Batch_acc: 0.294785. Batch_loss: 2.032133 \n",
      "Batch: 1221. Acc: 0.250070. Loss: 2.181055. Batch_acc: 0.277939. Batch_loss: 2.087189 \n",
      "Batch: 1222. Acc: 0.250095. Loss: 2.180981. Batch_acc: 0.280783. Batch_loss: 2.090099 \n",
      "Batch: 1223. Acc: 0.250125. Loss: 2.180918. Batch_acc: 0.286942. Batch_loss: 2.103530 \n",
      "Batch: 1224. Acc: 0.250161. Loss: 2.180822. Batch_acc: 0.294529. Batch_loss: 2.062601 \n",
      "Batch: 1225. Acc: 0.250198. Loss: 2.180723. Batch_acc: 0.295195. Batch_loss: 2.060216 \n",
      "Batch: 1226. Acc: 0.250220. Loss: 2.180647. Batch_acc: 0.277875. Batch_loss: 2.086475 \n",
      "Batch: 1227. Acc: 0.250228. Loss: 2.180588. Batch_acc: 0.259572. Batch_loss: 2.108857 \n",
      "Batch: 1228. Acc: 0.250264. Loss: 2.180470. Batch_acc: 0.294218. Batch_loss: 2.038176 \n",
      "Batch: 1229. Acc: 0.250289. Loss: 2.180369. Batch_acc: 0.280000. Batch_loss: 2.058672 \n",
      "Batch: 1230. Acc: 0.250330. Loss: 2.180268. Batch_acc: 0.301219. Batch_loss: 2.055648 \n",
      "Batch: 1231. Acc: 0.250364. Loss: 2.180152. Batch_acc: 0.291833. Batch_loss: 2.038200 \n",
      "Batch: 1232. Acc: 0.250384. Loss: 2.180067. Batch_acc: 0.276545. Batch_loss: 2.070834 \n",
      "Batch: 1233. Acc: 0.250393. Loss: 2.179996. Batch_acc: 0.261350. Batch_loss: 2.091362 \n",
      "Batch: 1234. Acc: 0.250411. Loss: 2.179920. Batch_acc: 0.271884. Batch_loss: 2.086010 \n",
      "Batch: 1235. Acc: 0.250435. Loss: 2.179841. Batch_acc: 0.280854. Batch_loss: 2.081485 \n",
      "Batch: 1236. Acc: 0.250466. Loss: 2.179725. Batch_acc: 0.288361. Batch_loss: 2.035500 \n",
      "Batch: 1237. Acc: 0.250505. Loss: 2.179622. Batch_acc: 0.300716. Batch_loss: 2.047860 \n",
      "Batch: 1238. Acc: 0.250539. Loss: 2.179523. Batch_acc: 0.293083. Batch_loss: 2.054823 \n",
      "Batch: 1239. Acc: 0.250578. Loss: 2.179416. Batch_acc: 0.299713. Batch_loss: 2.046596 \n",
      "Batch: 1240. Acc: 0.250593. Loss: 2.179344. Batch_acc: 0.269231. Batch_loss: 2.091297 \n",
      "Batch: 1241. Acc: 0.250625. Loss: 2.179259. Batch_acc: 0.289937. Batch_loss: 2.074487 \n",
      "Batch: 1242. Acc: 0.250646. Loss: 2.179184. Batch_acc: 0.276596. Batch_loss: 2.086183 \n",
      "Batch: 1243. Acc: 0.250664. Loss: 2.179116. Batch_acc: 0.272779. Batch_loss: 2.094919 \n",
      "Batch: 1244. Acc: 0.250689. Loss: 2.179031. Batch_acc: 0.282816. Batch_loss: 2.069681 \n",
      "Batch: 1245. Acc: 0.250712. Loss: 2.178950. Batch_acc: 0.278975. Batch_loss: 2.076159 \n",
      "Batch: 1246. Acc: 0.250737. Loss: 2.178855. Batch_acc: 0.282460. Batch_loss: 2.061592 \n",
      "Batch: 1247. Acc: 0.250768. Loss: 2.178771. Batch_acc: 0.289889. Batch_loss: 2.073044 \n",
      "Batch: 1248. Acc: 0.250791. Loss: 2.178663. Batch_acc: 0.278726. Batch_loss: 2.045757 \n",
      "Batch: 1249. Acc: 0.250811. Loss: 2.178579. Batch_acc: 0.275362. Batch_loss: 2.077002 \n",
      "Batch: 1250. Acc: 0.250840. Loss: 2.178457. Batch_acc: 0.287042. Batch_loss: 2.023643 \n",
      "Batch: 1251. Acc: 0.250862. Loss: 2.178381. Batch_acc: 0.279112. Batch_loss: 2.079088 \n",
      "Batch: 1252. Acc: 0.250898. Loss: 2.178263. Batch_acc: 0.296465. Batch_loss: 2.032277 \n",
      "Batch: 1253. Acc: 0.250921. Loss: 2.178155. Batch_acc: 0.279018. Batch_loss: 2.046569 \n",
      "Batch: 1254. Acc: 0.250954. Loss: 2.178034. Batch_acc: 0.290981. Batch_loss: 2.029474 \n",
      "Batch: 1255. Acc: 0.250993. Loss: 2.177912. Batch_acc: 0.300000. Batch_loss: 2.026789 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.250993321343063. Loss per char: 2.177912326898527. Time: 1627203534.6225615\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 22, 23,  1, 66,\n",
      "        79, 69,  1, 14, 19, 25, 24, 17, 26, 26, 20, 25, 18, 21, 19, 26, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.251017. Loss: 2.177806. Batch_acc: 0.280384. Batch_loss: 2.046587 \n",
      "Batch: 1257. Acc: 0.251049. Loss: 2.177712. Batch_acc: 0.290638. Batch_loss: 2.059625 \n",
      "Batch: 1258. Acc: 0.251065. Loss: 2.177626. Batch_acc: 0.272245. Batch_loss: 2.067682 \n",
      "Batch: 1259. Acc: 0.251089. Loss: 2.177540. Batch_acc: 0.281034. Batch_loss: 2.069136 \n",
      "Batch: 1260. Acc: 0.251112. Loss: 2.177472. Batch_acc: 0.281158. Batch_loss: 2.089631 \n",
      "Batch: 1261. Acc: 0.251135. Loss: 2.177385. Batch_acc: 0.278927. Batch_loss: 2.070974 \n",
      "Batch: 1262. Acc: 0.251162. Loss: 2.177299. Batch_acc: 0.285965. Batch_loss: 2.066606 \n",
      "Batch: 1263. Acc: 0.251205. Loss: 2.177179. Batch_acc: 0.304471. Batch_loss: 2.027985 \n",
      "Batch: 1264. Acc: 0.251238. Loss: 2.177091. Batch_acc: 0.292994. Batch_loss: 2.065202 \n",
      "Batch: 1265. Acc: 0.251268. Loss: 2.176988. Batch_acc: 0.288914. Batch_loss: 2.047339 \n",
      "Batch: 1266. Acc: 0.251290. Loss: 2.176907. Batch_acc: 0.279907. Batch_loss: 2.073652 \n",
      "Batch: 1267. Acc: 0.251308. Loss: 2.176842. Batch_acc: 0.275676. Batch_loss: 2.089696 \n",
      "Batch: 1268. Acc: 0.251341. Loss: 2.176733. Batch_acc: 0.292808. Batch_loss: 2.040102 \n",
      "Batch: 1269. Acc: 0.251377. Loss: 2.176632. Batch_acc: 0.297001. Batch_loss: 2.047777 \n",
      "Batch: 1270. Acc: 0.251402. Loss: 2.176547. Batch_acc: 0.283943. Batch_loss: 2.066054 \n",
      "Batch: 1271. Acc: 0.251434. Loss: 2.176424. Batch_acc: 0.291525. Batch_loss: 2.022751 \n",
      "Batch: 1272. Acc: 0.251452. Loss: 2.176380. Batch_acc: 0.275000. Batch_loss: 2.118995 \n",
      "Batch: 1273. Acc: 0.251475. Loss: 2.176279. Batch_acc: 0.279724. Batch_loss: 2.047673 \n",
      "Batch: 1274. Acc: 0.251499. Loss: 2.176195. Batch_acc: 0.281875. Batch_loss: 2.069968 \n",
      "Batch: 1275. Acc: 0.251520. Loss: 2.176131. Batch_acc: 0.279056. Batch_loss: 2.095368 \n",
      "Batch: 1276. Acc: 0.251551. Loss: 2.176043. Batch_acc: 0.291074. Batch_loss: 2.064507 \n",
      "Batch: 1277. Acc: 0.251576. Loss: 2.175953. Batch_acc: 0.282659. Batch_loss: 2.061021 \n",
      "Batch: 1278. Acc: 0.251598. Loss: 2.175857. Batch_acc: 0.279239. Batch_loss: 2.056808 \n",
      "Batch: 1279. Acc: 0.251614. Loss: 2.175766. Batch_acc: 0.272059. Batch_loss: 2.061182 \n",
      "Batch: 1280. Acc: 0.251641. Loss: 2.175665. Batch_acc: 0.286464. Batch_loss: 2.043977 \n",
      "Batch: 1281. Acc: 0.251662. Loss: 2.175581. Batch_acc: 0.278596. Batch_loss: 2.069695 \n",
      "Batch: 1282. Acc: 0.251690. Loss: 2.175502. Batch_acc: 0.285954. Batch_loss: 2.076938 \n",
      "Batch: 1283. Acc: 0.251727. Loss: 2.175391. Batch_acc: 0.299597. Batch_loss: 2.033601 \n",
      "Batch: 1284. Acc: 0.251738. Loss: 2.175328. Batch_acc: 0.266204. Batch_loss: 2.094310 \n",
      "Batch: 1285. Acc: 0.251760. Loss: 2.175242. Batch_acc: 0.278771. Batch_loss: 2.067292 \n",
      "Batch: 1286. Acc: 0.251779. Loss: 2.175171. Batch_acc: 0.277158. Batch_loss: 2.082604 \n",
      "Batch: 1287. Acc: 0.251804. Loss: 2.175108. Batch_acc: 0.283140. Batch_loss: 2.092938 \n",
      "Batch: 1288. Acc: 0.251830. Loss: 2.175026. Batch_acc: 0.284989. Batch_loss: 2.071815 \n",
      "Batch: 1289. Acc: 0.251850. Loss: 2.174925. Batch_acc: 0.276993. Batch_loss: 2.046098 \n",
      "Batch: 1290. Acc: 0.251876. Loss: 2.174833. Batch_acc: 0.285386. Batch_loss: 2.057076 \n",
      "Batch: 1291. Acc: 0.251900. Loss: 2.174735. Batch_acc: 0.284539. Batch_loss: 2.045680 \n",
      "Batch: 1292. Acc: 0.251936. Loss: 2.174635. Batch_acc: 0.300000. Batch_loss: 2.040415 \n",
      "Batch: 1293. Acc: 0.251969. Loss: 2.174526. Batch_acc: 0.293191. Batch_loss: 2.037192 \n",
      "Batch: 1294. Acc: 0.251998. Loss: 2.174428. Batch_acc: 0.288385. Batch_loss: 2.049253 \n",
      "Batch: 1295. Acc: 0.252020. Loss: 2.174326. Batch_acc: 0.280732. Batch_loss: 2.043277 \n",
      "Batch: 1296. Acc: 0.252032. Loss: 2.174233. Batch_acc: 0.267929. Batch_loss: 2.054087 \n",
      "Batch: 1297. Acc: 0.252052. Loss: 2.174135. Batch_acc: 0.278660. Batch_loss: 2.043340 \n",
      "Batch: 1298. Acc: 0.252074. Loss: 2.174062. Batch_acc: 0.280618. Batch_loss: 2.076484 \n",
      "Batch: 1299. Acc: 0.252100. Loss: 2.173975. Batch_acc: 0.286947. Batch_loss: 2.060983 \n",
      "Batch: 1300. Acc: 0.252129. Loss: 2.173873. Batch_acc: 0.288549. Batch_loss: 2.044086 \n",
      "Batch: 1301. Acc: 0.252145. Loss: 2.173797. Batch_acc: 0.273460. Batch_loss: 2.074803 \n",
      "Batch: 1302. Acc: 0.252183. Loss: 2.173683. Batch_acc: 0.300971. Batch_loss: 2.026203 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1303. Acc: 0.252205. Loss: 2.173587. Batch_acc: 0.281287. Batch_loss: 2.046254 \n",
      "Batch: 1304. Acc: 0.252238. Loss: 2.173498. Batch_acc: 0.295612. Batch_loss: 2.057472 \n",
      "Batch: 1305. Acc: 0.252267. Loss: 2.173399. Batch_acc: 0.288926. Batch_loss: 2.046735 \n",
      "Batch: 1306. Acc: 0.252303. Loss: 2.173296. Batch_acc: 0.299652. Batch_loss: 2.037601 \n",
      "Batch: 1307. Acc: 0.252326. Loss: 2.173203. Batch_acc: 0.283063. Batch_loss: 2.050318 \n",
      "Batch: 1308. Acc: 0.252357. Loss: 2.173085. Batch_acc: 0.292447. Batch_loss: 2.021210 \n",
      "Batch: 1309. Acc: 0.252381. Loss: 2.173004. Batch_acc: 0.284539. Batch_loss: 2.064168 \n",
      "Batch: 1310. Acc: 0.252405. Loss: 2.172926. Batch_acc: 0.285033. Batch_loss: 2.067479 \n",
      "Batch: 1311. Acc: 0.252432. Loss: 2.172839. Batch_acc: 0.287435. Batch_loss: 2.058712 \n",
      "Batch: 1312. Acc: 0.252453. Loss: 2.172744. Batch_acc: 0.279243. Batch_loss: 2.048589 \n",
      "Batch: 1313. Acc: 0.252486. Loss: 2.172635. Batch_acc: 0.295726. Batch_loss: 2.031669 \n",
      "Batch: 1314. Acc: 0.252527. Loss: 2.172516. Batch_acc: 0.306931. Batch_loss: 2.013908 \n",
      "Batch: 1315. Acc: 0.252546. Loss: 2.172436. Batch_acc: 0.277520. Batch_loss: 2.066819 \n",
      "Batch: 1316. Acc: 0.252575. Loss: 2.172332. Batch_acc: 0.291074. Batch_loss: 2.036837 \n",
      "Batch: 1317. Acc: 0.252609. Loss: 2.172229. Batch_acc: 0.296615. Batch_loss: 2.037382 \n",
      "Batch: 1318. Acc: 0.252630. Loss: 2.172165. Batch_acc: 0.281323. Batch_loss: 2.086991 \n",
      "Batch: 1319. Acc: 0.252662. Loss: 2.172069. Batch_acc: 0.295415. Batch_loss: 2.045057 \n",
      "Batch: 1320. Acc: 0.252684. Loss: 2.171982. Batch_acc: 0.281530. Batch_loss: 2.052548 \n",
      "Batch: 1321. Acc: 0.252712. Loss: 2.171888. Batch_acc: 0.289102. Batch_loss: 2.049038 \n",
      "Batch: 1322. Acc: 0.252731. Loss: 2.171798. Batch_acc: 0.278459. Batch_loss: 2.051457 \n",
      "Batch: 1323. Acc: 0.252736. Loss: 2.171733. Batch_acc: 0.259174. Batch_loss: 2.085998 \n",
      "Batch: 1324. Acc: 0.252755. Loss: 2.171636. Batch_acc: 0.277810. Batch_loss: 2.043492 \n",
      "Batch: 1325. Acc: 0.252778. Loss: 2.171548. Batch_acc: 0.283893. Batch_loss: 2.054610 \n",
      "Batch: 1326. Acc: 0.252811. Loss: 2.171445. Batch_acc: 0.296548. Batch_loss: 2.037194 \n",
      "Batch: 1327. Acc: 0.252835. Loss: 2.171346. Batch_acc: 0.283496. Batch_loss: 2.039025 \n",
      "Batch: 1328. Acc: 0.252869. Loss: 2.171249. Batch_acc: 0.298490. Batch_loss: 2.041330 \n",
      "Batch: 1329. Acc: 0.252903. Loss: 2.171138. Batch_acc: 0.298286. Batch_loss: 2.025484 \n",
      "Batch: 1330. Acc: 0.252927. Loss: 2.171046. Batch_acc: 0.284175. Batch_loss: 2.049614 \n",
      "Batch: 1331. Acc: 0.252952. Loss: 2.170960. Batch_acc: 0.286613. Batch_loss: 2.057502 \n",
      "Batch: 1332. Acc: 0.252985. Loss: 2.170869. Batch_acc: 0.296532. Batch_loss: 2.049837 \n",
      "Batch: 1333. Acc: 0.253003. Loss: 2.170789. Batch_acc: 0.277011. Batch_loss: 2.063586 \n",
      "Batch: 1334. Acc: 0.253038. Loss: 2.170698. Batch_acc: 0.299717. Batch_loss: 2.050809 \n",
      "Batch: 1335. Acc: 0.253058. Loss: 2.170614. Batch_acc: 0.280281. Batch_loss: 2.057202 \n",
      "Batch: 1336. Acc: 0.253083. Loss: 2.170539. Batch_acc: 0.285714. Batch_loss: 2.070849 \n",
      "Batch: 1337. Acc: 0.253098. Loss: 2.170478. Batch_acc: 0.272675. Batch_loss: 2.089331 \n",
      "Batch: 1338. Acc: 0.253115. Loss: 2.170417. Batch_acc: 0.276390. Batch_loss: 2.089138 \n",
      "Batch: 1339. Acc: 0.253143. Loss: 2.170319. Batch_acc: 0.290564. Batch_loss: 2.040000 \n",
      "Batch: 1340. Acc: 0.253171. Loss: 2.170219. Batch_acc: 0.290323. Batch_loss: 2.038776 \n",
      "Batch: 1341. Acc: 0.253203. Loss: 2.170133. Batch_acc: 0.295533. Batch_loss: 2.055363 \n",
      "Batch: 1342. Acc: 0.253243. Loss: 2.170013. Batch_acc: 0.306064. Batch_loss: 2.008977 \n",
      "Batch: 1343. Acc: 0.253265. Loss: 2.169935. Batch_acc: 0.282891. Batch_loss: 2.067072 \n",
      "Batch: 1344. Acc: 0.253291. Loss: 2.169822. Batch_acc: 0.288262. Batch_loss: 2.018564 \n",
      "Batch: 1345. Acc: 0.253325. Loss: 2.169715. Batch_acc: 0.297024. Batch_loss: 2.029595 \n",
      "Batch: 1346. Acc: 0.253356. Loss: 2.169615. Batch_acc: 0.296189. Batch_loss: 2.034334 \n",
      "Batch: 1347. Acc: 0.253375. Loss: 2.169528. Batch_acc: 0.279017. Batch_loss: 2.052720 \n",
      "Batch: 1348. Acc: 0.253404. Loss: 2.169433. Batch_acc: 0.290981. Batch_loss: 2.043422 \n",
      "Batch: 1349. Acc: 0.253433. Loss: 2.169363. Batch_acc: 0.293103. Batch_loss: 2.074517 \n",
      "Batch: 1350. Acc: 0.253458. Loss: 2.169290. Batch_acc: 0.287616. Batch_loss: 2.070986 \n",
      "Batch: 1351. Acc: 0.253481. Loss: 2.169214. Batch_acc: 0.285049. Batch_loss: 2.065481 \n",
      "Batch: 1352. Acc: 0.253506. Loss: 2.169133. Batch_acc: 0.285876. Batch_loss: 2.060614 \n",
      "Batch: 1353. Acc: 0.253539. Loss: 2.169025. Batch_acc: 0.297373. Batch_loss: 2.027717 \n",
      "Batch: 1354. Acc: 0.253571. Loss: 2.168925. Batch_acc: 0.296317. Batch_loss: 2.034996 \n",
      "Batch: 1355. Acc: 0.253604. Loss: 2.168823. Batch_acc: 0.299823. Batch_loss: 2.026642 \n",
      "Batch: 1356. Acc: 0.253628. Loss: 2.168725. Batch_acc: 0.286464. Batch_loss: 2.034532 \n",
      "Batch: 1357. Acc: 0.253664. Loss: 2.168611. Batch_acc: 0.301191. Batch_loss: 2.015786 \n",
      "Batch: 1358. Acc: 0.253677. Loss: 2.168534. Batch_acc: 0.271935. Batch_loss: 2.062915 \n",
      "Batch: 1359. Acc: 0.253682. Loss: 2.168477. Batch_acc: 0.260035. Batch_loss: 2.090501 \n",
      "Batch: 1360. Acc: 0.253706. Loss: 2.168399. Batch_acc: 0.286207. Batch_loss: 2.062841 \n",
      "Batch: 1361. Acc: 0.253735. Loss: 2.168318. Batch_acc: 0.293642. Batch_loss: 2.056544 \n",
      "Batch: 1362. Acc: 0.253744. Loss: 2.168261. Batch_acc: 0.266902. Batch_loss: 2.089044 \n",
      "Batch: 1363. Acc: 0.253773. Loss: 2.168168. Batch_acc: 0.292437. Batch_loss: 2.045376 \n",
      "Batch: 1364. Acc: 0.253802. Loss: 2.168072. Batch_acc: 0.292281. Batch_loss: 2.039095 \n",
      "Batch: 1365. Acc: 0.253827. Loss: 2.167979. Batch_acc: 0.288654. Batch_loss: 2.037992 \n",
      "Batch: 1366. Acc: 0.253847. Loss: 2.167885. Batch_acc: 0.281903. Batch_loss: 2.037927 \n",
      "Batch: 1367. Acc: 0.253878. Loss: 2.167785. Batch_acc: 0.294843. Batch_loss: 2.035240 \n",
      "Batch: 1368. Acc: 0.253905. Loss: 2.167672. Batch_acc: 0.289252. Batch_loss: 2.016961 \n",
      "Batch: 1369. Acc: 0.253936. Loss: 2.167574. Batch_acc: 0.296402. Batch_loss: 2.034275 \n",
      "Batch: 1370. Acc: 0.253965. Loss: 2.167469. Batch_acc: 0.293250. Batch_loss: 2.025840 \n",
      "Batch: 1371. Acc: 0.253997. Loss: 2.167368. Batch_acc: 0.297114. Batch_loss: 2.030259 \n",
      "Batch: 1372. Acc: 0.254004. Loss: 2.167303. Batch_acc: 0.264448. Batch_loss: 2.076958 \n",
      "Batch: 1373. Acc: 0.254026. Loss: 2.167225. Batch_acc: 0.283343. Batch_loss: 2.060650 \n",
      "Batch: 1374. Acc: 0.254042. Loss: 2.167151. Batch_acc: 0.276158. Batch_loss: 2.066869 \n",
      "Batch: 1375. Acc: 0.254061. Loss: 2.167079. Batch_acc: 0.281231. Batch_loss: 2.065113 \n",
      "Batch: 1376. Acc: 0.254101. Loss: 2.166958. Batch_acc: 0.309249. Batch_loss: 1.999862 \n",
      "Batch: 1377. Acc: 0.254125. Loss: 2.166882. Batch_acc: 0.287032. Batch_loss: 2.062108 \n",
      "Batch: 1378. Acc: 0.254150. Loss: 2.166793. Batch_acc: 0.288126. Batch_loss: 2.047131 \n",
      "Batch: 1379. Acc: 0.254174. Loss: 2.166683. Batch_acc: 0.285634. Batch_loss: 2.018410 \n",
      "Batch: 1380. Acc: 0.254200. Loss: 2.166594. Batch_acc: 0.290268. Batch_loss: 2.044935 \n",
      "Batch: 1381. Acc: 0.254217. Loss: 2.166522. Batch_acc: 0.278066. Batch_loss: 2.066870 \n",
      "Batch: 1382. Acc: 0.254232. Loss: 2.166455. Batch_acc: 0.274147. Batch_loss: 2.073076 \n",
      "Batch: 1383. Acc: 0.254246. Loss: 2.166377. Batch_acc: 0.273830. Batch_loss: 2.058798 \n",
      "Batch: 1384. Acc: 0.254272. Loss: 2.166292. Batch_acc: 0.290304. Batch_loss: 2.050528 \n",
      "Batch: 1385. Acc: 0.254303. Loss: 2.166191. Batch_acc: 0.294908. Batch_loss: 2.030313 \n",
      "Batch: 1386. Acc: 0.254332. Loss: 2.166090. Batch_acc: 0.295337. Batch_loss: 2.026144 \n",
      "Batch: 1387. Acc: 0.254351. Loss: 2.166025. Batch_acc: 0.281178. Batch_loss: 2.075941 \n",
      "Batch: 1388. Acc: 0.254366. Loss: 2.165964. Batch_acc: 0.274926. Batch_loss: 2.079311 \n",
      "Batch: 1389. Acc: 0.254387. Loss: 2.165878. Batch_acc: 0.282743. Batch_loss: 2.049230 \n",
      "Batch: 1390. Acc: 0.254402. Loss: 2.165822. Batch_acc: 0.275943. Batch_loss: 2.085182 \n",
      "Batch: 1391. Acc: 0.254420. Loss: 2.165755. Batch_acc: 0.279514. Batch_loss: 2.071783 \n",
      "Batch: 1392. Acc: 0.254455. Loss: 2.165646. Batch_acc: 0.302459. Batch_loss: 2.015964 \n",
      "Batch: 1393. Acc: 0.254477. Loss: 2.165568. Batch_acc: 0.286290. Batch_loss: 2.055747 \n",
      "Batch: 1394. Acc: 0.254507. Loss: 2.165470. Batch_acc: 0.295702. Batch_loss: 2.030229 \n",
      "Batch: 1395. Acc: 0.254545. Loss: 2.165358. Batch_acc: 0.306644. Batch_loss: 2.011065 \n",
      "Batch: 1396. Acc: 0.254581. Loss: 2.165263. Batch_acc: 0.304373. Batch_loss: 2.034248 \n",
      "Batch: 1397. Acc: 0.254616. Loss: 2.165176. Batch_acc: 0.303520. Batch_loss: 2.042821 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1398. Acc: 0.254633. Loss: 2.165094. Batch_acc: 0.278868. Batch_loss: 2.050489 \n",
      "Batch: 1399. Acc: 0.254655. Loss: 2.165002. Batch_acc: 0.284110. Batch_loss: 2.039425 \n",
      "Batch: 1400. Acc: 0.254680. Loss: 2.164915. Batch_acc: 0.290962. Batch_loss: 2.040875 \n",
      "Batch: 1401. Acc: 0.254711. Loss: 2.164823. Batch_acc: 0.297374. Batch_loss: 2.037320 \n",
      "Batch: 1402. Acc: 0.254746. Loss: 2.164709. Batch_acc: 0.304121. Batch_loss: 2.004114 \n",
      "Batch: 1403. Acc: 0.254767. Loss: 2.164641. Batch_acc: 0.285134. Batch_loss: 2.068798 \n",
      "Batch: 1404. Acc: 0.254795. Loss: 2.164532. Batch_acc: 0.294118. Batch_loss: 2.005628 \n",
      "Batch: 1405. Acc: 0.254807. Loss: 2.164475. Batch_acc: 0.273602. Batch_loss: 2.080785 \n",
      "Batch: 1406. Acc: 0.254834. Loss: 2.164409. Batch_acc: 0.292388. Batch_loss: 2.071285 \n",
      "Batch: 1407. Acc: 0.254864. Loss: 2.164320. Batch_acc: 0.296804. Batch_loss: 2.041022 \n",
      "Batch: 1408. Acc: 0.254891. Loss: 2.164222. Batch_acc: 0.292045. Batch_loss: 2.027075 \n",
      "Batch: 1409. Acc: 0.254911. Loss: 2.164147. Batch_acc: 0.283324. Batch_loss: 2.058286 \n",
      "Batch: 1410. Acc: 0.254937. Loss: 2.164070. Batch_acc: 0.291811. Batch_loss: 2.056123 \n",
      "Batch: 1411. Acc: 0.254962. Loss: 2.163994. Batch_acc: 0.289489. Batch_loss: 2.056246 \n",
      "Batch: 1412. Acc: 0.254976. Loss: 2.163928. Batch_acc: 0.276236. Batch_loss: 2.066784 \n",
      "Batch: 1413. Acc: 0.255008. Loss: 2.163828. Batch_acc: 0.300056. Batch_loss: 2.025388 \n",
      "Batch: 1414. Acc: 0.255034. Loss: 2.163722. Batch_acc: 0.291449. Batch_loss: 2.011493 \n",
      "Batch: 1415. Acc: 0.255045. Loss: 2.163669. Batch_acc: 0.271562. Batch_loss: 2.088003 \n",
      "Batch: 1416. Acc: 0.255073. Loss: 2.163570. Batch_acc: 0.293348. Batch_loss: 2.025561 \n",
      "Batch: 1417. Acc: 0.255088. Loss: 2.163495. Batch_acc: 0.276471. Batch_loss: 2.055015 \n",
      "Batch: 1418. Acc: 0.255112. Loss: 2.163403. Batch_acc: 0.290028. Batch_loss: 2.033880 \n",
      "Batch: 1419. Acc: 0.255144. Loss: 2.163311. Batch_acc: 0.299656. Batch_loss: 2.032446 \n",
      "Batch: 1420. Acc: 0.255181. Loss: 2.163200. Batch_acc: 0.306948. Batch_loss: 2.008022 \n",
      "Batch: 1421. Acc: 0.255191. Loss: 2.163120. Batch_acc: 0.270568. Batch_loss: 2.048836 \n",
      "Batch: 1422. Acc: 0.255214. Loss: 2.163047. Batch_acc: 0.288186. Batch_loss: 2.055173 \n",
      "Batch: 1423. Acc: 0.255236. Loss: 2.162964. Batch_acc: 0.288085. Batch_loss: 2.041490 \n",
      "Batch: 1424. Acc: 0.255253. Loss: 2.162896. Batch_acc: 0.279162. Batch_loss: 2.067707 \n",
      "Batch: 1425. Acc: 0.255282. Loss: 2.162792. Batch_acc: 0.294613. Batch_loss: 2.017379 \n",
      "Batch: 1426. Acc: 0.255309. Loss: 2.162691. Batch_acc: 0.293423. Batch_loss: 2.022653 \n",
      "Batch: 1427. Acc: 0.255330. Loss: 2.162610. Batch_acc: 0.286467. Batch_loss: 2.044953 \n",
      "Batch: 1428. Acc: 0.255347. Loss: 2.162537. Batch_acc: 0.279557. Batch_loss: 2.057121 \n",
      "Batch: 1429. Acc: 0.255367. Loss: 2.162457. Batch_acc: 0.283737. Batch_loss: 2.047194 \n",
      "Batch: 1430. Acc: 0.255385. Loss: 2.162394. Batch_acc: 0.280822. Batch_loss: 2.073153 \n",
      "Batch: 1431. Acc: 0.255417. Loss: 2.162303. Batch_acc: 0.299552. Batch_loss: 2.035458 \n",
      "Batch: 1432. Acc: 0.255433. Loss: 2.162240. Batch_acc: 0.279833. Batch_loss: 2.068964 \n",
      "Batch: 1433. Acc: 0.255449. Loss: 2.162166. Batch_acc: 0.278351. Batch_loss: 2.056994 \n",
      "Batch: 1434. Acc: 0.255470. Loss: 2.162089. Batch_acc: 0.285552. Batch_loss: 2.052885 \n",
      "Batch: 1435. Acc: 0.255501. Loss: 2.162006. Batch_acc: 0.300347. Batch_loss: 2.043161 \n",
      "Batch: 1436. Acc: 0.255528. Loss: 2.161932. Batch_acc: 0.294187. Batch_loss: 2.053021 \n",
      "Batch: 1437. Acc: 0.255554. Loss: 2.161849. Batch_acc: 0.293242. Batch_loss: 2.043549 \n",
      "Batch: 1438. Acc: 0.255570. Loss: 2.161792. Batch_acc: 0.278610. Batch_loss: 2.075842 \n",
      "Batch: 1439. Acc: 0.255590. Loss: 2.161716. Batch_acc: 0.285386. Batch_loss: 2.051724 \n",
      "Batch: 1440. Acc: 0.255608. Loss: 2.161647. Batch_acc: 0.280944. Batch_loss: 2.063516 \n",
      "Batch: 1441. Acc: 0.255630. Loss: 2.161574. Batch_acc: 0.286693. Batch_loss: 2.056891 \n",
      "Batch: 1442. Acc: 0.255655. Loss: 2.161487. Batch_acc: 0.292882. Batch_loss: 2.034504 \n",
      "Batch: 1443. Acc: 0.255686. Loss: 2.161393. Batch_acc: 0.300578. Batch_loss: 2.025341 \n",
      "Batch: 1444. Acc: 0.255708. Loss: 2.161329. Batch_acc: 0.288116. Batch_loss: 2.068025 \n",
      "Batch: 1445. Acc: 0.255728. Loss: 2.161232. Batch_acc: 0.284388. Batch_loss: 2.018983 \n",
      "Batch: 1446. Acc: 0.255754. Loss: 2.161153. Batch_acc: 0.292877. Batch_loss: 2.049032 \n",
      "Batch: 1447. Acc: 0.255770. Loss: 2.161083. Batch_acc: 0.279221. Batch_loss: 2.056783 \n",
      "Batch: 1448. Acc: 0.255790. Loss: 2.161004. Batch_acc: 0.284722. Batch_loss: 2.045764 \n",
      "Batch: 1449. Acc: 0.255822. Loss: 2.160912. Batch_acc: 0.301983. Batch_loss: 2.029064 \n",
      "Batch: 1450. Acc: 0.255831. Loss: 2.160854. Batch_acc: 0.269297. Batch_loss: 2.077430 \n",
      "Batch: 1451. Acc: 0.255839. Loss: 2.160792. Batch_acc: 0.266550. Batch_loss: 2.070066 \n",
      "Batch: 1452. Acc: 0.255867. Loss: 2.160691. Batch_acc: 0.296586. Batch_loss: 2.017949 \n",
      "Batch: 1453. Acc: 0.255890. Loss: 2.160615. Batch_acc: 0.288194. Batch_loss: 2.048922 \n",
      "Batch: 1454. Acc: 0.255914. Loss: 2.160543. Batch_acc: 0.291284. Batch_loss: 2.056484 \n",
      "Batch: 1455. Acc: 0.255932. Loss: 2.160482. Batch_acc: 0.282634. Batch_loss: 2.071107 \n",
      "Batch: 1456. Acc: 0.255951. Loss: 2.160405. Batch_acc: 0.282869. Batch_loss: 2.048704 \n",
      "Batch: 1457. Acc: 0.255961. Loss: 2.160335. Batch_acc: 0.271363. Batch_loss: 2.058517 \n",
      "Batch: 1458. Acc: 0.255990. Loss: 2.160244. Batch_acc: 0.297052. Batch_loss: 2.029652 \n",
      "Batch: 1459. Acc: 0.256020. Loss: 2.160149. Batch_acc: 0.300402. Batch_loss: 2.022399 \n",
      "Batch: 1460. Acc: 0.256034. Loss: 2.160111. Batch_acc: 0.276207. Batch_loss: 2.102149 \n",
      "Batch: 1461. Acc: 0.256057. Loss: 2.160024. Batch_acc: 0.289608. Batch_loss: 2.035026 \n",
      "Batch: 1462. Acc: 0.256083. Loss: 2.159931. Batch_acc: 0.291943. Batch_loss: 2.029326 \n",
      "Batch: 1463. Acc: 0.256104. Loss: 2.159867. Batch_acc: 0.287897. Batch_loss: 2.065272 \n",
      "Batch: 1464. Acc: 0.256122. Loss: 2.159785. Batch_acc: 0.281803. Batch_loss: 2.039627 \n",
      "Batch: 1465. Acc: 0.256152. Loss: 2.159692. Batch_acc: 0.298934. Batch_loss: 2.027552 \n",
      "Batch: 1466. Acc: 0.256163. Loss: 2.159643. Batch_acc: 0.271850. Batch_loss: 2.088573 \n",
      "Batch: 1467. Acc: 0.256192. Loss: 2.159562. Batch_acc: 0.300599. Batch_loss: 2.036055 \n",
      "Batch: 1468. Acc: 0.256222. Loss: 2.159466. Batch_acc: 0.300695. Batch_loss: 2.018035 \n",
      "Batch: 1469. Acc: 0.256241. Loss: 2.159393. Batch_acc: 0.284784. Batch_loss: 2.048626 \n",
      "Batch: 1470. Acc: 0.256257. Loss: 2.159325. Batch_acc: 0.281525. Batch_loss: 2.057598 \n",
      "Batch: 1471. Acc: 0.256276. Loss: 2.159255. Batch_acc: 0.283451. Batch_loss: 2.053536 \n",
      "Batch: 1472. Acc: 0.256302. Loss: 2.159183. Batch_acc: 0.293984. Batch_loss: 2.055649 \n",
      "Batch: 1473. Acc: 0.256314. Loss: 2.159124. Batch_acc: 0.273702. Batch_loss: 2.073682 \n",
      "Batch: 1474. Acc: 0.256334. Loss: 2.159047. Batch_acc: 0.287647. Batch_loss: 2.042327 \n",
      "Batch: 1475. Acc: 0.256366. Loss: 2.158947. Batch_acc: 0.301117. Batch_loss: 2.015705 \n",
      "Batch: 1476. Acc: 0.256392. Loss: 2.158866. Batch_acc: 0.295351. Batch_loss: 2.041154 \n",
      "Batch: 1477. Acc: 0.256418. Loss: 2.158781. Batch_acc: 0.293152. Batch_loss: 2.035495 \n",
      "Batch: 1478. Acc: 0.256440. Loss: 2.158684. Batch_acc: 0.288625. Batch_loss: 2.017983 \n",
      "Batch: 1479. Acc: 0.256467. Loss: 2.158583. Batch_acc: 0.297297. Batch_loss: 2.009387 \n",
      "Batch: 1480. Acc: 0.256495. Loss: 2.158492. Batch_acc: 0.296045. Batch_loss: 2.026868 \n",
      "Batch: 1481. Acc: 0.256516. Loss: 2.158416. Batch_acc: 0.288106. Batch_loss: 2.045168 \n",
      "Batch: 1482. Acc: 0.256546. Loss: 2.158334. Batch_acc: 0.300994. Batch_loss: 2.035007 \n",
      "Batch: 1483. Acc: 0.256568. Loss: 2.158266. Batch_acc: 0.290028. Batch_loss: 2.057768 \n",
      "Batch: 1484. Acc: 0.256587. Loss: 2.158193. Batch_acc: 0.284302. Batch_loss: 2.049066 \n",
      "Batch: 1485. Acc: 0.256627. Loss: 2.158095. Batch_acc: 0.315670. Batch_loss: 2.014397 \n",
      "Batch: 1486. Acc: 0.256651. Loss: 2.158010. Batch_acc: 0.292148. Batch_loss: 2.030289 \n",
      "Batch: 1487. Acc: 0.256679. Loss: 2.157924. Batch_acc: 0.297824. Batch_loss: 2.031241 \n",
      "Batch: 1488. Acc: 0.256699. Loss: 2.157853. Batch_acc: 0.287442. Batch_loss: 2.051986 \n",
      "Batch: 1489. Acc: 0.256725. Loss: 2.157782. Batch_acc: 0.294284. Batch_loss: 2.053509 \n",
      "Batch: 1490. Acc: 0.256751. Loss: 2.157698. Batch_acc: 0.294814. Batch_loss: 2.035695 \n",
      "Batch: 1491. Acc: 0.256763. Loss: 2.157641. Batch_acc: 0.274941. Batch_loss: 2.069774 \n",
      "Batch: 1492. Acc: 0.256782. Loss: 2.157571. Batch_acc: 0.285714. Batch_loss: 2.052492 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1493. Acc: 0.256799. Loss: 2.157497. Batch_acc: 0.282759. Batch_loss: 2.046923 \n",
      "Batch: 1494. Acc: 0.256829. Loss: 2.157417. Batch_acc: 0.302162. Batch_loss: 2.035611 \n",
      "Batch: 1495. Acc: 0.256852. Loss: 2.157355. Batch_acc: 0.291398. Batch_loss: 2.063492 \n",
      "Batch: 1496. Acc: 0.256880. Loss: 2.157279. Batch_acc: 0.298236. Batch_loss: 2.044687 \n",
      "Batch: 1497. Acc: 0.256901. Loss: 2.157201. Batch_acc: 0.288462. Batch_loss: 2.038733 \n",
      "Batch: 1498. Acc: 0.256920. Loss: 2.157148. Batch_acc: 0.287164. Batch_loss: 2.074449 \n",
      "Batch: 1499. Acc: 0.256937. Loss: 2.157088. Batch_acc: 0.282571. Batch_loss: 2.067628 \n",
      "Batch: 1500. Acc: 0.256953. Loss: 2.157029. Batch_acc: 0.280912. Batch_loss: 2.068910 \n",
      "Batch: 1501. Acc: 0.256973. Loss: 2.156969. Batch_acc: 0.287042. Batch_loss: 2.065697 \n",
      "Batch: 1502. Acc: 0.257007. Loss: 2.156863. Batch_acc: 0.305962. Batch_loss: 2.002290 \n",
      "Batch: 1503. Acc: 0.257027. Loss: 2.156796. Batch_acc: 0.289192. Batch_loss: 2.052272 \n",
      "Batch: 1504. Acc: 0.257046. Loss: 2.156725. Batch_acc: 0.285304. Batch_loss: 2.050500 \n",
      "Batch: 1505. Acc: 0.257074. Loss: 2.156651. Batch_acc: 0.299823. Batch_loss: 2.042085 \n",
      "Batch: 1506. Acc: 0.257104. Loss: 2.156576. Batch_acc: 0.302540. Batch_loss: 2.042629 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.25710383671916803. Loss per char: 2.1565755941200244. Time: 1627203734.2152574\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 14, 23, 20,  1, 14,  1, 17, 15,\n",
      "        17, 25, 26, 21, 25, 18, 25, 18, 25, 22, 20, 19, 21, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.257133. Loss: 2.156487. Batch_acc: 0.301670. Batch_loss: 2.023299 \n",
      "Batch: 1508. Acc: 0.257167. Loss: 2.156401. Batch_acc: 0.308713. Batch_loss: 2.026328 \n",
      "Batch: 1509. Acc: 0.257189. Loss: 2.156321. Batch_acc: 0.289252. Batch_loss: 2.038532 \n",
      "Batch: 1510. Acc: 0.257208. Loss: 2.156266. Batch_acc: 0.286374. Batch_loss: 2.071881 \n",
      "Batch: 1511. Acc: 0.257226. Loss: 2.156213. Batch_acc: 0.283237. Batch_loss: 2.075670 \n",
      "Batch: 1512. Acc: 0.257253. Loss: 2.156125. Batch_acc: 0.297343. Batch_loss: 2.026371 \n",
      "Batch: 1513. Acc: 0.257275. Loss: 2.156037. Batch_acc: 0.290657. Batch_loss: 2.022971 \n",
      "Batch: 1514. Acc: 0.257295. Loss: 2.155977. Batch_acc: 0.287958. Batch_loss: 2.064156 \n",
      "Batch: 1515. Acc: 0.257317. Loss: 2.155897. Batch_acc: 0.291619. Batch_loss: 2.033770 \n",
      "Batch: 1516. Acc: 0.257341. Loss: 2.155835. Batch_acc: 0.295024. Batch_loss: 2.059012 \n",
      "Batch: 1517. Acc: 0.257365. Loss: 2.155757. Batch_acc: 0.293053. Batch_loss: 2.037128 \n",
      "Batch: 1518. Acc: 0.257385. Loss: 2.155681. Batch_acc: 0.288749. Batch_loss: 2.040137 \n",
      "Batch: 1519. Acc: 0.257410. Loss: 2.155609. Batch_acc: 0.294622. Batch_loss: 2.046874 \n",
      "Batch: 1520. Acc: 0.257440. Loss: 2.155518. Batch_acc: 0.303893. Batch_loss: 2.016308 \n",
      "Batch: 1521. Acc: 0.257467. Loss: 2.155452. Batch_acc: 0.297688. Batch_loss: 2.053795 \n",
      "Batch: 1522. Acc: 0.257484. Loss: 2.155380. Batch_acc: 0.282976. Batch_loss: 2.048795 \n",
      "Batch: 1523. Acc: 0.257505. Loss: 2.155301. Batch_acc: 0.289143. Batch_loss: 2.035251 \n",
      "Batch: 1524. Acc: 0.257521. Loss: 2.155247. Batch_acc: 0.282353. Batch_loss: 2.070616 \n",
      "Batch: 1525. Acc: 0.257540. Loss: 2.155158. Batch_acc: 0.287197. Batch_loss: 2.019174 \n",
      "Batch: 1526. Acc: 0.257559. Loss: 2.155101. Batch_acc: 0.287390. Batch_loss: 2.067002 \n",
      "Batch: 1527. Acc: 0.257575. Loss: 2.155049. Batch_acc: 0.281616. Batch_loss: 2.074806 \n",
      "Batch: 1528. Acc: 0.257606. Loss: 2.154962. Batch_acc: 0.304176. Batch_loss: 2.023739 \n",
      "Batch: 1529. Acc: 0.257629. Loss: 2.154882. Batch_acc: 0.293242. Batch_loss: 2.034091 \n",
      "Batch: 1530. Acc: 0.257653. Loss: 2.154798. Batch_acc: 0.294084. Batch_loss: 2.025302 \n",
      "Batch: 1531. Acc: 0.257676. Loss: 2.154727. Batch_acc: 0.293434. Batch_loss: 2.045297 \n",
      "Batch: 1532. Acc: 0.257703. Loss: 2.154646. Batch_acc: 0.298456. Batch_loss: 2.031256 \n",
      "Batch: 1533. Acc: 0.257724. Loss: 2.154586. Batch_acc: 0.291442. Batch_loss: 2.058928 \n",
      "Batch: 1534. Acc: 0.257761. Loss: 2.154489. Batch_acc: 0.314121. Batch_loss: 2.005254 \n",
      "Batch: 1535. Acc: 0.257779. Loss: 2.154415. Batch_acc: 0.286543. Batch_loss: 2.040211 \n",
      "Batch: 1536. Acc: 0.257802. Loss: 2.154333. Batch_acc: 0.292237. Batch_loss: 2.030138 \n",
      "Batch: 1537. Acc: 0.257824. Loss: 2.154273. Batch_acc: 0.291667. Batch_loss: 2.063219 \n",
      "Batch: 1538. Acc: 0.257841. Loss: 2.154212. Batch_acc: 0.283792. Batch_loss: 2.058822 \n",
      "Batch: 1539. Acc: 0.257862. Loss: 2.154151. Batch_acc: 0.292162. Batch_loss: 2.056867 \n",
      "Batch: 1540. Acc: 0.257876. Loss: 2.154088. Batch_acc: 0.278896. Batch_loss: 2.056510 \n",
      "Batch: 1541. Acc: 0.257896. Loss: 2.154019. Batch_acc: 0.288450. Batch_loss: 2.047323 \n",
      "Batch: 1542. Acc: 0.257912. Loss: 2.153966. Batch_acc: 0.281834. Batch_loss: 2.074143 \n",
      "Batch: 1543. Acc: 0.257937. Loss: 2.153880. Batch_acc: 0.297497. Batch_loss: 2.021934 \n",
      "Batch: 1544. Acc: 0.257963. Loss: 2.153801. Batch_acc: 0.297835. Batch_loss: 2.030225 \n",
      "Batch: 1545. Acc: 0.257989. Loss: 2.153743. Batch_acc: 0.298671. Batch_loss: 2.063311 \n",
      "Batch: 1546. Acc: 0.258004. Loss: 2.153683. Batch_acc: 0.279299. Batch_loss: 2.066325 \n",
      "Batch: 1547. Acc: 0.258019. Loss: 2.153621. Batch_acc: 0.282775. Batch_loss: 2.054156 \n",
      "Batch: 1548. Acc: 0.258035. Loss: 2.153586. Batch_acc: 0.282545. Batch_loss: 2.099700 \n",
      "Batch: 1549. Acc: 0.258060. Loss: 2.153511. Batch_acc: 0.296946. Batch_loss: 2.039655 \n",
      "Batch: 1550. Acc: 0.258078. Loss: 2.153437. Batch_acc: 0.285303. Batch_loss: 2.037818 \n",
      "Batch: 1551. Acc: 0.258099. Loss: 2.153368. Batch_acc: 0.290268. Batch_loss: 2.047763 \n",
      "Batch: 1552. Acc: 0.258108. Loss: 2.153318. Batch_acc: 0.271895. Batch_loss: 2.075896 \n",
      "Batch: 1553. Acc: 0.258132. Loss: 2.153251. Batch_acc: 0.295167. Batch_loss: 2.049242 \n",
      "Batch: 1554. Acc: 0.258148. Loss: 2.153179. Batch_acc: 0.284468. Batch_loss: 2.040007 \n",
      "Batch: 1555. Acc: 0.258162. Loss: 2.153120. Batch_acc: 0.278431. Batch_loss: 2.064592 \n",
      "Batch: 1556. Acc: 0.258181. Loss: 2.153055. Batch_acc: 0.287168. Batch_loss: 2.052993 \n",
      "Batch: 1557. Acc: 0.258205. Loss: 2.152989. Batch_acc: 0.296556. Batch_loss: 2.048191 \n",
      "Batch: 1558. Acc: 0.258221. Loss: 2.152925. Batch_acc: 0.283972. Batch_loss: 2.052579 \n",
      "Batch: 1559. Acc: 0.258242. Loss: 2.152834. Batch_acc: 0.291569. Batch_loss: 2.008307 \n",
      "Batch: 1560. Acc: 0.258265. Loss: 2.152779. Batch_acc: 0.294425. Batch_loss: 2.066159 \n",
      "Batch: 1561. Acc: 0.258288. Loss: 2.152694. Batch_acc: 0.292204. Batch_loss: 2.024321 \n",
      "Batch: 1562. Acc: 0.258305. Loss: 2.152634. Batch_acc: 0.284753. Batch_loss: 2.061829 \n",
      "Batch: 1563. Acc: 0.258326. Loss: 2.152559. Batch_acc: 0.291813. Batch_loss: 2.033249 \n",
      "Batch: 1564. Acc: 0.258355. Loss: 2.152472. Batch_acc: 0.302579. Batch_loss: 2.016195 \n",
      "Batch: 1565. Acc: 0.258374. Loss: 2.152411. Batch_acc: 0.288749. Batch_loss: 2.057902 \n",
      "Batch: 1566. Acc: 0.258396. Loss: 2.152326. Batch_acc: 0.291785. Batch_loss: 2.021369 \n",
      "Batch: 1567. Acc: 0.258412. Loss: 2.152253. Batch_acc: 0.283160. Batch_loss: 2.037183 \n",
      "Batch: 1568. Acc: 0.258427. Loss: 2.152182. Batch_acc: 0.283073. Batch_loss: 2.040131 \n",
      "Batch: 1569. Acc: 0.258448. Loss: 2.152097. Batch_acc: 0.289766. Batch_loss: 2.023745 \n",
      "Batch: 1570. Acc: 0.258472. Loss: 2.152018. Batch_acc: 0.295912. Batch_loss: 2.027127 \n",
      "Batch: 1571. Acc: 0.258494. Loss: 2.151948. Batch_acc: 0.293547. Batch_loss: 2.043879 \n",
      "Batch: 1572. Acc: 0.258516. Loss: 2.151882. Batch_acc: 0.292971. Batch_loss: 2.045217 \n",
      "Batch: 1573. Acc: 0.258536. Loss: 2.151808. Batch_acc: 0.290888. Batch_loss: 2.032869 \n",
      "Batch: 1574. Acc: 0.258543. Loss: 2.151770. Batch_acc: 0.270821. Batch_loss: 2.089385 \n",
      "Batch: 1575. Acc: 0.258571. Loss: 2.151690. Batch_acc: 0.301462. Batch_loss: 2.029001 \n",
      "Batch: 1576. Acc: 0.258590. Loss: 2.151619. Batch_acc: 0.289458. Batch_loss: 2.038817 \n",
      "Batch: 1577. Acc: 0.258605. Loss: 2.151541. Batch_acc: 0.281978. Batch_loss: 2.029115 \n",
      "Batch: 1578. Acc: 0.258630. Loss: 2.151456. Batch_acc: 0.295690. Batch_loss: 2.024634 \n",
      "Batch: 1579. Acc: 0.258663. Loss: 2.151358. Batch_acc: 0.309835. Batch_loss: 1.999469 \n",
      "Batch: 1580. Acc: 0.258675. Loss: 2.151297. Batch_acc: 0.277939. Batch_loss: 2.053665 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1581. Acc: 0.258700. Loss: 2.151231. Batch_acc: 0.297688. Batch_loss: 2.046406 \n",
      "Batch: 1582. Acc: 0.258711. Loss: 2.151174. Batch_acc: 0.276744. Batch_loss: 2.059539 \n",
      "Batch: 1583. Acc: 0.258732. Loss: 2.151106. Batch_acc: 0.291139. Batch_loss: 2.044351 \n",
      "Batch: 1584. Acc: 0.258751. Loss: 2.151026. Batch_acc: 0.290304. Batch_loss: 2.024107 \n",
      "Batch: 1585. Acc: 0.258781. Loss: 2.150939. Batch_acc: 0.303812. Batch_loss: 2.017218 \n",
      "Batch: 1586. Acc: 0.258804. Loss: 2.150874. Batch_acc: 0.296339. Batch_loss: 2.046203 \n",
      "Batch: 1587. Acc: 0.258820. Loss: 2.150811. Batch_acc: 0.284567. Batch_loss: 2.052007 \n",
      "Batch: 1588. Acc: 0.258850. Loss: 2.150731. Batch_acc: 0.304969. Batch_loss: 2.024724 \n",
      "Batch: 1589. Acc: 0.258876. Loss: 2.150645. Batch_acc: 0.299717. Batch_loss: 2.014961 \n",
      "Batch: 1590. Acc: 0.258887. Loss: 2.150581. Batch_acc: 0.276039. Batch_loss: 2.050561 \n",
      "Batch: 1591. Acc: 0.258922. Loss: 2.150481. Batch_acc: 0.314318. Batch_loss: 1.993258 \n",
      "Batch: 1592. Acc: 0.258942. Loss: 2.150401. Batch_acc: 0.289921. Batch_loss: 2.024061 \n",
      "Batch: 1593. Acc: 0.258961. Loss: 2.150336. Batch_acc: 0.290068. Batch_loss: 2.049460 \n",
      "Batch: 1594. Acc: 0.258982. Loss: 2.150267. Batch_acc: 0.291352. Batch_loss: 2.038856 \n",
      "Batch: 1595. Acc: 0.259010. Loss: 2.150186. Batch_acc: 0.301928. Batch_loss: 2.027022 \n",
      "Batch: 1596. Acc: 0.259029. Loss: 2.150119. Batch_acc: 0.290323. Batch_loss: 2.042423 \n",
      "Batch: 1597. Acc: 0.259047. Loss: 2.150050. Batch_acc: 0.286693. Batch_loss: 2.040686 \n",
      "Batch: 1598. Acc: 0.259072. Loss: 2.149956. Batch_acc: 0.299770. Batch_loss: 1.999533 \n",
      "Batch: 1599. Acc: 0.259099. Loss: 2.149895. Batch_acc: 0.302405. Batch_loss: 2.054088 \n",
      "Batch: 1600. Acc: 0.259111. Loss: 2.149827. Batch_acc: 0.277011. Batch_loss: 2.040063 \n",
      "Batch: 1601. Acc: 0.259128. Loss: 2.149760. Batch_acc: 0.286452. Batch_loss: 2.043868 \n",
      "Batch: 1602. Acc: 0.259144. Loss: 2.149709. Batch_acc: 0.284562. Batch_loss: 2.067801 \n",
      "Batch: 1603. Acc: 0.259164. Loss: 2.149647. Batch_acc: 0.291527. Batch_loss: 2.052281 \n",
      "Batch: 1604. Acc: 0.259191. Loss: 2.149571. Batch_acc: 0.300910. Batch_loss: 2.030108 \n",
      "Batch: 1605. Acc: 0.259218. Loss: 2.149509. Batch_acc: 0.303065. Batch_loss: 2.051334 \n",
      "Batch: 1606. Acc: 0.259235. Loss: 2.149452. Batch_acc: 0.286628. Batch_loss: 2.057178 \n",
      "Batch: 1607. Acc: 0.259261. Loss: 2.149370. Batch_acc: 0.301056. Batch_loss: 2.015059 \n",
      "Batch: 1608. Acc: 0.259277. Loss: 2.149299. Batch_acc: 0.285796. Batch_loss: 2.035118 \n",
      "Batch: 1609. Acc: 0.259296. Loss: 2.149230. Batch_acc: 0.289352. Batch_loss: 2.038544 \n",
      "Batch: 1610. Acc: 0.259328. Loss: 2.149139. Batch_acc: 0.311353. Batch_loss: 2.002906 \n",
      "Batch: 1611. Acc: 0.259345. Loss: 2.149087. Batch_acc: 0.285466. Batch_loss: 2.065094 \n",
      "Batch: 1612. Acc: 0.259370. Loss: 2.149000. Batch_acc: 0.300343. Batch_loss: 2.008591 \n",
      "Batch: 1613. Acc: 0.259382. Loss: 2.148920. Batch_acc: 0.278403. Batch_loss: 2.022433 \n",
      "Batch: 1614. Acc: 0.259409. Loss: 2.148827. Batch_acc: 0.301124. Batch_loss: 2.003362 \n",
      "Batch: 1615. Acc: 0.259428. Loss: 2.148771. Batch_acc: 0.291234. Batch_loss: 2.057327 \n",
      "Batch: 1616. Acc: 0.259445. Loss: 2.148710. Batch_acc: 0.286121. Batch_loss: 2.052085 \n",
      "Batch: 1617. Acc: 0.259467. Loss: 2.148662. Batch_acc: 0.295415. Batch_loss: 2.070720 \n",
      "Batch: 1618. Acc: 0.259487. Loss: 2.148579. Batch_acc: 0.292071. Batch_loss: 2.014370 \n",
      "Batch: 1619. Acc: 0.259506. Loss: 2.148521. Batch_acc: 0.290553. Batch_loss: 2.052187 \n",
      "Batch: 1620. Acc: 0.259519. Loss: 2.148469. Batch_acc: 0.281122. Batch_loss: 2.063121 \n",
      "Batch: 1621. Acc: 0.259539. Loss: 2.148399. Batch_acc: 0.291933. Batch_loss: 2.034339 \n",
      "Batch: 1622. Acc: 0.259567. Loss: 2.148309. Batch_acc: 0.304724. Batch_loss: 2.001843 \n",
      "Batch: 1623. Acc: 0.259599. Loss: 2.148227. Batch_acc: 0.311890. Batch_loss: 2.015138 \n",
      "Batch: 1624. Acc: 0.259611. Loss: 2.148162. Batch_acc: 0.279056. Batch_loss: 2.042746 \n",
      "Batch: 1625. Acc: 0.259636. Loss: 2.148096. Batch_acc: 0.299885. Batch_loss: 2.040361 \n",
      "Batch: 1626. Acc: 0.259661. Loss: 2.148019. Batch_acc: 0.300459. Batch_loss: 2.023414 \n",
      "Batch: 1627. Acc: 0.259684. Loss: 2.147946. Batch_acc: 0.296009. Batch_loss: 2.033515 \n",
      "Batch: 1628. Acc: 0.259698. Loss: 2.147897. Batch_acc: 0.281393. Batch_loss: 2.069164 \n",
      "Batch: 1629. Acc: 0.259712. Loss: 2.147838. Batch_acc: 0.282313. Batch_loss: 2.052277 \n",
      "Batch: 1630. Acc: 0.259730. Loss: 2.147780. Batch_acc: 0.290623. Batch_loss: 2.051965 \n",
      "Batch: 1631. Acc: 0.259748. Loss: 2.147731. Batch_acc: 0.289427. Batch_loss: 2.066792 \n",
      "Batch: 1632. Acc: 0.259769. Loss: 2.147667. Batch_acc: 0.294694. Batch_loss: 2.041765 \n",
      "Batch: 1633. Acc: 0.259779. Loss: 2.147621. Batch_acc: 0.275117. Batch_loss: 2.072111 \n",
      "Batch: 1634. Acc: 0.259798. Loss: 2.147555. Batch_acc: 0.291023. Batch_loss: 2.039952 \n",
      "Batch: 1635. Acc: 0.259818. Loss: 2.147480. Batch_acc: 0.292882. Batch_loss: 2.023282 \n",
      "Batch: 1636. Acc: 0.259836. Loss: 2.147416. Batch_acc: 0.288876. Batch_loss: 2.044652 \n",
      "Batch: 1637. Acc: 0.259860. Loss: 2.147344. Batch_acc: 0.299770. Batch_loss: 2.028861 \n",
      "Batch: 1638. Acc: 0.259887. Loss: 2.147265. Batch_acc: 0.303602. Batch_loss: 2.019193 \n",
      "Batch: 1639. Acc: 0.259900. Loss: 2.147211. Batch_acc: 0.281069. Batch_loss: 2.058374 \n",
      "Batch: 1640. Acc: 0.259920. Loss: 2.147119. Batch_acc: 0.292154. Batch_loss: 2.001159 \n",
      "Batch: 1641. Acc: 0.259949. Loss: 2.147052. Batch_acc: 0.308227. Batch_loss: 2.036477 \n",
      "Batch: 1642. Acc: 0.259970. Loss: 2.146992. Batch_acc: 0.293478. Batch_loss: 2.047989 \n",
      "Batch: 1643. Acc: 0.259998. Loss: 2.146930. Batch_acc: 0.307012. Batch_loss: 2.043296 \n",
      "Batch: 1644. Acc: 0.260016. Loss: 2.146863. Batch_acc: 0.289429. Batch_loss: 2.037911 \n",
      "Batch: 1645. Acc: 0.260034. Loss: 2.146793. Batch_acc: 0.288927. Batch_loss: 2.031585 \n",
      "Batch: 1646. Acc: 0.260048. Loss: 2.146734. Batch_acc: 0.282426. Batch_loss: 2.051727 \n",
      "Batch: 1647. Acc: 0.260068. Loss: 2.146674. Batch_acc: 0.293434. Batch_loss: 2.048140 \n",
      "Batch: 1648. Acc: 0.260083. Loss: 2.146618. Batch_acc: 0.285466. Batch_loss: 2.053042 \n",
      "Batch: 1649. Acc: 0.260102. Loss: 2.146561. Batch_acc: 0.291595. Batch_loss: 2.053550 \n",
      "Batch: 1650. Acc: 0.260126. Loss: 2.146491. Batch_acc: 0.300000. Batch_loss: 2.029369 \n",
      "Batch: 1651. Acc: 0.260142. Loss: 2.146430. Batch_acc: 0.287203. Batch_loss: 2.044982 \n",
      "Batch: 1652. Acc: 0.260161. Loss: 2.146376. Batch_acc: 0.291274. Batch_loss: 2.055676 \n",
      "Batch: 1653. Acc: 0.260179. Loss: 2.146309. Batch_acc: 0.291257. Batch_loss: 2.034898 \n",
      "Batch: 1654. Acc: 0.260194. Loss: 2.146257. Batch_acc: 0.282913. Batch_loss: 2.062150 \n",
      "Batch: 1655. Acc: 0.260221. Loss: 2.146187. Batch_acc: 0.304299. Batch_loss: 2.031866 \n",
      "Batch: 1656. Acc: 0.260233. Loss: 2.146139. Batch_acc: 0.280495. Batch_loss: 2.064574 \n",
      "Batch: 1657. Acc: 0.260245. Loss: 2.146089. Batch_acc: 0.281360. Batch_loss: 2.062973 \n",
      "Batch: 1658. Acc: 0.260257. Loss: 2.146039. Batch_acc: 0.280742. Batch_loss: 2.061242 \n",
      "Batch: 1659. Acc: 0.260275. Loss: 2.145960. Batch_acc: 0.287938. Batch_loss: 2.020261 \n",
      "Batch: 1660. Acc: 0.260295. Loss: 2.145888. Batch_acc: 0.293687. Batch_loss: 2.027834 \n",
      "Batch: 1661. Acc: 0.260325. Loss: 2.145811. Batch_acc: 0.309867. Batch_loss: 2.018024 \n",
      "Batch: 1662. Acc: 0.260342. Loss: 2.145759. Batch_acc: 0.289643. Batch_loss: 2.057571 \n",
      "Batch: 1663. Acc: 0.260372. Loss: 2.145684. Batch_acc: 0.311124. Batch_loss: 2.017879 \n",
      "Batch: 1664. Acc: 0.260391. Loss: 2.145645. Batch_acc: 0.293264. Batch_loss: 2.080188 \n",
      "Batch: 1665. Acc: 0.260407. Loss: 2.145579. Batch_acc: 0.285396. Batch_loss: 2.037925 \n",
      "Batch: 1666. Acc: 0.260418. Loss: 2.145522. Batch_acc: 0.278416. Batch_loss: 2.051501 \n",
      "Batch: 1667. Acc: 0.260435. Loss: 2.145450. Batch_acc: 0.290285. Batch_loss: 2.024138 \n",
      "Batch: 1668. Acc: 0.260446. Loss: 2.145386. Batch_acc: 0.279111. Batch_loss: 2.036032 \n",
      "Batch: 1669. Acc: 0.260471. Loss: 2.145311. Batch_acc: 0.301308. Batch_loss: 2.022993 \n",
      "Batch: 1670. Acc: 0.260494. Loss: 2.145249. Batch_acc: 0.298137. Batch_loss: 2.042060 \n",
      "Batch: 1671. Acc: 0.260510. Loss: 2.145208. Batch_acc: 0.288034. Batch_loss: 2.074657 \n",
      "Batch: 1672. Acc: 0.260524. Loss: 2.145159. Batch_acc: 0.284314. Batch_loss: 2.062874 \n",
      "Batch: 1673. Acc: 0.260540. Loss: 2.145105. Batch_acc: 0.286917. Batch_loss: 2.056556 \n",
      "Batch: 1674. Acc: 0.260547. Loss: 2.145064. Batch_acc: 0.271635. Batch_loss: 2.073972 \n",
      "Batch: 1675. Acc: 0.260565. Loss: 2.144995. Batch_acc: 0.291312. Batch_loss: 2.031167 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1676. Acc: 0.260567. Loss: 2.144955. Batch_acc: 0.263552. Batch_loss: 2.077501 \n",
      "Batch: 1677. Acc: 0.260593. Loss: 2.144885. Batch_acc: 0.304621. Batch_loss: 2.028078 \n",
      "Batch: 1678. Acc: 0.260615. Loss: 2.144823. Batch_acc: 0.295416. Batch_loss: 2.043595 \n",
      "Batch: 1679. Acc: 0.260626. Loss: 2.144763. Batch_acc: 0.280390. Batch_loss: 2.044287 \n",
      "Batch: 1680. Acc: 0.260642. Loss: 2.144702. Batch_acc: 0.285876. Batch_loss: 2.042371 \n",
      "Batch: 1681. Acc: 0.260648. Loss: 2.144655. Batch_acc: 0.271098. Batch_loss: 2.065454 \n",
      "Batch: 1682. Acc: 0.260660. Loss: 2.144607. Batch_acc: 0.281508. Batch_loss: 2.062216 \n",
      "Batch: 1683. Acc: 0.260676. Loss: 2.144558. Batch_acc: 0.288315. Batch_loss: 2.061256 \n",
      "Batch: 1684. Acc: 0.260695. Loss: 2.144495. Batch_acc: 0.292394. Batch_loss: 2.040497 \n",
      "Batch: 1685. Acc: 0.260715. Loss: 2.144431. Batch_acc: 0.293503. Batch_loss: 2.035215 \n",
      "Batch: 1686. Acc: 0.260733. Loss: 2.144360. Batch_acc: 0.291379. Batch_loss: 2.024571 \n",
      "Batch: 1687. Acc: 0.260755. Loss: 2.144282. Batch_acc: 0.298857. Batch_loss: 2.014449 \n",
      "Batch: 1688. Acc: 0.260772. Loss: 2.144223. Batch_acc: 0.289595. Batch_loss: 2.043139 \n",
      "Batch: 1689. Acc: 0.260784. Loss: 2.144161. Batch_acc: 0.280681. Batch_loss: 2.038487 \n",
      "Batch: 1690. Acc: 0.260804. Loss: 2.144097. Batch_acc: 0.293423. Batch_loss: 2.037500 \n",
      "Batch: 1691. Acc: 0.260827. Loss: 2.144043. Batch_acc: 0.302090. Batch_loss: 2.049214 \n",
      "Batch: 1692. Acc: 0.260845. Loss: 2.143975. Batch_acc: 0.291911. Batch_loss: 2.026696 \n",
      "Batch: 1693. Acc: 0.260859. Loss: 2.143918. Batch_acc: 0.285129. Batch_loss: 2.046299 \n",
      "Batch: 1694. Acc: 0.260876. Loss: 2.143856. Batch_acc: 0.288202. Batch_loss: 2.041508 \n",
      "Batch: 1695. Acc: 0.260897. Loss: 2.143790. Batch_acc: 0.296000. Batch_loss: 2.033277 \n",
      "Batch: 1696. Acc: 0.260915. Loss: 2.143738. Batch_acc: 0.291883. Batch_loss: 2.054333 \n",
      "Batch: 1697. Acc: 0.260930. Loss: 2.143699. Batch_acc: 0.287129. Batch_loss: 2.076703 \n",
      "Batch: 1698. Acc: 0.260946. Loss: 2.143643. Batch_acc: 0.288126. Batch_loss: 2.048202 \n",
      "Batch: 1699. Acc: 0.260967. Loss: 2.143573. Batch_acc: 0.295855. Batch_loss: 2.025157 \n",
      "Batch: 1700. Acc: 0.260984. Loss: 2.143522. Batch_acc: 0.289897. Batch_loss: 2.058621 \n",
      "Batch: 1701. Acc: 0.261005. Loss: 2.143453. Batch_acc: 0.296697. Batch_loss: 2.027139 \n",
      "Batch: 1702. Acc: 0.261012. Loss: 2.143422. Batch_acc: 0.272152. Batch_loss: 2.089987 \n",
      "Batch: 1703. Acc: 0.261028. Loss: 2.143379. Batch_acc: 0.288864. Batch_loss: 2.070983 \n",
      "Batch: 1704. Acc: 0.261047. Loss: 2.143315. Batch_acc: 0.293372. Batch_loss: 2.034590 \n",
      "Batch: 1705. Acc: 0.261066. Loss: 2.143256. Batch_acc: 0.293610. Batch_loss: 2.042362 \n",
      "Batch: 1706. Acc: 0.261088. Loss: 2.143176. Batch_acc: 0.297680. Batch_loss: 2.008696 \n",
      "Batch: 1707. Acc: 0.261100. Loss: 2.143129. Batch_acc: 0.280509. Batch_loss: 2.062428 \n",
      "Batch: 1708. Acc: 0.261130. Loss: 2.143059. Batch_acc: 0.313554. Batch_loss: 2.022771 \n",
      "Batch: 1709. Acc: 0.261143. Loss: 2.143015. Batch_acc: 0.283257. Batch_loss: 2.068205 \n",
      "Batch: 1710. Acc: 0.261167. Loss: 2.142940. Batch_acc: 0.300111. Batch_loss: 2.019882 \n",
      "Batch: 1711. Acc: 0.261184. Loss: 2.142873. Batch_acc: 0.290230. Batch_loss: 2.027599 \n",
      "Batch: 1712. Acc: 0.261197. Loss: 2.142827. Batch_acc: 0.284965. Batch_loss: 2.062881 \n",
      "Batch: 1713. Acc: 0.261220. Loss: 2.142753. Batch_acc: 0.300743. Batch_loss: 2.017192 \n",
      "Batch: 1714. Acc: 0.261235. Loss: 2.142688. Batch_acc: 0.285877. Batch_loss: 2.032209 \n",
      "Batch: 1715. Acc: 0.261257. Loss: 2.142632. Batch_acc: 0.299356. Batch_loss: 2.044492 \n",
      "Batch: 1716. Acc: 0.261277. Loss: 2.142561. Batch_acc: 0.294960. Batch_loss: 2.022550 \n",
      "Batch: 1717. Acc: 0.261298. Loss: 2.142490. Batch_acc: 0.297897. Batch_loss: 2.018328 \n",
      "Batch: 1718. Acc: 0.261318. Loss: 2.142422. Batch_acc: 0.297018. Batch_loss: 2.026504 \n",
      "Batch: 1719. Acc: 0.261343. Loss: 2.142349. Batch_acc: 0.304247. Batch_loss: 2.015104 \n",
      "Batch: 1720. Acc: 0.261360. Loss: 2.142292. Batch_acc: 0.290993. Batch_loss: 2.043654 \n",
      "Batch: 1721. Acc: 0.261380. Loss: 2.142232. Batch_acc: 0.294658. Batch_loss: 2.040093 \n",
      "Batch: 1722. Acc: 0.261388. Loss: 2.142192. Batch_acc: 0.276959. Batch_loss: 2.070357 \n",
      "Batch: 1723. Acc: 0.261406. Loss: 2.142122. Batch_acc: 0.290711. Batch_loss: 2.022037 \n",
      "Batch: 1724. Acc: 0.261417. Loss: 2.142085. Batch_acc: 0.282021. Batch_loss: 2.077229 \n",
      "Batch: 1725. Acc: 0.261437. Loss: 2.142028. Batch_acc: 0.295872. Batch_loss: 2.043433 \n",
      "Batch: 1726. Acc: 0.261447. Loss: 2.141994. Batch_acc: 0.279070. Batch_loss: 2.081078 \n",
      "Batch: 1727. Acc: 0.261470. Loss: 2.141922. Batch_acc: 0.302150. Batch_loss: 2.016766 \n",
      "Batch: 1728. Acc: 0.261492. Loss: 2.141850. Batch_acc: 0.298157. Batch_loss: 2.021142 \n",
      "Batch: 1729. Acc: 0.261507. Loss: 2.141791. Batch_acc: 0.287522. Batch_loss: 2.040065 \n",
      "Batch: 1730. Acc: 0.261527. Loss: 2.141727. Batch_acc: 0.295468. Batch_loss: 2.029255 \n",
      "Batch: 1731. Acc: 0.261547. Loss: 2.141667. Batch_acc: 0.296785. Batch_loss: 2.038319 \n",
      "Batch: 1732. Acc: 0.261565. Loss: 2.141615. Batch_acc: 0.292370. Batch_loss: 2.049119 \n",
      "Batch: 1733. Acc: 0.261578. Loss: 2.141567. Batch_acc: 0.284169. Batch_loss: 2.059207 \n",
      "Batch: 1734. Acc: 0.261604. Loss: 2.141500. Batch_acc: 0.307558. Batch_loss: 2.025097 \n",
      "Batch: 1735. Acc: 0.261625. Loss: 2.141421. Batch_acc: 0.297130. Batch_loss: 2.007060 \n",
      "Batch: 1736. Acc: 0.261646. Loss: 2.141353. Batch_acc: 0.297646. Batch_loss: 2.026200 \n",
      "Batch: 1737. Acc: 0.261674. Loss: 2.141286. Batch_acc: 0.311437. Batch_loss: 2.022818 \n",
      "Batch: 1738. Acc: 0.261694. Loss: 2.141224. Batch_acc: 0.295211. Batch_loss: 2.034970 \n",
      "Batch: 1739. Acc: 0.261711. Loss: 2.141170. Batch_acc: 0.291786. Batch_loss: 2.047483 \n",
      "Batch: 1740. Acc: 0.261725. Loss: 2.141106. Batch_acc: 0.285235. Batch_loss: 2.032823 \n",
      "Batch: 1741. Acc: 0.261744. Loss: 2.141046. Batch_acc: 0.294821. Batch_loss: 2.038615 \n",
      "Batch: 1742. Acc: 0.261760. Loss: 2.141005. Batch_acc: 0.288736. Batch_loss: 2.069170 \n",
      "Batch: 1743. Acc: 0.261779. Loss: 2.140951. Batch_acc: 0.294658. Batch_loss: 2.048245 \n",
      "Batch: 1744. Acc: 0.261800. Loss: 2.140904. Batch_acc: 0.299425. Batch_loss: 2.057923 \n",
      "Batch: 1745. Acc: 0.261812. Loss: 2.140857. Batch_acc: 0.281375. Batch_loss: 2.059364 \n",
      "Batch: 1746. Acc: 0.261830. Loss: 2.140798. Batch_acc: 0.293779. Batch_loss: 2.038022 \n",
      "Batch: 1747. Acc: 0.261850. Loss: 2.140736. Batch_acc: 0.298329. Batch_loss: 2.028228 \n",
      "Batch: 1748. Acc: 0.261866. Loss: 2.140696. Batch_acc: 0.289931. Batch_loss: 2.070036 \n",
      "Batch: 1749. Acc: 0.261893. Loss: 2.140631. Batch_acc: 0.308271. Batch_loss: 2.026961 \n",
      "Batch: 1750. Acc: 0.261910. Loss: 2.140563. Batch_acc: 0.292935. Batch_loss: 2.022280 \n",
      "Batch: 1751. Acc: 0.261925. Loss: 2.140512. Batch_acc: 0.287648. Batch_loss: 2.053075 \n",
      "Batch: 1752. Acc: 0.261942. Loss: 2.140459. Batch_acc: 0.291908. Batch_loss: 2.046725 \n",
      "Batch: 1753. Acc: 0.261969. Loss: 2.140376. Batch_acc: 0.308305. Batch_loss: 1.997305 \n",
      "Batch: 1754. Acc: 0.261981. Loss: 2.140329. Batch_acc: 0.282964. Batch_loss: 2.056298 \n",
      "Batch: 1755. Acc: 0.262000. Loss: 2.140259. Batch_acc: 0.294761. Batch_loss: 2.017326 \n",
      "Batch: 1756. Acc: 0.262014. Loss: 2.140201. Batch_acc: 0.287522. Batch_loss: 2.037693 \n",
      "Batch: 1757. Acc: 0.262027. Loss: 2.140179. Batch_acc: 0.284887. Batch_loss: 2.101802 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.26202697058218904. Loss per char: 2.140179023413563. Time: 1627203933.8580718\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 21, 19,  1, 77, 70, 84, 84,  1,\n",
      "        85, 73, 66, 79,  1, 14, 18, 24, 26, 20, 17, 22, 18, 20, 25, 21, 23, 32,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.262039. Loss: 2.140143. Batch_acc: 0.283154. Batch_loss: 2.074979 \n",
      "Batch: 1759. Acc: 0.262048. Loss: 2.140102. Batch_acc: 0.278256. Batch_loss: 2.066863 \n",
      "Batch: 1760. Acc: 0.262058. Loss: 2.140052. Batch_acc: 0.279310. Batch_loss: 2.053499 \n",
      "Batch: 1761. Acc: 0.262069. Loss: 2.139993. Batch_acc: 0.281214. Batch_loss: 2.036843 \n",
      "Batch: 1762. Acc: 0.262085. Loss: 2.139945. Batch_acc: 0.290230. Batch_loss: 2.053890 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1763. Acc: 0.262095. Loss: 2.139912. Batch_acc: 0.281340. Batch_loss: 2.082552 \n",
      "Batch: 1764. Acc: 0.262118. Loss: 2.139854. Batch_acc: 0.302907. Batch_loss: 2.036762 \n",
      "Batch: 1765. Acc: 0.262139. Loss: 2.139791. Batch_acc: 0.298686. Batch_loss: 2.028980 \n",
      "Batch: 1766. Acc: 0.262162. Loss: 2.139735. Batch_acc: 0.302800. Batch_loss: 2.039571 \n",
      "Batch: 1767. Acc: 0.262183. Loss: 2.139663. Batch_acc: 0.298844. Batch_loss: 2.011180 \n",
      "Batch: 1768. Acc: 0.262199. Loss: 2.139604. Batch_acc: 0.290837. Batch_loss: 2.036392 \n",
      "Batch: 1769. Acc: 0.262211. Loss: 2.139551. Batch_acc: 0.284211. Batch_loss: 2.045485 \n",
      "Batch: 1770. Acc: 0.262241. Loss: 2.139473. Batch_acc: 0.313960. Batch_loss: 2.002281 \n",
      "Batch: 1771. Acc: 0.262253. Loss: 2.139422. Batch_acc: 0.284558. Batch_loss: 2.047710 \n",
      "Batch: 1772. Acc: 0.262272. Loss: 2.139353. Batch_acc: 0.296060. Batch_loss: 2.017992 \n",
      "Batch: 1773. Acc: 0.262288. Loss: 2.139300. Batch_acc: 0.290102. Batch_loss: 2.046221 \n",
      "Batch: 1774. Acc: 0.262310. Loss: 2.139239. Batch_acc: 0.300459. Batch_loss: 2.031245 \n",
      "Batch: 1775. Acc: 0.262327. Loss: 2.139172. Batch_acc: 0.292752. Batch_loss: 2.021797 \n",
      "Batch: 1776. Acc: 0.262343. Loss: 2.139115. Batch_acc: 0.291933. Batch_loss: 2.036792 \n",
      "Batch: 1777. Acc: 0.262361. Loss: 2.139060. Batch_acc: 0.292641. Batch_loss: 2.041477 \n",
      "Batch: 1778. Acc: 0.262377. Loss: 2.138975. Batch_acc: 0.291361. Batch_loss: 1.992164 \n",
      "Batch: 1779. Acc: 0.262397. Loss: 2.138899. Batch_acc: 0.298055. Batch_loss: 2.003508 \n",
      "Batch: 1780. Acc: 0.262399. Loss: 2.138867. Batch_acc: 0.265815. Batch_loss: 2.082020 \n",
      "Batch: 1781. Acc: 0.262420. Loss: 2.138816. Batch_acc: 0.299374. Batch_loss: 2.049442 \n",
      "Batch: 1782. Acc: 0.262429. Loss: 2.138768. Batch_acc: 0.277650. Batch_loss: 2.051919 \n",
      "Batch: 1783. Acc: 0.262447. Loss: 2.138718. Batch_acc: 0.295481. Batch_loss: 2.050152 \n",
      "Batch: 1784. Acc: 0.262469. Loss: 2.138660. Batch_acc: 0.302339. Batch_loss: 2.032424 \n",
      "Batch: 1785. Acc: 0.262477. Loss: 2.138617. Batch_acc: 0.277164. Batch_loss: 2.061570 \n",
      "Batch: 1786. Acc: 0.262490. Loss: 2.138562. Batch_acc: 0.284264. Batch_loss: 2.042515 \n",
      "Batch: 1787. Acc: 0.262493. Loss: 2.138531. Batch_acc: 0.267541. Batch_loss: 2.082927 \n",
      "Batch: 1788. Acc: 0.262501. Loss: 2.138503. Batch_acc: 0.277745. Batch_loss: 2.086968 \n",
      "Batch: 1789. Acc: 0.262512. Loss: 2.138480. Batch_acc: 0.282037. Batch_loss: 2.097679 \n",
      "Batch: 1790. Acc: 0.262529. Loss: 2.138443. Batch_acc: 0.293632. Batch_loss: 2.070836 \n",
      "Batch: 1791. Acc: 0.262553. Loss: 2.138379. Batch_acc: 0.304471. Batch_loss: 2.025876 \n",
      "Batch: 1792. Acc: 0.262572. Loss: 2.138317. Batch_acc: 0.296840. Batch_loss: 2.029217 \n",
      "Batch: 1793. Acc: 0.262572. Loss: 2.138302. Batch_acc: 0.262736. Batch_loss: 2.111482 \n",
      "Batch: 1794. Acc: 0.262593. Loss: 2.138248. Batch_acc: 0.300695. Batch_loss: 2.040950 \n",
      "Batch: 1795. Acc: 0.262614. Loss: 2.138194. Batch_acc: 0.300175. Batch_loss: 2.040636 \n",
      "Batch: 1796. Acc: 0.262627. Loss: 2.138144. Batch_acc: 0.286722. Batch_loss: 2.047145 \n",
      "Batch: 1797. Acc: 0.262643. Loss: 2.138087. Batch_acc: 0.291023. Batch_loss: 2.034744 \n",
      "Batch: 1798. Acc: 0.262665. Loss: 2.138020. Batch_acc: 0.301930. Batch_loss: 2.020007 \n",
      "Batch: 1799. Acc: 0.262687. Loss: 2.137952. Batch_acc: 0.300456. Batch_loss: 2.015908 \n",
      "Batch: 1800. Acc: 0.262704. Loss: 2.137897. Batch_acc: 0.293710. Batch_loss: 2.039295 \n",
      "Batch: 1801. Acc: 0.262719. Loss: 2.137844. Batch_acc: 0.290560. Batch_loss: 2.043712 \n",
      "Batch: 1802. Acc: 0.262736. Loss: 2.137790. Batch_acc: 0.293911. Batch_loss: 2.038872 \n",
      "Batch: 1803. Acc: 0.262755. Loss: 2.137725. Batch_acc: 0.295544. Batch_loss: 2.023242 \n",
      "Batch: 1804. Acc: 0.262772. Loss: 2.137662. Batch_acc: 0.292599. Batch_loss: 2.023771 \n",
      "Batch: 1805. Acc: 0.262792. Loss: 2.137599. Batch_acc: 0.301063. Batch_loss: 2.022348 \n",
      "Batch: 1806. Acc: 0.262808. Loss: 2.137538. Batch_acc: 0.290878. Batch_loss: 2.027755 \n",
      "Batch: 1807. Acc: 0.262817. Loss: 2.137493. Batch_acc: 0.279656. Batch_loss: 2.055505 \n",
      "Batch: 1808. Acc: 0.262832. Loss: 2.137436. Batch_acc: 0.289838. Batch_loss: 2.034941 \n",
      "Batch: 1809. Acc: 0.262856. Loss: 2.137366. Batch_acc: 0.306845. Batch_loss: 2.008712 \n",
      "Batch: 1810. Acc: 0.262869. Loss: 2.137301. Batch_acc: 0.284994. Batch_loss: 2.022960 \n",
      "Batch: 1811. Acc: 0.262887. Loss: 2.137252. Batch_acc: 0.295982. Batch_loss: 2.049577 \n",
      "Batch: 1812. Acc: 0.262901. Loss: 2.137207. Batch_acc: 0.287744. Batch_loss: 2.053384 \n",
      "Batch: 1813. Acc: 0.262916. Loss: 2.137165. Batch_acc: 0.290677. Batch_loss: 2.060289 \n",
      "Batch: 1814. Acc: 0.262939. Loss: 2.137115. Batch_acc: 0.306122. Batch_loss: 2.045999 \n",
      "Batch: 1815. Acc: 0.262957. Loss: 2.137071. Batch_acc: 0.294842. Batch_loss: 2.055918 \n",
      "Batch: 1816. Acc: 0.262970. Loss: 2.137019. Batch_acc: 0.287522. Batch_loss: 2.042339 \n",
      "Batch: 1817. Acc: 0.262979. Loss: 2.136997. Batch_acc: 0.279621. Batch_loss: 2.095270 \n",
      "Batch: 1818. Acc: 0.262997. Loss: 2.136943. Batch_acc: 0.295493. Batch_loss: 2.041070 \n",
      "Batch: 1819. Acc: 0.263010. Loss: 2.136899. Batch_acc: 0.287026. Batch_loss: 2.057143 \n",
      "Batch: 1820. Acc: 0.263033. Loss: 2.136847. Batch_acc: 0.304822. Batch_loss: 2.042204 \n",
      "Batch: 1821. Acc: 0.263052. Loss: 2.136784. Batch_acc: 0.295735. Batch_loss: 2.024386 \n",
      "Batch: 1822. Acc: 0.263068. Loss: 2.136736. Batch_acc: 0.292497. Batch_loss: 2.046839 \n",
      "Batch: 1823. Acc: 0.263088. Loss: 2.136672. Batch_acc: 0.300400. Batch_loss: 2.022296 \n",
      "Batch: 1824. Acc: 0.263102. Loss: 2.136635. Batch_acc: 0.287774. Batch_loss: 2.069016 \n",
      "Batch: 1825. Acc: 0.263117. Loss: 2.136585. Batch_acc: 0.291811. Batch_loss: 2.045101 \n",
      "Batch: 1826. Acc: 0.263133. Loss: 2.136530. Batch_acc: 0.291472. Batch_loss: 2.034152 \n",
      "Batch: 1827. Acc: 0.263153. Loss: 2.136469. Batch_acc: 0.299253. Batch_loss: 2.025246 \n",
      "Batch: 1828. Acc: 0.263161. Loss: 2.136416. Batch_acc: 0.278127. Batch_loss: 2.040239 \n",
      "Batch: 1829. Acc: 0.263177. Loss: 2.136373. Batch_acc: 0.293215. Batch_loss: 2.056152 \n",
      "Batch: 1830. Acc: 0.263191. Loss: 2.136319. Batch_acc: 0.289233. Batch_loss: 2.037522 \n",
      "Batch: 1831. Acc: 0.263208. Loss: 2.136267. Batch_acc: 0.294118. Batch_loss: 2.040313 \n",
      "Batch: 1832. Acc: 0.263219. Loss: 2.136211. Batch_acc: 0.282755. Batch_loss: 2.035834 \n",
      "Batch: 1833. Acc: 0.263231. Loss: 2.136156. Batch_acc: 0.286129. Batch_loss: 2.035279 \n",
      "Batch: 1834. Acc: 0.263254. Loss: 2.136100. Batch_acc: 0.305572. Batch_loss: 2.032981 \n",
      "Batch: 1835. Acc: 0.263272. Loss: 2.136038. Batch_acc: 0.295687. Batch_loss: 2.024421 \n",
      "Batch: 1836. Acc: 0.263294. Loss: 2.135977. Batch_acc: 0.303377. Batch_loss: 2.024092 \n",
      "Batch: 1837. Acc: 0.263302. Loss: 2.135944. Batch_acc: 0.278226. Batch_loss: 2.075966 \n",
      "Batch: 1838. Acc: 0.263321. Loss: 2.135896. Batch_acc: 0.297727. Batch_loss: 2.047966 \n",
      "Batch: 1839. Acc: 0.263335. Loss: 2.135853. Batch_acc: 0.288978. Batch_loss: 2.057898 \n",
      "Batch: 1840. Acc: 0.263344. Loss: 2.135823. Batch_acc: 0.279489. Batch_loss: 2.080387 \n",
      "Batch: 1841. Acc: 0.263365. Loss: 2.135755. Batch_acc: 0.302817. Batch_loss: 2.007174 \n",
      "Batch: 1842. Acc: 0.263384. Loss: 2.135700. Batch_acc: 0.298378. Batch_loss: 2.034341 \n",
      "Batch: 1843. Acc: 0.263402. Loss: 2.135639. Batch_acc: 0.296275. Batch_loss: 2.022915 \n",
      "Batch: 1844. Acc: 0.263424. Loss: 2.135585. Batch_acc: 0.303704. Batch_loss: 2.037595 \n",
      "Batch: 1845. Acc: 0.263442. Loss: 2.135527. Batch_acc: 0.296634. Batch_loss: 2.029071 \n",
      "Batch: 1846. Acc: 0.263459. Loss: 2.135468. Batch_acc: 0.295702. Batch_loss: 2.027647 \n",
      "Batch: 1847. Acc: 0.263482. Loss: 2.135404. Batch_acc: 0.303165. Batch_loss: 2.020610 \n",
      "Batch: 1848. Acc: 0.263494. Loss: 2.135359. Batch_acc: 0.285883. Batch_loss: 2.050294 \n",
      "Batch: 1849. Acc: 0.263522. Loss: 2.135288. Batch_acc: 0.315248. Batch_loss: 2.004614 \n",
      "Batch: 1850. Acc: 0.263535. Loss: 2.135224. Batch_acc: 0.287774. Batch_loss: 2.017488 \n",
      "Batch: 1851. Acc: 0.263558. Loss: 2.135162. Batch_acc: 0.306146. Batch_loss: 2.019417 \n",
      "Batch: 1852. Acc: 0.263578. Loss: 2.135101. Batch_acc: 0.299377. Batch_loss: 2.024951 \n",
      "Batch: 1853. Acc: 0.263597. Loss: 2.135035. Batch_acc: 0.299770. Batch_loss: 2.013059 \n",
      "Batch: 1854. Acc: 0.263612. Loss: 2.134975. Batch_acc: 0.291883. Batch_loss: 2.023023 \n",
      "Batch: 1855. Acc: 0.263626. Loss: 2.134921. Batch_acc: 0.288712. Batch_loss: 2.035904 \n",
      "Batch: 1856. Acc: 0.263648. Loss: 2.134855. Batch_acc: 0.303531. Batch_loss: 2.014047 \n",
      "Batch: 1857. Acc: 0.263667. Loss: 2.134807. Batch_acc: 0.299071. Batch_loss: 2.044531 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1858. Acc: 0.263690. Loss: 2.134732. Batch_acc: 0.305804. Batch_loss: 1.999654 \n",
      "Batch: 1859. Acc: 0.263710. Loss: 2.134669. Batch_acc: 0.301876. Batch_loss: 2.014503 \n",
      "Batch: 1860. Acc: 0.263726. Loss: 2.134606. Batch_acc: 0.292186. Batch_loss: 2.019656 \n",
      "Batch: 1861. Acc: 0.263735. Loss: 2.134555. Batch_acc: 0.281214. Batch_loss: 2.039647 \n",
      "Batch: 1862. Acc: 0.263743. Loss: 2.134491. Batch_acc: 0.279676. Batch_loss: 2.014335 \n",
      "Batch: 1863. Acc: 0.263750. Loss: 2.134451. Batch_acc: 0.275463. Batch_loss: 2.059072 \n",
      "Batch: 1864. Acc: 0.263761. Loss: 2.134412. Batch_acc: 0.284890. Batch_loss: 2.060811 \n",
      "Batch: 1865. Acc: 0.263765. Loss: 2.134365. Batch_acc: 0.271795. Batch_loss: 2.047954 \n",
      "Batch: 1866. Acc: 0.263784. Loss: 2.134295. Batch_acc: 0.297024. Batch_loss: 2.006554 \n",
      "Batch: 1867. Acc: 0.263793. Loss: 2.134243. Batch_acc: 0.281891. Batch_loss: 2.039253 \n",
      "Batch: 1868. Acc: 0.263802. Loss: 2.134198. Batch_acc: 0.279029. Batch_loss: 2.048952 \n",
      "Batch: 1869. Acc: 0.263821. Loss: 2.134141. Batch_acc: 0.299370. Batch_loss: 2.027891 \n",
      "Batch: 1870. Acc: 0.263834. Loss: 2.134085. Batch_acc: 0.287754. Batch_loss: 2.034511 \n",
      "Batch: 1871. Acc: 0.263843. Loss: 2.134037. Batch_acc: 0.280899. Batch_loss: 2.042504 \n",
      "Batch: 1872. Acc: 0.263860. Loss: 2.133966. Batch_acc: 0.296149. Batch_loss: 2.002951 \n",
      "Batch: 1873. Acc: 0.263886. Loss: 2.133895. Batch_acc: 0.311098. Batch_loss: 2.000435 \n",
      "Batch: 1874. Acc: 0.263899. Loss: 2.133852. Batch_acc: 0.290018. Batch_loss: 2.051753 \n",
      "Batch: 1875. Acc: 0.263919. Loss: 2.133792. Batch_acc: 0.299885. Batch_loss: 2.021115 \n",
      "Batch: 1876. Acc: 0.263938. Loss: 2.133734. Batch_acc: 0.299885. Batch_loss: 2.024248 \n",
      "Batch: 1877. Acc: 0.263951. Loss: 2.133673. Batch_acc: 0.289323. Batch_loss: 2.019391 \n",
      "Batch: 1878. Acc: 0.263966. Loss: 2.133624. Batch_acc: 0.292404. Batch_loss: 2.043145 \n",
      "Batch: 1879. Acc: 0.263980. Loss: 2.133573. Batch_acc: 0.288483. Batch_loss: 2.038444 \n",
      "Batch: 1880. Acc: 0.263991. Loss: 2.133523. Batch_acc: 0.285795. Batch_loss: 2.040499 \n",
      "Batch: 1881. Acc: 0.264011. Loss: 2.133468. Batch_acc: 0.301183. Batch_loss: 2.028645 \n",
      "Batch: 1882. Acc: 0.264028. Loss: 2.133409. Batch_acc: 0.296512. Batch_loss: 2.021158 \n",
      "Batch: 1883. Acc: 0.264039. Loss: 2.133360. Batch_acc: 0.284880. Batch_loss: 2.039217 \n",
      "Batch: 1884. Acc: 0.264063. Loss: 2.133282. Batch_acc: 0.308385. Batch_loss: 1.988839 \n",
      "Batch: 1885. Acc: 0.264075. Loss: 2.133224. Batch_acc: 0.287711. Batch_loss: 2.023577 \n",
      "Batch: 1886. Acc: 0.264090. Loss: 2.133171. Batch_acc: 0.291667. Batch_loss: 2.034270 \n",
      "Batch: 1887. Acc: 0.264109. Loss: 2.133123. Batch_acc: 0.299552. Batch_loss: 2.043388 \n",
      "Batch: 1888. Acc: 0.264125. Loss: 2.133072. Batch_acc: 0.294493. Batch_loss: 2.036422 \n",
      "Batch: 1889. Acc: 0.264136. Loss: 2.133033. Batch_acc: 0.285143. Batch_loss: 2.059997 \n",
      "Batch: 1890. Acc: 0.264145. Loss: 2.132994. Batch_acc: 0.280530. Batch_loss: 2.059978 \n",
      "Batch: 1891. Acc: 0.264164. Loss: 2.132932. Batch_acc: 0.300113. Batch_loss: 2.018022 \n",
      "Batch: 1892. Acc: 0.264186. Loss: 2.132883. Batch_acc: 0.306086. Batch_loss: 2.037158 \n",
      "Batch: 1893. Acc: 0.264200. Loss: 2.132826. Batch_acc: 0.291860. Batch_loss: 2.023466 \n",
      "Batch: 1894. Acc: 0.264226. Loss: 2.132754. Batch_acc: 0.312681. Batch_loss: 1.995292 \n",
      "Batch: 1895. Acc: 0.264237. Loss: 2.132696. Batch_acc: 0.287053. Batch_loss: 2.021706 \n",
      "Batch: 1896. Acc: 0.264256. Loss: 2.132637. Batch_acc: 0.299125. Batch_loss: 2.017610 \n",
      "Batch: 1897. Acc: 0.264269. Loss: 2.132591. Batch_acc: 0.289458. Batch_loss: 2.045420 \n",
      "Batch: 1898. Acc: 0.264284. Loss: 2.132540. Batch_acc: 0.293478. Batch_loss: 2.036501 \n",
      "Batch: 1899. Acc: 0.264291. Loss: 2.132496. Batch_acc: 0.277453. Batch_loss: 2.047301 \n",
      "Batch: 1900. Acc: 0.264306. Loss: 2.132441. Batch_acc: 0.292193. Batch_loss: 2.028804 \n",
      "Batch: 1901. Acc: 0.264328. Loss: 2.132376. Batch_acc: 0.308745. Batch_loss: 2.004092 \n",
      "Batch: 1902. Acc: 0.264346. Loss: 2.132303. Batch_acc: 0.298165. Batch_loss: 1.992864 \n",
      "Batch: 1903. Acc: 0.264366. Loss: 2.132233. Batch_acc: 0.301308. Batch_loss: 2.000792 \n",
      "Batch: 1904. Acc: 0.264378. Loss: 2.132191. Batch_acc: 0.288372. Batch_loss: 2.051732 \n",
      "Batch: 1905. Acc: 0.264396. Loss: 2.132125. Batch_acc: 0.296973. Batch_loss: 2.007298 \n",
      "Batch: 1906. Acc: 0.264406. Loss: 2.132100. Batch_acc: 0.285052. Batch_loss: 2.084094 \n",
      "Batch: 1907. Acc: 0.264425. Loss: 2.132044. Batch_acc: 0.300398. Batch_loss: 2.026711 \n",
      "Batch: 1908. Acc: 0.264446. Loss: 2.131988. Batch_acc: 0.304323. Batch_loss: 2.024595 \n",
      "Batch: 1909. Acc: 0.264454. Loss: 2.131934. Batch_acc: 0.278975. Batch_loss: 2.028555 \n",
      "Batch: 1910. Acc: 0.264471. Loss: 2.131880. Batch_acc: 0.295720. Batch_loss: 2.033028 \n",
      "Batch: 1911. Acc: 0.264487. Loss: 2.131815. Batch_acc: 0.294761. Batch_loss: 2.006945 \n",
      "Batch: 1912. Acc: 0.264503. Loss: 2.131762. Batch_acc: 0.296018. Batch_loss: 2.029850 \n",
      "Batch: 1913. Acc: 0.264515. Loss: 2.131726. Batch_acc: 0.287376. Batch_loss: 2.061118 \n",
      "Batch: 1914. Acc: 0.264539. Loss: 2.131651. Batch_acc: 0.310246. Batch_loss: 1.989159 \n",
      "Batch: 1915. Acc: 0.264562. Loss: 2.131592. Batch_acc: 0.309091. Batch_loss: 2.021074 \n",
      "Batch: 1916. Acc: 0.264579. Loss: 2.131538. Batch_acc: 0.295672. Batch_loss: 2.029514 \n",
      "Batch: 1917. Acc: 0.264595. Loss: 2.131483. Batch_acc: 0.296231. Batch_loss: 2.023730 \n",
      "Batch: 1918. Acc: 0.264620. Loss: 2.131409. Batch_acc: 0.310500. Batch_loss: 1.992653 \n",
      "Batch: 1919. Acc: 0.264633. Loss: 2.131350. Batch_acc: 0.290058. Batch_loss: 2.016423 \n",
      "Batch: 1920. Acc: 0.264652. Loss: 2.131280. Batch_acc: 0.302179. Batch_loss: 1.997760 \n",
      "Batch: 1921. Acc: 0.264669. Loss: 2.131221. Batch_acc: 0.295767. Batch_loss: 2.018486 \n",
      "Batch: 1922. Acc: 0.264689. Loss: 2.131160. Batch_acc: 0.302558. Batch_loss: 2.018062 \n",
      "Batch: 1923. Acc: 0.264699. Loss: 2.131117. Batch_acc: 0.283496. Batch_loss: 2.048813 \n",
      "Batch: 1924. Acc: 0.264722. Loss: 2.131045. Batch_acc: 0.309456. Batch_loss: 1.993459 \n",
      "Batch: 1925. Acc: 0.264734. Loss: 2.131001. Batch_acc: 0.287879. Batch_loss: 2.044859 \n",
      "Batch: 1926. Acc: 0.264750. Loss: 2.130946. Batch_acc: 0.295255. Batch_loss: 2.023541 \n",
      "Batch: 1927. Acc: 0.264773. Loss: 2.130871. Batch_acc: 0.309348. Batch_loss: 1.987853 \n",
      "Batch: 1928. Acc: 0.264789. Loss: 2.130824. Batch_acc: 0.296640. Batch_loss: 2.040194 \n",
      "Batch: 1929. Acc: 0.264811. Loss: 2.130764. Batch_acc: 0.307073. Batch_loss: 2.014092 \n",
      "Batch: 1930. Acc: 0.264824. Loss: 2.130704. Batch_acc: 0.289611. Batch_loss: 2.014024 \n",
      "Batch: 1931. Acc: 0.264841. Loss: 2.130650. Batch_acc: 0.296255. Batch_loss: 2.029836 \n",
      "Batch: 1932. Acc: 0.264860. Loss: 2.130604. Batch_acc: 0.303013. Batch_loss: 2.041329 \n",
      "Batch: 1933. Acc: 0.264878. Loss: 2.130541. Batch_acc: 0.298305. Batch_loss: 2.010992 \n",
      "Batch: 1934. Acc: 0.264889. Loss: 2.130493. Batch_acc: 0.285550. Batch_loss: 2.037287 \n",
      "Batch: 1935. Acc: 0.264904. Loss: 2.130431. Batch_acc: 0.293583. Batch_loss: 2.012226 \n",
      "Batch: 1936. Acc: 0.264917. Loss: 2.130375. Batch_acc: 0.289280. Batch_loss: 2.023701 \n",
      "Batch: 1937. Acc: 0.264930. Loss: 2.130335. Batch_acc: 0.292014. Batch_loss: 2.049410 \n",
      "Batch: 1938. Acc: 0.264936. Loss: 2.130288. Batch_acc: 0.275782. Batch_loss: 2.038290 \n",
      "Batch: 1939. Acc: 0.264957. Loss: 2.130216. Batch_acc: 0.305085. Batch_loss: 1.994148 \n",
      "Batch: 1940. Acc: 0.264973. Loss: 2.130146. Batch_acc: 0.296210. Batch_loss: 1.991617 \n",
      "Batch: 1941. Acc: 0.264993. Loss: 2.130092. Batch_acc: 0.304046. Batch_loss: 2.025420 \n",
      "Batch: 1942. Acc: 0.265006. Loss: 2.130059. Batch_acc: 0.290784. Batch_loss: 2.065497 \n",
      "Batch: 1943. Acc: 0.265020. Loss: 2.130019. Batch_acc: 0.292326. Batch_loss: 2.051236 \n",
      "Batch: 1944. Acc: 0.265028. Loss: 2.129985. Batch_acc: 0.280763. Batch_loss: 2.063961 \n",
      "Batch: 1945. Acc: 0.265039. Loss: 2.129937. Batch_acc: 0.286385. Batch_loss: 2.034499 \n",
      "Batch: 1946. Acc: 0.265045. Loss: 2.129896. Batch_acc: 0.277171. Batch_loss: 2.049717 \n",
      "Batch: 1947. Acc: 0.265067. Loss: 2.129841. Batch_acc: 0.307082. Batch_loss: 2.025851 \n",
      "Batch: 1948. Acc: 0.265077. Loss: 2.129798. Batch_acc: 0.284959. Batch_loss: 2.043594 \n",
      "Batch: 1949. Acc: 0.265080. Loss: 2.129763. Batch_acc: 0.271619. Batch_loss: 2.060722 \n",
      "Batch: 1950. Acc: 0.265091. Loss: 2.129700. Batch_acc: 0.286474. Batch_loss: 2.004229 \n",
      "Batch: 1951. Acc: 0.265108. Loss: 2.129648. Batch_acc: 0.299408. Batch_loss: 2.025157 \n",
      "Batch: 1952. Acc: 0.265125. Loss: 2.129588. Batch_acc: 0.299190. Batch_loss: 2.012192 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1953. Acc: 0.265149. Loss: 2.129531. Batch_acc: 0.310443. Batch_loss: 2.019970 \n",
      "Batch: 1954. Acc: 0.265167. Loss: 2.129472. Batch_acc: 0.301974. Batch_loss: 2.012969 \n",
      "Batch: 1955. Acc: 0.265185. Loss: 2.129417. Batch_acc: 0.300114. Batch_loss: 2.023098 \n",
      "Batch: 1956. Acc: 0.265201. Loss: 2.129365. Batch_acc: 0.295000. Batch_loss: 2.030798 \n",
      "Batch: 1957. Acc: 0.265220. Loss: 2.129304. Batch_acc: 0.300998. Batch_loss: 2.013698 \n",
      "Batch: 1958. Acc: 0.265226. Loss: 2.129270. Batch_acc: 0.275984. Batch_loss: 2.060921 \n",
      "Batch: 1959. Acc: 0.265238. Loss: 2.129222. Batch_acc: 0.289655. Batch_loss: 2.035285 \n",
      "Batch: 1960. Acc: 0.265250. Loss: 2.129179. Batch_acc: 0.289367. Batch_loss: 2.045143 \n",
      "Batch: 1961. Acc: 0.265266. Loss: 2.129128. Batch_acc: 0.297173. Batch_loss: 2.029604 \n",
      "Batch: 1962. Acc: 0.265275. Loss: 2.129079. Batch_acc: 0.283175. Batch_loss: 2.029341 \n",
      "Batch: 1963. Acc: 0.265289. Loss: 2.129015. Batch_acc: 0.292076. Batch_loss: 2.002287 \n",
      "Batch: 1964. Acc: 0.265301. Loss: 2.128963. Batch_acc: 0.288606. Batch_loss: 2.025806 \n",
      "Batch: 1965. Acc: 0.265320. Loss: 2.128895. Batch_acc: 0.302326. Batch_loss: 1.997987 \n",
      "Batch: 1966. Acc: 0.265331. Loss: 2.128854. Batch_acc: 0.287711. Batch_loss: 2.046425 \n",
      "Batch: 1967. Acc: 0.265348. Loss: 2.128808. Batch_acc: 0.299308. Batch_loss: 2.038565 \n",
      "Batch: 1968. Acc: 0.265365. Loss: 2.128761. Batch_acc: 0.298044. Batch_loss: 2.036258 \n",
      "Batch: 1969. Acc: 0.265383. Loss: 2.128710. Batch_acc: 0.301779. Batch_loss: 2.028010 \n",
      "Batch: 1970. Acc: 0.265398. Loss: 2.128658. Batch_acc: 0.294638. Batch_loss: 2.024964 \n",
      "Batch: 1971. Acc: 0.265405. Loss: 2.128614. Batch_acc: 0.279083. Batch_loss: 2.041299 \n",
      "Batch: 1972. Acc: 0.265417. Loss: 2.128575. Batch_acc: 0.289354. Batch_loss: 2.053388 \n",
      "Batch: 1973. Acc: 0.265434. Loss: 2.128512. Batch_acc: 0.298144. Batch_loss: 2.003287 \n",
      "Batch: 1974. Acc: 0.265448. Loss: 2.128472. Batch_acc: 0.293919. Batch_loss: 2.051591 \n",
      "Batch: 1975. Acc: 0.265467. Loss: 2.128425. Batch_acc: 0.301446. Batch_loss: 2.038092 \n",
      "Batch: 1976. Acc: 0.265486. Loss: 2.128378. Batch_acc: 0.302220. Batch_loss: 2.037484 \n",
      "Batch: 1977. Acc: 0.265501. Loss: 2.128330. Batch_acc: 0.294689. Batch_loss: 2.033676 \n",
      "Batch: 1978. Acc: 0.265512. Loss: 2.128309. Batch_acc: 0.287655. Batch_loss: 2.085695 \n",
      "Batch: 1979. Acc: 0.265522. Loss: 2.128262. Batch_acc: 0.285471. Batch_loss: 2.037327 \n",
      "Batch: 1980. Acc: 0.265541. Loss: 2.128212. Batch_acc: 0.303288. Batch_loss: 2.029461 \n",
      "Batch: 1981. Acc: 0.265548. Loss: 2.128183. Batch_acc: 0.279258. Batch_loss: 2.071571 \n",
      "Batch: 1982. Acc: 0.265566. Loss: 2.128151. Batch_acc: 0.301107. Batch_loss: 2.064022 \n",
      "Batch: 1983. Acc: 0.265579. Loss: 2.128101. Batch_acc: 0.291251. Batch_loss: 2.025253 \n",
      "Batch: 1984. Acc: 0.265601. Loss: 2.128039. Batch_acc: 0.309510. Batch_loss: 2.005584 \n",
      "Batch: 1985. Acc: 0.265616. Loss: 2.127988. Batch_acc: 0.295667. Batch_loss: 2.025720 \n",
      "Batch: 1986. Acc: 0.265623. Loss: 2.127944. Batch_acc: 0.280023. Batch_loss: 2.037343 \n",
      "Batch: 1987. Acc: 0.265642. Loss: 2.127884. Batch_acc: 0.302727. Batch_loss: 2.013650 \n",
      "Batch: 1988. Acc: 0.265659. Loss: 2.127830. Batch_acc: 0.297740. Batch_loss: 2.022659 \n",
      "Batch: 1989. Acc: 0.265672. Loss: 2.127774. Batch_acc: 0.293154. Batch_loss: 2.014920 \n",
      "Batch: 1990. Acc: 0.265684. Loss: 2.127729. Batch_acc: 0.289906. Batch_loss: 2.035267 \n",
      "Batch: 1991. Acc: 0.265697. Loss: 2.127688. Batch_acc: 0.291406. Batch_loss: 2.047257 \n",
      "Batch: 1992. Acc: 0.265708. Loss: 2.127649. Batch_acc: 0.287861. Batch_loss: 2.049036 \n",
      "Batch: 1993. Acc: 0.265727. Loss: 2.127595. Batch_acc: 0.303409. Batch_loss: 2.022056 \n",
      "Batch: 1994. Acc: 0.265740. Loss: 2.127546. Batch_acc: 0.291883. Batch_loss: 2.028947 \n",
      "Batch: 1995. Acc: 0.265755. Loss: 2.127493. Batch_acc: 0.294675. Batch_loss: 2.019601 \n",
      "Batch: 1996. Acc: 0.265768. Loss: 2.127444. Batch_acc: 0.292486. Batch_loss: 2.029164 \n",
      "Batch: 1997. Acc: 0.265789. Loss: 2.127384. Batch_acc: 0.307131. Batch_loss: 2.010429 \n",
      "Batch: 1998. Acc: 0.265805. Loss: 2.127337. Batch_acc: 0.297251. Batch_loss: 2.033684 \n",
      "Batch: 1999. Acc: 0.265818. Loss: 2.127294. Batch_acc: 0.291475. Batch_loss: 2.040411 \n",
      "Batch: 2000. Acc: 0.265833. Loss: 2.127247. Batch_acc: 0.295995. Batch_loss: 2.033875 \n",
      "Batch: 2001. Acc: 0.265856. Loss: 2.127186. Batch_acc: 0.310229. Batch_loss: 2.009039 \n",
      "Batch: 2002. Acc: 0.265872. Loss: 2.127121. Batch_acc: 0.298798. Batch_loss: 1.997574 \n",
      "Batch: 2003. Acc: 0.265896. Loss: 2.127063. Batch_acc: 0.314021. Batch_loss: 2.008984 \n",
      "Batch: 2004. Acc: 0.265904. Loss: 2.127021. Batch_acc: 0.282521. Batch_loss: 2.044462 \n",
      "Batch: 2005. Acc: 0.265922. Loss: 2.126961. Batch_acc: 0.300743. Batch_loss: 2.007433 \n",
      "Batch: 2006. Acc: 0.265933. Loss: 2.126926. Batch_acc: 0.287679. Batch_loss: 2.056677 \n",
      "Batch: 2007. Acc: 0.265946. Loss: 2.126876. Batch_acc: 0.293212. Batch_loss: 2.026042 \n",
      "Batch: 2008. Acc: 0.265961. Loss: 2.126825. Batch_acc: 0.295255. Batch_loss: 2.023534 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.26596064329798635. Loss per char: 2.1268251150484034. Time: 1627204136.6502712\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 18, 17, 24, 18, 19, 21,  1, 66, 79, 69,  1, 14, 22,\n",
      "        21, 18, 23, 26, 15, 25, 20, 25, 20, 15,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.265978. Loss: 2.126782. Batch_acc: 0.302632. Batch_loss: 2.035865 \n",
      "Batch: 2010. Acc: 0.266005. Loss: 2.126707. Batch_acc: 0.321637. Batch_loss: 1.973778 \n",
      "Batch: 2011. Acc: 0.266019. Loss: 2.126655. Batch_acc: 0.294287. Batch_loss: 2.022688 \n",
      "Batch: 2012. Acc: 0.266032. Loss: 2.126616. Batch_acc: 0.290984. Batch_loss: 2.047412 \n",
      "Batch: 2013. Acc: 0.266039. Loss: 2.126574. Batch_acc: 0.281250. Batch_loss: 2.041598 \n",
      "Batch: 2014. Acc: 0.266055. Loss: 2.126538. Batch_acc: 0.297710. Batch_loss: 2.051374 \n",
      "Batch: 2015. Acc: 0.266067. Loss: 2.126497. Batch_acc: 0.291117. Batch_loss: 2.044196 \n",
      "Batch: 2016. Acc: 0.266082. Loss: 2.126445. Batch_acc: 0.295889. Batch_loss: 2.021527 \n",
      "Batch: 2017. Acc: 0.266094. Loss: 2.126397. Batch_acc: 0.291472. Batch_loss: 2.028551 \n",
      "Batch: 2018. Acc: 0.266115. Loss: 2.126329. Batch_acc: 0.307958. Batch_loss: 1.988052 \n",
      "Batch: 2019. Acc: 0.266123. Loss: 2.126298. Batch_acc: 0.282187. Batch_loss: 2.061539 \n",
      "Batch: 2020. Acc: 0.266134. Loss: 2.126261. Batch_acc: 0.289080. Batch_loss: 2.053076 \n",
      "Batch: 2021. Acc: 0.266147. Loss: 2.126213. Batch_acc: 0.293372. Batch_loss: 2.028776 \n",
      "Batch: 2022. Acc: 0.266169. Loss: 2.126156. Batch_acc: 0.308254. Batch_loss: 2.013892 \n",
      "Batch: 2023. Acc: 0.266187. Loss: 2.126098. Batch_acc: 0.302247. Batch_loss: 2.010959 \n",
      "Batch: 2024. Acc: 0.266196. Loss: 2.126065. Batch_acc: 0.283979. Batch_loss: 2.058261 \n",
      "Batch: 2025. Acc: 0.266208. Loss: 2.126020. Batch_acc: 0.291168. Batch_loss: 2.037513 \n",
      "Batch: 2026. Acc: 0.266213. Loss: 2.125990. Batch_acc: 0.275903. Batch_loss: 2.063254 \n",
      "Batch: 2027. Acc: 0.266229. Loss: 2.125945. Batch_acc: 0.299593. Batch_loss: 2.032092 \n",
      "Batch: 2028. Acc: 0.266232. Loss: 2.125917. Batch_acc: 0.272995. Batch_loss: 2.067780 \n",
      "Batch: 2029. Acc: 0.266258. Loss: 2.125871. Batch_acc: 0.318790. Batch_loss: 2.031950 \n",
      "Batch: 2030. Acc: 0.266279. Loss: 2.125824. Batch_acc: 0.310142. Batch_loss: 2.027874 \n",
      "Batch: 2031. Acc: 0.266281. Loss: 2.125808. Batch_acc: 0.270548. Batch_loss: 2.094496 \n",
      "Batch: 2032. Acc: 0.266296. Loss: 2.125758. Batch_acc: 0.296339. Batch_loss: 2.022009 \n",
      "Batch: 2033. Acc: 0.266304. Loss: 2.125721. Batch_acc: 0.281963. Batch_loss: 2.052144 \n",
      "Batch: 2034. Acc: 0.266316. Loss: 2.125674. Batch_acc: 0.292051. Batch_loss: 2.028841 \n",
      "Batch: 2035. Acc: 0.266329. Loss: 2.125613. Batch_acc: 0.291831. Batch_loss: 2.005039 \n",
      "Batch: 2036. Acc: 0.266347. Loss: 2.125564. Batch_acc: 0.301898. Batch_loss: 2.026743 \n",
      "Batch: 2037. Acc: 0.266360. Loss: 2.125514. Batch_acc: 0.293588. Batch_loss: 2.025539 \n",
      "Batch: 2038. Acc: 0.266375. Loss: 2.125465. Batch_acc: 0.296893. Batch_loss: 2.024732 \n",
      "Batch: 2039. Acc: 0.266390. Loss: 2.125423. Batch_acc: 0.296189. Batch_loss: 2.039285 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2040. Acc: 0.266405. Loss: 2.125399. Batch_acc: 0.296610. Batch_loss: 2.078520 \n",
      "Batch: 2041. Acc: 0.266413. Loss: 2.125376. Batch_acc: 0.284360. Batch_loss: 2.075864 \n",
      "Batch: 2042. Acc: 0.266427. Loss: 2.125319. Batch_acc: 0.294360. Batch_loss: 2.007625 \n",
      "Batch: 2043. Acc: 0.266446. Loss: 2.125276. Batch_acc: 0.305776. Batch_loss: 2.037798 \n",
      "Batch: 2044. Acc: 0.266464. Loss: 2.125233. Batch_acc: 0.302752. Batch_loss: 2.039146 \n",
      "Batch: 2045. Acc: 0.266480. Loss: 2.125191. Batch_acc: 0.298387. Batch_loss: 2.038378 \n",
      "Batch: 2046. Acc: 0.266491. Loss: 2.125156. Batch_acc: 0.289072. Batch_loss: 2.052061 \n",
      "Batch: 2047. Acc: 0.266500. Loss: 2.125118. Batch_acc: 0.285882. Batch_loss: 2.045390 \n",
      "Batch: 2048. Acc: 0.266518. Loss: 2.125055. Batch_acc: 0.303251. Batch_loss: 1.999744 \n",
      "Batch: 2049. Acc: 0.266536. Loss: 2.124986. Batch_acc: 0.302459. Batch_loss: 1.984901 \n",
      "Batch: 2050. Acc: 0.266547. Loss: 2.124947. Batch_acc: 0.288928. Batch_loss: 2.042992 \n",
      "Batch: 2051. Acc: 0.266559. Loss: 2.124889. Batch_acc: 0.293233. Batch_loss: 2.004388 \n",
      "Batch: 2052. Acc: 0.266578. Loss: 2.124840. Batch_acc: 0.302945. Batch_loss: 2.025614 \n",
      "Batch: 2053. Acc: 0.266588. Loss: 2.124791. Batch_acc: 0.287330. Batch_loss: 2.026390 \n",
      "Batch: 2054. Acc: 0.266609. Loss: 2.124731. Batch_acc: 0.309332. Batch_loss: 2.000795 \n",
      "Batch: 2055. Acc: 0.266622. Loss: 2.124678. Batch_acc: 0.294835. Batch_loss: 2.014838 \n",
      "Batch: 2056. Acc: 0.266638. Loss: 2.124638. Batch_acc: 0.299087. Batch_loss: 2.043963 \n",
      "Batch: 2057. Acc: 0.266651. Loss: 2.124591. Batch_acc: 0.292724. Batch_loss: 2.028944 \n",
      "Batch: 2058. Acc: 0.266661. Loss: 2.124538. Batch_acc: 0.286857. Batch_loss: 2.016358 \n",
      "Batch: 2059. Acc: 0.266678. Loss: 2.124486. Batch_acc: 0.302150. Batch_loss: 2.017801 \n",
      "Batch: 2060. Acc: 0.266690. Loss: 2.124454. Batch_acc: 0.291036. Batch_loss: 2.057441 \n",
      "Batch: 2061. Acc: 0.266706. Loss: 2.124415. Batch_acc: 0.300282. Batch_loss: 2.045352 \n",
      "Batch: 2062. Acc: 0.266721. Loss: 2.124377. Batch_acc: 0.297126. Batch_loss: 2.046764 \n",
      "Batch: 2063. Acc: 0.266733. Loss: 2.124334. Batch_acc: 0.291570. Batch_loss: 2.034047 \n",
      "Batch: 2064. Acc: 0.266751. Loss: 2.124273. Batch_acc: 0.303013. Batch_loss: 1.998752 \n",
      "Batch: 2065. Acc: 0.266761. Loss: 2.124230. Batch_acc: 0.287600. Batch_loss: 2.034785 \n",
      "Batch: 2066. Acc: 0.266781. Loss: 2.124171. Batch_acc: 0.308390. Batch_loss: 2.005207 \n",
      "Batch: 2067. Acc: 0.266790. Loss: 2.124133. Batch_acc: 0.285219. Batch_loss: 2.043370 \n",
      "Batch: 2068. Acc: 0.266804. Loss: 2.124070. Batch_acc: 0.295388. Batch_loss: 1.993155 \n",
      "Batch: 2069. Acc: 0.266823. Loss: 2.124017. Batch_acc: 0.307253. Batch_loss: 2.015491 \n",
      "Batch: 2070. Acc: 0.266839. Loss: 2.123961. Batch_acc: 0.298246. Batch_loss: 2.009269 \n",
      "Batch: 2071. Acc: 0.266853. Loss: 2.123923. Batch_acc: 0.297564. Batch_loss: 2.044279 \n",
      "Batch: 2072. Acc: 0.266868. Loss: 2.123872. Batch_acc: 0.297173. Batch_loss: 2.018834 \n",
      "Batch: 2073. Acc: 0.266877. Loss: 2.123842. Batch_acc: 0.285138. Batch_loss: 2.060169 \n",
      "Batch: 2074. Acc: 0.266896. Loss: 2.123790. Batch_acc: 0.307514. Batch_loss: 2.016886 \n",
      "Batch: 2075. Acc: 0.266905. Loss: 2.123756. Batch_acc: 0.285880. Batch_loss: 2.052933 \n",
      "Batch: 2076. Acc: 0.266921. Loss: 2.123701. Batch_acc: 0.298364. Batch_loss: 2.010290 \n",
      "Batch: 2077. Acc: 0.266939. Loss: 2.123650. Batch_acc: 0.304070. Batch_loss: 2.017323 \n",
      "Batch: 2078. Acc: 0.266953. Loss: 2.123598. Batch_acc: 0.296830. Batch_loss: 2.015719 \n",
      "Batch: 2079. Acc: 0.266975. Loss: 2.123530. Batch_acc: 0.312788. Batch_loss: 1.982454 \n",
      "Batch: 2080. Acc: 0.266991. Loss: 2.123477. Batch_acc: 0.300224. Batch_loss: 2.016021 \n",
      "Batch: 2081. Acc: 0.266997. Loss: 2.123448. Batch_acc: 0.279564. Batch_loss: 2.063152 \n",
      "Batch: 2082. Acc: 0.267007. Loss: 2.123412. Batch_acc: 0.288473. Batch_loss: 2.045870 \n",
      "Batch: 2083. Acc: 0.267029. Loss: 2.123351. Batch_acc: 0.312281. Batch_loss: 1.995659 \n",
      "Batch: 2084. Acc: 0.267046. Loss: 2.123295. Batch_acc: 0.301533. Batch_loss: 2.008153 \n",
      "Batch: 2085. Acc: 0.267069. Loss: 2.123236. Batch_acc: 0.314113. Batch_loss: 2.004661 \n",
      "Batch: 2086. Acc: 0.267087. Loss: 2.123175. Batch_acc: 0.303421. Batch_loss: 1.999911 \n",
      "Batch: 2087. Acc: 0.267102. Loss: 2.123117. Batch_acc: 0.298305. Batch_loss: 2.003167 \n",
      "Batch: 2088. Acc: 0.267119. Loss: 2.123066. Batch_acc: 0.302600. Batch_loss: 2.014405 \n",
      "Batch: 2089. Acc: 0.267137. Loss: 2.123021. Batch_acc: 0.303833. Batch_loss: 2.030278 \n",
      "Batch: 2090. Acc: 0.267152. Loss: 2.122973. Batch_acc: 0.297653. Batch_loss: 2.023812 \n",
      "Batch: 2091. Acc: 0.267165. Loss: 2.122930. Batch_acc: 0.294018. Batch_loss: 2.035481 \n",
      "Batch: 2092. Acc: 0.267184. Loss: 2.122888. Batch_acc: 0.307780. Batch_loss: 2.035631 \n",
      "Batch: 2093. Acc: 0.267184. Loss: 2.122861. Batch_acc: 0.267338. Batch_loss: 2.068434 \n",
      "Batch: 2094. Acc: 0.267196. Loss: 2.122809. Batch_acc: 0.291925. Batch_loss: 2.016240 \n",
      "Batch: 2095. Acc: 0.267211. Loss: 2.122756. Batch_acc: 0.297693. Batch_loss: 2.014008 \n",
      "Batch: 2096. Acc: 0.267224. Loss: 2.122724. Batch_acc: 0.294048. Batch_loss: 2.052556 \n",
      "Batch: 2097. Acc: 0.267239. Loss: 2.122674. Batch_acc: 0.300880. Batch_loss: 2.015165 \n",
      "Batch: 2098. Acc: 0.267262. Loss: 2.122599. Batch_acc: 0.313848. Batch_loss: 1.969148 \n",
      "Batch: 2099. Acc: 0.267272. Loss: 2.122564. Batch_acc: 0.288407. Batch_loss: 2.048911 \n",
      "Batch: 2100. Acc: 0.267277. Loss: 2.122526. Batch_acc: 0.276730. Batch_loss: 2.042447 \n",
      "Batch: 2101. Acc: 0.267294. Loss: 2.122475. Batch_acc: 0.304298. Batch_loss: 2.015449 \n",
      "Batch: 2102. Acc: 0.267303. Loss: 2.122448. Batch_acc: 0.286048. Batch_loss: 2.065278 \n",
      "Batch: 2103. Acc: 0.267319. Loss: 2.122398. Batch_acc: 0.301765. Batch_loss: 2.014854 \n",
      "Batch: 2104. Acc: 0.267332. Loss: 2.122357. Batch_acc: 0.295972. Batch_loss: 2.035376 \n",
      "Batch: 2105. Acc: 0.267340. Loss: 2.122326. Batch_acc: 0.282811. Batch_loss: 2.056415 \n",
      "Batch: 2106. Acc: 0.267347. Loss: 2.122287. Batch_acc: 0.283608. Batch_loss: 2.038239 \n",
      "Batch: 2107. Acc: 0.267369. Loss: 2.122236. Batch_acc: 0.313253. Batch_loss: 2.014815 \n",
      "Batch: 2108. Acc: 0.267380. Loss: 2.122200. Batch_acc: 0.289982. Batch_loss: 2.045415 \n",
      "Batch: 2109. Acc: 0.267393. Loss: 2.122163. Batch_acc: 0.295616. Batch_loss: 2.041960 \n",
      "Batch: 2110. Acc: 0.267409. Loss: 2.122101. Batch_acc: 0.301972. Batch_loss: 1.992672 \n",
      "Batch: 2111. Acc: 0.267420. Loss: 2.122062. Batch_acc: 0.288193. Batch_loss: 2.043063 \n",
      "Batch: 2112. Acc: 0.267431. Loss: 2.122022. Batch_acc: 0.291523. Batch_loss: 2.037395 \n",
      "Batch: 2113. Acc: 0.267451. Loss: 2.121962. Batch_acc: 0.309267. Batch_loss: 1.997670 \n",
      "Batch: 2114. Acc: 0.267461. Loss: 2.121923. Batch_acc: 0.287299. Batch_loss: 2.041710 \n",
      "Batch: 2115. Acc: 0.267484. Loss: 2.121858. Batch_acc: 0.315315. Batch_loss: 1.987570 \n",
      "Batch: 2116. Acc: 0.267495. Loss: 2.121806. Batch_acc: 0.289720. Batch_loss: 2.015933 \n",
      "Batch: 2117. Acc: 0.267511. Loss: 2.121758. Batch_acc: 0.301768. Batch_loss: 2.021550 \n",
      "Batch: 2118. Acc: 0.267519. Loss: 2.121728. Batch_acc: 0.283688. Batch_loss: 2.056138 \n",
      "Batch: 2119. Acc: 0.267537. Loss: 2.121682. Batch_acc: 0.306134. Batch_loss: 2.023414 \n",
      "Batch: 2120. Acc: 0.267555. Loss: 2.121630. Batch_acc: 0.305604. Batch_loss: 2.010932 \n",
      "Batch: 2121. Acc: 0.267574. Loss: 2.121591. Batch_acc: 0.307560. Batch_loss: 2.040103 \n",
      "Batch: 2122. Acc: 0.267593. Loss: 2.121552. Batch_acc: 0.309524. Batch_loss: 2.038661 \n",
      "Batch: 2123. Acc: 0.267613. Loss: 2.121505. Batch_acc: 0.309091. Batch_loss: 2.023170 \n",
      "Batch: 2124. Acc: 0.267621. Loss: 2.121477. Batch_acc: 0.285714. Batch_loss: 2.061278 \n",
      "Batch: 2125. Acc: 0.267635. Loss: 2.121439. Batch_acc: 0.296317. Batch_loss: 2.043211 \n",
      "Batch: 2126. Acc: 0.267644. Loss: 2.121402. Batch_acc: 0.286520. Batch_loss: 2.044327 \n",
      "Batch: 2127. Acc: 0.267659. Loss: 2.121352. Batch_acc: 0.299240. Batch_loss: 2.012853 \n",
      "Batch: 2128. Acc: 0.267681. Loss: 2.121283. Batch_acc: 0.316344. Batch_loss: 1.970230 \n",
      "Batch: 2129. Acc: 0.267694. Loss: 2.121237. Batch_acc: 0.294886. Batch_loss: 2.025798 \n",
      "Batch: 2130. Acc: 0.267714. Loss: 2.121180. Batch_acc: 0.309207. Batch_loss: 1.999186 \n",
      "Batch: 2131. Acc: 0.267720. Loss: 2.121149. Batch_acc: 0.281542. Batch_loss: 2.053842 \n",
      "Batch: 2132. Acc: 0.267731. Loss: 2.121105. Batch_acc: 0.289961. Batch_loss: 2.028789 \n",
      "Batch: 2133. Acc: 0.267742. Loss: 2.121065. Batch_acc: 0.291425. Batch_loss: 2.035517 \n",
      "Batch: 2134. Acc: 0.267752. Loss: 2.121039. Batch_acc: 0.290529. Batch_loss: 2.066197 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2135. Acc: 0.267766. Loss: 2.120994. Batch_acc: 0.296672. Batch_loss: 2.025126 \n",
      "Batch: 2136. Acc: 0.267779. Loss: 2.120946. Batch_acc: 0.296318. Batch_loss: 2.017084 \n",
      "Batch: 2137. Acc: 0.267795. Loss: 2.120909. Batch_acc: 0.302270. Batch_loss: 2.039237 \n",
      "Batch: 2138. Acc: 0.267812. Loss: 2.120862. Batch_acc: 0.305819. Batch_loss: 2.016843 \n",
      "Batch: 2139. Acc: 0.267826. Loss: 2.120811. Batch_acc: 0.296893. Batch_loss: 2.012908 \n",
      "Batch: 2140. Acc: 0.267842. Loss: 2.120756. Batch_acc: 0.303222. Batch_loss: 2.001704 \n",
      "Batch: 2141. Acc: 0.267852. Loss: 2.120720. Batch_acc: 0.289698. Batch_loss: 2.045760 \n",
      "Batch: 2142. Acc: 0.267873. Loss: 2.120651. Batch_acc: 0.311673. Batch_loss: 1.973248 \n",
      "Batch: 2143. Acc: 0.267884. Loss: 2.120603. Batch_acc: 0.291763. Batch_loss: 2.015525 \n",
      "Batch: 2144. Acc: 0.267895. Loss: 2.120548. Batch_acc: 0.290929. Batch_loss: 2.007483 \n",
      "Batch: 2145. Acc: 0.267909. Loss: 2.120504. Batch_acc: 0.298387. Batch_loss: 2.026292 \n",
      "Batch: 2146. Acc: 0.267925. Loss: 2.120453. Batch_acc: 0.301184. Batch_loss: 2.013888 \n",
      "Batch: 2147. Acc: 0.267939. Loss: 2.120400. Batch_acc: 0.297586. Batch_loss: 2.009698 \n",
      "Batch: 2148. Acc: 0.267949. Loss: 2.120370. Batch_acc: 0.289982. Batch_loss: 2.052819 \n",
      "Batch: 2149. Acc: 0.267968. Loss: 2.120308. Batch_acc: 0.306326. Batch_loss: 1.991736 \n",
      "Batch: 2150. Acc: 0.267975. Loss: 2.120260. Batch_acc: 0.283761. Batch_loss: 2.019160 \n",
      "Batch: 2151. Acc: 0.267997. Loss: 2.120197. Batch_acc: 0.313501. Batch_loss: 1.986320 \n",
      "Batch: 2152. Acc: 0.268005. Loss: 2.120155. Batch_acc: 0.285877. Batch_loss: 2.028725 \n",
      "Batch: 2153. Acc: 0.268015. Loss: 2.120124. Batch_acc: 0.289747. Batch_loss: 2.054397 \n",
      "Batch: 2154. Acc: 0.268033. Loss: 2.120072. Batch_acc: 0.306261. Batch_loss: 2.010816 \n",
      "Batch: 2155. Acc: 0.268050. Loss: 2.120025. Batch_acc: 0.305006. Batch_loss: 2.017555 \n",
      "Batch: 2156. Acc: 0.268065. Loss: 2.119984. Batch_acc: 0.300799. Batch_loss: 2.031308 \n",
      "Batch: 2157. Acc: 0.268079. Loss: 2.119932. Batch_acc: 0.297501. Batch_loss: 2.007912 \n",
      "Batch: 2158. Acc: 0.268093. Loss: 2.119886. Batch_acc: 0.297013. Batch_loss: 2.022658 \n",
      "Batch: 2159. Acc: 0.268107. Loss: 2.119845. Batch_acc: 0.298777. Batch_loss: 2.032085 \n",
      "Batch: 2160. Acc: 0.268133. Loss: 2.119793. Batch_acc: 0.323077. Batch_loss: 2.006678 \n",
      "Batch: 2161. Acc: 0.268152. Loss: 2.119746. Batch_acc: 0.310406. Batch_loss: 2.016300 \n",
      "Batch: 2162. Acc: 0.268156. Loss: 2.119705. Batch_acc: 0.277011. Batch_loss: 2.031861 \n",
      "Batch: 2163. Acc: 0.268163. Loss: 2.119675. Batch_acc: 0.284710. Batch_loss: 2.053313 \n",
      "Batch: 2164. Acc: 0.268182. Loss: 2.119616. Batch_acc: 0.308542. Batch_loss: 1.990657 \n",
      "Batch: 2165. Acc: 0.268205. Loss: 2.119572. Batch_acc: 0.318129. Batch_loss: 2.023610 \n",
      "Batch: 2166. Acc: 0.268219. Loss: 2.119526. Batch_acc: 0.299595. Batch_loss: 2.019395 \n",
      "Batch: 2167. Acc: 0.268234. Loss: 2.119489. Batch_acc: 0.301898. Batch_loss: 2.038299 \n",
      "Batch: 2168. Acc: 0.268243. Loss: 2.119456. Batch_acc: 0.287478. Batch_loss: 2.046004 \n",
      "Batch: 2169. Acc: 0.268255. Loss: 2.119412. Batch_acc: 0.294872. Batch_loss: 2.023082 \n",
      "Batch: 2170. Acc: 0.268272. Loss: 2.119368. Batch_acc: 0.304524. Batch_loss: 2.024129 \n",
      "Batch: 2171. Acc: 0.268292. Loss: 2.119308. Batch_acc: 0.310972. Batch_loss: 1.991269 \n",
      "Batch: 2172. Acc: 0.268299. Loss: 2.119276. Batch_acc: 0.284509. Batch_loss: 2.044594 \n",
      "Batch: 2173. Acc: 0.268315. Loss: 2.119235. Batch_acc: 0.303776. Batch_loss: 2.031668 \n",
      "Batch: 2174. Acc: 0.268328. Loss: 2.119184. Batch_acc: 0.296893. Batch_loss: 2.008026 \n",
      "Batch: 2175. Acc: 0.268351. Loss: 2.119122. Batch_acc: 0.316686. Batch_loss: 1.986281 \n",
      "Batch: 2176. Acc: 0.268356. Loss: 2.119083. Batch_acc: 0.279202. Batch_loss: 2.034634 \n",
      "Batch: 2177. Acc: 0.268370. Loss: 2.119033. Batch_acc: 0.299150. Batch_loss: 2.011273 \n",
      "Batch: 2178. Acc: 0.268386. Loss: 2.118979. Batch_acc: 0.301479. Batch_loss: 2.004093 \n",
      "Batch: 2179. Acc: 0.268398. Loss: 2.118933. Batch_acc: 0.294385. Batch_loss: 2.018805 \n",
      "Batch: 2180. Acc: 0.268412. Loss: 2.118900. Batch_acc: 0.299429. Batch_loss: 2.048167 \n",
      "Batch: 2181. Acc: 0.268432. Loss: 2.118850. Batch_acc: 0.312717. Batch_loss: 2.009434 \n",
      "Batch: 2182. Acc: 0.268439. Loss: 2.118813. Batch_acc: 0.282621. Batch_loss: 2.039154 \n",
      "Batch: 2183. Acc: 0.268448. Loss: 2.118774. Batch_acc: 0.288076. Batch_loss: 2.030875 \n",
      "Batch: 2184. Acc: 0.268455. Loss: 2.118738. Batch_acc: 0.284297. Batch_loss: 2.039163 \n",
      "Batch: 2185. Acc: 0.268465. Loss: 2.118713. Batch_acc: 0.290931. Batch_loss: 2.063781 \n",
      "Batch: 2186. Acc: 0.268481. Loss: 2.118672. Batch_acc: 0.303255. Batch_loss: 2.029600 \n",
      "Batch: 2187. Acc: 0.268494. Loss: 2.118630. Batch_acc: 0.296105. Batch_loss: 2.026271 \n",
      "Batch: 2188. Acc: 0.268505. Loss: 2.118584. Batch_acc: 0.293515. Batch_loss: 2.018864 \n",
      "Batch: 2189. Acc: 0.268512. Loss: 2.118553. Batch_acc: 0.282787. Batch_loss: 2.050763 \n",
      "Batch: 2190. Acc: 0.268527. Loss: 2.118511. Batch_acc: 0.302204. Batch_loss: 2.025127 \n",
      "Batch: 2191. Acc: 0.268538. Loss: 2.118475. Batch_acc: 0.293945. Batch_loss: 2.038457 \n",
      "Batch: 2192. Acc: 0.268550. Loss: 2.118433. Batch_acc: 0.293750. Batch_loss: 2.026841 \n",
      "Batch: 2193. Acc: 0.268557. Loss: 2.118399. Batch_acc: 0.283700. Batch_loss: 2.045008 \n",
      "Batch: 2194. Acc: 0.268571. Loss: 2.118350. Batch_acc: 0.299597. Batch_loss: 2.010322 \n",
      "Batch: 2195. Acc: 0.268575. Loss: 2.118317. Batch_acc: 0.276852. Batch_loss: 2.047231 \n",
      "Batch: 2196. Acc: 0.268582. Loss: 2.118279. Batch_acc: 0.284884. Batch_loss: 2.034123 \n",
      "Batch: 2197. Acc: 0.268603. Loss: 2.118223. Batch_acc: 0.313703. Batch_loss: 1.996113 \n",
      "Batch: 2198. Acc: 0.268611. Loss: 2.118200. Batch_acc: 0.287164. Batch_loss: 2.066140 \n",
      "Batch: 2199. Acc: 0.268624. Loss: 2.118154. Batch_acc: 0.295912. Batch_loss: 2.017193 \n",
      "Batch: 2200. Acc: 0.268638. Loss: 2.118111. Batch_acc: 0.301624. Batch_loss: 2.022218 \n",
      "Batch: 2201. Acc: 0.268649. Loss: 2.118075. Batch_acc: 0.293459. Batch_loss: 2.038474 \n",
      "Batch: 2202. Acc: 0.268660. Loss: 2.118040. Batch_acc: 0.291023. Batch_loss: 2.039952 \n",
      "Batch: 2203. Acc: 0.268673. Loss: 2.117999. Batch_acc: 0.297872. Batch_loss: 2.029225 \n",
      "Batch: 2204. Acc: 0.268682. Loss: 2.117965. Batch_acc: 0.289027. Batch_loss: 2.043274 \n",
      "Batch: 2205. Acc: 0.268694. Loss: 2.117921. Batch_acc: 0.295376. Batch_loss: 2.019566 \n",
      "Batch: 2206. Acc: 0.268716. Loss: 2.117854. Batch_acc: 0.315175. Batch_loss: 1.976147 \n",
      "Batch: 2207. Acc: 0.268731. Loss: 2.117811. Batch_acc: 0.300870. Batch_loss: 2.022904 \n",
      "Batch: 2208. Acc: 0.268738. Loss: 2.117782. Batch_acc: 0.285714. Batch_loss: 2.051094 \n",
      "Batch: 2209. Acc: 0.268751. Loss: 2.117748. Batch_acc: 0.297173. Batch_loss: 2.042569 \n",
      "Batch: 2210. Acc: 0.268763. Loss: 2.117705. Batch_acc: 0.294118. Batch_loss: 2.024712 \n",
      "Batch: 2211. Acc: 0.268777. Loss: 2.117671. Batch_acc: 0.300347. Batch_loss: 2.040817 \n",
      "Batch: 2212. Acc: 0.268791. Loss: 2.117628. Batch_acc: 0.299150. Batch_loss: 2.024647 \n",
      "Batch: 2213. Acc: 0.268806. Loss: 2.117587. Batch_acc: 0.303561. Batch_loss: 2.024462 \n",
      "Batch: 2214. Acc: 0.268819. Loss: 2.117538. Batch_acc: 0.296946. Batch_loss: 2.011444 \n",
      "Batch: 2215. Acc: 0.268832. Loss: 2.117490. Batch_acc: 0.297680. Batch_loss: 2.014325 \n",
      "Batch: 2216. Acc: 0.268843. Loss: 2.117452. Batch_acc: 0.293182. Batch_loss: 2.034338 \n",
      "Batch: 2217. Acc: 0.268854. Loss: 2.117402. Batch_acc: 0.291334. Batch_loss: 2.007392 \n",
      "Batch: 2218. Acc: 0.268875. Loss: 2.117353. Batch_acc: 0.315820. Batch_loss: 2.005271 \n",
      "Batch: 2219. Acc: 0.268887. Loss: 2.117304. Batch_acc: 0.297564. Batch_loss: 2.009465 \n",
      "Batch: 2220. Acc: 0.268897. Loss: 2.117259. Batch_acc: 0.289177. Batch_loss: 2.017908 \n",
      "Batch: 2221. Acc: 0.268909. Loss: 2.117225. Batch_acc: 0.295637. Batch_loss: 2.042479 \n",
      "Batch: 2222. Acc: 0.268920. Loss: 2.117193. Batch_acc: 0.293023. Batch_loss: 2.046409 \n",
      "Batch: 2223. Acc: 0.268942. Loss: 2.117135. Batch_acc: 0.318439. Batch_loss: 1.989385 \n",
      "Batch: 2224. Acc: 0.268959. Loss: 2.117087. Batch_acc: 0.306461. Batch_loss: 2.011393 \n",
      "Batch: 2225. Acc: 0.268972. Loss: 2.117054. Batch_acc: 0.297501. Batch_loss: 2.042378 \n",
      "Batch: 2226. Acc: 0.268993. Loss: 2.116999. Batch_acc: 0.314302. Batch_loss: 1.996127 \n",
      "Batch: 2227. Acc: 0.269015. Loss: 2.116934. Batch_acc: 0.318807. Batch_loss: 1.974672 \n",
      "Batch: 2228. Acc: 0.269031. Loss: 2.116886. Batch_acc: 0.304397. Batch_loss: 2.009158 \n",
      "Batch: 2229. Acc: 0.269045. Loss: 2.116835. Batch_acc: 0.299781. Batch_loss: 2.009619 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2230. Acc: 0.269064. Loss: 2.116781. Batch_acc: 0.309008. Batch_loss: 1.997790 \n",
      "Batch: 2231. Acc: 0.269083. Loss: 2.116727. Batch_acc: 0.312285. Batch_loss: 1.995045 \n",
      "Batch: 2232. Acc: 0.269098. Loss: 2.116674. Batch_acc: 0.302150. Batch_loss: 1.997857 \n",
      "Batch: 2233. Acc: 0.269106. Loss: 2.116647. Batch_acc: 0.288451. Batch_loss: 2.056808 \n",
      "Batch: 2234. Acc: 0.269117. Loss: 2.116614. Batch_acc: 0.292056. Batch_loss: 2.042471 \n",
      "Batch: 2235. Acc: 0.269130. Loss: 2.116566. Batch_acc: 0.299135. Batch_loss: 2.008374 \n",
      "Batch: 2236. Acc: 0.269144. Loss: 2.116538. Batch_acc: 0.300402. Batch_loss: 2.055286 \n",
      "Batch: 2237. Acc: 0.269162. Loss: 2.116499. Batch_acc: 0.310448. Batch_loss: 2.025034 \n",
      "Batch: 2238. Acc: 0.269175. Loss: 2.116448. Batch_acc: 0.299022. Batch_loss: 2.002627 \n",
      "Batch: 2239. Acc: 0.269193. Loss: 2.116403. Batch_acc: 0.308966. Batch_loss: 2.017441 \n",
      "Batch: 2240. Acc: 0.269203. Loss: 2.116381. Batch_acc: 0.291691. Batch_loss: 2.065873 \n",
      "Batch: 2241. Acc: 0.269210. Loss: 2.116358. Batch_acc: 0.284457. Batch_loss: 2.063790 \n",
      "Batch: 2242. Acc: 0.269222. Loss: 2.116317. Batch_acc: 0.297897. Batch_loss: 2.023360 \n",
      "Batch: 2243. Acc: 0.269231. Loss: 2.116276. Batch_acc: 0.288028. Batch_loss: 2.023540 \n",
      "Batch: 2244. Acc: 0.269246. Loss: 2.116241. Batch_acc: 0.303288. Batch_loss: 2.039003 \n",
      "Batch: 2245. Acc: 0.269257. Loss: 2.116209. Batch_acc: 0.292506. Batch_loss: 2.046490 \n",
      "Batch: 2246. Acc: 0.269267. Loss: 2.116159. Batch_acc: 0.293396. Batch_loss: 2.002753 \n",
      "Batch: 2247. Acc: 0.269278. Loss: 2.116117. Batch_acc: 0.294118. Batch_loss: 2.020506 \n",
      "Batch: 2248. Acc: 0.269297. Loss: 2.116065. Batch_acc: 0.311523. Batch_loss: 1.999209 \n",
      "Batch: 2249. Acc: 0.269308. Loss: 2.116042. Batch_acc: 0.294084. Batch_loss: 2.065114 \n",
      "Batch: 2250. Acc: 0.269319. Loss: 2.116002. Batch_acc: 0.294664. Batch_loss: 2.025843 \n",
      "Batch: 2251. Acc: 0.269338. Loss: 2.115956. Batch_acc: 0.311239. Batch_loss: 2.011545 \n",
      "Batch: 2252. Acc: 0.269350. Loss: 2.115922. Batch_acc: 0.295608. Batch_loss: 2.040578 \n",
      "Batch: 2253. Acc: 0.269362. Loss: 2.115897. Batch_acc: 0.296902. Batch_loss: 2.059215 \n",
      "Batch: 2254. Acc: 0.269385. Loss: 2.115845. Batch_acc: 0.320701. Batch_loss: 2.000942 \n",
      "Batch: 2255. Acc: 0.269396. Loss: 2.115805. Batch_acc: 0.294252. Batch_loss: 2.026424 \n",
      "Batch: 2256. Acc: 0.269409. Loss: 2.115761. Batch_acc: 0.298447. Batch_loss: 2.015625 \n",
      "Batch: 2257. Acc: 0.269419. Loss: 2.115731. Batch_acc: 0.291257. Batch_loss: 2.049528 \n",
      "Batch: 2258. Acc: 0.269434. Loss: 2.115695. Batch_acc: 0.303204. Batch_loss: 2.034945 \n",
      "Batch: 2259. Acc: 0.269450. Loss: 2.115646. Batch_acc: 0.305619. Batch_loss: 2.005279 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.2694497917009843. Loss per char: 2.115646446539909. Time: 1627204336.9727478\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 14, 26, 24, 20, 17, 20, 19, 19,\n",
      "        17, 23, 20,  1, 14,  1, 22, 25, 17, 15,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.269473. Loss: 2.115597. Batch_acc: 0.321965. Batch_loss: 2.004147 \n",
      "Batch: 2261. Acc: 0.269484. Loss: 2.115550. Batch_acc: 0.294864. Batch_loss: 2.008802 \n",
      "Batch: 2262. Acc: 0.269491. Loss: 2.115525. Batch_acc: 0.286385. Batch_loss: 2.057661 \n",
      "Batch: 2263. Acc: 0.269515. Loss: 2.115461. Batch_acc: 0.323563. Batch_loss: 1.969562 \n",
      "Batch: 2264. Acc: 0.269527. Loss: 2.115432. Batch_acc: 0.296600. Batch_loss: 2.048788 \n",
      "Batch: 2265. Acc: 0.269540. Loss: 2.115380. Batch_acc: 0.297945. Batch_loss: 1.999262 \n",
      "Batch: 2266. Acc: 0.269546. Loss: 2.115345. Batch_acc: 0.283921. Batch_loss: 2.032643 \n",
      "Batch: 2267. Acc: 0.269558. Loss: 2.115312. Batch_acc: 0.297530. Batch_loss: 2.041647 \n",
      "Batch: 2268. Acc: 0.269569. Loss: 2.115270. Batch_acc: 0.293535. Batch_loss: 2.017584 \n",
      "Batch: 2269. Acc: 0.269581. Loss: 2.115226. Batch_acc: 0.298770. Batch_loss: 2.014114 \n",
      "Batch: 2270. Acc: 0.269592. Loss: 2.115191. Batch_acc: 0.295072. Batch_loss: 2.035454 \n",
      "Batch: 2271. Acc: 0.269610. Loss: 2.115144. Batch_acc: 0.310167. Batch_loss: 2.007481 \n",
      "Batch: 2272. Acc: 0.269630. Loss: 2.115091. Batch_acc: 0.313907. Batch_loss: 1.994659 \n",
      "Batch: 2273. Acc: 0.269643. Loss: 2.115052. Batch_acc: 0.300115. Batch_loss: 2.027692 \n",
      "Batch: 2274. Acc: 0.269652. Loss: 2.115017. Batch_acc: 0.289290. Batch_loss: 2.032648 \n",
      "Batch: 2275. Acc: 0.269663. Loss: 2.114978. Batch_acc: 0.295271. Batch_loss: 2.026992 \n",
      "Batch: 2276. Acc: 0.269674. Loss: 2.114949. Batch_acc: 0.293718. Batch_loss: 2.050957 \n",
      "Batch: 2277. Acc: 0.269681. Loss: 2.114918. Batch_acc: 0.285873. Batch_loss: 2.045358 \n",
      "Batch: 2278. Acc: 0.269695. Loss: 2.114871. Batch_acc: 0.302768. Batch_loss: 2.008905 \n",
      "Batch: 2279. Acc: 0.269699. Loss: 2.114831. Batch_acc: 0.278661. Batch_loss: 2.023078 \n",
      "Batch: 2280. Acc: 0.269711. Loss: 2.114792. Batch_acc: 0.297047. Batch_loss: 2.025275 \n",
      "Batch: 2281. Acc: 0.269730. Loss: 2.114745. Batch_acc: 0.312648. Batch_loss: 2.006246 \n",
      "Batch: 2282. Acc: 0.269751. Loss: 2.114703. Batch_acc: 0.317794. Batch_loss: 2.019972 \n",
      "Batch: 2283. Acc: 0.269757. Loss: 2.114677. Batch_acc: 0.282659. Batch_loss: 2.055442 \n",
      "Batch: 2284. Acc: 0.269764. Loss: 2.114640. Batch_acc: 0.286461. Batch_loss: 2.028974 \n",
      "Batch: 2285. Acc: 0.269773. Loss: 2.114589. Batch_acc: 0.290548. Batch_loss: 1.995325 \n",
      "Batch: 2286. Acc: 0.269789. Loss: 2.114547. Batch_acc: 0.307692. Batch_loss: 2.014884 \n",
      "Batch: 2287. Acc: 0.269800. Loss: 2.114506. Batch_acc: 0.294454. Batch_loss: 2.022110 \n",
      "Batch: 2288. Acc: 0.269814. Loss: 2.114464. Batch_acc: 0.302150. Batch_loss: 2.016232 \n",
      "Batch: 2289. Acc: 0.269831. Loss: 2.114403. Batch_acc: 0.308211. Batch_loss: 1.978469 \n",
      "Batch: 2290. Acc: 0.269836. Loss: 2.114376. Batch_acc: 0.283019. Batch_loss: 2.051179 \n",
      "Batch: 2291. Acc: 0.269850. Loss: 2.114329. Batch_acc: 0.300343. Batch_loss: 2.008415 \n",
      "Batch: 2292. Acc: 0.269862. Loss: 2.114295. Batch_acc: 0.298619. Batch_loss: 2.035402 \n",
      "Batch: 2293. Acc: 0.269876. Loss: 2.114245. Batch_acc: 0.301596. Batch_loss: 2.000621 \n",
      "Batch: 2294. Acc: 0.269887. Loss: 2.114215. Batch_acc: 0.294016. Batch_loss: 2.045994 \n",
      "Batch: 2295. Acc: 0.269900. Loss: 2.114175. Batch_acc: 0.300931. Batch_loss: 2.021064 \n",
      "Batch: 2296. Acc: 0.269915. Loss: 2.114130. Batch_acc: 0.302768. Batch_loss: 2.010283 \n",
      "Batch: 2297. Acc: 0.269928. Loss: 2.114092. Batch_acc: 0.301100. Batch_loss: 2.025335 \n",
      "Batch: 2298. Acc: 0.269943. Loss: 2.114057. Batch_acc: 0.304248. Batch_loss: 2.034744 \n",
      "Batch: 2299. Acc: 0.269959. Loss: 2.114013. Batch_acc: 0.306395. Batch_loss: 2.012240 \n",
      "Batch: 2300. Acc: 0.269968. Loss: 2.113987. Batch_acc: 0.290813. Batch_loss: 2.053209 \n",
      "Batch: 2301. Acc: 0.269983. Loss: 2.113943. Batch_acc: 0.303662. Batch_loss: 2.014379 \n",
      "Batch: 2302. Acc: 0.269993. Loss: 2.113900. Batch_acc: 0.293203. Batch_loss: 2.015966 \n",
      "Batch: 2303. Acc: 0.270002. Loss: 2.113861. Batch_acc: 0.290731. Batch_loss: 2.022501 \n",
      "Batch: 2304. Acc: 0.270018. Loss: 2.113811. Batch_acc: 0.307558. Batch_loss: 1.996838 \n",
      "Batch: 2305. Acc: 0.270032. Loss: 2.113775. Batch_acc: 0.303520. Batch_loss: 2.031073 \n",
      "Batch: 2306. Acc: 0.270041. Loss: 2.113740. Batch_acc: 0.290731. Batch_loss: 2.033629 \n",
      "Batch: 2307. Acc: 0.270053. Loss: 2.113685. Batch_acc: 0.297558. Batch_loss: 1.988655 \n",
      "Batch: 2308. Acc: 0.270064. Loss: 2.113653. Batch_acc: 0.294761. Batch_loss: 2.039287 \n",
      "Batch: 2309. Acc: 0.270075. Loss: 2.113616. Batch_acc: 0.295205. Batch_loss: 2.027387 \n",
      "Batch: 2310. Acc: 0.270088. Loss: 2.113577. Batch_acc: 0.300351. Batch_loss: 2.021626 \n",
      "Batch: 2311. Acc: 0.270102. Loss: 2.113533. Batch_acc: 0.304042. Batch_loss: 2.011951 \n",
      "Batch: 2312. Acc: 0.270116. Loss: 2.113503. Batch_acc: 0.301542. Batch_loss: 2.042845 \n",
      "Batch: 2313. Acc: 0.270122. Loss: 2.113481. Batch_acc: 0.284986. Batch_loss: 2.063586 \n",
      "Batch: 2314. Acc: 0.270134. Loss: 2.113441. Batch_acc: 0.295936. Batch_loss: 2.022980 \n",
      "Batch: 2315. Acc: 0.270147. Loss: 2.113408. Batch_acc: 0.302113. Batch_loss: 2.036712 \n",
      "Batch: 2316. Acc: 0.270157. Loss: 2.113371. Batch_acc: 0.291762. Batch_loss: 2.028882 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2317. Acc: 0.270174. Loss: 2.113332. Batch_acc: 0.309249. Batch_loss: 2.021827 \n",
      "Batch: 2318. Acc: 0.270180. Loss: 2.113306. Batch_acc: 0.285207. Batch_loss: 2.051141 \n",
      "Batch: 2319. Acc: 0.270188. Loss: 2.113275. Batch_acc: 0.288194. Batch_loss: 2.041826 \n",
      "Batch: 2320. Acc: 0.270199. Loss: 2.113237. Batch_acc: 0.295906. Batch_loss: 2.023208 \n",
      "Batch: 2321. Acc: 0.270207. Loss: 2.113197. Batch_acc: 0.291228. Batch_loss: 2.018301 \n",
      "Batch: 2322. Acc: 0.270221. Loss: 2.113152. Batch_acc: 0.302125. Batch_loss: 2.009495 \n",
      "Batch: 2323. Acc: 0.270237. Loss: 2.113115. Batch_acc: 0.305902. Batch_loss: 2.028161 \n",
      "Batch: 2324. Acc: 0.270251. Loss: 2.113077. Batch_acc: 0.302624. Batch_loss: 2.023719 \n",
      "Batch: 2325. Acc: 0.270260. Loss: 2.113056. Batch_acc: 0.291117. Batch_loss: 2.064238 \n",
      "Batch: 2326. Acc: 0.270273. Loss: 2.113020. Batch_acc: 0.302924. Batch_loss: 2.027911 \n",
      "Batch: 2327. Acc: 0.270285. Loss: 2.112982. Batch_acc: 0.296445. Batch_loss: 2.025578 \n",
      "Batch: 2328. Acc: 0.270297. Loss: 2.112947. Batch_acc: 0.298870. Batch_loss: 2.032546 \n",
      "Batch: 2329. Acc: 0.270313. Loss: 2.112899. Batch_acc: 0.305416. Batch_loss: 2.004115 \n",
      "Batch: 2330. Acc: 0.270325. Loss: 2.112859. Batch_acc: 0.298567. Batch_loss: 2.019227 \n",
      "Batch: 2331. Acc: 0.270339. Loss: 2.112816. Batch_acc: 0.304046. Batch_loss: 2.012279 \n",
      "Batch: 2332. Acc: 0.270358. Loss: 2.112756. Batch_acc: 0.313458. Batch_loss: 1.974327 \n",
      "Batch: 2333. Acc: 0.270378. Loss: 2.112702. Batch_acc: 0.316427. Batch_loss: 1.987709 \n",
      "Batch: 2334. Acc: 0.270390. Loss: 2.112652. Batch_acc: 0.299652. Batch_loss: 1.994920 \n",
      "Batch: 2335. Acc: 0.270404. Loss: 2.112612. Batch_acc: 0.302977. Batch_loss: 2.017818 \n",
      "Batch: 2336. Acc: 0.270411. Loss: 2.112586. Batch_acc: 0.286464. Batch_loss: 2.049958 \n",
      "Batch: 2337. Acc: 0.270424. Loss: 2.112541. Batch_acc: 0.301941. Batch_loss: 2.008077 \n",
      "Batch: 2338. Acc: 0.270439. Loss: 2.112504. Batch_acc: 0.304447. Batch_loss: 2.027056 \n",
      "Batch: 2339. Acc: 0.270452. Loss: 2.112457. Batch_acc: 0.300786. Batch_loss: 2.006364 \n",
      "Batch: 2340. Acc: 0.270464. Loss: 2.112415. Batch_acc: 0.296567. Batch_loss: 2.014770 \n",
      "Batch: 2341. Acc: 0.270472. Loss: 2.112393. Batch_acc: 0.291993. Batch_loss: 2.059879 \n",
      "Batch: 2342. Acc: 0.270485. Loss: 2.112368. Batch_acc: 0.299941. Batch_loss: 2.051593 \n",
      "Batch: 2343. Acc: 0.270496. Loss: 2.112322. Batch_acc: 0.297123. Batch_loss: 2.001488 \n",
      "Batch: 2344. Acc: 0.270503. Loss: 2.112290. Batch_acc: 0.286613. Batch_loss: 2.038954 \n",
      "Batch: 2345. Acc: 0.270510. Loss: 2.112259. Batch_acc: 0.288372. Batch_loss: 2.037445 \n",
      "Batch: 2346. Acc: 0.270521. Loss: 2.112213. Batch_acc: 0.296027. Batch_loss: 2.007257 \n",
      "Batch: 2347. Acc: 0.270538. Loss: 2.112175. Batch_acc: 0.309674. Batch_loss: 2.024060 \n",
      "Batch: 2348. Acc: 0.270554. Loss: 2.112130. Batch_acc: 0.306606. Batch_loss: 2.008220 \n",
      "Batch: 2349. Acc: 0.270573. Loss: 2.112081. Batch_acc: 0.315186. Batch_loss: 1.998923 \n",
      "Batch: 2350. Acc: 0.270585. Loss: 2.112041. Batch_acc: 0.299478. Batch_loss: 2.016405 \n",
      "Batch: 2351. Acc: 0.270601. Loss: 2.111985. Batch_acc: 0.306271. Batch_loss: 1.984078 \n",
      "Batch: 2352. Acc: 0.270612. Loss: 2.111949. Batch_acc: 0.299757. Batch_loss: 2.022540 \n",
      "Batch: 2353. Acc: 0.270625. Loss: 2.111905. Batch_acc: 0.298723. Batch_loss: 2.011702 \n",
      "Batch: 2354. Acc: 0.270633. Loss: 2.111870. Batch_acc: 0.290649. Batch_loss: 2.026500 \n",
      "Batch: 2355. Acc: 0.270637. Loss: 2.111843. Batch_acc: 0.281268. Batch_loss: 2.048245 \n",
      "Batch: 2356. Acc: 0.270651. Loss: 2.111804. Batch_acc: 0.303939. Batch_loss: 2.016631 \n",
      "Batch: 2357. Acc: 0.270668. Loss: 2.111761. Batch_acc: 0.310404. Batch_loss: 2.012067 \n",
      "Batch: 2358. Acc: 0.270682. Loss: 2.111719. Batch_acc: 0.304273. Batch_loss: 2.011708 \n",
      "Batch: 2359. Acc: 0.270692. Loss: 2.111696. Batch_acc: 0.292245. Batch_loss: 2.057819 \n",
      "Batch: 2360. Acc: 0.270707. Loss: 2.111662. Batch_acc: 0.306122. Batch_loss: 2.032249 \n",
      "Batch: 2361. Acc: 0.270717. Loss: 2.111625. Batch_acc: 0.295535. Batch_loss: 2.022446 \n",
      "Batch: 2362. Acc: 0.270734. Loss: 2.111581. Batch_acc: 0.311073. Batch_loss: 2.009030 \n",
      "Batch: 2363. Acc: 0.270744. Loss: 2.111554. Batch_acc: 0.292655. Batch_loss: 2.047504 \n",
      "Batch: 2364. Acc: 0.270756. Loss: 2.111516. Batch_acc: 0.298791. Batch_loss: 2.021698 \n",
      "Batch: 2365. Acc: 0.270764. Loss: 2.111470. Batch_acc: 0.290212. Batch_loss: 2.005085 \n",
      "Batch: 2366. Acc: 0.270777. Loss: 2.111434. Batch_acc: 0.302684. Batch_loss: 2.027221 \n",
      "Batch: 2367. Acc: 0.270787. Loss: 2.111384. Batch_acc: 0.294118. Batch_loss: 1.991428 \n",
      "Batch: 2368. Acc: 0.270796. Loss: 2.111338. Batch_acc: 0.292415. Batch_loss: 2.002431 \n",
      "Batch: 2369. Acc: 0.270809. Loss: 2.111306. Batch_acc: 0.299718. Batch_loss: 2.037110 \n",
      "Batch: 2370. Acc: 0.270826. Loss: 2.111254. Batch_acc: 0.310246. Batch_loss: 1.989235 \n",
      "Batch: 2371. Acc: 0.270851. Loss: 2.111193. Batch_acc: 0.331618. Batch_loss: 1.965940 \n",
      "Batch: 2372. Acc: 0.270863. Loss: 2.111161. Batch_acc: 0.299823. Batch_loss: 2.033040 \n",
      "Batch: 2373. Acc: 0.270873. Loss: 2.111135. Batch_acc: 0.293427. Batch_loss: 2.049626 \n",
      "Batch: 2374. Acc: 0.270888. Loss: 2.111087. Batch_acc: 0.306742. Batch_loss: 1.999928 \n",
      "Batch: 2375. Acc: 0.270908. Loss: 2.111042. Batch_acc: 0.317621. Batch_loss: 2.005099 \n",
      "Batch: 2376. Acc: 0.270922. Loss: 2.111015. Batch_acc: 0.303730. Batch_loss: 2.046592 \n",
      "Batch: 2377. Acc: 0.270941. Loss: 2.110963. Batch_acc: 0.315878. Batch_loss: 1.988366 \n",
      "Batch: 2378. Acc: 0.270950. Loss: 2.110918. Batch_acc: 0.292486. Batch_loss: 2.004780 \n",
      "Batch: 2379. Acc: 0.270961. Loss: 2.110875. Batch_acc: 0.296064. Batch_loss: 2.009492 \n",
      "Batch: 2380. Acc: 0.270975. Loss: 2.110826. Batch_acc: 0.304398. Batch_loss: 1.992114 \n",
      "Batch: 2381. Acc: 0.270994. Loss: 2.110777. Batch_acc: 0.316820. Batch_loss: 1.996008 \n",
      "Batch: 2382. Acc: 0.271008. Loss: 2.110749. Batch_acc: 0.303237. Batch_loss: 2.044484 \n",
      "Batch: 2383. Acc: 0.271015. Loss: 2.110730. Batch_acc: 0.288375. Batch_loss: 2.066160 \n",
      "Batch: 2384. Acc: 0.271026. Loss: 2.110704. Batch_acc: 0.298184. Batch_loss: 2.047914 \n",
      "Batch: 2385. Acc: 0.271035. Loss: 2.110669. Batch_acc: 0.292148. Batch_loss: 2.025592 \n",
      "Batch: 2386. Acc: 0.271044. Loss: 2.110638. Batch_acc: 0.292025. Batch_loss: 2.038316 \n",
      "Batch: 2387. Acc: 0.271050. Loss: 2.110614. Batch_acc: 0.284890. Batch_loss: 2.052912 \n",
      "Batch: 2388. Acc: 0.271060. Loss: 2.110574. Batch_acc: 0.295302. Batch_loss: 2.018343 \n",
      "Batch: 2389. Acc: 0.271068. Loss: 2.110534. Batch_acc: 0.290643. Batch_loss: 2.012018 \n",
      "Batch: 2390. Acc: 0.271080. Loss: 2.110501. Batch_acc: 0.300524. Batch_loss: 2.031768 \n",
      "Batch: 2391. Acc: 0.271089. Loss: 2.110488. Batch_acc: 0.290632. Batch_loss: 2.079978 \n",
      "Batch: 2392. Acc: 0.271104. Loss: 2.110460. Batch_acc: 0.309290. Batch_loss: 2.042175 \n",
      "Batch: 2393. Acc: 0.271112. Loss: 2.110434. Batch_acc: 0.288396. Batch_loss: 2.048464 \n",
      "Batch: 2394. Acc: 0.271124. Loss: 2.110400. Batch_acc: 0.299374. Batch_loss: 2.031676 \n",
      "Batch: 2395. Acc: 0.271133. Loss: 2.110374. Batch_acc: 0.293403. Batch_loss: 2.047193 \n",
      "Batch: 2396. Acc: 0.271138. Loss: 2.110353. Batch_acc: 0.284382. Batch_loss: 2.059779 \n",
      "Batch: 2397. Acc: 0.271142. Loss: 2.110319. Batch_acc: 0.279953. Batch_loss: 2.026121 \n",
      "Batch: 2398. Acc: 0.271156. Loss: 2.110266. Batch_acc: 0.304961. Batch_loss: 1.987341 \n",
      "Batch: 2399. Acc: 0.271167. Loss: 2.110252. Batch_acc: 0.296820. Batch_loss: 2.074251 \n",
      "Batch: 2400. Acc: 0.271181. Loss: 2.110225. Batch_acc: 0.305491. Batch_loss: 2.044654 \n",
      "Batch: 2401. Acc: 0.271198. Loss: 2.110182. Batch_acc: 0.312204. Batch_loss: 2.004607 \n",
      "Batch: 2402. Acc: 0.271203. Loss: 2.110153. Batch_acc: 0.285211. Batch_loss: 2.038569 \n",
      "Batch: 2403. Acc: 0.271213. Loss: 2.110120. Batch_acc: 0.293541. Batch_loss: 2.030026 \n",
      "Batch: 2404. Acc: 0.271223. Loss: 2.110093. Batch_acc: 0.295082. Batch_loss: 2.046538 \n",
      "Batch: 2405. Acc: 0.271240. Loss: 2.110036. Batch_acc: 0.313748. Batch_loss: 1.975164 \n",
      "Batch: 2406. Acc: 0.271248. Loss: 2.110007. Batch_acc: 0.289290. Batch_loss: 2.038417 \n",
      "Batch: 2407. Acc: 0.271259. Loss: 2.109975. Batch_acc: 0.298957. Batch_loss: 2.033994 \n",
      "Batch: 2408. Acc: 0.271273. Loss: 2.109937. Batch_acc: 0.304724. Batch_loss: 2.016742 \n",
      "Batch: 2409. Acc: 0.271293. Loss: 2.109898. Batch_acc: 0.320710. Batch_loss: 2.014572 \n",
      "Batch: 2410. Acc: 0.271302. Loss: 2.109874. Batch_acc: 0.292469. Batch_loss: 2.050465 \n",
      "Batch: 2411. Acc: 0.271322. Loss: 2.109811. Batch_acc: 0.318669. Batch_loss: 1.960401 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2412. Acc: 0.271338. Loss: 2.109764. Batch_acc: 0.310130. Batch_loss: 1.998022 \n",
      "Batch: 2413. Acc: 0.271349. Loss: 2.109725. Batch_acc: 0.296659. Batch_loss: 2.017631 \n",
      "Batch: 2414. Acc: 0.271357. Loss: 2.109695. Batch_acc: 0.291325. Batch_loss: 2.034971 \n",
      "Batch: 2415. Acc: 0.271368. Loss: 2.109651. Batch_acc: 0.298083. Batch_loss: 2.002956 \n",
      "Batch: 2416. Acc: 0.271376. Loss: 2.109621. Batch_acc: 0.292290. Batch_loss: 2.036104 \n",
      "Batch: 2417. Acc: 0.271396. Loss: 2.109575. Batch_acc: 0.319429. Batch_loss: 1.999953 \n",
      "Batch: 2418. Acc: 0.271406. Loss: 2.109552. Batch_acc: 0.293310. Batch_loss: 2.052764 \n",
      "Batch: 2419. Acc: 0.271416. Loss: 2.109513. Batch_acc: 0.295807. Batch_loss: 2.016397 \n",
      "Batch: 2420. Acc: 0.271430. Loss: 2.109476. Batch_acc: 0.305910. Batch_loss: 2.020319 \n",
      "Batch: 2421. Acc: 0.271436. Loss: 2.109437. Batch_acc: 0.287522. Batch_loss: 2.014175 \n",
      "Batch: 2422. Acc: 0.271448. Loss: 2.109395. Batch_acc: 0.298791. Batch_loss: 2.007210 \n",
      "Batch: 2423. Acc: 0.271459. Loss: 2.109358. Batch_acc: 0.299425. Batch_loss: 2.020426 \n",
      "Batch: 2424. Acc: 0.271470. Loss: 2.109322. Batch_acc: 0.298133. Batch_loss: 2.021763 \n",
      "Batch: 2425. Acc: 0.271484. Loss: 2.109288. Batch_acc: 0.305848. Batch_loss: 2.023883 \n",
      "Batch: 2426. Acc: 0.271492. Loss: 2.109244. Batch_acc: 0.290629. Batch_loss: 2.000051 \n",
      "Batch: 2427. Acc: 0.271508. Loss: 2.109202. Batch_acc: 0.312172. Batch_loss: 2.005204 \n",
      "Batch: 2428. Acc: 0.271527. Loss: 2.109138. Batch_acc: 0.317073. Batch_loss: 1.957076 \n",
      "Batch: 2429. Acc: 0.271540. Loss: 2.109095. Batch_acc: 0.303013. Batch_loss: 2.005384 \n",
      "Batch: 2430. Acc: 0.271552. Loss: 2.109055. Batch_acc: 0.299547. Batch_loss: 2.013215 \n",
      "Batch: 2431. Acc: 0.271562. Loss: 2.109018. Batch_acc: 0.295831. Batch_loss: 2.020830 \n",
      "Batch: 2432. Acc: 0.271568. Loss: 2.108990. Batch_acc: 0.284655. Batch_loss: 2.040715 \n",
      "Batch: 2433. Acc: 0.271573. Loss: 2.108972. Batch_acc: 0.283958. Batch_loss: 2.063487 \n",
      "Batch: 2434. Acc: 0.271584. Loss: 2.108935. Batch_acc: 0.299262. Batch_loss: 2.020950 \n",
      "Batch: 2435. Acc: 0.271590. Loss: 2.108911. Batch_acc: 0.286799. Batch_loss: 2.048399 \n",
      "Batch: 2436. Acc: 0.271602. Loss: 2.108883. Batch_acc: 0.300799. Batch_loss: 2.043339 \n",
      "Batch: 2437. Acc: 0.271615. Loss: 2.108853. Batch_acc: 0.301560. Batch_loss: 2.034053 \n",
      "Batch: 2438. Acc: 0.271625. Loss: 2.108818. Batch_acc: 0.296785. Batch_loss: 2.024421 \n",
      "Batch: 2439. Acc: 0.271635. Loss: 2.108779. Batch_acc: 0.295139. Batch_loss: 2.011727 \n",
      "Batch: 2440. Acc: 0.271643. Loss: 2.108731. Batch_acc: 0.292986. Batch_loss: 1.995567 \n",
      "Batch: 2441. Acc: 0.271652. Loss: 2.108701. Batch_acc: 0.293980. Batch_loss: 2.032462 \n",
      "Batch: 2442. Acc: 0.271658. Loss: 2.108670. Batch_acc: 0.285960. Batch_loss: 2.033700 \n",
      "Batch: 2443. Acc: 0.271668. Loss: 2.108623. Batch_acc: 0.295119. Batch_loss: 1.996685 \n",
      "Batch: 2444. Acc: 0.271676. Loss: 2.108591. Batch_acc: 0.291279. Batch_loss: 2.028611 \n",
      "Batch: 2445. Acc: 0.271685. Loss: 2.108566. Batch_acc: 0.293782. Batch_loss: 2.048450 \n",
      "Batch: 2446. Acc: 0.271696. Loss: 2.108526. Batch_acc: 0.297688. Batch_loss: 2.009504 \n",
      "Batch: 2447. Acc: 0.271706. Loss: 2.108488. Batch_acc: 0.296023. Batch_loss: 2.018017 \n",
      "Batch: 2448. Acc: 0.271719. Loss: 2.108461. Batch_acc: 0.304651. Batch_loss: 2.039547 \n",
      "Batch: 2449. Acc: 0.271736. Loss: 2.108411. Batch_acc: 0.312248. Batch_loss: 1.986296 \n",
      "Batch: 2450. Acc: 0.271745. Loss: 2.108368. Batch_acc: 0.294560. Batch_loss: 2.003065 \n",
      "Batch: 2451. Acc: 0.271760. Loss: 2.108328. Batch_acc: 0.307256. Batch_loss: 2.011803 \n",
      "Batch: 2452. Acc: 0.271772. Loss: 2.108292. Batch_acc: 0.302405. Batch_loss: 2.020034 \n",
      "Batch: 2453. Acc: 0.271784. Loss: 2.108257. Batch_acc: 0.300173. Batch_loss: 2.023254 \n",
      "Batch: 2454. Acc: 0.271796. Loss: 2.108219. Batch_acc: 0.301689. Batch_loss: 2.014550 \n",
      "Batch: 2455. Acc: 0.271803. Loss: 2.108189. Batch_acc: 0.288724. Batch_loss: 2.034937 \n",
      "Batch: 2456. Acc: 0.271814. Loss: 2.108149. Batch_acc: 0.300117. Batch_loss: 2.008969 \n",
      "Batch: 2457. Acc: 0.271825. Loss: 2.108102. Batch_acc: 0.298831. Batch_loss: 1.996060 \n",
      "Batch: 2458. Acc: 0.271829. Loss: 2.108080. Batch_acc: 0.280532. Batch_loss: 2.050266 \n",
      "Batch: 2459. Acc: 0.271841. Loss: 2.108047. Batch_acc: 0.300571. Batch_loss: 2.028533 \n",
      "Batch: 2460. Acc: 0.271846. Loss: 2.108036. Batch_acc: 0.286557. Batch_loss: 2.078779 \n",
      "Batch: 2461. Acc: 0.271852. Loss: 2.108009. Batch_acc: 0.284962. Batch_loss: 2.041859 \n",
      "Batch: 2462. Acc: 0.271858. Loss: 2.107981. Batch_acc: 0.287209. Batch_loss: 2.036590 \n",
      "Batch: 2463. Acc: 0.271869. Loss: 2.107945. Batch_acc: 0.300948. Batch_loss: 2.017673 \n",
      "Batch: 2464. Acc: 0.271884. Loss: 2.107901. Batch_acc: 0.308671. Batch_loss: 2.000254 \n",
      "Batch: 2465. Acc: 0.271899. Loss: 2.107867. Batch_acc: 0.308362. Batch_loss: 2.021473 \n",
      "Batch: 2466. Acc: 0.271911. Loss: 2.107827. Batch_acc: 0.301578. Batch_loss: 2.008697 \n",
      "Batch: 2467. Acc: 0.271921. Loss: 2.107794. Batch_acc: 0.296339. Batch_loss: 2.025357 \n",
      "Batch: 2468. Acc: 0.271934. Loss: 2.107752. Batch_acc: 0.305172. Batch_loss: 2.005530 \n",
      "Batch: 2469. Acc: 0.271943. Loss: 2.107714. Batch_acc: 0.294382. Batch_loss: 2.015776 \n",
      "Batch: 2470. Acc: 0.271949. Loss: 2.107687. Batch_acc: 0.284424. Batch_loss: 2.042247 \n",
      "Batch: 2471. Acc: 0.271965. Loss: 2.107638. Batch_acc: 0.312395. Batch_loss: 1.990847 \n",
      "Batch: 2472. Acc: 0.271973. Loss: 2.107610. Batch_acc: 0.290603. Batch_loss: 2.036302 \n",
      "Batch: 2473. Acc: 0.271989. Loss: 2.107563. Batch_acc: 0.312251. Batch_loss: 1.992652 \n",
      "Batch: 2474. Acc: 0.272001. Loss: 2.107520. Batch_acc: 0.300115. Batch_loss: 2.001716 \n",
      "Batch: 2475. Acc: 0.272013. Loss: 2.107485. Batch_acc: 0.302526. Batch_loss: 2.020797 \n",
      "Batch: 2476. Acc: 0.272020. Loss: 2.107457. Batch_acc: 0.290285. Batch_loss: 2.037060 \n",
      "Batch: 2477. Acc: 0.272032. Loss: 2.107421. Batch_acc: 0.300407. Batch_loss: 2.017448 \n",
      "Batch: 2478. Acc: 0.272045. Loss: 2.107377. Batch_acc: 0.305233. Batch_loss: 1.998298 \n",
      "Batch: 2479. Acc: 0.272059. Loss: 2.107343. Batch_acc: 0.306798. Batch_loss: 2.020157 \n",
      "Batch: 2480. Acc: 0.272069. Loss: 2.107319. Batch_acc: 0.298378. Batch_loss: 2.048084 \n",
      "Batch: 2481. Acc: 0.272082. Loss: 2.107290. Batch_acc: 0.302943. Batch_loss: 2.035586 \n",
      "Batch: 2482. Acc: 0.272092. Loss: 2.107256. Batch_acc: 0.298226. Batch_loss: 2.023305 \n",
      "Batch: 2483. Acc: 0.272112. Loss: 2.107196. Batch_acc: 0.318436. Batch_loss: 1.961523 \n",
      "Batch: 2484. Acc: 0.272125. Loss: 2.107146. Batch_acc: 0.304773. Batch_loss: 1.984406 \n",
      "Batch: 2485. Acc: 0.272135. Loss: 2.107120. Batch_acc: 0.297619. Batch_loss: 2.039593 \n",
      "Batch: 2486. Acc: 0.272146. Loss: 2.107089. Batch_acc: 0.301458. Batch_loss: 2.028914 \n",
      "Batch: 2487. Acc: 0.272154. Loss: 2.107064. Batch_acc: 0.292442. Batch_loss: 2.044996 \n",
      "Batch: 2488. Acc: 0.272166. Loss: 2.107022. Batch_acc: 0.301267. Batch_loss: 2.001455 \n",
      "Batch: 2489. Acc: 0.272178. Loss: 2.106986. Batch_acc: 0.300731. Batch_loss: 2.019887 \n",
      "Batch: 2490. Acc: 0.272186. Loss: 2.106957. Batch_acc: 0.292994. Batch_loss: 2.035400 \n",
      "Batch: 2491. Acc: 0.272198. Loss: 2.106920. Batch_acc: 0.302715. Batch_loss: 2.012537 \n",
      "Batch: 2492. Acc: 0.272209. Loss: 2.106876. Batch_acc: 0.299492. Batch_loss: 2.001101 \n",
      "Batch: 2493. Acc: 0.272225. Loss: 2.106829. Batch_acc: 0.311277. Batch_loss: 1.989406 \n",
      "Batch: 2494. Acc: 0.272237. Loss: 2.106787. Batch_acc: 0.301876. Batch_loss: 2.003053 \n",
      "Batch: 2495. Acc: 0.272249. Loss: 2.106752. Batch_acc: 0.301346. Batch_loss: 2.017768 \n",
      "Batch: 2496. Acc: 0.272263. Loss: 2.106704. Batch_acc: 0.307256. Batch_loss: 1.988627 \n",
      "Batch: 2497. Acc: 0.272267. Loss: 2.106678. Batch_acc: 0.282997. Batch_loss: 2.042755 \n",
      "Batch: 2498. Acc: 0.272283. Loss: 2.106633. Batch_acc: 0.310598. Batch_loss: 1.996587 \n",
      "Batch: 2499. Acc: 0.272296. Loss: 2.106582. Batch_acc: 0.304878. Batch_loss: 1.977651 \n",
      "Batch: 2500. Acc: 0.272312. Loss: 2.106545. Batch_acc: 0.313749. Batch_loss: 2.010796 \n",
      "Batch: 2501. Acc: 0.272324. Loss: 2.106501. Batch_acc: 0.301293. Batch_loss: 1.999172 \n",
      "Batch: 2502. Acc: 0.272329. Loss: 2.106470. Batch_acc: 0.286804. Batch_loss: 2.028694 \n",
      "Batch: 2503. Acc: 0.272335. Loss: 2.106452. Batch_acc: 0.285213. Batch_loss: 2.059643 \n",
      "Batch: 2504. Acc: 0.272346. Loss: 2.106412. Batch_acc: 0.301854. Batch_loss: 2.005248 \n",
      "Batch: 2505. Acc: 0.272352. Loss: 2.106379. Batch_acc: 0.287711. Batch_loss: 2.022916 \n",
      "Batch: 2506. Acc: 0.272366. Loss: 2.106332. Batch_acc: 0.307127. Batch_loss: 1.990655 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2507. Acc: 0.272375. Loss: 2.106294. Batch_acc: 0.295468. Batch_loss: 2.008174 \n",
      "Batch: 2508. Acc: 0.272383. Loss: 2.106271. Batch_acc: 0.290548. Batch_loss: 2.049758 \n",
      "Batch: 2509. Acc: 0.272387. Loss: 2.106251. Batch_acc: 0.283520. Batch_loss: 2.052705 \n",
      "Batch: 2510. Acc: 0.272398. Loss: 2.106214. Batch_acc: 0.299941. Batch_loss: 2.013560 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.27239767711664703. Loss per char: 2.106214328627817. Time: 1627204534.3936124\n",
      "Last question is tensor([ 2, 19, 20, 22, 19, 22, 18, 18, 17, 12, 14, 22, 17, 25,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.272404. Loss: 2.106194. Batch_acc: 0.289550. Batch_loss: 2.053370 \n",
      "Batch: 2512. Acc: 0.272425. Loss: 2.106148. Batch_acc: 0.323377. Batch_loss: 1.990680 \n",
      "Batch: 2513. Acc: 0.272435. Loss: 2.106111. Batch_acc: 0.297885. Batch_loss: 2.015466 \n",
      "Batch: 2514. Acc: 0.272446. Loss: 2.106080. Batch_acc: 0.301679. Batch_loss: 2.028116 \n",
      "Batch: 2515. Acc: 0.272457. Loss: 2.106043. Batch_acc: 0.300000. Batch_loss: 2.011279 \n",
      "Batch: 2516. Acc: 0.272465. Loss: 2.106016. Batch_acc: 0.291840. Batch_loss: 2.035427 \n",
      "Batch: 2517. Acc: 0.272479. Loss: 2.105985. Batch_acc: 0.307295. Batch_loss: 2.029290 \n",
      "Batch: 2518. Acc: 0.272495. Loss: 2.105936. Batch_acc: 0.313657. Batch_loss: 1.980673 \n",
      "Batch: 2519. Acc: 0.272500. Loss: 2.105903. Batch_acc: 0.284742. Batch_loss: 2.025996 \n",
      "Batch: 2520. Acc: 0.272507. Loss: 2.105886. Batch_acc: 0.291642. Batch_loss: 2.060637 \n",
      "Batch: 2521. Acc: 0.272521. Loss: 2.105848. Batch_acc: 0.306735. Batch_loss: 2.012457 \n",
      "Batch: 2522. Acc: 0.272538. Loss: 2.105807. Batch_acc: 0.314901. Batch_loss: 2.001719 \n",
      "Batch: 2523. Acc: 0.272555. Loss: 2.105766. Batch_acc: 0.315638. Batch_loss: 2.002227 \n",
      "Batch: 2524. Acc: 0.272570. Loss: 2.105735. Batch_acc: 0.309255. Batch_loss: 2.029116 \n",
      "Batch: 2525. Acc: 0.272586. Loss: 2.105684. Batch_acc: 0.314400. Batch_loss: 1.977409 \n",
      "Batch: 2526. Acc: 0.272598. Loss: 2.105643. Batch_acc: 0.299834. Batch_loss: 2.005259 \n",
      "Batch: 2527. Acc: 0.272615. Loss: 2.105590. Batch_acc: 0.314763. Batch_loss: 1.975336 \n",
      "Batch: 2528. Acc: 0.272623. Loss: 2.105552. Batch_acc: 0.293882. Batch_loss: 2.011316 \n",
      "Batch: 2529. Acc: 0.272635. Loss: 2.105513. Batch_acc: 0.302299. Batch_loss: 2.005562 \n",
      "Batch: 2530. Acc: 0.272648. Loss: 2.105475. Batch_acc: 0.305493. Batch_loss: 2.012144 \n",
      "Batch: 2531. Acc: 0.272653. Loss: 2.105451. Batch_acc: 0.284398. Batch_loss: 2.045705 \n",
      "Batch: 2532. Acc: 0.272660. Loss: 2.105428. Batch_acc: 0.291811. Batch_loss: 2.047837 \n",
      "Batch: 2533. Acc: 0.272670. Loss: 2.105395. Batch_acc: 0.294697. Batch_loss: 2.025283 \n",
      "Batch: 2534. Acc: 0.272682. Loss: 2.105354. Batch_acc: 0.304822. Batch_loss: 2.000057 \n",
      "Batch: 2535. Acc: 0.272697. Loss: 2.105314. Batch_acc: 0.309361. Batch_loss: 2.005618 \n",
      "Batch: 2536. Acc: 0.272703. Loss: 2.105297. Batch_acc: 0.289271. Batch_loss: 2.060041 \n",
      "Batch: 2537. Acc: 0.272715. Loss: 2.105268. Batch_acc: 0.302053. Batch_loss: 2.030889 \n",
      "Batch: 2538. Acc: 0.272728. Loss: 2.105227. Batch_acc: 0.308049. Batch_loss: 2.001894 \n",
      "Batch: 2539. Acc: 0.272736. Loss: 2.105186. Batch_acc: 0.292378. Batch_loss: 2.002303 \n",
      "Batch: 2540. Acc: 0.272752. Loss: 2.105136. Batch_acc: 0.311411. Batch_loss: 1.979960 \n",
      "Batch: 2541. Acc: 0.272762. Loss: 2.105086. Batch_acc: 0.298315. Batch_loss: 1.981909 \n",
      "Batch: 2542. Acc: 0.272781. Loss: 2.105045. Batch_acc: 0.319909. Batch_loss: 2.002856 \n",
      "Batch: 2543. Acc: 0.272796. Loss: 2.104995. Batch_acc: 0.311927. Batch_loss: 1.976669 \n",
      "Batch: 2544. Acc: 0.272809. Loss: 2.104959. Batch_acc: 0.305491. Batch_loss: 2.011466 \n",
      "Batch: 2545. Acc: 0.272818. Loss: 2.104933. Batch_acc: 0.294664. Batch_loss: 2.038465 \n",
      "Batch: 2546. Acc: 0.272827. Loss: 2.104894. Batch_acc: 0.297101. Batch_loss: 2.010579 \n",
      "Batch: 2547. Acc: 0.272842. Loss: 2.104845. Batch_acc: 0.309028. Batch_loss: 1.977823 \n",
      "Batch: 2548. Acc: 0.272859. Loss: 2.104802. Batch_acc: 0.318021. Batch_loss: 1.993147 \n",
      "Batch: 2549. Acc: 0.272868. Loss: 2.104763. Batch_acc: 0.296147. Batch_loss: 2.006328 \n",
      "Batch: 2550. Acc: 0.272876. Loss: 2.104723. Batch_acc: 0.292935. Batch_loss: 2.002852 \n",
      "Batch: 2551. Acc: 0.272892. Loss: 2.104673. Batch_acc: 0.311558. Batch_loss: 1.980528 \n",
      "Batch: 2552. Acc: 0.272907. Loss: 2.104643. Batch_acc: 0.312862. Batch_loss: 2.027954 \n",
      "Batch: 2553. Acc: 0.272924. Loss: 2.104593. Batch_acc: 0.315285. Batch_loss: 1.978012 \n",
      "Batch: 2554. Acc: 0.272942. Loss: 2.104543. Batch_acc: 0.320000. Batch_loss: 1.976223 \n",
      "Batch: 2555. Acc: 0.272954. Loss: 2.104495. Batch_acc: 0.301714. Batch_loss: 1.983285 \n",
      "Batch: 2556. Acc: 0.272969. Loss: 2.104449. Batch_acc: 0.312464. Batch_loss: 1.987845 \n",
      "Batch: 2557. Acc: 0.272978. Loss: 2.104415. Batch_acc: 0.294185. Batch_loss: 2.018338 \n",
      "Batch: 2558. Acc: 0.272986. Loss: 2.104383. Batch_acc: 0.293541. Batch_loss: 2.022467 \n",
      "Batch: 2559. Acc: 0.273000. Loss: 2.104344. Batch_acc: 0.308523. Batch_loss: 2.005852 \n",
      "Batch: 2560. Acc: 0.273008. Loss: 2.104307. Batch_acc: 0.295139. Batch_loss: 2.008113 \n",
      "Batch: 2561. Acc: 0.273019. Loss: 2.104268. Batch_acc: 0.299707. Batch_loss: 2.002417 \n",
      "Batch: 2562. Acc: 0.273027. Loss: 2.104234. Batch_acc: 0.295783. Batch_loss: 2.016657 \n",
      "Batch: 2563. Acc: 0.273040. Loss: 2.104193. Batch_acc: 0.305809. Batch_loss: 2.000125 \n",
      "Batch: 2564. Acc: 0.273055. Loss: 2.104158. Batch_acc: 0.309226. Batch_loss: 2.015917 \n",
      "Batch: 2565. Acc: 0.273066. Loss: 2.104122. Batch_acc: 0.303082. Batch_loss: 2.013955 \n",
      "Batch: 2566. Acc: 0.273083. Loss: 2.104080. Batch_acc: 0.315068. Batch_loss: 1.997233 \n",
      "Batch: 2567. Acc: 0.273095. Loss: 2.104050. Batch_acc: 0.306062. Batch_loss: 2.024510 \n",
      "Batch: 2568. Acc: 0.273107. Loss: 2.104019. Batch_acc: 0.302669. Batch_loss: 2.026312 \n",
      "Batch: 2569. Acc: 0.273117. Loss: 2.103974. Batch_acc: 0.297762. Batch_loss: 1.987734 \n",
      "Batch: 2570. Acc: 0.273128. Loss: 2.103932. Batch_acc: 0.302669. Batch_loss: 1.997912 \n",
      "Batch: 2571. Acc: 0.273140. Loss: 2.103892. Batch_acc: 0.302312. Batch_loss: 2.001927 \n",
      "Batch: 2572. Acc: 0.273148. Loss: 2.103857. Batch_acc: 0.292490. Batch_loss: 2.015053 \n",
      "Batch: 2573. Acc: 0.273158. Loss: 2.103818. Batch_acc: 0.300575. Batch_loss: 2.004971 \n",
      "Batch: 2574. Acc: 0.273164. Loss: 2.103794. Batch_acc: 0.287471. Batch_loss: 2.040176 \n",
      "Batch: 2575. Acc: 0.273183. Loss: 2.103743. Batch_acc: 0.321569. Batch_loss: 1.976888 \n",
      "Batch: 2576. Acc: 0.273196. Loss: 2.103700. Batch_acc: 0.306536. Batch_loss: 1.992693 \n",
      "Batch: 2577. Acc: 0.273207. Loss: 2.103659. Batch_acc: 0.301699. Batch_loss: 1.994354 \n",
      "Batch: 2578. Acc: 0.273220. Loss: 2.103617. Batch_acc: 0.307391. Batch_loss: 1.998749 \n",
      "Batch: 2579. Acc: 0.273227. Loss: 2.103590. Batch_acc: 0.290155. Batch_loss: 2.033131 \n",
      "Batch: 2580. Acc: 0.273235. Loss: 2.103561. Batch_acc: 0.293294. Batch_loss: 2.028678 \n",
      "Batch: 2581. Acc: 0.273245. Loss: 2.103528. Batch_acc: 0.301624. Batch_loss: 2.018857 \n",
      "Batch: 2582. Acc: 0.273254. Loss: 2.103492. Batch_acc: 0.296318. Batch_loss: 2.008930 \n",
      "Batch: 2583. Acc: 0.273267. Loss: 2.103461. Batch_acc: 0.304948. Batch_loss: 2.022655 \n",
      "Batch: 2584. Acc: 0.273274. Loss: 2.103429. Batch_acc: 0.293427. Batch_loss: 2.019899 \n",
      "Batch: 2585. Acc: 0.273281. Loss: 2.103408. Batch_acc: 0.290509. Batch_loss: 2.047975 \n",
      "Batch: 2586. Acc: 0.273284. Loss: 2.103394. Batch_acc: 0.281342. Batch_loss: 2.065726 \n",
      "Batch: 2587. Acc: 0.273294. Loss: 2.103358. Batch_acc: 0.299883. Batch_loss: 2.008001 \n",
      "Batch: 2588. Acc: 0.273302. Loss: 2.103330. Batch_acc: 0.293242. Batch_loss: 2.030836 \n",
      "Batch: 2589. Acc: 0.273310. Loss: 2.103303. Batch_acc: 0.296232. Batch_loss: 2.033380 \n",
      "Batch: 2590. Acc: 0.273319. Loss: 2.103275. Batch_acc: 0.295167. Batch_loss: 2.032579 \n",
      "Batch: 2591. Acc: 0.273326. Loss: 2.103242. Batch_acc: 0.291357. Batch_loss: 2.017989 \n",
      "Batch: 2592. Acc: 0.273335. Loss: 2.103214. Batch_acc: 0.297824. Batch_loss: 2.029542 \n",
      "Batch: 2593. Acc: 0.273349. Loss: 2.103178. Batch_acc: 0.308438. Batch_loss: 2.011528 \n",
      "Batch: 2594. Acc: 0.273351. Loss: 2.103165. Batch_acc: 0.278884. Batch_loss: 2.068801 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2595. Acc: 0.273365. Loss: 2.103135. Batch_acc: 0.307003. Batch_loss: 2.027292 \n",
      "Batch: 2596. Acc: 0.273375. Loss: 2.103097. Batch_acc: 0.299367. Batch_loss: 2.004561 \n",
      "Batch: 2597. Acc: 0.273386. Loss: 2.103060. Batch_acc: 0.303922. Batch_loss: 2.006965 \n",
      "Batch: 2598. Acc: 0.273396. Loss: 2.103032. Batch_acc: 0.297592. Batch_loss: 2.030684 \n",
      "Batch: 2599. Acc: 0.273407. Loss: 2.102993. Batch_acc: 0.302943. Batch_loss: 2.001014 \n",
      "Batch: 2600. Acc: 0.273414. Loss: 2.102957. Batch_acc: 0.291406. Batch_loss: 2.010351 \n",
      "Batch: 2601. Acc: 0.273437. Loss: 2.102908. Batch_acc: 0.333333. Batch_loss: 1.975610 \n",
      "Batch: 2602. Acc: 0.273450. Loss: 2.102871. Batch_acc: 0.306953. Batch_loss: 2.007733 \n",
      "Batch: 2603. Acc: 0.273469. Loss: 2.102828. Batch_acc: 0.321267. Batch_loss: 1.993047 \n",
      "Batch: 2604. Acc: 0.273480. Loss: 2.102787. Batch_acc: 0.301533. Batch_loss: 1.998451 \n",
      "Batch: 2605. Acc: 0.273491. Loss: 2.102750. Batch_acc: 0.304019. Batch_loss: 2.004293 \n",
      "Batch: 2606. Acc: 0.273500. Loss: 2.102711. Batch_acc: 0.296317. Batch_loss: 2.002460 \n",
      "Batch: 2607. Acc: 0.273510. Loss: 2.102677. Batch_acc: 0.298812. Batch_loss: 2.016737 \n",
      "Batch: 2608. Acc: 0.273519. Loss: 2.102648. Batch_acc: 0.298981. Batch_loss: 2.021873 \n",
      "Batch: 2609. Acc: 0.273535. Loss: 2.102595. Batch_acc: 0.313960. Batch_loss: 1.967532 \n",
      "Batch: 2610. Acc: 0.273546. Loss: 2.102570. Batch_acc: 0.302922. Batch_loss: 2.035257 \n",
      "Batch: 2611. Acc: 0.273557. Loss: 2.102522. Batch_acc: 0.301130. Batch_loss: 1.979638 \n",
      "Batch: 2612. Acc: 0.273563. Loss: 2.102497. Batch_acc: 0.291206. Batch_loss: 2.034504 \n",
      "Batch: 2613. Acc: 0.273581. Loss: 2.102451. Batch_acc: 0.317680. Batch_loss: 1.988586 \n",
      "Batch: 2614. Acc: 0.273586. Loss: 2.102429. Batch_acc: 0.287264. Batch_loss: 2.045077 \n",
      "Batch: 2615. Acc: 0.273591. Loss: 2.102395. Batch_acc: 0.285632. Batch_loss: 2.013094 \n",
      "Batch: 2616. Acc: 0.273602. Loss: 2.102355. Batch_acc: 0.302555. Batch_loss: 1.995546 \n",
      "Batch: 2617. Acc: 0.273620. Loss: 2.102309. Batch_acc: 0.322305. Batch_loss: 1.982949 \n",
      "Batch: 2618. Acc: 0.273629. Loss: 2.102270. Batch_acc: 0.296902. Batch_loss: 1.998656 \n",
      "Batch: 2619. Acc: 0.273643. Loss: 2.102232. Batch_acc: 0.308698. Batch_loss: 2.003385 \n",
      "Batch: 2620. Acc: 0.273655. Loss: 2.102192. Batch_acc: 0.305396. Batch_loss: 1.998544 \n",
      "Batch: 2621. Acc: 0.273668. Loss: 2.102149. Batch_acc: 0.308962. Batch_loss: 1.987196 \n",
      "Batch: 2622. Acc: 0.273685. Loss: 2.102095. Batch_acc: 0.317335. Batch_loss: 1.961958 \n",
      "Batch: 2623. Acc: 0.273697. Loss: 2.102063. Batch_acc: 0.303833. Batch_loss: 2.020816 \n",
      "Batch: 2624. Acc: 0.273704. Loss: 2.102028. Batch_acc: 0.293044. Batch_loss: 2.011889 \n",
      "Batch: 2625. Acc: 0.273719. Loss: 2.101984. Batch_acc: 0.313510. Batch_loss: 1.983508 \n",
      "Batch: 2626. Acc: 0.273724. Loss: 2.101955. Batch_acc: 0.285063. Batch_loss: 2.028385 \n",
      "Batch: 2627. Acc: 0.273735. Loss: 2.101927. Batch_acc: 0.304807. Batch_loss: 2.026647 \n",
      "Batch: 2628. Acc: 0.273745. Loss: 2.101893. Batch_acc: 0.299531. Batch_loss: 2.011448 \n",
      "Batch: 2629. Acc: 0.273759. Loss: 2.101854. Batch_acc: 0.310968. Batch_loss: 1.997670 \n",
      "Batch: 2630. Acc: 0.273773. Loss: 2.101803. Batch_acc: 0.310576. Batch_loss: 1.970577 \n",
      "Batch: 2631. Acc: 0.273782. Loss: 2.101762. Batch_acc: 0.296571. Batch_loss: 1.994180 \n",
      "Batch: 2632. Acc: 0.273798. Loss: 2.101724. Batch_acc: 0.316752. Batch_loss: 2.002305 \n",
      "Batch: 2633. Acc: 0.273802. Loss: 2.101699. Batch_acc: 0.283105. Batch_loss: 2.037994 \n",
      "Batch: 2634. Acc: 0.273813. Loss: 2.101669. Batch_acc: 0.304601. Batch_loss: 2.021496 \n",
      "Batch: 2635. Acc: 0.273827. Loss: 2.101630. Batch_acc: 0.309320. Batch_loss: 1.998967 \n",
      "Batch: 2636. Acc: 0.273841. Loss: 2.101588. Batch_acc: 0.311035. Batch_loss: 1.990933 \n",
      "Batch: 2637. Acc: 0.273847. Loss: 2.101555. Batch_acc: 0.288914. Batch_loss: 2.014379 \n",
      "Batch: 2638. Acc: 0.273856. Loss: 2.101524. Batch_acc: 0.299641. Batch_loss: 2.018125 \n",
      "Batch: 2639. Acc: 0.273871. Loss: 2.101494. Batch_acc: 0.313184. Batch_loss: 2.021046 \n",
      "Batch: 2640. Acc: 0.273881. Loss: 2.101466. Batch_acc: 0.300171. Batch_loss: 2.029410 \n",
      "Batch: 2641. Acc: 0.273893. Loss: 2.101440. Batch_acc: 0.304548. Batch_loss: 2.031619 \n",
      "Batch: 2642. Acc: 0.273901. Loss: 2.101405. Batch_acc: 0.294587. Batch_loss: 2.009677 \n",
      "Batch: 2643. Acc: 0.273912. Loss: 2.101368. Batch_acc: 0.303302. Batch_loss: 2.007601 \n",
      "Batch: 2644. Acc: 0.273926. Loss: 2.101328. Batch_acc: 0.308343. Batch_loss: 1.996147 \n",
      "Batch: 2645. Acc: 0.273932. Loss: 2.101300. Batch_acc: 0.290023. Batch_loss: 2.028286 \n",
      "Batch: 2646. Acc: 0.273942. Loss: 2.101258. Batch_acc: 0.300635. Batch_loss: 1.989665 \n",
      "Batch: 2647. Acc: 0.273954. Loss: 2.101216. Batch_acc: 0.306017. Batch_loss: 1.990902 \n",
      "Batch: 2648. Acc: 0.273966. Loss: 2.101178. Batch_acc: 0.306987. Batch_loss: 2.000849 \n",
      "Batch: 2649. Acc: 0.273974. Loss: 2.101148. Batch_acc: 0.295082. Batch_loss: 2.021765 \n",
      "Batch: 2650. Acc: 0.273991. Loss: 2.101106. Batch_acc: 0.317101. Batch_loss: 1.989550 \n",
      "Batch: 2651. Acc: 0.274011. Loss: 2.101054. Batch_acc: 0.327140. Batch_loss: 1.966717 \n",
      "Batch: 2652. Acc: 0.274024. Loss: 2.101013. Batch_acc: 0.307514. Batch_loss: 1.991040 \n",
      "Batch: 2653. Acc: 0.274033. Loss: 2.100976. Batch_acc: 0.300235. Batch_loss: 2.000302 \n",
      "Batch: 2654. Acc: 0.274034. Loss: 2.100945. Batch_acc: 0.275723. Batch_loss: 2.019247 \n",
      "Batch: 2655. Acc: 0.274044. Loss: 2.100907. Batch_acc: 0.300752. Batch_loss: 1.999040 \n",
      "Batch: 2656. Acc: 0.274052. Loss: 2.100876. Batch_acc: 0.295322. Batch_loss: 2.017953 \n",
      "Batch: 2657. Acc: 0.274064. Loss: 2.100861. Batch_acc: 0.307087. Batch_loss: 2.057224 \n",
      "Batch: 2658. Acc: 0.274078. Loss: 2.100823. Batch_acc: 0.312752. Batch_loss: 1.999276 \n",
      "Batch: 2659. Acc: 0.274085. Loss: 2.100790. Batch_acc: 0.293420. Batch_loss: 2.012668 \n",
      "Batch: 2660. Acc: 0.274095. Loss: 2.100756. Batch_acc: 0.299828. Batch_loss: 2.008842 \n",
      "Batch: 2661. Acc: 0.274106. Loss: 2.100718. Batch_acc: 0.304928. Batch_loss: 1.999967 \n",
      "Batch: 2662. Acc: 0.274117. Loss: 2.100689. Batch_acc: 0.303893. Batch_loss: 2.022578 \n",
      "Batch: 2663. Acc: 0.274133. Loss: 2.100638. Batch_acc: 0.313606. Batch_loss: 1.968897 \n",
      "Batch: 2664. Acc: 0.274151. Loss: 2.100592. Batch_acc: 0.321551. Batch_loss: 1.980356 \n",
      "Batch: 2665. Acc: 0.274166. Loss: 2.100540. Batch_acc: 0.313171. Batch_loss: 1.964503 \n",
      "Batch: 2666. Acc: 0.274177. Loss: 2.100509. Batch_acc: 0.305294. Batch_loss: 2.014872 \n",
      "Batch: 2667. Acc: 0.274197. Loss: 2.100458. Batch_acc: 0.325711. Batch_loss: 1.970577 \n",
      "Batch: 2668. Acc: 0.274207. Loss: 2.100425. Batch_acc: 0.301920. Batch_loss: 2.009619 \n",
      "Batch: 2669. Acc: 0.274224. Loss: 2.100376. Batch_acc: 0.317865. Batch_loss: 1.970259 \n",
      "Batch: 2670. Acc: 0.274234. Loss: 2.100339. Batch_acc: 0.301634. Batch_loss: 1.999221 \n",
      "Batch: 2671. Acc: 0.274251. Loss: 2.100293. Batch_acc: 0.319460. Batch_loss: 1.978780 \n",
      "Batch: 2672. Acc: 0.274258. Loss: 2.100255. Batch_acc: 0.291667. Batch_loss: 2.000647 \n",
      "Batch: 2673. Acc: 0.274266. Loss: 2.100225. Batch_acc: 0.295775. Batch_loss: 2.020814 \n",
      "Batch: 2674. Acc: 0.274279. Loss: 2.100183. Batch_acc: 0.310505. Batch_loss: 1.988261 \n",
      "Batch: 2675. Acc: 0.274291. Loss: 2.100136. Batch_acc: 0.305949. Batch_loss: 1.977243 \n",
      "Batch: 2676. Acc: 0.274303. Loss: 2.100106. Batch_acc: 0.304751. Batch_loss: 2.017846 \n",
      "Batch: 2677. Acc: 0.274316. Loss: 2.100068. Batch_acc: 0.312061. Batch_loss: 1.996764 \n",
      "Batch: 2678. Acc: 0.274328. Loss: 2.100030. Batch_acc: 0.306745. Batch_loss: 1.995713 \n",
      "Batch: 2679. Acc: 0.274341. Loss: 2.099991. Batch_acc: 0.306524. Batch_loss: 1.998144 \n",
      "Batch: 2680. Acc: 0.274346. Loss: 2.099969. Batch_acc: 0.289822. Batch_loss: 2.040262 \n",
      "Batch: 2681. Acc: 0.274360. Loss: 2.099932. Batch_acc: 0.309081. Batch_loss: 2.002665 \n",
      "Batch: 2682. Acc: 0.274374. Loss: 2.099884. Batch_acc: 0.312429. Batch_loss: 1.974140 \n",
      "Batch: 2683. Acc: 0.274380. Loss: 2.099865. Batch_acc: 0.291452. Batch_loss: 2.048251 \n",
      "Batch: 2684. Acc: 0.274389. Loss: 2.099849. Batch_acc: 0.298810. Batch_loss: 2.056032 \n",
      "Batch: 2685. Acc: 0.274395. Loss: 2.099816. Batch_acc: 0.289580. Batch_loss: 2.009454 \n",
      "Batch: 2686. Acc: 0.274402. Loss: 2.099794. Batch_acc: 0.294387. Batch_loss: 2.041562 \n",
      "Batch: 2687. Acc: 0.274418. Loss: 2.099755. Batch_acc: 0.317479. Batch_loss: 1.997014 \n",
      "Batch: 2688. Acc: 0.274431. Loss: 2.099720. Batch_acc: 0.308492. Batch_loss: 2.005197 \n",
      "Batch: 2689. Acc: 0.274437. Loss: 2.099699. Batch_acc: 0.291954. Batch_loss: 2.043256 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2690. Acc: 0.274448. Loss: 2.099674. Batch_acc: 0.303219. Batch_loss: 2.031782 \n",
      "Batch: 2691. Acc: 0.274457. Loss: 2.099635. Batch_acc: 0.298236. Batch_loss: 1.996316 \n",
      "Batch: 2692. Acc: 0.274473. Loss: 2.099592. Batch_acc: 0.314992. Batch_loss: 1.987691 \n",
      "Batch: 2693. Acc: 0.274484. Loss: 2.099560. Batch_acc: 0.304248. Batch_loss: 2.013108 \n",
      "Batch: 2694. Acc: 0.274492. Loss: 2.099516. Batch_acc: 0.296064. Batch_loss: 1.983321 \n",
      "Batch: 2695. Acc: 0.274507. Loss: 2.099472. Batch_acc: 0.314693. Batch_loss: 1.984277 \n",
      "Batch: 2696. Acc: 0.274515. Loss: 2.099435. Batch_acc: 0.293258. Batch_loss: 2.001977 \n",
      "Batch: 2697. Acc: 0.274530. Loss: 2.099391. Batch_acc: 0.317681. Batch_loss: 1.981473 \n",
      "Batch: 2698. Acc: 0.274533. Loss: 2.099371. Batch_acc: 0.282286. Batch_loss: 2.045938 \n",
      "Batch: 2699. Acc: 0.274543. Loss: 2.099345. Batch_acc: 0.299194. Batch_loss: 2.028772 \n",
      "Batch: 2700. Acc: 0.274550. Loss: 2.099307. Batch_acc: 0.294828. Batch_loss: 1.997375 \n",
      "Batch: 2701. Acc: 0.274560. Loss: 2.099283. Batch_acc: 0.302632. Batch_loss: 2.032756 \n",
      "Batch: 2702. Acc: 0.274566. Loss: 2.099258. Batch_acc: 0.289550. Batch_loss: 2.030680 \n",
      "Batch: 2703. Acc: 0.274575. Loss: 2.099227. Batch_acc: 0.299718. Batch_loss: 2.018487 \n",
      "Batch: 2704. Acc: 0.274581. Loss: 2.099194. Batch_acc: 0.288340. Batch_loss: 2.010281 \n",
      "Batch: 2705. Acc: 0.274588. Loss: 2.099166. Batch_acc: 0.294828. Batch_loss: 2.023731 \n",
      "Batch: 2706. Acc: 0.274602. Loss: 2.099117. Batch_acc: 0.312852. Batch_loss: 1.968315 \n",
      "Batch: 2707. Acc: 0.274618. Loss: 2.099079. Batch_acc: 0.317506. Batch_loss: 1.996959 \n",
      "Batch: 2708. Acc: 0.274625. Loss: 2.099060. Batch_acc: 0.293034. Batch_loss: 2.048019 \n",
      "Batch: 2709. Acc: 0.274638. Loss: 2.099018. Batch_acc: 0.309745. Batch_loss: 1.984353 \n",
      "Batch: 2710. Acc: 0.274646. Loss: 2.098985. Batch_acc: 0.297267. Batch_loss: 2.010372 \n",
      "Batch: 2711. Acc: 0.274655. Loss: 2.098961. Batch_acc: 0.297251. Batch_loss: 2.034720 \n",
      "Batch: 2712. Acc: 0.274662. Loss: 2.098934. Batch_acc: 0.295216. Batch_loss: 2.023943 \n",
      "Batch: 2713. Acc: 0.274677. Loss: 2.098896. Batch_acc: 0.312713. Batch_loss: 1.997916 \n",
      "Batch: 2714. Acc: 0.274686. Loss: 2.098870. Batch_acc: 0.301386. Batch_loss: 2.026755 \n",
      "Batch: 2715. Acc: 0.274690. Loss: 2.098849. Batch_acc: 0.284308. Batch_loss: 2.043259 \n",
      "Batch: 2716. Acc: 0.274705. Loss: 2.098808. Batch_acc: 0.315061. Batch_loss: 1.984988 \n",
      "Batch: 2717. Acc: 0.274718. Loss: 2.098769. Batch_acc: 0.309948. Batch_loss: 1.994299 \n",
      "Batch: 2718. Acc: 0.274732. Loss: 2.098726. Batch_acc: 0.313901. Batch_loss: 1.985319 \n",
      "Batch: 2719. Acc: 0.274746. Loss: 2.098693. Batch_acc: 0.311021. Batch_loss: 2.008295 \n",
      "Batch: 2720. Acc: 0.274754. Loss: 2.098666. Batch_acc: 0.296782. Batch_loss: 2.022377 \n",
      "Batch: 2721. Acc: 0.274761. Loss: 2.098637. Batch_acc: 0.294387. Batch_loss: 2.020644 \n",
      "Batch: 2722. Acc: 0.274768. Loss: 2.098606. Batch_acc: 0.295351. Batch_loss: 2.014786 \n",
      "Batch: 2723. Acc: 0.274772. Loss: 2.098584. Batch_acc: 0.285223. Batch_loss: 2.039266 \n",
      "Batch: 2724. Acc: 0.274787. Loss: 2.098541. Batch_acc: 0.315514. Batch_loss: 1.981159 \n",
      "Batch: 2725. Acc: 0.274799. Loss: 2.098507. Batch_acc: 0.307737. Batch_loss: 2.002387 \n",
      "Batch: 2726. Acc: 0.274803. Loss: 2.098484. Batch_acc: 0.285131. Batch_loss: 2.035430 \n",
      "Batch: 2727. Acc: 0.274810. Loss: 2.098450. Batch_acc: 0.295260. Batch_loss: 2.007179 \n",
      "Batch: 2728. Acc: 0.274820. Loss: 2.098420. Batch_acc: 0.301297. Batch_loss: 2.013694 \n",
      "Batch: 2729. Acc: 0.274831. Loss: 2.098385. Batch_acc: 0.305330. Batch_loss: 2.001766 \n",
      "Batch: 2730. Acc: 0.274842. Loss: 2.098354. Batch_acc: 0.303754. Batch_loss: 2.015431 \n",
      "Batch: 2731. Acc: 0.274850. Loss: 2.098329. Batch_acc: 0.297544. Batch_loss: 2.029707 \n",
      "Batch: 2732. Acc: 0.274859. Loss: 2.098294. Batch_acc: 0.298456. Batch_loss: 2.004710 \n",
      "Batch: 2733. Acc: 0.274864. Loss: 2.098259. Batch_acc: 0.290623. Batch_loss: 2.000296 \n",
      "Batch: 2734. Acc: 0.274878. Loss: 2.098225. Batch_acc: 0.311124. Batch_loss: 2.006477 \n",
      "Batch: 2735. Acc: 0.274886. Loss: 2.098199. Batch_acc: 0.298392. Batch_loss: 2.025217 \n",
      "Batch: 2736. Acc: 0.274896. Loss: 2.098164. Batch_acc: 0.302890. Batch_loss: 2.003362 \n",
      "Batch: 2737. Acc: 0.274910. Loss: 2.098120. Batch_acc: 0.312571. Batch_loss: 1.977922 \n",
      "Batch: 2738. Acc: 0.274920. Loss: 2.098089. Batch_acc: 0.302258. Batch_loss: 2.013057 \n",
      "Batch: 2739. Acc: 0.274934. Loss: 2.098055. Batch_acc: 0.313314. Batch_loss: 2.004175 \n",
      "Batch: 2740. Acc: 0.274948. Loss: 2.098018. Batch_acc: 0.310325. Batch_loss: 2.000684 \n",
      "Batch: 2741. Acc: 0.274960. Loss: 2.097987. Batch_acc: 0.308262. Batch_loss: 2.014482 \n",
      "Batch: 2742. Acc: 0.274970. Loss: 2.097954. Batch_acc: 0.303848. Batch_loss: 2.005651 \n",
      "Batch: 2743. Acc: 0.274989. Loss: 2.097912. Batch_acc: 0.324417. Batch_loss: 1.985086 \n",
      "Batch: 2744. Acc: 0.274992. Loss: 2.097897. Batch_acc: 0.283401. Batch_loss: 2.057369 \n",
      "Batch: 2745. Acc: 0.275005. Loss: 2.097854. Batch_acc: 0.309835. Batch_loss: 1.980565 \n",
      "Batch: 2746. Acc: 0.275025. Loss: 2.097803. Batch_acc: 0.330870. Batch_loss: 1.958670 \n",
      "Batch: 2747. Acc: 0.275038. Loss: 2.097760. Batch_acc: 0.310172. Batch_loss: 1.984018 \n",
      "Batch: 2748. Acc: 0.275051. Loss: 2.097719. Batch_acc: 0.309510. Batch_loss: 1.984370 \n",
      "Batch: 2749. Acc: 0.275067. Loss: 2.097672. Batch_acc: 0.318625. Batch_loss: 1.970532 \n",
      "Batch: 2750. Acc: 0.275079. Loss: 2.097639. Batch_acc: 0.309165. Batch_loss: 2.003973 \n",
      "Batch: 2751. Acc: 0.275089. Loss: 2.097607. Batch_acc: 0.303582. Batch_loss: 2.009046 \n",
      "Batch: 2752. Acc: 0.275097. Loss: 2.097569. Batch_acc: 0.295493. Batch_loss: 1.994047 \n",
      "Batch: 2753. Acc: 0.275104. Loss: 2.097535. Batch_acc: 0.295831. Batch_loss: 2.003771 \n",
      "Batch: 2754. Acc: 0.275116. Loss: 2.097495. Batch_acc: 0.307028. Batch_loss: 1.988028 \n",
      "Batch: 2755. Acc: 0.275128. Loss: 2.097462. Batch_acc: 0.308406. Batch_loss: 2.004629 \n",
      "Batch: 2756. Acc: 0.275142. Loss: 2.097425. Batch_acc: 0.314815. Batch_loss: 1.996758 \n",
      "Batch: 2757. Acc: 0.275143. Loss: 2.097408. Batch_acc: 0.278286. Batch_loss: 2.051248 \n",
      "Batch: 2758. Acc: 0.275157. Loss: 2.097371. Batch_acc: 0.312009. Batch_loss: 1.995737 \n",
      "Batch: 2759. Acc: 0.275164. Loss: 2.097343. Batch_acc: 0.293984. Batch_loss: 2.022133 \n",
      "Batch: 2760. Acc: 0.275181. Loss: 2.097296. Batch_acc: 0.321267. Batch_loss: 1.969789 \n",
      "Batch: 2761. Acc: 0.275194. Loss: 2.097254. Batch_acc: 0.311048. Batch_loss: 1.983806 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.27519409396085. Loss per char: 2.0972543047916394. Time: 1627204733.3333838\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 17,  1, 14,  1, 23, 19, 20, 22,\n",
      "        22, 23, 25, 18, 20, 24, 23, 23, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.275208. Loss: 2.097218. Batch_acc: 0.314697. Batch_loss: 1.995991 \n",
      "Batch: 2763. Acc: 0.275218. Loss: 2.097195. Batch_acc: 0.302763. Batch_loss: 2.032623 \n",
      "Batch: 2764. Acc: 0.275228. Loss: 2.097177. Batch_acc: 0.303721. Batch_loss: 2.046966 \n",
      "Batch: 2765. Acc: 0.275240. Loss: 2.097137. Batch_acc: 0.309284. Batch_loss: 1.981052 \n",
      "Batch: 2766. Acc: 0.275248. Loss: 2.097115. Batch_acc: 0.296703. Batch_loss: 2.036230 \n",
      "Batch: 2767. Acc: 0.275257. Loss: 2.097081. Batch_acc: 0.301471. Batch_loss: 2.006772 \n",
      "Batch: 2768. Acc: 0.275264. Loss: 2.097050. Batch_acc: 0.293985. Batch_loss: 2.011719 \n",
      "Batch: 2769. Acc: 0.275273. Loss: 2.097026. Batch_acc: 0.298891. Batch_loss: 2.028401 \n",
      "Batch: 2770. Acc: 0.275282. Loss: 2.096995. Batch_acc: 0.303337. Batch_loss: 2.010077 \n",
      "Batch: 2771. Acc: 0.275294. Loss: 2.096953. Batch_acc: 0.306488. Batch_loss: 1.983616 \n",
      "Batch: 2772. Acc: 0.275305. Loss: 2.096913. Batch_acc: 0.304447. Batch_loss: 1.986498 \n",
      "Batch: 2773. Acc: 0.275310. Loss: 2.096879. Batch_acc: 0.289655. Batch_loss: 2.002203 \n",
      "Batch: 2774. Acc: 0.275322. Loss: 2.096842. Batch_acc: 0.310160. Batch_loss: 1.991373 \n",
      "Batch: 2775. Acc: 0.275329. Loss: 2.096812. Batch_acc: 0.295587. Batch_loss: 2.014006 \n",
      "Batch: 2776. Acc: 0.275337. Loss: 2.096790. Batch_acc: 0.297047. Batch_loss: 2.033188 \n",
      "Batch: 2777. Acc: 0.275342. Loss: 2.096769. Batch_acc: 0.290323. Batch_loss: 2.037599 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2778. Acc: 0.275353. Loss: 2.096745. Batch_acc: 0.305556. Batch_loss: 2.030523 \n",
      "Batch: 2779. Acc: 0.275364. Loss: 2.096712. Batch_acc: 0.306960. Batch_loss: 2.000390 \n",
      "Batch: 2780. Acc: 0.275375. Loss: 2.096686. Batch_acc: 0.306931. Batch_loss: 2.024294 \n",
      "Batch: 2781. Acc: 0.275386. Loss: 2.096654. Batch_acc: 0.305619. Batch_loss: 2.008473 \n",
      "Batch: 2782. Acc: 0.275393. Loss: 2.096637. Batch_acc: 0.294422. Batch_loss: 2.048773 \n",
      "Batch: 2783. Acc: 0.275402. Loss: 2.096610. Batch_acc: 0.301578. Batch_loss: 2.021632 \n",
      "Batch: 2784. Acc: 0.275414. Loss: 2.096565. Batch_acc: 0.307518. Batch_loss: 1.974864 \n",
      "Batch: 2785. Acc: 0.275419. Loss: 2.096536. Batch_acc: 0.289398. Batch_loss: 2.014694 \n",
      "Batch: 2786. Acc: 0.275431. Loss: 2.096492. Batch_acc: 0.309050. Batch_loss: 1.976645 \n",
      "Batch: 2787. Acc: 0.275439. Loss: 2.096466. Batch_acc: 0.297203. Batch_loss: 2.023637 \n",
      "Batch: 2788. Acc: 0.275456. Loss: 2.096427. Batch_acc: 0.322280. Batch_loss: 1.985295 \n",
      "Batch: 2789. Acc: 0.275472. Loss: 2.096385. Batch_acc: 0.321617. Batch_loss: 1.977777 \n",
      "Batch: 2790. Acc: 0.275481. Loss: 2.096359. Batch_acc: 0.299092. Batch_loss: 2.025521 \n",
      "Batch: 2791. Acc: 0.275483. Loss: 2.096335. Batch_acc: 0.283565. Batch_loss: 2.026458 \n",
      "Batch: 2792. Acc: 0.275495. Loss: 2.096296. Batch_acc: 0.307253. Batch_loss: 1.990312 \n",
      "Batch: 2793. Acc: 0.275510. Loss: 2.096258. Batch_acc: 0.316918. Batch_loss: 1.987410 \n",
      "Batch: 2794. Acc: 0.275525. Loss: 2.096217. Batch_acc: 0.319198. Batch_loss: 1.984028 \n",
      "Batch: 2795. Acc: 0.275537. Loss: 2.096174. Batch_acc: 0.307468. Batch_loss: 1.973387 \n",
      "Batch: 2796. Acc: 0.275541. Loss: 2.096146. Batch_acc: 0.288319. Batch_loss: 2.018974 \n",
      "Batch: 2797. Acc: 0.275548. Loss: 2.096120. Batch_acc: 0.294220. Batch_loss: 2.022898 \n",
      "Batch: 2798. Acc: 0.275560. Loss: 2.096072. Batch_acc: 0.310209. Batch_loss: 1.963521 \n",
      "Batch: 2799. Acc: 0.275574. Loss: 2.096031. Batch_acc: 0.313177. Batch_loss: 1.983474 \n",
      "Batch: 2800. Acc: 0.275582. Loss: 2.096003. Batch_acc: 0.297064. Batch_loss: 2.017215 \n",
      "Batch: 2801. Acc: 0.275603. Loss: 2.095954. Batch_acc: 0.334892. Batch_loss: 1.955479 \n",
      "Batch: 2802. Acc: 0.275613. Loss: 2.095924. Batch_acc: 0.305104. Batch_loss: 2.013161 \n",
      "Batch: 2803. Acc: 0.275624. Loss: 2.095894. Batch_acc: 0.306452. Batch_loss: 2.006786 \n",
      "Batch: 2804. Acc: 0.275638. Loss: 2.095858. Batch_acc: 0.315341. Batch_loss: 1.998036 \n",
      "Batch: 2805. Acc: 0.275647. Loss: 2.095832. Batch_acc: 0.302298. Batch_loss: 2.020102 \n",
      "Batch: 2806. Acc: 0.275662. Loss: 2.095802. Batch_acc: 0.317627. Batch_loss: 2.009326 \n",
      "Batch: 2807. Acc: 0.275671. Loss: 2.095763. Batch_acc: 0.300174. Batch_loss: 1.985686 \n",
      "Batch: 2808. Acc: 0.275683. Loss: 2.095727. Batch_acc: 0.309308. Batch_loss: 1.996254 \n",
      "Batch: 2809. Acc: 0.275694. Loss: 2.095690. Batch_acc: 0.306897. Batch_loss: 1.992684 \n",
      "Batch: 2810. Acc: 0.275705. Loss: 2.095658. Batch_acc: 0.307827. Batch_loss: 2.005884 \n",
      "Batch: 2811. Acc: 0.275717. Loss: 2.095619. Batch_acc: 0.308438. Batch_loss: 1.984551 \n",
      "Batch: 2812. Acc: 0.275733. Loss: 2.095580. Batch_acc: 0.320046. Batch_loss: 1.987695 \n",
      "Batch: 2813. Acc: 0.275743. Loss: 2.095549. Batch_acc: 0.304496. Batch_loss: 2.008180 \n",
      "Batch: 2814. Acc: 0.275756. Loss: 2.095504. Batch_acc: 0.311847. Batch_loss: 1.967968 \n",
      "Batch: 2815. Acc: 0.275770. Loss: 2.095460. Batch_acc: 0.317101. Batch_loss: 1.971391 \n",
      "Batch: 2816. Acc: 0.275780. Loss: 2.095421. Batch_acc: 0.305226. Batch_loss: 1.980647 \n",
      "Batch: 2817. Acc: 0.275791. Loss: 2.095394. Batch_acc: 0.305491. Batch_loss: 2.017586 \n",
      "Batch: 2818. Acc: 0.275801. Loss: 2.095358. Batch_acc: 0.305474. Batch_loss: 1.993570 \n",
      "Batch: 2819. Acc: 0.275808. Loss: 2.095333. Batch_acc: 0.295244. Batch_loss: 2.024154 \n",
      "Batch: 2820. Acc: 0.275820. Loss: 2.095286. Batch_acc: 0.310034. Batch_loss: 1.965881 \n",
      "Batch: 2821. Acc: 0.275830. Loss: 2.095255. Batch_acc: 0.303047. Batch_loss: 2.009084 \n",
      "Batch: 2822. Acc: 0.275836. Loss: 2.095217. Batch_acc: 0.293372. Batch_loss: 1.987052 \n",
      "Batch: 2823. Acc: 0.275849. Loss: 2.095183. Batch_acc: 0.313267. Batch_loss: 1.998163 \n",
      "Batch: 2824. Acc: 0.275861. Loss: 2.095145. Batch_acc: 0.307649. Batch_loss: 1.989101 \n",
      "Batch: 2825. Acc: 0.275875. Loss: 2.095108. Batch_acc: 0.316368. Batch_loss: 1.990893 \n",
      "Batch: 2826. Acc: 0.275891. Loss: 2.095063. Batch_acc: 0.319405. Batch_loss: 1.968070 \n",
      "Batch: 2827. Acc: 0.275903. Loss: 2.095025. Batch_acc: 0.310046. Batch_loss: 1.986850 \n",
      "Batch: 2828. Acc: 0.275917. Loss: 2.094988. Batch_acc: 0.316327. Batch_loss: 1.993234 \n",
      "Batch: 2829. Acc: 0.275922. Loss: 2.094966. Batch_acc: 0.288967. Batch_loss: 2.030555 \n",
      "Batch: 2830. Acc: 0.275935. Loss: 2.094931. Batch_acc: 0.312929. Batch_loss: 1.995852 \n",
      "Batch: 2831. Acc: 0.275945. Loss: 2.094897. Batch_acc: 0.303653. Batch_loss: 2.000844 \n",
      "Batch: 2832. Acc: 0.275958. Loss: 2.094853. Batch_acc: 0.312929. Batch_loss: 1.969785 \n",
      "Batch: 2833. Acc: 0.275962. Loss: 2.094825. Batch_acc: 0.289323. Batch_loss: 2.015036 \n",
      "Batch: 2834. Acc: 0.275975. Loss: 2.094794. Batch_acc: 0.312788. Batch_loss: 2.008125 \n",
      "Batch: 2835. Acc: 0.275985. Loss: 2.094759. Batch_acc: 0.301724. Batch_loss: 1.995248 \n",
      "Batch: 2836. Acc: 0.275996. Loss: 2.094723. Batch_acc: 0.306659. Batch_loss: 1.994846 \n",
      "Batch: 2837. Acc: 0.276010. Loss: 2.094681. Batch_acc: 0.315285. Batch_loss: 1.977274 \n",
      "Batch: 2838. Acc: 0.276017. Loss: 2.094648. Batch_acc: 0.296083. Batch_loss: 2.000821 \n",
      "Batch: 2839. Acc: 0.276030. Loss: 2.094615. Batch_acc: 0.313771. Batch_loss: 2.002089 \n",
      "Batch: 2840. Acc: 0.276048. Loss: 2.094565. Batch_acc: 0.325267. Batch_loss: 1.954723 \n",
      "Batch: 2841. Acc: 0.276051. Loss: 2.094534. Batch_acc: 0.284965. Batch_loss: 2.005481 \n",
      "Batch: 2842. Acc: 0.276056. Loss: 2.094510. Batch_acc: 0.290772. Batch_loss: 2.025272 \n",
      "Batch: 2843. Acc: 0.276068. Loss: 2.094471. Batch_acc: 0.308607. Batch_loss: 1.986561 \n",
      "Batch: 2844. Acc: 0.276081. Loss: 2.094430. Batch_acc: 0.314645. Batch_loss: 1.977013 \n",
      "Batch: 2845. Acc: 0.276092. Loss: 2.094401. Batch_acc: 0.306146. Batch_loss: 2.012617 \n",
      "Batch: 2846. Acc: 0.276109. Loss: 2.094355. Batch_acc: 0.323952. Batch_loss: 1.963223 \n",
      "Batch: 2847. Acc: 0.276121. Loss: 2.094320. Batch_acc: 0.310029. Batch_loss: 1.995338 \n",
      "Batch: 2848. Acc: 0.276136. Loss: 2.094278. Batch_acc: 0.318882. Batch_loss: 1.974866 \n",
      "Batch: 2849. Acc: 0.276140. Loss: 2.094253. Batch_acc: 0.289054. Batch_loss: 2.023852 \n",
      "Batch: 2850. Acc: 0.276156. Loss: 2.094212. Batch_acc: 0.321429. Batch_loss: 1.977283 \n",
      "Batch: 2851. Acc: 0.276168. Loss: 2.094175. Batch_acc: 0.308790. Batch_loss: 1.991372 \n",
      "Batch: 2852. Acc: 0.276178. Loss: 2.094146. Batch_acc: 0.305889. Batch_loss: 2.011982 \n",
      "Batch: 2853. Acc: 0.276184. Loss: 2.094122. Batch_acc: 0.293765. Batch_loss: 2.020684 \n",
      "Batch: 2854. Acc: 0.276193. Loss: 2.094092. Batch_acc: 0.301003. Batch_loss: 2.013102 \n",
      "Batch: 2855. Acc: 0.276207. Loss: 2.094055. Batch_acc: 0.314400. Batch_loss: 1.986604 \n",
      "Batch: 2856. Acc: 0.276218. Loss: 2.094027. Batch_acc: 0.309811. Batch_loss: 2.014714 \n",
      "Batch: 2857. Acc: 0.276234. Loss: 2.093987. Batch_acc: 0.320624. Batch_loss: 1.978635 \n",
      "Batch: 2858. Acc: 0.276245. Loss: 2.093952. Batch_acc: 0.309925. Batch_loss: 1.995067 \n",
      "Batch: 2859. Acc: 0.276253. Loss: 2.093921. Batch_acc: 0.298060. Batch_loss: 2.001999 \n",
      "Batch: 2860. Acc: 0.276258. Loss: 2.093894. Batch_acc: 0.289897. Batch_loss: 2.017892 \n",
      "Batch: 2861. Acc: 0.276270. Loss: 2.093860. Batch_acc: 0.310364. Batch_loss: 1.998567 \n",
      "Batch: 2862. Acc: 0.276278. Loss: 2.093828. Batch_acc: 0.299490. Batch_loss: 2.003347 \n",
      "Batch: 2863. Acc: 0.276289. Loss: 2.093791. Batch_acc: 0.308092. Batch_loss: 1.987399 \n",
      "Batch: 2864. Acc: 0.276296. Loss: 2.093763. Batch_acc: 0.296424. Batch_loss: 2.014236 \n",
      "Batch: 2865. Acc: 0.276301. Loss: 2.093732. Batch_acc: 0.290041. Batch_loss: 2.004107 \n",
      "Batch: 2866. Acc: 0.276312. Loss: 2.093700. Batch_acc: 0.308438. Batch_loss: 2.003545 \n",
      "Batch: 2867. Acc: 0.276325. Loss: 2.093669. Batch_acc: 0.311968. Batch_loss: 2.003455 \n",
      "Batch: 2868. Acc: 0.276336. Loss: 2.093634. Batch_acc: 0.307331. Batch_loss: 1.992799 \n",
      "Batch: 2869. Acc: 0.276344. Loss: 2.093599. Batch_acc: 0.300880. Batch_loss: 1.990775 \n",
      "Batch: 2870. Acc: 0.276355. Loss: 2.093562. Batch_acc: 0.308966. Batch_loss: 1.988780 \n",
      "Batch: 2871. Acc: 0.276364. Loss: 2.093531. Batch_acc: 0.302204. Batch_loss: 2.004356 \n",
      "Batch: 2872. Acc: 0.276372. Loss: 2.093493. Batch_acc: 0.299539. Batch_loss: 1.984550 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2873. Acc: 0.276380. Loss: 2.093467. Batch_acc: 0.299425. Batch_loss: 2.016341 \n",
      "Batch: 2874. Acc: 0.276395. Loss: 2.093433. Batch_acc: 0.319249. Batch_loss: 1.996484 \n",
      "Batch: 2875. Acc: 0.276406. Loss: 2.093398. Batch_acc: 0.308535. Batch_loss: 1.992502 \n",
      "Batch: 2876. Acc: 0.276413. Loss: 2.093378. Batch_acc: 0.295865. Batch_loss: 2.033435 \n",
      "Batch: 2877. Acc: 0.276428. Loss: 2.093332. Batch_acc: 0.321244. Batch_loss: 1.960121 \n",
      "Batch: 2878. Acc: 0.276436. Loss: 2.093296. Batch_acc: 0.298575. Batch_loss: 1.991664 \n",
      "Batch: 2879. Acc: 0.276447. Loss: 2.093268. Batch_acc: 0.306667. Batch_loss: 2.012214 \n",
      "Batch: 2880. Acc: 0.276454. Loss: 2.093242. Batch_acc: 0.297971. Batch_loss: 2.018260 \n",
      "Batch: 2881. Acc: 0.276464. Loss: 2.093213. Batch_acc: 0.304554. Batch_loss: 2.008031 \n",
      "Batch: 2882. Acc: 0.276470. Loss: 2.093186. Batch_acc: 0.294977. Batch_loss: 2.013770 \n",
      "Batch: 2883. Acc: 0.276481. Loss: 2.093147. Batch_acc: 0.307692. Batch_loss: 1.982872 \n",
      "Batch: 2884. Acc: 0.276488. Loss: 2.093113. Batch_acc: 0.297344. Batch_loss: 1.995687 \n",
      "Batch: 2885. Acc: 0.276501. Loss: 2.093071. Batch_acc: 0.311732. Batch_loss: 1.973101 \n",
      "Batch: 2886. Acc: 0.276508. Loss: 2.093036. Batch_acc: 0.298465. Batch_loss: 1.993411 \n",
      "Batch: 2887. Acc: 0.276521. Loss: 2.092994. Batch_acc: 0.313322. Batch_loss: 1.972857 \n",
      "Batch: 2888. Acc: 0.276533. Loss: 2.092956. Batch_acc: 0.310986. Batch_loss: 1.987423 \n",
      "Batch: 2889. Acc: 0.276538. Loss: 2.092929. Batch_acc: 0.288606. Batch_loss: 2.013831 \n",
      "Batch: 2890. Acc: 0.276549. Loss: 2.092896. Batch_acc: 0.309060. Batch_loss: 1.996241 \n",
      "Batch: 2891. Acc: 0.276556. Loss: 2.092872. Batch_acc: 0.298463. Batch_loss: 2.022825 \n",
      "Batch: 2892. Acc: 0.276567. Loss: 2.092834. Batch_acc: 0.306261. Batch_loss: 1.985328 \n",
      "Batch: 2893. Acc: 0.276579. Loss: 2.092788. Batch_acc: 0.312045. Batch_loss: 1.964164 \n",
      "Batch: 2894. Acc: 0.276589. Loss: 2.092759. Batch_acc: 0.305957. Batch_loss: 2.008072 \n",
      "Batch: 2895. Acc: 0.276596. Loss: 2.092727. Batch_acc: 0.296729. Batch_loss: 1.996446 \n",
      "Batch: 2896. Acc: 0.276606. Loss: 2.092696. Batch_acc: 0.304795. Batch_loss: 2.003911 \n",
      "Batch: 2897. Acc: 0.276615. Loss: 2.092662. Batch_acc: 0.302779. Batch_loss: 1.992047 \n",
      "Batch: 2898. Acc: 0.276625. Loss: 2.092625. Batch_acc: 0.305718. Batch_loss: 1.984393 \n",
      "Batch: 2899. Acc: 0.276631. Loss: 2.092597. Batch_acc: 0.294725. Batch_loss: 2.011254 \n",
      "Batch: 2900. Acc: 0.276629. Loss: 2.092575. Batch_acc: 0.269710. Batch_loss: 2.026291 \n",
      "Batch: 2901. Acc: 0.276639. Loss: 2.092536. Batch_acc: 0.307110. Batch_loss: 1.979238 \n",
      "Batch: 2902. Acc: 0.276645. Loss: 2.092509. Batch_acc: 0.292599. Batch_loss: 2.013407 \n",
      "Batch: 2903. Acc: 0.276652. Loss: 2.092479. Batch_acc: 0.299359. Batch_loss: 2.005360 \n",
      "Batch: 2904. Acc: 0.276661. Loss: 2.092458. Batch_acc: 0.303013. Batch_loss: 2.030695 \n",
      "Batch: 2905. Acc: 0.276671. Loss: 2.092422. Batch_acc: 0.303480. Batch_loss: 1.990687 \n",
      "Batch: 2906. Acc: 0.276683. Loss: 2.092386. Batch_acc: 0.311326. Batch_loss: 1.988579 \n",
      "Batch: 2907. Acc: 0.276691. Loss: 2.092355. Batch_acc: 0.299534. Batch_loss: 2.000647 \n",
      "Batch: 2908. Acc: 0.276700. Loss: 2.092319. Batch_acc: 0.304323. Batch_loss: 1.988361 \n",
      "Batch: 2909. Acc: 0.276708. Loss: 2.092290. Batch_acc: 0.300823. Batch_loss: 2.005672 \n",
      "Batch: 2910. Acc: 0.276718. Loss: 2.092260. Batch_acc: 0.305952. Batch_loss: 2.003678 \n",
      "Batch: 2911. Acc: 0.276727. Loss: 2.092229. Batch_acc: 0.303448. Batch_loss: 2.000529 \n",
      "Batch: 2912. Acc: 0.276734. Loss: 2.092215. Batch_acc: 0.297153. Batch_loss: 2.051507 \n",
      "Batch: 2913. Acc: 0.276745. Loss: 2.092188. Batch_acc: 0.308986. Batch_loss: 2.011649 \n",
      "Batch: 2914. Acc: 0.276753. Loss: 2.092156. Batch_acc: 0.298694. Batch_loss: 2.001975 \n",
      "Batch: 2915. Acc: 0.276762. Loss: 2.092113. Batch_acc: 0.303840. Batch_loss: 1.970247 \n",
      "Batch: 2916. Acc: 0.276768. Loss: 2.092090. Batch_acc: 0.293913. Batch_loss: 2.025087 \n",
      "Batch: 2917. Acc: 0.276772. Loss: 2.092062. Batch_acc: 0.288978. Batch_loss: 2.011190 \n",
      "Batch: 2918. Acc: 0.276783. Loss: 2.092029. Batch_acc: 0.307253. Batch_loss: 1.995070 \n",
      "Batch: 2919. Acc: 0.276794. Loss: 2.092000. Batch_acc: 0.308092. Batch_loss: 2.007903 \n",
      "Batch: 2920. Acc: 0.276806. Loss: 2.091964. Batch_acc: 0.313510. Batch_loss: 1.986839 \n",
      "Batch: 2921. Acc: 0.276815. Loss: 2.091921. Batch_acc: 0.302380. Batch_loss: 1.964736 \n",
      "Batch: 2922. Acc: 0.276828. Loss: 2.091889. Batch_acc: 0.315548. Batch_loss: 1.999589 \n",
      "Batch: 2923. Acc: 0.276840. Loss: 2.091850. Batch_acc: 0.311859. Batch_loss: 1.978275 \n",
      "Batch: 2924. Acc: 0.276847. Loss: 2.091835. Batch_acc: 0.297468. Batch_loss: 2.047309 \n",
      "Batch: 2925. Acc: 0.276857. Loss: 2.091793. Batch_acc: 0.305479. Batch_loss: 1.973888 \n",
      "Batch: 2926. Acc: 0.276868. Loss: 2.091758. Batch_acc: 0.307431. Batch_loss: 1.991406 \n",
      "Batch: 2927. Acc: 0.276879. Loss: 2.091722. Batch_acc: 0.308849. Batch_loss: 1.985620 \n",
      "Batch: 2928. Acc: 0.276891. Loss: 2.091689. Batch_acc: 0.311494. Batch_loss: 1.995452 \n",
      "Batch: 2929. Acc: 0.276903. Loss: 2.091657. Batch_acc: 0.312175. Batch_loss: 1.997809 \n",
      "Batch: 2930. Acc: 0.276911. Loss: 2.091620. Batch_acc: 0.300518. Batch_loss: 1.980757 \n",
      "Batch: 2931. Acc: 0.276922. Loss: 2.091592. Batch_acc: 0.309028. Batch_loss: 2.011467 \n",
      "Batch: 2932. Acc: 0.276935. Loss: 2.091554. Batch_acc: 0.317369. Batch_loss: 1.979665 \n",
      "Batch: 2933. Acc: 0.276943. Loss: 2.091527. Batch_acc: 0.299539. Batch_loss: 2.011351 \n",
      "Batch: 2934. Acc: 0.276952. Loss: 2.091507. Batch_acc: 0.303686. Batch_loss: 2.030213 \n",
      "Batch: 2935. Acc: 0.276960. Loss: 2.091482. Batch_acc: 0.301458. Batch_loss: 2.017288 \n",
      "Batch: 2936. Acc: 0.276970. Loss: 2.091451. Batch_acc: 0.306275. Batch_loss: 2.000350 \n",
      "Batch: 2937. Acc: 0.276976. Loss: 2.091426. Batch_acc: 0.295177. Batch_loss: 2.020056 \n",
      "Batch: 2938. Acc: 0.276987. Loss: 2.091390. Batch_acc: 0.307263. Batch_loss: 1.988034 \n",
      "Batch: 2939. Acc: 0.277002. Loss: 2.091355. Batch_acc: 0.319954. Batch_loss: 1.989412 \n",
      "Batch: 2940. Acc: 0.277016. Loss: 2.091321. Batch_acc: 0.318815. Batch_loss: 1.988785 \n",
      "Batch: 2941. Acc: 0.277029. Loss: 2.091282. Batch_acc: 0.314205. Batch_loss: 1.977523 \n",
      "Batch: 2942. Acc: 0.277042. Loss: 2.091236. Batch_acc: 0.317280. Batch_loss: 1.957636 \n",
      "Batch: 2943. Acc: 0.277052. Loss: 2.091197. Batch_acc: 0.304496. Batch_loss: 1.979248 \n",
      "Batch: 2944. Acc: 0.277066. Loss: 2.091170. Batch_acc: 0.319908. Batch_loss: 2.010521 \n",
      "Batch: 2945. Acc: 0.277073. Loss: 2.091148. Batch_acc: 0.295742. Batch_loss: 2.025971 \n",
      "Batch: 2946. Acc: 0.277084. Loss: 2.091115. Batch_acc: 0.309875. Batch_loss: 1.997274 \n",
      "Batch: 2947. Acc: 0.277097. Loss: 2.091073. Batch_acc: 0.316155. Batch_loss: 1.966679 \n",
      "Batch: 2948. Acc: 0.277114. Loss: 2.091034. Batch_acc: 0.325766. Batch_loss: 1.975328 \n",
      "Batch: 2949. Acc: 0.277127. Loss: 2.090998. Batch_acc: 0.315937. Batch_loss: 1.988885 \n",
      "Batch: 2950. Acc: 0.277135. Loss: 2.090975. Batch_acc: 0.301044. Batch_loss: 2.021557 \n",
      "Batch: 2951. Acc: 0.277149. Loss: 2.090928. Batch_acc: 0.317156. Batch_loss: 1.955277 \n",
      "Batch: 2952. Acc: 0.277158. Loss: 2.090888. Batch_acc: 0.303065. Batch_loss: 1.975130 \n",
      "Batch: 2953. Acc: 0.277168. Loss: 2.090854. Batch_acc: 0.306644. Batch_loss: 1.990892 \n",
      "Batch: 2954. Acc: 0.277177. Loss: 2.090818. Batch_acc: 0.303602. Batch_loss: 1.986831 \n",
      "Batch: 2955. Acc: 0.277188. Loss: 2.090785. Batch_acc: 0.307604. Batch_loss: 1.991402 \n",
      "Batch: 2956. Acc: 0.277193. Loss: 2.090758. Batch_acc: 0.293200. Batch_loss: 2.013523 \n",
      "Batch: 2957. Acc: 0.277205. Loss: 2.090724. Batch_acc: 0.311485. Batch_loss: 1.991359 \n",
      "Batch: 2958. Acc: 0.277214. Loss: 2.090695. Batch_acc: 0.306086. Batch_loss: 1.999277 \n",
      "Batch: 2959. Acc: 0.277225. Loss: 2.090654. Batch_acc: 0.310819. Batch_loss: 1.970964 \n",
      "Batch: 2960. Acc: 0.277238. Loss: 2.090612. Batch_acc: 0.314709. Batch_loss: 1.968026 \n",
      "Batch: 2961. Acc: 0.277244. Loss: 2.090586. Batch_acc: 0.294362. Batch_loss: 2.010267 \n",
      "Batch: 2962. Acc: 0.277260. Loss: 2.090547. Batch_acc: 0.325450. Batch_loss: 1.978027 \n",
      "Batch: 2963. Acc: 0.277277. Loss: 2.090505. Batch_acc: 0.324432. Batch_loss: 1.965910 \n",
      "Batch: 2964. Acc: 0.277283. Loss: 2.090472. Batch_acc: 0.295388. Batch_loss: 1.993391 \n",
      "Batch: 2965. Acc: 0.277290. Loss: 2.090447. Batch_acc: 0.298176. Batch_loss: 2.014881 \n",
      "Batch: 2966. Acc: 0.277303. Loss: 2.090408. Batch_acc: 0.316629. Batch_loss: 1.977566 \n",
      "Batch: 2967. Acc: 0.277312. Loss: 2.090386. Batch_acc: 0.303241. Batch_loss: 2.024837 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2968. Acc: 0.277330. Loss: 2.090344. Batch_acc: 0.329358. Batch_loss: 1.968128 \n",
      "Batch: 2969. Acc: 0.277333. Loss: 2.090309. Batch_acc: 0.287819. Batch_loss: 1.985859 \n",
      "Batch: 2970. Acc: 0.277349. Loss: 2.090272. Batch_acc: 0.324531. Batch_loss: 1.980193 \n",
      "Batch: 2971. Acc: 0.277361. Loss: 2.090228. Batch_acc: 0.313759. Batch_loss: 1.959896 \n",
      "Batch: 2972. Acc: 0.277376. Loss: 2.090189. Batch_acc: 0.323821. Batch_loss: 1.972496 \n",
      "Batch: 2973. Acc: 0.277386. Loss: 2.090152. Batch_acc: 0.305936. Batch_loss: 1.979653 \n",
      "Batch: 2974. Acc: 0.277397. Loss: 2.090113. Batch_acc: 0.309091. Batch_loss: 1.976704 \n",
      "Batch: 2975. Acc: 0.277407. Loss: 2.090075. Batch_acc: 0.307604. Batch_loss: 1.975145 \n",
      "Batch: 2976. Acc: 0.277417. Loss: 2.090037. Batch_acc: 0.307913. Batch_loss: 1.978253 \n",
      "Batch: 2977. Acc: 0.277429. Loss: 2.090002. Batch_acc: 0.311163. Batch_loss: 1.985835 \n",
      "Batch: 2978. Acc: 0.277435. Loss: 2.089972. Batch_acc: 0.297250. Batch_loss: 1.999610 \n",
      "Batch: 2979. Acc: 0.277446. Loss: 2.089936. Batch_acc: 0.309018. Batch_loss: 1.983221 \n",
      "Batch: 2980. Acc: 0.277464. Loss: 2.089892. Batch_acc: 0.329565. Batch_loss: 1.959562 \n",
      "Batch: 2981. Acc: 0.277473. Loss: 2.089859. Batch_acc: 0.305300. Batch_loss: 1.991019 \n",
      "Batch: 2982. Acc: 0.277482. Loss: 2.089825. Batch_acc: 0.305294. Batch_loss: 1.985172 \n",
      "Batch: 2983. Acc: 0.277492. Loss: 2.089795. Batch_acc: 0.307649. Batch_loss: 2.003186 \n",
      "Batch: 2984. Acc: 0.277503. Loss: 2.089756. Batch_acc: 0.309290. Batch_loss: 1.974359 \n",
      "Batch: 2985. Acc: 0.277518. Loss: 2.089707. Batch_acc: 0.322981. Batch_loss: 1.945558 \n",
      "Batch: 2986. Acc: 0.277533. Loss: 2.089661. Batch_acc: 0.323339. Batch_loss: 1.947766 \n",
      "Batch: 2987. Acc: 0.277545. Loss: 2.089629. Batch_acc: 0.310864. Batch_loss: 1.999260 \n",
      "Batch: 2988. Acc: 0.277556. Loss: 2.089598. Batch_acc: 0.309827. Batch_loss: 1.995662 \n",
      "Batch: 2989. Acc: 0.277566. Loss: 2.089570. Batch_acc: 0.308000. Batch_loss: 2.006057 \n",
      "Batch: 2990. Acc: 0.277572. Loss: 2.089545. Batch_acc: 0.296684. Batch_loss: 2.014363 \n",
      "Batch: 2991. Acc: 0.277585. Loss: 2.089509. Batch_acc: 0.315372. Batch_loss: 1.982470 \n",
      "Batch: 2992. Acc: 0.277600. Loss: 2.089472. Batch_acc: 0.324882. Batch_loss: 1.977536 \n",
      "Batch: 2993. Acc: 0.277614. Loss: 2.089431. Batch_acc: 0.317045. Batch_loss: 1.966594 \n",
      "Batch: 2994. Acc: 0.277624. Loss: 2.089400. Batch_acc: 0.306388. Batch_loss: 1.998817 \n",
      "Batch: 2995. Acc: 0.277632. Loss: 2.089366. Batch_acc: 0.302979. Batch_loss: 1.988913 \n",
      "Batch: 2996. Acc: 0.277640. Loss: 2.089332. Batch_acc: 0.300171. Batch_loss: 1.988588 \n",
      "Batch: 2997. Acc: 0.277653. Loss: 2.089292. Batch_acc: 0.316893. Batch_loss: 1.972710 \n",
      "Batch: 2998. Acc: 0.277664. Loss: 2.089269. Batch_acc: 0.310164. Batch_loss: 2.017416 \n",
      "Batch: 2999. Acc: 0.277675. Loss: 2.089235. Batch_acc: 0.311381. Batch_loss: 1.988828 \n",
      "Batch: 3000. Acc: 0.277685. Loss: 2.089205. Batch_acc: 0.306897. Batch_loss: 1.998967 \n",
      "Batch: 3001. Acc: 0.277695. Loss: 2.089176. Batch_acc: 0.307345. Batch_loss: 2.003349 \n",
      "Batch: 3002. Acc: 0.277700. Loss: 2.089153. Batch_acc: 0.292299. Batch_loss: 2.019731 \n",
      "Batch: 3003. Acc: 0.277718. Loss: 2.089104. Batch_acc: 0.332390. Batch_loss: 1.943624 \n",
      "Batch: 3004. Acc: 0.277730. Loss: 2.089072. Batch_acc: 0.313529. Batch_loss: 1.991999 \n",
      "Batch: 3005. Acc: 0.277741. Loss: 2.089048. Batch_acc: 0.311512. Batch_loss: 2.016184 \n",
      "Batch: 3006. Acc: 0.277749. Loss: 2.089019. Batch_acc: 0.302191. Batch_loss: 2.001590 \n",
      "Batch: 3007. Acc: 0.277762. Loss: 2.088985. Batch_acc: 0.314730. Batch_loss: 1.987768 \n",
      "Batch: 3008. Acc: 0.277774. Loss: 2.088957. Batch_acc: 0.314836. Batch_loss: 2.004730 \n",
      "Batch: 3009. Acc: 0.277787. Loss: 2.088913. Batch_acc: 0.317487. Batch_loss: 1.958590 \n",
      "Batch: 3010. Acc: 0.277802. Loss: 2.088868. Batch_acc: 0.321710. Batch_loss: 1.955255 \n",
      "Batch: 3011. Acc: 0.277813. Loss: 2.088840. Batch_acc: 0.310646. Batch_loss: 2.005084 \n",
      "Batch: 3012. Acc: 0.277818. Loss: 2.088819. Batch_acc: 0.294591. Batch_loss: 2.023707 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.2778184837407526. Loss per char: 2.0888188128825225. Time: 1627204939.9547246\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 19, 21, 20, 19,\n",
      "        17, 26, 15, 20, 22, 24, 25, 20, 17, 25,  1, 66, 79, 69,  1, 17, 15, 23,\n",
      "        15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.277828. Loss: 2.088789. Batch_acc: 0.306062. Batch_loss: 1.996035 \n",
      "Batch: 3014. Acc: 0.277837. Loss: 2.088761. Batch_acc: 0.306838. Batch_loss: 2.004910 \n",
      "Batch: 3015. Acc: 0.277846. Loss: 2.088738. Batch_acc: 0.305770. Batch_loss: 2.014693 \n",
      "Batch: 3016. Acc: 0.277853. Loss: 2.088712. Batch_acc: 0.297822. Batch_loss: 2.008344 \n",
      "Batch: 3017. Acc: 0.277864. Loss: 2.088675. Batch_acc: 0.313149. Batch_loss: 1.977969 \n",
      "Batch: 3018. Acc: 0.277876. Loss: 2.088641. Batch_acc: 0.312464. Batch_loss: 1.988051 \n",
      "Batch: 3019. Acc: 0.277885. Loss: 2.088609. Batch_acc: 0.305477. Batch_loss: 1.992307 \n",
      "Batch: 3020. Acc: 0.277897. Loss: 2.088574. Batch_acc: 0.311828. Batch_loss: 1.984956 \n",
      "Batch: 3021. Acc: 0.277905. Loss: 2.088549. Batch_acc: 0.303883. Batch_loss: 2.014382 \n",
      "Batch: 3022. Acc: 0.277913. Loss: 2.088531. Batch_acc: 0.301394. Batch_loss: 2.035541 \n",
      "Batch: 3023. Acc: 0.277919. Loss: 2.088503. Batch_acc: 0.294749. Batch_loss: 2.004180 \n",
      "Batch: 3024. Acc: 0.277936. Loss: 2.088454. Batch_acc: 0.329584. Batch_loss: 1.944840 \n",
      "Batch: 3025. Acc: 0.277948. Loss: 2.088422. Batch_acc: 0.314562. Batch_loss: 1.991073 \n",
      "Batch: 3026. Acc: 0.277954. Loss: 2.088397. Batch_acc: 0.293814. Batch_loss: 2.014538 \n",
      "Batch: 3027. Acc: 0.277965. Loss: 2.088358. Batch_acc: 0.314640. Batch_loss: 1.966175 \n",
      "Batch: 3028. Acc: 0.277968. Loss: 2.088340. Batch_acc: 0.284539. Batch_loss: 2.033669 \n",
      "Batch: 3029. Acc: 0.277984. Loss: 2.088300. Batch_acc: 0.326249. Batch_loss: 1.966326 \n",
      "Batch: 3030. Acc: 0.277994. Loss: 2.088261. Batch_acc: 0.311475. Batch_loss: 1.967397 \n",
      "Batch: 3031. Acc: 0.278010. Loss: 2.088218. Batch_acc: 0.325542. Batch_loss: 1.959028 \n",
      "Batch: 3032. Acc: 0.278023. Loss: 2.088176. Batch_acc: 0.315881. Batch_loss: 1.960245 \n",
      "Batch: 3033. Acc: 0.278028. Loss: 2.088152. Batch_acc: 0.294749. Batch_loss: 2.015362 \n",
      "Batch: 3034. Acc: 0.278038. Loss: 2.088120. Batch_acc: 0.306766. Batch_loss: 1.992652 \n",
      "Batch: 3035. Acc: 0.278053. Loss: 2.088082. Batch_acc: 0.325810. Batch_loss: 1.971194 \n",
      "Batch: 3036. Acc: 0.278064. Loss: 2.088042. Batch_acc: 0.309143. Batch_loss: 1.967778 \n",
      "Batch: 3037. Acc: 0.278079. Loss: 2.088005. Batch_acc: 0.323870. Batch_loss: 1.975024 \n",
      "Batch: 3038. Acc: 0.278092. Loss: 2.087972. Batch_acc: 0.317838. Batch_loss: 1.987278 \n",
      "Batch: 3039. Acc: 0.278103. Loss: 2.087935. Batch_acc: 0.311381. Batch_loss: 1.973679 \n",
      "Batch: 3040. Acc: 0.278108. Loss: 2.087911. Batch_acc: 0.295758. Batch_loss: 2.014526 \n",
      "Batch: 3041. Acc: 0.278121. Loss: 2.087878. Batch_acc: 0.315607. Batch_loss: 1.986944 \n",
      "Batch: 3042. Acc: 0.278135. Loss: 2.087833. Batch_acc: 0.322152. Batch_loss: 1.951971 \n",
      "Batch: 3043. Acc: 0.278143. Loss: 2.087809. Batch_acc: 0.302366. Batch_loss: 2.013774 \n",
      "Batch: 3044. Acc: 0.278154. Loss: 2.087778. Batch_acc: 0.312178. Batch_loss: 1.994039 \n",
      "Batch: 3045. Acc: 0.278163. Loss: 2.087748. Batch_acc: 0.304198. Batch_loss: 1.997220 \n",
      "Batch: 3046. Acc: 0.278170. Loss: 2.087709. Batch_acc: 0.301596. Batch_loss: 1.970391 \n",
      "Batch: 3047. Acc: 0.278177. Loss: 2.087680. Batch_acc: 0.298226. Batch_loss: 1.998921 \n",
      "Batch: 3048. Acc: 0.278188. Loss: 2.087649. Batch_acc: 0.310267. Batch_loss: 1.995094 \n",
      "Batch: 3049. Acc: 0.278196. Loss: 2.087620. Batch_acc: 0.303150. Batch_loss: 2.001008 \n",
      "Batch: 3050. Acc: 0.278206. Loss: 2.087581. Batch_acc: 0.309123. Batch_loss: 1.965844 \n",
      "Batch: 3051. Acc: 0.278217. Loss: 2.087543. Batch_acc: 0.311822. Batch_loss: 1.974536 \n",
      "Batch: 3052. Acc: 0.278228. Loss: 2.087521. Batch_acc: 0.310285. Batch_loss: 2.018998 \n",
      "Batch: 3053. Acc: 0.278237. Loss: 2.087481. Batch_acc: 0.306122. Batch_loss: 1.963904 \n",
      "Batch: 3054. Acc: 0.278243. Loss: 2.087453. Batch_acc: 0.299180. Batch_loss: 2.001336 \n",
      "Batch: 3055. Acc: 0.278253. Loss: 2.087424. Batch_acc: 0.308621. Batch_loss: 1.998542 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3056. Acc: 0.278264. Loss: 2.087394. Batch_acc: 0.310896. Batch_loss: 1.996352 \n",
      "Batch: 3057. Acc: 0.278274. Loss: 2.087357. Batch_acc: 0.307427. Batch_loss: 1.972781 \n",
      "Batch: 3058. Acc: 0.278289. Loss: 2.087319. Batch_acc: 0.325406. Batch_loss: 1.971279 \n",
      "Batch: 3059. Acc: 0.278300. Loss: 2.087296. Batch_acc: 0.312000. Batch_loss: 2.016886 \n",
      "Batch: 3060. Acc: 0.278308. Loss: 2.087274. Batch_acc: 0.301205. Batch_loss: 2.020578 \n",
      "Batch: 3061. Acc: 0.278319. Loss: 2.087236. Batch_acc: 0.313848. Batch_loss: 1.973261 \n",
      "Batch: 3062. Acc: 0.278331. Loss: 2.087196. Batch_acc: 0.312856. Batch_loss: 1.964051 \n",
      "Batch: 3063. Acc: 0.278340. Loss: 2.087161. Batch_acc: 0.308455. Batch_loss: 1.979064 \n",
      "Batch: 3064. Acc: 0.278348. Loss: 2.087125. Batch_acc: 0.301525. Batch_loss: 1.979596 \n",
      "Batch: 3065. Acc: 0.278360. Loss: 2.087084. Batch_acc: 0.312994. Batch_loss: 1.963670 \n",
      "Batch: 3066. Acc: 0.278369. Loss: 2.087065. Batch_acc: 0.306193. Batch_loss: 2.028837 \n",
      "Batch: 3067. Acc: 0.278381. Loss: 2.087029. Batch_acc: 0.317145. Batch_loss: 1.973483 \n",
      "Batch: 3068. Acc: 0.278390. Loss: 2.086999. Batch_acc: 0.306042. Batch_loss: 1.996092 \n",
      "Batch: 3069. Acc: 0.278399. Loss: 2.086971. Batch_acc: 0.303826. Batch_loss: 2.004544 \n",
      "Batch: 3070. Acc: 0.278408. Loss: 2.086944. Batch_acc: 0.306524. Batch_loss: 2.004215 \n",
      "Batch: 3071. Acc: 0.278420. Loss: 2.086911. Batch_acc: 0.315116. Batch_loss: 1.984375 \n",
      "Batch: 3072. Acc: 0.278429. Loss: 2.086876. Batch_acc: 0.306812. Batch_loss: 1.981248 \n",
      "Batch: 3073. Acc: 0.278435. Loss: 2.086845. Batch_acc: 0.296254. Batch_loss: 1.993011 \n",
      "Batch: 3074. Acc: 0.278440. Loss: 2.086829. Batch_acc: 0.292752. Batch_loss: 2.036826 \n",
      "Batch: 3075. Acc: 0.278454. Loss: 2.086790. Batch_acc: 0.321826. Batch_loss: 1.970411 \n",
      "Batch: 3076. Acc: 0.278461. Loss: 2.086765. Batch_acc: 0.299110. Batch_loss: 2.008909 \n",
      "Batch: 3077. Acc: 0.278470. Loss: 2.086736. Batch_acc: 0.308729. Batch_loss: 1.993911 \n",
      "Batch: 3078. Acc: 0.278477. Loss: 2.086699. Batch_acc: 0.297632. Batch_loss: 1.978035 \n",
      "Batch: 3079. Acc: 0.278495. Loss: 2.086647. Batch_acc: 0.332209. Batch_loss: 1.928712 \n",
      "Batch: 3080. Acc: 0.278504. Loss: 2.086614. Batch_acc: 0.308867. Batch_loss: 1.982497 \n",
      "Batch: 3081. Acc: 0.278511. Loss: 2.086585. Batch_acc: 0.297468. Batch_loss: 1.998840 \n",
      "Batch: 3082. Acc: 0.278519. Loss: 2.086560. Batch_acc: 0.304094. Batch_loss: 2.007321 \n",
      "Batch: 3083. Acc: 0.278525. Loss: 2.086535. Batch_acc: 0.299363. Batch_loss: 2.010115 \n",
      "Batch: 3084. Acc: 0.278538. Loss: 2.086501. Batch_acc: 0.316215. Batch_loss: 1.978565 \n",
      "Batch: 3085. Acc: 0.278551. Loss: 2.086457. Batch_acc: 0.321573. Batch_loss: 1.951129 \n",
      "Batch: 3086. Acc: 0.278562. Loss: 2.086420. Batch_acc: 0.312721. Batch_loss: 1.971129 \n",
      "Batch: 3087. Acc: 0.278577. Loss: 2.086375. Batch_acc: 0.322653. Batch_loss: 1.948735 \n",
      "Batch: 3088. Acc: 0.278587. Loss: 2.086338. Batch_acc: 0.309843. Batch_loss: 1.972413 \n",
      "Batch: 3089. Acc: 0.278596. Loss: 2.086310. Batch_acc: 0.307692. Batch_loss: 1.998283 \n",
      "Batch: 3090. Acc: 0.278602. Loss: 2.086284. Batch_acc: 0.295912. Batch_loss: 2.007244 \n",
      "Batch: 3091. Acc: 0.278609. Loss: 2.086254. Batch_acc: 0.300400. Batch_loss: 1.993122 \n",
      "Batch: 3092. Acc: 0.278619. Loss: 2.086224. Batch_acc: 0.308043. Batch_loss: 1.992851 \n",
      "Batch: 3093. Acc: 0.278631. Loss: 2.086178. Batch_acc: 0.315556. Batch_loss: 1.949813 \n",
      "Batch: 3094. Acc: 0.278640. Loss: 2.086138. Batch_acc: 0.305762. Batch_loss: 1.964447 \n",
      "Batch: 3095. Acc: 0.278650. Loss: 2.086099. Batch_acc: 0.309018. Batch_loss: 1.965611 \n",
      "Batch: 3096. Acc: 0.278654. Loss: 2.086067. Batch_acc: 0.291929. Batch_loss: 1.987774 \n",
      "Batch: 3097. Acc: 0.278666. Loss: 2.086026. Batch_acc: 0.317919. Batch_loss: 1.955846 \n",
      "Batch: 3098. Acc: 0.278676. Loss: 2.085988. Batch_acc: 0.307521. Batch_loss: 1.972905 \n",
      "Batch: 3099. Acc: 0.278687. Loss: 2.085954. Batch_acc: 0.313295. Batch_loss: 1.981364 \n",
      "Batch: 3100. Acc: 0.278694. Loss: 2.085929. Batch_acc: 0.298176. Batch_loss: 2.009205 \n",
      "Batch: 3101. Acc: 0.278703. Loss: 2.085894. Batch_acc: 0.307604. Batch_loss: 1.978156 \n",
      "Batch: 3102. Acc: 0.278718. Loss: 2.085854. Batch_acc: 0.325647. Batch_loss: 1.964138 \n",
      "Batch: 3103. Acc: 0.278726. Loss: 2.085819. Batch_acc: 0.301542. Batch_loss: 1.978594 \n",
      "Batch: 3104. Acc: 0.278729. Loss: 2.085796. Batch_acc: 0.289428. Batch_loss: 2.012769 \n",
      "Batch: 3105. Acc: 0.278735. Loss: 2.085780. Batch_acc: 0.296716. Batch_loss: 2.038407 \n",
      "Batch: 3106. Acc: 0.278740. Loss: 2.085758. Batch_acc: 0.292947. Batch_loss: 2.017847 \n",
      "Batch: 3107. Acc: 0.278749. Loss: 2.085729. Batch_acc: 0.306296. Batch_loss: 1.995599 \n",
      "Batch: 3108. Acc: 0.278759. Loss: 2.085699. Batch_acc: 0.311008. Batch_loss: 1.990716 \n",
      "Batch: 3109. Acc: 0.278770. Loss: 2.085657. Batch_acc: 0.313793. Batch_loss: 1.955541 \n",
      "Batch: 3110. Acc: 0.278779. Loss: 2.085617. Batch_acc: 0.306215. Batch_loss: 1.963525 \n",
      "Batch: 3111. Acc: 0.278787. Loss: 2.085585. Batch_acc: 0.304046. Batch_loss: 1.985167 \n",
      "Batch: 3112. Acc: 0.278795. Loss: 2.085562. Batch_acc: 0.303571. Batch_loss: 2.013780 \n",
      "Batch: 3113. Acc: 0.278803. Loss: 2.085541. Batch_acc: 0.301378. Batch_loss: 2.021694 \n",
      "Batch: 3114. Acc: 0.278812. Loss: 2.085513. Batch_acc: 0.307649. Batch_loss: 1.998545 \n",
      "Batch: 3115. Acc: 0.278820. Loss: 2.085489. Batch_acc: 0.302487. Batch_loss: 2.009509 \n",
      "Batch: 3116. Acc: 0.278828. Loss: 2.085450. Batch_acc: 0.304740. Batch_loss: 1.968835 \n",
      "Batch: 3117. Acc: 0.278834. Loss: 2.085420. Batch_acc: 0.296571. Batch_loss: 1.990961 \n",
      "Batch: 3118. Acc: 0.278846. Loss: 2.085385. Batch_acc: 0.317997. Batch_loss: 1.975789 \n",
      "Batch: 3119. Acc: 0.278859. Loss: 2.085347. Batch_acc: 0.317762. Batch_loss: 1.965135 \n",
      "Batch: 3120. Acc: 0.278867. Loss: 2.085320. Batch_acc: 0.304756. Batch_loss: 1.999835 \n",
      "Batch: 3121. Acc: 0.278875. Loss: 2.085277. Batch_acc: 0.303950. Batch_loss: 1.950897 \n",
      "Batch: 3122. Acc: 0.278884. Loss: 2.085239. Batch_acc: 0.306296. Batch_loss: 1.970397 \n",
      "Batch: 3123. Acc: 0.278897. Loss: 2.085208. Batch_acc: 0.321408. Batch_loss: 1.986874 \n",
      "Batch: 3124. Acc: 0.278911. Loss: 2.085173. Batch_acc: 0.321859. Batch_loss: 1.977548 \n",
      "Batch: 3125. Acc: 0.278919. Loss: 2.085144. Batch_acc: 0.305263. Batch_loss: 1.990889 \n",
      "Batch: 3126. Acc: 0.278936. Loss: 2.085103. Batch_acc: 0.330301. Batch_loss: 1.959359 \n",
      "Batch: 3127. Acc: 0.278953. Loss: 2.085058. Batch_acc: 0.332373. Batch_loss: 1.945551 \n",
      "Batch: 3128. Acc: 0.278962. Loss: 2.085018. Batch_acc: 0.307028. Batch_loss: 1.958067 \n",
      "Batch: 3129. Acc: 0.278974. Loss: 2.084988. Batch_acc: 0.317031. Batch_loss: 1.992835 \n",
      "Batch: 3130. Acc: 0.278981. Loss: 2.084963. Batch_acc: 0.298798. Batch_loss: 2.006777 \n",
      "Batch: 3131. Acc: 0.278989. Loss: 2.084932. Batch_acc: 0.305379. Batch_loss: 1.985273 \n",
      "Batch: 3132. Acc: 0.278998. Loss: 2.084906. Batch_acc: 0.307824. Batch_loss: 2.004808 \n",
      "Batch: 3133. Acc: 0.279007. Loss: 2.084877. Batch_acc: 0.307003. Batch_loss: 1.997362 \n",
      "Batch: 3134. Acc: 0.279018. Loss: 2.084840. Batch_acc: 0.311791. Batch_loss: 1.970870 \n",
      "Batch: 3135. Acc: 0.279032. Loss: 2.084796. Batch_acc: 0.323059. Batch_loss: 1.946921 \n",
      "Batch: 3136. Acc: 0.279048. Loss: 2.084758. Batch_acc: 0.328134. Batch_loss: 1.966321 \n",
      "Batch: 3137. Acc: 0.279054. Loss: 2.084726. Batch_acc: 0.298236. Batch_loss: 1.985253 \n",
      "Batch: 3138. Acc: 0.279061. Loss: 2.084699. Batch_acc: 0.299771. Batch_loss: 1.998425 \n",
      "Batch: 3139. Acc: 0.279075. Loss: 2.084653. Batch_acc: 0.321369. Batch_loss: 1.947309 \n",
      "Batch: 3140. Acc: 0.279086. Loss: 2.084608. Batch_acc: 0.315639. Batch_loss: 1.944271 \n",
      "Batch: 3141. Acc: 0.279103. Loss: 2.084564. Batch_acc: 0.330173. Batch_loss: 1.951921 \n",
      "Batch: 3142. Acc: 0.279113. Loss: 2.084528. Batch_acc: 0.309729. Batch_loss: 1.969949 \n",
      "Batch: 3143. Acc: 0.279123. Loss: 2.084498. Batch_acc: 0.313353. Batch_loss: 1.988063 \n",
      "Batch: 3144. Acc: 0.279134. Loss: 2.084463. Batch_acc: 0.313137. Batch_loss: 1.975921 \n",
      "Batch: 3145. Acc: 0.279147. Loss: 2.084428. Batch_acc: 0.317708. Batch_loss: 1.973884 \n",
      "Batch: 3146. Acc: 0.279151. Loss: 2.084402. Batch_acc: 0.294835. Batch_loss: 1.999846 \n",
      "Batch: 3147. Acc: 0.279162. Loss: 2.084366. Batch_acc: 0.312323. Batch_loss: 1.975082 \n",
      "Batch: 3148. Acc: 0.279173. Loss: 2.084336. Batch_acc: 0.315173. Batch_loss: 1.986702 \n",
      "Batch: 3149. Acc: 0.279181. Loss: 2.084315. Batch_acc: 0.303288. Batch_loss: 2.018421 \n",
      "Batch: 3150. Acc: 0.279191. Loss: 2.084287. Batch_acc: 0.310064. Batch_loss: 1.997394 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3151. Acc: 0.279197. Loss: 2.084268. Batch_acc: 0.300234. Batch_loss: 2.021692 \n",
      "Batch: 3152. Acc: 0.279210. Loss: 2.084233. Batch_acc: 0.318681. Batch_loss: 1.973639 \n",
      "Batch: 3153. Acc: 0.279223. Loss: 2.084198. Batch_acc: 0.321994. Batch_loss: 1.971059 \n",
      "Batch: 3154. Acc: 0.279230. Loss: 2.084166. Batch_acc: 0.300976. Batch_loss: 1.983667 \n",
      "Batch: 3155. Acc: 0.279239. Loss: 2.084138. Batch_acc: 0.307295. Batch_loss: 1.996011 \n",
      "Batch: 3156. Acc: 0.279254. Loss: 2.084089. Batch_acc: 0.327607. Batch_loss: 1.924149 \n",
      "Batch: 3157. Acc: 0.279264. Loss: 2.084049. Batch_acc: 0.311288. Batch_loss: 1.960500 \n",
      "Batch: 3158. Acc: 0.279276. Loss: 2.084018. Batch_acc: 0.316030. Batch_loss: 1.987772 \n",
      "Batch: 3159. Acc: 0.279286. Loss: 2.083984. Batch_acc: 0.309061. Batch_loss: 1.978860 \n",
      "Batch: 3160. Acc: 0.279299. Loss: 2.083942. Batch_acc: 0.323686. Batch_loss: 1.948518 \n",
      "Batch: 3161. Acc: 0.279307. Loss: 2.083920. Batch_acc: 0.303226. Batch_loss: 2.011856 \n",
      "Batch: 3162. Acc: 0.279322. Loss: 2.083875. Batch_acc: 0.325792. Batch_loss: 1.944855 \n",
      "Batch: 3163. Acc: 0.279330. Loss: 2.083843. Batch_acc: 0.305382. Batch_loss: 1.984850 \n",
      "Batch: 3164. Acc: 0.279341. Loss: 2.083803. Batch_acc: 0.315037. Batch_loss: 1.958067 \n",
      "Batch: 3165. Acc: 0.279357. Loss: 2.083766. Batch_acc: 0.329107. Batch_loss: 1.965339 \n",
      "Batch: 3166. Acc: 0.279370. Loss: 2.083727. Batch_acc: 0.319149. Batch_loss: 1.960398 \n",
      "Batch: 3167. Acc: 0.279383. Loss: 2.083693. Batch_acc: 0.320250. Batch_loss: 1.975564 \n",
      "Batch: 3168. Acc: 0.279395. Loss: 2.083655. Batch_acc: 0.319516. Batch_loss: 1.966102 \n",
      "Batch: 3169. Acc: 0.279405. Loss: 2.083620. Batch_acc: 0.309237. Batch_loss: 1.970006 \n",
      "Batch: 3170. Acc: 0.279413. Loss: 2.083589. Batch_acc: 0.304348. Batch_loss: 1.987922 \n",
      "Batch: 3171. Acc: 0.279424. Loss: 2.083547. Batch_acc: 0.314270. Batch_loss: 1.952855 \n",
      "Batch: 3172. Acc: 0.279431. Loss: 2.083518. Batch_acc: 0.301038. Batch_loss: 1.992116 \n",
      "Batch: 3173. Acc: 0.279444. Loss: 2.083478. Batch_acc: 0.321739. Batch_loss: 1.956279 \n",
      "Batch: 3174. Acc: 0.279452. Loss: 2.083449. Batch_acc: 0.304524. Batch_loss: 1.990553 \n",
      "Batch: 3175. Acc: 0.279463. Loss: 2.083416. Batch_acc: 0.315372. Batch_loss: 1.979511 \n",
      "Batch: 3176. Acc: 0.279475. Loss: 2.083372. Batch_acc: 0.317297. Batch_loss: 1.942414 \n",
      "Batch: 3177. Acc: 0.279485. Loss: 2.083334. Batch_acc: 0.311216. Batch_loss: 1.962601 \n",
      "Batch: 3178. Acc: 0.279495. Loss: 2.083299. Batch_acc: 0.310646. Batch_loss: 1.970678 \n",
      "Batch: 3179. Acc: 0.279510. Loss: 2.083265. Batch_acc: 0.327769. Batch_loss: 1.977377 \n",
      "Batch: 3180. Acc: 0.279519. Loss: 2.083228. Batch_acc: 0.306902. Batch_loss: 1.968128 \n",
      "Batch: 3181. Acc: 0.279525. Loss: 2.083203. Batch_acc: 0.299883. Batch_loss: 2.002239 \n",
      "Batch: 3182. Acc: 0.279536. Loss: 2.083175. Batch_acc: 0.311927. Batch_loss: 1.993959 \n",
      "Batch: 3183. Acc: 0.279542. Loss: 2.083146. Batch_acc: 0.300931. Batch_loss: 1.990325 \n",
      "Batch: 3184. Acc: 0.279556. Loss: 2.083110. Batch_acc: 0.322490. Batch_loss: 1.971200 \n",
      "Batch: 3185. Acc: 0.279569. Loss: 2.083070. Batch_acc: 0.322430. Batch_loss: 1.954415 \n",
      "Batch: 3186. Acc: 0.279579. Loss: 2.083030. Batch_acc: 0.310520. Batch_loss: 1.955783 \n",
      "Batch: 3187. Acc: 0.279593. Loss: 2.082991. Batch_acc: 0.322653. Batch_loss: 1.961330 \n",
      "Batch: 3188. Acc: 0.279603. Loss: 2.082955. Batch_acc: 0.312178. Batch_loss: 1.969941 \n",
      "Batch: 3189. Acc: 0.279617. Loss: 2.082919. Batch_acc: 0.324000. Batch_loss: 1.969176 \n",
      "Batch: 3190. Acc: 0.279625. Loss: 2.082894. Batch_acc: 0.304073. Batch_loss: 2.001461 \n",
      "Batch: 3191. Acc: 0.279634. Loss: 2.082855. Batch_acc: 0.309551. Batch_loss: 1.960496 \n",
      "Batch: 3192. Acc: 0.279638. Loss: 2.082836. Batch_acc: 0.291312. Batch_loss: 2.021258 \n",
      "Batch: 3193. Acc: 0.279649. Loss: 2.082803. Batch_acc: 0.313839. Batch_loss: 1.978077 \n",
      "Batch: 3194. Acc: 0.279663. Loss: 2.082769. Batch_acc: 0.322835. Batch_loss: 1.975025 \n",
      "Batch: 3195. Acc: 0.279676. Loss: 2.082733. Batch_acc: 0.321690. Batch_loss: 1.970871 \n",
      "Batch: 3196. Acc: 0.279687. Loss: 2.082696. Batch_acc: 0.316244. Batch_loss: 1.963259 \n",
      "Batch: 3197. Acc: 0.279696. Loss: 2.082669. Batch_acc: 0.308995. Batch_loss: 1.994972 \n",
      "Batch: 3198. Acc: 0.279709. Loss: 2.082627. Batch_acc: 0.320405. Batch_loss: 1.953782 \n",
      "Batch: 3199. Acc: 0.279715. Loss: 2.082602. Batch_acc: 0.298542. Batch_loss: 1.999277 \n",
      "Batch: 3200. Acc: 0.279718. Loss: 2.082576. Batch_acc: 0.289720. Batch_loss: 1.999712 \n",
      "Batch: 3201. Acc: 0.279724. Loss: 2.082555. Batch_acc: 0.297235. Batch_loss: 2.013987 \n",
      "Batch: 3202. Acc: 0.279731. Loss: 2.082535. Batch_acc: 0.304425. Batch_loss: 2.016230 \n",
      "Batch: 3203. Acc: 0.279737. Loss: 2.082520. Batch_acc: 0.298083. Batch_loss: 2.034830 \n",
      "Batch: 3204. Acc: 0.279740. Loss: 2.082500. Batch_acc: 0.290360. Batch_loss: 2.018539 \n",
      "Batch: 3205. Acc: 0.279748. Loss: 2.082477. Batch_acc: 0.305124. Batch_loss: 2.008622 \n",
      "Batch: 3206. Acc: 0.279757. Loss: 2.082455. Batch_acc: 0.308790. Batch_loss: 2.013879 \n",
      "Batch: 3207. Acc: 0.279768. Loss: 2.082421. Batch_acc: 0.314352. Batch_loss: 1.972125 \n",
      "Batch: 3208. Acc: 0.279777. Loss: 2.082395. Batch_acc: 0.307604. Batch_loss: 1.996473 \n",
      "Batch: 3209. Acc: 0.279785. Loss: 2.082369. Batch_acc: 0.308009. Batch_loss: 1.998289 \n",
      "Batch: 3210. Acc: 0.279796. Loss: 2.082340. Batch_acc: 0.313974. Batch_loss: 1.989449 \n",
      "Batch: 3211. Acc: 0.279802. Loss: 2.082314. Batch_acc: 0.299065. Batch_loss: 1.996987 \n",
      "Batch: 3212. Acc: 0.279812. Loss: 2.082290. Batch_acc: 0.311419. Batch_loss: 2.006551 \n",
      "Batch: 3213. Acc: 0.279823. Loss: 2.082257. Batch_acc: 0.314974. Batch_loss: 1.975655 \n",
      "Batch: 3214. Acc: 0.279828. Loss: 2.082235. Batch_acc: 0.295612. Batch_loss: 2.009672 \n",
      "Batch: 3215. Acc: 0.279830. Loss: 2.082214. Batch_acc: 0.286366. Batch_loss: 2.017841 \n",
      "Batch: 3216. Acc: 0.279836. Loss: 2.082194. Batch_acc: 0.301290. Batch_loss: 2.016461 \n",
      "Batch: 3217. Acc: 0.279849. Loss: 2.082162. Batch_acc: 0.320988. Batch_loss: 1.980906 \n",
      "Batch: 3218. Acc: 0.279858. Loss: 2.082140. Batch_acc: 0.308438. Batch_loss: 2.010576 \n",
      "Batch: 3219. Acc: 0.279867. Loss: 2.082118. Batch_acc: 0.307513. Batch_loss: 2.011413 \n",
      "Batch: 3220. Acc: 0.279880. Loss: 2.082082. Batch_acc: 0.322053. Batch_loss: 1.967731 \n",
      "Batch: 3221. Acc: 0.279891. Loss: 2.082052. Batch_acc: 0.315124. Batch_loss: 1.986267 \n",
      "Batch: 3222. Acc: 0.279903. Loss: 2.082010. Batch_acc: 0.320416. Batch_loss: 1.947460 \n",
      "Batch: 3223. Acc: 0.279914. Loss: 2.081980. Batch_acc: 0.312937. Batch_loss: 1.981943 \n",
      "Batch: 3224. Acc: 0.279924. Loss: 2.081950. Batch_acc: 0.314157. Batch_loss: 1.989079 \n",
      "Batch: 3225. Acc: 0.279936. Loss: 2.081906. Batch_acc: 0.318021. Batch_loss: 1.934730 \n",
      "Batch: 3226. Acc: 0.279945. Loss: 2.081876. Batch_acc: 0.308271. Batch_loss: 1.984604 \n",
      "Batch: 3227. Acc: 0.279954. Loss: 2.081843. Batch_acc: 0.309008. Batch_loss: 1.977810 \n",
      "Batch: 3228. Acc: 0.279959. Loss: 2.081815. Batch_acc: 0.296857. Batch_loss: 1.989004 \n",
      "Batch: 3229. Acc: 0.279971. Loss: 2.081783. Batch_acc: 0.317654. Batch_loss: 1.978291 \n",
      "Batch: 3230. Acc: 0.279980. Loss: 2.081751. Batch_acc: 0.310325. Batch_loss: 1.978878 \n",
      "Batch: 3231. Acc: 0.279985. Loss: 2.081720. Batch_acc: 0.295711. Batch_loss: 1.982958 \n",
      "Batch: 3232. Acc: 0.279996. Loss: 2.081689. Batch_acc: 0.315242. Batch_loss: 1.981169 \n",
      "Batch: 3233. Acc: 0.280005. Loss: 2.081648. Batch_acc: 0.309377. Batch_loss: 1.952422 \n",
      "Batch: 3234. Acc: 0.280015. Loss: 2.081620. Batch_acc: 0.311703. Batch_loss: 1.990881 \n",
      "Batch: 3235. Acc: 0.280029. Loss: 2.081568. Batch_acc: 0.325221. Batch_loss: 1.920221 \n",
      "Batch: 3236. Acc: 0.280042. Loss: 2.081528. Batch_acc: 0.319611. Batch_loss: 1.950710 \n",
      "Batch: 3237. Acc: 0.280056. Loss: 2.081484. Batch_acc: 0.324928. Batch_loss: 1.939461 \n",
      "Batch: 3238. Acc: 0.280068. Loss: 2.081448. Batch_acc: 0.320186. Batch_loss: 1.964576 \n",
      "Batch: 3239. Acc: 0.280076. Loss: 2.081413. Batch_acc: 0.305889. Batch_loss: 1.969955 \n",
      "Batch: 3240. Acc: 0.280086. Loss: 2.081373. Batch_acc: 0.312570. Batch_loss: 1.954356 \n",
      "Batch: 3241. Acc: 0.280103. Loss: 2.081326. Batch_acc: 0.333333. Batch_loss: 1.928928 \n",
      "Batch: 3242. Acc: 0.280109. Loss: 2.081298. Batch_acc: 0.301149. Batch_loss: 1.992074 \n",
      "Batch: 3243. Acc: 0.280121. Loss: 2.081265. Batch_acc: 0.316809. Batch_loss: 1.975885 \n",
      "Batch: 3244. Acc: 0.280129. Loss: 2.081230. Batch_acc: 0.308266. Batch_loss: 1.965251 \n",
      "Batch: 3245. Acc: 0.280137. Loss: 2.081201. Batch_acc: 0.307110. Batch_loss: 1.986516 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3246. Acc: 0.280150. Loss: 2.081169. Batch_acc: 0.321859. Batch_loss: 1.977094 \n",
      "Batch: 3247. Acc: 0.280155. Loss: 2.081150. Batch_acc: 0.296211. Batch_loss: 2.021947 \n",
      "Batch: 3248. Acc: 0.280166. Loss: 2.081116. Batch_acc: 0.316559. Batch_loss: 1.968551 \n",
      "Batch: 3249. Acc: 0.280178. Loss: 2.081081. Batch_acc: 0.316905. Batch_loss: 1.966847 \n",
      "Batch: 3250. Acc: 0.280186. Loss: 2.081043. Batch_acc: 0.307913. Batch_loss: 1.957141 \n",
      "Batch: 3251. Acc: 0.280195. Loss: 2.081010. Batch_acc: 0.307913. Batch_loss: 1.975947 \n",
      "Batch: 3252. Acc: 0.280207. Loss: 2.080973. Batch_acc: 0.318732. Batch_loss: 1.960824 \n",
      "Batch: 3253. Acc: 0.280214. Loss: 2.080950. Batch_acc: 0.304114. Batch_loss: 2.000394 \n",
      "Batch: 3254. Acc: 0.280227. Loss: 2.080914. Batch_acc: 0.321551. Batch_loss: 1.965715 \n",
      "Batch: 3255. Acc: 0.280237. Loss: 2.080878. Batch_acc: 0.314525. Batch_loss: 1.968162 \n",
      "Batch: 3256. Acc: 0.280245. Loss: 2.080853. Batch_acc: 0.305556. Batch_loss: 1.995281 \n",
      "Batch: 3257. Acc: 0.280255. Loss: 2.080822. Batch_acc: 0.313450. Batch_loss: 1.980163 \n",
      "Batch: 3258. Acc: 0.280263. Loss: 2.080791. Batch_acc: 0.306628. Batch_loss: 1.977736 \n",
      "Batch: 3259. Acc: 0.280270. Loss: 2.080760. Batch_acc: 0.303864. Batch_loss: 1.977858 \n",
      "Batch: 3260. Acc: 0.280282. Loss: 2.080726. Batch_acc: 0.320140. Batch_loss: 1.970687 \n",
      "Batch: 3261. Acc: 0.280292. Loss: 2.080698. Batch_acc: 0.309843. Batch_loss: 1.992769 \n",
      "Batch: 3262. Acc: 0.280302. Loss: 2.080674. Batch_acc: 0.314368. Batch_loss: 2.000110 \n",
      "Batch: 3263. Acc: 0.280312. Loss: 2.080645. Batch_acc: 0.314418. Batch_loss: 1.987508 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.28031238488694465. Loss per char: 2.080645412567118. Time: 1627205145.1591027\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 21, 20, 20, 17, 19, 18, 17, 25, 21,\n",
      "        23, 23,  1, 85, 66, 76, 70,  1, 66, 88, 66, 90,  1, 14, 20, 17, 21, 22,\n",
      "        32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.280318. Loss: 2.080620. Batch_acc: 0.299356. Batch_loss: 1.995458 \n",
      "Batch: 3265. Acc: 0.280330. Loss: 2.080582. Batch_acc: 0.319294. Batch_loss: 1.958417 \n",
      "Batch: 3266. Acc: 0.280340. Loss: 2.080566. Batch_acc: 0.313167. Batch_loss: 2.027873 \n",
      "Batch: 3267. Acc: 0.280351. Loss: 2.080541. Batch_acc: 0.314825. Batch_loss: 1.997519 \n",
      "Batch: 3268. Acc: 0.280357. Loss: 2.080515. Batch_acc: 0.302655. Batch_loss: 1.994926 \n",
      "Batch: 3269. Acc: 0.280367. Loss: 2.080489. Batch_acc: 0.312571. Batch_loss: 1.996061 \n",
      "Batch: 3270. Acc: 0.280380. Loss: 2.080446. Batch_acc: 0.321793. Batch_loss: 1.942116 \n",
      "Batch: 3271. Acc: 0.280389. Loss: 2.080416. Batch_acc: 0.311164. Batch_loss: 1.979048 \n",
      "Batch: 3272. Acc: 0.280395. Loss: 2.080392. Batch_acc: 0.298155. Batch_loss: 2.000629 \n",
      "Batch: 3273. Acc: 0.280403. Loss: 2.080356. Batch_acc: 0.308227. Batch_loss: 1.963937 \n",
      "Batch: 3274. Acc: 0.280413. Loss: 2.080324. Batch_acc: 0.313356. Batch_loss: 1.976242 \n",
      "Batch: 3275. Acc: 0.280421. Loss: 2.080306. Batch_acc: 0.305652. Batch_loss: 2.019257 \n",
      "Batch: 3276. Acc: 0.280426. Loss: 2.080277. Batch_acc: 0.296812. Batch_loss: 1.983719 \n",
      "Batch: 3277. Acc: 0.280434. Loss: 2.080242. Batch_acc: 0.306931. Batch_loss: 1.971314 \n",
      "Batch: 3278. Acc: 0.280443. Loss: 2.080213. Batch_acc: 0.307648. Batch_loss: 1.985619 \n",
      "Batch: 3279. Acc: 0.280452. Loss: 2.080187. Batch_acc: 0.310725. Batch_loss: 1.993587 \n",
      "Batch: 3280. Acc: 0.280458. Loss: 2.080169. Batch_acc: 0.301026. Batch_loss: 2.023686 \n",
      "Batch: 3281. Acc: 0.280468. Loss: 2.080138. Batch_acc: 0.310887. Batch_loss: 1.979933 \n",
      "Batch: 3282. Acc: 0.280478. Loss: 2.080110. Batch_acc: 0.313467. Batch_loss: 1.989628 \n",
      "Batch: 3283. Acc: 0.280487. Loss: 2.080091. Batch_acc: 0.312536. Batch_loss: 2.015656 \n",
      "Batch: 3284. Acc: 0.280497. Loss: 2.080067. Batch_acc: 0.311758. Batch_loss: 1.999258 \n",
      "Batch: 3285. Acc: 0.280506. Loss: 2.080039. Batch_acc: 0.312246. Batch_loss: 1.987906 \n",
      "Batch: 3286. Acc: 0.280512. Loss: 2.080013. Batch_acc: 0.300228. Batch_loss: 1.994849 \n",
      "Batch: 3287. Acc: 0.280524. Loss: 2.079985. Batch_acc: 0.316921. Batch_loss: 1.988334 \n",
      "Batch: 3288. Acc: 0.280530. Loss: 2.079958. Batch_acc: 0.303136. Batch_loss: 1.991135 \n",
      "Batch: 3289. Acc: 0.280539. Loss: 2.079931. Batch_acc: 0.308815. Batch_loss: 1.991940 \n",
      "Batch: 3290. Acc: 0.280545. Loss: 2.079912. Batch_acc: 0.302312. Batch_loss: 2.015862 \n",
      "Batch: 3291. Acc: 0.280557. Loss: 2.079879. Batch_acc: 0.318001. Batch_loss: 1.971142 \n",
      "Batch: 3292. Acc: 0.280567. Loss: 2.079855. Batch_acc: 0.315789. Batch_loss: 1.999189 \n",
      "Batch: 3293. Acc: 0.280573. Loss: 2.079834. Batch_acc: 0.299487. Batch_loss: 2.013422 \n",
      "Batch: 3294. Acc: 0.280585. Loss: 2.079799. Batch_acc: 0.319429. Batch_loss: 1.963224 \n",
      "Batch: 3295. Acc: 0.280595. Loss: 2.079767. Batch_acc: 0.311785. Batch_loss: 1.974751 \n",
      "Batch: 3296. Acc: 0.280604. Loss: 2.079736. Batch_acc: 0.312464. Batch_loss: 1.978408 \n",
      "Batch: 3297. Acc: 0.280618. Loss: 2.079703. Batch_acc: 0.325836. Batch_loss: 1.972787 \n",
      "Batch: 3298. Acc: 0.280634. Loss: 2.079657. Batch_acc: 0.332373. Batch_loss: 1.926179 \n",
      "Batch: 3299. Acc: 0.280643. Loss: 2.079632. Batch_acc: 0.311847. Batch_loss: 1.998257 \n",
      "Batch: 3300. Acc: 0.280651. Loss: 2.079604. Batch_acc: 0.309102. Batch_loss: 1.983950 \n",
      "Batch: 3301. Acc: 0.280662. Loss: 2.079577. Batch_acc: 0.315607. Batch_loss: 1.990889 \n",
      "Batch: 3302. Acc: 0.280671. Loss: 2.079543. Batch_acc: 0.309740. Batch_loss: 1.968626 \n",
      "Batch: 3303. Acc: 0.280677. Loss: 2.079517. Batch_acc: 0.300581. Batch_loss: 1.992821 \n",
      "Batch: 3304. Acc: 0.280687. Loss: 2.079478. Batch_acc: 0.314898. Batch_loss: 1.952137 \n",
      "Batch: 3305. Acc: 0.280695. Loss: 2.079452. Batch_acc: 0.307018. Batch_loss: 1.991698 \n",
      "Batch: 3306. Acc: 0.280708. Loss: 2.079414. Batch_acc: 0.321531. Batch_loss: 1.956218 \n",
      "Batch: 3307. Acc: 0.280714. Loss: 2.079379. Batch_acc: 0.302573. Batch_loss: 1.964812 \n",
      "Batch: 3308. Acc: 0.280723. Loss: 2.079357. Batch_acc: 0.306908. Batch_loss: 2.010063 \n",
      "Batch: 3309. Acc: 0.280734. Loss: 2.079323. Batch_acc: 0.317171. Batch_loss: 1.966876 \n",
      "Batch: 3310. Acc: 0.280746. Loss: 2.079286. Batch_acc: 0.321529. Batch_loss: 1.957506 \n",
      "Batch: 3311. Acc: 0.280760. Loss: 2.079249. Batch_acc: 0.325488. Batch_loss: 1.957244 \n",
      "Batch: 3312. Acc: 0.280767. Loss: 2.079226. Batch_acc: 0.303541. Batch_loss: 2.006577 \n",
      "Batch: 3313. Acc: 0.280779. Loss: 2.079193. Batch_acc: 0.320821. Batch_loss: 1.966409 \n",
      "Batch: 3314. Acc: 0.280790. Loss: 2.079156. Batch_acc: 0.317533. Batch_loss: 1.957050 \n",
      "Batch: 3315. Acc: 0.280799. Loss: 2.079131. Batch_acc: 0.309132. Batch_loss: 2.000110 \n",
      "Batch: 3316. Acc: 0.280812. Loss: 2.079089. Batch_acc: 0.323745. Batch_loss: 1.942009 \n",
      "Batch: 3317. Acc: 0.280822. Loss: 2.079049. Batch_acc: 0.314594. Batch_loss: 1.948484 \n",
      "Batch: 3318. Acc: 0.280836. Loss: 2.079010. Batch_acc: 0.326365. Batch_loss: 1.945550 \n",
      "Batch: 3319. Acc: 0.280843. Loss: 2.078982. Batch_acc: 0.303674. Batch_loss: 1.987384 \n",
      "Batch: 3320. Acc: 0.280853. Loss: 2.078955. Batch_acc: 0.316059. Batch_loss: 1.990275 \n",
      "Batch: 3321. Acc: 0.280865. Loss: 2.078921. Batch_acc: 0.320952. Batch_loss: 1.963967 \n",
      "Batch: 3322. Acc: 0.280881. Loss: 2.078871. Batch_acc: 0.333718. Batch_loss: 1.911952 \n",
      "Batch: 3323. Acc: 0.280892. Loss: 2.078834. Batch_acc: 0.316219. Batch_loss: 1.955131 \n",
      "Batch: 3324. Acc: 0.280901. Loss: 2.078802. Batch_acc: 0.314760. Batch_loss: 1.970871 \n",
      "Batch: 3325. Acc: 0.280911. Loss: 2.078767. Batch_acc: 0.310535. Batch_loss: 1.967462 \n",
      "Batch: 3326. Acc: 0.280922. Loss: 2.078749. Batch_acc: 0.317861. Batch_loss: 2.015060 \n",
      "Batch: 3327. Acc: 0.280933. Loss: 2.078722. Batch_acc: 0.320000. Batch_loss: 1.989615 \n",
      "Batch: 3328. Acc: 0.280939. Loss: 2.078698. Batch_acc: 0.300117. Batch_loss: 1.997411 \n",
      "Batch: 3329. Acc: 0.280951. Loss: 2.078669. Batch_acc: 0.320624. Batch_loss: 1.982469 \n",
      "Batch: 3330. Acc: 0.280957. Loss: 2.078660. Batch_acc: 0.302647. Batch_loss: 2.047522 \n",
      "Batch: 3331. Acc: 0.280967. Loss: 2.078626. Batch_acc: 0.313441. Batch_loss: 1.964879 \n",
      "Batch: 3332. Acc: 0.280978. Loss: 2.078587. Batch_acc: 0.318815. Batch_loss: 1.949381 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3333. Acc: 0.280979. Loss: 2.078569. Batch_acc: 0.282787. Batch_loss: 2.016880 \n",
      "Batch: 3334. Acc: 0.280991. Loss: 2.078530. Batch_acc: 0.322414. Batch_loss: 1.948407 \n",
      "Batch: 3335. Acc: 0.281008. Loss: 2.078488. Batch_acc: 0.334862. Batch_loss: 1.940376 \n",
      "Batch: 3336. Acc: 0.281016. Loss: 2.078459. Batch_acc: 0.310523. Batch_loss: 1.979357 \n",
      "Batch: 3337. Acc: 0.281024. Loss: 2.078427. Batch_acc: 0.304518. Batch_loss: 1.975147 \n",
      "Batch: 3338. Acc: 0.281028. Loss: 2.078405. Batch_acc: 0.295139. Batch_loss: 2.004235 \n",
      "Batch: 3339. Acc: 0.281037. Loss: 2.078378. Batch_acc: 0.310167. Batch_loss: 1.990275 \n",
      "Batch: 3340. Acc: 0.281046. Loss: 2.078343. Batch_acc: 0.312535. Batch_loss: 1.963189 \n",
      "Batch: 3341. Acc: 0.281053. Loss: 2.078313. Batch_acc: 0.304977. Batch_loss: 1.977333 \n",
      "Batch: 3342. Acc: 0.281068. Loss: 2.078270. Batch_acc: 0.328524. Batch_loss: 1.939484 \n",
      "Batch: 3343. Acc: 0.281074. Loss: 2.078250. Batch_acc: 0.300000. Batch_loss: 2.010252 \n",
      "Batch: 3344. Acc: 0.281081. Loss: 2.078221. Batch_acc: 0.304446. Batch_loss: 1.982696 \n",
      "Batch: 3345. Acc: 0.281088. Loss: 2.078200. Batch_acc: 0.304174. Batch_loss: 2.010035 \n",
      "Batch: 3346. Acc: 0.281096. Loss: 2.078179. Batch_acc: 0.310708. Batch_loss: 2.005302 \n",
      "Batch: 3347. Acc: 0.281102. Loss: 2.078165. Batch_acc: 0.299125. Batch_loss: 2.031256 \n",
      "Batch: 3348. Acc: 0.281111. Loss: 2.078137. Batch_acc: 0.310896. Batch_loss: 1.985028 \n",
      "Batch: 3349. Acc: 0.281118. Loss: 2.078117. Batch_acc: 0.306206. Batch_loss: 2.010961 \n",
      "Batch: 3350. Acc: 0.281125. Loss: 2.078091. Batch_acc: 0.305305. Batch_loss: 1.991563 \n",
      "Batch: 3351. Acc: 0.281135. Loss: 2.078062. Batch_acc: 0.313246. Batch_loss: 1.982011 \n",
      "Batch: 3352. Acc: 0.281144. Loss: 2.078033. Batch_acc: 0.310563. Batch_loss: 1.980578 \n",
      "Batch: 3353. Acc: 0.281154. Loss: 2.078000. Batch_acc: 0.315107. Batch_loss: 1.971261 \n",
      "Batch: 3354. Acc: 0.281167. Loss: 2.077960. Batch_acc: 0.323283. Batch_loss: 1.945240 \n",
      "Batch: 3355. Acc: 0.281171. Loss: 2.077943. Batch_acc: 0.295255. Batch_loss: 2.022573 \n",
      "Batch: 3356. Acc: 0.281177. Loss: 2.077925. Batch_acc: 0.298876. Batch_loss: 2.016778 \n",
      "Batch: 3357. Acc: 0.281185. Loss: 2.077900. Batch_acc: 0.310267. Batch_loss: 1.997037 \n",
      "Batch: 3358. Acc: 0.281197. Loss: 2.077865. Batch_acc: 0.320966. Batch_loss: 1.955591 \n",
      "Batch: 3359. Acc: 0.281204. Loss: 2.077844. Batch_acc: 0.306853. Batch_loss: 2.005650 \n",
      "Batch: 3360. Acc: 0.281215. Loss: 2.077804. Batch_acc: 0.315670. Batch_loss: 1.944067 \n",
      "Batch: 3361. Acc: 0.281225. Loss: 2.077781. Batch_acc: 0.315789. Batch_loss: 2.000935 \n",
      "Batch: 3362. Acc: 0.281235. Loss: 2.077751. Batch_acc: 0.313647. Batch_loss: 1.975856 \n",
      "Batch: 3363. Acc: 0.281242. Loss: 2.077728. Batch_acc: 0.305923. Batch_loss: 1.999854 \n",
      "Batch: 3364. Acc: 0.281251. Loss: 2.077698. Batch_acc: 0.311785. Batch_loss: 1.978207 \n",
      "Batch: 3365. Acc: 0.281259. Loss: 2.077680. Batch_acc: 0.308378. Batch_loss: 2.014095 \n",
      "Batch: 3366. Acc: 0.281269. Loss: 2.077655. Batch_acc: 0.316686. Batch_loss: 1.994579 \n",
      "Batch: 3367. Acc: 0.281278. Loss: 2.077624. Batch_acc: 0.309699. Batch_loss: 1.973737 \n",
      "Batch: 3368. Acc: 0.281286. Loss: 2.077592. Batch_acc: 0.310046. Batch_loss: 1.969217 \n",
      "Batch: 3369. Acc: 0.281293. Loss: 2.077561. Batch_acc: 0.304399. Batch_loss: 1.971796 \n",
      "Batch: 3370. Acc: 0.281304. Loss: 2.077533. Batch_acc: 0.320163. Batch_loss: 1.981319 \n",
      "Batch: 3371. Acc: 0.281311. Loss: 2.077512. Batch_acc: 0.303662. Batch_loss: 2.009223 \n",
      "Batch: 3372. Acc: 0.281318. Loss: 2.077486. Batch_acc: 0.306110. Batch_loss: 1.988027 \n",
      "Batch: 3373. Acc: 0.281331. Loss: 2.077454. Batch_acc: 0.323977. Batch_loss: 1.966511 \n",
      "Batch: 3374. Acc: 0.281345. Loss: 2.077424. Batch_acc: 0.327606. Batch_loss: 1.977215 \n",
      "Batch: 3375. Acc: 0.281357. Loss: 2.077394. Batch_acc: 0.322357. Batch_loss: 1.976729 \n",
      "Batch: 3376. Acc: 0.281363. Loss: 2.077363. Batch_acc: 0.300620. Batch_loss: 1.971751 \n",
      "Batch: 3377. Acc: 0.281373. Loss: 2.077327. Batch_acc: 0.314961. Batch_loss: 1.960016 \n",
      "Batch: 3378. Acc: 0.281383. Loss: 2.077294. Batch_acc: 0.314952. Batch_loss: 1.967281 \n",
      "Batch: 3379. Acc: 0.281395. Loss: 2.077265. Batch_acc: 0.322996. Batch_loss: 1.976208 \n",
      "Batch: 3380. Acc: 0.281403. Loss: 2.077236. Batch_acc: 0.307648. Batch_loss: 1.980333 \n",
      "Batch: 3381. Acc: 0.281414. Loss: 2.077200. Batch_acc: 0.320118. Batch_loss: 1.953269 \n",
      "Batch: 3382. Acc: 0.281426. Loss: 2.077162. Batch_acc: 0.321799. Batch_loss: 1.948105 \n",
      "Batch: 3383. Acc: 0.281436. Loss: 2.077140. Batch_acc: 0.316404. Batch_loss: 2.003026 \n",
      "Batch: 3384. Acc: 0.281443. Loss: 2.077121. Batch_acc: 0.305790. Batch_loss: 2.014431 \n",
      "Batch: 3385. Acc: 0.281458. Loss: 2.077080. Batch_acc: 0.330650. Batch_loss: 1.936950 \n",
      "Batch: 3386. Acc: 0.281465. Loss: 2.077057. Batch_acc: 0.306845. Batch_loss: 1.997150 \n",
      "Batch: 3387. Acc: 0.281474. Loss: 2.077024. Batch_acc: 0.310405. Batch_loss: 1.966397 \n",
      "Batch: 3388. Acc: 0.281477. Loss: 2.077005. Batch_acc: 0.294118. Batch_loss: 2.010825 \n",
      "Batch: 3389. Acc: 0.281484. Loss: 2.076980. Batch_acc: 0.304800. Batch_loss: 1.989999 \n",
      "Batch: 3390. Acc: 0.281491. Loss: 2.076956. Batch_acc: 0.303592. Batch_loss: 1.996078 \n",
      "Batch: 3391. Acc: 0.281496. Loss: 2.076935. Batch_acc: 0.298871. Batch_loss: 2.002907 \n",
      "Batch: 3392. Acc: 0.281502. Loss: 2.076909. Batch_acc: 0.301994. Batch_loss: 1.992221 \n",
      "Batch: 3393. Acc: 0.281516. Loss: 2.076872. Batch_acc: 0.330654. Batch_loss: 1.950452 \n",
      "Batch: 3394. Acc: 0.281527. Loss: 2.076845. Batch_acc: 0.317116. Batch_loss: 1.983714 \n",
      "Batch: 3395. Acc: 0.281536. Loss: 2.076815. Batch_acc: 0.314253. Batch_loss: 1.974663 \n",
      "Batch: 3396. Acc: 0.281546. Loss: 2.076785. Batch_acc: 0.314965. Batch_loss: 1.973635 \n",
      "Batch: 3397. Acc: 0.281557. Loss: 2.076752. Batch_acc: 0.316990. Batch_loss: 1.965585 \n",
      "Batch: 3398. Acc: 0.281557. Loss: 2.076746. Batch_acc: 0.282840. Batch_loss: 2.055803 \n",
      "Batch: 3399. Acc: 0.281569. Loss: 2.076716. Batch_acc: 0.323167. Batch_loss: 1.972289 \n",
      "Batch: 3400. Acc: 0.281578. Loss: 2.076689. Batch_acc: 0.311703. Batch_loss: 1.985383 \n",
      "Batch: 3401. Acc: 0.281582. Loss: 2.076669. Batch_acc: 0.294872. Batch_loss: 2.007354 \n",
      "Batch: 3402. Acc: 0.281587. Loss: 2.076647. Batch_acc: 0.298276. Batch_loss: 2.002975 \n",
      "Batch: 3403. Acc: 0.281591. Loss: 2.076630. Batch_acc: 0.298359. Batch_loss: 2.017951 \n",
      "Batch: 3404. Acc: 0.281602. Loss: 2.076603. Batch_acc: 0.316448. Batch_loss: 1.983624 \n",
      "Batch: 3405. Acc: 0.281610. Loss: 2.076575. Batch_acc: 0.310029. Batch_loss: 1.983575 \n",
      "Batch: 3406. Acc: 0.281619. Loss: 2.076544. Batch_acc: 0.313737. Batch_loss: 1.969903 \n",
      "Batch: 3407. Acc: 0.281629. Loss: 2.076512. Batch_acc: 0.314773. Batch_loss: 1.968769 \n",
      "Batch: 3408. Acc: 0.281640. Loss: 2.076485. Batch_acc: 0.316667. Batch_loss: 1.984393 \n",
      "Batch: 3409. Acc: 0.281647. Loss: 2.076454. Batch_acc: 0.306977. Batch_loss: 1.968688 \n",
      "Batch: 3410. Acc: 0.281653. Loss: 2.076430. Batch_acc: 0.301974. Batch_loss: 1.992149 \n",
      "Batch: 3411. Acc: 0.281665. Loss: 2.076396. Batch_acc: 0.322338. Batch_loss: 1.960884 \n",
      "Batch: 3412. Acc: 0.281666. Loss: 2.076379. Batch_acc: 0.286132. Batch_loss: 2.018116 \n",
      "Batch: 3413. Acc: 0.281671. Loss: 2.076345. Batch_acc: 0.300875. Batch_loss: 1.957334 \n",
      "Batch: 3414. Acc: 0.281680. Loss: 2.076323. Batch_acc: 0.309780. Batch_loss: 2.003616 \n",
      "Batch: 3415. Acc: 0.281692. Loss: 2.076297. Batch_acc: 0.323227. Batch_loss: 1.989334 \n",
      "Batch: 3416. Acc: 0.281700. Loss: 2.076279. Batch_acc: 0.308849. Batch_loss: 2.013981 \n",
      "Batch: 3417. Acc: 0.281708. Loss: 2.076253. Batch_acc: 0.308910. Batch_loss: 1.984930 \n",
      "Batch: 3418. Acc: 0.281720. Loss: 2.076220. Batch_acc: 0.323580. Batch_loss: 1.963748 \n",
      "Batch: 3419. Acc: 0.281727. Loss: 2.076194. Batch_acc: 0.304773. Batch_loss: 1.986072 \n",
      "Batch: 3420. Acc: 0.281739. Loss: 2.076160. Batch_acc: 0.321826. Batch_loss: 1.965082 \n",
      "Batch: 3421. Acc: 0.281750. Loss: 2.076125. Batch_acc: 0.320874. Batch_loss: 1.954834 \n",
      "Batch: 3422. Acc: 0.281764. Loss: 2.076085. Batch_acc: 0.328125. Batch_loss: 1.939154 \n",
      "Batch: 3423. Acc: 0.281764. Loss: 2.076068. Batch_acc: 0.283343. Batch_loss: 2.015308 \n",
      "Batch: 3424. Acc: 0.281770. Loss: 2.076036. Batch_acc: 0.302220. Batch_loss: 1.968145 \n",
      "Batch: 3425. Acc: 0.281778. Loss: 2.076001. Batch_acc: 0.309689. Batch_loss: 1.957678 \n",
      "Batch: 3426. Acc: 0.281785. Loss: 2.075974. Batch_acc: 0.306075. Batch_loss: 1.980453 \n",
      "Batch: 3427. Acc: 0.281797. Loss: 2.075936. Batch_acc: 0.320615. Batch_loss: 1.947859 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3428. Acc: 0.281806. Loss: 2.075905. Batch_acc: 0.313458. Batch_loss: 1.969828 \n",
      "Batch: 3429. Acc: 0.281811. Loss: 2.075883. Batch_acc: 0.298791. Batch_loss: 1.999832 \n",
      "Batch: 3430. Acc: 0.281822. Loss: 2.075857. Batch_acc: 0.318610. Batch_loss: 1.985636 \n",
      "Batch: 3431. Acc: 0.281830. Loss: 2.075828. Batch_acc: 0.311673. Batch_loss: 1.977786 \n",
      "Batch: 3432. Acc: 0.281845. Loss: 2.075786. Batch_acc: 0.331062. Batch_loss: 1.931623 \n",
      "Batch: 3433. Acc: 0.281856. Loss: 2.075746. Batch_acc: 0.318775. Batch_loss: 1.941542 \n",
      "Batch: 3434. Acc: 0.281865. Loss: 2.075713. Batch_acc: 0.311364. Batch_loss: 1.964465 \n",
      "Batch: 3435. Acc: 0.281875. Loss: 2.075677. Batch_acc: 0.315436. Batch_loss: 1.955293 \n",
      "Batch: 3436. Acc: 0.281884. Loss: 2.075651. Batch_acc: 0.314783. Batch_loss: 1.984692 \n",
      "Batch: 3437. Acc: 0.281887. Loss: 2.075626. Batch_acc: 0.292935. Batch_loss: 1.990024 \n",
      "Batch: 3438. Acc: 0.281900. Loss: 2.075591. Batch_acc: 0.324801. Batch_loss: 1.957974 \n",
      "Batch: 3439. Acc: 0.281904. Loss: 2.075567. Batch_acc: 0.296857. Batch_loss: 1.990271 \n",
      "Batch: 3440. Acc: 0.281910. Loss: 2.075553. Batch_acc: 0.303842. Batch_loss: 2.026050 \n",
      "Batch: 3441. Acc: 0.281922. Loss: 2.075521. Batch_acc: 0.320416. Batch_loss: 1.967262 \n",
      "Batch: 3442. Acc: 0.281930. Loss: 2.075495. Batch_acc: 0.309714. Batch_loss: 1.985826 \n",
      "Batch: 3443. Acc: 0.281942. Loss: 2.075459. Batch_acc: 0.323579. Batch_loss: 1.952457 \n",
      "Batch: 3444. Acc: 0.281949. Loss: 2.075428. Batch_acc: 0.305312. Batch_loss: 1.968474 \n",
      "Batch: 3445. Acc: 0.281956. Loss: 2.075404. Batch_acc: 0.305162. Batch_loss: 1.992647 \n",
      "Batch: 3446. Acc: 0.281957. Loss: 2.075388. Batch_acc: 0.287152. Batch_loss: 2.021491 \n",
      "Batch: 3447. Acc: 0.281969. Loss: 2.075357. Batch_acc: 0.325103. Batch_loss: 1.965614 \n",
      "Batch: 3448. Acc: 0.281980. Loss: 2.075327. Batch_acc: 0.320046. Batch_loss: 1.970689 \n",
      "Batch: 3449. Acc: 0.281986. Loss: 2.075312. Batch_acc: 0.301156. Batch_loss: 2.024271 \n",
      "Batch: 3450. Acc: 0.281996. Loss: 2.075275. Batch_acc: 0.313791. Batch_loss: 1.950491 \n",
      "Batch: 3451. Acc: 0.281998. Loss: 2.075253. Batch_acc: 0.292193. Batch_loss: 2.000993 \n",
      "Batch: 3452. Acc: 0.282007. Loss: 2.075227. Batch_acc: 0.310064. Batch_loss: 1.983087 \n",
      "Batch: 3453. Acc: 0.282010. Loss: 2.075208. Batch_acc: 0.295271. Batch_loss: 2.010377 \n",
      "Batch: 3454. Acc: 0.282021. Loss: 2.075180. Batch_acc: 0.318925. Batch_loss: 1.978290 \n",
      "Batch: 3455. Acc: 0.282029. Loss: 2.075157. Batch_acc: 0.310160. Batch_loss: 1.992537 \n",
      "Batch: 3456. Acc: 0.282040. Loss: 2.075123. Batch_acc: 0.320092. Batch_loss: 1.955998 \n",
      "Batch: 3457. Acc: 0.282046. Loss: 2.075098. Batch_acc: 0.302821. Batch_loss: 1.989869 \n",
      "Batch: 3458. Acc: 0.282054. Loss: 2.075069. Batch_acc: 0.309226. Batch_loss: 1.975910 \n",
      "Batch: 3459. Acc: 0.282062. Loss: 2.075040. Batch_acc: 0.311958. Batch_loss: 1.974633 \n",
      "Batch: 3460. Acc: 0.282067. Loss: 2.075022. Batch_acc: 0.298897. Batch_loss: 2.012468 \n",
      "Batch: 3461. Acc: 0.282075. Loss: 2.075002. Batch_acc: 0.309320. Batch_loss: 2.004661 \n",
      "Batch: 3462. Acc: 0.282083. Loss: 2.074969. Batch_acc: 0.311047. Batch_loss: 1.959558 \n",
      "Batch: 3463. Acc: 0.282092. Loss: 2.074950. Batch_acc: 0.312061. Batch_loss: 2.008293 \n",
      "Batch: 3464. Acc: 0.282101. Loss: 2.074922. Batch_acc: 0.313232. Batch_loss: 1.975920 \n",
      "Batch: 3465. Acc: 0.282112. Loss: 2.074891. Batch_acc: 0.321703. Batch_loss: 1.966051 \n",
      "Batch: 3466. Acc: 0.282119. Loss: 2.074865. Batch_acc: 0.308585. Batch_loss: 1.983247 \n",
      "Batch: 3467. Acc: 0.282125. Loss: 2.074843. Batch_acc: 0.301865. Batch_loss: 1.996285 \n",
      "Batch: 3468. Acc: 0.282133. Loss: 2.074817. Batch_acc: 0.310598. Batch_loss: 1.988597 \n",
      "Batch: 3469. Acc: 0.282145. Loss: 2.074787. Batch_acc: 0.321734. Batch_loss: 1.970791 \n",
      "Batch: 3470. Acc: 0.282153. Loss: 2.074761. Batch_acc: 0.310934. Batch_loss: 1.986735 \n",
      "Batch: 3471. Acc: 0.282163. Loss: 2.074733. Batch_acc: 0.315268. Batch_loss: 1.974980 \n",
      "Batch: 3472. Acc: 0.282174. Loss: 2.074691. Batch_acc: 0.321131. Batch_loss: 1.933458 \n",
      "Batch: 3473. Acc: 0.282183. Loss: 2.074663. Batch_acc: 0.312318. Batch_loss: 1.976537 \n",
      "Batch: 3474. Acc: 0.282193. Loss: 2.074639. Batch_acc: 0.317599. Batch_loss: 1.991519 \n",
      "Batch: 3475. Acc: 0.282200. Loss: 2.074622. Batch_acc: 0.306442. Batch_loss: 2.012849 \n",
      "Batch: 3476. Acc: 0.282206. Loss: 2.074605. Batch_acc: 0.302709. Batch_loss: 2.015396 \n",
      "Batch: 3477. Acc: 0.282217. Loss: 2.074569. Batch_acc: 0.320023. Batch_loss: 1.949490 \n",
      "Batch: 3478. Acc: 0.282225. Loss: 2.074541. Batch_acc: 0.310267. Batch_loss: 1.978687 \n",
      "Batch: 3479. Acc: 0.282228. Loss: 2.074527. Batch_acc: 0.294648. Batch_loss: 2.025313 \n",
      "Batch: 3480. Acc: 0.282238. Loss: 2.074497. Batch_acc: 0.317073. Batch_loss: 1.968641 \n",
      "Batch: 3481. Acc: 0.282247. Loss: 2.074468. Batch_acc: 0.311688. Batch_loss: 1.974775 \n",
      "Batch: 3482. Acc: 0.282252. Loss: 2.074447. Batch_acc: 0.301032. Batch_loss: 2.001925 \n",
      "Batch: 3483. Acc: 0.282259. Loss: 2.074424. Batch_acc: 0.306286. Batch_loss: 1.992630 \n",
      "Batch: 3484. Acc: 0.282273. Loss: 2.074388. Batch_acc: 0.330805. Batch_loss: 1.949226 \n",
      "Batch: 3485. Acc: 0.282283. Loss: 2.074363. Batch_acc: 0.319064. Batch_loss: 1.988616 \n",
      "Batch: 3486. Acc: 0.282295. Loss: 2.074327. Batch_acc: 0.320180. Batch_loss: 1.950320 \n",
      "Batch: 3487. Acc: 0.282303. Loss: 2.074298. Batch_acc: 0.312065. Batch_loss: 1.973526 \n",
      "Batch: 3488. Acc: 0.282314. Loss: 2.074261. Batch_acc: 0.319617. Batch_loss: 1.945476 \n",
      "Batch: 3489. Acc: 0.282325. Loss: 2.074231. Batch_acc: 0.321202. Batch_loss: 1.968754 \n",
      "Batch: 3490. Acc: 0.282332. Loss: 2.074205. Batch_acc: 0.308729. Batch_loss: 1.983312 \n",
      "Batch: 3491. Acc: 0.282337. Loss: 2.074185. Batch_acc: 0.298317. Batch_loss: 2.003204 \n",
      "Batch: 3492. Acc: 0.282346. Loss: 2.074158. Batch_acc: 0.315358. Batch_loss: 1.977622 \n",
      "Batch: 3493. Acc: 0.282356. Loss: 2.074127. Batch_acc: 0.317352. Batch_loss: 1.966502 \n",
      "Batch: 3494. Acc: 0.282369. Loss: 2.074093. Batch_acc: 0.325101. Batch_loss: 1.956548 \n",
      "Batch: 3495. Acc: 0.282380. Loss: 2.074071. Batch_acc: 0.324373. Batch_loss: 1.992910 \n",
      "Batch: 3496. Acc: 0.282393. Loss: 2.074041. Batch_acc: 0.329254. Batch_loss: 1.970012 \n",
      "Batch: 3497. Acc: 0.282402. Loss: 2.074011. Batch_acc: 0.313907. Batch_loss: 1.967461 \n",
      "Batch: 3498. Acc: 0.282411. Loss: 2.073980. Batch_acc: 0.311991. Batch_loss: 1.964584 \n",
      "Batch: 3499. Acc: 0.282418. Loss: 2.073959. Batch_acc: 0.308449. Batch_loss: 2.001634 \n",
      "Batch: 3500. Acc: 0.282426. Loss: 2.073921. Batch_acc: 0.311466. Batch_loss: 1.940376 \n",
      "Batch: 3501. Acc: 0.282436. Loss: 2.073882. Batch_acc: 0.317087. Batch_loss: 1.937678 \n",
      "Batch: 3502. Acc: 0.282438. Loss: 2.073870. Batch_acc: 0.289136. Batch_loss: 2.029984 \n",
      "Batch: 3503. Acc: 0.282441. Loss: 2.073850. Batch_acc: 0.293447. Batch_loss: 2.004811 \n",
      "Batch: 3504. Acc: 0.282449. Loss: 2.073824. Batch_acc: 0.309538. Batch_loss: 1.982872 \n",
      "Batch: 3505. Acc: 0.282455. Loss: 2.073794. Batch_acc: 0.304520. Batch_loss: 1.971550 \n",
      "Batch: 3506. Acc: 0.282467. Loss: 2.073762. Batch_acc: 0.323238. Batch_loss: 1.959103 \n",
      "Batch: 3507. Acc: 0.282475. Loss: 2.073736. Batch_acc: 0.312069. Batch_loss: 1.981225 \n",
      "Batch: 3508. Acc: 0.282485. Loss: 2.073706. Batch_acc: 0.315336. Batch_loss: 1.969572 \n",
      "Batch: 3509. Acc: 0.282492. Loss: 2.073677. Batch_acc: 0.306818. Batch_loss: 1.974964 \n",
      "Batch: 3510. Acc: 0.282504. Loss: 2.073642. Batch_acc: 0.326496. Batch_loss: 1.950023 \n",
      "Batch: 3511. Acc: 0.282511. Loss: 2.073613. Batch_acc: 0.306659. Batch_loss: 1.970266 \n",
      "Batch: 3512. Acc: 0.282515. Loss: 2.073593. Batch_acc: 0.295775. Batch_loss: 2.002816 \n",
      "Batch: 3513. Acc: 0.282522. Loss: 2.073576. Batch_acc: 0.306706. Batch_loss: 2.012908 \n",
      "Batch: 3514. Acc: 0.282535. Loss: 2.073542. Batch_acc: 0.330765. Batch_loss: 1.950071 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.2825350568538848. Loss per char: 2.073542000870122. Time: 1627205349.570215\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 22, 24, 18, 24,\n",
      "        20, 25, 23, 23, 20, 15, 21, 18,  1, 66, 79, 69,  1, 14, 17, 15, 23, 32,\n",
      "         3,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.282545. Loss: 2.073510. Batch_acc: 0.316118. Batch_loss: 1.964124 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3516. Acc: 0.282555. Loss: 2.073474. Batch_acc: 0.318497. Batch_loss: 1.946375 \n",
      "Batch: 3517. Acc: 0.282564. Loss: 2.073444. Batch_acc: 0.313603. Batch_loss: 1.966532 \n",
      "Batch: 3518. Acc: 0.282573. Loss: 2.073413. Batch_acc: 0.313974. Batch_loss: 1.966751 \n",
      "Batch: 3519. Acc: 0.282583. Loss: 2.073383. Batch_acc: 0.318815. Batch_loss: 1.964956 \n",
      "Batch: 3520. Acc: 0.282592. Loss: 2.073356. Batch_acc: 0.314320. Batch_loss: 1.975471 \n",
      "Batch: 3521. Acc: 0.282600. Loss: 2.073330. Batch_acc: 0.311853. Batch_loss: 1.981520 \n",
      "Batch: 3522. Acc: 0.282611. Loss: 2.073290. Batch_acc: 0.320658. Batch_loss: 1.935174 \n",
      "Batch: 3523. Acc: 0.282619. Loss: 2.073260. Batch_acc: 0.310563. Batch_loss: 1.967759 \n",
      "Batch: 3524. Acc: 0.282629. Loss: 2.073228. Batch_acc: 0.319767. Batch_loss: 1.958677 \n",
      "Batch: 3525. Acc: 0.282634. Loss: 2.073211. Batch_acc: 0.301435. Batch_loss: 2.011471 \n",
      "Batch: 3526. Acc: 0.282641. Loss: 2.073183. Batch_acc: 0.304273. Batch_loss: 1.972438 \n",
      "Batch: 3527. Acc: 0.282650. Loss: 2.073156. Batch_acc: 0.314718. Batch_loss: 1.977885 \n",
      "Batch: 3528. Acc: 0.282661. Loss: 2.073117. Batch_acc: 0.321368. Batch_loss: 1.937079 \n",
      "Batch: 3529. Acc: 0.282669. Loss: 2.073084. Batch_acc: 0.312429. Batch_loss: 1.958871 \n",
      "Batch: 3530. Acc: 0.282673. Loss: 2.073061. Batch_acc: 0.297081. Batch_loss: 1.990500 \n",
      "Batch: 3531. Acc: 0.282681. Loss: 2.073036. Batch_acc: 0.310803. Batch_loss: 1.987417 \n",
      "Batch: 3532. Acc: 0.282686. Loss: 2.073007. Batch_acc: 0.301032. Batch_loss: 1.970369 \n",
      "Batch: 3533. Acc: 0.282695. Loss: 2.072978. Batch_acc: 0.313817. Batch_loss: 1.967050 \n",
      "Batch: 3534. Acc: 0.282705. Loss: 2.072947. Batch_acc: 0.315820. Batch_loss: 1.964864 \n",
      "Batch: 3535. Acc: 0.282716. Loss: 2.072921. Batch_acc: 0.324324. Batch_loss: 1.982491 \n",
      "Batch: 3536. Acc: 0.282726. Loss: 2.072889. Batch_acc: 0.317358. Batch_loss: 1.954979 \n",
      "Batch: 3537. Acc: 0.282736. Loss: 2.072852. Batch_acc: 0.316108. Batch_loss: 1.950074 \n",
      "Batch: 3538. Acc: 0.282744. Loss: 2.072822. Batch_acc: 0.312253. Batch_loss: 1.968261 \n",
      "Batch: 3539. Acc: 0.282753. Loss: 2.072800. Batch_acc: 0.314581. Batch_loss: 1.996571 \n",
      "Batch: 3540. Acc: 0.282762. Loss: 2.072774. Batch_acc: 0.312135. Batch_loss: 1.977970 \n",
      "Batch: 3541. Acc: 0.282765. Loss: 2.072755. Batch_acc: 0.294328. Batch_loss: 2.004097 \n",
      "Batch: 3542. Acc: 0.282773. Loss: 2.072731. Batch_acc: 0.312215. Batch_loss: 1.986491 \n",
      "Batch: 3543. Acc: 0.282781. Loss: 2.072697. Batch_acc: 0.313161. Batch_loss: 1.949645 \n",
      "Batch: 3544. Acc: 0.282796. Loss: 2.072667. Batch_acc: 0.331658. Batch_loss: 1.969361 \n",
      "Batch: 3545. Acc: 0.282803. Loss: 2.072631. Batch_acc: 0.310345. Batch_loss: 1.945056 \n",
      "Batch: 3546. Acc: 0.282812. Loss: 2.072596. Batch_acc: 0.314106. Batch_loss: 1.948903 \n",
      "Batch: 3547. Acc: 0.282821. Loss: 2.072567. Batch_acc: 0.313803. Batch_loss: 1.971418 \n",
      "Batch: 3548. Acc: 0.282833. Loss: 2.072530. Batch_acc: 0.324646. Batch_loss: 1.944619 \n",
      "Batch: 3549. Acc: 0.282843. Loss: 2.072496. Batch_acc: 0.316498. Batch_loss: 1.955813 \n",
      "Batch: 3550. Acc: 0.282854. Loss: 2.072468. Batch_acc: 0.321839. Batch_loss: 1.971083 \n",
      "Batch: 3551. Acc: 0.282864. Loss: 2.072443. Batch_acc: 0.318966. Batch_loss: 1.984026 \n",
      "Batch: 3552. Acc: 0.282875. Loss: 2.072411. Batch_acc: 0.320628. Batch_loss: 1.963786 \n",
      "Batch: 3553. Acc: 0.282887. Loss: 2.072381. Batch_acc: 0.327273. Batch_loss: 1.963346 \n",
      "Batch: 3554. Acc: 0.282895. Loss: 2.072355. Batch_acc: 0.312573. Batch_loss: 1.977236 \n",
      "Batch: 3555. Acc: 0.282907. Loss: 2.072320. Batch_acc: 0.324801. Batch_loss: 1.948814 \n",
      "Batch: 3556. Acc: 0.282915. Loss: 2.072302. Batch_acc: 0.309123. Batch_loss: 2.007396 \n",
      "Batch: 3557. Acc: 0.282925. Loss: 2.072266. Batch_acc: 0.318391. Batch_loss: 1.944384 \n",
      "Batch: 3558. Acc: 0.282933. Loss: 2.072242. Batch_acc: 0.313034. Batch_loss: 1.987613 \n",
      "Batch: 3559. Acc: 0.282947. Loss: 2.072206. Batch_acc: 0.331435. Batch_loss: 1.947304 \n",
      "Batch: 3560. Acc: 0.282956. Loss: 2.072179. Batch_acc: 0.314403. Batch_loss: 1.971738 \n",
      "Batch: 3561. Acc: 0.282964. Loss: 2.072146. Batch_acc: 0.314040. Batch_loss: 1.957147 \n",
      "Batch: 3562. Acc: 0.282971. Loss: 2.072127. Batch_acc: 0.304985. Batch_loss: 2.001445 \n",
      "Batch: 3563. Acc: 0.282978. Loss: 2.072105. Batch_acc: 0.309005. Batch_loss: 1.991407 \n",
      "Batch: 3564. Acc: 0.282984. Loss: 2.072080. Batch_acc: 0.304719. Batch_loss: 1.985241 \n",
      "Batch: 3565. Acc: 0.282995. Loss: 2.072038. Batch_acc: 0.319822. Batch_loss: 1.929005 \n",
      "Batch: 3566. Acc: 0.283003. Loss: 2.072007. Batch_acc: 0.312360. Batch_loss: 1.961367 \n",
      "Batch: 3567. Acc: 0.283012. Loss: 2.071969. Batch_acc: 0.313647. Batch_loss: 1.937530 \n",
      "Batch: 3568. Acc: 0.283021. Loss: 2.071936. Batch_acc: 0.317171. Batch_loss: 1.955275 \n",
      "Batch: 3569. Acc: 0.283030. Loss: 2.071907. Batch_acc: 0.314334. Batch_loss: 1.971540 \n",
      "Batch: 3570. Acc: 0.283036. Loss: 2.071885. Batch_acc: 0.302312. Batch_loss: 1.996135 \n",
      "Batch: 3571. Acc: 0.283043. Loss: 2.071863. Batch_acc: 0.310051. Batch_loss: 1.993873 \n",
      "Batch: 3572. Acc: 0.283055. Loss: 2.071825. Batch_acc: 0.325926. Batch_loss: 1.937114 \n",
      "Batch: 3573. Acc: 0.283062. Loss: 2.071803. Batch_acc: 0.306342. Batch_loss: 1.992141 \n",
      "Batch: 3574. Acc: 0.283071. Loss: 2.071790. Batch_acc: 0.314568. Batch_loss: 2.026008 \n",
      "Batch: 3575. Acc: 0.283082. Loss: 2.071767. Batch_acc: 0.322711. Batch_loss: 1.990940 \n",
      "Batch: 3576. Acc: 0.283091. Loss: 2.071746. Batch_acc: 0.316696. Batch_loss: 1.993359 \n",
      "Batch: 3577. Acc: 0.283097. Loss: 2.071721. Batch_acc: 0.305795. Batch_loss: 1.983195 \n",
      "Batch: 3578. Acc: 0.283101. Loss: 2.071702. Batch_acc: 0.294683. Batch_loss: 2.005029 \n",
      "Batch: 3579. Acc: 0.283104. Loss: 2.071686. Batch_acc: 0.293852. Batch_loss: 2.014728 \n",
      "Batch: 3580. Acc: 0.283107. Loss: 2.071674. Batch_acc: 0.294902. Batch_loss: 2.027407 \n",
      "Batch: 3581. Acc: 0.283114. Loss: 2.071658. Batch_acc: 0.307736. Batch_loss: 2.014651 \n",
      "Batch: 3582. Acc: 0.283121. Loss: 2.071657. Batch_acc: 0.307478. Batch_loss: 2.067838 \n",
      "Batch: 3583. Acc: 0.283129. Loss: 2.071652. Batch_acc: 0.312463. Batch_loss: 2.055304 \n",
      "Batch: 3584. Acc: 0.283137. Loss: 2.071633. Batch_acc: 0.313873. Batch_loss: 2.000872 \n",
      "Batch: 3585. Acc: 0.283140. Loss: 2.071620. Batch_acc: 0.293396. Batch_loss: 2.026543 \n",
      "Batch: 3586. Acc: 0.283143. Loss: 2.071603. Batch_acc: 0.292160. Batch_loss: 2.009237 \n",
      "Batch: 3587. Acc: 0.283155. Loss: 2.071569. Batch_acc: 0.327146. Batch_loss: 1.948458 \n",
      "Batch: 3588. Acc: 0.283162. Loss: 2.071535. Batch_acc: 0.309226. Batch_loss: 1.952881 \n",
      "Batch: 3589. Acc: 0.283170. Loss: 2.071512. Batch_acc: 0.312865. Batch_loss: 1.988960 \n",
      "Batch: 3590. Acc: 0.283177. Loss: 2.071499. Batch_acc: 0.306395. Batch_loss: 2.021746 \n",
      "Batch: 3591. Acc: 0.283179. Loss: 2.071482. Batch_acc: 0.290051. Batch_loss: 2.011992 \n",
      "Batch: 3592. Acc: 0.283189. Loss: 2.071453. Batch_acc: 0.319246. Batch_loss: 1.969541 \n",
      "Batch: 3593. Acc: 0.283194. Loss: 2.071433. Batch_acc: 0.301260. Batch_loss: 1.997629 \n",
      "Batch: 3594. Acc: 0.283204. Loss: 2.071415. Batch_acc: 0.318644. Batch_loss: 2.009083 \n",
      "Batch: 3595. Acc: 0.283206. Loss: 2.071406. Batch_acc: 0.290920. Batch_loss: 2.038292 \n",
      "Batch: 3596. Acc: 0.283218. Loss: 2.071380. Batch_acc: 0.323680. Batch_loss: 1.981565 \n",
      "Batch: 3597. Acc: 0.283225. Loss: 2.071360. Batch_acc: 0.309972. Batch_loss: 1.998372 \n",
      "Batch: 3598. Acc: 0.283226. Loss: 2.071348. Batch_acc: 0.288232. Batch_loss: 2.028085 \n",
      "Batch: 3599. Acc: 0.283231. Loss: 2.071332. Batch_acc: 0.300343. Batch_loss: 2.014619 \n",
      "Batch: 3600. Acc: 0.283238. Loss: 2.071304. Batch_acc: 0.306215. Batch_loss: 1.973939 \n",
      "Batch: 3601. Acc: 0.283241. Loss: 2.071278. Batch_acc: 0.295184. Batch_loss: 1.975863 \n",
      "Batch: 3602. Acc: 0.283242. Loss: 2.071265. Batch_acc: 0.287836. Batch_loss: 2.026950 \n",
      "Batch: 3603. Acc: 0.283250. Loss: 2.071240. Batch_acc: 0.309050. Batch_loss: 1.982870 \n",
      "Batch: 3604. Acc: 0.283256. Loss: 2.071216. Batch_acc: 0.307963. Batch_loss: 1.980961 \n",
      "Batch: 3605. Acc: 0.283264. Loss: 2.071194. Batch_acc: 0.311772. Batch_loss: 1.991987 \n",
      "Batch: 3606. Acc: 0.283269. Loss: 2.071175. Batch_acc: 0.302339. Batch_loss: 2.001688 \n",
      "Batch: 3607. Acc: 0.283274. Loss: 2.071167. Batch_acc: 0.298975. Batch_loss: 2.044078 \n",
      "Batch: 3608. Acc: 0.283284. Loss: 2.071138. Batch_acc: 0.318891. Batch_loss: 1.966632 \n",
      "Batch: 3609. Acc: 0.283294. Loss: 2.071109. Batch_acc: 0.320416. Batch_loss: 1.963725 \n",
      "Batch: 3610. Acc: 0.283294. Loss: 2.071100. Batch_acc: 0.284828. Batch_loss: 2.041990 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3611. Acc: 0.283298. Loss: 2.071082. Batch_acc: 0.296067. Batch_loss: 2.006144 \n",
      "Batch: 3612. Acc: 0.283305. Loss: 2.071056. Batch_acc: 0.310011. Batch_loss: 1.977039 \n",
      "Batch: 3613. Acc: 0.283311. Loss: 2.071040. Batch_acc: 0.303550. Batch_loss: 2.011708 \n",
      "Batch: 3614. Acc: 0.283320. Loss: 2.071019. Batch_acc: 0.313649. Batch_loss: 1.997679 \n",
      "Batch: 3615. Acc: 0.283328. Loss: 2.070999. Batch_acc: 0.314073. Batch_loss: 1.999718 \n",
      "Batch: 3616. Acc: 0.283337. Loss: 2.070972. Batch_acc: 0.315913. Batch_loss: 1.970887 \n",
      "Batch: 3617. Acc: 0.283348. Loss: 2.070940. Batch_acc: 0.322015. Batch_loss: 1.956363 \n",
      "Batch: 3618. Acc: 0.283355. Loss: 2.070909. Batch_acc: 0.308748. Batch_loss: 1.961310 \n",
      "Batch: 3619. Acc: 0.283359. Loss: 2.070887. Batch_acc: 0.299884. Batch_loss: 1.991750 \n",
      "Batch: 3620. Acc: 0.283370. Loss: 2.070855. Batch_acc: 0.323042. Batch_loss: 1.953632 \n",
      "Batch: 3621. Acc: 0.283380. Loss: 2.070831. Batch_acc: 0.317348. Batch_loss: 1.980560 \n",
      "Batch: 3622. Acc: 0.283387. Loss: 2.070805. Batch_acc: 0.311073. Batch_loss: 1.977997 \n",
      "Batch: 3623. Acc: 0.283401. Loss: 2.070767. Batch_acc: 0.331823. Batch_loss: 1.937338 \n",
      "Batch: 3624. Acc: 0.283405. Loss: 2.070746. Batch_acc: 0.298559. Batch_loss: 1.992312 \n",
      "Batch: 3625. Acc: 0.283418. Loss: 2.070714. Batch_acc: 0.328308. Batch_loss: 1.958160 \n",
      "Batch: 3626. Acc: 0.283423. Loss: 2.070688. Batch_acc: 0.301765. Batch_loss: 1.976970 \n",
      "Batch: 3627. Acc: 0.283428. Loss: 2.070677. Batch_acc: 0.302352. Batch_loss: 2.027704 \n",
      "Batch: 3628. Acc: 0.283440. Loss: 2.070639. Batch_acc: 0.324830. Batch_loss: 1.937639 \n",
      "Batch: 3629. Acc: 0.283443. Loss: 2.070627. Batch_acc: 0.295195. Batch_loss: 2.024591 \n",
      "Batch: 3630. Acc: 0.283448. Loss: 2.070607. Batch_acc: 0.301653. Batch_loss: 1.997166 \n",
      "Batch: 3631. Acc: 0.283459. Loss: 2.070573. Batch_acc: 0.324801. Batch_loss: 1.949665 \n",
      "Batch: 3632. Acc: 0.283467. Loss: 2.070552. Batch_acc: 0.312427. Batch_loss: 1.990985 \n",
      "Batch: 3633. Acc: 0.283476. Loss: 2.070524. Batch_acc: 0.317003. Batch_loss: 1.968992 \n",
      "Batch: 3634. Acc: 0.283487. Loss: 2.070492. Batch_acc: 0.322727. Batch_loss: 1.956979 \n",
      "Batch: 3635. Acc: 0.283494. Loss: 2.070467. Batch_acc: 0.308585. Batch_loss: 1.977112 \n",
      "Batch: 3636. Acc: 0.283495. Loss: 2.070446. Batch_acc: 0.287913. Batch_loss: 1.996474 \n",
      "Batch: 3637. Acc: 0.283498. Loss: 2.070428. Batch_acc: 0.295044. Batch_loss: 2.005070 \n",
      "Batch: 3638. Acc: 0.283510. Loss: 2.070399. Batch_acc: 0.324653. Batch_loss: 1.962285 \n",
      "Batch: 3639. Acc: 0.283519. Loss: 2.070374. Batch_acc: 0.318290. Batch_loss: 1.976147 \n",
      "Batch: 3640. Acc: 0.283526. Loss: 2.070347. Batch_acc: 0.308815. Batch_loss: 1.970394 \n",
      "Batch: 3641. Acc: 0.283539. Loss: 2.070308. Batch_acc: 0.332360. Batch_loss: 1.926488 \n",
      "Batch: 3642. Acc: 0.283555. Loss: 2.070271. Batch_acc: 0.343643. Batch_loss: 1.937363 \n",
      "Batch: 3643. Acc: 0.283563. Loss: 2.070250. Batch_acc: 0.310702. Batch_loss: 1.992534 \n",
      "Batch: 3644. Acc: 0.283567. Loss: 2.070226. Batch_acc: 0.296400. Batch_loss: 1.985761 \n",
      "Batch: 3645. Acc: 0.283576. Loss: 2.070198. Batch_acc: 0.318922. Batch_loss: 1.968467 \n",
      "Batch: 3646. Acc: 0.283586. Loss: 2.070160. Batch_acc: 0.317560. Batch_loss: 1.934907 \n",
      "Batch: 3647. Acc: 0.283597. Loss: 2.070124. Batch_acc: 0.324511. Batch_loss: 1.936602 \n",
      "Batch: 3648. Acc: 0.283603. Loss: 2.070098. Batch_acc: 0.304696. Batch_loss: 1.976212 \n",
      "Batch: 3649. Acc: 0.283612. Loss: 2.070064. Batch_acc: 0.315367. Batch_loss: 1.947098 \n",
      "Batch: 3650. Acc: 0.283620. Loss: 2.070039. Batch_acc: 0.313467. Batch_loss: 1.979729 \n",
      "Batch: 3651. Acc: 0.283629. Loss: 2.070011. Batch_acc: 0.316975. Batch_loss: 1.965639 \n",
      "Batch: 3652. Acc: 0.283642. Loss: 2.069975. Batch_acc: 0.329526. Batch_loss: 1.939818 \n",
      "Batch: 3653. Acc: 0.283653. Loss: 2.069941. Batch_acc: 0.324610. Batch_loss: 1.949418 \n",
      "Batch: 3654. Acc: 0.283660. Loss: 2.069924. Batch_acc: 0.309340. Batch_loss: 2.008435 \n",
      "Batch: 3655. Acc: 0.283665. Loss: 2.069907. Batch_acc: 0.303416. Batch_loss: 2.006209 \n",
      "Batch: 3656. Acc: 0.283673. Loss: 2.069884. Batch_acc: 0.310424. Batch_loss: 1.987005 \n",
      "Batch: 3657. Acc: 0.283679. Loss: 2.069866. Batch_acc: 0.307007. Batch_loss: 2.000463 \n",
      "Batch: 3658. Acc: 0.283687. Loss: 2.069837. Batch_acc: 0.315242. Batch_loss: 1.965620 \n",
      "Batch: 3659. Acc: 0.283695. Loss: 2.069821. Batch_acc: 0.310305. Batch_loss: 2.009063 \n",
      "Batch: 3660. Acc: 0.283708. Loss: 2.069783. Batch_acc: 0.332955. Batch_loss: 1.934175 \n",
      "Batch: 3661. Acc: 0.283719. Loss: 2.069758. Batch_acc: 0.322044. Batch_loss: 1.978624 \n",
      "Batch: 3662. Acc: 0.283725. Loss: 2.069733. Batch_acc: 0.307692. Batch_loss: 1.978611 \n",
      "Batch: 3663. Acc: 0.283736. Loss: 2.069708. Batch_acc: 0.323462. Batch_loss: 1.977007 \n",
      "Batch: 3664. Acc: 0.283747. Loss: 2.069680. Batch_acc: 0.322216. Batch_loss: 1.969683 \n",
      "Batch: 3665. Acc: 0.283756. Loss: 2.069652. Batch_acc: 0.317156. Batch_loss: 1.969374 \n",
      "Batch: 3666. Acc: 0.283760. Loss: 2.069630. Batch_acc: 0.295930. Batch_loss: 1.989944 \n",
      "Batch: 3667. Acc: 0.283765. Loss: 2.069607. Batch_acc: 0.302995. Batch_loss: 1.984677 \n",
      "Batch: 3668. Acc: 0.283774. Loss: 2.069575. Batch_acc: 0.318260. Batch_loss: 1.952086 \n",
      "Batch: 3669. Acc: 0.283780. Loss: 2.069548. Batch_acc: 0.304857. Batch_loss: 1.966693 \n",
      "Batch: 3670. Acc: 0.283789. Loss: 2.069525. Batch_acc: 0.315553. Batch_loss: 1.987879 \n",
      "Batch: 3671. Acc: 0.283804. Loss: 2.069480. Batch_acc: 0.339397. Batch_loss: 1.908266 \n",
      "Batch: 3672. Acc: 0.283810. Loss: 2.069468. Batch_acc: 0.304973. Batch_loss: 2.022424 \n",
      "Batch: 3673. Acc: 0.283818. Loss: 2.069434. Batch_acc: 0.312184. Batch_loss: 1.947780 \n",
      "Batch: 3674. Acc: 0.283820. Loss: 2.069411. Batch_acc: 0.291104. Batch_loss: 1.987615 \n",
      "Batch: 3675. Acc: 0.283830. Loss: 2.069380. Batch_acc: 0.322727. Batch_loss: 1.955298 \n",
      "Batch: 3676. Acc: 0.283838. Loss: 2.069353. Batch_acc: 0.311853. Batch_loss: 1.970885 \n",
      "Batch: 3677. Acc: 0.283846. Loss: 2.069330. Batch_acc: 0.313980. Batch_loss: 1.985339 \n",
      "Batch: 3678. Acc: 0.283850. Loss: 2.069317. Batch_acc: 0.296119. Batch_loss: 2.018585 \n",
      "Batch: 3679. Acc: 0.283855. Loss: 2.069290. Batch_acc: 0.301651. Batch_loss: 1.972404 \n",
      "Batch: 3680. Acc: 0.283858. Loss: 2.069271. Batch_acc: 0.296567. Batch_loss: 2.000682 \n",
      "Batch: 3681. Acc: 0.283871. Loss: 2.069234. Batch_acc: 0.329781. Batch_loss: 1.935661 \n",
      "Batch: 3682. Acc: 0.283879. Loss: 2.069213. Batch_acc: 0.312037. Batch_loss: 1.993544 \n",
      "Batch: 3683. Acc: 0.283887. Loss: 2.069186. Batch_acc: 0.316147. Batch_loss: 1.971639 \n",
      "Batch: 3684. Acc: 0.283896. Loss: 2.069164. Batch_acc: 0.316099. Batch_loss: 1.987836 \n",
      "Batch: 3685. Acc: 0.283906. Loss: 2.069138. Batch_acc: 0.320160. Batch_loss: 1.970537 \n",
      "Batch: 3686. Acc: 0.283910. Loss: 2.069118. Batch_acc: 0.300178. Batch_loss: 1.995700 \n",
      "Batch: 3687. Acc: 0.283918. Loss: 2.069094. Batch_acc: 0.312717. Batch_loss: 1.981144 \n",
      "Batch: 3688. Acc: 0.283927. Loss: 2.069072. Batch_acc: 0.317470. Batch_loss: 1.985001 \n",
      "Batch: 3689. Acc: 0.283935. Loss: 2.069045. Batch_acc: 0.312429. Batch_loss: 1.969414 \n",
      "Batch: 3690. Acc: 0.283944. Loss: 2.069008. Batch_acc: 0.318003. Batch_loss: 1.938123 \n",
      "Batch: 3691. Acc: 0.283948. Loss: 2.068993. Batch_acc: 0.297909. Batch_loss: 2.013766 \n",
      "Batch: 3692. Acc: 0.283963. Loss: 2.068957. Batch_acc: 0.339135. Batch_loss: 1.938822 \n",
      "Batch: 3693. Acc: 0.283972. Loss: 2.068934. Batch_acc: 0.317369. Batch_loss: 1.981373 \n",
      "Batch: 3694. Acc: 0.283980. Loss: 2.068908. Batch_acc: 0.312145. Batch_loss: 1.974916 \n",
      "Batch: 3695. Acc: 0.283983. Loss: 2.068882. Batch_acc: 0.295699. Batch_loss: 1.971049 \n",
      "Batch: 3696. Acc: 0.283986. Loss: 2.068861. Batch_acc: 0.295612. Batch_loss: 1.990216 \n",
      "Batch: 3697. Acc: 0.284002. Loss: 2.068823. Batch_acc: 0.341787. Batch_loss: 1.927435 \n",
      "Batch: 3698. Acc: 0.284002. Loss: 2.068811. Batch_acc: 0.286122. Batch_loss: 2.023454 \n",
      "Batch: 3699. Acc: 0.284013. Loss: 2.068780. Batch_acc: 0.322506. Batch_loss: 1.952947 \n",
      "Batch: 3700. Acc: 0.284019. Loss: 2.068751. Batch_acc: 0.308049. Batch_loss: 1.961045 \n",
      "Batch: 3701. Acc: 0.284027. Loss: 2.068721. Batch_acc: 0.313003. Batch_loss: 1.960574 \n",
      "Batch: 3702. Acc: 0.284036. Loss: 2.068696. Batch_acc: 0.318235. Batch_loss: 1.973004 \n",
      "Batch: 3703. Acc: 0.284043. Loss: 2.068675. Batch_acc: 0.310091. Batch_loss: 1.994031 \n",
      "Batch: 3704. Acc: 0.284049. Loss: 2.068652. Batch_acc: 0.306706. Batch_loss: 1.981864 \n",
      "Batch: 3705. Acc: 0.284058. Loss: 2.068619. Batch_acc: 0.316111. Batch_loss: 1.949879 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3706. Acc: 0.284069. Loss: 2.068595. Batch_acc: 0.322785. Batch_loss: 1.978376 \n",
      "Batch: 3707. Acc: 0.284078. Loss: 2.068566. Batch_acc: 0.320115. Batch_loss: 1.963650 \n",
      "Batch: 3708. Acc: 0.284080. Loss: 2.068560. Batch_acc: 0.291593. Batch_loss: 2.044602 \n",
      "Batch: 3709. Acc: 0.284085. Loss: 2.068543. Batch_acc: 0.300748. Batch_loss: 2.005760 \n",
      "Batch: 3710. Acc: 0.284088. Loss: 2.068521. Batch_acc: 0.295101. Batch_loss: 1.987342 \n",
      "Batch: 3711. Acc: 0.284100. Loss: 2.068484. Batch_acc: 0.328188. Batch_loss: 1.930107 \n",
      "Batch: 3712. Acc: 0.284110. Loss: 2.068461. Batch_acc: 0.323139. Batch_loss: 1.983261 \n",
      "Batch: 3713. Acc: 0.284117. Loss: 2.068441. Batch_acc: 0.310345. Batch_loss: 1.990274 \n",
      "Batch: 3714. Acc: 0.284126. Loss: 2.068417. Batch_acc: 0.317297. Batch_loss: 1.981938 \n",
      "Batch: 3715. Acc: 0.284134. Loss: 2.068394. Batch_acc: 0.314403. Batch_loss: 1.980140 \n",
      "Batch: 3716. Acc: 0.284145. Loss: 2.068366. Batch_acc: 0.323446. Batch_loss: 1.967105 \n",
      "Batch: 3717. Acc: 0.284155. Loss: 2.068333. Batch_acc: 0.320690. Batch_loss: 1.942786 \n",
      "Batch: 3718. Acc: 0.284165. Loss: 2.068311. Batch_acc: 0.321614. Batch_loss: 1.989780 \n",
      "Batch: 3719. Acc: 0.284173. Loss: 2.068282. Batch_acc: 0.315759. Batch_loss: 1.958143 \n",
      "Batch: 3720. Acc: 0.284177. Loss: 2.068262. Batch_acc: 0.298447. Batch_loss: 1.995518 \n",
      "Batch: 3721. Acc: 0.284186. Loss: 2.068236. Batch_acc: 0.316618. Batch_loss: 1.967314 \n",
      "Batch: 3722. Acc: 0.284199. Loss: 2.068205. Batch_acc: 0.334086. Batch_loss: 1.955394 \n",
      "Batch: 3723. Acc: 0.284206. Loss: 2.068179. Batch_acc: 0.310285. Batch_loss: 1.972880 \n",
      "Batch: 3724. Acc: 0.284221. Loss: 2.068143. Batch_acc: 0.337900. Batch_loss: 1.934075 \n",
      "Batch: 3725. Acc: 0.284230. Loss: 2.068116. Batch_acc: 0.319026. Batch_loss: 1.965809 \n",
      "Batch: 3726. Acc: 0.284240. Loss: 2.068091. Batch_acc: 0.321159. Batch_loss: 1.974553 \n",
      "Batch: 3727. Acc: 0.284248. Loss: 2.068064. Batch_acc: 0.313737. Batch_loss: 1.970437 \n",
      "Batch: 3728. Acc: 0.284257. Loss: 2.068036. Batch_acc: 0.318605. Batch_loss: 1.961250 \n",
      "Batch: 3729. Acc: 0.284268. Loss: 2.068007. Batch_acc: 0.324492. Batch_loss: 1.962070 \n",
      "Batch: 3730. Acc: 0.284278. Loss: 2.067974. Batch_acc: 0.321985. Batch_loss: 1.944497 \n",
      "Batch: 3731. Acc: 0.284289. Loss: 2.067938. Batch_acc: 0.322635. Batch_loss: 1.937376 \n",
      "Batch: 3732. Acc: 0.284297. Loss: 2.067915. Batch_acc: 0.315490. Batch_loss: 1.983291 \n",
      "Batch: 3733. Acc: 0.284305. Loss: 2.067885. Batch_acc: 0.314626. Batch_loss: 1.956016 \n",
      "Batch: 3734. Acc: 0.284310. Loss: 2.067858. Batch_acc: 0.302837. Batch_loss: 1.965901 \n",
      "Batch: 3735. Acc: 0.284319. Loss: 2.067824. Batch_acc: 0.319362. Batch_loss: 1.939304 \n",
      "Batch: 3736. Acc: 0.284329. Loss: 2.067790. Batch_acc: 0.318832. Batch_loss: 1.941490 \n",
      "Batch: 3737. Acc: 0.284335. Loss: 2.067767. Batch_acc: 0.307518. Batch_loss: 1.983052 \n",
      "Batch: 3738. Acc: 0.284342. Loss: 2.067736. Batch_acc: 0.311523. Batch_loss: 1.949573 \n",
      "Batch: 3739. Acc: 0.284356. Loss: 2.067696. Batch_acc: 0.334876. Batch_loss: 1.918618 \n",
      "Batch: 3740. Acc: 0.284365. Loss: 2.067664. Batch_acc: 0.321513. Batch_loss: 1.942513 \n",
      "Batch: 3741. Acc: 0.284376. Loss: 2.067639. Batch_acc: 0.325217. Batch_loss: 1.975289 \n",
      "Batch: 3742. Acc: 0.284386. Loss: 2.067610. Batch_acc: 0.321096. Batch_loss: 1.956861 \n",
      "Batch: 3743. Acc: 0.284394. Loss: 2.067578. Batch_acc: 0.314465. Batch_loss: 1.949741 \n",
      "Batch: 3744. Acc: 0.284404. Loss: 2.067538. Batch_acc: 0.323227. Batch_loss: 1.917498 \n",
      "Batch: 3745. Acc: 0.284417. Loss: 2.067499. Batch_acc: 0.332390. Batch_loss: 1.925635 \n",
      "Batch: 3746. Acc: 0.284424. Loss: 2.067472. Batch_acc: 0.309454. Batch_loss: 1.962869 \n",
      "Batch: 3747. Acc: 0.284432. Loss: 2.067440. Batch_acc: 0.315940. Batch_loss: 1.945598 \n",
      "Batch: 3748. Acc: 0.284442. Loss: 2.067414. Batch_acc: 0.320988. Batch_loss: 1.973043 \n",
      "Batch: 3749. Acc: 0.284450. Loss: 2.067390. Batch_acc: 0.314099. Batch_loss: 1.976339 \n",
      "Batch: 3750. Acc: 0.284460. Loss: 2.067360. Batch_acc: 0.321223. Batch_loss: 1.952026 \n",
      "Batch: 3751. Acc: 0.284468. Loss: 2.067336. Batch_acc: 0.316609. Batch_loss: 1.979372 \n",
      "Batch: 3752. Acc: 0.284479. Loss: 2.067307. Batch_acc: 0.323821. Batch_loss: 1.955418 \n",
      "Batch: 3753. Acc: 0.284489. Loss: 2.067273. Batch_acc: 0.323944. Batch_loss: 1.944150 \n",
      "Batch: 3754. Acc: 0.284498. Loss: 2.067244. Batch_acc: 0.318156. Batch_loss: 1.961893 \n",
      "Batch: 3755. Acc: 0.284501. Loss: 2.067233. Batch_acc: 0.296122. Batch_loss: 2.021497 \n",
      "Batch: 3756. Acc: 0.284513. Loss: 2.067213. Batch_acc: 0.329247. Batch_loss: 1.990871 \n",
      "Batch: 3757. Acc: 0.284520. Loss: 2.067190. Batch_acc: 0.309982. Batch_loss: 1.980110 \n",
      "Batch: 3758. Acc: 0.284526. Loss: 2.067173. Batch_acc: 0.307243. Batch_loss: 2.003867 \n",
      "Batch: 3759. Acc: 0.284539. Loss: 2.067145. Batch_acc: 0.334481. Batch_loss: 1.961718 \n",
      "Batch: 3760. Acc: 0.284551. Loss: 2.067117. Batch_acc: 0.328751. Batch_loss: 1.961899 \n",
      "Batch: 3761. Acc: 0.284561. Loss: 2.067087. Batch_acc: 0.322745. Batch_loss: 1.955141 \n",
      "Batch: 3762. Acc: 0.284569. Loss: 2.067063. Batch_acc: 0.314952. Batch_loss: 1.980452 \n",
      "Batch: 3763. Acc: 0.284578. Loss: 2.067040. Batch_acc: 0.315759. Batch_loss: 1.976943 \n",
      "Batch: 3764. Acc: 0.284587. Loss: 2.067014. Batch_acc: 0.317768. Batch_loss: 1.971799 \n",
      "Batch: 3765. Acc: 0.284593. Loss: 2.066992. Batch_acc: 0.308772. Batch_loss: 1.981070 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.2845929187682841. Loss per char: 2.066991580507431. Time: 1627205555.3925345\n",
      "Last question is tensor([ 2, 14, 18, 19, 23,  1, 14,  1, 19, 18, 23, 22, 15, 18, 25, 18, 26, 17,\n",
      "        20, 20,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.284604. Loss: 2.066963. Batch_acc: 0.325488. Batch_loss: 1.959497 \n",
      "Batch: 3767. Acc: 0.284613. Loss: 2.066932. Batch_acc: 0.319629. Batch_loss: 1.947605 \n",
      "Batch: 3768. Acc: 0.284630. Loss: 2.066896. Batch_acc: 0.348354. Batch_loss: 1.931340 \n",
      "Batch: 3769. Acc: 0.284640. Loss: 2.066861. Batch_acc: 0.322305. Batch_loss: 1.935729 \n",
      "Batch: 3770. Acc: 0.284649. Loss: 2.066828. Batch_acc: 0.316639. Batch_loss: 1.948512 \n",
      "Batch: 3771. Acc: 0.284657. Loss: 2.066798. Batch_acc: 0.314730. Batch_loss: 1.953385 \n",
      "Batch: 3772. Acc: 0.284662. Loss: 2.066774. Batch_acc: 0.305461. Batch_loss: 1.976397 \n",
      "Batch: 3773. Acc: 0.284668. Loss: 2.066747. Batch_acc: 0.308467. Batch_loss: 1.961879 \n",
      "Batch: 3774. Acc: 0.284679. Loss: 2.066722. Batch_acc: 0.322617. Batch_loss: 1.975627 \n",
      "Batch: 3775. Acc: 0.284684. Loss: 2.066697. Batch_acc: 0.303183. Batch_loss: 1.974956 \n",
      "Batch: 3776. Acc: 0.284695. Loss: 2.066668. Batch_acc: 0.329268. Batch_loss: 1.956312 \n",
      "Batch: 3777. Acc: 0.284707. Loss: 2.066642. Batch_acc: 0.328324. Batch_loss: 1.966873 \n",
      "Batch: 3778. Acc: 0.284714. Loss: 2.066613. Batch_acc: 0.311816. Batch_loss: 1.955933 \n",
      "Batch: 3779. Acc: 0.284721. Loss: 2.066597. Batch_acc: 0.310425. Batch_loss: 2.004782 \n",
      "Batch: 3780. Acc: 0.284730. Loss: 2.066576. Batch_acc: 0.321886. Batch_loss: 1.989222 \n",
      "Batch: 3781. Acc: 0.284746. Loss: 2.066544. Batch_acc: 0.342225. Batch_loss: 1.945937 \n",
      "Batch: 3782. Acc: 0.284753. Loss: 2.066518. Batch_acc: 0.311060. Batch_loss: 1.966331 \n",
      "Batch: 3783. Acc: 0.284757. Loss: 2.066503. Batch_acc: 0.300691. Batch_loss: 2.012047 \n",
      "Batch: 3784. Acc: 0.284766. Loss: 2.066471. Batch_acc: 0.317308. Batch_loss: 1.946325 \n",
      "Batch: 3785. Acc: 0.284774. Loss: 2.066448. Batch_acc: 0.317414. Batch_loss: 1.980074 \n",
      "Batch: 3786. Acc: 0.284784. Loss: 2.066426. Batch_acc: 0.321926. Batch_loss: 1.980762 \n",
      "Batch: 3787. Acc: 0.284794. Loss: 2.066397. Batch_acc: 0.321994. Batch_loss: 1.954274 \n",
      "Batch: 3788. Acc: 0.284804. Loss: 2.066373. Batch_acc: 0.324826. Batch_loss: 1.973426 \n",
      "Batch: 3789. Acc: 0.284808. Loss: 2.066356. Batch_acc: 0.298567. Batch_loss: 2.003205 \n",
      "Batch: 3790. Acc: 0.284818. Loss: 2.066329. Batch_acc: 0.321388. Batch_loss: 1.967667 \n",
      "Batch: 3791. Acc: 0.284825. Loss: 2.066308. Batch_acc: 0.313805. Batch_loss: 1.984457 \n",
      "Batch: 3792. Acc: 0.284829. Loss: 2.066286. Batch_acc: 0.299425. Batch_loss: 1.983037 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3793. Acc: 0.284838. Loss: 2.066253. Batch_acc: 0.316760. Batch_loss: 1.945336 \n",
      "Batch: 3794. Acc: 0.284844. Loss: 2.066228. Batch_acc: 0.307913. Batch_loss: 1.972162 \n",
      "Batch: 3795. Acc: 0.284850. Loss: 2.066214. Batch_acc: 0.307559. Batch_loss: 2.013001 \n",
      "Batch: 3796. Acc: 0.284862. Loss: 2.066181. Batch_acc: 0.329689. Batch_loss: 1.940946 \n",
      "Batch: 3797. Acc: 0.284873. Loss: 2.066142. Batch_acc: 0.328955. Batch_loss: 1.919361 \n",
      "Batch: 3798. Acc: 0.284878. Loss: 2.066119. Batch_acc: 0.302768. Batch_loss: 1.977763 \n",
      "Batch: 3799. Acc: 0.284886. Loss: 2.066087. Batch_acc: 0.317341. Batch_loss: 1.941593 \n",
      "Batch: 3800. Acc: 0.284892. Loss: 2.066067. Batch_acc: 0.307514. Batch_loss: 1.991912 \n",
      "Batch: 3801. Acc: 0.284895. Loss: 2.066044. Batch_acc: 0.296767. Batch_loss: 1.978536 \n",
      "Batch: 3802. Acc: 0.284905. Loss: 2.066010. Batch_acc: 0.323139. Batch_loss: 1.936918 \n",
      "Batch: 3803. Acc: 0.284914. Loss: 2.065990. Batch_acc: 0.318339. Batch_loss: 1.987192 \n",
      "Batch: 3804. Acc: 0.284921. Loss: 2.065969. Batch_acc: 0.310556. Batch_loss: 1.990276 \n",
      "Batch: 3805. Acc: 0.284930. Loss: 2.065949. Batch_acc: 0.316962. Batch_loss: 1.991159 \n",
      "Batch: 3806. Acc: 0.284936. Loss: 2.065926. Batch_acc: 0.309776. Batch_loss: 1.974677 \n",
      "Batch: 3807. Acc: 0.284942. Loss: 2.065905. Batch_acc: 0.307471. Batch_loss: 1.985306 \n",
      "Batch: 3808. Acc: 0.284949. Loss: 2.065877. Batch_acc: 0.309891. Batch_loss: 1.960794 \n",
      "Batch: 3809. Acc: 0.284955. Loss: 2.065855. Batch_acc: 0.310046. Batch_loss: 1.982703 \n",
      "Batch: 3810. Acc: 0.284968. Loss: 2.065814. Batch_acc: 0.332211. Batch_loss: 1.912933 \n",
      "Batch: 3811. Acc: 0.284973. Loss: 2.065789. Batch_acc: 0.305995. Batch_loss: 1.971907 \n",
      "Batch: 3812. Acc: 0.284985. Loss: 2.065762. Batch_acc: 0.328098. Batch_loss: 1.962084 \n",
      "Batch: 3813. Acc: 0.284993. Loss: 2.065735. Batch_acc: 0.317579. Batch_loss: 1.963576 \n",
      "Batch: 3814. Acc: 0.285002. Loss: 2.065712. Batch_acc: 0.318001. Batch_loss: 1.976615 \n",
      "Batch: 3815. Acc: 0.285015. Loss: 2.065674. Batch_acc: 0.336395. Batch_loss: 1.922612 \n",
      "Batch: 3816. Acc: 0.285029. Loss: 2.065640. Batch_acc: 0.336222. Batch_loss: 1.936399 \n",
      "Batch: 3817. Acc: 0.285037. Loss: 2.065608. Batch_acc: 0.314462. Batch_loss: 1.945981 \n",
      "Batch: 3818. Acc: 0.285048. Loss: 2.065578. Batch_acc: 0.328940. Batch_loss: 1.951709 \n",
      "Batch: 3819. Acc: 0.285054. Loss: 2.065554. Batch_acc: 0.307253. Batch_loss: 1.973024 \n",
      "Batch: 3820. Acc: 0.285064. Loss: 2.065526. Batch_acc: 0.323860. Batch_loss: 1.955660 \n",
      "Batch: 3821. Acc: 0.285070. Loss: 2.065500. Batch_acc: 0.309195. Batch_loss: 1.965137 \n",
      "Batch: 3822. Acc: 0.285077. Loss: 2.065469. Batch_acc: 0.311755. Batch_loss: 1.949780 \n",
      "Batch: 3823. Acc: 0.285082. Loss: 2.065447. Batch_acc: 0.304273. Batch_loss: 1.982259 \n",
      "Batch: 3824. Acc: 0.285093. Loss: 2.065417. Batch_acc: 0.326531. Batch_loss: 1.950434 \n",
      "Batch: 3825. Acc: 0.285106. Loss: 2.065389. Batch_acc: 0.330891. Batch_loss: 1.959854 \n",
      "Batch: 3826. Acc: 0.285113. Loss: 2.065365. Batch_acc: 0.314007. Batch_loss: 1.975526 \n",
      "Batch: 3827. Acc: 0.285122. Loss: 2.065339. Batch_acc: 0.320744. Batch_loss: 1.963688 \n",
      "Batch: 3828. Acc: 0.285130. Loss: 2.065309. Batch_acc: 0.315514. Batch_loss: 1.951481 \n",
      "Batch: 3829. Acc: 0.285138. Loss: 2.065285. Batch_acc: 0.315402. Batch_loss: 1.974219 \n",
      "Batch: 3830. Acc: 0.285147. Loss: 2.065255. Batch_acc: 0.315996. Batch_loss: 1.953363 \n",
      "Batch: 3831. Acc: 0.285160. Loss: 2.065215. Batch_acc: 0.335779. Batch_loss: 1.914849 \n",
      "Batch: 3832. Acc: 0.285169. Loss: 2.065183. Batch_acc: 0.319863. Batch_loss: 1.941807 \n",
      "Batch: 3833. Acc: 0.285171. Loss: 2.065161. Batch_acc: 0.291469. Batch_loss: 1.981297 \n",
      "Batch: 3834. Acc: 0.285180. Loss: 2.065131. Batch_acc: 0.318931. Batch_loss: 1.949094 \n",
      "Batch: 3835. Acc: 0.285191. Loss: 2.065096. Batch_acc: 0.327746. Batch_loss: 1.932596 \n",
      "Batch: 3836. Acc: 0.285197. Loss: 2.065075. Batch_acc: 0.310444. Batch_loss: 1.981361 \n",
      "Batch: 3837. Acc: 0.285211. Loss: 2.065044. Batch_acc: 0.335991. Batch_loss: 1.948532 \n",
      "Batch: 3838. Acc: 0.285216. Loss: 2.065019. Batch_acc: 0.304899. Batch_loss: 1.969878 \n",
      "Batch: 3839. Acc: 0.285225. Loss: 2.064991. Batch_acc: 0.318233. Batch_loss: 1.957885 \n",
      "Batch: 3840. Acc: 0.285234. Loss: 2.064961. Batch_acc: 0.322353. Batch_loss: 1.947814 \n",
      "Batch: 3841. Acc: 0.285241. Loss: 2.064930. Batch_acc: 0.312717. Batch_loss: 1.944465 \n",
      "Batch: 3842. Acc: 0.285251. Loss: 2.064898. Batch_acc: 0.323103. Batch_loss: 1.945172 \n",
      "Batch: 3843. Acc: 0.285259. Loss: 2.064868. Batch_acc: 0.316147. Batch_loss: 1.952250 \n",
      "Batch: 3844. Acc: 0.285272. Loss: 2.064836. Batch_acc: 0.334297. Batch_loss: 1.941774 \n",
      "Batch: 3845. Acc: 0.285281. Loss: 2.064810. Batch_acc: 0.318619. Batch_loss: 1.966000 \n",
      "Batch: 3846. Acc: 0.285286. Loss: 2.064787. Batch_acc: 0.304773. Batch_loss: 1.975978 \n",
      "Batch: 3847. Acc: 0.285293. Loss: 2.064763. Batch_acc: 0.310130. Batch_loss: 1.975441 \n",
      "Batch: 3848. Acc: 0.285302. Loss: 2.064737. Batch_acc: 0.321264. Batch_loss: 1.963185 \n",
      "Batch: 3849. Acc: 0.285313. Loss: 2.064705. Batch_acc: 0.329352. Batch_loss: 1.944898 \n",
      "Batch: 3850. Acc: 0.285320. Loss: 2.064684. Batch_acc: 0.308883. Batch_loss: 1.980829 \n",
      "Batch: 3851. Acc: 0.285334. Loss: 2.064647. Batch_acc: 0.338565. Batch_loss: 1.928735 \n",
      "Batch: 3852. Acc: 0.285339. Loss: 2.064625. Batch_acc: 0.303826. Batch_loss: 1.979547 \n",
      "Batch: 3853. Acc: 0.285351. Loss: 2.064594. Batch_acc: 0.331808. Batch_loss: 1.944092 \n",
      "Batch: 3854. Acc: 0.285361. Loss: 2.064566. Batch_acc: 0.324278. Batch_loss: 1.958524 \n",
      "Batch: 3855. Acc: 0.285374. Loss: 2.064531. Batch_acc: 0.333146. Batch_loss: 1.932098 \n",
      "Batch: 3856. Acc: 0.285381. Loss: 2.064503. Batch_acc: 0.314718. Batch_loss: 1.958902 \n",
      "Batch: 3857. Acc: 0.285391. Loss: 2.064472. Batch_acc: 0.321694. Batch_loss: 1.942201 \n",
      "Batch: 3858. Acc: 0.285394. Loss: 2.064460. Batch_acc: 0.300236. Batch_loss: 2.019533 \n",
      "Batch: 3859. Acc: 0.285403. Loss: 2.064434. Batch_acc: 0.316695. Batch_loss: 1.962859 \n",
      "Batch: 3860. Acc: 0.285413. Loss: 2.064404. Batch_acc: 0.325260. Batch_loss: 1.949238 \n",
      "Batch: 3861. Acc: 0.285420. Loss: 2.064374. Batch_acc: 0.313535. Batch_loss: 1.950523 \n",
      "Batch: 3862. Acc: 0.285427. Loss: 2.064355. Batch_acc: 0.313260. Batch_loss: 1.989223 \n",
      "Batch: 3863. Acc: 0.285437. Loss: 2.064332. Batch_acc: 0.322562. Batch_loss: 1.971371 \n",
      "Batch: 3864. Acc: 0.285447. Loss: 2.064297. Batch_acc: 0.322911. Batch_loss: 1.930555 \n",
      "Batch: 3865. Acc: 0.285454. Loss: 2.064267. Batch_acc: 0.312148. Batch_loss: 1.952632 \n",
      "Batch: 3866. Acc: 0.285462. Loss: 2.064237. Batch_acc: 0.315993. Batch_loss: 1.953469 \n",
      "Batch: 3867. Acc: 0.285473. Loss: 2.064199. Batch_acc: 0.330114. Batch_loss: 1.919467 \n",
      "Batch: 3868. Acc: 0.285488. Loss: 2.064167. Batch_acc: 0.341477. Batch_loss: 1.940077 \n",
      "Batch: 3869. Acc: 0.285497. Loss: 2.064140. Batch_acc: 0.318574. Batch_loss: 1.961658 \n",
      "Batch: 3870. Acc: 0.285505. Loss: 2.064117. Batch_acc: 0.318048. Batch_loss: 1.970313 \n",
      "Batch: 3871. Acc: 0.285517. Loss: 2.064087. Batch_acc: 0.334108. Batch_loss: 1.949441 \n",
      "Batch: 3872. Acc: 0.285527. Loss: 2.064051. Batch_acc: 0.321965. Batch_loss: 1.922894 \n",
      "Batch: 3873. Acc: 0.285535. Loss: 2.064017. Batch_acc: 0.317799. Batch_loss: 1.936513 \n",
      "Batch: 3874. Acc: 0.285547. Loss: 2.063984. Batch_acc: 0.330636. Batch_loss: 1.935245 \n",
      "Batch: 3875. Acc: 0.285552. Loss: 2.063961. Batch_acc: 0.303768. Batch_loss: 1.973727 \n",
      "Batch: 3876. Acc: 0.285560. Loss: 2.063934. Batch_acc: 0.319606. Batch_loss: 1.959450 \n",
      "Batch: 3877. Acc: 0.285573. Loss: 2.063898. Batch_acc: 0.332955. Batch_loss: 1.923009 \n",
      "Batch: 3878. Acc: 0.285581. Loss: 2.063869. Batch_acc: 0.318841. Batch_loss: 1.958471 \n",
      "Batch: 3879. Acc: 0.285589. Loss: 2.063840. Batch_acc: 0.316085. Batch_loss: 1.950311 \n",
      "Batch: 3880. Acc: 0.285599. Loss: 2.063811. Batch_acc: 0.320808. Batch_loss: 1.954618 \n",
      "Batch: 3881. Acc: 0.285607. Loss: 2.063784. Batch_acc: 0.316368. Batch_loss: 1.959914 \n",
      "Batch: 3882. Acc: 0.285614. Loss: 2.063757. Batch_acc: 0.316224. Batch_loss: 1.957142 \n",
      "Batch: 3883. Acc: 0.285625. Loss: 2.063724. Batch_acc: 0.325129. Batch_loss: 1.935121 \n",
      "Batch: 3884. Acc: 0.285635. Loss: 2.063698. Batch_acc: 0.325329. Batch_loss: 1.962439 \n",
      "Batch: 3885. Acc: 0.285646. Loss: 2.063662. Batch_acc: 0.328720. Batch_loss: 1.923887 \n",
      "Batch: 3886. Acc: 0.285660. Loss: 2.063621. Batch_acc: 0.336854. Batch_loss: 1.910308 \n",
      "Batch: 3887. Acc: 0.285665. Loss: 2.063604. Batch_acc: 0.305868. Batch_loss: 1.994832 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3888. Acc: 0.285677. Loss: 2.063565. Batch_acc: 0.335632. Batch_loss: 1.913738 \n",
      "Batch: 3889. Acc: 0.285685. Loss: 2.063533. Batch_acc: 0.314254. Batch_loss: 1.941146 \n",
      "Batch: 3890. Acc: 0.285692. Loss: 2.063507. Batch_acc: 0.312019. Batch_loss: 1.959940 \n",
      "Batch: 3891. Acc: 0.285701. Loss: 2.063476. Batch_acc: 0.323273. Batch_loss: 1.942201 \n",
      "Batch: 3892. Acc: 0.285711. Loss: 2.063443. Batch_acc: 0.323582. Batch_loss: 1.929376 \n",
      "Batch: 3893. Acc: 0.285722. Loss: 2.063412. Batch_acc: 0.331419. Batch_loss: 1.941131 \n",
      "Batch: 3894. Acc: 0.285734. Loss: 2.063372. Batch_acc: 0.330097. Batch_loss: 1.910379 \n",
      "Batch: 3895. Acc: 0.285742. Loss: 2.063345. Batch_acc: 0.318182. Batch_loss: 1.957417 \n",
      "Batch: 3896. Acc: 0.285750. Loss: 2.063316. Batch_acc: 0.315728. Batch_loss: 1.950038 \n",
      "Batch: 3897. Acc: 0.285756. Loss: 2.063295. Batch_acc: 0.311124. Batch_loss: 1.980686 \n",
      "Batch: 3898. Acc: 0.285765. Loss: 2.063267. Batch_acc: 0.319516. Batch_loss: 1.954851 \n",
      "Batch: 3899. Acc: 0.285778. Loss: 2.063239. Batch_acc: 0.335224. Batch_loss: 1.956335 \n",
      "Batch: 3900. Acc: 0.285785. Loss: 2.063213. Batch_acc: 0.316471. Batch_loss: 1.959344 \n",
      "Batch: 3901. Acc: 0.285791. Loss: 2.063185. Batch_acc: 0.308215. Batch_loss: 1.955452 \n",
      "Batch: 3902. Acc: 0.285798. Loss: 2.063164. Batch_acc: 0.310109. Batch_loss: 1.980009 \n",
      "Batch: 3903. Acc: 0.285805. Loss: 2.063145. Batch_acc: 0.313529. Batch_loss: 1.990948 \n",
      "Batch: 3904. Acc: 0.285813. Loss: 2.063119. Batch_acc: 0.318866. Batch_loss: 1.960984 \n",
      "Batch: 3905. Acc: 0.285820. Loss: 2.063100. Batch_acc: 0.313416. Batch_loss: 1.987149 \n",
      "Batch: 3906. Acc: 0.285827. Loss: 2.063077. Batch_acc: 0.312428. Batch_loss: 1.975865 \n",
      "Batch: 3907. Acc: 0.285831. Loss: 2.063068. Batch_acc: 0.303760. Batch_loss: 2.027011 \n",
      "Batch: 3908. Acc: 0.285838. Loss: 2.063042. Batch_acc: 0.313054. Batch_loss: 1.957148 \n",
      "Batch: 3909. Acc: 0.285848. Loss: 2.063010. Batch_acc: 0.325217. Batch_loss: 1.937996 \n",
      "Batch: 3910. Acc: 0.285855. Loss: 2.062988. Batch_acc: 0.314170. Batch_loss: 1.975931 \n",
      "Batch: 3911. Acc: 0.285866. Loss: 2.062960. Batch_acc: 0.326801. Batch_loss: 1.952266 \n",
      "Batch: 3912. Acc: 0.285875. Loss: 2.062934. Batch_acc: 0.321555. Batch_loss: 1.960445 \n",
      "Batch: 3913. Acc: 0.285880. Loss: 2.062918. Batch_acc: 0.305115. Batch_loss: 1.998517 \n",
      "Batch: 3914. Acc: 0.285883. Loss: 2.062898. Batch_acc: 0.300292. Batch_loss: 1.982630 \n",
      "Batch: 3915. Acc: 0.285889. Loss: 2.062877. Batch_acc: 0.310606. Batch_loss: 1.978273 \n",
      "Batch: 3916. Acc: 0.285899. Loss: 2.062850. Batch_acc: 0.323444. Batch_loss: 1.958448 \n",
      "Batch: 3917. Acc: 0.285905. Loss: 2.062829. Batch_acc: 0.311149. Batch_loss: 1.982524 \n",
      "Batch: 3918. Acc: 0.285911. Loss: 2.062808. Batch_acc: 0.308874. Batch_loss: 1.978845 \n",
      "Batch: 3919. Acc: 0.285922. Loss: 2.062775. Batch_acc: 0.326519. Batch_loss: 1.936612 \n",
      "Batch: 3920. Acc: 0.285932. Loss: 2.062751. Batch_acc: 0.324069. Batch_loss: 1.972212 \n",
      "Batch: 3921. Acc: 0.285942. Loss: 2.062725. Batch_acc: 0.323749. Batch_loss: 1.961644 \n",
      "Batch: 3922. Acc: 0.285948. Loss: 2.062699. Batch_acc: 0.311586. Batch_loss: 1.960898 \n",
      "Batch: 3923. Acc: 0.285957. Loss: 2.062675. Batch_acc: 0.319551. Batch_loss: 1.967429 \n",
      "Batch: 3924. Acc: 0.285963. Loss: 2.062649. Batch_acc: 0.312536. Batch_loss: 1.956864 \n",
      "Batch: 3925. Acc: 0.285972. Loss: 2.062618. Batch_acc: 0.319653. Batch_loss: 1.939810 \n",
      "Batch: 3926. Acc: 0.285983. Loss: 2.062586. Batch_acc: 0.328844. Batch_loss: 1.942588 \n",
      "Batch: 3927. Acc: 0.285993. Loss: 2.062556. Batch_acc: 0.326979. Batch_loss: 1.944263 \n",
      "Batch: 3928. Acc: 0.286006. Loss: 2.062531. Batch_acc: 0.334706. Batch_loss: 1.960086 \n",
      "Batch: 3929. Acc: 0.286011. Loss: 2.062516. Batch_acc: 0.308858. Batch_loss: 2.001993 \n",
      "Batch: 3930. Acc: 0.286022. Loss: 2.062494. Batch_acc: 0.327011. Batch_loss: 1.977462 \n",
      "Batch: 3931. Acc: 0.286032. Loss: 2.062462. Batch_acc: 0.327888. Batch_loss: 1.934631 \n",
      "Batch: 3932. Acc: 0.286039. Loss: 2.062441. Batch_acc: 0.311224. Batch_loss: 1.981640 \n",
      "Batch: 3933. Acc: 0.286047. Loss: 2.062414. Batch_acc: 0.319381. Batch_loss: 1.955592 \n",
      "Batch: 3934. Acc: 0.286057. Loss: 2.062387. Batch_acc: 0.323330. Batch_loss: 1.959538 \n",
      "Batch: 3935. Acc: 0.286061. Loss: 2.062366. Batch_acc: 0.303551. Batch_loss: 1.979838 \n",
      "Batch: 3936. Acc: 0.286073. Loss: 2.062333. Batch_acc: 0.331818. Batch_loss: 1.935407 \n",
      "Batch: 3937. Acc: 0.286084. Loss: 2.062307. Batch_acc: 0.327991. Batch_loss: 1.959278 \n",
      "Batch: 3938. Acc: 0.286093. Loss: 2.062275. Batch_acc: 0.320840. Batch_loss: 1.937401 \n",
      "Batch: 3939. Acc: 0.286101. Loss: 2.062252. Batch_acc: 0.320400. Batch_loss: 1.970549 \n",
      "Batch: 3940. Acc: 0.286116. Loss: 2.062217. Batch_acc: 0.344649. Batch_loss: 1.924297 \n",
      "Batch: 3941. Acc: 0.286123. Loss: 2.062189. Batch_acc: 0.314302. Batch_loss: 1.949928 \n",
      "Batch: 3942. Acc: 0.286129. Loss: 2.062165. Batch_acc: 0.310151. Batch_loss: 1.969654 \n",
      "Batch: 3943. Acc: 0.286137. Loss: 2.062135. Batch_acc: 0.315514. Batch_loss: 1.945458 \n",
      "Batch: 3944. Acc: 0.286146. Loss: 2.062103. Batch_acc: 0.322380. Batch_loss: 1.937380 \n",
      "Batch: 3945. Acc: 0.286151. Loss: 2.062078. Batch_acc: 0.305776. Batch_loss: 1.962130 \n",
      "Batch: 3946. Acc: 0.286161. Loss: 2.062042. Batch_acc: 0.325515. Batch_loss: 1.921252 \n",
      "Batch: 3947. Acc: 0.286170. Loss: 2.062013. Batch_acc: 0.322159. Batch_loss: 1.950370 \n",
      "Batch: 3948. Acc: 0.286181. Loss: 2.061991. Batch_acc: 0.327765. Batch_loss: 1.975336 \n",
      "Batch: 3949. Acc: 0.286191. Loss: 2.061955. Batch_acc: 0.323864. Batch_loss: 1.921761 \n",
      "Batch: 3950. Acc: 0.286200. Loss: 2.061927. Batch_acc: 0.322785. Batch_loss: 1.950894 \n",
      "Batch: 3951. Acc: 0.286209. Loss: 2.061899. Batch_acc: 0.323968. Batch_loss: 1.952901 \n",
      "Batch: 3952. Acc: 0.286215. Loss: 2.061874. Batch_acc: 0.308748. Batch_loss: 1.961527 \n",
      "Batch: 3953. Acc: 0.286222. Loss: 2.061849. Batch_acc: 0.312215. Batch_loss: 1.964394 \n",
      "Batch: 3954. Acc: 0.286228. Loss: 2.061829. Batch_acc: 0.309123. Batch_loss: 1.981290 \n",
      "Batch: 3955. Acc: 0.286233. Loss: 2.061804. Batch_acc: 0.308598. Batch_loss: 1.960302 \n",
      "Batch: 3956. Acc: 0.286242. Loss: 2.061776. Batch_acc: 0.320566. Batch_loss: 1.947380 \n",
      "Batch: 3957. Acc: 0.286246. Loss: 2.061757. Batch_acc: 0.303066. Batch_loss: 1.984839 \n",
      "Batch: 3958. Acc: 0.286252. Loss: 2.061739. Batch_acc: 0.311986. Batch_loss: 1.991229 \n",
      "Batch: 3959. Acc: 0.286261. Loss: 2.061711. Batch_acc: 0.320680. Batch_loss: 1.951865 \n",
      "Batch: 3960. Acc: 0.286270. Loss: 2.061684. Batch_acc: 0.322091. Batch_loss: 1.955426 \n",
      "Batch: 3961. Acc: 0.286277. Loss: 2.061657. Batch_acc: 0.314103. Batch_loss: 1.954398 \n",
      "Batch: 3962. Acc: 0.286286. Loss: 2.061627. Batch_acc: 0.321852. Batch_loss: 1.944876 \n",
      "Batch: 3963. Acc: 0.286299. Loss: 2.061586. Batch_acc: 0.334276. Batch_loss: 1.903967 \n",
      "Batch: 3964. Acc: 0.286309. Loss: 2.061563. Batch_acc: 0.327982. Batch_loss: 1.968773 \n",
      "Batch: 3965. Acc: 0.286312. Loss: 2.061553. Batch_acc: 0.298100. Batch_loss: 2.019332 \n",
      "Batch: 3966. Acc: 0.286322. Loss: 2.061528. Batch_acc: 0.325437. Batch_loss: 1.965099 \n",
      "Batch: 3967. Acc: 0.286331. Loss: 2.061493. Batch_acc: 0.321948. Batch_loss: 1.927075 \n",
      "Batch: 3968. Acc: 0.286339. Loss: 2.061468. Batch_acc: 0.317922. Batch_loss: 1.963844 \n",
      "Batch: 3969. Acc: 0.286350. Loss: 2.061429. Batch_acc: 0.328151. Batch_loss: 1.911435 \n",
      "Batch: 3970. Acc: 0.286357. Loss: 2.061402. Batch_acc: 0.312826. Batch_loss: 1.952370 \n",
      "Batch: 3971. Acc: 0.286367. Loss: 2.061372. Batch_acc: 0.326738. Batch_loss: 1.945246 \n",
      "Batch: 3972. Acc: 0.286374. Loss: 2.061350. Batch_acc: 0.312353. Batch_loss: 1.972100 \n",
      "Batch: 3973. Acc: 0.286380. Loss: 2.061327. Batch_acc: 0.312823. Batch_loss: 1.968772 \n",
      "Batch: 3974. Acc: 0.286386. Loss: 2.061298. Batch_acc: 0.307780. Batch_loss: 1.948968 \n",
      "Batch: 3975. Acc: 0.286393. Loss: 2.061275. Batch_acc: 0.316268. Batch_loss: 1.967763 \n",
      "Batch: 3976. Acc: 0.286398. Loss: 2.061254. Batch_acc: 0.305008. Batch_loss: 1.980021 \n",
      "Batch: 3977. Acc: 0.286401. Loss: 2.061236. Batch_acc: 0.300412. Batch_loss: 1.990396 \n",
      "Batch: 3978. Acc: 0.286408. Loss: 2.061216. Batch_acc: 0.313974. Batch_loss: 1.980138 \n",
      "Batch: 3979. Acc: 0.286423. Loss: 2.061175. Batch_acc: 0.345714. Batch_loss: 1.898652 \n",
      "Batch: 3980. Acc: 0.286430. Loss: 2.061150. Batch_acc: 0.312427. Batch_loss: 1.960237 \n",
      "Batch: 3981. Acc: 0.286439. Loss: 2.061127. Batch_acc: 0.324248. Batch_loss: 1.969949 \n",
      "Batch: 3982. Acc: 0.286447. Loss: 2.061099. Batch_acc: 0.317997. Batch_loss: 1.950267 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3983. Acc: 0.286459. Loss: 2.061070. Batch_acc: 0.332565. Batch_loss: 1.945360 \n",
      "Batch: 3984. Acc: 0.286467. Loss: 2.061039. Batch_acc: 0.318053. Batch_loss: 1.939780 \n",
      "Batch: 3985. Acc: 0.286478. Loss: 2.061009. Batch_acc: 0.329114. Batch_loss: 1.940700 \n",
      "Batch: 3986. Acc: 0.286490. Loss: 2.060977. Batch_acc: 0.337342. Batch_loss: 1.932941 \n",
      "Batch: 3987. Acc: 0.286500. Loss: 2.060950. Batch_acc: 0.325015. Batch_loss: 1.953658 \n",
      "Batch: 3988. Acc: 0.286502. Loss: 2.060929. Batch_acc: 0.295977. Batch_loss: 1.974699 \n",
      "Batch: 3989. Acc: 0.286507. Loss: 2.060916. Batch_acc: 0.303986. Batch_loss: 2.007687 \n",
      "Batch: 3990. Acc: 0.286518. Loss: 2.060883. Batch_acc: 0.333525. Batch_loss: 1.929169 \n",
      "Batch: 3991. Acc: 0.286525. Loss: 2.060864. Batch_acc: 0.313380. Batch_loss: 1.986744 \n",
      "Batch: 3992. Acc: 0.286531. Loss: 2.060836. Batch_acc: 0.310999. Batch_loss: 1.950363 \n",
      "Batch: 3993. Acc: 0.286539. Loss: 2.060804. Batch_acc: 0.318106. Batch_loss: 1.935694 \n",
      "Batch: 3994. Acc: 0.286551. Loss: 2.060769. Batch_acc: 0.331803. Batch_loss: 1.921189 \n",
      "Batch: 3995. Acc: 0.286557. Loss: 2.060750. Batch_acc: 0.311734. Batch_loss: 1.984404 \n",
      "Batch: 3996. Acc: 0.286564. Loss: 2.060726. Batch_acc: 0.314658. Batch_loss: 1.966423 \n",
      "Batch: 3997. Acc: 0.286576. Loss: 2.060697. Batch_acc: 0.334086. Batch_loss: 1.947539 \n",
      "Batch: 3998. Acc: 0.286584. Loss: 2.060665. Batch_acc: 0.317926. Batch_loss: 1.936771 \n",
      "Batch: 3999. Acc: 0.286591. Loss: 2.060637. Batch_acc: 0.310915. Batch_loss: 1.951620 \n",
      "Batch: 4000. Acc: 0.286597. Loss: 2.060622. Batch_acc: 0.311266. Batch_loss: 1.999319 \n",
      "Batch: 4001. Acc: 0.286604. Loss: 2.060599. Batch_acc: 0.314762. Batch_loss: 1.972120 \n",
      "Batch: 4002. Acc: 0.286612. Loss: 2.060576. Batch_acc: 0.321599. Batch_loss: 1.964139 \n",
      "Batch: 4003. Acc: 0.286623. Loss: 2.060555. Batch_acc: 0.328367. Batch_loss: 1.975865 \n",
      "Batch: 4004. Acc: 0.286630. Loss: 2.060532. Batch_acc: 0.316309. Batch_loss: 1.965961 \n",
      "Batch: 4005. Acc: 0.286641. Loss: 2.060501. Batch_acc: 0.331641. Batch_loss: 1.939927 \n",
      "Batch: 4006. Acc: 0.286643. Loss: 2.060486. Batch_acc: 0.291595. Batch_loss: 2.000383 \n",
      "Batch: 4007. Acc: 0.286647. Loss: 2.060473. Batch_acc: 0.303623. Batch_loss: 2.009429 \n",
      "Batch: 4008. Acc: 0.286651. Loss: 2.060457. Batch_acc: 0.301015. Batch_loss: 1.998978 \n",
      "Batch: 4009. Acc: 0.286658. Loss: 2.060428. Batch_acc: 0.317003. Batch_loss: 1.941801 \n",
      "Batch: 4010. Acc: 0.286667. Loss: 2.060406. Batch_acc: 0.319955. Batch_loss: 1.975458 \n",
      "Batch: 4011. Acc: 0.286675. Loss: 2.060383. Batch_acc: 0.318510. Batch_loss: 1.969762 \n",
      "Batch: 4012. Acc: 0.286683. Loss: 2.060358. Batch_acc: 0.320046. Batch_loss: 1.959685 \n",
      "Batch: 4013. Acc: 0.286690. Loss: 2.060336. Batch_acc: 0.315285. Batch_loss: 1.976400 \n",
      "Batch: 4014. Acc: 0.286701. Loss: 2.060310. Batch_acc: 0.329702. Batch_loss: 1.954082 \n",
      "Batch: 4015. Acc: 0.286713. Loss: 2.060283. Batch_acc: 0.333706. Batch_loss: 1.956031 \n",
      "Batch: 4016. Acc: 0.286717. Loss: 2.060266. Batch_acc: 0.301075. Batch_loss: 1.990068 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.2867166962329767. Loss per char: 2.060266185384802. Time: 1627205765.4203646\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 19, 19,  1, 12,  1, 14, 19,\n",
      "        18, 19, 21, 26, 21, 15, 24, 21, 26, 26, 17, 18, 22, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.286728. Loss: 2.060236. Batch_acc: 0.332947. Batch_loss: 1.939444 \n",
      "Batch: 4018. Acc: 0.286739. Loss: 2.060207. Batch_acc: 0.328798. Batch_loss: 1.943236 \n",
      "Batch: 4019. Acc: 0.286747. Loss: 2.060177. Batch_acc: 0.318468. Batch_loss: 1.939769 \n",
      "Batch: 4020. Acc: 0.286755. Loss: 2.060146. Batch_acc: 0.320819. Batch_loss: 1.937161 \n",
      "Batch: 4021. Acc: 0.286762. Loss: 2.060121. Batch_acc: 0.313079. Batch_loss: 1.961592 \n",
      "Batch: 4022. Acc: 0.286771. Loss: 2.060091. Batch_acc: 0.321729. Batch_loss: 1.941862 \n",
      "Batch: 4023. Acc: 0.286780. Loss: 2.060064. Batch_acc: 0.325771. Batch_loss: 1.948211 \n",
      "Batch: 4024. Acc: 0.286786. Loss: 2.060040. Batch_acc: 0.311251. Batch_loss: 1.964324 \n",
      "Batch: 4025. Acc: 0.286795. Loss: 2.060017. Batch_acc: 0.319611. Batch_loss: 1.969313 \n",
      "Batch: 4026. Acc: 0.286811. Loss: 2.059978. Batch_acc: 0.351291. Batch_loss: 1.905731 \n",
      "Batch: 4027. Acc: 0.286824. Loss: 2.059938. Batch_acc: 0.339195. Batch_loss: 1.902638 \n",
      "Batch: 4028. Acc: 0.286834. Loss: 2.059906. Batch_acc: 0.323761. Batch_loss: 1.933388 \n",
      "Batch: 4029. Acc: 0.286840. Loss: 2.059884. Batch_acc: 0.311927. Batch_loss: 1.969118 \n",
      "Batch: 4030. Acc: 0.286847. Loss: 2.059860. Batch_acc: 0.314600. Batch_loss: 1.962937 \n",
      "Batch: 4031. Acc: 0.286857. Loss: 2.059838. Batch_acc: 0.331336. Batch_loss: 1.968763 \n",
      "Batch: 4032. Acc: 0.286870. Loss: 2.059810. Batch_acc: 0.337632. Batch_loss: 1.944832 \n",
      "Batch: 4033. Acc: 0.286881. Loss: 2.059780. Batch_acc: 0.335263. Batch_loss: 1.936210 \n",
      "Batch: 4034. Acc: 0.286884. Loss: 2.059761. Batch_acc: 0.297762. Batch_loss: 1.983836 \n",
      "Batch: 4035. Acc: 0.286895. Loss: 2.059730. Batch_acc: 0.329739. Batch_loss: 1.935498 \n",
      "Batch: 4036. Acc: 0.286904. Loss: 2.059702. Batch_acc: 0.324230. Batch_loss: 1.947545 \n",
      "Batch: 4037. Acc: 0.286910. Loss: 2.059683. Batch_acc: 0.311072. Batch_loss: 1.979751 \n",
      "Batch: 4038. Acc: 0.286920. Loss: 2.059657. Batch_acc: 0.326316. Batch_loss: 1.953480 \n",
      "Batch: 4039. Acc: 0.286929. Loss: 2.059623. Batch_acc: 0.326472. Batch_loss: 1.926001 \n",
      "Batch: 4040. Acc: 0.286938. Loss: 2.059599. Batch_acc: 0.322102. Batch_loss: 1.962665 \n",
      "Batch: 4041. Acc: 0.286946. Loss: 2.059571. Batch_acc: 0.316781. Batch_loss: 1.947777 \n",
      "Batch: 4042. Acc: 0.286951. Loss: 2.059546. Batch_acc: 0.310859. Batch_loss: 1.954700 \n",
      "Batch: 4043. Acc: 0.286959. Loss: 2.059520. Batch_acc: 0.318527. Batch_loss: 1.951239 \n",
      "Batch: 4044. Acc: 0.286966. Loss: 2.059493. Batch_acc: 0.314021. Batch_loss: 1.949569 \n",
      "Batch: 4045. Acc: 0.286974. Loss: 2.059465. Batch_acc: 0.319173. Batch_loss: 1.947534 \n",
      "Batch: 4046. Acc: 0.286982. Loss: 2.059438. Batch_acc: 0.322152. Batch_loss: 1.948589 \n",
      "Batch: 4047. Acc: 0.286993. Loss: 2.059410. Batch_acc: 0.331221. Batch_loss: 1.945833 \n",
      "Batch: 4048. Acc: 0.286998. Loss: 2.059389. Batch_acc: 0.305202. Batch_loss: 1.974069 \n",
      "Batch: 4049. Acc: 0.287006. Loss: 2.059363. Batch_acc: 0.321995. Batch_loss: 1.954095 \n",
      "Batch: 4050. Acc: 0.287013. Loss: 2.059343. Batch_acc: 0.315425. Batch_loss: 1.979666 \n",
      "Batch: 4051. Acc: 0.287024. Loss: 2.059311. Batch_acc: 0.328009. Batch_loss: 1.930894 \n",
      "Batch: 4052. Acc: 0.287037. Loss: 2.059279. Batch_acc: 0.340974. Batch_loss: 1.927708 \n",
      "Batch: 4053. Acc: 0.287049. Loss: 2.059247. Batch_acc: 0.336085. Batch_loss: 1.927136 \n",
      "Batch: 4054. Acc: 0.287055. Loss: 2.059227. Batch_acc: 0.313171. Batch_loss: 1.980399 \n",
      "Batch: 4055. Acc: 0.287064. Loss: 2.059198. Batch_acc: 0.320160. Batch_loss: 1.941630 \n",
      "Batch: 4056. Acc: 0.287066. Loss: 2.059178. Batch_acc: 0.299076. Batch_loss: 1.979090 \n",
      "Batch: 4057. Acc: 0.287072. Loss: 2.059152. Batch_acc: 0.310204. Batch_loss: 1.949605 \n",
      "Batch: 4058. Acc: 0.287078. Loss: 2.059126. Batch_acc: 0.312098. Batch_loss: 1.955019 \n",
      "Batch: 4059. Acc: 0.287087. Loss: 2.059101. Batch_acc: 0.320798. Batch_loss: 1.958717 \n",
      "Batch: 4060. Acc: 0.287096. Loss: 2.059079. Batch_acc: 0.326590. Batch_loss: 1.966838 \n",
      "Batch: 4061. Acc: 0.287102. Loss: 2.059052. Batch_acc: 0.309818. Batch_loss: 1.948379 \n",
      "Batch: 4062. Acc: 0.287110. Loss: 2.059023. Batch_acc: 0.321906. Batch_loss: 1.939654 \n",
      "Batch: 4063. Acc: 0.287116. Loss: 2.059002. Batch_acc: 0.311485. Batch_loss: 1.974006 \n",
      "Batch: 4064. Acc: 0.287120. Loss: 2.058982. Batch_acc: 0.302737. Batch_loss: 1.977136 \n",
      "Batch: 4065. Acc: 0.287130. Loss: 2.058951. Batch_acc: 0.328036. Batch_loss: 1.936019 \n",
      "Batch: 4066. Acc: 0.287138. Loss: 2.058919. Batch_acc: 0.320394. Batch_loss: 1.926215 \n",
      "Batch: 4067. Acc: 0.287146. Loss: 2.058893. Batch_acc: 0.319523. Batch_loss: 1.955355 \n",
      "Batch: 4068. Acc: 0.287159. Loss: 2.058866. Batch_acc: 0.339590. Batch_loss: 1.949478 \n",
      "Batch: 4069. Acc: 0.287166. Loss: 2.058838. Batch_acc: 0.314879. Batch_loss: 1.946831 \n",
      "Batch: 4070. Acc: 0.287174. Loss: 2.058814. Batch_acc: 0.317997. Batch_loss: 1.957924 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4071. Acc: 0.287182. Loss: 2.058783. Batch_acc: 0.322159. Batch_loss: 1.934655 \n",
      "Batch: 4072. Acc: 0.287190. Loss: 2.058756. Batch_acc: 0.316463. Batch_loss: 1.945675 \n",
      "Batch: 4073. Acc: 0.287199. Loss: 2.058722. Batch_acc: 0.326185. Batch_loss: 1.922905 \n",
      "Batch: 4074. Acc: 0.287209. Loss: 2.058694. Batch_acc: 0.326744. Batch_loss: 1.945572 \n",
      "Batch: 4075. Acc: 0.287216. Loss: 2.058662. Batch_acc: 0.316315. Batch_loss: 1.926621 \n",
      "Batch: 4076. Acc: 0.287223. Loss: 2.058641. Batch_acc: 0.316427. Batch_loss: 1.970779 \n",
      "Batch: 4077. Acc: 0.287232. Loss: 2.058615. Batch_acc: 0.325922. Batch_loss: 1.952039 \n",
      "Batch: 4078. Acc: 0.287244. Loss: 2.058584. Batch_acc: 0.334302. Batch_loss: 1.931457 \n",
      "Batch: 4079. Acc: 0.287253. Loss: 2.058562. Batch_acc: 0.324526. Batch_loss: 1.966079 \n",
      "Batch: 4080. Acc: 0.287259. Loss: 2.058537. Batch_acc: 0.310680. Batch_loss: 1.960718 \n",
      "Batch: 4081. Acc: 0.287268. Loss: 2.058511. Batch_acc: 0.325753. Batch_loss: 1.950911 \n",
      "Batch: 4082. Acc: 0.287276. Loss: 2.058481. Batch_acc: 0.318388. Batch_loss: 1.937961 \n",
      "Batch: 4083. Acc: 0.287285. Loss: 2.058454. Batch_acc: 0.323086. Batch_loss: 1.947314 \n",
      "Batch: 4084. Acc: 0.287289. Loss: 2.058428. Batch_acc: 0.306368. Batch_loss: 1.954710 \n",
      "Batch: 4085. Acc: 0.287301. Loss: 2.058397. Batch_acc: 0.336788. Batch_loss: 1.928172 \n",
      "Batch: 4086. Acc: 0.287309. Loss: 2.058371. Batch_acc: 0.318423. Batch_loss: 1.952552 \n",
      "Batch: 4087. Acc: 0.287317. Loss: 2.058346. Batch_acc: 0.319222. Batch_loss: 1.955125 \n",
      "Batch: 4088. Acc: 0.287325. Loss: 2.058316. Batch_acc: 0.322435. Batch_loss: 1.939476 \n",
      "Batch: 4089. Acc: 0.287336. Loss: 2.058285. Batch_acc: 0.329658. Batch_loss: 1.930857 \n",
      "Batch: 4090. Acc: 0.287344. Loss: 2.058264. Batch_acc: 0.320303. Batch_loss: 1.970770 \n",
      "Batch: 4091. Acc: 0.287351. Loss: 2.058241. Batch_acc: 0.317700. Batch_loss: 1.964760 \n",
      "Batch: 4092. Acc: 0.287361. Loss: 2.058219. Batch_acc: 0.325541. Batch_loss: 1.969217 \n",
      "Batch: 4093. Acc: 0.287372. Loss: 2.058183. Batch_acc: 0.335808. Batch_loss: 1.912458 \n",
      "Batch: 4094. Acc: 0.287381. Loss: 2.058152. Batch_acc: 0.320045. Batch_loss: 1.931305 \n",
      "Batch: 4095. Acc: 0.287383. Loss: 2.058133. Batch_acc: 0.298115. Batch_loss: 1.983846 \n",
      "Batch: 4096. Acc: 0.287387. Loss: 2.058125. Batch_acc: 0.303665. Batch_loss: 2.022071 \n",
      "Batch: 4097. Acc: 0.287394. Loss: 2.058099. Batch_acc: 0.315285. Batch_loss: 1.955984 \n",
      "Batch: 4098. Acc: 0.287406. Loss: 2.058066. Batch_acc: 0.334868. Batch_loss: 1.922718 \n",
      "Batch: 4099. Acc: 0.287414. Loss: 2.058043. Batch_acc: 0.320455. Batch_loss: 1.962313 \n",
      "Batch: 4100. Acc: 0.287423. Loss: 2.058015. Batch_acc: 0.323716. Batch_loss: 1.942965 \n",
      "Batch: 4101. Acc: 0.287434. Loss: 2.057984. Batch_acc: 0.332597. Batch_loss: 1.935908 \n",
      "Batch: 4102. Acc: 0.287441. Loss: 2.057961. Batch_acc: 0.315486. Batch_loss: 1.965679 \n",
      "Batch: 4103. Acc: 0.287450. Loss: 2.057934. Batch_acc: 0.324048. Batch_loss: 1.947600 \n",
      "Batch: 4104. Acc: 0.287459. Loss: 2.057910. Batch_acc: 0.323944. Batch_loss: 1.962549 \n",
      "Batch: 4105. Acc: 0.287466. Loss: 2.057900. Batch_acc: 0.316648. Batch_loss: 2.018125 \n",
      "Batch: 4106. Acc: 0.287475. Loss: 2.057875. Batch_acc: 0.324355. Batch_loss: 1.953430 \n",
      "Batch: 4107. Acc: 0.287485. Loss: 2.057841. Batch_acc: 0.328143. Batch_loss: 1.917510 \n",
      "Batch: 4108. Acc: 0.287488. Loss: 2.057821. Batch_acc: 0.298671. Batch_loss: 1.976159 \n",
      "Batch: 4109. Acc: 0.287495. Loss: 2.057794. Batch_acc: 0.315819. Batch_loss: 1.949400 \n",
      "Batch: 4110. Acc: 0.287505. Loss: 2.057765. Batch_acc: 0.328767. Batch_loss: 1.939165 \n",
      "Batch: 4111. Acc: 0.287516. Loss: 2.057737. Batch_acc: 0.332170. Batch_loss: 1.943219 \n",
      "Batch: 4112. Acc: 0.287523. Loss: 2.057709. Batch_acc: 0.318630. Batch_loss: 1.940394 \n",
      "Batch: 4113. Acc: 0.287530. Loss: 2.057688. Batch_acc: 0.313520. Batch_loss: 1.969566 \n",
      "Batch: 4114. Acc: 0.287536. Loss: 2.057667. Batch_acc: 0.312217. Batch_loss: 1.973562 \n",
      "Batch: 4115. Acc: 0.287548. Loss: 2.057634. Batch_acc: 0.336000. Batch_loss: 1.922500 \n",
      "Batch: 4116. Acc: 0.287555. Loss: 2.057607. Batch_acc: 0.315848. Batch_loss: 1.948465 \n",
      "Batch: 4117. Acc: 0.287564. Loss: 2.057582. Batch_acc: 0.324826. Batch_loss: 1.953398 \n",
      "Batch: 4118. Acc: 0.287565. Loss: 2.057572. Batch_acc: 0.293617. Batch_loss: 2.015694 \n",
      "Batch: 4119. Acc: 0.287570. Loss: 2.057546. Batch_acc: 0.310167. Batch_loss: 1.949219 \n",
      "Batch: 4120. Acc: 0.287575. Loss: 2.057532. Batch_acc: 0.307295. Batch_loss: 2.000786 \n",
      "Batch: 4121. Acc: 0.287588. Loss: 2.057497. Batch_acc: 0.338926. Batch_loss: 1.916950 \n",
      "Batch: 4122. Acc: 0.287597. Loss: 2.057472. Batch_acc: 0.325000. Batch_loss: 1.950591 \n",
      "Batch: 4123. Acc: 0.287608. Loss: 2.057444. Batch_acc: 0.333713. Batch_loss: 1.943964 \n",
      "Batch: 4124. Acc: 0.287614. Loss: 2.057426. Batch_acc: 0.314035. Batch_loss: 1.981953 \n",
      "Batch: 4125. Acc: 0.287620. Loss: 2.057400. Batch_acc: 0.310505. Batch_loss: 1.949416 \n",
      "Batch: 4126. Acc: 0.287626. Loss: 2.057381. Batch_acc: 0.313232. Batch_loss: 1.975424 \n",
      "Batch: 4127. Acc: 0.287632. Loss: 2.057360. Batch_acc: 0.314069. Batch_loss: 1.971161 \n",
      "Batch: 4128. Acc: 0.287640. Loss: 2.057332. Batch_acc: 0.321576. Batch_loss: 1.940950 \n",
      "Batch: 4129. Acc: 0.287647. Loss: 2.057312. Batch_acc: 0.316249. Batch_loss: 1.972820 \n",
      "Batch: 4130. Acc: 0.287655. Loss: 2.057286. Batch_acc: 0.318579. Batch_loss: 1.947326 \n",
      "Batch: 4131. Acc: 0.287665. Loss: 2.057253. Batch_acc: 0.328563. Batch_loss: 1.923726 \n",
      "Batch: 4132. Acc: 0.287673. Loss: 2.057231. Batch_acc: 0.322821. Batch_loss: 1.963295 \n",
      "Batch: 4133. Acc: 0.287687. Loss: 2.057198. Batch_acc: 0.344205. Batch_loss: 1.921779 \n",
      "Batch: 4134. Acc: 0.287695. Loss: 2.057170. Batch_acc: 0.323112. Batch_loss: 1.941636 \n",
      "Batch: 4135. Acc: 0.287704. Loss: 2.057147. Batch_acc: 0.325691. Batch_loss: 1.958924 \n",
      "Batch: 4136. Acc: 0.287715. Loss: 2.057115. Batch_acc: 0.333144. Batch_loss: 1.925875 \n",
      "Batch: 4137. Acc: 0.287718. Loss: 2.057093. Batch_acc: 0.298498. Batch_loss: 1.962234 \n",
      "Batch: 4138. Acc: 0.287726. Loss: 2.057068. Batch_acc: 0.319405. Batch_loss: 1.953264 \n",
      "Batch: 4139. Acc: 0.287733. Loss: 2.057048. Batch_acc: 0.321090. Batch_loss: 1.975625 \n",
      "Batch: 4140. Acc: 0.287740. Loss: 2.057028. Batch_acc: 0.314783. Batch_loss: 1.970111 \n",
      "Batch: 4141. Acc: 0.287750. Loss: 2.057002. Batch_acc: 0.329702. Batch_loss: 1.951068 \n",
      "Batch: 4142. Acc: 0.287761. Loss: 2.056974. Batch_acc: 0.332186. Batch_loss: 1.939494 \n",
      "Batch: 4143. Acc: 0.287773. Loss: 2.056949. Batch_acc: 0.338785. Batch_loss: 1.953303 \n",
      "Batch: 4144. Acc: 0.287786. Loss: 2.056914. Batch_acc: 0.341969. Batch_loss: 1.910325 \n",
      "Batch: 4145. Acc: 0.287795. Loss: 2.056890. Batch_acc: 0.323512. Batch_loss: 1.957627 \n",
      "Batch: 4146. Acc: 0.287803. Loss: 2.056883. Batch_acc: 0.321202. Batch_loss: 2.027671 \n",
      "Batch: 4147. Acc: 0.287808. Loss: 2.056864. Batch_acc: 0.311176. Batch_loss: 1.979472 \n",
      "Batch: 4148. Acc: 0.287819. Loss: 2.056831. Batch_acc: 0.331461. Batch_loss: 1.922949 \n",
      "Batch: 4149. Acc: 0.287827. Loss: 2.056809. Batch_acc: 0.320273. Batch_loss: 1.963967 \n",
      "Batch: 4150. Acc: 0.287834. Loss: 2.056783. Batch_acc: 0.318003. Batch_loss: 1.951700 \n",
      "Batch: 4151. Acc: 0.287841. Loss: 2.056756. Batch_acc: 0.313193. Batch_loss: 1.948077 \n",
      "Batch: 4152. Acc: 0.287849. Loss: 2.056724. Batch_acc: 0.322159. Batch_loss: 1.926877 \n",
      "Batch: 4153. Acc: 0.287855. Loss: 2.056698. Batch_acc: 0.313246. Batch_loss: 1.950552 \n",
      "Batch: 4154. Acc: 0.287868. Loss: 2.056668. Batch_acc: 0.340377. Batch_loss: 1.934080 \n",
      "Batch: 4155. Acc: 0.287874. Loss: 2.056649. Batch_acc: 0.313174. Batch_loss: 1.971548 \n",
      "Batch: 4156. Acc: 0.287880. Loss: 2.056632. Batch_acc: 0.313476. Batch_loss: 1.986722 \n",
      "Batch: 4157. Acc: 0.287891. Loss: 2.056604. Batch_acc: 0.336848. Batch_loss: 1.937124 \n",
      "Batch: 4158. Acc: 0.287900. Loss: 2.056575. Batch_acc: 0.322140. Batch_loss: 1.936783 \n",
      "Batch: 4159. Acc: 0.287908. Loss: 2.056555. Batch_acc: 0.323430. Batch_loss: 1.976187 \n",
      "Batch: 4160. Acc: 0.287916. Loss: 2.056526. Batch_acc: 0.318736. Batch_loss: 1.941961 \n",
      "Batch: 4161. Acc: 0.287925. Loss: 2.056505. Batch_acc: 0.325677. Batch_loss: 1.966179 \n",
      "Batch: 4162. Acc: 0.287930. Loss: 2.056500. Batch_acc: 0.307331. Batch_loss: 2.033291 \n",
      "Batch: 4163. Acc: 0.287938. Loss: 2.056473. Batch_acc: 0.320615. Batch_loss: 1.945929 \n",
      "Batch: 4164. Acc: 0.287949. Loss: 2.056443. Batch_acc: 0.334094. Batch_loss: 1.934867 \n",
      "Batch: 4165. Acc: 0.287959. Loss: 2.056413. Batch_acc: 0.331070. Batch_loss: 1.932727 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4166. Acc: 0.287967. Loss: 2.056391. Batch_acc: 0.322525. Batch_loss: 1.963785 \n",
      "Batch: 4167. Acc: 0.287975. Loss: 2.056363. Batch_acc: 0.320091. Batch_loss: 1.939693 \n",
      "Batch: 4168. Acc: 0.287980. Loss: 2.056340. Batch_acc: 0.308176. Batch_loss: 1.961697 \n",
      "Batch: 4169. Acc: 0.287990. Loss: 2.056317. Batch_acc: 0.329526. Batch_loss: 1.961009 \n",
      "Batch: 4170. Acc: 0.287996. Loss: 2.056284. Batch_acc: 0.312823. Batch_loss: 1.921619 \n",
      "Batch: 4171. Acc: 0.288009. Loss: 2.056247. Batch_acc: 0.341143. Batch_loss: 1.899895 \n",
      "Batch: 4172. Acc: 0.288016. Loss: 2.056219. Batch_acc: 0.317003. Batch_loss: 1.939547 \n",
      "Batch: 4173. Acc: 0.288024. Loss: 2.056197. Batch_acc: 0.320896. Batch_loss: 1.965362 \n",
      "Batch: 4174. Acc: 0.288034. Loss: 2.056167. Batch_acc: 0.329379. Batch_loss: 1.933674 \n",
      "Batch: 4175. Acc: 0.288042. Loss: 2.056146. Batch_acc: 0.322656. Batch_loss: 1.965290 \n",
      "Batch: 4176. Acc: 0.288052. Loss: 2.056119. Batch_acc: 0.327982. Batch_loss: 1.945702 \n",
      "Batch: 4177. Acc: 0.288059. Loss: 2.056093. Batch_acc: 0.319493. Batch_loss: 1.948869 \n",
      "Batch: 4178. Acc: 0.288068. Loss: 2.056062. Batch_acc: 0.325356. Batch_loss: 1.927662 \n",
      "Batch: 4179. Acc: 0.288074. Loss: 2.056040. Batch_acc: 0.313196. Batch_loss: 1.961388 \n",
      "Batch: 4180. Acc: 0.288080. Loss: 2.056018. Batch_acc: 0.312573. Batch_loss: 1.960115 \n",
      "Batch: 4181. Acc: 0.288087. Loss: 2.055997. Batch_acc: 0.319026. Batch_loss: 1.970711 \n",
      "Batch: 4182. Acc: 0.288094. Loss: 2.055974. Batch_acc: 0.316792. Batch_loss: 1.956040 \n",
      "Batch: 4183. Acc: 0.288105. Loss: 2.055940. Batch_acc: 0.335270. Batch_loss: 1.912932 \n",
      "Batch: 4184. Acc: 0.288113. Loss: 2.055917. Batch_acc: 0.321037. Batch_loss: 1.959868 \n",
      "Batch: 4185. Acc: 0.288121. Loss: 2.055897. Batch_acc: 0.321387. Batch_loss: 1.973353 \n",
      "Batch: 4186. Acc: 0.288132. Loss: 2.055865. Batch_acc: 0.331836. Batch_loss: 1.925439 \n",
      "Batch: 4187. Acc: 0.288136. Loss: 2.055840. Batch_acc: 0.308492. Batch_loss: 1.951774 \n",
      "Batch: 4188. Acc: 0.288146. Loss: 2.055808. Batch_acc: 0.326648. Batch_loss: 1.919675 \n",
      "Batch: 4189. Acc: 0.288152. Loss: 2.055785. Batch_acc: 0.314092. Batch_loss: 1.961361 \n",
      "Batch: 4190. Acc: 0.288160. Loss: 2.055759. Batch_acc: 0.323870. Batch_loss: 1.946623 \n",
      "Batch: 4191. Acc: 0.288169. Loss: 2.055741. Batch_acc: 0.322857. Batch_loss: 1.980804 \n",
      "Batch: 4192. Acc: 0.288175. Loss: 2.055723. Batch_acc: 0.314502. Batch_loss: 1.977671 \n",
      "Batch: 4193. Acc: 0.288180. Loss: 2.055708. Batch_acc: 0.310663. Batch_loss: 1.993755 \n",
      "Batch: 4194. Acc: 0.288188. Loss: 2.055682. Batch_acc: 0.318333. Batch_loss: 1.948634 \n",
      "Batch: 4195. Acc: 0.288195. Loss: 2.055658. Batch_acc: 0.318925. Batch_loss: 1.953948 \n",
      "Batch: 4196. Acc: 0.288206. Loss: 2.055626. Batch_acc: 0.336247. Batch_loss: 1.922067 \n",
      "Batch: 4197. Acc: 0.288213. Loss: 2.055601. Batch_acc: 0.315084. Batch_loss: 1.950009 \n",
      "Batch: 4198. Acc: 0.288226. Loss: 2.055573. Batch_acc: 0.341899. Batch_loss: 1.937822 \n",
      "Batch: 4199. Acc: 0.288235. Loss: 2.055547. Batch_acc: 0.324757. Batch_loss: 1.949336 \n",
      "Batch: 4200. Acc: 0.288242. Loss: 2.055518. Batch_acc: 0.318931. Batch_loss: 1.933454 \n",
      "Batch: 4201. Acc: 0.288249. Loss: 2.055495. Batch_acc: 0.318675. Batch_loss: 1.961457 \n",
      "Batch: 4202. Acc: 0.288252. Loss: 2.055476. Batch_acc: 0.301044. Batch_loss: 1.975923 \n",
      "Batch: 4203. Acc: 0.288257. Loss: 2.055448. Batch_acc: 0.308628. Batch_loss: 1.935886 \n",
      "Batch: 4204. Acc: 0.288264. Loss: 2.055427. Batch_acc: 0.316609. Batch_loss: 1.966726 \n",
      "Batch: 4205. Acc: 0.288272. Loss: 2.055398. Batch_acc: 0.325350. Batch_loss: 1.931361 \n",
      "Batch: 4206. Acc: 0.288281. Loss: 2.055369. Batch_acc: 0.323462. Batch_loss: 1.932729 \n",
      "Batch: 4207. Acc: 0.288288. Loss: 2.055350. Batch_acc: 0.318960. Batch_loss: 1.974074 \n",
      "Batch: 4208. Acc: 0.288297. Loss: 2.055319. Batch_acc: 0.327429. Batch_loss: 1.928091 \n",
      "Batch: 4209. Acc: 0.288302. Loss: 2.055295. Batch_acc: 0.309237. Batch_loss: 1.952682 \n",
      "Batch: 4210. Acc: 0.288305. Loss: 2.055275. Batch_acc: 0.298716. Batch_loss: 1.971774 \n",
      "Batch: 4211. Acc: 0.288310. Loss: 2.055246. Batch_acc: 0.311438. Batch_loss: 1.935089 \n",
      "Batch: 4212. Acc: 0.288318. Loss: 2.055221. Batch_acc: 0.321793. Batch_loss: 1.950294 \n",
      "Batch: 4213. Acc: 0.288326. Loss: 2.055190. Batch_acc: 0.319728. Batch_loss: 1.925816 \n",
      "Batch: 4214. Acc: 0.288335. Loss: 2.055165. Batch_acc: 0.326934. Batch_loss: 1.948251 \n",
      "Batch: 4215. Acc: 0.288338. Loss: 2.055146. Batch_acc: 0.302258. Batch_loss: 1.976567 \n",
      "Batch: 4216. Acc: 0.288351. Loss: 2.055113. Batch_acc: 0.340547. Batch_loss: 1.914740 \n",
      "Batch: 4217. Acc: 0.288357. Loss: 2.055094. Batch_acc: 0.312929. Batch_loss: 1.976658 \n",
      "Batch: 4218. Acc: 0.288369. Loss: 2.055064. Batch_acc: 0.339919. Batch_loss: 1.927224 \n",
      "Batch: 4219. Acc: 0.288379. Loss: 2.055030. Batch_acc: 0.330342. Batch_loss: 1.913728 \n",
      "Batch: 4220. Acc: 0.288386. Loss: 2.055009. Batch_acc: 0.319274. Batch_loss: 1.967269 \n",
      "Batch: 4221. Acc: 0.288397. Loss: 2.054979. Batch_acc: 0.333911. Batch_loss: 1.928400 \n",
      "Batch: 4222. Acc: 0.288409. Loss: 2.054949. Batch_acc: 0.336323. Batch_loss: 1.930824 \n",
      "Batch: 4223. Acc: 0.288417. Loss: 2.054917. Batch_acc: 0.324841. Batch_loss: 1.919413 \n",
      "Batch: 4224. Acc: 0.288425. Loss: 2.054889. Batch_acc: 0.323804. Batch_loss: 1.935701 \n",
      "Batch: 4225. Acc: 0.288436. Loss: 2.054861. Batch_acc: 0.331618. Batch_loss: 1.935670 \n",
      "Batch: 4226. Acc: 0.288445. Loss: 2.054835. Batch_acc: 0.328231. Batch_loss: 1.946461 \n",
      "Batch: 4227. Acc: 0.288452. Loss: 2.054818. Batch_acc: 0.317217. Batch_loss: 1.982301 \n",
      "Batch: 4228. Acc: 0.288455. Loss: 2.054801. Batch_acc: 0.302217. Batch_loss: 1.979110 \n",
      "Batch: 4229. Acc: 0.288460. Loss: 2.054781. Batch_acc: 0.310641. Batch_loss: 1.970034 \n",
      "Batch: 4230. Acc: 0.288472. Loss: 2.054749. Batch_acc: 0.335362. Batch_loss: 1.924831 \n",
      "Batch: 4231. Acc: 0.288476. Loss: 2.054730. Batch_acc: 0.305828. Batch_loss: 1.976364 \n",
      "Batch: 4232. Acc: 0.288480. Loss: 2.054709. Batch_acc: 0.305850. Batch_loss: 1.968520 \n",
      "Batch: 4233. Acc: 0.288487. Loss: 2.054692. Batch_acc: 0.319050. Batch_loss: 1.979693 \n",
      "Batch: 4234. Acc: 0.288492. Loss: 2.054675. Batch_acc: 0.308046. Batch_loss: 1.985067 \n",
      "Batch: 4235. Acc: 0.288499. Loss: 2.054648. Batch_acc: 0.320557. Batch_loss: 1.938417 \n",
      "Batch: 4236. Acc: 0.288511. Loss: 2.054613. Batch_acc: 0.336800. Batch_loss: 1.905623 \n",
      "Batch: 4237. Acc: 0.288520. Loss: 2.054591. Batch_acc: 0.327449. Batch_loss: 1.960837 \n",
      "Batch: 4238. Acc: 0.288524. Loss: 2.054577. Batch_acc: 0.307028. Batch_loss: 1.998777 \n",
      "Batch: 4239. Acc: 0.288532. Loss: 2.054553. Batch_acc: 0.322357. Batch_loss: 1.952114 \n",
      "Batch: 4240. Acc: 0.288538. Loss: 2.054537. Batch_acc: 0.310267. Batch_loss: 1.985201 \n",
      "Batch: 4241. Acc: 0.288550. Loss: 2.054500. Batch_acc: 0.341230. Batch_loss: 1.902351 \n",
      "Batch: 4242. Acc: 0.288557. Loss: 2.054476. Batch_acc: 0.315029. Batch_loss: 1.950679 \n",
      "Batch: 4243. Acc: 0.288567. Loss: 2.054451. Batch_acc: 0.334111. Batch_loss: 1.948878 \n",
      "Batch: 4244. Acc: 0.288578. Loss: 2.054419. Batch_acc: 0.337420. Batch_loss: 1.915935 \n",
      "Batch: 4245. Acc: 0.288586. Loss: 2.054398. Batch_acc: 0.318718. Batch_loss: 1.966280 \n",
      "Batch: 4246. Acc: 0.288593. Loss: 2.054378. Batch_acc: 0.320744. Batch_loss: 1.967354 \n",
      "Batch: 4247. Acc: 0.288598. Loss: 2.054358. Batch_acc: 0.309242. Batch_loss: 1.970469 \n",
      "Batch: 4248. Acc: 0.288608. Loss: 2.054332. Batch_acc: 0.329885. Batch_loss: 1.942195 \n",
      "Batch: 4249. Acc: 0.288614. Loss: 2.054309. Batch_acc: 0.317297. Batch_loss: 1.957932 \n",
      "Batch: 4250. Acc: 0.288621. Loss: 2.054297. Batch_acc: 0.317619. Batch_loss: 1.999573 \n",
      "Batch: 4251. Acc: 0.288628. Loss: 2.054271. Batch_acc: 0.316889. Batch_loss: 1.945359 \n",
      "Batch: 4252. Acc: 0.288637. Loss: 2.054247. Batch_acc: 0.330046. Batch_loss: 1.949049 \n",
      "Batch: 4253. Acc: 0.288644. Loss: 2.054227. Batch_acc: 0.315486. Batch_loss: 1.971726 \n",
      "Batch: 4254. Acc: 0.288653. Loss: 2.054200. Batch_acc: 0.327697. Batch_loss: 1.937286 \n",
      "Batch: 4255. Acc: 0.288657. Loss: 2.054183. Batch_acc: 0.308352. Batch_loss: 1.982263 \n",
      "Batch: 4256. Acc: 0.288664. Loss: 2.054163. Batch_acc: 0.315517. Batch_loss: 1.968218 \n",
      "Batch: 4257. Acc: 0.288671. Loss: 2.054142. Batch_acc: 0.320092. Batch_loss: 1.964715 \n",
      "Batch: 4258. Acc: 0.288677. Loss: 2.054118. Batch_acc: 0.316185. Batch_loss: 1.952448 \n",
      "Batch: 4259. Acc: 0.288687. Loss: 2.054090. Batch_acc: 0.328358. Batch_loss: 1.934171 \n",
      "Batch: 4260. Acc: 0.288695. Loss: 2.054072. Batch_acc: 0.321926. Batch_loss: 1.975276 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4261. Acc: 0.288702. Loss: 2.054047. Batch_acc: 0.318976. Batch_loss: 1.948418 \n",
      "Batch: 4262. Acc: 0.288709. Loss: 2.054022. Batch_acc: 0.320186. Batch_loss: 1.944914 \n",
      "Batch: 4263. Acc: 0.288717. Loss: 2.053998. Batch_acc: 0.323478. Batch_loss: 1.951916 \n",
      "Batch: 4264. Acc: 0.288727. Loss: 2.053971. Batch_acc: 0.331046. Batch_loss: 1.938348 \n",
      "Batch: 4265. Acc: 0.288731. Loss: 2.053953. Batch_acc: 0.307151. Batch_loss: 1.977070 \n",
      "Batch: 4266. Acc: 0.288740. Loss: 2.053927. Batch_acc: 0.327108. Batch_loss: 1.943227 \n",
      "Batch: 4267. Acc: 0.288752. Loss: 2.053897. Batch_acc: 0.335955. Batch_loss: 1.931291 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.2887516426711899. Loss per char: 2.0538973204312625. Time: 1627205971.4244483\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 18, 26, 20,  1, 12,  1, 18, 26, 26,\n",
      "        17, 21, 20, 24, 24, 18, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.288757. Loss: 2.053876. Batch_acc: 0.310345. Batch_loss: 1.965476 \n",
      "Batch: 4269. Acc: 0.288767. Loss: 2.053844. Batch_acc: 0.332953. Batch_loss: 1.917230 \n",
      "Batch: 4270. Acc: 0.288777. Loss: 2.053815. Batch_acc: 0.329708. Batch_loss: 1.928913 \n",
      "Batch: 4271. Acc: 0.288780. Loss: 2.053799. Batch_acc: 0.302339. Batch_loss: 1.987189 \n",
      "Batch: 4272. Acc: 0.288789. Loss: 2.053770. Batch_acc: 0.326693. Batch_loss: 1.931072 \n",
      "Batch: 4273. Acc: 0.288801. Loss: 2.053737. Batch_acc: 0.336706. Batch_loss: 1.918474 \n",
      "Batch: 4274. Acc: 0.288807. Loss: 2.053707. Batch_acc: 0.315274. Batch_loss: 1.924503 \n",
      "Batch: 4275. Acc: 0.288815. Loss: 2.053685. Batch_acc: 0.323529. Batch_loss: 1.955377 \n",
      "Batch: 4276. Acc: 0.288821. Loss: 2.053666. Batch_acc: 0.315636. Batch_loss: 1.970680 \n",
      "Batch: 4277. Acc: 0.288824. Loss: 2.053654. Batch_acc: 0.301330. Batch_loss: 2.003226 \n",
      "Batch: 4278. Acc: 0.288834. Loss: 2.053617. Batch_acc: 0.332365. Batch_loss: 1.895082 \n",
      "Batch: 4279. Acc: 0.288838. Loss: 2.053599. Batch_acc: 0.306590. Batch_loss: 1.975805 \n",
      "Batch: 4280. Acc: 0.288847. Loss: 2.053570. Batch_acc: 0.326670. Batch_loss: 1.932324 \n",
      "Batch: 4281. Acc: 0.288857. Loss: 2.053539. Batch_acc: 0.333527. Batch_loss: 1.917756 \n",
      "Batch: 4282. Acc: 0.288866. Loss: 2.053520. Batch_acc: 0.326012. Batch_loss: 1.972437 \n",
      "Batch: 4283. Acc: 0.288872. Loss: 2.053500. Batch_acc: 0.318075. Batch_loss: 1.963406 \n",
      "Batch: 4284. Acc: 0.288881. Loss: 2.053475. Batch_acc: 0.325410. Batch_loss: 1.949582 \n",
      "Batch: 4285. Acc: 0.288890. Loss: 2.053449. Batch_acc: 0.326968. Batch_loss: 1.939229 \n",
      "Batch: 4286. Acc: 0.288901. Loss: 2.053422. Batch_acc: 0.337250. Batch_loss: 1.936817 \n",
      "Batch: 4287. Acc: 0.288903. Loss: 2.053403. Batch_acc: 0.298032. Batch_loss: 1.970972 \n",
      "Batch: 4288. Acc: 0.288913. Loss: 2.053370. Batch_acc: 0.329873. Batch_loss: 1.913994 \n",
      "Batch: 4289. Acc: 0.288920. Loss: 2.053352. Batch_acc: 0.320344. Batch_loss: 1.975487 \n",
      "Batch: 4290. Acc: 0.288928. Loss: 2.053322. Batch_acc: 0.323912. Batch_loss: 1.925311 \n",
      "Batch: 4291. Acc: 0.288935. Loss: 2.053298. Batch_acc: 0.319953. Batch_loss: 1.950493 \n",
      "Batch: 4292. Acc: 0.288942. Loss: 2.053282. Batch_acc: 0.318235. Batch_loss: 1.984239 \n",
      "Batch: 4293. Acc: 0.288948. Loss: 2.053258. Batch_acc: 0.315425. Batch_loss: 1.947293 \n",
      "Batch: 4294. Acc: 0.288957. Loss: 2.053229. Batch_acc: 0.327954. Batch_loss: 1.928740 \n",
      "Batch: 4295. Acc: 0.288962. Loss: 2.053208. Batch_acc: 0.310663. Batch_loss: 1.962388 \n",
      "Batch: 4296. Acc: 0.288967. Loss: 2.053184. Batch_acc: 0.310244. Batch_loss: 1.951432 \n",
      "Batch: 4297. Acc: 0.288979. Loss: 2.053156. Batch_acc: 0.337370. Batch_loss: 1.931613 \n",
      "Batch: 4298. Acc: 0.288988. Loss: 2.053130. Batch_acc: 0.327508. Batch_loss: 1.941260 \n",
      "Batch: 4299. Acc: 0.288994. Loss: 2.053105. Batch_acc: 0.316000. Batch_loss: 1.948999 \n",
      "Batch: 4300. Acc: 0.289001. Loss: 2.053089. Batch_acc: 0.319611. Batch_loss: 1.982642 \n",
      "Batch: 4301. Acc: 0.289009. Loss: 2.053068. Batch_acc: 0.320952. Batch_loss: 1.964943 \n",
      "Batch: 4302. Acc: 0.289017. Loss: 2.053042. Batch_acc: 0.325542. Batch_loss: 1.940161 \n",
      "Batch: 4303. Acc: 0.289022. Loss: 2.053017. Batch_acc: 0.309081. Batch_loss: 1.949329 \n",
      "Batch: 4304. Acc: 0.289034. Loss: 2.052987. Batch_acc: 0.340148. Batch_loss: 1.922070 \n",
      "Batch: 4305. Acc: 0.289044. Loss: 2.052955. Batch_acc: 0.331844. Batch_loss: 1.919138 \n",
      "Batch: 4306. Acc: 0.289048. Loss: 2.052936. Batch_acc: 0.305732. Batch_loss: 1.973843 \n",
      "Batch: 4307. Acc: 0.289057. Loss: 2.052907. Batch_acc: 0.327001. Batch_loss: 1.926845 \n",
      "Batch: 4308. Acc: 0.289065. Loss: 2.052878. Batch_acc: 0.325447. Batch_loss: 1.926293 \n",
      "Batch: 4309. Acc: 0.289072. Loss: 2.052856. Batch_acc: 0.318824. Batch_loss: 1.957091 \n",
      "Batch: 4310. Acc: 0.289080. Loss: 2.052830. Batch_acc: 0.324009. Batch_loss: 1.938347 \n",
      "Batch: 4311. Acc: 0.289087. Loss: 2.052806. Batch_acc: 0.317568. Batch_loss: 1.951153 \n",
      "Batch: 4312. Acc: 0.289093. Loss: 2.052786. Batch_acc: 0.314974. Batch_loss: 1.967269 \n",
      "Batch: 4313. Acc: 0.289099. Loss: 2.052763. Batch_acc: 0.314965. Batch_loss: 1.952376 \n",
      "Batch: 4314. Acc: 0.289109. Loss: 2.052734. Batch_acc: 0.336247. Batch_loss: 1.928637 \n",
      "Batch: 4315. Acc: 0.289117. Loss: 2.052710. Batch_acc: 0.322361. Batch_loss: 1.949067 \n",
      "Batch: 4316. Acc: 0.289127. Loss: 2.052686. Batch_acc: 0.329909. Batch_loss: 1.949312 \n",
      "Batch: 4317. Acc: 0.289137. Loss: 2.052651. Batch_acc: 0.331254. Batch_loss: 1.905960 \n",
      "Batch: 4318. Acc: 0.289145. Loss: 2.052618. Batch_acc: 0.325964. Batch_loss: 1.910635 \n",
      "Batch: 4319. Acc: 0.289154. Loss: 2.052595. Batch_acc: 0.327556. Batch_loss: 1.951162 \n",
      "Batch: 4320. Acc: 0.289160. Loss: 2.052572. Batch_acc: 0.312358. Batch_loss: 1.956118 \n",
      "Batch: 4321. Acc: 0.289168. Loss: 2.052550. Batch_acc: 0.325434. Batch_loss: 1.958137 \n",
      "Batch: 4322. Acc: 0.289175. Loss: 2.052531. Batch_acc: 0.321694. Batch_loss: 1.968688 \n",
      "Batch: 4323. Acc: 0.289185. Loss: 2.052504. Batch_acc: 0.328863. Batch_loss: 1.936992 \n",
      "Batch: 4324. Acc: 0.289192. Loss: 2.052483. Batch_acc: 0.321024. Batch_loss: 1.956339 \n",
      "Batch: 4325. Acc: 0.289198. Loss: 2.052460. Batch_acc: 0.317681. Batch_loss: 1.953401 \n",
      "Batch: 4326. Acc: 0.289206. Loss: 2.052437. Batch_acc: 0.325086. Batch_loss: 1.953987 \n",
      "Batch: 4327. Acc: 0.289216. Loss: 2.052404. Batch_acc: 0.329399. Batch_loss: 1.910870 \n",
      "Batch: 4328. Acc: 0.289221. Loss: 2.052391. Batch_acc: 0.310064. Batch_loss: 1.995493 \n",
      "Batch: 4329. Acc: 0.289229. Loss: 2.052367. Batch_acc: 0.324855. Batch_loss: 1.947950 \n",
      "Batch: 4330. Acc: 0.289239. Loss: 2.052340. Batch_acc: 0.333908. Batch_loss: 1.933921 \n",
      "Batch: 4331. Acc: 0.289248. Loss: 2.052304. Batch_acc: 0.325424. Batch_loss: 1.902742 \n",
      "Batch: 4332. Acc: 0.289254. Loss: 2.052282. Batch_acc: 0.317997. Batch_loss: 1.954969 \n",
      "Batch: 4333. Acc: 0.289263. Loss: 2.052251. Batch_acc: 0.325711. Batch_loss: 1.922395 \n",
      "Batch: 4334. Acc: 0.289268. Loss: 2.052231. Batch_acc: 0.313389. Batch_loss: 1.962987 \n",
      "Batch: 4335. Acc: 0.289278. Loss: 2.052201. Batch_acc: 0.330075. Batch_loss: 1.921104 \n",
      "Batch: 4336. Acc: 0.289284. Loss: 2.052183. Batch_acc: 0.316411. Batch_loss: 1.972486 \n",
      "Batch: 4337. Acc: 0.289289. Loss: 2.052171. Batch_acc: 0.312172. Batch_loss: 1.999449 \n",
      "Batch: 4338. Acc: 0.289293. Loss: 2.052148. Batch_acc: 0.306442. Batch_loss: 1.949904 \n",
      "Batch: 4339. Acc: 0.289302. Loss: 2.052123. Batch_acc: 0.327526. Batch_loss: 1.942629 \n",
      "Batch: 4340. Acc: 0.289311. Loss: 2.052096. Batch_acc: 0.331585. Batch_loss: 1.932256 \n",
      "Batch: 4341. Acc: 0.289316. Loss: 2.052082. Batch_acc: 0.310914. Batch_loss: 1.992950 \n",
      "Batch: 4342. Acc: 0.289323. Loss: 2.052062. Batch_acc: 0.319523. Batch_loss: 1.966258 \n",
      "Batch: 4343. Acc: 0.289332. Loss: 2.052044. Batch_acc: 0.329749. Batch_loss: 1.967578 \n",
      "Batch: 4344. Acc: 0.289341. Loss: 2.052016. Batch_acc: 0.324986. Batch_loss: 1.933520 \n",
      "Batch: 4345. Acc: 0.289347. Loss: 2.051998. Batch_acc: 0.318078. Batch_loss: 1.972767 \n",
      "Batch: 4346. Acc: 0.289355. Loss: 2.051974. Batch_acc: 0.321654. Batch_loss: 1.949481 \n",
      "Batch: 4347. Acc: 0.289362. Loss: 2.051950. Batch_acc: 0.319185. Batch_loss: 1.947790 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4348. Acc: 0.289369. Loss: 2.051925. Batch_acc: 0.320046. Batch_loss: 1.944233 \n",
      "Batch: 4349. Acc: 0.289377. Loss: 2.051889. Batch_acc: 0.326369. Batch_loss: 1.899319 \n",
      "Batch: 4350. Acc: 0.289384. Loss: 2.051869. Batch_acc: 0.316463. Batch_loss: 1.962673 \n",
      "Batch: 4351. Acc: 0.289394. Loss: 2.051838. Batch_acc: 0.332958. Batch_loss: 1.922321 \n",
      "Batch: 4352. Acc: 0.289403. Loss: 2.051815. Batch_acc: 0.328994. Batch_loss: 1.945495 \n",
      "Batch: 4353. Acc: 0.289412. Loss: 2.051794. Batch_acc: 0.332743. Batch_loss: 1.958123 \n",
      "Batch: 4354. Acc: 0.289421. Loss: 2.051770. Batch_acc: 0.327972. Batch_loss: 1.949159 \n",
      "Batch: 4355. Acc: 0.289428. Loss: 2.051743. Batch_acc: 0.317130. Batch_loss: 1.932806 \n",
      "Batch: 4356. Acc: 0.289437. Loss: 2.051710. Batch_acc: 0.331364. Batch_loss: 1.904678 \n",
      "Batch: 4357. Acc: 0.289444. Loss: 2.051688. Batch_acc: 0.318493. Batch_loss: 1.956110 \n",
      "Batch: 4358. Acc: 0.289456. Loss: 2.051651. Batch_acc: 0.343423. Batch_loss: 1.890657 \n",
      "Batch: 4359. Acc: 0.289464. Loss: 2.051627. Batch_acc: 0.323782. Batch_loss: 1.945896 \n",
      "Batch: 4360. Acc: 0.289471. Loss: 2.051600. Batch_acc: 0.320158. Batch_loss: 1.935433 \n",
      "Batch: 4361. Acc: 0.289482. Loss: 2.051567. Batch_acc: 0.334068. Batch_loss: 1.912740 \n",
      "Batch: 4362. Acc: 0.289489. Loss: 2.051541. Batch_acc: 0.321937. Batch_loss: 1.938798 \n",
      "Batch: 4363. Acc: 0.289495. Loss: 2.051522. Batch_acc: 0.315020. Batch_loss: 1.971645 \n",
      "Batch: 4364. Acc: 0.289505. Loss: 2.051493. Batch_acc: 0.333911. Batch_loss: 1.923437 \n",
      "Batch: 4365. Acc: 0.289516. Loss: 2.051460. Batch_acc: 0.334839. Batch_loss: 1.907418 \n",
      "Batch: 4366. Acc: 0.289525. Loss: 2.051433. Batch_acc: 0.329855. Batch_loss: 1.935698 \n",
      "Batch: 4367. Acc: 0.289535. Loss: 2.051406. Batch_acc: 0.336075. Batch_loss: 1.930553 \n",
      "Batch: 4368. Acc: 0.289543. Loss: 2.051383. Batch_acc: 0.324592. Batch_loss: 1.949889 \n",
      "Batch: 4369. Acc: 0.289558. Loss: 2.051336. Batch_acc: 0.352514. Batch_loss: 1.850634 \n",
      "Batch: 4370. Acc: 0.289567. Loss: 2.051310. Batch_acc: 0.331042. Batch_loss: 1.939180 \n",
      "Batch: 4371. Acc: 0.289578. Loss: 2.051279. Batch_acc: 0.337971. Batch_loss: 1.912725 \n",
      "Batch: 4372. Acc: 0.289582. Loss: 2.051265. Batch_acc: 0.305889. Batch_loss: 1.989388 \n",
      "Batch: 4373. Acc: 0.289589. Loss: 2.051235. Batch_acc: 0.320819. Batch_loss: 1.921763 \n",
      "Batch: 4374. Acc: 0.289600. Loss: 2.051211. Batch_acc: 0.335274. Batch_loss: 1.942411 \n",
      "Batch: 4375. Acc: 0.289608. Loss: 2.051184. Batch_acc: 0.325308. Batch_loss: 1.930213 \n",
      "Batch: 4376. Acc: 0.289612. Loss: 2.051162. Batch_acc: 0.310866. Batch_loss: 1.956855 \n",
      "Batch: 4377. Acc: 0.289620. Loss: 2.051139. Batch_acc: 0.324246. Batch_loss: 1.949994 \n",
      "Batch: 4378. Acc: 0.289626. Loss: 2.051121. Batch_acc: 0.313225. Batch_loss: 1.970621 \n",
      "Batch: 4379. Acc: 0.289631. Loss: 2.051103. Batch_acc: 0.311636. Batch_loss: 1.971108 \n",
      "Batch: 4380. Acc: 0.289640. Loss: 2.051071. Batch_acc: 0.329513. Batch_loss: 1.912577 \n",
      "Batch: 4381. Acc: 0.289646. Loss: 2.051047. Batch_acc: 0.315940. Batch_loss: 1.946296 \n",
      "Batch: 4382. Acc: 0.289655. Loss: 2.051017. Batch_acc: 0.329683. Batch_loss: 1.916877 \n",
      "Batch: 4383. Acc: 0.289662. Loss: 2.050992. Batch_acc: 0.321155. Batch_loss: 1.938705 \n",
      "Batch: 4384. Acc: 0.289670. Loss: 2.050975. Batch_acc: 0.327454. Batch_loss: 1.978532 \n",
      "Batch: 4385. Acc: 0.289675. Loss: 2.050956. Batch_acc: 0.310523. Batch_loss: 1.965646 \n",
      "Batch: 4386. Acc: 0.289683. Loss: 2.050934. Batch_acc: 0.324293. Batch_loss: 1.953560 \n",
      "Batch: 4387. Acc: 0.289692. Loss: 2.050904. Batch_acc: 0.331218. Batch_loss: 1.919760 \n",
      "Batch: 4388. Acc: 0.289698. Loss: 2.050886. Batch_acc: 0.314319. Batch_loss: 1.969287 \n",
      "Batch: 4389. Acc: 0.289704. Loss: 2.050858. Batch_acc: 0.316905. Batch_loss: 1.928569 \n",
      "Batch: 4390. Acc: 0.289715. Loss: 2.050829. Batch_acc: 0.337001. Batch_loss: 1.924554 \n",
      "Batch: 4391. Acc: 0.289720. Loss: 2.050807. Batch_acc: 0.311666. Batch_loss: 1.951965 \n",
      "Batch: 4392. Acc: 0.289731. Loss: 2.050776. Batch_acc: 0.339348. Batch_loss: 1.915772 \n",
      "Batch: 4393. Acc: 0.289739. Loss: 2.050756. Batch_acc: 0.326756. Batch_loss: 1.958348 \n",
      "Batch: 4394. Acc: 0.289750. Loss: 2.050726. Batch_acc: 0.336957. Batch_loss: 1.922211 \n",
      "Batch: 4395. Acc: 0.289757. Loss: 2.050700. Batch_acc: 0.319444. Batch_loss: 1.935979 \n",
      "Batch: 4396. Acc: 0.289766. Loss: 2.050665. Batch_acc: 0.329757. Batch_loss: 1.900337 \n",
      "Batch: 4397. Acc: 0.289774. Loss: 2.050637. Batch_acc: 0.324541. Batch_loss: 1.924965 \n",
      "Batch: 4398. Acc: 0.289783. Loss: 2.050607. Batch_acc: 0.329085. Batch_loss: 1.916935 \n",
      "Batch: 4399. Acc: 0.289789. Loss: 2.050584. Batch_acc: 0.316279. Batch_loss: 1.948039 \n",
      "Batch: 4400. Acc: 0.289798. Loss: 2.050555. Batch_acc: 0.330435. Batch_loss: 1.924436 \n",
      "Batch: 4401. Acc: 0.289808. Loss: 2.050527. Batch_acc: 0.333525. Batch_loss: 1.927702 \n",
      "Batch: 4402. Acc: 0.289814. Loss: 2.050510. Batch_acc: 0.317627. Batch_loss: 1.975300 \n",
      "Batch: 4403. Acc: 0.289818. Loss: 2.050496. Batch_acc: 0.307824. Batch_loss: 1.986789 \n",
      "Batch: 4404. Acc: 0.289827. Loss: 2.050466. Batch_acc: 0.326099. Batch_loss: 1.920732 \n",
      "Batch: 4405. Acc: 0.289835. Loss: 2.050446. Batch_acc: 0.326401. Batch_loss: 1.963281 \n",
      "Batch: 4406. Acc: 0.289847. Loss: 2.050415. Batch_acc: 0.341408. Batch_loss: 1.915681 \n",
      "Batch: 4407. Acc: 0.289854. Loss: 2.050389. Batch_acc: 0.324198. Batch_loss: 1.933739 \n",
      "Batch: 4408. Acc: 0.289860. Loss: 2.050364. Batch_acc: 0.313827. Batch_loss: 1.939502 \n",
      "Batch: 4409. Acc: 0.289868. Loss: 2.050336. Batch_acc: 0.326923. Batch_loss: 1.929090 \n",
      "Batch: 4410. Acc: 0.289876. Loss: 2.050308. Batch_acc: 0.323733. Batch_loss: 1.925484 \n",
      "Batch: 4411. Acc: 0.289883. Loss: 2.050279. Batch_acc: 0.321185. Batch_loss: 1.925135 \n",
      "Batch: 4412. Acc: 0.289893. Loss: 2.050252. Batch_acc: 0.330286. Batch_loss: 1.932638 \n",
      "Batch: 4413. Acc: 0.289900. Loss: 2.050226. Batch_acc: 0.322470. Batch_loss: 1.935875 \n",
      "Batch: 4414. Acc: 0.289905. Loss: 2.050207. Batch_acc: 0.313084. Batch_loss: 1.967076 \n",
      "Batch: 4415. Acc: 0.289909. Loss: 2.050192. Batch_acc: 0.305572. Batch_loss: 1.980299 \n",
      "Batch: 4416. Acc: 0.289919. Loss: 2.050160. Batch_acc: 0.336571. Batch_loss: 1.911360 \n",
      "Batch: 4417. Acc: 0.289927. Loss: 2.050131. Batch_acc: 0.324294. Batch_loss: 1.924571 \n",
      "Batch: 4418. Acc: 0.289936. Loss: 2.050109. Batch_acc: 0.329107. Batch_loss: 1.954143 \n",
      "Batch: 4419. Acc: 0.289947. Loss: 2.050081. Batch_acc: 0.334989. Batch_loss: 1.930127 \n",
      "Batch: 4420. Acc: 0.289958. Loss: 2.050053. Batch_acc: 0.337521. Batch_loss: 1.925066 \n",
      "Batch: 4421. Acc: 0.289962. Loss: 2.050032. Batch_acc: 0.311047. Batch_loss: 1.957502 \n",
      "Batch: 4422. Acc: 0.289973. Loss: 2.050006. Batch_acc: 0.335804. Batch_loss: 1.936009 \n",
      "Batch: 4423. Acc: 0.289980. Loss: 2.049977. Batch_acc: 0.324465. Batch_loss: 1.923649 \n",
      "Batch: 4424. Acc: 0.289986. Loss: 2.049955. Batch_acc: 0.315155. Batch_loss: 1.950881 \n",
      "Batch: 4425. Acc: 0.289993. Loss: 2.049923. Batch_acc: 0.319260. Batch_loss: 1.906536 \n",
      "Batch: 4426. Acc: 0.289997. Loss: 2.049901. Batch_acc: 0.310463. Batch_loss: 1.956099 \n",
      "Batch: 4427. Acc: 0.290004. Loss: 2.049875. Batch_acc: 0.319396. Batch_loss: 1.931839 \n",
      "Batch: 4428. Acc: 0.290014. Loss: 2.049853. Batch_acc: 0.335458. Batch_loss: 1.951712 \n",
      "Batch: 4429. Acc: 0.290021. Loss: 2.049820. Batch_acc: 0.319053. Batch_loss: 1.904372 \n",
      "Batch: 4430. Acc: 0.290028. Loss: 2.049799. Batch_acc: 0.323149. Batch_loss: 1.958543 \n",
      "Batch: 4431. Acc: 0.290037. Loss: 2.049771. Batch_acc: 0.329577. Batch_loss: 1.926117 \n",
      "Batch: 4432. Acc: 0.290046. Loss: 2.049745. Batch_acc: 0.328332. Batch_loss: 1.935038 \n",
      "Batch: 4433. Acc: 0.290055. Loss: 2.049716. Batch_acc: 0.332555. Batch_loss: 1.920480 \n",
      "Batch: 4434. Acc: 0.290065. Loss: 2.049690. Batch_acc: 0.331054. Batch_loss: 1.931979 \n",
      "Batch: 4435. Acc: 0.290075. Loss: 2.049660. Batch_acc: 0.334271. Batch_loss: 1.919776 \n",
      "Batch: 4436. Acc: 0.290081. Loss: 2.049639. Batch_acc: 0.319260. Batch_loss: 1.955830 \n",
      "Batch: 4437. Acc: 0.290091. Loss: 2.049610. Batch_acc: 0.334495. Batch_loss: 1.923205 \n",
      "Batch: 4438. Acc: 0.290094. Loss: 2.049594. Batch_acc: 0.301005. Batch_loss: 1.975866 \n",
      "Batch: 4439. Acc: 0.290102. Loss: 2.049569. Batch_acc: 0.327469. Batch_loss: 1.937268 \n",
      "Batch: 4440. Acc: 0.290111. Loss: 2.049534. Batch_acc: 0.330152. Batch_loss: 1.898314 \n",
      "Batch: 4441. Acc: 0.290116. Loss: 2.049514. Batch_acc: 0.312244. Batch_loss: 1.962524 \n",
      "Batch: 4442. Acc: 0.290126. Loss: 2.049486. Batch_acc: 0.334914. Batch_loss: 1.918121 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4443. Acc: 0.290132. Loss: 2.049456. Batch_acc: 0.316470. Batch_loss: 1.918385 \n",
      "Batch: 4444. Acc: 0.290139. Loss: 2.049432. Batch_acc: 0.318497. Batch_loss: 1.945440 \n",
      "Batch: 4445. Acc: 0.290146. Loss: 2.049407. Batch_acc: 0.323529. Batch_loss: 1.938454 \n",
      "Batch: 4446. Acc: 0.290155. Loss: 2.049377. Batch_acc: 0.329303. Batch_loss: 1.916806 \n",
      "Batch: 4447. Acc: 0.290164. Loss: 2.049354. Batch_acc: 0.328179. Batch_loss: 1.945957 \n",
      "Batch: 4448. Acc: 0.290170. Loss: 2.049331. Batch_acc: 0.319005. Batch_loss: 1.949463 \n",
      "Batch: 4449. Acc: 0.290179. Loss: 2.049304. Batch_acc: 0.328704. Batch_loss: 1.927257 \n",
      "Batch: 4450. Acc: 0.290185. Loss: 2.049283. Batch_acc: 0.318209. Batch_loss: 1.955627 \n",
      "Batch: 4451. Acc: 0.290195. Loss: 2.049254. Batch_acc: 0.335057. Batch_loss: 1.919258 \n",
      "Batch: 4452. Acc: 0.290205. Loss: 2.049228. Batch_acc: 0.334323. Batch_loss: 1.929993 \n",
      "Batch: 4453. Acc: 0.290211. Loss: 2.049209. Batch_acc: 0.320092. Batch_loss: 1.963749 \n",
      "Batch: 4454. Acc: 0.290215. Loss: 2.049190. Batch_acc: 0.308962. Batch_loss: 1.963043 \n",
      "Batch: 4455. Acc: 0.290223. Loss: 2.049163. Batch_acc: 0.324986. Batch_loss: 1.930520 \n",
      "Batch: 4456. Acc: 0.290232. Loss: 2.049145. Batch_acc: 0.328005. Batch_loss: 1.966182 \n",
      "Batch: 4457. Acc: 0.290239. Loss: 2.049122. Batch_acc: 0.322656. Batch_loss: 1.947757 \n",
      "Batch: 4458. Acc: 0.290249. Loss: 2.049092. Batch_acc: 0.334294. Batch_loss: 1.914206 \n",
      "Batch: 4459. Acc: 0.290256. Loss: 2.049073. Batch_acc: 0.324577. Batch_loss: 1.960117 \n",
      "Batch: 4460. Acc: 0.290264. Loss: 2.049049. Batch_acc: 0.325960. Batch_loss: 1.945107 \n",
      "Batch: 4461. Acc: 0.290274. Loss: 2.049018. Batch_acc: 0.335465. Batch_loss: 1.908055 \n",
      "Batch: 4462. Acc: 0.290286. Loss: 2.048986. Batch_acc: 0.343446. Batch_loss: 1.905072 \n",
      "Batch: 4463. Acc: 0.290291. Loss: 2.048964. Batch_acc: 0.311552. Batch_loss: 1.948151 \n",
      "Batch: 4464. Acc: 0.290294. Loss: 2.048954. Batch_acc: 0.304664. Batch_loss: 2.002003 \n",
      "Batch: 4465. Acc: 0.290304. Loss: 2.048929. Batch_acc: 0.333524. Batch_loss: 1.939342 \n",
      "Batch: 4466. Acc: 0.290312. Loss: 2.048906. Batch_acc: 0.328571. Batch_loss: 1.948073 \n",
      "Batch: 4467. Acc: 0.290318. Loss: 2.048884. Batch_acc: 0.316918. Batch_loss: 1.950885 \n",
      "Batch: 4468. Acc: 0.290325. Loss: 2.048863. Batch_acc: 0.320250. Batch_loss: 1.952798 \n",
      "Batch: 4469. Acc: 0.290330. Loss: 2.048841. Batch_acc: 0.314088. Batch_loss: 1.951572 \n",
      "Batch: 4470. Acc: 0.290335. Loss: 2.048827. Batch_acc: 0.311059. Batch_loss: 1.983521 \n",
      "Batch: 4471. Acc: 0.290340. Loss: 2.048803. Batch_acc: 0.313692. Batch_loss: 1.944100 \n",
      "Batch: 4472. Acc: 0.290342. Loss: 2.048787. Batch_acc: 0.300177. Batch_loss: 1.973651 \n",
      "Batch: 4473. Acc: 0.290352. Loss: 2.048757. Batch_acc: 0.333714. Batch_loss: 1.917909 \n",
      "Batch: 4474. Acc: 0.290361. Loss: 2.048722. Batch_acc: 0.330460. Batch_loss: 1.888015 \n",
      "Batch: 4475. Acc: 0.290366. Loss: 2.048697. Batch_acc: 0.315394. Batch_loss: 1.937836 \n",
      "Batch: 4476. Acc: 0.290377. Loss: 2.048667. Batch_acc: 0.337196. Batch_loss: 1.915649 \n",
      "Batch: 4477. Acc: 0.290389. Loss: 2.048641. Batch_acc: 0.346751. Batch_loss: 1.931595 \n",
      "Batch: 4478. Acc: 0.290402. Loss: 2.048606. Batch_acc: 0.346834. Batch_loss: 1.893229 \n",
      "Batch: 4479. Acc: 0.290411. Loss: 2.048575. Batch_acc: 0.328375. Batch_loss: 1.907895 \n",
      "Batch: 4480. Acc: 0.290417. Loss: 2.048550. Batch_acc: 0.320680. Batch_loss: 1.941116 \n",
      "Batch: 4481. Acc: 0.290425. Loss: 2.048527. Batch_acc: 0.323564. Batch_loss: 1.940196 \n",
      "Batch: 4482. Acc: 0.290432. Loss: 2.048502. Batch_acc: 0.322357. Batch_loss: 1.939646 \n",
      "Batch: 4483. Acc: 0.290442. Loss: 2.048479. Batch_acc: 0.335028. Batch_loss: 1.943406 \n",
      "Batch: 4484. Acc: 0.290450. Loss: 2.048450. Batch_acc: 0.324698. Batch_loss: 1.922300 \n",
      "Batch: 4485. Acc: 0.290455. Loss: 2.048427. Batch_acc: 0.312964. Batch_loss: 1.945904 \n",
      "Batch: 4486. Acc: 0.290458. Loss: 2.048408. Batch_acc: 0.307647. Batch_loss: 1.959192 \n",
      "Batch: 4487. Acc: 0.290467. Loss: 2.048374. Batch_acc: 0.326667. Batch_loss: 1.902329 \n",
      "Batch: 4488. Acc: 0.290474. Loss: 2.048351. Batch_acc: 0.322353. Batch_loss: 1.941648 \n",
      "Batch: 4489. Acc: 0.290480. Loss: 2.048327. Batch_acc: 0.318471. Batch_loss: 1.941456 \n",
      "Batch: 4490. Acc: 0.290488. Loss: 2.048292. Batch_acc: 0.326716. Batch_loss: 1.893556 \n",
      "Batch: 4491. Acc: 0.290496. Loss: 2.048266. Batch_acc: 0.327283. Batch_loss: 1.932486 \n",
      "Batch: 4492. Acc: 0.290506. Loss: 2.048237. Batch_acc: 0.333525. Batch_loss: 1.914399 \n",
      "Batch: 4493. Acc: 0.290513. Loss: 2.048210. Batch_acc: 0.322417. Batch_loss: 1.931364 \n",
      "Batch: 4494. Acc: 0.290526. Loss: 2.048183. Batch_acc: 0.347725. Batch_loss: 1.925689 \n",
      "Batch: 4495. Acc: 0.290529. Loss: 2.048173. Batch_acc: 0.306322. Batch_loss: 2.003477 \n",
      "Batch: 4496. Acc: 0.290536. Loss: 2.048150. Batch_acc: 0.319222. Batch_loss: 1.942699 \n",
      "Batch: 4497. Acc: 0.290542. Loss: 2.048128. Batch_acc: 0.321954. Batch_loss: 1.947385 \n",
      "Batch: 4498. Acc: 0.290548. Loss: 2.048102. Batch_acc: 0.316792. Batch_loss: 1.930688 \n",
      "Batch: 4499. Acc: 0.290554. Loss: 2.048072. Batch_acc: 0.317115. Batch_loss: 1.916481 \n",
      "Batch: 4500. Acc: 0.290562. Loss: 2.048048. Batch_acc: 0.326727. Batch_loss: 1.942120 \n",
      "Batch: 4501. Acc: 0.290568. Loss: 2.048018. Batch_acc: 0.318235. Batch_loss: 1.911440 \n",
      "Batch: 4502. Acc: 0.290577. Loss: 2.047991. Batch_acc: 0.330831. Batch_loss: 1.923626 \n",
      "Batch: 4503. Acc: 0.290585. Loss: 2.047966. Batch_acc: 0.327210. Batch_loss: 1.936243 \n",
      "Batch: 4504. Acc: 0.290594. Loss: 2.047939. Batch_acc: 0.326846. Batch_loss: 1.928368 \n",
      "Batch: 4505. Acc: 0.290604. Loss: 2.047912. Batch_acc: 0.336794. Batch_loss: 1.926920 \n",
      "Batch: 4506. Acc: 0.290610. Loss: 2.047893. Batch_acc: 0.318675. Batch_loss: 1.958808 \n",
      "Batch: 4507. Acc: 0.290617. Loss: 2.047869. Batch_acc: 0.321594. Batch_loss: 1.941018 \n",
      "Batch: 4508. Acc: 0.290624. Loss: 2.047848. Batch_acc: 0.320776. Batch_loss: 1.952403 \n",
      "Batch: 4509. Acc: 0.290634. Loss: 2.047812. Batch_acc: 0.335624. Batch_loss: 1.888254 \n",
      "Batch: 4510. Acc: 0.290640. Loss: 2.047787. Batch_acc: 0.320878. Batch_loss: 1.932332 \n",
      "Batch: 4511. Acc: 0.290651. Loss: 2.047756. Batch_acc: 0.336866. Batch_loss: 1.912812 \n",
      "Batch: 4512. Acc: 0.290654. Loss: 2.047730. Batch_acc: 0.306346. Batch_loss: 1.932733 \n",
      "Batch: 4513. Acc: 0.290660. Loss: 2.047704. Batch_acc: 0.314136. Batch_loss: 1.928714 \n",
      "Batch: 4514. Acc: 0.290669. Loss: 2.047674. Batch_acc: 0.333520. Batch_loss: 1.919417 \n",
      "Batch: 4515. Acc: 0.290677. Loss: 2.047648. Batch_acc: 0.328217. Batch_loss: 1.928081 \n",
      "Batch: 4516. Acc: 0.290683. Loss: 2.047626. Batch_acc: 0.315910. Batch_loss: 1.948293 \n",
      "Batch: 4517. Acc: 0.290691. Loss: 2.047597. Batch_acc: 0.326099. Batch_loss: 1.917884 \n",
      "Batch: 4518. Acc: 0.290699. Loss: 2.047576. Batch_acc: 0.327283. Batch_loss: 1.946990 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.29069887333517486. Loss per char: 2.0475756237669547. Time: 1627206177.2293797\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 23, 26,  1, 14,  1, 25, 17, 23,\n",
      "        22, 20, 15, 20, 18, 19, 24, 26, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.290705. Loss: 2.047549. Batch_acc: 0.317919. Batch_loss: 1.927108 \n",
      "Batch: 4520. Acc: 0.290712. Loss: 2.047528. Batch_acc: 0.324727. Batch_loss: 1.952765 \n",
      "Batch: 4521. Acc: 0.290719. Loss: 2.047503. Batch_acc: 0.321205. Batch_loss: 1.937364 \n",
      "Batch: 4522. Acc: 0.290724. Loss: 2.047482. Batch_acc: 0.313974. Batch_loss: 1.951713 \n",
      "Batch: 4523. Acc: 0.290735. Loss: 2.047449. Batch_acc: 0.336555. Batch_loss: 1.899761 \n",
      "Batch: 4524. Acc: 0.290746. Loss: 2.047424. Batch_acc: 0.342939. Batch_loss: 1.933017 \n",
      "Batch: 4525. Acc: 0.290755. Loss: 2.047397. Batch_acc: 0.329171. Batch_loss: 1.927921 \n",
      "Batch: 4526. Acc: 0.290761. Loss: 2.047371. Batch_acc: 0.319885. Batch_loss: 1.926696 \n",
      "Batch: 4527. Acc: 0.290769. Loss: 2.047342. Batch_acc: 0.327242. Batch_loss: 1.917081 \n",
      "Batch: 4528. Acc: 0.290774. Loss: 2.047321. Batch_acc: 0.312069. Batch_loss: 1.954135 \n",
      "Batch: 4529. Acc: 0.290782. Loss: 2.047294. Batch_acc: 0.327850. Batch_loss: 1.921407 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4530. Acc: 0.290793. Loss: 2.047261. Batch_acc: 0.337458. Batch_loss: 1.903090 \n",
      "Batch: 4531. Acc: 0.290804. Loss: 2.047235. Batch_acc: 0.341549. Batch_loss: 1.928089 \n",
      "Batch: 4532. Acc: 0.290812. Loss: 2.047215. Batch_acc: 0.328902. Batch_loss: 1.954116 \n",
      "Batch: 4533. Acc: 0.290819. Loss: 2.047187. Batch_acc: 0.325273. Batch_loss: 1.919642 \n",
      "Batch: 4534. Acc: 0.290827. Loss: 2.047159. Batch_acc: 0.327103. Batch_loss: 1.917945 \n",
      "Batch: 4535. Acc: 0.290838. Loss: 2.047129. Batch_acc: 0.340563. Batch_loss: 1.910736 \n",
      "Batch: 4536. Acc: 0.290848. Loss: 2.047102. Batch_acc: 0.335605. Batch_loss: 1.924005 \n",
      "Batch: 4537. Acc: 0.290852. Loss: 2.047076. Batch_acc: 0.309399. Batch_loss: 1.927523 \n",
      "Batch: 4538. Acc: 0.290857. Loss: 2.047052. Batch_acc: 0.314318. Batch_loss: 1.940266 \n",
      "Batch: 4539. Acc: 0.290862. Loss: 2.047036. Batch_acc: 0.313038. Batch_loss: 1.973408 \n",
      "Batch: 4540. Acc: 0.290870. Loss: 2.047011. Batch_acc: 0.324324. Batch_loss: 1.935514 \n",
      "Batch: 4541. Acc: 0.290877. Loss: 2.046991. Batch_acc: 0.322636. Batch_loss: 1.957409 \n",
      "Batch: 4542. Acc: 0.290886. Loss: 2.046964. Batch_acc: 0.334475. Batch_loss: 1.924991 \n",
      "Batch: 4543. Acc: 0.290897. Loss: 2.046936. Batch_acc: 0.337900. Batch_loss: 1.918725 \n",
      "Batch: 4544. Acc: 0.290902. Loss: 2.046910. Batch_acc: 0.316716. Batch_loss: 1.926686 \n",
      "Batch: 4545. Acc: 0.290911. Loss: 2.046880. Batch_acc: 0.327408. Batch_loss: 1.911934 \n",
      "Batch: 4546. Acc: 0.290917. Loss: 2.046860. Batch_acc: 0.321159. Batch_loss: 1.955595 \n",
      "Batch: 4547. Acc: 0.290927. Loss: 2.046835. Batch_acc: 0.335439. Batch_loss: 1.935795 \n",
      "Batch: 4548. Acc: 0.290939. Loss: 2.046808. Batch_acc: 0.346001. Batch_loss: 1.921866 \n",
      "Batch: 4549. Acc: 0.290948. Loss: 2.046782. Batch_acc: 0.331046. Batch_loss: 1.930739 \n",
      "Batch: 4550. Acc: 0.290958. Loss: 2.046757. Batch_acc: 0.335995. Batch_loss: 1.932466 \n",
      "Batch: 4551. Acc: 0.290966. Loss: 2.046730. Batch_acc: 0.326846. Batch_loss: 1.925719 \n",
      "Batch: 4552. Acc: 0.290974. Loss: 2.046706. Batch_acc: 0.326878. Batch_loss: 1.933798 \n",
      "Batch: 4553. Acc: 0.290983. Loss: 2.046674. Batch_acc: 0.333525. Batch_loss: 1.901887 \n",
      "Batch: 4554. Acc: 0.290993. Loss: 2.046641. Batch_acc: 0.337670. Batch_loss: 1.901920 \n",
      "Batch: 4555. Acc: 0.291004. Loss: 2.046606. Batch_acc: 0.337389. Batch_loss: 1.892558 \n",
      "Batch: 4556. Acc: 0.291010. Loss: 2.046579. Batch_acc: 0.318027. Batch_loss: 1.925103 \n",
      "Batch: 4557. Acc: 0.291019. Loss: 2.046545. Batch_acc: 0.331034. Batch_loss: 1.893407 \n",
      "Batch: 4558. Acc: 0.291025. Loss: 2.046523. Batch_acc: 0.318523. Batch_loss: 1.942888 \n",
      "Batch: 4559. Acc: 0.291031. Loss: 2.046502. Batch_acc: 0.318286. Batch_loss: 1.953140 \n",
      "Batch: 4560. Acc: 0.291040. Loss: 2.046472. Batch_acc: 0.333525. Batch_loss: 1.908092 \n",
      "Batch: 4561. Acc: 0.291049. Loss: 2.046449. Batch_acc: 0.330882. Batch_loss: 1.945329 \n",
      "Batch: 4562. Acc: 0.291055. Loss: 2.046428. Batch_acc: 0.317396. Batch_loss: 1.951571 \n",
      "Batch: 4563. Acc: 0.291065. Loss: 2.046395. Batch_acc: 0.337163. Batch_loss: 1.896001 \n",
      "Batch: 4564. Acc: 0.291075. Loss: 2.046370. Batch_acc: 0.337223. Batch_loss: 1.928498 \n",
      "Batch: 4565. Acc: 0.291083. Loss: 2.046348. Batch_acc: 0.329419. Batch_loss: 1.944438 \n",
      "Batch: 4566. Acc: 0.291090. Loss: 2.046332. Batch_acc: 0.323597. Batch_loss: 1.972839 \n",
      "Batch: 4567. Acc: 0.291095. Loss: 2.046316. Batch_acc: 0.311203. Batch_loss: 1.971168 \n",
      "Batch: 4568. Acc: 0.291103. Loss: 2.046290. Batch_acc: 0.330146. Batch_loss: 1.931489 \n",
      "Batch: 4569. Acc: 0.291114. Loss: 2.046262. Batch_acc: 0.337117. Batch_loss: 1.916714 \n",
      "Batch: 4570. Acc: 0.291120. Loss: 2.046241. Batch_acc: 0.322674. Batch_loss: 1.949916 \n",
      "Batch: 4571. Acc: 0.291126. Loss: 2.046224. Batch_acc: 0.318182. Batch_loss: 1.967017 \n",
      "Batch: 4572. Acc: 0.291132. Loss: 2.046196. Batch_acc: 0.316420. Batch_loss: 1.921965 \n",
      "Batch: 4573. Acc: 0.291138. Loss: 2.046174. Batch_acc: 0.320690. Batch_loss: 1.942712 \n",
      "Batch: 4574. Acc: 0.291145. Loss: 2.046148. Batch_acc: 0.321016. Batch_loss: 1.928221 \n",
      "Batch: 4575. Acc: 0.291153. Loss: 2.046127. Batch_acc: 0.328863. Batch_loss: 1.950522 \n",
      "Batch: 4576. Acc: 0.291160. Loss: 2.046105. Batch_acc: 0.324262. Batch_loss: 1.943661 \n",
      "Batch: 4577. Acc: 0.291168. Loss: 2.046082. Batch_acc: 0.328580. Batch_loss: 1.940712 \n",
      "Batch: 4578. Acc: 0.291177. Loss: 2.046054. Batch_acc: 0.327557. Batch_loss: 1.921102 \n",
      "Batch: 4579. Acc: 0.291184. Loss: 2.046031. Batch_acc: 0.324668. Batch_loss: 1.940029 \n",
      "Batch: 4580. Acc: 0.291194. Loss: 2.045998. Batch_acc: 0.336343. Batch_loss: 1.898385 \n",
      "Batch: 4581. Acc: 0.291208. Loss: 2.045966. Batch_acc: 0.353242. Batch_loss: 1.904115 \n",
      "Batch: 4582. Acc: 0.291215. Loss: 2.045941. Batch_acc: 0.323308. Batch_loss: 1.929087 \n",
      "Batch: 4583. Acc: 0.291222. Loss: 2.045912. Batch_acc: 0.327869. Batch_loss: 1.907936 \n",
      "Batch: 4584. Acc: 0.291228. Loss: 2.045894. Batch_acc: 0.316522. Batch_loss: 1.962707 \n",
      "Batch: 4585. Acc: 0.291231. Loss: 2.045883. Batch_acc: 0.304551. Batch_loss: 1.994910 \n",
      "Batch: 4586. Acc: 0.291238. Loss: 2.045858. Batch_acc: 0.323968. Batch_loss: 1.932683 \n",
      "Batch: 4587. Acc: 0.291244. Loss: 2.045833. Batch_acc: 0.319774. Batch_loss: 1.935170 \n",
      "Batch: 4588. Acc: 0.291253. Loss: 2.045814. Batch_acc: 0.329552. Batch_loss: 1.957822 \n",
      "Batch: 4589. Acc: 0.291260. Loss: 2.045794. Batch_acc: 0.323477. Batch_loss: 1.953940 \n",
      "Batch: 4590. Acc: 0.291265. Loss: 2.045773. Batch_acc: 0.316062. Batch_loss: 1.947068 \n",
      "Batch: 4591. Acc: 0.291272. Loss: 2.045750. Batch_acc: 0.321819. Batch_loss: 1.941340 \n",
      "Batch: 4592. Acc: 0.291277. Loss: 2.045727. Batch_acc: 0.317101. Batch_loss: 1.939529 \n",
      "Batch: 4593. Acc: 0.291286. Loss: 2.045700. Batch_acc: 0.332174. Batch_loss: 1.923999 \n",
      "Batch: 4594. Acc: 0.291295. Loss: 2.045670. Batch_acc: 0.331243. Batch_loss: 1.905326 \n",
      "Batch: 4595. Acc: 0.291304. Loss: 2.045643. Batch_acc: 0.331038. Batch_loss: 1.923137 \n",
      "Batch: 4596. Acc: 0.291310. Loss: 2.045624. Batch_acc: 0.321429. Batch_loss: 1.958242 \n",
      "Batch: 4597. Acc: 0.291318. Loss: 2.045598. Batch_acc: 0.329689. Batch_loss: 1.927508 \n",
      "Batch: 4598. Acc: 0.291329. Loss: 2.045572. Batch_acc: 0.339408. Batch_loss: 1.923605 \n",
      "Batch: 4599. Acc: 0.291340. Loss: 2.045541. Batch_acc: 0.341103. Batch_loss: 1.905369 \n",
      "Batch: 4600. Acc: 0.291348. Loss: 2.045510. Batch_acc: 0.327398. Batch_loss: 1.905118 \n",
      "Batch: 4601. Acc: 0.291353. Loss: 2.045485. Batch_acc: 0.317869. Batch_loss: 1.928085 \n",
      "Batch: 4602. Acc: 0.291359. Loss: 2.045461. Batch_acc: 0.316514. Batch_loss: 1.938953 \n",
      "Batch: 4603. Acc: 0.291364. Loss: 2.045438. Batch_acc: 0.314114. Batch_loss: 1.931244 \n",
      "Batch: 4604. Acc: 0.291372. Loss: 2.045413. Batch_acc: 0.327935. Batch_loss: 1.932137 \n",
      "Batch: 4605. Acc: 0.291379. Loss: 2.045395. Batch_acc: 0.324541. Batch_loss: 1.961991 \n",
      "Batch: 4606. Acc: 0.291386. Loss: 2.045375. Batch_acc: 0.323512. Batch_loss: 1.949958 \n",
      "Batch: 4607. Acc: 0.291395. Loss: 2.045346. Batch_acc: 0.334087. Batch_loss: 1.912272 \n",
      "Batch: 4608. Acc: 0.291402. Loss: 2.045320. Batch_acc: 0.323121. Batch_loss: 1.924840 \n",
      "Batch: 4609. Acc: 0.291412. Loss: 2.045281. Batch_acc: 0.337997. Batch_loss: 1.871495 \n",
      "Batch: 4610. Acc: 0.291419. Loss: 2.045255. Batch_acc: 0.325541. Batch_loss: 1.925363 \n",
      "Batch: 4611. Acc: 0.291424. Loss: 2.045239. Batch_acc: 0.313458. Batch_loss: 1.971638 \n",
      "Batch: 4612. Acc: 0.291430. Loss: 2.045221. Batch_acc: 0.315670. Batch_loss: 1.959801 \n",
      "Batch: 4613. Acc: 0.291440. Loss: 2.045192. Batch_acc: 0.338738. Batch_loss: 1.912864 \n",
      "Batch: 4614. Acc: 0.291452. Loss: 2.045162. Batch_acc: 0.346132. Batch_loss: 1.909014 \n",
      "Batch: 4615. Acc: 0.291462. Loss: 2.045136. Batch_acc: 0.339655. Batch_loss: 1.921744 \n",
      "Batch: 4616. Acc: 0.291467. Loss: 2.045115. Batch_acc: 0.314653. Batch_loss: 1.946054 \n",
      "Batch: 4617. Acc: 0.291473. Loss: 2.045090. Batch_acc: 0.316849. Batch_loss: 1.933965 \n",
      "Batch: 4618. Acc: 0.291480. Loss: 2.045062. Batch_acc: 0.326310. Batch_loss: 1.912930 \n",
      "Batch: 4619. Acc: 0.291485. Loss: 2.045045. Batch_acc: 0.312977. Batch_loss: 1.968636 \n",
      "Batch: 4620. Acc: 0.291491. Loss: 2.045018. Batch_acc: 0.322392. Batch_loss: 1.918545 \n",
      "Batch: 4621. Acc: 0.291499. Loss: 2.044994. Batch_acc: 0.325568. Batch_loss: 1.935570 \n",
      "Batch: 4622. Acc: 0.291507. Loss: 2.044967. Batch_acc: 0.330259. Batch_loss: 1.916822 \n",
      "Batch: 4623. Acc: 0.291514. Loss: 2.044946. Batch_acc: 0.324691. Batch_loss: 1.944792 \n",
      "Batch: 4624. Acc: 0.291521. Loss: 2.044924. Batch_acc: 0.325129. Batch_loss: 1.946913 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4625. Acc: 0.291531. Loss: 2.044893. Batch_acc: 0.334865. Batch_loss: 1.899923 \n",
      "Batch: 4626. Acc: 0.291542. Loss: 2.044863. Batch_acc: 0.341270. Batch_loss: 1.909056 \n",
      "Batch: 4627. Acc: 0.291550. Loss: 2.044841. Batch_acc: 0.329040. Batch_loss: 1.938963 \n",
      "Batch: 4628. Acc: 0.291557. Loss: 2.044819. Batch_acc: 0.324653. Batch_loss: 1.941891 \n",
      "Batch: 4629. Acc: 0.291563. Loss: 2.044795. Batch_acc: 0.322132. Batch_loss: 1.935285 \n",
      "Batch: 4630. Acc: 0.291571. Loss: 2.044768. Batch_acc: 0.327344. Batch_loss: 1.922308 \n",
      "Batch: 4631. Acc: 0.291579. Loss: 2.044742. Batch_acc: 0.329645. Batch_loss: 1.924929 \n",
      "Batch: 4632. Acc: 0.291587. Loss: 2.044713. Batch_acc: 0.327200. Batch_loss: 1.906152 \n",
      "Batch: 4633. Acc: 0.291596. Loss: 2.044688. Batch_acc: 0.331789. Batch_loss: 1.932045 \n",
      "Batch: 4634. Acc: 0.291604. Loss: 2.044662. Batch_acc: 0.331225. Batch_loss: 1.921192 \n",
      "Batch: 4635. Acc: 0.291610. Loss: 2.044636. Batch_acc: 0.320235. Batch_loss: 1.920903 \n",
      "Batch: 4636. Acc: 0.291620. Loss: 2.044607. Batch_acc: 0.335668. Batch_loss: 1.908376 \n",
      "Batch: 4637. Acc: 0.291627. Loss: 2.044580. Batch_acc: 0.324248. Batch_loss: 1.922675 \n",
      "Batch: 4638. Acc: 0.291637. Loss: 2.044556. Batch_acc: 0.337587. Batch_loss: 1.932057 \n",
      "Batch: 4639. Acc: 0.291648. Loss: 2.044518. Batch_acc: 0.344728. Batch_loss: 1.866465 \n",
      "Batch: 4640. Acc: 0.291655. Loss: 2.044495. Batch_acc: 0.324972. Batch_loss: 1.943214 \n",
      "Batch: 4641. Acc: 0.291658. Loss: 2.044483. Batch_acc: 0.305422. Batch_loss: 1.983696 \n",
      "Batch: 4642. Acc: 0.291663. Loss: 2.044459. Batch_acc: 0.314706. Batch_loss: 1.930756 \n",
      "Batch: 4643. Acc: 0.291667. Loss: 2.044449. Batch_acc: 0.311203. Batch_loss: 1.996697 \n",
      "Batch: 4644. Acc: 0.291668. Loss: 2.044442. Batch_acc: 0.295547. Batch_loss: 2.011193 \n",
      "Batch: 4645. Acc: 0.291676. Loss: 2.044419. Batch_acc: 0.325880. Batch_loss: 1.941028 \n",
      "Batch: 4646. Acc: 0.291684. Loss: 2.044393. Batch_acc: 0.330853. Batch_loss: 1.925474 \n",
      "Batch: 4647. Acc: 0.291692. Loss: 2.044372. Batch_acc: 0.329727. Batch_loss: 1.947163 \n",
      "Batch: 4648. Acc: 0.291701. Loss: 2.044344. Batch_acc: 0.333906. Batch_loss: 1.915384 \n",
      "Batch: 4649. Acc: 0.291707. Loss: 2.044325. Batch_acc: 0.318976. Batch_loss: 1.954808 \n",
      "Batch: 4650. Acc: 0.291716. Loss: 2.044303. Batch_acc: 0.334111. Batch_loss: 1.941959 \n",
      "Batch: 4651. Acc: 0.291727. Loss: 2.044268. Batch_acc: 0.342045. Batch_loss: 1.882823 \n",
      "Batch: 4652. Acc: 0.291735. Loss: 2.044252. Batch_acc: 0.328605. Batch_loss: 1.966153 \n",
      "Batch: 4653. Acc: 0.291740. Loss: 2.044232. Batch_acc: 0.315945. Batch_loss: 1.950998 \n",
      "Batch: 4654. Acc: 0.291747. Loss: 2.044209. Batch_acc: 0.325608. Batch_loss: 1.932209 \n",
      "Batch: 4655. Acc: 0.291756. Loss: 2.044187. Batch_acc: 0.332761. Batch_loss: 1.946466 \n",
      "Batch: 4656. Acc: 0.291762. Loss: 2.044164. Batch_acc: 0.317114. Batch_loss: 1.938673 \n",
      "Batch: 4657. Acc: 0.291768. Loss: 2.044146. Batch_acc: 0.324468. Batch_loss: 1.956234 \n",
      "Batch: 4658. Acc: 0.291775. Loss: 2.044128. Batch_acc: 0.321658. Batch_loss: 1.960032 \n",
      "Batch: 4659. Acc: 0.291780. Loss: 2.044113. Batch_acc: 0.317612. Batch_loss: 1.971702 \n",
      "Batch: 4660. Acc: 0.291785. Loss: 2.044098. Batch_acc: 0.316448. Batch_loss: 1.973247 \n",
      "Batch: 4661. Acc: 0.291794. Loss: 2.044070. Batch_acc: 0.331278. Batch_loss: 1.914123 \n",
      "Batch: 4662. Acc: 0.291803. Loss: 2.044048. Batch_acc: 0.335429. Batch_loss: 1.942741 \n",
      "Batch: 4663. Acc: 0.291811. Loss: 2.044022. Batch_acc: 0.327125. Batch_loss: 1.921193 \n",
      "Batch: 4664. Acc: 0.291819. Loss: 2.043998. Batch_acc: 0.332550. Batch_loss: 1.932258 \n",
      "Batch: 4665. Acc: 0.291829. Loss: 2.043973. Batch_acc: 0.337722. Batch_loss: 1.924671 \n",
      "Batch: 4666. Acc: 0.291840. Loss: 2.043939. Batch_acc: 0.341216. Batch_loss: 1.891276 \n",
      "Batch: 4667. Acc: 0.291847. Loss: 2.043920. Batch_acc: 0.327928. Batch_loss: 1.951843 \n",
      "Batch: 4668. Acc: 0.291854. Loss: 2.043896. Batch_acc: 0.322654. Batch_loss: 1.929374 \n",
      "Batch: 4669. Acc: 0.291858. Loss: 2.043880. Batch_acc: 0.311772. Batch_loss: 1.967900 \n",
      "Batch: 4670. Acc: 0.291867. Loss: 2.043846. Batch_acc: 0.333904. Batch_loss: 1.890022 \n",
      "Batch: 4671. Acc: 0.291877. Loss: 2.043820. Batch_acc: 0.335640. Batch_loss: 1.922391 \n",
      "Batch: 4672. Acc: 0.291885. Loss: 2.043794. Batch_acc: 0.329584. Batch_loss: 1.921580 \n",
      "Batch: 4673. Acc: 0.291899. Loss: 2.043767. Batch_acc: 0.355415. Batch_loss: 1.918164 \n",
      "Batch: 4674. Acc: 0.291904. Loss: 2.043749. Batch_acc: 0.316338. Batch_loss: 1.957527 \n",
      "Batch: 4675. Acc: 0.291914. Loss: 2.043722. Batch_acc: 0.341435. Batch_loss: 1.919499 \n",
      "Batch: 4676. Acc: 0.291923. Loss: 2.043693. Batch_acc: 0.330695. Batch_loss: 1.908682 \n",
      "Batch: 4677. Acc: 0.291929. Loss: 2.043677. Batch_acc: 0.319452. Batch_loss: 1.970332 \n",
      "Batch: 4678. Acc: 0.291939. Loss: 2.043646. Batch_acc: 0.340973. Batch_loss: 1.904472 \n",
      "Batch: 4679. Acc: 0.291942. Loss: 2.043628. Batch_acc: 0.301425. Batch_loss: 1.957790 \n",
      "Batch: 4680. Acc: 0.291948. Loss: 2.043601. Batch_acc: 0.321858. Batch_loss: 1.926001 \n",
      "Batch: 4681. Acc: 0.291958. Loss: 2.043577. Batch_acc: 0.337149. Batch_loss: 1.928166 \n",
      "Batch: 4682. Acc: 0.291966. Loss: 2.043554. Batch_acc: 0.328324. Batch_loss: 1.936423 \n",
      "Batch: 4683. Acc: 0.291972. Loss: 2.043536. Batch_acc: 0.323407. Batch_loss: 1.955027 \n",
      "Batch: 4684. Acc: 0.291980. Loss: 2.043509. Batch_acc: 0.327252. Batch_loss: 1.919354 \n",
      "Batch: 4685. Acc: 0.291987. Loss: 2.043486. Batch_acc: 0.323826. Batch_loss: 1.941873 \n",
      "Batch: 4686. Acc: 0.291995. Loss: 2.043457. Batch_acc: 0.327722. Batch_loss: 1.908878 \n",
      "Batch: 4687. Acc: 0.291999. Loss: 2.043441. Batch_acc: 0.336018. Batch_loss: 1.892844 \n",
      "[Training]  loss: 2.043440974782927, ppl:  7.717118, accuracy: 29.200 %, elapse: 3710823.433ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.8824216448581848,  ppl:  6.56939, accuracy: 34.915 %, elapse: 37604.108ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1083.5957527160645ms\n",
      "[ Epoch: 1 / 8, Run Batch: 4688 / None]\n",
      "Batch: 0. Acc: 0.318916. Loss: 1.960437. Batch_acc: 0.318916. Batch_loss: 1.960436 \n",
      "Batch: 1. Acc: 0.323972. Loss: 1.944997. Batch_acc: 0.329070. Batch_loss: 1.929431 \n",
      "Batch: 2. Acc: 0.327600. Loss: 1.936600. Batch_acc: 0.334884. Batch_loss: 1.919738 \n",
      "Batch: 3. Acc: 0.324360. Loss: 1.940570. Batch_acc: 0.314697. Batch_loss: 1.952411 \n",
      "Batch: 4. Acc: 0.323190. Loss: 1.941620. Batch_acc: 0.318619. Batch_loss: 1.945724 \n",
      "Batch: 5. Acc: 0.324015. Loss: 1.939040. Batch_acc: 0.328143. Batch_loss: 1.926132 \n",
      "Batch: 6. Acc: 0.326901. Loss: 1.933893. Batch_acc: 0.344406. Batch_loss: 1.902669 \n",
      "Batch: 7. Acc: 0.325850. Loss: 1.937143. Batch_acc: 0.318471. Batch_loss: 1.959959 \n",
      "Batch: 8. Acc: 0.327167. Loss: 1.930906. Batch_acc: 0.337479. Batch_loss: 1.882067 \n",
      "Batch: 9. Acc: 0.326960. Loss: 1.933729. Batch_acc: 0.325101. Batch_loss: 1.959059 \n",
      "Batch: 10. Acc: 0.328062. Loss: 1.932552. Batch_acc: 0.339100. Batch_loss: 1.920771 \n",
      "Batch: 11. Acc: 0.328513. Loss: 1.931706. Batch_acc: 0.333527. Batch_loss: 1.922296 \n",
      "Batch: 12. Acc: 0.327953. Loss: 1.931073. Batch_acc: 0.321244. Batch_loss: 1.923493 \n",
      "Batch: 13. Acc: 0.327516. Loss: 1.934598. Batch_acc: 0.321662. Batch_loss: 1.981781 \n",
      "Batch: 14. Acc: 0.328218. Loss: 1.933768. Batch_acc: 0.337876. Batch_loss: 1.922332 \n",
      "Batch: 15. Acc: 0.329543. Loss: 1.931611. Batch_acc: 0.348772. Batch_loss: 1.900328 \n",
      "Batch: 16. Acc: 0.329056. Loss: 1.932629. Batch_acc: 0.321285. Batch_loss: 1.948847 \n",
      "Batch: 17. Acc: 0.328840. Loss: 1.932701. Batch_acc: 0.325074. Batch_loss: 1.933967 \n",
      "Batch: 18. Acc: 0.328310. Loss: 1.933440. Batch_acc: 0.318882. Batch_loss: 1.946598 \n",
      "Batch: 19. Acc: 0.328587. Loss: 1.932048. Batch_acc: 0.333707. Batch_loss: 1.906301 \n",
      "Batch: 20. Acc: 0.328287. Loss: 1.932022. Batch_acc: 0.322124. Batch_loss: 1.931494 \n",
      "Batch: 21. Acc: 0.327948. Loss: 1.932264. Batch_acc: 0.320809. Batch_loss: 1.937357 \n",
      "Batch: 22. Acc: 0.327956. Loss: 1.932529. Batch_acc: 0.328134. Batch_loss: 1.938368 \n",
      "Batch: 23. Acc: 0.327020. Loss: 1.933098. Batch_acc: 0.305524. Batch_loss: 1.946175 \n",
      "Batch: 24. Acc: 0.327899. Loss: 1.931908. Batch_acc: 0.348562. Batch_loss: 1.903963 \n",
      "Batch: 25. Acc: 0.328470. Loss: 1.930732. Batch_acc: 0.342726. Batch_loss: 1.901347 \n",
      "Batch: 26. Acc: 0.327985. Loss: 1.931280. Batch_acc: 0.315520. Batch_loss: 1.945351 \n",
      "Batch: 27. Acc: 0.328437. Loss: 1.930336. Batch_acc: 0.340584. Batch_loss: 1.904978 \n",
      "Batch: 28. Acc: 0.328663. Loss: 1.930332. Batch_acc: 0.334831. Batch_loss: 1.930231 \n",
      "Batch: 29. Acc: 0.328422. Loss: 1.931164. Batch_acc: 0.321172. Batch_loss: 1.956252 \n",
      "Batch: 30. Acc: 0.328963. Loss: 1.930203. Batch_acc: 0.345328. Batch_loss: 1.901149 \n",
      "Batch: 31. Acc: 0.328793. Loss: 1.930386. Batch_acc: 0.323512. Batch_loss: 1.936060 \n",
      "Batch: 32. Acc: 0.329168. Loss: 1.930046. Batch_acc: 0.341293. Batch_loss: 1.919053 \n",
      "Batch: 33. Acc: 0.329126. Loss: 1.929241. Batch_acc: 0.327796. Batch_loss: 1.903713 \n",
      "Batch: 34. Acc: 0.329105. Loss: 1.928816. Batch_acc: 0.328384. Batch_loss: 1.914462 \n",
      "Batch: 35. Acc: 0.329069. Loss: 1.928394. Batch_acc: 0.327822. Batch_loss: 1.913745 \n",
      "Batch: 36. Acc: 0.329155. Loss: 1.927992. Batch_acc: 0.332205. Batch_loss: 1.913801 \n",
      "Batch: 37. Acc: 0.329214. Loss: 1.928029. Batch_acc: 0.331405. Batch_loss: 1.929410 \n",
      "Batch: 38. Acc: 0.329126. Loss: 1.927819. Batch_acc: 0.325731. Batch_loss: 1.919715 \n",
      "Batch: 39. Acc: 0.329011. Loss: 1.928156. Batch_acc: 0.324480. Batch_loss: 1.941345 \n",
      "Batch: 40. Acc: 0.328672. Loss: 1.928743. Batch_acc: 0.315124. Batch_loss: 1.952207 \n",
      "Batch: 41. Acc: 0.328620. Loss: 1.928742. Batch_acc: 0.326434. Batch_loss: 1.928686 \n",
      "Batch: 42. Acc: 0.328330. Loss: 1.928806. Batch_acc: 0.316298. Batch_loss: 1.931493 \n",
      "Batch: 43. Acc: 0.328052. Loss: 1.929389. Batch_acc: 0.316210. Batch_loss: 1.954251 \n",
      "Batch: 44. Acc: 0.328168. Loss: 1.928940. Batch_acc: 0.333333. Batch_loss: 1.908977 \n",
      "Batch: 45. Acc: 0.327917. Loss: 1.928755. Batch_acc: 0.316882. Batch_loss: 1.920643 \n",
      "Batch: 46. Acc: 0.327872. Loss: 1.928544. Batch_acc: 0.325784. Batch_loss: 1.918727 \n",
      "Batch: 47. Acc: 0.327943. Loss: 1.927910. Batch_acc: 0.331375. Batch_loss: 1.897490 \n",
      "Batch: 48. Acc: 0.327928. Loss: 1.927563. Batch_acc: 0.327175. Batch_loss: 1.910308 \n",
      "Batch: 49. Acc: 0.328071. Loss: 1.927503. Batch_acc: 0.335063. Batch_loss: 1.924538 \n",
      "Batch: 50. Acc: 0.327862. Loss: 1.927830. Batch_acc: 0.317044. Batch_loss: 1.944750 \n",
      "Batch: 51. Acc: 0.328081. Loss: 1.927078. Batch_acc: 0.339296. Batch_loss: 1.888692 \n",
      "Batch: 52. Acc: 0.327958. Loss: 1.927450. Batch_acc: 0.321690. Batch_loss: 1.946342 \n",
      "Batch: 53. Acc: 0.328371. Loss: 1.926944. Batch_acc: 0.350028. Batch_loss: 1.900474 \n",
      "Batch: 54. Acc: 0.328625. Loss: 1.926268. Batch_acc: 0.342410. Batch_loss: 1.889512 \n",
      "Batch: 55. Acc: 0.328720. Loss: 1.926071. Batch_acc: 0.333701. Batch_loss: 1.915712 \n",
      "Batch: 56. Acc: 0.329029. Loss: 1.925417. Batch_acc: 0.346466. Batch_loss: 1.888522 \n",
      "Batch: 57. Acc: 0.328919. Loss: 1.925644. Batch_acc: 0.322799. Batch_loss: 1.938363 \n",
      "Batch: 58. Acc: 0.328996. Loss: 1.925276. Batch_acc: 0.333529. Batch_loss: 1.903424 \n",
      "Batch: 59. Acc: 0.329110. Loss: 1.925225. Batch_acc: 0.335829. Batch_loss: 1.922216 \n",
      "Batch: 60. Acc: 0.329038. Loss: 1.924774. Batch_acc: 0.324727. Batch_loss: 1.897796 \n",
      "Batch: 61. Acc: 0.329120. Loss: 1.924539. Batch_acc: 0.334097. Batch_loss: 1.910287 \n",
      "Batch: 62. Acc: 0.328897. Loss: 1.924575. Batch_acc: 0.315124. Batch_loss: 1.926767 \n",
      "Batch: 63. Acc: 0.329059. Loss: 1.924165. Batch_acc: 0.338907. Batch_loss: 1.899152 \n",
      "Batch: 64. Acc: 0.329083. Loss: 1.924025. Batch_acc: 0.330641. Batch_loss: 1.915038 \n",
      "Batch: 65. Acc: 0.329028. Loss: 1.924014. Batch_acc: 0.325488. Batch_loss: 1.923288 \n",
      "Batch: 66. Acc: 0.329088. Loss: 1.923919. Batch_acc: 0.332955. Batch_loss: 1.917785 \n",
      "Batch: 67. Acc: 0.329234. Loss: 1.923525. Batch_acc: 0.339181. Batch_loss: 1.896618 \n",
      "Batch: 68. Acc: 0.329257. Loss: 1.923361. Batch_acc: 0.330836. Batch_loss: 1.912194 \n",
      "Batch: 69. Acc: 0.329178. Loss: 1.923711. Batch_acc: 0.323716. Batch_loss: 1.947943 \n",
      "Batch: 70. Acc: 0.329125. Loss: 1.923619. Batch_acc: 0.325490. Batch_loss: 1.917376 \n",
      "Batch: 71. Acc: 0.329009. Loss: 1.923919. Batch_acc: 0.320766. Batch_loss: 1.945390 \n",
      "Batch: 72. Acc: 0.328862. Loss: 1.924241. Batch_acc: 0.317912. Batch_loss: 1.948175 \n",
      "Batch: 73. Acc: 0.328849. Loss: 1.924139. Batch_acc: 0.327888. Batch_loss: 1.916579 \n",
      "Batch: 74. Acc: 0.328718. Loss: 1.924569. Batch_acc: 0.319161. Batch_loss: 1.955907 \n",
      "Batch: 75. Acc: 0.328625. Loss: 1.925457. Batch_acc: 0.321654. Batch_loss: 1.991942 \n",
      "Batch: 76. Acc: 0.328654. Loss: 1.925234. Batch_acc: 0.330836. Batch_loss: 1.908261 \n",
      "Batch: 77. Acc: 0.328440. Loss: 1.925658. Batch_acc: 0.311921. Batch_loss: 1.958473 \n",
      "Batch: 78. Acc: 0.328509. Loss: 1.925451. Batch_acc: 0.333708. Batch_loss: 1.909683 \n",
      "Batch: 79. Acc: 0.328813. Loss: 1.925242. Batch_acc: 0.353043. Batch_loss: 1.908619 \n",
      "Batch: 80. Acc: 0.328840. Loss: 1.925568. Batch_acc: 0.331023. Batch_loss: 1.951750 \n",
      "Batch: 81. Acc: 0.328799. Loss: 1.925467. Batch_acc: 0.325447. Batch_loss: 1.917247 \n",
      "Batch: 82. Acc: 0.328763. Loss: 1.925781. Batch_acc: 0.325849. Batch_loss: 1.951585 \n",
      "Batch: 83. Acc: 0.328912. Loss: 1.925617. Batch_acc: 0.341156. Batch_loss: 1.912052 \n",
      "Batch: 84. Acc: 0.328911. Loss: 1.925978. Batch_acc: 0.328839. Batch_loss: 1.956930 \n",
      "Batch: 85. Acc: 0.329033. Loss: 1.926191. Batch_acc: 0.339557. Batch_loss: 1.944541 \n",
      "Batch: 86. Acc: 0.329055. Loss: 1.926211. Batch_acc: 0.330907. Batch_loss: 1.927835 \n",
      "Batch: 87. Acc: 0.328962. Loss: 1.926427. Batch_acc: 0.320917. Batch_loss: 1.945187 \n",
      "Batch: 88. Acc: 0.329148. Loss: 1.926029. Batch_acc: 0.345118. Batch_loss: 1.891840 \n",
      "Batch: 89. Acc: 0.329065. Loss: 1.926005. Batch_acc: 0.321774. Batch_loss: 1.923905 \n",
      "Batch: 90. Acc: 0.329149. Loss: 1.925905. Batch_acc: 0.336501. Batch_loss: 1.917106 \n",
      "Batch: 91. Acc: 0.329027. Loss: 1.926000. Batch_acc: 0.318053. Batch_loss: 1.934596 \n",
      "Batch: 92. Acc: 0.328964. Loss: 1.926197. Batch_acc: 0.323040. Batch_loss: 1.944864 \n",
      "Batch: 93. Acc: 0.329080. Loss: 1.926143. Batch_acc: 0.339919. Batch_loss: 1.921114 \n",
      "Batch: 94. Acc: 0.329078. Loss: 1.926039. Batch_acc: 0.328909. Batch_loss: 1.916185 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.329192. Loss: 1.925956. Batch_acc: 0.340011. Batch_loss: 1.918094 \n",
      "Batch: 96. Acc: 0.329143. Loss: 1.925926. Batch_acc: 0.324566. Batch_loss: 1.923120 \n",
      "Batch: 97. Acc: 0.329213. Loss: 1.925767. Batch_acc: 0.336061. Batch_loss: 1.910067 \n",
      "Batch: 98. Acc: 0.329218. Loss: 1.926192. Batch_acc: 0.329714. Batch_loss: 1.967678 \n",
      "Batch: 99. Acc: 0.329110. Loss: 1.926459. Batch_acc: 0.318365. Batch_loss: 1.952849 \n",
      "Batch: 100. Acc: 0.328951. Loss: 1.926418. Batch_acc: 0.313450. Batch_loss: 1.922403 \n",
      "Batch: 101. Acc: 0.328964. Loss: 1.926439. Batch_acc: 0.330291. Batch_loss: 1.928571 \n",
      "Batch: 102. Acc: 0.328871. Loss: 1.926716. Batch_acc: 0.319235. Batch_loss: 1.955253 \n",
      "Batch: 103. Acc: 0.328749. Loss: 1.926841. Batch_acc: 0.316095. Batch_loss: 1.939797 \n",
      "Batch: 104. Acc: 0.328802. Loss: 1.926778. Batch_acc: 0.334292. Batch_loss: 1.920236 \n",
      "Batch: 105. Acc: 0.328973. Loss: 1.926507. Batch_acc: 0.347021. Batch_loss: 1.897821 \n",
      "Batch: 106. Acc: 0.329018. Loss: 1.926565. Batch_acc: 0.333712. Batch_loss: 1.932664 \n",
      "Batch: 107. Acc: 0.328933. Loss: 1.926829. Batch_acc: 0.320222. Batch_loss: 1.954078 \n",
      "Batch: 108. Acc: 0.329039. Loss: 1.926559. Batch_acc: 0.340329. Batch_loss: 1.897821 \n",
      "Batch: 109. Acc: 0.329090. Loss: 1.926203. Batch_acc: 0.334454. Batch_loss: 1.888306 \n",
      "Batch: 110. Acc: 0.329148. Loss: 1.926071. Batch_acc: 0.335644. Batch_loss: 1.911467 \n",
      "Batch: 111. Acc: 0.329063. Loss: 1.926279. Batch_acc: 0.319751. Batch_loss: 1.949044 \n",
      "Batch: 112. Acc: 0.329076. Loss: 1.926130. Batch_acc: 0.330588. Batch_loss: 1.908992 \n",
      "Batch: 113. Acc: 0.329148. Loss: 1.925994. Batch_acc: 0.337110. Batch_loss: 1.910891 \n",
      "Batch: 114. Acc: 0.328969. Loss: 1.926311. Batch_acc: 0.308406. Batch_loss: 1.962716 \n",
      "Batch: 115. Acc: 0.328961. Loss: 1.926346. Batch_acc: 0.328000. Batch_loss: 1.930383 \n",
      "Batch: 116. Acc: 0.329140. Loss: 1.926140. Batch_acc: 0.350116. Batch_loss: 1.902125 \n",
      "Batch: 117. Acc: 0.329092. Loss: 1.926078. Batch_acc: 0.323444. Batch_loss: 1.918676 \n",
      "Batch: 118. Acc: 0.329112. Loss: 1.926060. Batch_acc: 0.331544. Batch_loss: 1.923900 \n",
      "Batch: 119. Acc: 0.329151. Loss: 1.926051. Batch_acc: 0.333718. Batch_loss: 1.924976 \n",
      "Batch: 120. Acc: 0.329077. Loss: 1.926076. Batch_acc: 0.320299. Batch_loss: 1.929047 \n",
      "Batch: 121. Acc: 0.329138. Loss: 1.925826. Batch_acc: 0.336663. Batch_loss: 1.894881 \n",
      "Batch: 122. Acc: 0.329076. Loss: 1.926161. Batch_acc: 0.321670. Batch_loss: 1.966257 \n",
      "Batch: 123. Acc: 0.329150. Loss: 1.926121. Batch_acc: 0.338390. Batch_loss: 1.921200 \n",
      "Batch: 124. Acc: 0.329210. Loss: 1.925935. Batch_acc: 0.336583. Batch_loss: 1.902910 \n",
      "Batch: 125. Acc: 0.329195. Loss: 1.925816. Batch_acc: 0.327344. Batch_loss: 1.911243 \n",
      "Batch: 126. Acc: 0.329223. Loss: 1.925707. Batch_acc: 0.332763. Batch_loss: 1.912117 \n",
      "Batch: 127. Acc: 0.329179. Loss: 1.925730. Batch_acc: 0.323512. Batch_loss: 1.928658 \n",
      "Batch: 128. Acc: 0.329081. Loss: 1.925449. Batch_acc: 0.316492. Batch_loss: 1.889137 \n",
      "Batch: 129. Acc: 0.329170. Loss: 1.925349. Batch_acc: 0.340698. Batch_loss: 1.912220 \n",
      "Batch: 130. Acc: 0.329243. Loss: 1.925270. Batch_acc: 0.338682. Batch_loss: 1.915116 \n",
      "Batch: 131. Acc: 0.329304. Loss: 1.925082. Batch_acc: 0.337349. Batch_loss: 1.900472 \n",
      "Batch: 132. Acc: 0.329300. Loss: 1.924763. Batch_acc: 0.328736. Batch_loss: 1.882585 \n",
      "Batch: 133. Acc: 0.329497. Loss: 1.924332. Batch_acc: 0.356061. Batch_loss: 1.866293 \n",
      "Batch: 134. Acc: 0.329462. Loss: 1.924432. Batch_acc: 0.324736. Batch_loss: 1.938095 \n",
      "Batch: 135. Acc: 0.329498. Loss: 1.924395. Batch_acc: 0.334289. Batch_loss: 1.919335 \n",
      "Batch: 136. Acc: 0.329484. Loss: 1.924498. Batch_acc: 0.327576. Batch_loss: 1.938533 \n",
      "Batch: 137. Acc: 0.329415. Loss: 1.924463. Batch_acc: 0.319859. Batch_loss: 1.919693 \n",
      "Batch: 138. Acc: 0.329522. Loss: 1.924257. Batch_acc: 0.344484. Batch_loss: 1.895234 \n",
      "Batch: 139. Acc: 0.329575. Loss: 1.924258. Batch_acc: 0.336988. Batch_loss: 1.924308 \n",
      "Batch: 140. Acc: 0.329586. Loss: 1.924371. Batch_acc: 0.331192. Batch_loss: 1.940482 \n",
      "Batch: 141. Acc: 0.329642. Loss: 1.924000. Batch_acc: 0.337558. Batch_loss: 1.871581 \n",
      "Batch: 142. Acc: 0.329583. Loss: 1.924193. Batch_acc: 0.321053. Batch_loss: 1.952134 \n",
      "Batch: 143. Acc: 0.329601. Loss: 1.924120. Batch_acc: 0.332174. Batch_loss: 1.913595 \n",
      "Batch: 144. Acc: 0.329512. Loss: 1.924133. Batch_acc: 0.316559. Batch_loss: 1.925952 \n",
      "Batch: 145. Acc: 0.329561. Loss: 1.923993. Batch_acc: 0.336560. Batch_loss: 1.904001 \n",
      "Batch: 146. Acc: 0.329521. Loss: 1.923863. Batch_acc: 0.323713. Batch_loss: 1.905100 \n",
      "Batch: 147. Acc: 0.329454. Loss: 1.923987. Batch_acc: 0.319606. Batch_loss: 1.942413 \n",
      "Batch: 148. Acc: 0.329501. Loss: 1.923643. Batch_acc: 0.336343. Batch_loss: 1.873671 \n",
      "Batch: 149. Acc: 0.329531. Loss: 1.923680. Batch_acc: 0.333912. Batch_loss: 1.929169 \n",
      "Batch: 150. Acc: 0.329540. Loss: 1.923669. Batch_acc: 0.330866. Batch_loss: 1.922040 \n",
      "Batch: 151. Acc: 0.329495. Loss: 1.923654. Batch_acc: 0.322875. Batch_loss: 1.921543 \n",
      "Batch: 152. Acc: 0.329463. Loss: 1.923638. Batch_acc: 0.324496. Batch_loss: 1.921116 \n",
      "Batch: 153. Acc: 0.329513. Loss: 1.923607. Batch_acc: 0.337085. Batch_loss: 1.919013 \n",
      "Batch: 154. Acc: 0.329526. Loss: 1.923536. Batch_acc: 0.331409. Batch_loss: 1.912524 \n",
      "Batch: 155. Acc: 0.329477. Loss: 1.923545. Batch_acc: 0.321976. Batch_loss: 1.924878 \n",
      "Batch: 156. Acc: 0.329499. Loss: 1.923546. Batch_acc: 0.332955. Batch_loss: 1.923757 \n",
      "Batch: 157. Acc: 0.329484. Loss: 1.923689. Batch_acc: 0.327014. Batch_loss: 1.946834 \n",
      "Batch: 158. Acc: 0.329464. Loss: 1.923661. Batch_acc: 0.326381. Batch_loss: 1.919343 \n",
      "Batch: 159. Acc: 0.329513. Loss: 1.923684. Batch_acc: 0.337449. Batch_loss: 1.927388 \n",
      "Batch: 160. Acc: 0.329487. Loss: 1.923687. Batch_acc: 0.325378. Batch_loss: 1.924105 \n",
      "Batch: 161. Acc: 0.329412. Loss: 1.923968. Batch_acc: 0.317201. Batch_loss: 1.969824 \n",
      "Batch: 162. Acc: 0.329283. Loss: 1.924259. Batch_acc: 0.308183. Batch_loss: 1.971923 \n",
      "Batch: 163. Acc: 0.329269. Loss: 1.924346. Batch_acc: 0.326878. Batch_loss: 1.938801 \n",
      "Batch: 164. Acc: 0.329269. Loss: 1.924368. Batch_acc: 0.329289. Batch_loss: 1.927983 \n",
      "Batch: 165. Acc: 0.329293. Loss: 1.924282. Batch_acc: 0.333144. Batch_loss: 1.910316 \n",
      "Batch: 166. Acc: 0.329249. Loss: 1.924372. Batch_acc: 0.321812. Batch_loss: 1.939839 \n",
      "Batch: 167. Acc: 0.329155. Loss: 1.924499. Batch_acc: 0.313535. Batch_loss: 1.945577 \n",
      "Batch: 168. Acc: 0.329162. Loss: 1.924685. Batch_acc: 0.330233. Batch_loss: 1.956119 \n",
      "Batch: 169. Acc: 0.329102. Loss: 1.924748. Batch_acc: 0.318950. Batch_loss: 1.935668 \n",
      "Batch: 170. Acc: 0.329099. Loss: 1.924613. Batch_acc: 0.328532. Batch_loss: 1.902406 \n",
      "Batch: 171. Acc: 0.329114. Loss: 1.924487. Batch_acc: 0.331653. Batch_loss: 1.903515 \n",
      "Batch: 172. Acc: 0.329145. Loss: 1.924391. Batch_acc: 0.334503. Batch_loss: 1.907668 \n",
      "Batch: 173. Acc: 0.329180. Loss: 1.924397. Batch_acc: 0.335257. Batch_loss: 1.925371 \n",
      "Batch: 174. Acc: 0.329065. Loss: 1.924681. Batch_acc: 0.309348. Batch_loss: 1.973373 \n",
      "Batch: 175. Acc: 0.329110. Loss: 1.924573. Batch_acc: 0.336914. Batch_loss: 1.906055 \n",
      "Batch: 176. Acc: 0.329114. Loss: 1.924448. Batch_acc: 0.329799. Batch_loss: 1.903024 \n",
      "Batch: 177. Acc: 0.328921. Loss: 1.924757. Batch_acc: 0.294425. Batch_loss: 1.979991 \n",
      "Batch: 178. Acc: 0.328931. Loss: 1.924678. Batch_acc: 0.330682. Batch_loss: 1.910884 \n",
      "Batch: 179. Acc: 0.328824. Loss: 1.924865. Batch_acc: 0.309565. Batch_loss: 1.958460 \n",
      "Batch: 180. Acc: 0.328833. Loss: 1.924775. Batch_acc: 0.330445. Batch_loss: 1.908516 \n",
      "Batch: 181. Acc: 0.328820. Loss: 1.924764. Batch_acc: 0.326413. Batch_loss: 1.922810 \n",
      "Batch: 182. Acc: 0.328879. Loss: 1.924543. Batch_acc: 0.339580. Batch_loss: 1.884769 \n",
      "Batch: 183. Acc: 0.328918. Loss: 1.924493. Batch_acc: 0.335738. Batch_loss: 1.915742 \n",
      "Batch: 184. Acc: 0.328895. Loss: 1.924386. Batch_acc: 0.324616. Batch_loss: 1.904951 \n",
      "Batch: 185. Acc: 0.328844. Loss: 1.924444. Batch_acc: 0.319098. Batch_loss: 1.935454 \n",
      "Batch: 186. Acc: 0.328858. Loss: 1.924478. Batch_acc: 0.331448. Batch_loss: 1.930706 \n",
      "Batch: 187. Acc: 0.328916. Loss: 1.924303. Batch_acc: 0.339817. Batch_loss: 1.891715 \n",
      "Batch: 188. Acc: 0.328975. Loss: 1.924235. Batch_acc: 0.340034. Batch_loss: 1.911467 \n",
      "Batch: 189. Acc: 0.328872. Loss: 1.924460. Batch_acc: 0.309165. Batch_loss: 1.967447 \n",
      "Batch: 190. Acc: 0.328977. Loss: 1.924347. Batch_acc: 0.349106. Batch_loss: 1.902699 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.329049. Loss: 1.924344. Batch_acc: 0.342551. Batch_loss: 1.923889 \n",
      "Batch: 192. Acc: 0.329111. Loss: 1.924271. Batch_acc: 0.340948. Batch_loss: 1.910373 \n",
      "Batch: 193. Acc: 0.329113. Loss: 1.924332. Batch_acc: 0.329506. Batch_loss: 1.935933 \n",
      "Batch: 194. Acc: 0.329121. Loss: 1.924127. Batch_acc: 0.330645. Batch_loss: 1.884324 \n",
      "Batch: 195. Acc: 0.329159. Loss: 1.924047. Batch_acc: 0.336369. Batch_loss: 1.908552 \n",
      "Batch: 196. Acc: 0.329132. Loss: 1.924114. Batch_acc: 0.323952. Batch_loss: 1.937229 \n",
      "Batch: 197. Acc: 0.329127. Loss: 1.924169. Batch_acc: 0.328045. Batch_loss: 1.935007 \n",
      "Batch: 198. Acc: 0.329127. Loss: 1.924364. Batch_acc: 0.329164. Batch_loss: 1.962434 \n",
      "Batch: 199. Acc: 0.329152. Loss: 1.924206. Batch_acc: 0.334105. Batch_loss: 1.892643 \n",
      "Batch: 200. Acc: 0.329131. Loss: 1.924295. Batch_acc: 0.324927. Batch_loss: 1.942339 \n",
      "Batch: 201. Acc: 0.329071. Loss: 1.924370. Batch_acc: 0.316975. Batch_loss: 1.939517 \n",
      "Batch: 202. Acc: 0.329151. Loss: 1.924226. Batch_acc: 0.345062. Batch_loss: 1.895559 \n",
      "Batch: 203. Acc: 0.329136. Loss: 1.924256. Batch_acc: 0.326049. Batch_loss: 1.930434 \n",
      "Batch: 204. Acc: 0.329167. Loss: 1.924104. Batch_acc: 0.335421. Batch_loss: 1.893355 \n",
      "Batch: 205. Acc: 0.329205. Loss: 1.924005. Batch_acc: 0.337176. Batch_loss: 1.903583 \n",
      "Batch: 206. Acc: 0.329162. Loss: 1.924066. Batch_acc: 0.320093. Batch_loss: 1.936864 \n",
      "Batch: 207. Acc: 0.329204. Loss: 1.923911. Batch_acc: 0.337655. Batch_loss: 1.892351 \n",
      "Batch: 208. Acc: 0.329204. Loss: 1.924005. Batch_acc: 0.329233. Batch_loss: 1.943918 \n",
      "Batch: 209. Acc: 0.329180. Loss: 1.924047. Batch_acc: 0.324262. Batch_loss: 1.932964 \n",
      "Batch: 210. Acc: 0.329214. Loss: 1.924012. Batch_acc: 0.336197. Batch_loss: 1.916644 \n",
      "Batch: 211. Acc: 0.329181. Loss: 1.923984. Batch_acc: 0.322305. Batch_loss: 1.918168 \n",
      "Batch: 212. Acc: 0.329155. Loss: 1.924062. Batch_acc: 0.323713. Batch_loss: 1.940344 \n",
      "Batch: 213. Acc: 0.329120. Loss: 1.924199. Batch_acc: 0.321429. Batch_loss: 1.954497 \n",
      "Batch: 214. Acc: 0.329170. Loss: 1.924101. Batch_acc: 0.339907. Batch_loss: 1.902786 \n",
      "Batch: 215. Acc: 0.329174. Loss: 1.924081. Batch_acc: 0.330086. Batch_loss: 1.919798 \n",
      "Batch: 216. Acc: 0.329195. Loss: 1.924107. Batch_acc: 0.333720. Batch_loss: 1.929763 \n",
      "Batch: 217. Acc: 0.329131. Loss: 1.924276. Batch_acc: 0.315053. Batch_loss: 1.961526 \n",
      "Batch: 218. Acc: 0.329139. Loss: 1.924294. Batch_acc: 0.330857. Batch_loss: 1.928310 \n",
      "Batch: 219. Acc: 0.329198. Loss: 1.924255. Batch_acc: 0.342243. Batch_loss: 1.915636 \n",
      "Batch: 220. Acc: 0.329217. Loss: 1.924175. Batch_acc: 0.333333. Batch_loss: 1.906780 \n",
      "Batch: 221. Acc: 0.329246. Loss: 1.924085. Batch_acc: 0.335624. Batch_loss: 1.904329 \n",
      "Batch: 222. Acc: 0.329269. Loss: 1.924134. Batch_acc: 0.334491. Batch_loss: 1.935160 \n",
      "Batch: 223. Acc: 0.329308. Loss: 1.924120. Batch_acc: 0.337939. Batch_loss: 1.920904 \n",
      "Batch: 224. Acc: 0.329285. Loss: 1.924159. Batch_acc: 0.324036. Batch_loss: 1.933231 \n",
      "Batch: 225. Acc: 0.329326. Loss: 1.924212. Batch_acc: 0.338488. Batch_loss: 1.936080 \n",
      "Batch: 226. Acc: 0.329430. Loss: 1.924022. Batch_acc: 0.353248. Batch_loss: 1.880738 \n",
      "Batch: 227. Acc: 0.329455. Loss: 1.923984. Batch_acc: 0.335103. Batch_loss: 1.915016 \n",
      "Batch: 228. Acc: 0.329416. Loss: 1.923985. Batch_acc: 0.320871. Batch_loss: 1.924304 \n",
      "Batch: 229. Acc: 0.329455. Loss: 1.923982. Batch_acc: 0.338578. Batch_loss: 1.923201 \n",
      "Batch: 230. Acc: 0.329464. Loss: 1.923867. Batch_acc: 0.331448. Batch_loss: 1.897901 \n",
      "Batch: 231. Acc: 0.329476. Loss: 1.923992. Batch_acc: 0.332363. Batch_loss: 1.953096 \n",
      "Batch: 232. Acc: 0.329474. Loss: 1.923999. Batch_acc: 0.328947. Batch_loss: 1.925814 \n",
      "Batch: 233. Acc: 0.329420. Loss: 1.924072. Batch_acc: 0.316411. Batch_loss: 1.941547 \n",
      "Batch: 234. Acc: 0.329443. Loss: 1.924084. Batch_acc: 0.334628. Batch_loss: 1.926586 \n",
      "Batch: 235. Acc: 0.329492. Loss: 1.924013. Batch_acc: 0.341081. Batch_loss: 1.907178 \n",
      "Batch: 236. Acc: 0.329466. Loss: 1.924253. Batch_acc: 0.323178. Batch_loss: 1.983186 \n",
      "Batch: 237. Acc: 0.329411. Loss: 1.924325. Batch_acc: 0.316600. Batch_loss: 1.941173 \n",
      "Batch: 238. Acc: 0.329430. Loss: 1.924352. Batch_acc: 0.333913. Batch_loss: 1.930912 \n",
      "Batch: 239. Acc: 0.329417. Loss: 1.924477. Batch_acc: 0.326298. Batch_loss: 1.954064 \n",
      "Batch: 240. Acc: 0.329424. Loss: 1.924499. Batch_acc: 0.331038. Batch_loss: 1.929773 \n",
      "Batch: 241. Acc: 0.329360. Loss: 1.924616. Batch_acc: 0.313468. Batch_loss: 1.953956 \n",
      "Batch: 242. Acc: 0.329360. Loss: 1.924621. Batch_acc: 0.329358. Batch_loss: 1.925696 \n",
      "Batch: 243. Acc: 0.329327. Loss: 1.924738. Batch_acc: 0.321159. Batch_loss: 1.953301 \n",
      "Batch: 244. Acc: 0.329314. Loss: 1.924781. Batch_acc: 0.326023. Batch_loss: 1.935807 \n",
      "Batch: 245. Acc: 0.329308. Loss: 1.924720. Batch_acc: 0.327906. Batch_loss: 1.910134 \n",
      "Batch: 246. Acc: 0.329327. Loss: 1.924773. Batch_acc: 0.334105. Batch_loss: 1.937793 \n",
      "Batch: 247. Acc: 0.329355. Loss: 1.924680. Batch_acc: 0.336227. Batch_loss: 1.901609 \n",
      "Batch: 248. Acc: 0.329328. Loss: 1.924698. Batch_acc: 0.322745. Batch_loss: 1.928980 \n",
      "Batch: 249. Acc: 0.329261. Loss: 1.924823. Batch_acc: 0.312890. Batch_loss: 1.955685 \n",
      "Batch: 250. Acc: 0.329312. Loss: 1.924807. Batch_acc: 0.341999. Batch_loss: 1.920720 \n",
      "Batch: 251. Acc: 0.329282. Loss: 1.924807. Batch_acc: 0.321719. Batch_loss: 1.924868 \n",
      "Checkpointing on batch: 251. Accuracy: 0.3292818764065974. Loss per char: 1.924807134400771. Time: 1627206588.1923661\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 21, 21, 17, 25, 26, 25,  1, 71,\n",
      "        83, 80, 78,  1, 23, 23, 17, 26, 25, 26, 26, 15,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.329295. Loss: 1.924674. Batch_acc: 0.332565. Batch_loss: 1.890955 \n",
      "Batch: 253. Acc: 0.329296. Loss: 1.924778. Batch_acc: 0.329473. Batch_loss: 1.951396 \n",
      "Batch: 254. Acc: 0.329248. Loss: 1.924758. Batch_acc: 0.317280. Batch_loss: 1.919639 \n",
      "Batch: 255. Acc: 0.329183. Loss: 1.924893. Batch_acc: 0.312609. Batch_loss: 1.959800 \n",
      "Batch: 256. Acc: 0.329140. Loss: 1.924930. Batch_acc: 0.318023. Batch_loss: 1.934407 \n",
      "Batch: 257. Acc: 0.329121. Loss: 1.924865. Batch_acc: 0.324182. Batch_loss: 1.907990 \n",
      "Batch: 258. Acc: 0.329093. Loss: 1.924916. Batch_acc: 0.321557. Batch_loss: 1.938479 \n",
      "Batch: 259. Acc: 0.329157. Loss: 1.924748. Batch_acc: 0.345838. Batch_loss: 1.880404 \n",
      "Batch: 260. Acc: 0.329177. Loss: 1.924594. Batch_acc: 0.334481. Batch_loss: 1.884711 \n",
      "Batch: 261. Acc: 0.329221. Loss: 1.924506. Batch_acc: 0.340883. Batch_loss: 1.901313 \n",
      "Batch: 262. Acc: 0.329229. Loss: 1.924476. Batch_acc: 0.331246. Batch_loss: 1.916832 \n",
      "Batch: 263. Acc: 0.329207. Loss: 1.924510. Batch_acc: 0.323167. Batch_loss: 1.933688 \n",
      "Batch: 264. Acc: 0.329189. Loss: 1.924570. Batch_acc: 0.324419. Batch_loss: 1.940412 \n",
      "Batch: 265. Acc: 0.329245. Loss: 1.924415. Batch_acc: 0.344167. Batch_loss: 1.883142 \n",
      "Batch: 266. Acc: 0.329320. Loss: 1.924378. Batch_acc: 0.349882. Batch_loss: 1.914245 \n",
      "Batch: 267. Acc: 0.329333. Loss: 1.924315. Batch_acc: 0.332949. Batch_loss: 1.907239 \n",
      "Batch: 268. Acc: 0.329406. Loss: 1.924205. Batch_acc: 0.348958. Batch_loss: 1.894781 \n",
      "Batch: 269. Acc: 0.329402. Loss: 1.924133. Batch_acc: 0.328426. Batch_loss: 1.904963 \n",
      "Batch: 270. Acc: 0.329415. Loss: 1.924125. Batch_acc: 0.332949. Batch_loss: 1.921912 \n",
      "Batch: 271. Acc: 0.329416. Loss: 1.924066. Batch_acc: 0.329539. Batch_loss: 1.908210 \n",
      "Batch: 272. Acc: 0.329354. Loss: 1.924096. Batch_acc: 0.312536. Batch_loss: 1.932368 \n",
      "Batch: 273. Acc: 0.329341. Loss: 1.924058. Batch_acc: 0.325836. Batch_loss: 1.913507 \n",
      "Batch: 274. Acc: 0.329338. Loss: 1.923977. Batch_acc: 0.328547. Batch_loss: 1.901901 \n",
      "Batch: 275. Acc: 0.329355. Loss: 1.923946. Batch_acc: 0.333899. Batch_loss: 1.915731 \n",
      "Batch: 276. Acc: 0.329372. Loss: 1.924039. Batch_acc: 0.334291. Batch_loss: 1.949405 \n",
      "Batch: 277. Acc: 0.329340. Loss: 1.924155. Batch_acc: 0.320163. Batch_loss: 1.956783 \n",
      "Batch: 278. Acc: 0.329357. Loss: 1.924045. Batch_acc: 0.334095. Batch_loss: 1.893608 \n",
      "Batch: 279. Acc: 0.329375. Loss: 1.924037. Batch_acc: 0.334463. Batch_loss: 1.921917 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.329392. Loss: 1.923821. Batch_acc: 0.334088. Batch_loss: 1.864170 \n",
      "Batch: 281. Acc: 0.329459. Loss: 1.923647. Batch_acc: 0.347802. Batch_loss: 1.875926 \n",
      "Batch: 282. Acc: 0.329509. Loss: 1.923570. Batch_acc: 0.343429. Batch_loss: 1.902011 \n",
      "Batch: 283. Acc: 0.329506. Loss: 1.923451. Batch_acc: 0.328704. Batch_loss: 1.889419 \n",
      "Batch: 284. Acc: 0.329526. Loss: 1.923383. Batch_acc: 0.335244. Batch_loss: 1.904131 \n",
      "Batch: 285. Acc: 0.329584. Loss: 1.923280. Batch_acc: 0.345890. Batch_loss: 1.894342 \n",
      "Batch: 286. Acc: 0.329656. Loss: 1.923138. Batch_acc: 0.349776. Batch_loss: 1.883495 \n",
      "Batch: 287. Acc: 0.329662. Loss: 1.923031. Batch_acc: 0.331419. Batch_loss: 1.892184 \n",
      "Batch: 288. Acc: 0.329756. Loss: 1.922936. Batch_acc: 0.356374. Batch_loss: 1.896230 \n",
      "Batch: 289. Acc: 0.329777. Loss: 1.922857. Batch_acc: 0.335825. Batch_loss: 1.899944 \n",
      "Batch: 290. Acc: 0.329742. Loss: 1.922821. Batch_acc: 0.319817. Batch_loss: 1.912392 \n",
      "Batch: 291. Acc: 0.329781. Loss: 1.922689. Batch_acc: 0.340935. Batch_loss: 1.884695 \n",
      "Batch: 292. Acc: 0.329863. Loss: 1.922577. Batch_acc: 0.353575. Batch_loss: 1.890284 \n",
      "Batch: 293. Acc: 0.329869. Loss: 1.922570. Batch_acc: 0.331445. Batch_loss: 1.920554 \n",
      "Batch: 294. Acc: 0.329883. Loss: 1.922500. Batch_acc: 0.333896. Batch_loss: 1.902418 \n",
      "Batch: 295. Acc: 0.329900. Loss: 1.922418. Batch_acc: 0.334878. Batch_loss: 1.898110 \n",
      "Batch: 296. Acc: 0.329936. Loss: 1.922366. Batch_acc: 0.340792. Batch_loss: 1.906824 \n",
      "Batch: 297. Acc: 0.329994. Loss: 1.922307. Batch_acc: 0.346962. Batch_loss: 1.905074 \n",
      "Batch: 298. Acc: 0.329974. Loss: 1.922387. Batch_acc: 0.323960. Batch_loss: 1.946691 \n",
      "Batch: 299. Acc: 0.330036. Loss: 1.922298. Batch_acc: 0.347948. Batch_loss: 1.896379 \n",
      "Batch: 300. Acc: 0.330021. Loss: 1.922282. Batch_acc: 0.325555. Batch_loss: 1.917442 \n",
      "Batch: 301. Acc: 0.330101. Loss: 1.922152. Batch_acc: 0.353734. Batch_loss: 1.883996 \n",
      "Batch: 302. Acc: 0.330115. Loss: 1.922091. Batch_acc: 0.334489. Batch_loss: 1.903358 \n",
      "Batch: 303. Acc: 0.330118. Loss: 1.922065. Batch_acc: 0.330870. Batch_loss: 1.914429 \n",
      "Batch: 304. Acc: 0.330129. Loss: 1.922114. Batch_acc: 0.333529. Batch_loss: 1.937226 \n",
      "Batch: 305. Acc: 0.330097. Loss: 1.922227. Batch_acc: 0.319976. Batch_loss: 1.957702 \n",
      "Batch: 306. Acc: 0.330112. Loss: 1.922328. Batch_acc: 0.334906. Batch_loss: 1.954039 \n",
      "Batch: 307. Acc: 0.330108. Loss: 1.922309. Batch_acc: 0.328940. Batch_loss: 1.916235 \n",
      "Batch: 308. Acc: 0.330207. Loss: 1.922168. Batch_acc: 0.361047. Batch_loss: 1.878254 \n",
      "Batch: 309. Acc: 0.330206. Loss: 1.922174. Batch_acc: 0.329840. Batch_loss: 1.923962 \n",
      "Batch: 310. Acc: 0.330206. Loss: 1.922181. Batch_acc: 0.330259. Batch_loss: 1.924523 \n",
      "Batch: 311. Acc: 0.330318. Loss: 1.922047. Batch_acc: 0.364619. Batch_loss: 1.880658 \n",
      "Batch: 312. Acc: 0.330221. Loss: 1.922240. Batch_acc: 0.299590. Batch_loss: 1.983742 \n",
      "Batch: 313. Acc: 0.330119. Loss: 1.922339. Batch_acc: 0.298105. Batch_loss: 1.953134 \n",
      "Batch: 314. Acc: 0.330150. Loss: 1.922305. Batch_acc: 0.339989. Batch_loss: 1.911649 \n",
      "Batch: 315. Acc: 0.330124. Loss: 1.922331. Batch_acc: 0.321744. Batch_loss: 1.930871 \n",
      "Batch: 316. Acc: 0.330189. Loss: 1.922223. Batch_acc: 0.350427. Batch_loss: 1.888344 \n",
      "Batch: 317. Acc: 0.330180. Loss: 1.922152. Batch_acc: 0.327398. Batch_loss: 1.899748 \n",
      "Batch: 318. Acc: 0.330220. Loss: 1.922092. Batch_acc: 0.342598. Batch_loss: 1.903333 \n",
      "Batch: 319. Acc: 0.330259. Loss: 1.922056. Batch_acc: 0.342990. Batch_loss: 1.910356 \n",
      "Batch: 320. Acc: 0.330299. Loss: 1.922031. Batch_acc: 0.342956. Batch_loss: 1.913938 \n",
      "Batch: 321. Acc: 0.330243. Loss: 1.922124. Batch_acc: 0.312393. Batch_loss: 1.951962 \n",
      "Batch: 322. Acc: 0.330227. Loss: 1.922210. Batch_acc: 0.325424. Batch_loss: 1.949329 \n",
      "Batch: 323. Acc: 0.330218. Loss: 1.922189. Batch_acc: 0.327168. Batch_loss: 1.915447 \n",
      "Batch: 324. Acc: 0.330188. Loss: 1.922222. Batch_acc: 0.320423. Batch_loss: 1.933106 \n",
      "Batch: 325. Acc: 0.330165. Loss: 1.922274. Batch_acc: 0.322581. Batch_loss: 1.939060 \n",
      "Batch: 326. Acc: 0.330163. Loss: 1.922227. Batch_acc: 0.329379. Batch_loss: 1.907227 \n",
      "Batch: 327. Acc: 0.330160. Loss: 1.922193. Batch_acc: 0.329275. Batch_loss: 1.910955 \n",
      "Batch: 328. Acc: 0.330156. Loss: 1.922149. Batch_acc: 0.328886. Batch_loss: 1.907720 \n",
      "Batch: 329. Acc: 0.330186. Loss: 1.922139. Batch_acc: 0.339932. Batch_loss: 1.918690 \n",
      "Batch: 330. Acc: 0.330210. Loss: 1.922148. Batch_acc: 0.337987. Batch_loss: 1.925155 \n",
      "Batch: 331. Acc: 0.330166. Loss: 1.922273. Batch_acc: 0.315421. Batch_loss: 1.964368 \n",
      "Batch: 332. Acc: 0.330224. Loss: 1.922090. Batch_acc: 0.349453. Batch_loss: 1.861422 \n",
      "Batch: 333. Acc: 0.330192. Loss: 1.922143. Batch_acc: 0.319396. Batch_loss: 1.939805 \n",
      "Batch: 334. Acc: 0.330211. Loss: 1.922183. Batch_acc: 0.336836. Batch_loss: 1.935904 \n",
      "Batch: 335. Acc: 0.330194. Loss: 1.922220. Batch_acc: 0.324586. Batch_loss: 1.934552 \n",
      "Batch: 336. Acc: 0.330194. Loss: 1.922101. Batch_acc: 0.330286. Batch_loss: 1.882418 \n",
      "Batch: 337. Acc: 0.330241. Loss: 1.921946. Batch_acc: 0.345506. Batch_loss: 1.870848 \n",
      "Batch: 338. Acc: 0.330287. Loss: 1.921937. Batch_acc: 0.345826. Batch_loss: 1.918717 \n",
      "Batch: 339. Acc: 0.330310. Loss: 1.921861. Batch_acc: 0.337823. Batch_loss: 1.896804 \n",
      "Batch: 340. Acc: 0.330285. Loss: 1.921845. Batch_acc: 0.321813. Batch_loss: 1.916568 \n",
      "Batch: 341. Acc: 0.330290. Loss: 1.921803. Batch_acc: 0.331979. Batch_loss: 1.907357 \n",
      "Batch: 342. Acc: 0.330286. Loss: 1.921749. Batch_acc: 0.329036. Batch_loss: 1.903785 \n",
      "Batch: 343. Acc: 0.330330. Loss: 1.921655. Batch_acc: 0.345320. Batch_loss: 1.889492 \n",
      "Batch: 344. Acc: 0.330332. Loss: 1.921528. Batch_acc: 0.330878. Batch_loss: 1.878544 \n",
      "Batch: 345. Acc: 0.330327. Loss: 1.921578. Batch_acc: 0.328520. Batch_loss: 1.939749 \n",
      "Batch: 346. Acc: 0.330331. Loss: 1.921573. Batch_acc: 0.331816. Batch_loss: 1.919822 \n",
      "Batch: 347. Acc: 0.330392. Loss: 1.921458. Batch_acc: 0.351184. Batch_loss: 1.882293 \n",
      "Batch: 348. Acc: 0.330393. Loss: 1.921425. Batch_acc: 0.330849. Batch_loss: 1.910069 \n",
      "Batch: 349. Acc: 0.330384. Loss: 1.921465. Batch_acc: 0.327125. Batch_loss: 1.935590 \n",
      "Batch: 350. Acc: 0.330409. Loss: 1.921521. Batch_acc: 0.339243. Batch_loss: 1.941703 \n",
      "Batch: 351. Acc: 0.330471. Loss: 1.921379. Batch_acc: 0.352266. Batch_loss: 1.871656 \n",
      "Batch: 352. Acc: 0.330467. Loss: 1.921323. Batch_acc: 0.328902. Batch_loss: 1.901441 \n",
      "Batch: 353. Acc: 0.330433. Loss: 1.921388. Batch_acc: 0.318707. Batch_loss: 1.944263 \n",
      "Batch: 354. Acc: 0.330433. Loss: 1.921408. Batch_acc: 0.330189. Batch_loss: 1.928894 \n",
      "Batch: 355. Acc: 0.330434. Loss: 1.921438. Batch_acc: 0.330861. Batch_loss: 1.931769 \n",
      "Batch: 356. Acc: 0.330449. Loss: 1.921388. Batch_acc: 0.335896. Batch_loss: 1.903344 \n",
      "Batch: 357. Acc: 0.330401. Loss: 1.921442. Batch_acc: 0.313149. Batch_loss: 1.940579 \n",
      "Batch: 358. Acc: 0.330360. Loss: 1.921434. Batch_acc: 0.315970. Batch_loss: 1.918527 \n",
      "Batch: 359. Acc: 0.330381. Loss: 1.921462. Batch_acc: 0.337677. Batch_loss: 1.931391 \n",
      "Batch: 360. Acc: 0.330365. Loss: 1.921462. Batch_acc: 0.324480. Batch_loss: 1.921362 \n",
      "Batch: 361. Acc: 0.330341. Loss: 1.921488. Batch_acc: 0.321614. Batch_loss: 1.931152 \n",
      "Batch: 362. Acc: 0.330310. Loss: 1.921621. Batch_acc: 0.319001. Batch_loss: 1.970092 \n",
      "Batch: 363. Acc: 0.330307. Loss: 1.921561. Batch_acc: 0.329289. Batch_loss: 1.899650 \n",
      "Batch: 364. Acc: 0.330276. Loss: 1.921623. Batch_acc: 0.319113. Batch_loss: 1.944206 \n",
      "Batch: 365. Acc: 0.330320. Loss: 1.921449. Batch_acc: 0.346489. Batch_loss: 1.857316 \n",
      "Batch: 366. Acc: 0.330313. Loss: 1.921451. Batch_acc: 0.327794. Batch_loss: 1.921968 \n",
      "Batch: 367. Acc: 0.330296. Loss: 1.921347. Batch_acc: 0.324415. Batch_loss: 1.884378 \n",
      "Batch: 368. Acc: 0.330256. Loss: 1.921352. Batch_acc: 0.315394. Batch_loss: 1.923135 \n",
      "Batch: 369. Acc: 0.330269. Loss: 1.921356. Batch_acc: 0.335287. Batch_loss: 1.923073 \n",
      "Batch: 370. Acc: 0.330268. Loss: 1.921399. Batch_acc: 0.329825. Batch_loss: 1.937596 \n",
      "Batch: 371. Acc: 0.330288. Loss: 1.921372. Batch_acc: 0.337791. Batch_loss: 1.910974 \n",
      "Batch: 372. Acc: 0.330300. Loss: 1.921334. Batch_acc: 0.334878. Batch_loss: 1.907086 \n",
      "Batch: 373. Acc: 0.330323. Loss: 1.921244. Batch_acc: 0.338435. Batch_loss: 1.888195 \n",
      "Batch: 374. Acc: 0.330329. Loss: 1.921133. Batch_acc: 0.332770. Batch_loss: 1.880528 \n",
      "Batch: 375. Acc: 0.330323. Loss: 1.921161. Batch_acc: 0.327935. Batch_loss: 1.931968 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.330331. Loss: 1.921144. Batch_acc: 0.333333. Batch_loss: 1.914745 \n",
      "Batch: 377. Acc: 0.330262. Loss: 1.921197. Batch_acc: 0.304670. Batch_loss: 1.940895 \n",
      "Batch: 378. Acc: 0.330236. Loss: 1.921205. Batch_acc: 0.320070. Batch_loss: 1.924149 \n",
      "Batch: 379. Acc: 0.330249. Loss: 1.921089. Batch_acc: 0.335008. Batch_loss: 1.878666 \n",
      "Batch: 380. Acc: 0.330239. Loss: 1.921060. Batch_acc: 0.326507. Batch_loss: 1.909770 \n",
      "Batch: 381. Acc: 0.330208. Loss: 1.921105. Batch_acc: 0.318076. Batch_loss: 1.938239 \n",
      "Batch: 382. Acc: 0.330227. Loss: 1.921060. Batch_acc: 0.337602. Batch_loss: 1.903753 \n",
      "Batch: 383. Acc: 0.330235. Loss: 1.921105. Batch_acc: 0.333526. Batch_loss: 1.938259 \n",
      "Batch: 384. Acc: 0.330256. Loss: 1.921056. Batch_acc: 0.338244. Batch_loss: 1.902789 \n",
      "Batch: 385. Acc: 0.330308. Loss: 1.920943. Batch_acc: 0.350172. Batch_loss: 1.877421 \n",
      "Batch: 386. Acc: 0.330315. Loss: 1.920954. Batch_acc: 0.333139. Batch_loss: 1.925307 \n",
      "Batch: 387. Acc: 0.330277. Loss: 1.920980. Batch_acc: 0.315141. Batch_loss: 1.931050 \n",
      "Batch: 388. Acc: 0.330325. Loss: 1.920847. Batch_acc: 0.348588. Batch_loss: 1.870340 \n",
      "Batch: 389. Acc: 0.330328. Loss: 1.920842. Batch_acc: 0.331594. Batch_loss: 1.918809 \n",
      "Batch: 390. Acc: 0.330275. Loss: 1.920877. Batch_acc: 0.309272. Batch_loss: 1.935015 \n",
      "Batch: 391. Acc: 0.330258. Loss: 1.920887. Batch_acc: 0.323496. Batch_loss: 1.924424 \n",
      "Batch: 392. Acc: 0.330220. Loss: 1.920927. Batch_acc: 0.315274. Batch_loss: 1.936864 \n",
      "Batch: 393. Acc: 0.330209. Loss: 1.920909. Batch_acc: 0.325895. Batch_loss: 1.913439 \n",
      "Batch: 394. Acc: 0.330200. Loss: 1.920890. Batch_acc: 0.326542. Batch_loss: 1.913596 \n",
      "Batch: 395. Acc: 0.330212. Loss: 1.920827. Batch_acc: 0.335253. Batch_loss: 1.896169 \n",
      "Batch: 396. Acc: 0.330211. Loss: 1.920831. Batch_acc: 0.329799. Batch_loss: 1.922235 \n",
      "Batch: 397. Acc: 0.330233. Loss: 1.920764. Batch_acc: 0.339003. Batch_loss: 1.893768 \n",
      "Batch: 398. Acc: 0.330203. Loss: 1.920826. Batch_acc: 0.318101. Batch_loss: 1.945940 \n",
      "Batch: 399. Acc: 0.330197. Loss: 1.920778. Batch_acc: 0.327444. Batch_loss: 1.901189 \n",
      "Batch: 400. Acc: 0.330185. Loss: 1.920788. Batch_acc: 0.325648. Batch_loss: 1.924804 \n",
      "Batch: 401. Acc: 0.330191. Loss: 1.920749. Batch_acc: 0.332564. Batch_loss: 1.905271 \n",
      "Batch: 402. Acc: 0.330187. Loss: 1.920709. Batch_acc: 0.328620. Batch_loss: 1.904840 \n",
      "Batch: 403. Acc: 0.330188. Loss: 1.920692. Batch_acc: 0.330368. Batch_loss: 1.913576 \n",
      "Batch: 404. Acc: 0.330191. Loss: 1.920675. Batch_acc: 0.331603. Batch_loss: 1.913861 \n",
      "Batch: 405. Acc: 0.330178. Loss: 1.920648. Batch_acc: 0.324751. Batch_loss: 1.909544 \n",
      "Batch: 406. Acc: 0.330170. Loss: 1.920647. Batch_acc: 0.327048. Batch_loss: 1.920125 \n",
      "Batch: 407. Acc: 0.330140. Loss: 1.920684. Batch_acc: 0.317816. Batch_loss: 1.935588 \n",
      "Batch: 408. Acc: 0.330162. Loss: 1.920633. Batch_acc: 0.339080. Batch_loss: 1.900016 \n",
      "Batch: 409. Acc: 0.330168. Loss: 1.920592. Batch_acc: 0.332762. Batch_loss: 1.903927 \n",
      "Batch: 410. Acc: 0.330231. Loss: 1.920410. Batch_acc: 0.355088. Batch_loss: 1.848848 \n",
      "Batch: 411. Acc: 0.330205. Loss: 1.920434. Batch_acc: 0.319347. Batch_loss: 1.930421 \n",
      "Batch: 412. Acc: 0.330190. Loss: 1.920493. Batch_acc: 0.323669. Batch_loss: 1.945349 \n",
      "Batch: 413. Acc: 0.330215. Loss: 1.920499. Batch_acc: 0.340609. Batch_loss: 1.922851 \n",
      "Batch: 414. Acc: 0.330234. Loss: 1.920466. Batch_acc: 0.337979. Batch_loss: 1.906721 \n",
      "Batch: 415. Acc: 0.330218. Loss: 1.920452. Batch_acc: 0.323581. Batch_loss: 1.914427 \n",
      "Batch: 416. Acc: 0.330221. Loss: 1.920398. Batch_acc: 0.331600. Batch_loss: 1.897815 \n",
      "Batch: 417. Acc: 0.330215. Loss: 1.920355. Batch_acc: 0.327526. Batch_loss: 1.902331 \n",
      "Batch: 418. Acc: 0.330205. Loss: 1.920347. Batch_acc: 0.325909. Batch_loss: 1.917147 \n",
      "Batch: 419. Acc: 0.330216. Loss: 1.920280. Batch_acc: 0.335094. Batch_loss: 1.891409 \n",
      "Batch: 420. Acc: 0.330228. Loss: 1.920199. Batch_acc: 0.335263. Batch_loss: 1.885939 \n",
      "Batch: 421. Acc: 0.330212. Loss: 1.920232. Batch_acc: 0.323613. Batch_loss: 1.934342 \n",
      "Batch: 422. Acc: 0.330205. Loss: 1.920267. Batch_acc: 0.327081. Batch_loss: 1.935063 \n",
      "Batch: 423. Acc: 0.330192. Loss: 1.920258. Batch_acc: 0.324419. Batch_loss: 1.916680 \n",
      "Batch: 424. Acc: 0.330226. Loss: 1.920197. Batch_acc: 0.345217. Batch_loss: 1.893172 \n",
      "Batch: 425. Acc: 0.330213. Loss: 1.920207. Batch_acc: 0.324586. Batch_loss: 1.924371 \n",
      "Batch: 426. Acc: 0.330236. Loss: 1.920114. Batch_acc: 0.340254. Batch_loss: 1.880702 \n",
      "Batch: 427. Acc: 0.330258. Loss: 1.920028. Batch_acc: 0.339439. Batch_loss: 1.883353 \n",
      "Batch: 428. Acc: 0.330305. Loss: 1.919928. Batch_acc: 0.350746. Batch_loss: 1.877159 \n",
      "Batch: 429. Acc: 0.330324. Loss: 1.919939. Batch_acc: 0.338596. Batch_loss: 1.924961 \n",
      "Batch: 430. Acc: 0.330329. Loss: 1.919848. Batch_acc: 0.332222. Batch_loss: 1.881915 \n",
      "Batch: 431. Acc: 0.330323. Loss: 1.919798. Batch_acc: 0.327740. Batch_loss: 1.899013 \n",
      "Batch: 432. Acc: 0.330331. Loss: 1.919775. Batch_acc: 0.334112. Batch_loss: 1.909691 \n",
      "Batch: 433. Acc: 0.330361. Loss: 1.919674. Batch_acc: 0.342778. Batch_loss: 1.877304 \n",
      "Batch: 434. Acc: 0.330389. Loss: 1.919602. Batch_acc: 0.342571. Batch_loss: 1.887551 \n",
      "Batch: 435. Acc: 0.330401. Loss: 1.919620. Batch_acc: 0.335582. Batch_loss: 1.927145 \n",
      "Batch: 436. Acc: 0.330402. Loss: 1.919620. Batch_acc: 0.330823. Batch_loss: 1.919629 \n",
      "Batch: 437. Acc: 0.330435. Loss: 1.919615. Batch_acc: 0.345349. Batch_loss: 1.917486 \n",
      "Batch: 438. Acc: 0.330477. Loss: 1.919510. Batch_acc: 0.348069. Batch_loss: 1.875085 \n",
      "Batch: 439. Acc: 0.330475. Loss: 1.919459. Batch_acc: 0.329664. Batch_loss: 1.896827 \n",
      "Batch: 440. Acc: 0.330440. Loss: 1.919519. Batch_acc: 0.314750. Batch_loss: 1.945826 \n",
      "Batch: 441. Acc: 0.330480. Loss: 1.919460. Batch_acc: 0.348485. Batch_loss: 1.893363 \n",
      "Batch: 442. Acc: 0.330476. Loss: 1.919477. Batch_acc: 0.328970. Batch_loss: 1.927028 \n",
      "Batch: 443. Acc: 0.330476. Loss: 1.919479. Batch_acc: 0.330404. Batch_loss: 1.920329 \n",
      "Batch: 444. Acc: 0.330472. Loss: 1.919433. Batch_acc: 0.328417. Batch_loss: 1.898977 \n",
      "Batch: 445. Acc: 0.330449. Loss: 1.919443. Batch_acc: 0.320299. Batch_loss: 1.924212 \n",
      "Batch: 446. Acc: 0.330447. Loss: 1.919352. Batch_acc: 0.329683. Batch_loss: 1.878713 \n",
      "Batch: 447. Acc: 0.330442. Loss: 1.919311. Batch_acc: 0.328271. Batch_loss: 1.900428 \n",
      "Batch: 448. Acc: 0.330417. Loss: 1.919310. Batch_acc: 0.319036. Batch_loss: 1.919120 \n",
      "Batch: 449. Acc: 0.330396. Loss: 1.919280. Batch_acc: 0.320744. Batch_loss: 1.905946 \n",
      "Batch: 450. Acc: 0.330382. Loss: 1.919283. Batch_acc: 0.324248. Batch_loss: 1.920800 \n",
      "Batch: 451. Acc: 0.330386. Loss: 1.919258. Batch_acc: 0.332170. Batch_loss: 1.907723 \n",
      "Batch: 452. Acc: 0.330426. Loss: 1.919174. Batch_acc: 0.348677. Batch_loss: 1.880979 \n",
      "Batch: 453. Acc: 0.330417. Loss: 1.919162. Batch_acc: 0.326588. Batch_loss: 1.913844 \n",
      "Batch: 454. Acc: 0.330425. Loss: 1.919131. Batch_acc: 0.333920. Batch_loss: 1.905170 \n",
      "Batch: 455. Acc: 0.330409. Loss: 1.919115. Batch_acc: 0.323042. Batch_loss: 1.911529 \n",
      "Batch: 456. Acc: 0.330396. Loss: 1.919090. Batch_acc: 0.324683. Batch_loss: 1.907731 \n",
      "Batch: 457. Acc: 0.330378. Loss: 1.919131. Batch_acc: 0.322005. Batch_loss: 1.937774 \n",
      "Batch: 458. Acc: 0.330355. Loss: 1.919209. Batch_acc: 0.319931. Batch_loss: 1.954953 \n",
      "Batch: 459. Acc: 0.330341. Loss: 1.919286. Batch_acc: 0.323936. Batch_loss: 1.954638 \n",
      "Batch: 460. Acc: 0.330363. Loss: 1.919194. Batch_acc: 0.340401. Batch_loss: 1.876990 \n",
      "Batch: 461. Acc: 0.330358. Loss: 1.919216. Batch_acc: 0.327840. Batch_loss: 1.929770 \n",
      "Batch: 462. Acc: 0.330362. Loss: 1.919154. Batch_acc: 0.332567. Batch_loss: 1.890448 \n",
      "Batch: 463. Acc: 0.330410. Loss: 1.919131. Batch_acc: 0.352668. Batch_loss: 1.908692 \n",
      "Batch: 464. Acc: 0.330392. Loss: 1.919104. Batch_acc: 0.322296. Batch_loss: 1.907127 \n",
      "Batch: 465. Acc: 0.330406. Loss: 1.919085. Batch_acc: 0.337176. Batch_loss: 1.910010 \n",
      "Batch: 466. Acc: 0.330415. Loss: 1.919108. Batch_acc: 0.334314. Batch_loss: 1.930038 \n",
      "Batch: 467. Acc: 0.330427. Loss: 1.919085. Batch_acc: 0.336438. Batch_loss: 1.908406 \n",
      "Batch: 468. Acc: 0.330425. Loss: 1.919111. Batch_acc: 0.329460. Batch_loss: 1.931117 \n",
      "Batch: 469. Acc: 0.330415. Loss: 1.919116. Batch_acc: 0.325701. Batch_loss: 1.921642 \n",
      "Batch: 470. Acc: 0.330435. Loss: 1.919077. Batch_acc: 0.339828. Batch_loss: 1.900824 \n",
      "Batch: 471. Acc: 0.330439. Loss: 1.919074. Batch_acc: 0.332375. Batch_loss: 1.917712 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.330473. Loss: 1.918967. Batch_acc: 0.346044. Batch_loss: 1.868917 \n",
      "Batch: 473. Acc: 0.330471. Loss: 1.918961. Batch_acc: 0.329903. Batch_loss: 1.916134 \n",
      "Batch: 474. Acc: 0.330478. Loss: 1.918915. Batch_acc: 0.333526. Batch_loss: 1.897261 \n",
      "Batch: 475. Acc: 0.330502. Loss: 1.918841. Batch_acc: 0.341890. Batch_loss: 1.882858 \n",
      "Batch: 476. Acc: 0.330527. Loss: 1.918817. Batch_acc: 0.342775. Batch_loss: 1.907610 \n",
      "Batch: 477. Acc: 0.330544. Loss: 1.918743. Batch_acc: 0.338863. Batch_loss: 1.882477 \n",
      "Batch: 478. Acc: 0.330531. Loss: 1.918788. Batch_acc: 0.324403. Batch_loss: 1.940489 \n",
      "Batch: 479. Acc: 0.330551. Loss: 1.918768. Batch_acc: 0.339966. Batch_loss: 1.909103 \n",
      "Batch: 480. Acc: 0.330558. Loss: 1.918739. Batch_acc: 0.333524. Batch_loss: 1.905122 \n",
      "Batch: 481. Acc: 0.330572. Loss: 1.918675. Batch_acc: 0.337558. Batch_loss: 1.887782 \n",
      "Batch: 482. Acc: 0.330606. Loss: 1.918568. Batch_acc: 0.346452. Batch_loss: 1.868975 \n",
      "Batch: 483. Acc: 0.330610. Loss: 1.918527. Batch_acc: 0.332375. Batch_loss: 1.898503 \n",
      "Batch: 484. Acc: 0.330625. Loss: 1.918504. Batch_acc: 0.338117. Batch_loss: 1.907221 \n",
      "Batch: 485. Acc: 0.330654. Loss: 1.918485. Batch_acc: 0.344646. Batch_loss: 1.909254 \n",
      "Batch: 486. Acc: 0.330664. Loss: 1.918463. Batch_acc: 0.335869. Batch_loss: 1.907715 \n",
      "Batch: 487. Acc: 0.330668. Loss: 1.918399. Batch_acc: 0.332562. Batch_loss: 1.887032 \n",
      "Batch: 488. Acc: 0.330693. Loss: 1.918340. Batch_acc: 0.343240. Batch_loss: 1.889394 \n",
      "Batch: 489. Acc: 0.330709. Loss: 1.918299. Batch_acc: 0.338084. Batch_loss: 1.898115 \n",
      "Batch: 490. Acc: 0.330717. Loss: 1.918231. Batch_acc: 0.334876. Batch_loss: 1.884700 \n",
      "Batch: 491. Acc: 0.330725. Loss: 1.918223. Batch_acc: 0.334699. Batch_loss: 1.914307 \n",
      "Batch: 492. Acc: 0.330716. Loss: 1.918221. Batch_acc: 0.326173. Batch_loss: 1.917390 \n",
      "Batch: 493. Acc: 0.330731. Loss: 1.918176. Batch_acc: 0.338297. Batch_loss: 1.895214 \n",
      "Batch: 494. Acc: 0.330730. Loss: 1.918192. Batch_acc: 0.330435. Batch_loss: 1.925888 \n",
      "Batch: 495. Acc: 0.330715. Loss: 1.918218. Batch_acc: 0.323495. Batch_loss: 1.931525 \n",
      "Batch: 496. Acc: 0.330733. Loss: 1.918139. Batch_acc: 0.339397. Batch_loss: 1.879165 \n",
      "Batch: 497. Acc: 0.330748. Loss: 1.918110. Batch_acc: 0.337939. Batch_loss: 1.903885 \n",
      "Batch: 498. Acc: 0.330740. Loss: 1.918128. Batch_acc: 0.326812. Batch_loss: 1.926899 \n",
      "Batch: 499. Acc: 0.330763. Loss: 1.918090. Batch_acc: 0.341986. Batch_loss: 1.899566 \n",
      "Batch: 500. Acc: 0.330790. Loss: 1.918038. Batch_acc: 0.344807. Batch_loss: 1.891270 \n",
      "Batch: 501. Acc: 0.330820. Loss: 1.918023. Batch_acc: 0.346087. Batch_loss: 1.910374 \n",
      "Batch: 502. Acc: 0.330803. Loss: 1.918033. Batch_acc: 0.322357. Batch_loss: 1.923343 \n",
      "Checkpointing on batch: 502. Accuracy: 0.33080330787290224. Loss per char: 1.918033462477697. Time: 1627206791.9088364\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 20, 17, 22, 26, 26, 15, 19, 26,\n",
      "        26, 17, 19, 17, 18,  1, 77, 70, 84, 84,  1, 85, 73, 66, 79,  1, 25, 32,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.330798. Loss: 1.917997. Batch_acc: 0.328099. Batch_loss: 1.899951 \n",
      "Batch: 504. Acc: 0.330807. Loss: 1.917931. Batch_acc: 0.335644. Batch_loss: 1.884556 \n",
      "Batch: 505. Acc: 0.330811. Loss: 1.917862. Batch_acc: 0.332755. Batch_loss: 1.882775 \n",
      "Batch: 506. Acc: 0.330805. Loss: 1.917836. Batch_acc: 0.327755. Batch_loss: 1.904611 \n",
      "Batch: 507. Acc: 0.330800. Loss: 1.917814. Batch_acc: 0.327972. Batch_loss: 1.907062 \n",
      "Batch: 508. Acc: 0.330824. Loss: 1.917742. Batch_acc: 0.343020. Batch_loss: 1.881273 \n",
      "Batch: 509. Acc: 0.330830. Loss: 1.917719. Batch_acc: 0.333908. Batch_loss: 1.906229 \n",
      "Batch: 510. Acc: 0.330838. Loss: 1.917720. Batch_acc: 0.335280. Batch_loss: 1.918058 \n",
      "Batch: 511. Acc: 0.330838. Loss: 1.917717. Batch_acc: 0.330831. Batch_loss: 1.916218 \n",
      "Batch: 512. Acc: 0.330832. Loss: 1.917716. Batch_acc: 0.327794. Batch_loss: 1.917384 \n",
      "Batch: 513. Acc: 0.330834. Loss: 1.917709. Batch_acc: 0.331597. Batch_loss: 1.913968 \n",
      "Batch: 514. Acc: 0.330898. Loss: 1.917645. Batch_acc: 0.363021. Batch_loss: 1.885298 \n",
      "Batch: 515. Acc: 0.330942. Loss: 1.917544. Batch_acc: 0.353311. Batch_loss: 1.865894 \n",
      "Batch: 516. Acc: 0.330950. Loss: 1.917555. Batch_acc: 0.335294. Batch_loss: 1.923620 \n",
      "Batch: 517. Acc: 0.330963. Loss: 1.917518. Batch_acc: 0.337822. Batch_loss: 1.897944 \n",
      "Batch: 518. Acc: 0.330970. Loss: 1.917458. Batch_acc: 0.334855. Batch_loss: 1.886521 \n",
      "Batch: 519. Acc: 0.331009. Loss: 1.917351. Batch_acc: 0.350423. Batch_loss: 1.863214 \n",
      "Batch: 520. Acc: 0.331042. Loss: 1.917278. Batch_acc: 0.348476. Batch_loss: 1.879193 \n",
      "Batch: 521. Acc: 0.331061. Loss: 1.917236. Batch_acc: 0.340974. Batch_loss: 1.895683 \n",
      "Batch: 522. Acc: 0.331066. Loss: 1.917257. Batch_acc: 0.333714. Batch_loss: 1.927817 \n",
      "Batch: 523. Acc: 0.331028. Loss: 1.917345. Batch_acc: 0.310787. Batch_loss: 1.964202 \n",
      "Batch: 524. Acc: 0.331048. Loss: 1.917312. Batch_acc: 0.341662. Batch_loss: 1.899798 \n",
      "Batch: 525. Acc: 0.331064. Loss: 1.917275. Batch_acc: 0.338993. Batch_loss: 1.898224 \n",
      "Batch: 526. Acc: 0.331086. Loss: 1.917200. Batch_acc: 0.342473. Batch_loss: 1.878885 \n",
      "Batch: 527. Acc: 0.331101. Loss: 1.917144. Batch_acc: 0.339225. Batch_loss: 1.887856 \n",
      "Batch: 528. Acc: 0.331093. Loss: 1.917192. Batch_acc: 0.326460. Batch_loss: 1.942472 \n",
      "Batch: 529. Acc: 0.331098. Loss: 1.917140. Batch_acc: 0.333714. Batch_loss: 1.889821 \n",
      "Batch: 530. Acc: 0.331090. Loss: 1.917097. Batch_acc: 0.327011. Batch_loss: 1.894019 \n",
      "Batch: 531. Acc: 0.331084. Loss: 1.917139. Batch_acc: 0.328107. Batch_loss: 1.940011 \n",
      "Batch: 532. Acc: 0.331111. Loss: 1.917061. Batch_acc: 0.345361. Batch_loss: 1.875623 \n",
      "Batch: 533. Acc: 0.331091. Loss: 1.917085. Batch_acc: 0.319764. Batch_loss: 1.929927 \n",
      "Batch: 534. Acc: 0.331099. Loss: 1.917051. Batch_acc: 0.335656. Batch_loss: 1.898858 \n",
      "Batch: 535. Acc: 0.331090. Loss: 1.917058. Batch_acc: 0.326340. Batch_loss: 1.920788 \n",
      "Batch: 536. Acc: 0.331118. Loss: 1.916999. Batch_acc: 0.345915. Batch_loss: 1.886003 \n",
      "Batch: 537. Acc: 0.331131. Loss: 1.916998. Batch_acc: 0.337822. Batch_loss: 1.916456 \n",
      "Batch: 538. Acc: 0.331145. Loss: 1.916990. Batch_acc: 0.338886. Batch_loss: 1.912680 \n",
      "Batch: 539. Acc: 0.331183. Loss: 1.916920. Batch_acc: 0.351094. Batch_loss: 1.880313 \n",
      "Batch: 540. Acc: 0.331207. Loss: 1.916897. Batch_acc: 0.344320. Batch_loss: 1.904202 \n",
      "Batch: 541. Acc: 0.331197. Loss: 1.916930. Batch_acc: 0.325951. Batch_loss: 1.934616 \n",
      "Batch: 542. Acc: 0.331178. Loss: 1.916893. Batch_acc: 0.320896. Batch_loss: 1.896942 \n",
      "Batch: 543. Acc: 0.331205. Loss: 1.916840. Batch_acc: 0.345526. Batch_loss: 1.888394 \n",
      "Batch: 544. Acc: 0.331212. Loss: 1.916809. Batch_acc: 0.335270. Batch_loss: 1.900064 \n",
      "Batch: 545. Acc: 0.331218. Loss: 1.916807. Batch_acc: 0.334296. Batch_loss: 1.915729 \n",
      "Batch: 546. Acc: 0.331239. Loss: 1.916698. Batch_acc: 0.342824. Batch_loss: 1.856602 \n",
      "Batch: 547. Acc: 0.331249. Loss: 1.916629. Batch_acc: 0.336806. Batch_loss: 1.878477 \n",
      "Batch: 548. Acc: 0.331267. Loss: 1.916587. Batch_acc: 0.341297. Batch_loss: 1.893746 \n",
      "Batch: 549. Acc: 0.331268. Loss: 1.916536. Batch_acc: 0.331672. Batch_loss: 1.889857 \n",
      "Batch: 550. Acc: 0.331267. Loss: 1.916496. Batch_acc: 0.330508. Batch_loss: 1.894925 \n",
      "Batch: 551. Acc: 0.331283. Loss: 1.916487. Batch_acc: 0.340136. Batch_loss: 1.911365 \n",
      "Batch: 552. Acc: 0.331242. Loss: 1.916491. Batch_acc: 0.308542. Batch_loss: 1.918858 \n",
      "Batch: 553. Acc: 0.331210. Loss: 1.916543. Batch_acc: 0.313501. Batch_loss: 1.945381 \n",
      "Batch: 554. Acc: 0.331217. Loss: 1.916510. Batch_acc: 0.334849. Batch_loss: 1.898010 \n",
      "Batch: 555. Acc: 0.331229. Loss: 1.916496. Batch_acc: 0.338101. Batch_loss: 1.908841 \n",
      "Batch: 556. Acc: 0.331230. Loss: 1.916469. Batch_acc: 0.331792. Batch_loss: 1.901320 \n",
      "Batch: 557. Acc: 0.331206. Loss: 1.916508. Batch_acc: 0.317291. Batch_loss: 1.939323 \n",
      "Batch: 558. Acc: 0.331237. Loss: 1.916445. Batch_acc: 0.348624. Batch_loss: 1.881220 \n",
      "Batch: 559. Acc: 0.331242. Loss: 1.916459. Batch_acc: 0.333911. Batch_loss: 1.924078 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 560. Acc: 0.331256. Loss: 1.916408. Batch_acc: 0.338945. Batch_loss: 1.888581 \n",
      "Batch: 561. Acc: 0.331288. Loss: 1.916309. Batch_acc: 0.348970. Batch_loss: 1.861214 \n",
      "Batch: 562. Acc: 0.331302. Loss: 1.916271. Batch_acc: 0.339589. Batch_loss: 1.894463 \n",
      "Batch: 563. Acc: 0.331324. Loss: 1.916236. Batch_acc: 0.343551. Batch_loss: 1.896715 \n",
      "Batch: 564. Acc: 0.331361. Loss: 1.916191. Batch_acc: 0.351790. Batch_loss: 1.891244 \n",
      "Batch: 565. Acc: 0.331385. Loss: 1.916164. Batch_acc: 0.344906. Batch_loss: 1.901142 \n",
      "Batch: 566. Acc: 0.331396. Loss: 1.916133. Batch_acc: 0.337536. Batch_loss: 1.898801 \n",
      "Batch: 567. Acc: 0.331416. Loss: 1.916123. Batch_acc: 0.342301. Batch_loss: 1.910628 \n",
      "Batch: 568. Acc: 0.331450. Loss: 1.916026. Batch_acc: 0.350917. Batch_loss: 1.861116 \n",
      "Batch: 569. Acc: 0.331467. Loss: 1.915975. Batch_acc: 0.341011. Batch_loss: 1.887254 \n",
      "Batch: 570. Acc: 0.331520. Loss: 1.915928. Batch_acc: 0.361446. Batch_loss: 1.889129 \n",
      "Batch: 571. Acc: 0.331530. Loss: 1.915915. Batch_acc: 0.337463. Batch_loss: 1.908377 \n",
      "Batch: 572. Acc: 0.331549. Loss: 1.915930. Batch_acc: 0.342587. Batch_loss: 1.924965 \n",
      "Batch: 573. Acc: 0.331572. Loss: 1.915881. Batch_acc: 0.344614. Batch_loss: 1.888049 \n",
      "Batch: 574. Acc: 0.331573. Loss: 1.915856. Batch_acc: 0.332381. Batch_loss: 1.902169 \n",
      "Batch: 575. Acc: 0.331591. Loss: 1.915848. Batch_acc: 0.341533. Batch_loss: 1.911215 \n",
      "Batch: 576. Acc: 0.331571. Loss: 1.915867. Batch_acc: 0.320138. Batch_loss: 1.926415 \n",
      "Batch: 577. Acc: 0.331558. Loss: 1.915837. Batch_acc: 0.324042. Batch_loss: 1.898704 \n",
      "Batch: 578. Acc: 0.331575. Loss: 1.915785. Batch_acc: 0.341393. Batch_loss: 1.885478 \n",
      "Batch: 579. Acc: 0.331623. Loss: 1.915707. Batch_acc: 0.359251. Batch_loss: 1.871452 \n",
      "Batch: 580. Acc: 0.331641. Loss: 1.915645. Batch_acc: 0.342321. Batch_loss: 1.878818 \n",
      "Batch: 581. Acc: 0.331660. Loss: 1.915680. Batch_acc: 0.342332. Batch_loss: 1.935916 \n",
      "Batch: 582. Acc: 0.331645. Loss: 1.915672. Batch_acc: 0.322748. Batch_loss: 1.910862 \n",
      "Batch: 583. Acc: 0.331643. Loss: 1.915637. Batch_acc: 0.330645. Batch_loss: 1.895599 \n",
      "Batch: 584. Acc: 0.331633. Loss: 1.915609. Batch_acc: 0.325581. Batch_loss: 1.898808 \n",
      "Batch: 585. Acc: 0.331630. Loss: 1.915533. Batch_acc: 0.330238. Batch_loss: 1.870556 \n",
      "Batch: 586. Acc: 0.331630. Loss: 1.915550. Batch_acc: 0.331243. Batch_loss: 1.925298 \n",
      "Batch: 587. Acc: 0.331642. Loss: 1.915479. Batch_acc: 0.338973. Batch_loss: 1.873377 \n",
      "Batch: 588. Acc: 0.331685. Loss: 1.915352. Batch_acc: 0.356374. Batch_loss: 1.841893 \n",
      "Batch: 589. Acc: 0.331687. Loss: 1.915301. Batch_acc: 0.332963. Batch_loss: 1.886208 \n",
      "Batch: 590. Acc: 0.331701. Loss: 1.915263. Batch_acc: 0.340000. Batch_loss: 1.893213 \n",
      "Batch: 591. Acc: 0.331724. Loss: 1.915247. Batch_acc: 0.345433. Batch_loss: 1.905432 \n",
      "Batch: 592. Acc: 0.331689. Loss: 1.915325. Batch_acc: 0.310611. Batch_loss: 1.962721 \n",
      "Batch: 593. Acc: 0.331688. Loss: 1.915329. Batch_acc: 0.331034. Batch_loss: 1.918206 \n",
      "Batch: 594. Acc: 0.331698. Loss: 1.915261. Batch_acc: 0.337437. Batch_loss: 1.875601 \n",
      "Batch: 595. Acc: 0.331730. Loss: 1.915199. Batch_acc: 0.350427. Batch_loss: 1.878583 \n",
      "Batch: 596. Acc: 0.331739. Loss: 1.915190. Batch_acc: 0.337398. Batch_loss: 1.910212 \n",
      "Batch: 597. Acc: 0.331749. Loss: 1.915128. Batch_acc: 0.337955. Batch_loss: 1.877643 \n",
      "Batch: 598. Acc: 0.331736. Loss: 1.915152. Batch_acc: 0.323461. Batch_loss: 1.929502 \n",
      "Batch: 599. Acc: 0.331734. Loss: 1.915104. Batch_acc: 0.330475. Batch_loss: 1.886826 \n",
      "Batch: 600. Acc: 0.331704. Loss: 1.915123. Batch_acc: 0.314088. Batch_loss: 1.926788 \n",
      "Batch: 601. Acc: 0.331692. Loss: 1.915145. Batch_acc: 0.324217. Batch_loss: 1.928005 \n",
      "Batch: 602. Acc: 0.331714. Loss: 1.915050. Batch_acc: 0.344907. Batch_loss: 1.857219 \n",
      "Batch: 603. Acc: 0.331718. Loss: 1.914990. Batch_acc: 0.334284. Batch_loss: 1.879631 \n",
      "Batch: 604. Acc: 0.331746. Loss: 1.914940. Batch_acc: 0.349040. Batch_loss: 1.884392 \n",
      "Batch: 605. Acc: 0.331777. Loss: 1.914915. Batch_acc: 0.350846. Batch_loss: 1.899549 \n",
      "Batch: 606. Acc: 0.331801. Loss: 1.914861. Batch_acc: 0.346241. Batch_loss: 1.882465 \n",
      "Batch: 607. Acc: 0.331804. Loss: 1.914869. Batch_acc: 0.333333. Batch_loss: 1.919271 \n",
      "Batch: 608. Acc: 0.331816. Loss: 1.914852. Batch_acc: 0.339423. Batch_loss: 1.904316 \n",
      "Batch: 609. Acc: 0.331816. Loss: 1.914860. Batch_acc: 0.331967. Batch_loss: 1.920266 \n",
      "Batch: 610. Acc: 0.331846. Loss: 1.914778. Batch_acc: 0.350352. Batch_loss: 1.863328 \n",
      "Batch: 611. Acc: 0.331862. Loss: 1.914716. Batch_acc: 0.341700. Batch_loss: 1.877237 \n",
      "Batch: 612. Acc: 0.331881. Loss: 1.914649. Batch_acc: 0.343335. Batch_loss: 1.873594 \n",
      "Batch: 613. Acc: 0.331895. Loss: 1.914578. Batch_acc: 0.340426. Batch_loss: 1.872513 \n",
      "Batch: 614. Acc: 0.331890. Loss: 1.914530. Batch_acc: 0.328759. Batch_loss: 1.884824 \n",
      "Batch: 615. Acc: 0.331882. Loss: 1.914584. Batch_acc: 0.326979. Batch_loss: 1.948366 \n",
      "Batch: 616. Acc: 0.331900. Loss: 1.914562. Batch_acc: 0.343137. Batch_loss: 1.900581 \n",
      "Batch: 617. Acc: 0.331918. Loss: 1.914499. Batch_acc: 0.342545. Batch_loss: 1.875466 \n",
      "Batch: 618. Acc: 0.331936. Loss: 1.914497. Batch_acc: 0.343249. Batch_loss: 1.913699 \n",
      "Batch: 619. Acc: 0.331939. Loss: 1.914492. Batch_acc: 0.333724. Batch_loss: 1.911489 \n",
      "Batch: 620. Acc: 0.331974. Loss: 1.914382. Batch_acc: 0.354203. Batch_loss: 1.845281 \n",
      "Batch: 621. Acc: 0.331948. Loss: 1.914402. Batch_acc: 0.314826. Batch_loss: 1.927425 \n",
      "Batch: 622. Acc: 0.331945. Loss: 1.914356. Batch_acc: 0.330275. Batch_loss: 1.885877 \n",
      "Batch: 623. Acc: 0.331954. Loss: 1.914304. Batch_acc: 0.337692. Batch_loss: 1.882130 \n",
      "Batch: 624. Acc: 0.331956. Loss: 1.914266. Batch_acc: 0.333143. Batch_loss: 1.890543 \n",
      "Batch: 625. Acc: 0.331975. Loss: 1.914208. Batch_acc: 0.343607. Batch_loss: 1.878574 \n",
      "Batch: 626. Acc: 0.331997. Loss: 1.914147. Batch_acc: 0.345651. Batch_loss: 1.875922 \n",
      "Batch: 627. Acc: 0.331998. Loss: 1.914116. Batch_acc: 0.332373. Batch_loss: 1.894775 \n",
      "Batch: 628. Acc: 0.331995. Loss: 1.914094. Batch_acc: 0.330404. Batch_loss: 1.900103 \n",
      "Batch: 629. Acc: 0.331993. Loss: 1.914074. Batch_acc: 0.330887. Batch_loss: 1.901834 \n",
      "Batch: 630. Acc: 0.331968. Loss: 1.914077. Batch_acc: 0.316065. Batch_loss: 1.915979 \n",
      "Batch: 631. Acc: 0.331943. Loss: 1.914140. Batch_acc: 0.316089. Batch_loss: 1.953406 \n",
      "Batch: 632. Acc: 0.331935. Loss: 1.914131. Batch_acc: 0.326772. Batch_loss: 1.908542 \n",
      "Batch: 633. Acc: 0.331918. Loss: 1.914159. Batch_acc: 0.321611. Batch_loss: 1.931896 \n",
      "Batch: 634. Acc: 0.331922. Loss: 1.914132. Batch_acc: 0.334701. Batch_loss: 1.896704 \n",
      "Batch: 635. Acc: 0.331919. Loss: 1.914116. Batch_acc: 0.329525. Batch_loss: 1.903184 \n",
      "Batch: 636. Acc: 0.331939. Loss: 1.914123. Batch_acc: 0.345294. Batch_loss: 1.918568 \n",
      "Batch: 637. Acc: 0.331954. Loss: 1.914101. Batch_acc: 0.341363. Batch_loss: 1.899782 \n",
      "Batch: 638. Acc: 0.331993. Loss: 1.914002. Batch_acc: 0.356981. Batch_loss: 1.851794 \n",
      "Batch: 639. Acc: 0.331990. Loss: 1.914020. Batch_acc: 0.329932. Batch_loss: 1.925413 \n",
      "Batch: 640. Acc: 0.332005. Loss: 1.913972. Batch_acc: 0.341691. Batch_loss: 1.883052 \n",
      "Batch: 641. Acc: 0.332004. Loss: 1.913950. Batch_acc: 0.331451. Batch_loss: 1.899625 \n",
      "Batch: 642. Acc: 0.332002. Loss: 1.913891. Batch_acc: 0.330414. Batch_loss: 1.875641 \n",
      "Batch: 643. Acc: 0.332005. Loss: 1.913831. Batch_acc: 0.333911. Batch_loss: 1.875433 \n",
      "Batch: 644. Acc: 0.332009. Loss: 1.913816. Batch_acc: 0.334878. Batch_loss: 1.903563 \n",
      "Batch: 645. Acc: 0.332011. Loss: 1.913811. Batch_acc: 0.332943. Batch_loss: 1.910562 \n",
      "Batch: 646. Acc: 0.332014. Loss: 1.913779. Batch_acc: 0.334495. Batch_loss: 1.893125 \n",
      "Batch: 647. Acc: 0.332009. Loss: 1.913751. Batch_acc: 0.328612. Batch_loss: 1.896196 \n",
      "Batch: 648. Acc: 0.332011. Loss: 1.913745. Batch_acc: 0.332953. Batch_loss: 1.909944 \n",
      "Batch: 649. Acc: 0.331995. Loss: 1.913815. Batch_acc: 0.322248. Batch_loss: 1.959098 \n",
      "Batch: 650. Acc: 0.332018. Loss: 1.913736. Batch_acc: 0.347190. Batch_loss: 1.861017 \n",
      "Batch: 651. Acc: 0.332055. Loss: 1.913651. Batch_acc: 0.355731. Batch_loss: 1.859208 \n",
      "Batch: 652. Acc: 0.332063. Loss: 1.913626. Batch_acc: 0.337271. Batch_loss: 1.897224 \n",
      "Batch: 653. Acc: 0.332052. Loss: 1.913645. Batch_acc: 0.324691. Batch_loss: 1.926559 \n",
      "Batch: 654. Acc: 0.332066. Loss: 1.913581. Batch_acc: 0.340909. Batch_loss: 1.871772 \n",
      "Batch: 655. Acc: 0.332062. Loss: 1.913596. Batch_acc: 0.329632. Batch_loss: 1.923720 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 656. Acc: 0.332068. Loss: 1.913552. Batch_acc: 0.335821. Batch_loss: 1.884767 \n",
      "Batch: 657. Acc: 0.332058. Loss: 1.913573. Batch_acc: 0.325430. Batch_loss: 1.927853 \n",
      "Batch: 658. Acc: 0.332053. Loss: 1.913611. Batch_acc: 0.328671. Batch_loss: 1.938685 \n",
      "Batch: 659. Acc: 0.332055. Loss: 1.913573. Batch_acc: 0.333333. Batch_loss: 1.889265 \n",
      "Batch: 660. Acc: 0.332077. Loss: 1.913538. Batch_acc: 0.346868. Batch_loss: 1.890249 \n",
      "Batch: 661. Acc: 0.332079. Loss: 1.913476. Batch_acc: 0.333528. Batch_loss: 1.871593 \n",
      "Batch: 662. Acc: 0.332085. Loss: 1.913460. Batch_acc: 0.336023. Batch_loss: 1.902583 \n",
      "Batch: 663. Acc: 0.332087. Loss: 1.913457. Batch_acc: 0.333333. Batch_loss: 1.911476 \n",
      "Batch: 664. Acc: 0.332080. Loss: 1.913406. Batch_acc: 0.327324. Batch_loss: 1.880459 \n",
      "Batch: 665. Acc: 0.332086. Loss: 1.913404. Batch_acc: 0.335847. Batch_loss: 1.911875 \n",
      "Batch: 666. Acc: 0.332096. Loss: 1.913365. Batch_acc: 0.339130. Batch_loss: 1.887614 \n",
      "Batch: 667. Acc: 0.332120. Loss: 1.913352. Batch_acc: 0.347582. Batch_loss: 1.904981 \n",
      "Batch: 668. Acc: 0.332159. Loss: 1.913306. Batch_acc: 0.358568. Batch_loss: 1.881528 \n",
      "Batch: 669. Acc: 0.332166. Loss: 1.913276. Batch_acc: 0.337156. Batch_loss: 1.893180 \n",
      "Batch: 670. Acc: 0.332164. Loss: 1.913295. Batch_acc: 0.330805. Batch_loss: 1.926555 \n",
      "Batch: 671. Acc: 0.332168. Loss: 1.913254. Batch_acc: 0.335046. Batch_loss: 1.886109 \n",
      "Batch: 672. Acc: 0.332170. Loss: 1.913228. Batch_acc: 0.333333. Batch_loss: 1.895626 \n",
      "Batch: 673. Acc: 0.332149. Loss: 1.913258. Batch_acc: 0.317460. Batch_loss: 1.934105 \n",
      "Batch: 674. Acc: 0.332135. Loss: 1.913276. Batch_acc: 0.322953. Batch_loss: 1.925812 \n",
      "Batch: 675. Acc: 0.332138. Loss: 1.913281. Batch_acc: 0.333707. Batch_loss: 1.916520 \n",
      "Batch: 676. Acc: 0.332127. Loss: 1.913291. Batch_acc: 0.325088. Batch_loss: 1.920108 \n",
      "Batch: 677. Acc: 0.332123. Loss: 1.913272. Batch_acc: 0.329085. Batch_loss: 1.899900 \n",
      "Batch: 678. Acc: 0.332092. Loss: 1.913279. Batch_acc: 0.310725. Batch_loss: 1.918141 \n",
      "Batch: 679. Acc: 0.332110. Loss: 1.913257. Batch_acc: 0.344767. Batch_loss: 1.898301 \n",
      "Batch: 680. Acc: 0.332128. Loss: 1.913202. Batch_acc: 0.344787. Batch_loss: 1.875257 \n",
      "Batch: 681. Acc: 0.332139. Loss: 1.913158. Batch_acc: 0.339460. Batch_loss: 1.883351 \n",
      "Batch: 682. Acc: 0.332149. Loss: 1.913128. Batch_acc: 0.338652. Batch_loss: 1.891870 \n",
      "Batch: 683. Acc: 0.332156. Loss: 1.913124. Batch_acc: 0.336907. Batch_loss: 1.910808 \n",
      "Batch: 684. Acc: 0.332138. Loss: 1.913138. Batch_acc: 0.320023. Batch_loss: 1.923038 \n",
      "Batch: 685. Acc: 0.332140. Loss: 1.913115. Batch_acc: 0.333333. Batch_loss: 1.897555 \n",
      "Batch: 686. Acc: 0.332144. Loss: 1.913078. Batch_acc: 0.335046. Batch_loss: 1.887910 \n",
      "Batch: 687. Acc: 0.332139. Loss: 1.913050. Batch_acc: 0.328308. Batch_loss: 1.894619 \n",
      "Batch: 688. Acc: 0.332139. Loss: 1.913059. Batch_acc: 0.332170. Batch_loss: 1.919199 \n",
      "Batch: 689. Acc: 0.332134. Loss: 1.913058. Batch_acc: 0.329136. Batch_loss: 1.912074 \n",
      "Batch: 690. Acc: 0.332133. Loss: 1.913073. Batch_acc: 0.331246. Batch_loss: 1.923303 \n",
      "Batch: 691. Acc: 0.332137. Loss: 1.913070. Batch_acc: 0.335079. Batch_loss: 1.910842 \n",
      "Batch: 692. Acc: 0.332161. Loss: 1.913021. Batch_acc: 0.348624. Batch_loss: 1.879730 \n",
      "Batch: 693. Acc: 0.332174. Loss: 1.913003. Batch_acc: 0.341081. Batch_loss: 1.899892 \n",
      "Batch: 694. Acc: 0.332191. Loss: 1.912946. Batch_acc: 0.344023. Batch_loss: 1.873120 \n",
      "Batch: 695. Acc: 0.332170. Loss: 1.912955. Batch_acc: 0.318052. Batch_loss: 1.919469 \n",
      "Batch: 696. Acc: 0.332166. Loss: 1.912951. Batch_acc: 0.328824. Batch_loss: 1.909902 \n",
      "Batch: 697. Acc: 0.332164. Loss: 1.912931. Batch_acc: 0.330769. Batch_loss: 1.898251 \n",
      "Batch: 698. Acc: 0.332169. Loss: 1.912863. Batch_acc: 0.335574. Batch_loss: 1.866969 \n",
      "Batch: 699. Acc: 0.332173. Loss: 1.912857. Batch_acc: 0.335244. Batch_loss: 1.908651 \n",
      "Batch: 700. Acc: 0.332192. Loss: 1.912863. Batch_acc: 0.345800. Batch_loss: 1.916861 \n",
      "Batch: 701. Acc: 0.332194. Loss: 1.912883. Batch_acc: 0.333137. Batch_loss: 1.927185 \n",
      "Batch: 702. Acc: 0.332217. Loss: 1.912847. Batch_acc: 0.348715. Batch_loss: 1.887744 \n",
      "Batch: 703. Acc: 0.332221. Loss: 1.912808. Batch_acc: 0.335425. Batch_loss: 1.884988 \n",
      "Batch: 704. Acc: 0.332219. Loss: 1.912813. Batch_acc: 0.330455. Batch_loss: 1.916385 \n",
      "Batch: 705. Acc: 0.332248. Loss: 1.912754. Batch_acc: 0.352770. Batch_loss: 1.871171 \n",
      "Batch: 706. Acc: 0.332245. Loss: 1.912743. Batch_acc: 0.330029. Batch_loss: 1.904501 \n",
      "Batch: 707. Acc: 0.332256. Loss: 1.912729. Batch_acc: 0.340351. Batch_loss: 1.902527 \n",
      "Batch: 708. Acc: 0.332249. Loss: 1.912753. Batch_acc: 0.327465. Batch_loss: 1.930126 \n",
      "Batch: 709. Acc: 0.332234. Loss: 1.912778. Batch_acc: 0.321176. Batch_loss: 1.930961 \n",
      "Batch: 710. Acc: 0.332239. Loss: 1.912795. Batch_acc: 0.335447. Batch_loss: 1.924684 \n",
      "Batch: 711. Acc: 0.332245. Loss: 1.912773. Batch_acc: 0.336866. Batch_loss: 1.898220 \n",
      "Batch: 712. Acc: 0.332256. Loss: 1.912759. Batch_acc: 0.340079. Batch_loss: 1.902558 \n",
      "Batch: 713. Acc: 0.332252. Loss: 1.912764. Batch_acc: 0.328759. Batch_loss: 1.916653 \n",
      "Batch: 714. Acc: 0.332274. Loss: 1.912708. Batch_acc: 0.348073. Batch_loss: 1.873465 \n",
      "Batch: 715. Acc: 0.332297. Loss: 1.912701. Batch_acc: 0.348824. Batch_loss: 1.907212 \n",
      "Batch: 716. Acc: 0.332294. Loss: 1.912735. Batch_acc: 0.330227. Batch_loss: 1.937658 \n",
      "Batch: 717. Acc: 0.332312. Loss: 1.912713. Batch_acc: 0.345169. Batch_loss: 1.896635 \n",
      "Batch: 718. Acc: 0.332319. Loss: 1.912680. Batch_acc: 0.337767. Batch_loss: 1.888478 \n",
      "Batch: 719. Acc: 0.332333. Loss: 1.912645. Batch_acc: 0.342135. Batch_loss: 1.888615 \n",
      "Batch: 720. Acc: 0.332336. Loss: 1.912606. Batch_acc: 0.334673. Batch_loss: 1.884523 \n",
      "Batch: 721. Acc: 0.332355. Loss: 1.912581. Batch_acc: 0.345413. Batch_loss: 1.894438 \n",
      "Batch: 722. Acc: 0.332351. Loss: 1.912629. Batch_acc: 0.329453. Batch_loss: 1.948026 \n",
      "Batch: 723. Acc: 0.332374. Loss: 1.912597. Batch_acc: 0.348955. Batch_loss: 1.890085 \n",
      "Batch: 724. Acc: 0.332379. Loss: 1.912590. Batch_acc: 0.335758. Batch_loss: 1.907010 \n",
      "Batch: 725. Acc: 0.332359. Loss: 1.912634. Batch_acc: 0.318078. Batch_loss: 1.944873 \n",
      "Batch: 726. Acc: 0.332368. Loss: 1.912618. Batch_acc: 0.338838. Batch_loss: 1.901260 \n",
      "Batch: 727. Acc: 0.332384. Loss: 1.912557. Batch_acc: 0.344310. Batch_loss: 1.867594 \n",
      "Batch: 728. Acc: 0.332374. Loss: 1.912566. Batch_acc: 0.324607. Batch_loss: 1.919326 \n",
      "Batch: 729. Acc: 0.332387. Loss: 1.912534. Batch_acc: 0.341314. Batch_loss: 1.889833 \n",
      "Batch: 730. Acc: 0.332369. Loss: 1.912525. Batch_acc: 0.319534. Batch_loss: 1.905957 \n",
      "Batch: 731. Acc: 0.332379. Loss: 1.912517. Batch_acc: 0.339850. Batch_loss: 1.906402 \n",
      "Batch: 732. Acc: 0.332376. Loss: 1.912479. Batch_acc: 0.329837. Batch_loss: 1.884843 \n",
      "Batch: 733. Acc: 0.332372. Loss: 1.912470. Batch_acc: 0.329365. Batch_loss: 1.905757 \n",
      "Batch: 734. Acc: 0.332403. Loss: 1.912439. Batch_acc: 0.354784. Batch_loss: 1.889988 \n",
      "Batch: 735. Acc: 0.332412. Loss: 1.912401. Batch_acc: 0.338973. Batch_loss: 1.885028 \n",
      "Batch: 736. Acc: 0.332410. Loss: 1.912373. Batch_acc: 0.331435. Batch_loss: 1.892051 \n",
      "Batch: 737. Acc: 0.332399. Loss: 1.912387. Batch_acc: 0.324309. Batch_loss: 1.922543 \n",
      "Batch: 738. Acc: 0.332416. Loss: 1.912324. Batch_acc: 0.344438. Batch_loss: 1.866418 \n",
      "Batch: 739. Acc: 0.332416. Loss: 1.912305. Batch_acc: 0.332750. Batch_loss: 1.898546 \n",
      "Batch: 740. Acc: 0.332442. Loss: 1.912251. Batch_acc: 0.351259. Batch_loss: 1.872551 \n",
      "Batch: 741. Acc: 0.332442. Loss: 1.912235. Batch_acc: 0.332764. Batch_loss: 1.900443 \n",
      "Batch: 742. Acc: 0.332452. Loss: 1.912185. Batch_acc: 0.339492. Batch_loss: 1.874493 \n",
      "Batch: 743. Acc: 0.332481. Loss: 1.912126. Batch_acc: 0.353776. Batch_loss: 1.868939 \n",
      "Batch: 744. Acc: 0.332481. Loss: 1.912108. Batch_acc: 0.332380. Batch_loss: 1.899330 \n",
      "Batch: 745. Acc: 0.332489. Loss: 1.912092. Batch_acc: 0.338700. Batch_loss: 1.900157 \n",
      "Batch: 746. Acc: 0.332505. Loss: 1.912066. Batch_acc: 0.344666. Batch_loss: 1.892368 \n",
      "Batch: 747. Acc: 0.332499. Loss: 1.912062. Batch_acc: 0.328223. Batch_loss: 1.908996 \n",
      "Batch: 748. Acc: 0.332520. Loss: 1.912010. Batch_acc: 0.347678. Batch_loss: 1.873714 \n",
      "Batch: 749. Acc: 0.332517. Loss: 1.911996. Batch_acc: 0.330479. Batch_loss: 1.901151 \n",
      "Batch: 750. Acc: 0.332526. Loss: 1.911958. Batch_acc: 0.338983. Batch_loss: 1.884247 \n",
      "Batch: 751. Acc: 0.332542. Loss: 1.911917. Batch_acc: 0.344671. Batch_loss: 1.881815 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 752. Acc: 0.332541. Loss: 1.911931. Batch_acc: 0.331445. Batch_loss: 1.921893 \n",
      "Batch: 753. Acc: 0.332540. Loss: 1.911921. Batch_acc: 0.332007. Batch_loss: 1.904989 \n",
      "Checkpointing on batch: 753. Accuracy: 0.3325402173158237. Loss per char: 1.9119214191561198. Time: 1627206995.938842\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 18, 20, 24, 20, 25, 20, 19, 26,\n",
      "        23,  1, 14,  1, 14, 26, 26, 26, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.332553. Loss: 1.911867. Batch_acc: 0.342593. Batch_loss: 1.870891 \n",
      "Batch: 755. Acc: 0.332536. Loss: 1.911869. Batch_acc: 0.319308. Batch_loss: 1.913092 \n",
      "Batch: 756. Acc: 0.332540. Loss: 1.911838. Batch_acc: 0.335804. Batch_loss: 1.888761 \n",
      "Batch: 757. Acc: 0.332546. Loss: 1.911848. Batch_acc: 0.336907. Batch_loss: 1.919455 \n",
      "Batch: 758. Acc: 0.332544. Loss: 1.911873. Batch_acc: 0.330814. Batch_loss: 1.931024 \n",
      "Batch: 759. Acc: 0.332534. Loss: 1.911943. Batch_acc: 0.324638. Batch_loss: 1.965501 \n",
      "Batch: 760. Acc: 0.332525. Loss: 1.911948. Batch_acc: 0.326381. Batch_loss: 1.915094 \n",
      "Batch: 761. Acc: 0.332527. Loss: 1.911910. Batch_acc: 0.333702. Batch_loss: 1.884413 \n",
      "Batch: 762. Acc: 0.332535. Loss: 1.911889. Batch_acc: 0.338329. Batch_loss: 1.895993 \n",
      "Batch: 763. Acc: 0.332523. Loss: 1.911866. Batch_acc: 0.323936. Batch_loss: 1.894319 \n",
      "Batch: 764. Acc: 0.332540. Loss: 1.911807. Batch_acc: 0.345455. Batch_loss: 1.867057 \n",
      "Batch: 765. Acc: 0.332558. Loss: 1.911760. Batch_acc: 0.345865. Batch_loss: 1.875792 \n",
      "Batch: 766. Acc: 0.332552. Loss: 1.911756. Batch_acc: 0.328341. Batch_loss: 1.908536 \n",
      "Batch: 767. Acc: 0.332536. Loss: 1.911758. Batch_acc: 0.319977. Batch_loss: 1.913109 \n",
      "Batch: 768. Acc: 0.332537. Loss: 1.911733. Batch_acc: 0.333526. Batch_loss: 1.892899 \n",
      "Batch: 769. Acc: 0.332526. Loss: 1.911773. Batch_acc: 0.324138. Batch_loss: 1.942484 \n",
      "Batch: 770. Acc: 0.332536. Loss: 1.911732. Batch_acc: 0.339740. Batch_loss: 1.880506 \n",
      "Batch: 771. Acc: 0.332562. Loss: 1.911675. Batch_acc: 0.352431. Batch_loss: 1.867382 \n",
      "Batch: 772. Acc: 0.332552. Loss: 1.911695. Batch_acc: 0.325356. Batch_loss: 1.927050 \n",
      "Batch: 773. Acc: 0.332550. Loss: 1.911682. Batch_acc: 0.330861. Batch_loss: 1.901907 \n",
      "Batch: 774. Acc: 0.332555. Loss: 1.911653. Batch_acc: 0.336252. Batch_loss: 1.888391 \n",
      "Batch: 775. Acc: 0.332563. Loss: 1.911660. Batch_acc: 0.339181. Batch_loss: 1.917060 \n",
      "Batch: 776. Acc: 0.332579. Loss: 1.911618. Batch_acc: 0.344963. Batch_loss: 1.880342 \n",
      "Batch: 777. Acc: 0.332591. Loss: 1.911604. Batch_acc: 0.341895. Batch_loss: 1.900323 \n",
      "Batch: 778. Acc: 0.332632. Loss: 1.911537. Batch_acc: 0.364002. Batch_loss: 1.859435 \n",
      "Batch: 779. Acc: 0.332660. Loss: 1.911450. Batch_acc: 0.353923. Batch_loss: 1.846123 \n",
      "Batch: 780. Acc: 0.332665. Loss: 1.911443. Batch_acc: 0.336700. Batch_loss: 1.906021 \n",
      "Batch: 781. Acc: 0.332674. Loss: 1.911463. Batch_acc: 0.339644. Batch_loss: 1.927128 \n",
      "Batch: 782. Acc: 0.332668. Loss: 1.911425. Batch_acc: 0.327963. Batch_loss: 1.881623 \n",
      "Batch: 783. Acc: 0.332682. Loss: 1.911415. Batch_acc: 0.343643. Batch_loss: 1.903565 \n",
      "Batch: 784. Acc: 0.332671. Loss: 1.911413. Batch_acc: 0.324111. Batch_loss: 1.909898 \n",
      "Batch: 785. Acc: 0.332685. Loss: 1.911413. Batch_acc: 0.343590. Batch_loss: 1.911647 \n",
      "Batch: 786. Acc: 0.332671. Loss: 1.911428. Batch_acc: 0.321634. Batch_loss: 1.923306 \n",
      "Batch: 787. Acc: 0.332690. Loss: 1.911416. Batch_acc: 0.347801. Batch_loss: 1.901579 \n",
      "Batch: 788. Acc: 0.332682. Loss: 1.911433. Batch_acc: 0.325935. Batch_loss: 1.924940 \n",
      "Batch: 789. Acc: 0.332668. Loss: 1.911457. Batch_acc: 0.321532. Batch_loss: 1.930672 \n",
      "Batch: 790. Acc: 0.332682. Loss: 1.911417. Batch_acc: 0.343645. Batch_loss: 1.880902 \n",
      "Batch: 791. Acc: 0.332704. Loss: 1.911354. Batch_acc: 0.350056. Batch_loss: 1.862497 \n",
      "Batch: 792. Acc: 0.332707. Loss: 1.911352. Batch_acc: 0.334881. Batch_loss: 1.909399 \n",
      "Batch: 793. Acc: 0.332710. Loss: 1.911308. Batch_acc: 0.335023. Batch_loss: 1.877482 \n",
      "Batch: 794. Acc: 0.332703. Loss: 1.911307. Batch_acc: 0.327033. Batch_loss: 1.910607 \n",
      "Batch: 795. Acc: 0.332690. Loss: 1.911306. Batch_acc: 0.322392. Batch_loss: 1.909874 \n",
      "Batch: 796. Acc: 0.332716. Loss: 1.911253. Batch_acc: 0.353488. Batch_loss: 1.868724 \n",
      "Batch: 797. Acc: 0.332722. Loss: 1.911233. Batch_acc: 0.337822. Batch_loss: 1.895036 \n",
      "Batch: 798. Acc: 0.332730. Loss: 1.911216. Batch_acc: 0.338664. Batch_loss: 1.898198 \n",
      "Batch: 799. Acc: 0.332737. Loss: 1.911227. Batch_acc: 0.338462. Batch_loss: 1.919747 \n",
      "Batch: 800. Acc: 0.332722. Loss: 1.911253. Batch_acc: 0.321074. Batch_loss: 1.932646 \n",
      "Batch: 801. Acc: 0.332722. Loss: 1.911251. Batch_acc: 0.332752. Batch_loss: 1.909538 \n",
      "Batch: 802. Acc: 0.332720. Loss: 1.911249. Batch_acc: 0.330479. Batch_loss: 1.909456 \n",
      "Batch: 803. Acc: 0.332750. Loss: 1.911163. Batch_acc: 0.356897. Batch_loss: 1.842156 \n",
      "Batch: 804. Acc: 0.332768. Loss: 1.911154. Batch_acc: 0.347776. Batch_loss: 1.904261 \n",
      "Batch: 805. Acc: 0.332784. Loss: 1.911108. Batch_acc: 0.345332. Batch_loss: 1.875057 \n",
      "Batch: 806. Acc: 0.332778. Loss: 1.911073. Batch_acc: 0.327336. Batch_loss: 1.882331 \n",
      "Batch: 807. Acc: 0.332766. Loss: 1.911074. Batch_acc: 0.323644. Batch_loss: 1.912063 \n",
      "Batch: 808. Acc: 0.332772. Loss: 1.911059. Batch_acc: 0.337767. Batch_loss: 1.898714 \n",
      "Batch: 809. Acc: 0.332758. Loss: 1.911048. Batch_acc: 0.321117. Batch_loss: 1.901857 \n",
      "Batch: 810. Acc: 0.332772. Loss: 1.910979. Batch_acc: 0.343874. Batch_loss: 1.855960 \n",
      "Batch: 811. Acc: 0.332774. Loss: 1.910979. Batch_acc: 0.334895. Batch_loss: 1.911325 \n",
      "Batch: 812. Acc: 0.332790. Loss: 1.910946. Batch_acc: 0.345299. Batch_loss: 1.884550 \n",
      "Batch: 813. Acc: 0.332795. Loss: 1.910901. Batch_acc: 0.336729. Batch_loss: 1.874487 \n",
      "Batch: 814. Acc: 0.332811. Loss: 1.910844. Batch_acc: 0.346241. Batch_loss: 1.865287 \n",
      "Batch: 815. Acc: 0.332801. Loss: 1.910857. Batch_acc: 0.324166. Batch_loss: 1.921596 \n",
      "Batch: 816. Acc: 0.332801. Loss: 1.910839. Batch_acc: 0.333138. Batch_loss: 1.895455 \n",
      "Batch: 817. Acc: 0.332808. Loss: 1.910877. Batch_acc: 0.337935. Batch_loss: 1.941111 \n",
      "Batch: 818. Acc: 0.332809. Loss: 1.910856. Batch_acc: 0.333526. Batch_loss: 1.893595 \n",
      "Batch: 819. Acc: 0.332803. Loss: 1.910888. Batch_acc: 0.327888. Batch_loss: 1.937159 \n",
      "Batch: 820. Acc: 0.332800. Loss: 1.910904. Batch_acc: 0.330383. Batch_loss: 1.924233 \n",
      "Batch: 821. Acc: 0.332792. Loss: 1.910885. Batch_acc: 0.325976. Batch_loss: 1.896152 \n",
      "Batch: 822. Acc: 0.332797. Loss: 1.910885. Batch_acc: 0.337209. Batch_loss: 1.910387 \n",
      "Batch: 823. Acc: 0.332792. Loss: 1.910901. Batch_acc: 0.328539. Batch_loss: 1.924300 \n",
      "Batch: 824. Acc: 0.332795. Loss: 1.910887. Batch_acc: 0.335843. Batch_loss: 1.898800 \n",
      "Batch: 825. Acc: 0.332792. Loss: 1.910866. Batch_acc: 0.329612. Batch_loss: 1.893620 \n",
      "Batch: 826. Acc: 0.332800. Loss: 1.910892. Batch_acc: 0.339850. Batch_loss: 1.932199 \n",
      "Batch: 827. Acc: 0.332811. Loss: 1.910882. Batch_acc: 0.341951. Batch_loss: 1.902569 \n",
      "Batch: 828. Acc: 0.332815. Loss: 1.910887. Batch_acc: 0.336449. Batch_loss: 1.914969 \n",
      "Batch: 829. Acc: 0.332828. Loss: 1.910893. Batch_acc: 0.343327. Batch_loss: 1.916494 \n",
      "Batch: 830. Acc: 0.332833. Loss: 1.910849. Batch_acc: 0.337216. Batch_loss: 1.873876 \n",
      "Batch: 831. Acc: 0.332845. Loss: 1.910829. Batch_acc: 0.342693. Batch_loss: 1.894018 \n",
      "Batch: 832. Acc: 0.332849. Loss: 1.910829. Batch_acc: 0.336187. Batch_loss: 1.911035 \n",
      "Batch: 833. Acc: 0.332867. Loss: 1.910784. Batch_acc: 0.347876. Batch_loss: 1.872750 \n",
      "Batch: 834. Acc: 0.332877. Loss: 1.910747. Batch_acc: 0.341795. Batch_loss: 1.879336 \n",
      "Batch: 835. Acc: 0.332871. Loss: 1.910714. Batch_acc: 0.327388. Batch_loss: 1.883300 \n",
      "Batch: 836. Acc: 0.332871. Loss: 1.910694. Batch_acc: 0.332773. Batch_loss: 1.894704 \n",
      "Batch: 837. Acc: 0.332889. Loss: 1.910650. Batch_acc: 0.348347. Batch_loss: 1.873491 \n",
      "Batch: 838. Acc: 0.332900. Loss: 1.910635. Batch_acc: 0.341924. Batch_loss: 1.898423 \n",
      "Batch: 839. Acc: 0.332879. Loss: 1.910673. Batch_acc: 0.314879. Batch_loss: 1.942974 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 840. Acc: 0.332888. Loss: 1.910653. Batch_acc: 0.340266. Batch_loss: 1.893076 \n",
      "Batch: 841. Acc: 0.332902. Loss: 1.910635. Batch_acc: 0.345169. Batch_loss: 1.895381 \n",
      "Batch: 842. Acc: 0.332900. Loss: 1.910609. Batch_acc: 0.331402. Batch_loss: 1.888641 \n",
      "Batch: 843. Acc: 0.332908. Loss: 1.910570. Batch_acc: 0.339359. Batch_loss: 1.877368 \n",
      "Batch: 844. Acc: 0.332895. Loss: 1.910563. Batch_acc: 0.322129. Batch_loss: 1.904731 \n",
      "Batch: 845. Acc: 0.332907. Loss: 1.910536. Batch_acc: 0.343429. Batch_loss: 1.888090 \n",
      "Batch: 846. Acc: 0.332920. Loss: 1.910521. Batch_acc: 0.343284. Batch_loss: 1.898076 \n",
      "Batch: 847. Acc: 0.332946. Loss: 1.910456. Batch_acc: 0.355301. Batch_loss: 1.855423 \n",
      "Batch: 848. Acc: 0.332954. Loss: 1.910437. Batch_acc: 0.339346. Batch_loss: 1.894744 \n",
      "Batch: 849. Acc: 0.332955. Loss: 1.910431. Batch_acc: 0.333894. Batch_loss: 1.905512 \n",
      "Batch: 850. Acc: 0.332965. Loss: 1.910409. Batch_acc: 0.341001. Batch_loss: 1.892185 \n",
      "Batch: 851. Acc: 0.332964. Loss: 1.910390. Batch_acc: 0.332164. Batch_loss: 1.894140 \n",
      "Batch: 852. Acc: 0.332962. Loss: 1.910377. Batch_acc: 0.331014. Batch_loss: 1.898542 \n",
      "Batch: 853. Acc: 0.332978. Loss: 1.910335. Batch_acc: 0.346857. Batch_loss: 1.875348 \n",
      "Batch: 854. Acc: 0.332975. Loss: 1.910335. Batch_acc: 0.330870. Batch_loss: 1.909759 \n",
      "Batch: 855. Acc: 0.332979. Loss: 1.910315. Batch_acc: 0.335597. Batch_loss: 1.893827 \n",
      "Batch: 856. Acc: 0.332980. Loss: 1.910281. Batch_acc: 0.333899. Batch_loss: 1.881680 \n",
      "Batch: 857. Acc: 0.332961. Loss: 1.910287. Batch_acc: 0.317087. Batch_loss: 1.914907 \n",
      "Batch: 858. Acc: 0.332973. Loss: 1.910235. Batch_acc: 0.342825. Batch_loss: 1.866207 \n",
      "Batch: 859. Acc: 0.332980. Loss: 1.910219. Batch_acc: 0.339423. Batch_loss: 1.896675 \n",
      "Batch: 860. Acc: 0.332999. Loss: 1.910174. Batch_acc: 0.349216. Batch_loss: 1.870779 \n",
      "Batch: 861. Acc: 0.333008. Loss: 1.910175. Batch_acc: 0.341307. Batch_loss: 1.910677 \n",
      "Batch: 862. Acc: 0.333004. Loss: 1.910184. Batch_acc: 0.328908. Batch_loss: 1.918854 \n",
      "Batch: 863. Acc: 0.333000. Loss: 1.910158. Batch_acc: 0.329532. Batch_loss: 1.888112 \n",
      "Batch: 864. Acc: 0.332983. Loss: 1.910193. Batch_acc: 0.318584. Batch_loss: 1.940749 \n",
      "Batch: 865. Acc: 0.332980. Loss: 1.910180. Batch_acc: 0.330058. Batch_loss: 1.898985 \n",
      "Batch: 866. Acc: 0.332988. Loss: 1.910112. Batch_acc: 0.339751. Batch_loss: 1.852371 \n",
      "Batch: 867. Acc: 0.333025. Loss: 1.910044. Batch_acc: 0.364934. Batch_loss: 1.851361 \n",
      "Batch: 868. Acc: 0.333022. Loss: 1.910031. Batch_acc: 0.330265. Batch_loss: 1.899072 \n",
      "Batch: 869. Acc: 0.333043. Loss: 1.909983. Batch_acc: 0.351211. Batch_loss: 1.867475 \n",
      "Batch: 870. Acc: 0.333045. Loss: 1.909967. Batch_acc: 0.335465. Batch_loss: 1.895793 \n",
      "Batch: 871. Acc: 0.333041. Loss: 1.909984. Batch_acc: 0.329473. Batch_loss: 1.925058 \n",
      "Batch: 872. Acc: 0.333050. Loss: 1.909980. Batch_acc: 0.340792. Batch_loss: 1.906341 \n",
      "Batch: 873. Acc: 0.333056. Loss: 1.909974. Batch_acc: 0.337939. Batch_loss: 1.904946 \n",
      "Batch: 874. Acc: 0.333050. Loss: 1.909962. Batch_acc: 0.328467. Batch_loss: 1.900104 \n",
      "Batch: 875. Acc: 0.333035. Loss: 1.910030. Batch_acc: 0.319387. Batch_loss: 1.970468 \n",
      "Batch: 876. Acc: 0.333052. Loss: 1.909980. Batch_acc: 0.347191. Batch_loss: 1.867923 \n",
      "Batch: 877. Acc: 0.333073. Loss: 1.909933. Batch_acc: 0.351200. Batch_loss: 1.869166 \n",
      "Batch: 878. Acc: 0.333070. Loss: 1.909941. Batch_acc: 0.330654. Batch_loss: 1.917651 \n",
      "Batch: 879. Acc: 0.333073. Loss: 1.909915. Batch_acc: 0.335628. Batch_loss: 1.886811 \n",
      "Batch: 880. Acc: 0.333080. Loss: 1.909925. Batch_acc: 0.339061. Batch_loss: 1.918461 \n",
      "Batch: 881. Acc: 0.333086. Loss: 1.909925. Batch_acc: 0.338652. Batch_loss: 1.910370 \n",
      "Batch: 882. Acc: 0.333091. Loss: 1.909901. Batch_acc: 0.337752. Batch_loss: 1.888110 \n",
      "Batch: 883. Acc: 0.333093. Loss: 1.909886. Batch_acc: 0.334105. Batch_loss: 1.896699 \n",
      "Batch: 884. Acc: 0.333104. Loss: 1.909876. Batch_acc: 0.343547. Batch_loss: 1.901448 \n",
      "Batch: 885. Acc: 0.333110. Loss: 1.909892. Batch_acc: 0.338843. Batch_loss: 1.923573 \n",
      "Batch: 886. Acc: 0.333110. Loss: 1.909845. Batch_acc: 0.332965. Batch_loss: 1.870312 \n",
      "Batch: 887. Acc: 0.333126. Loss: 1.909831. Batch_acc: 0.346868. Batch_loss: 1.897593 \n",
      "Batch: 888. Acc: 0.333129. Loss: 1.909792. Batch_acc: 0.335771. Batch_loss: 1.875660 \n",
      "Batch: 889. Acc: 0.333131. Loss: 1.909765. Batch_acc: 0.335049. Batch_loss: 1.885961 \n",
      "Batch: 890. Acc: 0.333139. Loss: 1.909744. Batch_acc: 0.339955. Batch_loss: 1.891427 \n",
      "Batch: 891. Acc: 0.333159. Loss: 1.909681. Batch_acc: 0.351163. Batch_loss: 1.852411 \n",
      "Batch: 892. Acc: 0.333142. Loss: 1.909689. Batch_acc: 0.318725. Batch_loss: 1.917048 \n",
      "Batch: 893. Acc: 0.333125. Loss: 1.909732. Batch_acc: 0.317414. Batch_loss: 1.948318 \n",
      "Batch: 894. Acc: 0.333117. Loss: 1.909733. Batch_acc: 0.325662. Batch_loss: 1.911224 \n",
      "Batch: 895. Acc: 0.333127. Loss: 1.909696. Batch_acc: 0.342857. Batch_loss: 1.874825 \n",
      "Batch: 896. Acc: 0.333117. Loss: 1.909729. Batch_acc: 0.323754. Batch_loss: 1.939726 \n",
      "Batch: 897. Acc: 0.333115. Loss: 1.909725. Batch_acc: 0.331787. Batch_loss: 1.906820 \n",
      "Batch: 898. Acc: 0.333118. Loss: 1.909729. Batch_acc: 0.335783. Batch_loss: 1.913087 \n",
      "Batch: 899. Acc: 0.333102. Loss: 1.909762. Batch_acc: 0.318417. Batch_loss: 1.939018 \n",
      "Batch: 900. Acc: 0.333109. Loss: 1.909737. Batch_acc: 0.339513. Batch_loss: 1.886892 \n",
      "Batch: 901. Acc: 0.333118. Loss: 1.909687. Batch_acc: 0.341037. Batch_loss: 1.865973 \n",
      "Batch: 902. Acc: 0.333102. Loss: 1.909725. Batch_acc: 0.318423. Batch_loss: 1.944430 \n",
      "Batch: 903. Acc: 0.333136. Loss: 1.909656. Batch_acc: 0.363636. Batch_loss: 1.847575 \n",
      "Batch: 904. Acc: 0.333141. Loss: 1.909651. Batch_acc: 0.338012. Batch_loss: 1.905230 \n",
      "Batch: 905. Acc: 0.333137. Loss: 1.909676. Batch_acc: 0.329446. Batch_loss: 1.933117 \n",
      "Batch: 906. Acc: 0.333147. Loss: 1.909640. Batch_acc: 0.341984. Batch_loss: 1.876286 \n",
      "Batch: 907. Acc: 0.333166. Loss: 1.909608. Batch_acc: 0.350612. Batch_loss: 1.880232 \n",
      "Batch: 908. Acc: 0.333170. Loss: 1.909570. Batch_acc: 0.337163. Batch_loss: 1.875707 \n",
      "Batch: 909. Acc: 0.333178. Loss: 1.909531. Batch_acc: 0.339548. Batch_loss: 1.874196 \n",
      "Batch: 910. Acc: 0.333195. Loss: 1.909478. Batch_acc: 0.348613. Batch_loss: 1.862591 \n",
      "Batch: 911. Acc: 0.333176. Loss: 1.909536. Batch_acc: 0.315728. Batch_loss: 1.963056 \n",
      "Batch: 912. Acc: 0.333192. Loss: 1.909498. Batch_acc: 0.347572. Batch_loss: 1.874627 \n",
      "Batch: 913. Acc: 0.333185. Loss: 1.909478. Batch_acc: 0.326846. Batch_loss: 1.891113 \n",
      "Batch: 914. Acc: 0.333172. Loss: 1.909465. Batch_acc: 0.321926. Batch_loss: 1.897214 \n",
      "Batch: 915. Acc: 0.333173. Loss: 1.909415. Batch_acc: 0.334086. Batch_loss: 1.865225 \n",
      "Batch: 916. Acc: 0.333165. Loss: 1.909429. Batch_acc: 0.325101. Batch_loss: 1.921423 \n",
      "Batch: 917. Acc: 0.333152. Loss: 1.909436. Batch_acc: 0.321678. Batch_loss: 1.916380 \n",
      "Batch: 918. Acc: 0.333145. Loss: 1.909446. Batch_acc: 0.326721. Batch_loss: 1.918576 \n",
      "Batch: 919. Acc: 0.333154. Loss: 1.909428. Batch_acc: 0.341618. Batch_loss: 1.892726 \n",
      "Batch: 920. Acc: 0.333150. Loss: 1.909465. Batch_acc: 0.328839. Batch_loss: 1.944529 \n",
      "Batch: 921. Acc: 0.333160. Loss: 1.909449. Batch_acc: 0.342841. Batch_loss: 1.894931 \n",
      "Batch: 922. Acc: 0.333161. Loss: 1.909439. Batch_acc: 0.333524. Batch_loss: 1.900090 \n",
      "Batch: 923. Acc: 0.333167. Loss: 1.909441. Batch_acc: 0.339212. Batch_loss: 1.911131 \n",
      "Batch: 924. Acc: 0.333175. Loss: 1.909408. Batch_acc: 0.340351. Batch_loss: 1.878181 \n",
      "Batch: 925. Acc: 0.333187. Loss: 1.909331. Batch_acc: 0.344207. Batch_loss: 1.839985 \n",
      "Batch: 926. Acc: 0.333197. Loss: 1.909306. Batch_acc: 0.342243. Batch_loss: 1.885610 \n",
      "Batch: 927. Acc: 0.333201. Loss: 1.909283. Batch_acc: 0.337465. Batch_loss: 1.889130 \n",
      "Batch: 928. Acc: 0.333220. Loss: 1.909241. Batch_acc: 0.350442. Batch_loss: 1.869145 \n",
      "Batch: 929. Acc: 0.333236. Loss: 1.909207. Batch_acc: 0.348144. Batch_loss: 1.878112 \n",
      "Batch: 930. Acc: 0.333249. Loss: 1.909146. Batch_acc: 0.345905. Batch_loss: 1.850604 \n",
      "Batch: 931. Acc: 0.333252. Loss: 1.909133. Batch_acc: 0.335851. Batch_loss: 1.897076 \n",
      "Batch: 932. Acc: 0.333279. Loss: 1.909084. Batch_acc: 0.358184. Batch_loss: 1.864800 \n",
      "Batch: 933. Acc: 0.333281. Loss: 1.909063. Batch_acc: 0.334831. Batch_loss: 1.889726 \n",
      "Batch: 934. Acc: 0.333288. Loss: 1.909035. Batch_acc: 0.339527. Batch_loss: 1.883845 \n",
      "Batch: 935. Acc: 0.333301. Loss: 1.909025. Batch_acc: 0.345486. Batch_loss: 1.899369 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 936. Acc: 0.333330. Loss: 1.908956. Batch_acc: 0.359708. Batch_loss: 1.845675 \n",
      "Batch: 937. Acc: 0.333339. Loss: 1.908922. Batch_acc: 0.342181. Batch_loss: 1.877521 \n",
      "Batch: 938. Acc: 0.333340. Loss: 1.908917. Batch_acc: 0.334281. Batch_loss: 1.904415 \n",
      "Batch: 939. Acc: 0.333356. Loss: 1.908878. Batch_acc: 0.348174. Batch_loss: 1.872342 \n",
      "Batch: 940. Acc: 0.333351. Loss: 1.908878. Batch_acc: 0.328116. Batch_loss: 1.908676 \n",
      "Batch: 941. Acc: 0.333354. Loss: 1.908870. Batch_acc: 0.336153. Batch_loss: 1.901329 \n",
      "Batch: 942. Acc: 0.333358. Loss: 1.908832. Batch_acc: 0.337262. Batch_loss: 1.873821 \n",
      "Batch: 943. Acc: 0.333366. Loss: 1.908819. Batch_acc: 0.341321. Batch_loss: 1.896633 \n",
      "Batch: 944. Acc: 0.333356. Loss: 1.908841. Batch_acc: 0.323749. Batch_loss: 1.929999 \n",
      "Batch: 945. Acc: 0.333355. Loss: 1.908796. Batch_acc: 0.332763. Batch_loss: 1.866532 \n",
      "Batch: 946. Acc: 0.333373. Loss: 1.908778. Batch_acc: 0.349829. Batch_loss: 1.891530 \n",
      "Batch: 947. Acc: 0.333386. Loss: 1.908771. Batch_acc: 0.345486. Batch_loss: 1.901789 \n",
      "Batch: 948. Acc: 0.333393. Loss: 1.908728. Batch_acc: 0.340218. Batch_loss: 1.868819 \n",
      "Batch: 949. Acc: 0.333393. Loss: 1.908687. Batch_acc: 0.333333. Batch_loss: 1.870020 \n",
      "Batch: 950. Acc: 0.333377. Loss: 1.908712. Batch_acc: 0.318574. Batch_loss: 1.931625 \n",
      "Batch: 951. Acc: 0.333377. Loss: 1.908702. Batch_acc: 0.332760. Batch_loss: 1.900070 \n",
      "Batch: 952. Acc: 0.333384. Loss: 1.908694. Batch_acc: 0.340627. Batch_loss: 1.900617 \n",
      "Batch: 953. Acc: 0.333398. Loss: 1.908701. Batch_acc: 0.346439. Batch_loss: 1.915438 \n",
      "Batch: 954. Acc: 0.333412. Loss: 1.908675. Batch_acc: 0.347079. Batch_loss: 1.883925 \n",
      "Batch: 955. Acc: 0.333438. Loss: 1.908637. Batch_acc: 0.357756. Batch_loss: 1.872755 \n",
      "Batch: 956. Acc: 0.333446. Loss: 1.908656. Batch_acc: 0.341435. Batch_loss: 1.926903 \n",
      "Batch: 957. Acc: 0.333468. Loss: 1.908604. Batch_acc: 0.354460. Batch_loss: 1.857136 \n",
      "Batch: 958. Acc: 0.333469. Loss: 1.908597. Batch_acc: 0.334320. Batch_loss: 1.901822 \n",
      "Batch: 959. Acc: 0.333460. Loss: 1.908609. Batch_acc: 0.325660. Batch_loss: 1.920205 \n",
      "Batch: 960. Acc: 0.333473. Loss: 1.908587. Batch_acc: 0.345622. Batch_loss: 1.886771 \n",
      "Batch: 961. Acc: 0.333470. Loss: 1.908538. Batch_acc: 0.331070. Batch_loss: 1.862490 \n",
      "Batch: 962. Acc: 0.333466. Loss: 1.908540. Batch_acc: 0.329670. Batch_loss: 1.910325 \n",
      "Batch: 963. Acc: 0.333481. Loss: 1.908487. Batch_acc: 0.346916. Batch_loss: 1.859784 \n",
      "Batch: 964. Acc: 0.333488. Loss: 1.908437. Batch_acc: 0.339758. Batch_loss: 1.862726 \n",
      "Batch: 965. Acc: 0.333481. Loss: 1.908470. Batch_acc: 0.327305. Batch_loss: 1.940239 \n",
      "Batch: 966. Acc: 0.333507. Loss: 1.908402. Batch_acc: 0.357623. Batch_loss: 1.844742 \n",
      "Batch: 967. Acc: 0.333503. Loss: 1.908407. Batch_acc: 0.329915. Batch_loss: 1.913154 \n",
      "Batch: 968. Acc: 0.333488. Loss: 1.908442. Batch_acc: 0.318452. Batch_loss: 1.943152 \n",
      "Batch: 969. Acc: 0.333490. Loss: 1.908433. Batch_acc: 0.335436. Batch_loss: 1.900269 \n",
      "Batch: 970. Acc: 0.333473. Loss: 1.908449. Batch_acc: 0.316860. Batch_loss: 1.923434 \n",
      "Batch: 971. Acc: 0.333497. Loss: 1.908424. Batch_acc: 0.356603. Batch_loss: 1.884108 \n",
      "Batch: 972. Acc: 0.333508. Loss: 1.908387. Batch_acc: 0.344375. Batch_loss: 1.873086 \n",
      "Batch: 973. Acc: 0.333511. Loss: 1.908368. Batch_acc: 0.336273. Batch_loss: 1.889729 \n",
      "Batch: 974. Acc: 0.333506. Loss: 1.908369. Batch_acc: 0.328580. Batch_loss: 1.908586 \n",
      "Batch: 975. Acc: 0.333534. Loss: 1.908320. Batch_acc: 0.360340. Batch_loss: 1.861937 \n",
      "Batch: 976. Acc: 0.333544. Loss: 1.908295. Batch_acc: 0.342938. Batch_loss: 1.883625 \n",
      "Batch: 977. Acc: 0.333552. Loss: 1.908297. Batch_acc: 0.341365. Batch_loss: 1.910791 \n",
      "Batch: 978. Acc: 0.333562. Loss: 1.908288. Batch_acc: 0.344291. Batch_loss: 1.898926 \n",
      "Batch: 979. Acc: 0.333558. Loss: 1.908291. Batch_acc: 0.329466. Batch_loss: 1.911291 \n",
      "Batch: 980. Acc: 0.333554. Loss: 1.908321. Batch_acc: 0.329211. Batch_loss: 1.938874 \n",
      "Batch: 981. Acc: 0.333555. Loss: 1.908299. Batch_acc: 0.334876. Batch_loss: 1.886300 \n",
      "Batch: 982. Acc: 0.333543. Loss: 1.908358. Batch_acc: 0.321219. Batch_loss: 1.967943 \n",
      "Batch: 983. Acc: 0.333547. Loss: 1.908393. Batch_acc: 0.337565. Batch_loss: 1.942572 \n",
      "Batch: 984. Acc: 0.333534. Loss: 1.908434. Batch_acc: 0.320117. Batch_loss: 1.949697 \n",
      "Batch: 985. Acc: 0.333539. Loss: 1.908405. Batch_acc: 0.338785. Batch_loss: 1.879055 \n",
      "Batch: 986. Acc: 0.333553. Loss: 1.908363. Batch_acc: 0.346939. Batch_loss: 1.867322 \n",
      "Batch: 987. Acc: 0.333564. Loss: 1.908366. Batch_acc: 0.344606. Batch_loss: 1.911254 \n",
      "Batch: 988. Acc: 0.333569. Loss: 1.908358. Batch_acc: 0.338462. Batch_loss: 1.901109 \n",
      "Batch: 989. Acc: 0.333577. Loss: 1.908337. Batch_acc: 0.341729. Batch_loss: 1.886930 \n",
      "Batch: 990. Acc: 0.333588. Loss: 1.908331. Batch_acc: 0.344359. Batch_loss: 1.902567 \n",
      "Batch: 991. Acc: 0.333600. Loss: 1.908297. Batch_acc: 0.345816. Batch_loss: 1.874412 \n",
      "Batch: 992. Acc: 0.333618. Loss: 1.908231. Batch_acc: 0.351046. Batch_loss: 1.843624 \n",
      "Batch: 993. Acc: 0.333623. Loss: 1.908206. Batch_acc: 0.338682. Batch_loss: 1.883709 \n",
      "Batch: 994. Acc: 0.333633. Loss: 1.908193. Batch_acc: 0.344205. Batch_loss: 1.895336 \n",
      "Batch: 995. Acc: 0.333630. Loss: 1.908215. Batch_acc: 0.330603. Batch_loss: 1.930276 \n",
      "Batch: 996. Acc: 0.333629. Loss: 1.908225. Batch_acc: 0.332346. Batch_loss: 1.918125 \n",
      "Batch: 997. Acc: 0.333649. Loss: 1.908188. Batch_acc: 0.354070. Batch_loss: 1.870713 \n",
      "Batch: 998. Acc: 0.333629. Loss: 1.908224. Batch_acc: 0.313184. Batch_loss: 1.943977 \n",
      "Batch: 999. Acc: 0.333626. Loss: 1.908216. Batch_acc: 0.330853. Batch_loss: 1.900358 \n",
      "Batch: 1000. Acc: 0.333643. Loss: 1.908160. Batch_acc: 0.350480. Batch_loss: 1.853664 \n",
      "Batch: 1001. Acc: 0.333660. Loss: 1.908159. Batch_acc: 0.350767. Batch_loss: 1.906806 \n",
      "Batch: 1002. Acc: 0.333671. Loss: 1.908139. Batch_acc: 0.344337. Batch_loss: 1.888363 \n",
      "Batch: 1003. Acc: 0.333684. Loss: 1.908078. Batch_acc: 0.346614. Batch_loss: 1.847577 \n",
      "Batch: 1004. Acc: 0.333687. Loss: 1.908056. Batch_acc: 0.336047. Batch_loss: 1.885632 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.3336865261794895. Loss per char: 1.908055784291333. Time: 1627207199.7362506\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 14, 23, 26, 20, 25, 22, 26, 15,\n",
      "        20, 20,  1, 71, 83, 80, 78,  1, 20, 17, 22, 26, 23, 15, 18, 15,  3,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.333713. Loss: 1.908011. Batch_acc: 0.360298. Batch_loss: 1.863022 \n",
      "Batch: 1006. Acc: 0.333730. Loss: 1.907994. Batch_acc: 0.350568. Batch_loss: 1.891037 \n",
      "Batch: 1007. Acc: 0.333748. Loss: 1.907962. Batch_acc: 0.351630. Batch_loss: 1.876228 \n",
      "Batch: 1008. Acc: 0.333752. Loss: 1.907930. Batch_acc: 0.337647. Batch_loss: 1.875254 \n",
      "Batch: 1009. Acc: 0.333756. Loss: 1.907917. Batch_acc: 0.337907. Batch_loss: 1.894248 \n",
      "Batch: 1010. Acc: 0.333760. Loss: 1.907902. Batch_acc: 0.338294. Batch_loss: 1.892781 \n",
      "Batch: 1011. Acc: 0.333778. Loss: 1.907877. Batch_acc: 0.351046. Batch_loss: 1.883441 \n",
      "Batch: 1012. Acc: 0.333774. Loss: 1.907892. Batch_acc: 0.330362. Batch_loss: 1.922983 \n",
      "Batch: 1013. Acc: 0.333762. Loss: 1.907898. Batch_acc: 0.321240. Batch_loss: 1.914307 \n",
      "Batch: 1014. Acc: 0.333760. Loss: 1.907921. Batch_acc: 0.331221. Batch_loss: 1.931709 \n",
      "Batch: 1015. Acc: 0.333780. Loss: 1.907898. Batch_acc: 0.354179. Batch_loss: 1.883552 \n",
      "Batch: 1016. Acc: 0.333762. Loss: 1.907907. Batch_acc: 0.315452. Batch_loss: 1.917078 \n",
      "Batch: 1017. Acc: 0.333769. Loss: 1.907875. Batch_acc: 0.341750. Batch_loss: 1.874979 \n",
      "Batch: 1018. Acc: 0.333794. Loss: 1.907826. Batch_acc: 0.358310. Batch_loss: 1.858976 \n",
      "Batch: 1019. Acc: 0.333817. Loss: 1.907743. Batch_acc: 0.356309. Batch_loss: 1.826355 \n",
      "Batch: 1020. Acc: 0.333810. Loss: 1.907718. Batch_acc: 0.326979. Batch_loss: 1.881590 \n",
      "Batch: 1021. Acc: 0.333809. Loss: 1.907722. Batch_acc: 0.332557. Batch_loss: 1.912079 \n",
      "Batch: 1022. Acc: 0.333788. Loss: 1.907738. Batch_acc: 0.312098. Batch_loss: 1.924478 \n",
      "Batch: 1023. Acc: 0.333792. Loss: 1.907726. Batch_acc: 0.338076. Batch_loss: 1.895471 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1024. Acc: 0.333791. Loss: 1.907721. Batch_acc: 0.332575. Batch_loss: 1.902532 \n",
      "Batch: 1025. Acc: 0.333798. Loss: 1.907699. Batch_acc: 0.340776. Batch_loss: 1.885134 \n",
      "Batch: 1026. Acc: 0.333810. Loss: 1.907652. Batch_acc: 0.346265. Batch_loss: 1.858711 \n",
      "Batch: 1027. Acc: 0.333822. Loss: 1.907596. Batch_acc: 0.346025. Batch_loss: 1.851623 \n",
      "Batch: 1028. Acc: 0.333818. Loss: 1.907583. Batch_acc: 0.329365. Batch_loss: 1.894904 \n",
      "Batch: 1029. Acc: 0.333810. Loss: 1.907604. Batch_acc: 0.325542. Batch_loss: 1.928735 \n",
      "Batch: 1030. Acc: 0.333804. Loss: 1.907592. Batch_acc: 0.328471. Batch_loss: 1.894903 \n",
      "Batch: 1031. Acc: 0.333821. Loss: 1.907545. Batch_acc: 0.350967. Batch_loss: 1.860215 \n",
      "Batch: 1032. Acc: 0.333830. Loss: 1.907520. Batch_acc: 0.342939. Batch_loss: 1.880727 \n",
      "Batch: 1033. Acc: 0.333822. Loss: 1.907521. Batch_acc: 0.325231. Batch_loss: 1.908940 \n",
      "Batch: 1034. Acc: 0.333851. Loss: 1.907432. Batch_acc: 0.363842. Batch_loss: 1.817348 \n",
      "Batch: 1035. Acc: 0.333857. Loss: 1.907394. Batch_acc: 0.339751. Batch_loss: 1.868112 \n",
      "Batch: 1036. Acc: 0.333847. Loss: 1.907403. Batch_acc: 0.323059. Batch_loss: 1.917760 \n",
      "Batch: 1037. Acc: 0.333848. Loss: 1.907380. Batch_acc: 0.335237. Batch_loss: 1.883824 \n",
      "Batch: 1038. Acc: 0.333842. Loss: 1.907387. Batch_acc: 0.326756. Batch_loss: 1.914430 \n",
      "Batch: 1039. Acc: 0.333845. Loss: 1.907379. Batch_acc: 0.337437. Batch_loss: 1.898866 \n",
      "Batch: 1040. Acc: 0.333849. Loss: 1.907343. Batch_acc: 0.337737. Batch_loss: 1.870090 \n",
      "Batch: 1041. Acc: 0.333852. Loss: 1.907324. Batch_acc: 0.337550. Batch_loss: 1.887236 \n",
      "Batch: 1042. Acc: 0.333853. Loss: 1.907338. Batch_acc: 0.334499. Batch_loss: 1.922561 \n",
      "Batch: 1043. Acc: 0.333861. Loss: 1.907338. Batch_acc: 0.342014. Batch_loss: 1.907430 \n",
      "Batch: 1044. Acc: 0.333873. Loss: 1.907308. Batch_acc: 0.347214. Batch_loss: 1.875802 \n",
      "Batch: 1045. Acc: 0.333873. Loss: 1.907307. Batch_acc: 0.333527. Batch_loss: 1.905754 \n",
      "Batch: 1046. Acc: 0.333867. Loss: 1.907304. Batch_acc: 0.327577. Batch_loss: 1.903957 \n",
      "Batch: 1047. Acc: 0.333878. Loss: 1.907271. Batch_acc: 0.345252. Batch_loss: 1.872076 \n",
      "Batch: 1048. Acc: 0.333872. Loss: 1.907270. Batch_acc: 0.327924. Batch_loss: 1.906566 \n",
      "Batch: 1049. Acc: 0.333866. Loss: 1.907285. Batch_acc: 0.327721. Batch_loss: 1.923597 \n",
      "Batch: 1050. Acc: 0.333871. Loss: 1.907277. Batch_acc: 0.338655. Batch_loss: 1.899404 \n",
      "Batch: 1051. Acc: 0.333876. Loss: 1.907265. Batch_acc: 0.339318. Batch_loss: 1.893377 \n",
      "Batch: 1052. Acc: 0.333891. Loss: 1.907241. Batch_acc: 0.349827. Batch_loss: 1.882710 \n",
      "Batch: 1053. Acc: 0.333902. Loss: 1.907193. Batch_acc: 0.345123. Batch_loss: 1.857202 \n",
      "Batch: 1054. Acc: 0.333908. Loss: 1.907173. Batch_acc: 0.340377. Batch_loss: 1.885999 \n",
      "Batch: 1055. Acc: 0.333910. Loss: 1.907163. Batch_acc: 0.335821. Batch_loss: 1.896771 \n",
      "Batch: 1056. Acc: 0.333920. Loss: 1.907128. Batch_acc: 0.345266. Batch_loss: 1.869327 \n",
      "Batch: 1057. Acc: 0.333940. Loss: 1.907105. Batch_acc: 0.354671. Batch_loss: 1.882754 \n",
      "Batch: 1058. Acc: 0.333942. Loss: 1.907102. Batch_acc: 0.336207. Batch_loss: 1.904352 \n",
      "Batch: 1059. Acc: 0.333950. Loss: 1.907073. Batch_acc: 0.342697. Batch_loss: 1.876569 \n",
      "Batch: 1060. Acc: 0.333968. Loss: 1.907040. Batch_acc: 0.352359. Batch_loss: 1.872472 \n",
      "Batch: 1061. Acc: 0.333972. Loss: 1.907000. Batch_acc: 0.338645. Batch_loss: 1.864625 \n",
      "Batch: 1062. Acc: 0.333979. Loss: 1.906985. Batch_acc: 0.341714. Batch_loss: 1.891551 \n",
      "Batch: 1063. Acc: 0.333993. Loss: 1.906960. Batch_acc: 0.348575. Batch_loss: 1.878976 \n",
      "Batch: 1064. Acc: 0.333997. Loss: 1.906936. Batch_acc: 0.338747. Batch_loss: 1.881400 \n",
      "Batch: 1065. Acc: 0.333990. Loss: 1.906949. Batch_acc: 0.326413. Batch_loss: 1.920508 \n",
      "Batch: 1066. Acc: 0.333988. Loss: 1.906949. Batch_acc: 0.332368. Batch_loss: 1.907307 \n",
      "Batch: 1067. Acc: 0.333995. Loss: 1.906959. Batch_acc: 0.340802. Batch_loss: 1.917424 \n",
      "Batch: 1068. Acc: 0.334007. Loss: 1.906950. Batch_acc: 0.347501. Batch_loss: 1.898090 \n",
      "Batch: 1069. Acc: 0.334015. Loss: 1.906931. Batch_acc: 0.342566. Batch_loss: 1.886136 \n",
      "Batch: 1070. Acc: 0.334014. Loss: 1.906933. Batch_acc: 0.331979. Batch_loss: 1.909173 \n",
      "Batch: 1071. Acc: 0.334018. Loss: 1.906903. Batch_acc: 0.338452. Batch_loss: 1.874025 \n",
      "Batch: 1072. Acc: 0.334019. Loss: 1.906899. Batch_acc: 0.335025. Batch_loss: 1.902562 \n",
      "Batch: 1073. Acc: 0.334010. Loss: 1.906913. Batch_acc: 0.325000. Batch_loss: 1.921818 \n",
      "Batch: 1074. Acc: 0.334022. Loss: 1.906890. Batch_acc: 0.347472. Batch_loss: 1.881825 \n",
      "Batch: 1075. Acc: 0.334045. Loss: 1.906853. Batch_acc: 0.358501. Batch_loss: 1.867823 \n",
      "Batch: 1076. Acc: 0.334052. Loss: 1.906843. Batch_acc: 0.341860. Batch_loss: 1.895961 \n",
      "Batch: 1077. Acc: 0.334077. Loss: 1.906763. Batch_acc: 0.360023. Batch_loss: 1.820938 \n",
      "Batch: 1078. Acc: 0.334081. Loss: 1.906759. Batch_acc: 0.338691. Batch_loss: 1.902896 \n",
      "Batch: 1079. Acc: 0.334081. Loss: 1.906760. Batch_acc: 0.334501. Batch_loss: 1.908113 \n",
      "Batch: 1080. Acc: 0.334078. Loss: 1.906762. Batch_acc: 0.330769. Batch_loss: 1.908519 \n",
      "Batch: 1081. Acc: 0.334074. Loss: 1.906754. Batch_acc: 0.329480. Batch_loss: 1.898619 \n",
      "Batch: 1082. Acc: 0.334073. Loss: 1.906752. Batch_acc: 0.332562. Batch_loss: 1.904522 \n",
      "Batch: 1083. Acc: 0.334067. Loss: 1.906719. Batch_acc: 0.328009. Batch_loss: 1.871299 \n",
      "Batch: 1084. Acc: 0.334074. Loss: 1.906696. Batch_acc: 0.341103. Batch_loss: 1.882032 \n",
      "Batch: 1085. Acc: 0.334078. Loss: 1.906682. Batch_acc: 0.338219. Batch_loss: 1.891595 \n",
      "Batch: 1086. Acc: 0.334098. Loss: 1.906643. Batch_acc: 0.355981. Batch_loss: 1.863443 \n",
      "Batch: 1087. Acc: 0.334101. Loss: 1.906636. Batch_acc: 0.337947. Batch_loss: 1.899165 \n",
      "Batch: 1088. Acc: 0.334109. Loss: 1.906603. Batch_acc: 0.342412. Batch_loss: 1.871864 \n",
      "Batch: 1089. Acc: 0.334111. Loss: 1.906596. Batch_acc: 0.336651. Batch_loss: 1.899010 \n",
      "Batch: 1090. Acc: 0.334131. Loss: 1.906564. Batch_acc: 0.354931. Batch_loss: 1.872499 \n",
      "Batch: 1091. Acc: 0.334137. Loss: 1.906555. Batch_acc: 0.340792. Batch_loss: 1.896762 \n",
      "Batch: 1092. Acc: 0.334149. Loss: 1.906526. Batch_acc: 0.347547. Batch_loss: 1.873302 \n",
      "Batch: 1093. Acc: 0.334150. Loss: 1.906476. Batch_acc: 0.336051. Batch_loss: 1.851751 \n",
      "Batch: 1094. Acc: 0.334161. Loss: 1.906440. Batch_acc: 0.346313. Batch_loss: 1.865832 \n",
      "Batch: 1095. Acc: 0.334164. Loss: 1.906393. Batch_acc: 0.337315. Batch_loss: 1.855301 \n",
      "Batch: 1096. Acc: 0.334171. Loss: 1.906350. Batch_acc: 0.342166. Batch_loss: 1.859702 \n",
      "Batch: 1097. Acc: 0.334177. Loss: 1.906325. Batch_acc: 0.340206. Batch_loss: 1.879073 \n",
      "Batch: 1098. Acc: 0.334181. Loss: 1.906318. Batch_acc: 0.338776. Batch_loss: 1.898424 \n",
      "Batch: 1099. Acc: 0.334178. Loss: 1.906312. Batch_acc: 0.330216. Batch_loss: 1.899693 \n",
      "Batch: 1100. Acc: 0.334175. Loss: 1.906312. Batch_acc: 0.330792. Batch_loss: 1.905568 \n",
      "Batch: 1101. Acc: 0.334174. Loss: 1.906329. Batch_acc: 0.333530. Batch_loss: 1.926347 \n",
      "Batch: 1102. Acc: 0.334178. Loss: 1.906306. Batch_acc: 0.338710. Batch_loss: 1.880690 \n",
      "Batch: 1103. Acc: 0.334204. Loss: 1.906255. Batch_acc: 0.362998. Batch_loss: 1.848622 \n",
      "Batch: 1104. Acc: 0.334208. Loss: 1.906235. Batch_acc: 0.338496. Batch_loss: 1.885872 \n",
      "Batch: 1105. Acc: 0.334202. Loss: 1.906223. Batch_acc: 0.327945. Batch_loss: 1.892438 \n",
      "Batch: 1106. Acc: 0.334205. Loss: 1.906213. Batch_acc: 0.337737. Batch_loss: 1.894602 \n",
      "Batch: 1107. Acc: 0.334209. Loss: 1.906184. Batch_acc: 0.337806. Batch_loss: 1.874675 \n",
      "Batch: 1108. Acc: 0.334219. Loss: 1.906149. Batch_acc: 0.346288. Batch_loss: 1.866652 \n",
      "Batch: 1109. Acc: 0.334211. Loss: 1.906162. Batch_acc: 0.324885. Batch_loss: 1.919941 \n",
      "Batch: 1110. Acc: 0.334212. Loss: 1.906134. Batch_acc: 0.335656. Batch_loss: 1.875089 \n",
      "Batch: 1111. Acc: 0.334221. Loss: 1.906100. Batch_acc: 0.343660. Batch_loss: 1.868569 \n",
      "Batch: 1112. Acc: 0.334231. Loss: 1.906041. Batch_acc: 0.345794. Batch_loss: 1.839427 \n",
      "Batch: 1113. Acc: 0.334249. Loss: 1.906010. Batch_acc: 0.354312. Batch_loss: 1.871529 \n",
      "Batch: 1114. Acc: 0.334270. Loss: 1.905967. Batch_acc: 0.358166. Batch_loss: 1.858180 \n",
      "Batch: 1115. Acc: 0.334264. Loss: 1.905950. Batch_acc: 0.327044. Batch_loss: 1.886835 \n",
      "Batch: 1116. Acc: 0.334276. Loss: 1.905891. Batch_acc: 0.347625. Batch_loss: 1.840134 \n",
      "Batch: 1117. Acc: 0.334281. Loss: 1.905882. Batch_acc: 0.340136. Batch_loss: 1.895410 \n",
      "Batch: 1118. Acc: 0.334291. Loss: 1.905864. Batch_acc: 0.345519. Batch_loss: 1.885371 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1119. Acc: 0.334291. Loss: 1.905872. Batch_acc: 0.334699. Batch_loss: 1.914471 \n",
      "Batch: 1120. Acc: 0.334287. Loss: 1.905866. Batch_acc: 0.329708. Batch_loss: 1.899421 \n",
      "Batch: 1121. Acc: 0.334289. Loss: 1.905851. Batch_acc: 0.336374. Batch_loss: 1.889555 \n",
      "Batch: 1122. Acc: 0.334286. Loss: 1.905825. Batch_acc: 0.331451. Batch_loss: 1.876618 \n",
      "Batch: 1123. Acc: 0.334298. Loss: 1.905794. Batch_acc: 0.347093. Batch_loss: 1.870834 \n",
      "Batch: 1124. Acc: 0.334301. Loss: 1.905797. Batch_acc: 0.338615. Batch_loss: 1.909385 \n",
      "Batch: 1125. Acc: 0.334301. Loss: 1.905791. Batch_acc: 0.334282. Batch_loss: 1.899167 \n",
      "Batch: 1126. Acc: 0.334309. Loss: 1.905783. Batch_acc: 0.342873. Batch_loss: 1.896417 \n",
      "Batch: 1127. Acc: 0.334315. Loss: 1.905737. Batch_acc: 0.340792. Batch_loss: 1.854128 \n",
      "Batch: 1128. Acc: 0.334328. Loss: 1.905701. Batch_acc: 0.349109. Batch_loss: 1.866711 \n",
      "Batch: 1129. Acc: 0.334344. Loss: 1.905675. Batch_acc: 0.352338. Batch_loss: 1.877091 \n",
      "Batch: 1130. Acc: 0.334356. Loss: 1.905645. Batch_acc: 0.347698. Batch_loss: 1.870425 \n",
      "Batch: 1131. Acc: 0.334355. Loss: 1.905618. Batch_acc: 0.333139. Batch_loss: 1.874549 \n",
      "Batch: 1132. Acc: 0.334369. Loss: 1.905603. Batch_acc: 0.350528. Batch_loss: 1.888035 \n",
      "Batch: 1133. Acc: 0.334377. Loss: 1.905583. Batch_acc: 0.343292. Batch_loss: 1.882936 \n",
      "Batch: 1134. Acc: 0.334391. Loss: 1.905558. Batch_acc: 0.351009. Batch_loss: 1.877381 \n",
      "Batch: 1135. Acc: 0.334388. Loss: 1.905547. Batch_acc: 0.330435. Batch_loss: 1.892390 \n",
      "Batch: 1136. Acc: 0.334391. Loss: 1.905510. Batch_acc: 0.338506. Batch_loss: 1.863689 \n",
      "Batch: 1137. Acc: 0.334400. Loss: 1.905459. Batch_acc: 0.343856. Batch_loss: 1.849167 \n",
      "Batch: 1138. Acc: 0.334401. Loss: 1.905453. Batch_acc: 0.335284. Batch_loss: 1.898651 \n",
      "Batch: 1139. Acc: 0.334396. Loss: 1.905447. Batch_acc: 0.329412. Batch_loss: 1.897729 \n",
      "Batch: 1140. Acc: 0.334409. Loss: 1.905444. Batch_acc: 0.349280. Batch_loss: 1.901816 \n",
      "Batch: 1141. Acc: 0.334414. Loss: 1.905442. Batch_acc: 0.339369. Batch_loss: 1.903115 \n",
      "Batch: 1142. Acc: 0.334428. Loss: 1.905405. Batch_acc: 0.350432. Batch_loss: 1.863658 \n",
      "Batch: 1143. Acc: 0.334442. Loss: 1.905381. Batch_acc: 0.350917. Batch_loss: 1.878009 \n",
      "Batch: 1144. Acc: 0.334462. Loss: 1.905348. Batch_acc: 0.357724. Batch_loss: 1.867428 \n",
      "Batch: 1145. Acc: 0.334482. Loss: 1.905289. Batch_acc: 0.357390. Batch_loss: 1.837387 \n",
      "Batch: 1146. Acc: 0.334478. Loss: 1.905292. Batch_acc: 0.330052. Batch_loss: 1.908718 \n",
      "Batch: 1147. Acc: 0.334492. Loss: 1.905263. Batch_acc: 0.350515. Batch_loss: 1.872375 \n",
      "Batch: 1148. Acc: 0.334487. Loss: 1.905253. Batch_acc: 0.328217. Batch_loss: 1.892552 \n",
      "Batch: 1149. Acc: 0.334493. Loss: 1.905251. Batch_acc: 0.340883. Batch_loss: 1.903668 \n",
      "Batch: 1150. Acc: 0.334502. Loss: 1.905218. Batch_acc: 0.344649. Batch_loss: 1.867142 \n",
      "Batch: 1151. Acc: 0.334506. Loss: 1.905202. Batch_acc: 0.339110. Batch_loss: 1.886904 \n",
      "Batch: 1152. Acc: 0.334511. Loss: 1.905191. Batch_acc: 0.341156. Batch_loss: 1.892221 \n",
      "Batch: 1153. Acc: 0.334494. Loss: 1.905201. Batch_acc: 0.314252. Batch_loss: 1.917697 \n",
      "Batch: 1154. Acc: 0.334510. Loss: 1.905168. Batch_acc: 0.352436. Batch_loss: 1.867147 \n",
      "Batch: 1155. Acc: 0.334510. Loss: 1.905142. Batch_acc: 0.334668. Batch_loss: 1.874531 \n",
      "Batch: 1156. Acc: 0.334509. Loss: 1.905129. Batch_acc: 0.333718. Batch_loss: 1.891066 \n",
      "Batch: 1157. Acc: 0.334520. Loss: 1.905107. Batch_acc: 0.346466. Batch_loss: 1.878892 \n",
      "Batch: 1158. Acc: 0.334543. Loss: 1.905065. Batch_acc: 0.362059. Batch_loss: 1.856182 \n",
      "Batch: 1159. Acc: 0.334548. Loss: 1.905032. Batch_acc: 0.339450. Batch_loss: 1.867546 \n",
      "Batch: 1160. Acc: 0.334554. Loss: 1.905024. Batch_acc: 0.341676. Batch_loss: 1.895127 \n",
      "Batch: 1161. Acc: 0.334564. Loss: 1.904982. Batch_acc: 0.346066. Batch_loss: 1.857110 \n",
      "Batch: 1162. Acc: 0.334577. Loss: 1.904928. Batch_acc: 0.349242. Batch_loss: 1.843101 \n",
      "Batch: 1163. Acc: 0.334583. Loss: 1.904892. Batch_acc: 0.341851. Batch_loss: 1.863794 \n",
      "Batch: 1164. Acc: 0.334590. Loss: 1.904863. Batch_acc: 0.343345. Batch_loss: 1.869879 \n",
      "Batch: 1165. Acc: 0.334585. Loss: 1.904842. Batch_acc: 0.328459. Batch_loss: 1.881187 \n",
      "Batch: 1166. Acc: 0.334586. Loss: 1.904817. Batch_acc: 0.335280. Batch_loss: 1.875131 \n",
      "Batch: 1167. Acc: 0.334594. Loss: 1.904815. Batch_acc: 0.344148. Batch_loss: 1.902741 \n",
      "Batch: 1168. Acc: 0.334598. Loss: 1.904793. Batch_acc: 0.339795. Batch_loss: 1.878870 \n",
      "Batch: 1169. Acc: 0.334617. Loss: 1.904741. Batch_acc: 0.356527. Batch_loss: 1.844627 \n",
      "Batch: 1170. Acc: 0.334611. Loss: 1.904758. Batch_acc: 0.327677. Batch_loss: 1.924999 \n",
      "Batch: 1171. Acc: 0.334605. Loss: 1.904775. Batch_acc: 0.327794. Batch_loss: 1.924425 \n",
      "Batch: 1172. Acc: 0.334620. Loss: 1.904730. Batch_acc: 0.351799. Batch_loss: 1.852543 \n",
      "Batch: 1173. Acc: 0.334635. Loss: 1.904696. Batch_acc: 0.352299. Batch_loss: 1.864722 \n",
      "Batch: 1174. Acc: 0.334640. Loss: 1.904657. Batch_acc: 0.340155. Batch_loss: 1.860559 \n",
      "Batch: 1175. Acc: 0.334639. Loss: 1.904650. Batch_acc: 0.333148. Batch_loss: 1.896599 \n",
      "Batch: 1176. Acc: 0.334639. Loss: 1.904620. Batch_acc: 0.335025. Batch_loss: 1.870448 \n",
      "Batch: 1177. Acc: 0.334630. Loss: 1.904613. Batch_acc: 0.324069. Batch_loss: 1.895962 \n",
      "Batch: 1178. Acc: 0.334636. Loss: 1.904612. Batch_acc: 0.341643. Batch_loss: 1.903304 \n",
      "Batch: 1179. Acc: 0.334640. Loss: 1.904600. Batch_acc: 0.338738. Batch_loss: 1.890085 \n",
      "Batch: 1180. Acc: 0.334656. Loss: 1.904577. Batch_acc: 0.353952. Batch_loss: 1.877506 \n",
      "Batch: 1181. Acc: 0.334656. Loss: 1.904578. Batch_acc: 0.334652. Batch_loss: 1.905579 \n",
      "Batch: 1182. Acc: 0.334665. Loss: 1.904548. Batch_acc: 0.344847. Batch_loss: 1.870084 \n",
      "Batch: 1183. Acc: 0.334672. Loss: 1.904516. Batch_acc: 0.342677. Batch_loss: 1.866397 \n",
      "Batch: 1184. Acc: 0.334676. Loss: 1.904515. Batch_acc: 0.340083. Batch_loss: 1.902787 \n",
      "Batch: 1185. Acc: 0.334690. Loss: 1.904495. Batch_acc: 0.350657. Batch_loss: 1.880838 \n",
      "Batch: 1186. Acc: 0.334687. Loss: 1.904509. Batch_acc: 0.331432. Batch_loss: 1.922025 \n",
      "Batch: 1187. Acc: 0.334681. Loss: 1.904514. Batch_acc: 0.327327. Batch_loss: 1.910299 \n",
      "Batch: 1188. Acc: 0.334688. Loss: 1.904480. Batch_acc: 0.343096. Batch_loss: 1.862456 \n",
      "Batch: 1189. Acc: 0.334697. Loss: 1.904423. Batch_acc: 0.345869. Batch_loss: 1.837255 \n",
      "Batch: 1190. Acc: 0.334693. Loss: 1.904401. Batch_acc: 0.330023. Batch_loss: 1.877410 \n",
      "Batch: 1191. Acc: 0.334690. Loss: 1.904392. Batch_acc: 0.330450. Batch_loss: 1.893811 \n",
      "Batch: 1192. Acc: 0.334696. Loss: 1.904364. Batch_acc: 0.341477. Batch_loss: 1.871403 \n",
      "Batch: 1193. Acc: 0.334696. Loss: 1.904331. Batch_acc: 0.335060. Batch_loss: 1.865015 \n",
      "Batch: 1194. Acc: 0.334691. Loss: 1.904320. Batch_acc: 0.329303. Batch_loss: 1.891704 \n",
      "Batch: 1195. Acc: 0.334707. Loss: 1.904271. Batch_acc: 0.354034. Batch_loss: 1.845267 \n",
      "Batch: 1196. Acc: 0.334715. Loss: 1.904253. Batch_acc: 0.344394. Batch_loss: 1.882742 \n",
      "Batch: 1197. Acc: 0.334720. Loss: 1.904228. Batch_acc: 0.340012. Batch_loss: 1.872771 \n",
      "Batch: 1198. Acc: 0.334717. Loss: 1.904200. Batch_acc: 0.331535. Batch_loss: 1.869773 \n",
      "Batch: 1199. Acc: 0.334723. Loss: 1.904164. Batch_acc: 0.341969. Batch_loss: 1.860609 \n",
      "Batch: 1200. Acc: 0.334727. Loss: 1.904129. Batch_acc: 0.339031. Batch_loss: 1.862790 \n",
      "Batch: 1201. Acc: 0.334730. Loss: 1.904119. Batch_acc: 0.338004. Batch_loss: 1.892223 \n",
      "Batch: 1202. Acc: 0.334739. Loss: 1.904102. Batch_acc: 0.346132. Batch_loss: 1.884012 \n",
      "Batch: 1203. Acc: 0.334753. Loss: 1.904039. Batch_acc: 0.350809. Batch_loss: 1.830078 \n",
      "Batch: 1204. Acc: 0.334764. Loss: 1.903997. Batch_acc: 0.348219. Batch_loss: 1.854095 \n",
      "Batch: 1205. Acc: 0.334761. Loss: 1.903995. Batch_acc: 0.330641. Batch_loss: 1.901580 \n",
      "Batch: 1206. Acc: 0.334783. Loss: 1.903917. Batch_acc: 0.360647. Batch_loss: 1.813306 \n",
      "Batch: 1207. Acc: 0.334789. Loss: 1.903909. Batch_acc: 0.342137. Batch_loss: 1.893722 \n",
      "Batch: 1208. Acc: 0.334791. Loss: 1.903884. Batch_acc: 0.337633. Batch_loss: 1.874249 \n",
      "Batch: 1209. Acc: 0.334791. Loss: 1.903884. Batch_acc: 0.334108. Batch_loss: 1.904119 \n",
      "Batch: 1210. Acc: 0.334789. Loss: 1.903885. Batch_acc: 0.332566. Batch_loss: 1.905518 \n",
      "Batch: 1211. Acc: 0.334795. Loss: 1.903871. Batch_acc: 0.342426. Batch_loss: 1.886089 \n",
      "Batch: 1212. Acc: 0.334798. Loss: 1.903843. Batch_acc: 0.337729. Batch_loss: 1.870085 \n",
      "Batch: 1213. Acc: 0.334792. Loss: 1.903826. Batch_acc: 0.327954. Batch_loss: 1.883082 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1214. Acc: 0.334802. Loss: 1.903782. Batch_acc: 0.346996. Batch_loss: 1.851814 \n",
      "Batch: 1215. Acc: 0.334821. Loss: 1.903726. Batch_acc: 0.357383. Batch_loss: 1.837252 \n",
      "Batch: 1216. Acc: 0.334819. Loss: 1.903727. Batch_acc: 0.331594. Batch_loss: 1.905007 \n",
      "Batch: 1217. Acc: 0.334822. Loss: 1.903714. Batch_acc: 0.338924. Batch_loss: 1.888791 \n",
      "Batch: 1218. Acc: 0.334840. Loss: 1.903681. Batch_acc: 0.356125. Batch_loss: 1.863760 \n",
      "Batch: 1219. Acc: 0.334834. Loss: 1.903678. Batch_acc: 0.328014. Batch_loss: 1.900044 \n",
      "Batch: 1220. Acc: 0.334845. Loss: 1.903635. Batch_acc: 0.348432. Batch_loss: 1.850587 \n",
      "Batch: 1221. Acc: 0.334845. Loss: 1.903599. Batch_acc: 0.335028. Batch_loss: 1.860498 \n",
      "Batch: 1222. Acc: 0.334854. Loss: 1.903570. Batch_acc: 0.345003. Batch_loss: 1.868504 \n",
      "Batch: 1223. Acc: 0.334875. Loss: 1.903551. Batch_acc: 0.360517. Batch_loss: 1.880595 \n",
      "Batch: 1224. Acc: 0.334871. Loss: 1.903534. Batch_acc: 0.329532. Batch_loss: 1.883205 \n",
      "Batch: 1225. Acc: 0.334873. Loss: 1.903515. Batch_acc: 0.337939. Batch_loss: 1.879743 \n",
      "Batch: 1226. Acc: 0.334890. Loss: 1.903476. Batch_acc: 0.355864. Batch_loss: 1.855965 \n",
      "Batch: 1227. Acc: 0.334890. Loss: 1.903452. Batch_acc: 0.333716. Batch_loss: 1.873202 \n",
      "Batch: 1228. Acc: 0.334904. Loss: 1.903416. Batch_acc: 0.352975. Batch_loss: 1.859027 \n",
      "Batch: 1229. Acc: 0.334905. Loss: 1.903406. Batch_acc: 0.335923. Batch_loss: 1.891423 \n",
      "Batch: 1230. Acc: 0.334916. Loss: 1.903354. Batch_acc: 0.347850. Batch_loss: 1.841713 \n",
      "Batch: 1231. Acc: 0.334916. Loss: 1.903335. Batch_acc: 0.335040. Batch_loss: 1.879071 \n",
      "Batch: 1232. Acc: 0.334933. Loss: 1.903291. Batch_acc: 0.355807. Batch_loss: 1.850385 \n",
      "Batch: 1233. Acc: 0.334942. Loss: 1.903256. Batch_acc: 0.346176. Batch_loss: 1.859686 \n",
      "Batch: 1234. Acc: 0.334950. Loss: 1.903234. Batch_acc: 0.344646. Batch_loss: 1.875985 \n",
      "Batch: 1235. Acc: 0.334956. Loss: 1.903206. Batch_acc: 0.341957. Batch_loss: 1.869340 \n",
      "Batch: 1236. Acc: 0.334956. Loss: 1.903189. Batch_acc: 0.335640. Batch_loss: 1.882607 \n",
      "Batch: 1237. Acc: 0.334955. Loss: 1.903172. Batch_acc: 0.333908. Batch_loss: 1.882533 \n",
      "Batch: 1238. Acc: 0.334955. Loss: 1.903182. Batch_acc: 0.334503. Batch_loss: 1.915482 \n",
      "Batch: 1239. Acc: 0.334959. Loss: 1.903176. Batch_acc: 0.339755. Batch_loss: 1.894816 \n",
      "Batch: 1240. Acc: 0.334970. Loss: 1.903132. Batch_acc: 0.348340. Batch_loss: 1.850085 \n",
      "Batch: 1241. Acc: 0.334978. Loss: 1.903099. Batch_acc: 0.344671. Batch_loss: 1.862470 \n",
      "Batch: 1242. Acc: 0.334990. Loss: 1.903065. Batch_acc: 0.349598. Batch_loss: 1.861261 \n",
      "Batch: 1243. Acc: 0.335003. Loss: 1.903032. Batch_acc: 0.351680. Batch_loss: 1.862045 \n",
      "Batch: 1244. Acc: 0.335011. Loss: 1.903035. Batch_acc: 0.345107. Batch_loss: 1.906010 \n",
      "Batch: 1245. Acc: 0.335018. Loss: 1.903026. Batch_acc: 0.343087. Batch_loss: 1.892975 \n",
      "Batch: 1246. Acc: 0.335024. Loss: 1.903004. Batch_acc: 0.342625. Batch_loss: 1.875209 \n",
      "Batch: 1247. Acc: 0.335017. Loss: 1.902994. Batch_acc: 0.327242. Batch_loss: 1.890150 \n",
      "Batch: 1248. Acc: 0.335017. Loss: 1.902979. Batch_acc: 0.334884. Batch_loss: 1.883736 \n",
      "Batch: 1249. Acc: 0.335038. Loss: 1.902939. Batch_acc: 0.361175. Batch_loss: 1.853204 \n",
      "Batch: 1250. Acc: 0.335048. Loss: 1.902904. Batch_acc: 0.347032. Batch_loss: 1.859884 \n",
      "Batch: 1251. Acc: 0.335059. Loss: 1.902894. Batch_acc: 0.348732. Batch_loss: 1.890844 \n",
      "Batch: 1252. Acc: 0.335075. Loss: 1.902845. Batch_acc: 0.355301. Batch_loss: 1.841883 \n",
      "Batch: 1253. Acc: 0.335071. Loss: 1.902825. Batch_acc: 0.329352. Batch_loss: 1.877378 \n",
      "Batch: 1254. Acc: 0.335067. Loss: 1.902817. Batch_acc: 0.330286. Batch_loss: 1.893045 \n",
      "Batch: 1255. Acc: 0.335078. Loss: 1.902787. Batch_acc: 0.348946. Batch_loss: 1.864347 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.33507757700090574. Loss per char: 1.9027869732583744. Time: 1627207403.7323294\n",
      "Last question is tensor([ 2, 18, 18, 21, 22, 15, 18, 19, 20, 23, 18, 24,  1, 12,  1, 14, 19, 21,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.335078. Loss: 1.902782. Batch_acc: 0.335758. Batch_loss: 1.897145 \n",
      "Batch: 1257. Acc: 0.335086. Loss: 1.902760. Batch_acc: 0.345361. Batch_loss: 1.875138 \n",
      "Batch: 1258. Acc: 0.335087. Loss: 1.902739. Batch_acc: 0.336411. Batch_loss: 1.876423 \n",
      "Batch: 1259. Acc: 0.335096. Loss: 1.902716. Batch_acc: 0.346558. Batch_loss: 1.872851 \n",
      "Batch: 1260. Acc: 0.335101. Loss: 1.902717. Batch_acc: 0.340883. Batch_loss: 1.904336 \n",
      "Batch: 1261. Acc: 0.335115. Loss: 1.902673. Batch_acc: 0.352673. Batch_loss: 1.847790 \n",
      "Batch: 1262. Acc: 0.335122. Loss: 1.902640. Batch_acc: 0.343641. Batch_loss: 1.859612 \n",
      "Batch: 1263. Acc: 0.335114. Loss: 1.902651. Batch_acc: 0.325392. Batch_loss: 1.916962 \n",
      "Batch: 1264. Acc: 0.335101. Loss: 1.902659. Batch_acc: 0.318775. Batch_loss: 1.913331 \n",
      "Batch: 1265. Acc: 0.335104. Loss: 1.902647. Batch_acc: 0.338355. Batch_loss: 1.886994 \n",
      "Batch: 1266. Acc: 0.335094. Loss: 1.902683. Batch_acc: 0.322216. Batch_loss: 1.949827 \n",
      "Batch: 1267. Acc: 0.335098. Loss: 1.902669. Batch_acc: 0.340247. Batch_loss: 1.885019 \n",
      "Batch: 1268. Acc: 0.335098. Loss: 1.902654. Batch_acc: 0.334701. Batch_loss: 1.883661 \n",
      "Batch: 1269. Acc: 0.335099. Loss: 1.902639. Batch_acc: 0.337288. Batch_loss: 1.883724 \n",
      "Batch: 1270. Acc: 0.335100. Loss: 1.902614. Batch_acc: 0.336070. Batch_loss: 1.870497 \n",
      "Batch: 1271. Acc: 0.335100. Loss: 1.902594. Batch_acc: 0.335052. Batch_loss: 1.877118 \n",
      "Batch: 1272. Acc: 0.335102. Loss: 1.902564. Batch_acc: 0.337915. Batch_loss: 1.864335 \n",
      "Batch: 1273. Acc: 0.335122. Loss: 1.902526. Batch_acc: 0.360580. Batch_loss: 1.853889 \n",
      "Batch: 1274. Acc: 0.335124. Loss: 1.902526. Batch_acc: 0.337209. Batch_loss: 1.902715 \n",
      "Batch: 1275. Acc: 0.335124. Loss: 1.902530. Batch_acc: 0.334701. Batch_loss: 1.907867 \n",
      "Batch: 1276. Acc: 0.335118. Loss: 1.902526. Batch_acc: 0.327516. Batch_loss: 1.897016 \n",
      "Batch: 1277. Acc: 0.335123. Loss: 1.902521. Batch_acc: 0.342301. Batch_loss: 1.896848 \n",
      "Batch: 1278. Acc: 0.335122. Loss: 1.902505. Batch_acc: 0.332944. Batch_loss: 1.880700 \n",
      "Batch: 1279. Acc: 0.335122. Loss: 1.902497. Batch_acc: 0.335652. Batch_loss: 1.892233 \n",
      "Batch: 1280. Acc: 0.335144. Loss: 1.902456. Batch_acc: 0.363065. Batch_loss: 1.851149 \n",
      "Batch: 1281. Acc: 0.335142. Loss: 1.902446. Batch_acc: 0.332554. Batch_loss: 1.888861 \n",
      "Batch: 1282. Acc: 0.335140. Loss: 1.902446. Batch_acc: 0.332544. Batch_loss: 1.902870 \n",
      "Batch: 1283. Acc: 0.335149. Loss: 1.902414. Batch_acc: 0.346154. Batch_loss: 1.860798 \n",
      "Batch: 1284. Acc: 0.335163. Loss: 1.902371. Batch_acc: 0.353907. Batch_loss: 1.848057 \n",
      "Batch: 1285. Acc: 0.335182. Loss: 1.902344. Batch_acc: 0.359062. Batch_loss: 1.868133 \n",
      "Batch: 1286. Acc: 0.335199. Loss: 1.902319. Batch_acc: 0.356125. Batch_loss: 1.871087 \n",
      "Batch: 1287. Acc: 0.335198. Loss: 1.902317. Batch_acc: 0.334499. Batch_loss: 1.899664 \n",
      "Batch: 1288. Acc: 0.335208. Loss: 1.902284. Batch_acc: 0.348144. Batch_loss: 1.859935 \n",
      "Batch: 1289. Acc: 0.335207. Loss: 1.902253. Batch_acc: 0.333914. Batch_loss: 1.862473 \n",
      "Batch: 1290. Acc: 0.335216. Loss: 1.902223. Batch_acc: 0.345996. Batch_loss: 1.862364 \n",
      "Batch: 1291. Acc: 0.335223. Loss: 1.902212. Batch_acc: 0.345486. Batch_loss: 1.888829 \n",
      "Batch: 1292. Acc: 0.335229. Loss: 1.902206. Batch_acc: 0.342571. Batch_loss: 1.894015 \n",
      "Batch: 1293. Acc: 0.335234. Loss: 1.902189. Batch_acc: 0.342151. Batch_loss: 1.880571 \n",
      "Batch: 1294. Acc: 0.335241. Loss: 1.902171. Batch_acc: 0.343192. Batch_loss: 1.878484 \n",
      "Batch: 1295. Acc: 0.335257. Loss: 1.902136. Batch_acc: 0.357017. Batch_loss: 1.856602 \n",
      "Batch: 1296. Acc: 0.335272. Loss: 1.902097. Batch_acc: 0.353820. Batch_loss: 1.851326 \n",
      "Batch: 1297. Acc: 0.335278. Loss: 1.902078. Batch_acc: 0.343897. Batch_loss: 1.876742 \n",
      "Batch: 1298. Acc: 0.335283. Loss: 1.902055. Batch_acc: 0.341590. Batch_loss: 1.872690 \n",
      "Batch: 1299. Acc: 0.335283. Loss: 1.902033. Batch_acc: 0.335838. Batch_loss: 1.872509 \n",
      "Batch: 1300. Acc: 0.335282. Loss: 1.902005. Batch_acc: 0.333141. Batch_loss: 1.866712 \n",
      "Batch: 1301. Acc: 0.335283. Loss: 1.901986. Batch_acc: 0.337079. Batch_loss: 1.877606 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1302. Acc: 0.335282. Loss: 1.901986. Batch_acc: 0.334109. Batch_loss: 1.901842 \n",
      "Batch: 1303. Acc: 0.335294. Loss: 1.901968. Batch_acc: 0.350497. Batch_loss: 1.878356 \n",
      "Batch: 1304. Acc: 0.335301. Loss: 1.901937. Batch_acc: 0.344413. Batch_loss: 1.860917 \n",
      "Batch: 1305. Acc: 0.335309. Loss: 1.901908. Batch_acc: 0.345873. Batch_loss: 1.865904 \n",
      "Batch: 1306. Acc: 0.335327. Loss: 1.901855. Batch_acc: 0.358200. Batch_loss: 1.832853 \n",
      "Batch: 1307. Acc: 0.335333. Loss: 1.901838. Batch_acc: 0.344018. Batch_loss: 1.879253 \n",
      "Batch: 1308. Acc: 0.335334. Loss: 1.901834. Batch_acc: 0.336000. Batch_loss: 1.897500 \n",
      "Batch: 1309. Acc: 0.335327. Loss: 1.901828. Batch_acc: 0.326565. Batch_loss: 1.893414 \n",
      "Batch: 1310. Acc: 0.335335. Loss: 1.901807. Batch_acc: 0.345361. Batch_loss: 1.874863 \n",
      "Batch: 1311. Acc: 0.335340. Loss: 1.901767. Batch_acc: 0.342497. Batch_loss: 1.849722 \n",
      "Batch: 1312. Acc: 0.335353. Loss: 1.901730. Batch_acc: 0.352604. Batch_loss: 1.853035 \n",
      "Batch: 1313. Acc: 0.335358. Loss: 1.901710. Batch_acc: 0.341072. Batch_loss: 1.876644 \n",
      "Batch: 1314. Acc: 0.335363. Loss: 1.901697. Batch_acc: 0.341779. Batch_loss: 1.884467 \n",
      "Batch: 1315. Acc: 0.335373. Loss: 1.901667. Batch_acc: 0.348931. Batch_loss: 1.862812 \n",
      "Batch: 1316. Acc: 0.335375. Loss: 1.901653. Batch_acc: 0.338076. Batch_loss: 1.883259 \n",
      "Batch: 1317. Acc: 0.335391. Loss: 1.901611. Batch_acc: 0.355293. Batch_loss: 1.847386 \n",
      "Batch: 1318. Acc: 0.335396. Loss: 1.901593. Batch_acc: 0.342474. Batch_loss: 1.877409 \n",
      "Batch: 1319. Acc: 0.335389. Loss: 1.901590. Batch_acc: 0.325973. Batch_loss: 1.898276 \n",
      "Batch: 1320. Acc: 0.335398. Loss: 1.901566. Batch_acc: 0.346974. Batch_loss: 1.869249 \n",
      "Batch: 1321. Acc: 0.335412. Loss: 1.901532. Batch_acc: 0.353900. Batch_loss: 1.855826 \n",
      "Batch: 1322. Acc: 0.335414. Loss: 1.901513. Batch_acc: 0.338905. Batch_loss: 1.876460 \n",
      "Batch: 1323. Acc: 0.335415. Loss: 1.901498. Batch_acc: 0.336197. Batch_loss: 1.882405 \n",
      "Batch: 1324. Acc: 0.335428. Loss: 1.901482. Batch_acc: 0.353009. Batch_loss: 1.880056 \n",
      "Batch: 1325. Acc: 0.335431. Loss: 1.901441. Batch_acc: 0.338810. Batch_loss: 1.847335 \n",
      "Batch: 1326. Acc: 0.335428. Loss: 1.901431. Batch_acc: 0.331972. Batch_loss: 1.889033 \n",
      "Batch: 1327. Acc: 0.335437. Loss: 1.901403. Batch_acc: 0.346575. Batch_loss: 1.863623 \n",
      "Batch: 1328. Acc: 0.335445. Loss: 1.901394. Batch_acc: 0.346512. Batch_loss: 1.889319 \n",
      "Batch: 1329. Acc: 0.335447. Loss: 1.901394. Batch_acc: 0.338710. Batch_loss: 1.901835 \n",
      "Batch: 1330. Acc: 0.335454. Loss: 1.901383. Batch_acc: 0.344301. Batch_loss: 1.886670 \n",
      "Batch: 1331. Acc: 0.335456. Loss: 1.901373. Batch_acc: 0.338068. Batch_loss: 1.887588 \n",
      "Batch: 1332. Acc: 0.335450. Loss: 1.901372. Batch_acc: 0.327916. Batch_loss: 1.899700 \n",
      "Batch: 1333. Acc: 0.335452. Loss: 1.901354. Batch_acc: 0.338167. Batch_loss: 1.878118 \n",
      "Batch: 1334. Acc: 0.335455. Loss: 1.901349. Batch_acc: 0.338691. Batch_loss: 1.893450 \n",
      "Batch: 1335. Acc: 0.335467. Loss: 1.901316. Batch_acc: 0.352169. Batch_loss: 1.858084 \n",
      "Batch: 1336. Acc: 0.335473. Loss: 1.901277. Batch_acc: 0.342973. Batch_loss: 1.849346 \n",
      "Batch: 1337. Acc: 0.335466. Loss: 1.901264. Batch_acc: 0.326212. Batch_loss: 1.884070 \n",
      "Batch: 1338. Acc: 0.335472. Loss: 1.901215. Batch_acc: 0.343822. Batch_loss: 1.835680 \n",
      "Batch: 1339. Acc: 0.335489. Loss: 1.901172. Batch_acc: 0.357381. Batch_loss: 1.845156 \n",
      "Batch: 1340. Acc: 0.335488. Loss: 1.901155. Batch_acc: 0.334332. Batch_loss: 1.878006 \n",
      "Batch: 1341. Acc: 0.335502. Loss: 1.901116. Batch_acc: 0.353443. Batch_loss: 1.849743 \n",
      "Batch: 1342. Acc: 0.335509. Loss: 1.901105. Batch_acc: 0.344746. Batch_loss: 1.884966 \n",
      "Batch: 1343. Acc: 0.335526. Loss: 1.901076. Batch_acc: 0.358752. Batch_loss: 1.862151 \n",
      "Batch: 1344. Acc: 0.335538. Loss: 1.901026. Batch_acc: 0.351580. Batch_loss: 1.835523 \n",
      "Batch: 1345. Acc: 0.335554. Loss: 1.900981. Batch_acc: 0.357225. Batch_loss: 1.840048 \n",
      "Batch: 1346. Acc: 0.335565. Loss: 1.900965. Batch_acc: 0.349683. Batch_loss: 1.879116 \n",
      "Batch: 1347. Acc: 0.335573. Loss: 1.900939. Batch_acc: 0.346847. Batch_loss: 1.867854 \n",
      "Batch: 1348. Acc: 0.335577. Loss: 1.900915. Batch_acc: 0.340302. Batch_loss: 1.867311 \n",
      "Batch: 1349. Acc: 0.335570. Loss: 1.900923. Batch_acc: 0.326946. Batch_loss: 1.913188 \n",
      "Batch: 1350. Acc: 0.335568. Loss: 1.900917. Batch_acc: 0.331813. Batch_loss: 1.891680 \n",
      "Batch: 1351. Acc: 0.335574. Loss: 1.900889. Batch_acc: 0.344726. Batch_loss: 1.862879 \n",
      "Batch: 1352. Acc: 0.335582. Loss: 1.900881. Batch_acc: 0.346198. Batch_loss: 1.890633 \n",
      "Batch: 1353. Acc: 0.335574. Loss: 1.900902. Batch_acc: 0.323669. Batch_loss: 1.929325 \n",
      "Batch: 1354. Acc: 0.335575. Loss: 1.900903. Batch_acc: 0.337798. Batch_loss: 1.902699 \n",
      "Batch: 1355. Acc: 0.335586. Loss: 1.900879. Batch_acc: 0.349916. Batch_loss: 1.869531 \n",
      "Batch: 1356. Acc: 0.335589. Loss: 1.900847. Batch_acc: 0.339806. Batch_loss: 1.857584 \n",
      "Batch: 1357. Acc: 0.335599. Loss: 1.900819. Batch_acc: 0.348321. Batch_loss: 1.862479 \n",
      "Batch: 1358. Acc: 0.335601. Loss: 1.900780. Batch_acc: 0.339235. Batch_loss: 1.848946 \n",
      "Batch: 1359. Acc: 0.335620. Loss: 1.900750. Batch_acc: 0.360438. Batch_loss: 1.859199 \n",
      "Batch: 1360. Acc: 0.335621. Loss: 1.900746. Batch_acc: 0.337039. Batch_loss: 1.895697 \n",
      "Batch: 1361. Acc: 0.335626. Loss: 1.900729. Batch_acc: 0.342520. Batch_loss: 1.878694 \n",
      "Batch: 1362. Acc: 0.335644. Loss: 1.900680. Batch_acc: 0.360315. Batch_loss: 1.834572 \n",
      "Batch: 1363. Acc: 0.335655. Loss: 1.900653. Batch_acc: 0.349882. Batch_loss: 1.862983 \n",
      "Batch: 1364. Acc: 0.335658. Loss: 1.900606. Batch_acc: 0.340559. Batch_loss: 1.837254 \n",
      "Batch: 1365. Acc: 0.335662. Loss: 1.900597. Batch_acc: 0.341184. Batch_loss: 1.887531 \n",
      "Batch: 1366. Acc: 0.335665. Loss: 1.900578. Batch_acc: 0.340095. Batch_loss: 1.874462 \n",
      "Batch: 1367. Acc: 0.335685. Loss: 1.900537. Batch_acc: 0.363010. Batch_loss: 1.844248 \n",
      "Batch: 1368. Acc: 0.335688. Loss: 1.900525. Batch_acc: 0.339966. Batch_loss: 1.883580 \n",
      "Batch: 1369. Acc: 0.335695. Loss: 1.900515. Batch_acc: 0.344726. Batch_loss: 1.886895 \n",
      "Batch: 1370. Acc: 0.335697. Loss: 1.900520. Batch_acc: 0.338682. Batch_loss: 1.906894 \n",
      "Batch: 1371. Acc: 0.335704. Loss: 1.900478. Batch_acc: 0.344988. Batch_loss: 1.842521 \n",
      "Batch: 1372. Acc: 0.335717. Loss: 1.900430. Batch_acc: 0.353330. Batch_loss: 1.837108 \n",
      "Batch: 1373. Acc: 0.335725. Loss: 1.900414. Batch_acc: 0.346286. Batch_loss: 1.878488 \n",
      "Batch: 1374. Acc: 0.335718. Loss: 1.900418. Batch_acc: 0.326627. Batch_loss: 1.906903 \n",
      "Batch: 1375. Acc: 0.335729. Loss: 1.900386. Batch_acc: 0.350114. Batch_loss: 1.857072 \n",
      "Batch: 1376. Acc: 0.335729. Loss: 1.900366. Batch_acc: 0.336192. Batch_loss: 1.873069 \n",
      "Batch: 1377. Acc: 0.335727. Loss: 1.900363. Batch_acc: 0.332750. Batch_loss: 1.895716 \n",
      "Batch: 1378. Acc: 0.335728. Loss: 1.900317. Batch_acc: 0.336583. Batch_loss: 1.836995 \n",
      "Batch: 1379. Acc: 0.335727. Loss: 1.900318. Batch_acc: 0.334459. Batch_loss: 1.901627 \n",
      "Batch: 1380. Acc: 0.335734. Loss: 1.900292. Batch_acc: 0.345046. Batch_loss: 1.864354 \n",
      "Batch: 1381. Acc: 0.335741. Loss: 1.900253. Batch_acc: 0.346265. Batch_loss: 1.845575 \n",
      "Batch: 1382. Acc: 0.335747. Loss: 1.900205. Batch_acc: 0.344406. Batch_loss: 1.833014 \n",
      "Batch: 1383. Acc: 0.335760. Loss: 1.900180. Batch_acc: 0.353276. Batch_loss: 1.866097 \n",
      "Batch: 1384. Acc: 0.335764. Loss: 1.900167. Batch_acc: 0.340512. Batch_loss: 1.881730 \n",
      "Batch: 1385. Acc: 0.335773. Loss: 1.900141. Batch_acc: 0.349133. Batch_loss: 1.863929 \n",
      "Batch: 1386. Acc: 0.335782. Loss: 1.900102. Batch_acc: 0.348148. Batch_loss: 1.847130 \n",
      "Batch: 1387. Acc: 0.335787. Loss: 1.900066. Batch_acc: 0.342466. Batch_loss: 1.850947 \n",
      "Batch: 1388. Acc: 0.335795. Loss: 1.900045. Batch_acc: 0.347750. Batch_loss: 1.869974 \n",
      "Batch: 1389. Acc: 0.335805. Loss: 1.900024. Batch_acc: 0.348997. Batch_loss: 1.871457 \n",
      "Batch: 1390. Acc: 0.335818. Loss: 1.899983. Batch_acc: 0.354322. Batch_loss: 1.842778 \n",
      "Batch: 1391. Acc: 0.335831. Loss: 1.899946. Batch_acc: 0.353594. Batch_loss: 1.847323 \n",
      "Batch: 1392. Acc: 0.335834. Loss: 1.899891. Batch_acc: 0.340079. Batch_loss: 1.825894 \n",
      "Batch: 1393. Acc: 0.335838. Loss: 1.899869. Batch_acc: 0.341183. Batch_loss: 1.868860 \n",
      "Batch: 1394. Acc: 0.335845. Loss: 1.899842. Batch_acc: 0.345700. Batch_loss: 1.862755 \n",
      "Batch: 1395. Acc: 0.335840. Loss: 1.899827. Batch_acc: 0.328454. Batch_loss: 1.878355 \n",
      "Batch: 1396. Acc: 0.335839. Loss: 1.899823. Batch_acc: 0.334886. Batch_loss: 1.894135 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1397. Acc: 0.335838. Loss: 1.899799. Batch_acc: 0.334268. Batch_loss: 1.867260 \n",
      "Batch: 1398. Acc: 0.335844. Loss: 1.899774. Batch_acc: 0.344868. Batch_loss: 1.864260 \n",
      "Batch: 1399. Acc: 0.335858. Loss: 1.899756. Batch_acc: 0.354706. Batch_loss: 1.874358 \n",
      "Batch: 1400. Acc: 0.335872. Loss: 1.899716. Batch_acc: 0.355644. Batch_loss: 1.844337 \n",
      "Batch: 1401. Acc: 0.335887. Loss: 1.899666. Batch_acc: 0.356380. Batch_loss: 1.831468 \n",
      "Batch: 1402. Acc: 0.335891. Loss: 1.899643. Batch_acc: 0.341449. Batch_loss: 1.867094 \n",
      "Batch: 1403. Acc: 0.335889. Loss: 1.899626. Batch_acc: 0.332757. Batch_loss: 1.875658 \n",
      "Batch: 1404. Acc: 0.335897. Loss: 1.899593. Batch_acc: 0.348178. Batch_loss: 1.852709 \n",
      "Batch: 1405. Acc: 0.335907. Loss: 1.899572. Batch_acc: 0.350145. Batch_loss: 1.870960 \n",
      "Batch: 1406. Acc: 0.335913. Loss: 1.899552. Batch_acc: 0.343275. Batch_loss: 1.871660 \n",
      "Batch: 1407. Acc: 0.335926. Loss: 1.899468. Batch_acc: 0.354167. Batch_loss: 1.783161 \n",
      "Batch: 1408. Acc: 0.335932. Loss: 1.899462. Batch_acc: 0.343660. Batch_loss: 1.892025 \n",
      "Batch: 1409. Acc: 0.335942. Loss: 1.899433. Batch_acc: 0.350492. Batch_loss: 1.858095 \n",
      "Batch: 1410. Acc: 0.335941. Loss: 1.899407. Batch_acc: 0.334458. Batch_loss: 1.863072 \n",
      "Batch: 1411. Acc: 0.335956. Loss: 1.899370. Batch_acc: 0.358032. Batch_loss: 1.845167 \n",
      "Batch: 1412. Acc: 0.335956. Loss: 1.899332. Batch_acc: 0.335787. Batch_loss: 1.847269 \n",
      "Batch: 1413. Acc: 0.335954. Loss: 1.899337. Batch_acc: 0.332753. Batch_loss: 1.906910 \n",
      "Batch: 1414. Acc: 0.335982. Loss: 1.899272. Batch_acc: 0.374719. Batch_loss: 1.809005 \n",
      "Batch: 1415. Acc: 0.335999. Loss: 1.899250. Batch_acc: 0.360182. Batch_loss: 1.867863 \n",
      "Batch: 1416. Acc: 0.335996. Loss: 1.899255. Batch_acc: 0.331805. Batch_loss: 1.906709 \n",
      "Batch: 1417. Acc: 0.335997. Loss: 1.899229. Batch_acc: 0.337230. Batch_loss: 1.861762 \n",
      "Batch: 1418. Acc: 0.336012. Loss: 1.899198. Batch_acc: 0.357020. Batch_loss: 1.855741 \n",
      "Batch: 1419. Acc: 0.336010. Loss: 1.899160. Batch_acc: 0.334101. Batch_loss: 1.845699 \n",
      "Batch: 1420. Acc: 0.336017. Loss: 1.899144. Batch_acc: 0.346359. Batch_loss: 1.875799 \n",
      "Batch: 1421. Acc: 0.336021. Loss: 1.899127. Batch_acc: 0.341576. Batch_loss: 1.874707 \n",
      "Batch: 1422. Acc: 0.336035. Loss: 1.899077. Batch_acc: 0.355182. Batch_loss: 1.830047 \n",
      "Batch: 1423. Acc: 0.336032. Loss: 1.899071. Batch_acc: 0.331958. Batch_loss: 1.890404 \n",
      "Batch: 1424. Acc: 0.336044. Loss: 1.899039. Batch_acc: 0.352234. Batch_loss: 1.853201 \n",
      "Batch: 1425. Acc: 0.336039. Loss: 1.899040. Batch_acc: 0.329885. Batch_loss: 1.899928 \n",
      "Batch: 1426. Acc: 0.336047. Loss: 1.899032. Batch_acc: 0.346375. Batch_loss: 1.888735 \n",
      "Batch: 1427. Acc: 0.336046. Loss: 1.899005. Batch_acc: 0.335211. Batch_loss: 1.860713 \n",
      "Batch: 1428. Acc: 0.336041. Loss: 1.898984. Batch_acc: 0.328514. Batch_loss: 1.869359 \n",
      "Batch: 1429. Acc: 0.336057. Loss: 1.898940. Batch_acc: 0.359251. Batch_loss: 1.836169 \n",
      "Batch: 1430. Acc: 0.336063. Loss: 1.898925. Batch_acc: 0.344301. Batch_loss: 1.877107 \n",
      "Batch: 1431. Acc: 0.336062. Loss: 1.898908. Batch_acc: 0.334701. Batch_loss: 1.874606 \n",
      "Batch: 1432. Acc: 0.336058. Loss: 1.898883. Batch_acc: 0.329843. Batch_loss: 1.862156 \n",
      "Batch: 1433. Acc: 0.336060. Loss: 1.898860. Batch_acc: 0.339326. Batch_loss: 1.867118 \n",
      "Batch: 1434. Acc: 0.336069. Loss: 1.898825. Batch_acc: 0.348891. Batch_loss: 1.848177 \n",
      "Batch: 1435. Acc: 0.336078. Loss: 1.898780. Batch_acc: 0.349216. Batch_loss: 1.833080 \n",
      "Batch: 1436. Acc: 0.336076. Loss: 1.898783. Batch_acc: 0.332754. Batch_loss: 1.903559 \n",
      "Batch: 1437. Acc: 0.336072. Loss: 1.898771. Batch_acc: 0.330650. Batch_loss: 1.880786 \n",
      "Batch: 1438. Acc: 0.336072. Loss: 1.898742. Batch_acc: 0.335586. Batch_loss: 1.858343 \n",
      "Batch: 1439. Acc: 0.336071. Loss: 1.898741. Batch_acc: 0.335652. Batch_loss: 1.896586 \n",
      "Batch: 1440. Acc: 0.336069. Loss: 1.898728. Batch_acc: 0.333142. Batch_loss: 1.880973 \n",
      "Batch: 1441. Acc: 0.336077. Loss: 1.898692. Batch_acc: 0.347926. Batch_loss: 1.846310 \n",
      "Batch: 1442. Acc: 0.336073. Loss: 1.898676. Batch_acc: 0.330312. Batch_loss: 1.875930 \n",
      "Batch: 1443. Acc: 0.336085. Loss: 1.898646. Batch_acc: 0.352641. Batch_loss: 1.855797 \n",
      "Batch: 1444. Acc: 0.336087. Loss: 1.898632. Batch_acc: 0.339185. Batch_loss: 1.879064 \n",
      "Batch: 1445. Acc: 0.336103. Loss: 1.898590. Batch_acc: 0.359609. Batch_loss: 1.837675 \n",
      "Batch: 1446. Acc: 0.336115. Loss: 1.898545. Batch_acc: 0.353518. Batch_loss: 1.833899 \n",
      "Batch: 1447. Acc: 0.336113. Loss: 1.898533. Batch_acc: 0.332201. Batch_loss: 1.881151 \n",
      "Batch: 1448. Acc: 0.336116. Loss: 1.898510. Batch_acc: 0.341256. Batch_loss: 1.866146 \n",
      "Batch: 1449. Acc: 0.336134. Loss: 1.898471. Batch_acc: 0.361653. Batch_loss: 1.841858 \n",
      "Batch: 1450. Acc: 0.336145. Loss: 1.898446. Batch_acc: 0.352169. Batch_loss: 1.862182 \n",
      "Batch: 1451. Acc: 0.336152. Loss: 1.898408. Batch_acc: 0.345312. Batch_loss: 1.844061 \n",
      "Batch: 1452. Acc: 0.336165. Loss: 1.898370. Batch_acc: 0.355942. Batch_loss: 1.842819 \n",
      "Batch: 1453. Acc: 0.336163. Loss: 1.898356. Batch_acc: 0.332958. Batch_loss: 1.878451 \n",
      "Batch: 1454. Acc: 0.336162. Loss: 1.898331. Batch_acc: 0.335593. Batch_loss: 1.863445 \n",
      "Batch: 1455. Acc: 0.336180. Loss: 1.898311. Batch_acc: 0.361494. Batch_loss: 1.868965 \n",
      "Batch: 1456. Acc: 0.336181. Loss: 1.898295. Batch_acc: 0.338134. Batch_loss: 1.874305 \n",
      "Batch: 1457. Acc: 0.336192. Loss: 1.898282. Batch_acc: 0.351700. Batch_loss: 1.879645 \n",
      "Batch: 1458. Acc: 0.336192. Loss: 1.898269. Batch_acc: 0.336411. Batch_loss: 1.879413 \n",
      "Batch: 1459. Acc: 0.336204. Loss: 1.898253. Batch_acc: 0.354416. Batch_loss: 1.874494 \n",
      "Batch: 1460. Acc: 0.336214. Loss: 1.898231. Batch_acc: 0.349686. Batch_loss: 1.867496 \n",
      "Batch: 1461. Acc: 0.336221. Loss: 1.898221. Batch_acc: 0.346523. Batch_loss: 1.883206 \n",
      "Batch: 1462. Acc: 0.336222. Loss: 1.898191. Batch_acc: 0.338060. Batch_loss: 1.855521 \n",
      "Batch: 1463. Acc: 0.336228. Loss: 1.898166. Batch_acc: 0.345401. Batch_loss: 1.860451 \n",
      "Batch: 1464. Acc: 0.336233. Loss: 1.898181. Batch_acc: 0.343120. Batch_loss: 1.919634 \n",
      "Batch: 1465. Acc: 0.336235. Loss: 1.898146. Batch_acc: 0.338872. Batch_loss: 1.844958 \n",
      "Batch: 1466. Acc: 0.336246. Loss: 1.898111. Batch_acc: 0.352273. Batch_loss: 1.847352 \n",
      "Batch: 1467. Acc: 0.336250. Loss: 1.898087. Batch_acc: 0.342808. Batch_loss: 1.864032 \n",
      "Batch: 1468. Acc: 0.336258. Loss: 1.898091. Batch_acc: 0.347009. Batch_loss: 1.902830 \n",
      "Batch: 1469. Acc: 0.336257. Loss: 1.898075. Batch_acc: 0.335829. Batch_loss: 1.875162 \n",
      "Batch: 1470. Acc: 0.336262. Loss: 1.898057. Batch_acc: 0.343154. Batch_loss: 1.871240 \n",
      "Batch: 1471. Acc: 0.336276. Loss: 1.898021. Batch_acc: 0.355961. Batch_loss: 1.846155 \n",
      "Batch: 1472. Acc: 0.336296. Loss: 1.897960. Batch_acc: 0.365881. Batch_loss: 1.809456 \n",
      "Batch: 1473. Acc: 0.336305. Loss: 1.897938. Batch_acc: 0.349288. Batch_loss: 1.866933 \n",
      "Batch: 1474. Acc: 0.336312. Loss: 1.897912. Batch_acc: 0.346375. Batch_loss: 1.859662 \n",
      "Batch: 1475. Acc: 0.336310. Loss: 1.897904. Batch_acc: 0.334107. Batch_loss: 1.884724 \n",
      "Batch: 1476. Acc: 0.336315. Loss: 1.897887. Batch_acc: 0.343423. Batch_loss: 1.873641 \n",
      "Batch: 1477. Acc: 0.336329. Loss: 1.897866. Batch_acc: 0.356607. Batch_loss: 1.866369 \n",
      "Batch: 1478. Acc: 0.336336. Loss: 1.897843. Batch_acc: 0.346241. Batch_loss: 1.863386 \n",
      "Batch: 1479. Acc: 0.336335. Loss: 1.897854. Batch_acc: 0.334689. Batch_loss: 1.915446 \n",
      "Batch: 1480. Acc: 0.336348. Loss: 1.897803. Batch_acc: 0.355405. Batch_loss: 1.822411 \n",
      "Batch: 1481. Acc: 0.336357. Loss: 1.897763. Batch_acc: 0.349465. Batch_loss: 1.840183 \n",
      "Batch: 1482. Acc: 0.336358. Loss: 1.897728. Batch_acc: 0.338682. Batch_loss: 1.846323 \n",
      "Batch: 1483. Acc: 0.336360. Loss: 1.897735. Batch_acc: 0.339532. Batch_loss: 1.908498 \n",
      "Batch: 1484. Acc: 0.336368. Loss: 1.897731. Batch_acc: 0.347929. Batch_loss: 1.891697 \n",
      "Batch: 1485. Acc: 0.336380. Loss: 1.897690. Batch_acc: 0.353530. Batch_loss: 1.839631 \n",
      "Batch: 1486. Acc: 0.336387. Loss: 1.897664. Batch_acc: 0.347751. Batch_loss: 1.857504 \n",
      "Batch: 1487. Acc: 0.336412. Loss: 1.897624. Batch_acc: 0.373099. Batch_loss: 1.838127 \n",
      "Batch: 1488. Acc: 0.336418. Loss: 1.897599. Batch_acc: 0.345496. Batch_loss: 1.859931 \n",
      "Batch: 1489. Acc: 0.336429. Loss: 1.897583. Batch_acc: 0.352804. Batch_loss: 1.873369 \n",
      "Batch: 1490. Acc: 0.336440. Loss: 1.897559. Batch_acc: 0.352611. Batch_loss: 1.863182 \n",
      "Batch: 1491. Acc: 0.336448. Loss: 1.897514. Batch_acc: 0.348194. Batch_loss: 1.832015 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1492. Acc: 0.336444. Loss: 1.897521. Batch_acc: 0.330440. Batch_loss: 1.907234 \n",
      "Batch: 1493. Acc: 0.336447. Loss: 1.897508. Batch_acc: 0.340666. Batch_loss: 1.878645 \n",
      "Batch: 1494. Acc: 0.336458. Loss: 1.897478. Batch_acc: 0.353111. Batch_loss: 1.853459 \n",
      "Batch: 1495. Acc: 0.336462. Loss: 1.897440. Batch_acc: 0.342379. Batch_loss: 1.839534 \n",
      "Batch: 1496. Acc: 0.336476. Loss: 1.897390. Batch_acc: 0.357184. Batch_loss: 1.823422 \n",
      "Batch: 1497. Acc: 0.336482. Loss: 1.897368. Batch_acc: 0.345475. Batch_loss: 1.864575 \n",
      "Batch: 1498. Acc: 0.336486. Loss: 1.897332. Batch_acc: 0.343696. Batch_loss: 1.843007 \n",
      "Batch: 1499. Acc: 0.336490. Loss: 1.897316. Batch_acc: 0.341311. Batch_loss: 1.872952 \n",
      "Batch: 1500. Acc: 0.336504. Loss: 1.897293. Batch_acc: 0.358061. Batch_loss: 1.862154 \n",
      "Batch: 1501. Acc: 0.336508. Loss: 1.897270. Batch_acc: 0.342369. Batch_loss: 1.863042 \n",
      "Batch: 1502. Acc: 0.336518. Loss: 1.897247. Batch_acc: 0.352146. Batch_loss: 1.860932 \n",
      "Batch: 1503. Acc: 0.336532. Loss: 1.897212. Batch_acc: 0.357513. Batch_loss: 1.845282 \n",
      "Batch: 1504. Acc: 0.336531. Loss: 1.897203. Batch_acc: 0.335088. Batch_loss: 1.882719 \n",
      "Batch: 1505. Acc: 0.336540. Loss: 1.897177. Batch_acc: 0.350634. Batch_loss: 1.857904 \n",
      "Batch: 1506. Acc: 0.336541. Loss: 1.897167. Batch_acc: 0.337737. Batch_loss: 1.882364 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.3365410238496104. Loss per char: 1.8971667623681736. Time: 1627207607.3511074\n",
      "Last question is tensor([ 2, 19, 17, 19, 17, 15, 26, 21, 22, 12, 14, 23, 17, 21, 22, 25, 15, 20,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.336547. Loss: 1.897150. Batch_acc: 0.345026. Batch_loss: 1.872088 \n",
      "Batch: 1508. Acc: 0.336545. Loss: 1.897141. Batch_acc: 0.333909. Batch_loss: 1.883529 \n",
      "Batch: 1509. Acc: 0.336545. Loss: 1.897130. Batch_acc: 0.336599. Batch_loss: 1.880322 \n",
      "Batch: 1510. Acc: 0.336546. Loss: 1.897105. Batch_acc: 0.338664. Batch_loss: 1.859398 \n",
      "Batch: 1511. Acc: 0.336551. Loss: 1.897096. Batch_acc: 0.344386. Batch_loss: 1.884203 \n",
      "Batch: 1512. Acc: 0.336561. Loss: 1.897068. Batch_acc: 0.350867. Batch_loss: 1.852707 \n",
      "Batch: 1513. Acc: 0.336570. Loss: 1.897024. Batch_acc: 0.351211. Batch_loss: 1.830062 \n",
      "Batch: 1514. Acc: 0.336588. Loss: 1.896987. Batch_acc: 0.363585. Batch_loss: 1.841847 \n",
      "Batch: 1515. Acc: 0.336596. Loss: 1.896963. Batch_acc: 0.348245. Batch_loss: 1.861207 \n",
      "Batch: 1516. Acc: 0.336605. Loss: 1.896943. Batch_acc: 0.349771. Batch_loss: 1.867035 \n",
      "Batch: 1517. Acc: 0.336609. Loss: 1.896910. Batch_acc: 0.343381. Batch_loss: 1.845182 \n",
      "Batch: 1518. Acc: 0.336614. Loss: 1.896898. Batch_acc: 0.344458. Batch_loss: 1.878078 \n",
      "Batch: 1519. Acc: 0.336614. Loss: 1.896876. Batch_acc: 0.335951. Batch_loss: 1.864093 \n",
      "Batch: 1520. Acc: 0.336616. Loss: 1.896867. Batch_acc: 0.340353. Batch_loss: 1.883141 \n",
      "Batch: 1521. Acc: 0.336617. Loss: 1.896856. Batch_acc: 0.337624. Batch_loss: 1.880720 \n",
      "Batch: 1522. Acc: 0.336618. Loss: 1.896856. Batch_acc: 0.337878. Batch_loss: 1.897339 \n",
      "Batch: 1523. Acc: 0.336618. Loss: 1.896861. Batch_acc: 0.336379. Batch_loss: 1.903703 \n",
      "Batch: 1524. Acc: 0.336618. Loss: 1.896857. Batch_acc: 0.336770. Batch_loss: 1.890725 \n",
      "Batch: 1525. Acc: 0.336628. Loss: 1.896830. Batch_acc: 0.352736. Batch_loss: 1.855828 \n",
      "Batch: 1526. Acc: 0.336627. Loss: 1.896815. Batch_acc: 0.335049. Batch_loss: 1.873505 \n",
      "Batch: 1527. Acc: 0.336633. Loss: 1.896798. Batch_acc: 0.345434. Batch_loss: 1.870935 \n",
      "Batch: 1528. Acc: 0.336632. Loss: 1.896792. Batch_acc: 0.334659. Batch_loss: 1.887788 \n",
      "Batch: 1529. Acc: 0.336645. Loss: 1.896750. Batch_acc: 0.357060. Batch_loss: 1.832181 \n",
      "Batch: 1530. Acc: 0.336653. Loss: 1.896730. Batch_acc: 0.348398. Batch_loss: 1.866178 \n",
      "Batch: 1531. Acc: 0.336660. Loss: 1.896695. Batch_acc: 0.347680. Batch_loss: 1.844547 \n",
      "Batch: 1532. Acc: 0.336671. Loss: 1.896668. Batch_acc: 0.353375. Batch_loss: 1.856822 \n",
      "Batch: 1533. Acc: 0.336674. Loss: 1.896657. Batch_acc: 0.341027. Batch_loss: 1.879301 \n",
      "Batch: 1534. Acc: 0.336674. Loss: 1.896628. Batch_acc: 0.336005. Batch_loss: 1.851514 \n",
      "Batch: 1535. Acc: 0.336681. Loss: 1.896611. Batch_acc: 0.348098. Batch_loss: 1.871526 \n",
      "Batch: 1536. Acc: 0.336684. Loss: 1.896600. Batch_acc: 0.341335. Batch_loss: 1.880054 \n",
      "Batch: 1537. Acc: 0.336690. Loss: 1.896593. Batch_acc: 0.346267. Batch_loss: 1.885570 \n",
      "Batch: 1538. Acc: 0.336697. Loss: 1.896546. Batch_acc: 0.347678. Batch_loss: 1.824285 \n",
      "Batch: 1539. Acc: 0.336695. Loss: 1.896537. Batch_acc: 0.332770. Batch_loss: 1.882805 \n",
      "Batch: 1540. Acc: 0.336707. Loss: 1.896490. Batch_acc: 0.354402. Batch_loss: 1.825818 \n",
      "Batch: 1541. Acc: 0.336704. Loss: 1.896470. Batch_acc: 0.333333. Batch_loss: 1.866187 \n",
      "Batch: 1542. Acc: 0.336713. Loss: 1.896460. Batch_acc: 0.349153. Batch_loss: 1.881427 \n",
      "Batch: 1543. Acc: 0.336717. Loss: 1.896436. Batch_acc: 0.344425. Batch_loss: 1.858145 \n",
      "Batch: 1544. Acc: 0.336722. Loss: 1.896415. Batch_acc: 0.343610. Batch_loss: 1.865584 \n",
      "Batch: 1545. Acc: 0.336732. Loss: 1.896382. Batch_acc: 0.352137. Batch_loss: 1.844713 \n",
      "Batch: 1546. Acc: 0.336747. Loss: 1.896349. Batch_acc: 0.359131. Batch_loss: 1.846680 \n",
      "Batch: 1547. Acc: 0.336751. Loss: 1.896322. Batch_acc: 0.342481. Batch_loss: 1.855255 \n",
      "Batch: 1548. Acc: 0.336757. Loss: 1.896305. Batch_acc: 0.346220. Batch_loss: 1.869499 \n",
      "Batch: 1549. Acc: 0.336758. Loss: 1.896305. Batch_acc: 0.339125. Batch_loss: 1.896869 \n",
      "Batch: 1550. Acc: 0.336762. Loss: 1.896268. Batch_acc: 0.341786. Batch_loss: 1.841146 \n",
      "Batch: 1551. Acc: 0.336753. Loss: 1.896258. Batch_acc: 0.322807. Batch_loss: 1.880237 \n",
      "Batch: 1552. Acc: 0.336755. Loss: 1.896247. Batch_acc: 0.340401. Batch_loss: 1.879998 \n",
      "Batch: 1553. Acc: 0.336767. Loss: 1.896229. Batch_acc: 0.355060. Batch_loss: 1.868655 \n",
      "Batch: 1554. Acc: 0.336770. Loss: 1.896211. Batch_acc: 0.340792. Batch_loss: 1.867940 \n",
      "Batch: 1555. Acc: 0.336774. Loss: 1.896192. Batch_acc: 0.343429. Batch_loss: 1.867476 \n",
      "Batch: 1556. Acc: 0.336782. Loss: 1.896181. Batch_acc: 0.348955. Batch_loss: 1.878534 \n",
      "Batch: 1557. Acc: 0.336797. Loss: 1.896153. Batch_acc: 0.359135. Batch_loss: 1.852592 \n",
      "Batch: 1558. Acc: 0.336818. Loss: 1.896129. Batch_acc: 0.370017. Batch_loss: 1.859722 \n",
      "Batch: 1559. Acc: 0.336823. Loss: 1.896125. Batch_acc: 0.344244. Batch_loss: 1.890349 \n",
      "Batch: 1560. Acc: 0.336835. Loss: 1.896095. Batch_acc: 0.354930. Batch_loss: 1.850926 \n",
      "Batch: 1561. Acc: 0.336836. Loss: 1.896084. Batch_acc: 0.338068. Batch_loss: 1.878178 \n",
      "Batch: 1562. Acc: 0.336834. Loss: 1.896088. Batch_acc: 0.333333. Batch_loss: 1.903042 \n",
      "Batch: 1563. Acc: 0.336844. Loss: 1.896069. Batch_acc: 0.352975. Batch_loss: 1.867031 \n",
      "Batch: 1564. Acc: 0.336837. Loss: 1.896065. Batch_acc: 0.325823. Batch_loss: 1.889205 \n",
      "Batch: 1565. Acc: 0.336845. Loss: 1.896026. Batch_acc: 0.350028. Batch_loss: 1.834893 \n",
      "Batch: 1566. Acc: 0.336850. Loss: 1.895988. Batch_acc: 0.343593. Batch_loss: 1.838655 \n",
      "Batch: 1567. Acc: 0.336856. Loss: 1.895970. Batch_acc: 0.346855. Batch_loss: 1.867037 \n",
      "Batch: 1568. Acc: 0.336856. Loss: 1.895956. Batch_acc: 0.336848. Batch_loss: 1.873179 \n",
      "Batch: 1569. Acc: 0.336864. Loss: 1.895953. Batch_acc: 0.349405. Batch_loss: 1.891849 \n",
      "Batch: 1570. Acc: 0.336871. Loss: 1.895947. Batch_acc: 0.347852. Batch_loss: 1.886527 \n",
      "Batch: 1571. Acc: 0.336874. Loss: 1.895923. Batch_acc: 0.341957. Batch_loss: 1.859292 \n",
      "Batch: 1572. Acc: 0.336883. Loss: 1.895907. Batch_acc: 0.350967. Batch_loss: 1.871111 \n",
      "Batch: 1573. Acc: 0.336896. Loss: 1.895878. Batch_acc: 0.357303. Batch_loss: 1.850212 \n",
      "Batch: 1574. Acc: 0.336899. Loss: 1.895856. Batch_acc: 0.341210. Batch_loss: 1.860832 \n",
      "Batch: 1575. Acc: 0.336909. Loss: 1.895836. Batch_acc: 0.352319. Batch_loss: 1.864787 \n",
      "Batch: 1576. Acc: 0.336907. Loss: 1.895828. Batch_acc: 0.334694. Batch_loss: 1.882639 \n",
      "Batch: 1577. Acc: 0.336907. Loss: 1.895827. Batch_acc: 0.337133. Batch_loss: 1.893460 \n",
      "Batch: 1578. Acc: 0.336907. Loss: 1.895811. Batch_acc: 0.335783. Batch_loss: 1.871078 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1579. Acc: 0.336911. Loss: 1.895809. Batch_acc: 0.343240. Batch_loss: 1.893699 \n",
      "Batch: 1580. Acc: 0.336911. Loss: 1.895810. Batch_acc: 0.337072. Batch_loss: 1.896250 \n",
      "Batch: 1581. Acc: 0.336904. Loss: 1.895804. Batch_acc: 0.327181. Batch_loss: 1.887591 \n",
      "Batch: 1582. Acc: 0.336915. Loss: 1.895781. Batch_acc: 0.353967. Batch_loss: 1.859188 \n",
      "Batch: 1583. Acc: 0.336923. Loss: 1.895766. Batch_acc: 0.349532. Batch_loss: 1.872487 \n",
      "Batch: 1584. Acc: 0.336937. Loss: 1.895733. Batch_acc: 0.358310. Batch_loss: 1.844768 \n",
      "Batch: 1585. Acc: 0.336937. Loss: 1.895716. Batch_acc: 0.337597. Batch_loss: 1.868823 \n",
      "Batch: 1586. Acc: 0.336958. Loss: 1.895679. Batch_acc: 0.368876. Batch_loss: 1.837288 \n",
      "Batch: 1587. Acc: 0.336963. Loss: 1.895667. Batch_acc: 0.344887. Batch_loss: 1.876948 \n",
      "Batch: 1588. Acc: 0.336968. Loss: 1.895630. Batch_acc: 0.345905. Batch_loss: 1.835582 \n",
      "Batch: 1589. Acc: 0.336978. Loss: 1.895589. Batch_acc: 0.352299. Batch_loss: 1.829668 \n",
      "Batch: 1590. Acc: 0.336984. Loss: 1.895563. Batch_acc: 0.347278. Batch_loss: 1.854596 \n",
      "Batch: 1591. Acc: 0.336985. Loss: 1.895553. Batch_acc: 0.337572. Batch_loss: 1.880116 \n",
      "Batch: 1592. Acc: 0.336981. Loss: 1.895536. Batch_acc: 0.331965. Batch_loss: 1.867560 \n",
      "Batch: 1593. Acc: 0.336985. Loss: 1.895509. Batch_acc: 0.342674. Batch_loss: 1.851091 \n",
      "Batch: 1594. Acc: 0.336991. Loss: 1.895478. Batch_acc: 0.347350. Batch_loss: 1.846304 \n",
      "Batch: 1595. Acc: 0.337004. Loss: 1.895442. Batch_acc: 0.356257. Batch_loss: 1.840135 \n",
      "Batch: 1596. Acc: 0.337013. Loss: 1.895426. Batch_acc: 0.351991. Batch_loss: 1.868695 \n",
      "Batch: 1597. Acc: 0.337022. Loss: 1.895400. Batch_acc: 0.350837. Batch_loss: 1.854882 \n",
      "Batch: 1598. Acc: 0.337033. Loss: 1.895370. Batch_acc: 0.355620. Batch_loss: 1.846742 \n",
      "Batch: 1599. Acc: 0.337049. Loss: 1.895339. Batch_acc: 0.362998. Batch_loss: 1.845601 \n",
      "Batch: 1600. Acc: 0.337053. Loss: 1.895312. Batch_acc: 0.343020. Batch_loss: 1.852127 \n",
      "Batch: 1601. Acc: 0.337052. Loss: 1.895295. Batch_acc: 0.335461. Batch_loss: 1.866876 \n",
      "Batch: 1602. Acc: 0.337052. Loss: 1.895278. Batch_acc: 0.337216. Batch_loss: 1.868315 \n",
      "Batch: 1603. Acc: 0.337064. Loss: 1.895236. Batch_acc: 0.356611. Batch_loss: 1.828658 \n",
      "Batch: 1604. Acc: 0.337082. Loss: 1.895190. Batch_acc: 0.365826. Batch_loss: 1.821757 \n",
      "Batch: 1605. Acc: 0.337085. Loss: 1.895166. Batch_acc: 0.341519. Batch_loss: 1.856061 \n",
      "Batch: 1606. Acc: 0.337088. Loss: 1.895154. Batch_acc: 0.342181. Batch_loss: 1.876812 \n",
      "Batch: 1607. Acc: 0.337092. Loss: 1.895153. Batch_acc: 0.342529. Batch_loss: 1.892739 \n",
      "Batch: 1608. Acc: 0.337091. Loss: 1.895151. Batch_acc: 0.336237. Batch_loss: 1.892425 \n",
      "Batch: 1609. Acc: 0.337094. Loss: 1.895126. Batch_acc: 0.340935. Batch_loss: 1.854260 \n",
      "Batch: 1610. Acc: 0.337099. Loss: 1.895127. Batch_acc: 0.345231. Batch_loss: 1.896794 \n",
      "Batch: 1611. Acc: 0.337098. Loss: 1.895116. Batch_acc: 0.336487. Batch_loss: 1.877837 \n",
      "Batch: 1612. Acc: 0.337108. Loss: 1.895102. Batch_acc: 0.352594. Batch_loss: 1.871466 \n",
      "Batch: 1613. Acc: 0.337107. Loss: 1.895080. Batch_acc: 0.335404. Batch_loss: 1.859862 \n",
      "Batch: 1614. Acc: 0.337101. Loss: 1.895086. Batch_acc: 0.328205. Batch_loss: 1.905671 \n",
      "Batch: 1615. Acc: 0.337102. Loss: 1.895072. Batch_acc: 0.338235. Batch_loss: 1.871349 \n",
      "Batch: 1616. Acc: 0.337097. Loss: 1.895071. Batch_acc: 0.329085. Batch_loss: 1.894447 \n",
      "Batch: 1617. Acc: 0.337111. Loss: 1.895026. Batch_acc: 0.360206. Batch_loss: 1.822560 \n",
      "Batch: 1618. Acc: 0.337116. Loss: 1.895001. Batch_acc: 0.345580. Batch_loss: 1.854013 \n",
      "Batch: 1619. Acc: 0.337120. Loss: 1.894988. Batch_acc: 0.343126. Batch_loss: 1.873933 \n",
      "Batch: 1620. Acc: 0.337130. Loss: 1.894958. Batch_acc: 0.352279. Batch_loss: 1.847251 \n",
      "Batch: 1621. Acc: 0.337136. Loss: 1.894937. Batch_acc: 0.347729. Batch_loss: 1.861890 \n",
      "Batch: 1622. Acc: 0.337147. Loss: 1.894890. Batch_acc: 0.355140. Batch_loss: 1.816592 \n",
      "Batch: 1623. Acc: 0.337146. Loss: 1.894881. Batch_acc: 0.334852. Batch_loss: 1.880945 \n",
      "Batch: 1624. Acc: 0.337160. Loss: 1.894848. Batch_acc: 0.361192. Batch_loss: 1.840530 \n",
      "Batch: 1625. Acc: 0.337164. Loss: 1.894838. Batch_acc: 0.343768. Batch_loss: 1.877348 \n",
      "Batch: 1626. Acc: 0.337175. Loss: 1.894814. Batch_acc: 0.354023. Batch_loss: 1.857053 \n",
      "Batch: 1627. Acc: 0.337175. Loss: 1.894812. Batch_acc: 0.337299. Batch_loss: 1.891111 \n",
      "Batch: 1628. Acc: 0.337171. Loss: 1.894813. Batch_acc: 0.331576. Batch_loss: 1.896397 \n",
      "Batch: 1629. Acc: 0.337181. Loss: 1.894784. Batch_acc: 0.353106. Batch_loss: 1.848692 \n",
      "Batch: 1630. Acc: 0.337186. Loss: 1.894779. Batch_acc: 0.345266. Batch_loss: 1.887331 \n",
      "Batch: 1631. Acc: 0.337190. Loss: 1.894781. Batch_acc: 0.343659. Batch_loss: 1.896723 \n",
      "Batch: 1632. Acc: 0.337205. Loss: 1.894734. Batch_acc: 0.360414. Batch_loss: 1.823222 \n",
      "Batch: 1633. Acc: 0.337207. Loss: 1.894720. Batch_acc: 0.340314. Batch_loss: 1.870809 \n",
      "Batch: 1634. Acc: 0.337206. Loss: 1.894723. Batch_acc: 0.335060. Batch_loss: 1.899111 \n",
      "Batch: 1635. Acc: 0.337205. Loss: 1.894722. Batch_acc: 0.335648. Batch_loss: 1.893011 \n",
      "Batch: 1636. Acc: 0.337203. Loss: 1.894719. Batch_acc: 0.334299. Batch_loss: 1.890162 \n",
      "Batch: 1637. Acc: 0.337216. Loss: 1.894692. Batch_acc: 0.358003. Batch_loss: 1.851016 \n",
      "Batch: 1638. Acc: 0.337214. Loss: 1.894697. Batch_acc: 0.333923. Batch_loss: 1.903594 \n",
      "Batch: 1639. Acc: 0.337218. Loss: 1.894685. Batch_acc: 0.343353. Batch_loss: 1.873696 \n",
      "Batch: 1640. Acc: 0.337225. Loss: 1.894659. Batch_acc: 0.349612. Batch_loss: 1.853683 \n",
      "Batch: 1641. Acc: 0.337229. Loss: 1.894656. Batch_acc: 0.342760. Batch_loss: 1.890562 \n",
      "Batch: 1642. Acc: 0.337235. Loss: 1.894647. Batch_acc: 0.346951. Batch_loss: 1.879737 \n",
      "Batch: 1643. Acc: 0.337249. Loss: 1.894600. Batch_acc: 0.360023. Batch_loss: 1.818658 \n",
      "Batch: 1644. Acc: 0.337251. Loss: 1.894578. Batch_acc: 0.340069. Batch_loss: 1.858225 \n",
      "Batch: 1645. Acc: 0.337252. Loss: 1.894565. Batch_acc: 0.340336. Batch_loss: 1.872808 \n",
      "Batch: 1646. Acc: 0.337260. Loss: 1.894536. Batch_acc: 0.349603. Batch_loss: 1.846913 \n",
      "Batch: 1647. Acc: 0.337274. Loss: 1.894504. Batch_acc: 0.361389. Batch_loss: 1.840932 \n",
      "Batch: 1648. Acc: 0.337284. Loss: 1.894482. Batch_acc: 0.352839. Batch_loss: 1.857103 \n",
      "Batch: 1649. Acc: 0.337282. Loss: 1.894481. Batch_acc: 0.334302. Batch_loss: 1.893505 \n",
      "Batch: 1650. Acc: 0.337286. Loss: 1.894469. Batch_acc: 0.343446. Batch_loss: 1.874025 \n",
      "Batch: 1651. Acc: 0.337291. Loss: 1.894451. Batch_acc: 0.345848. Batch_loss: 1.865794 \n",
      "Batch: 1652. Acc: 0.337299. Loss: 1.894422. Batch_acc: 0.350887. Batch_loss: 1.846686 \n",
      "Batch: 1653. Acc: 0.337295. Loss: 1.894431. Batch_acc: 0.330994. Batch_loss: 1.909320 \n",
      "Batch: 1654. Acc: 0.337308. Loss: 1.894395. Batch_acc: 0.358352. Batch_loss: 1.835531 \n",
      "Batch: 1655. Acc: 0.337321. Loss: 1.894366. Batch_acc: 0.358765. Batch_loss: 1.845460 \n",
      "Batch: 1656. Acc: 0.337325. Loss: 1.894355. Batch_acc: 0.343641. Batch_loss: 1.875860 \n",
      "Batch: 1657. Acc: 0.337330. Loss: 1.894341. Batch_acc: 0.345224. Batch_loss: 1.872515 \n",
      "Batch: 1658. Acc: 0.337332. Loss: 1.894307. Batch_acc: 0.341379. Batch_loss: 1.837096 \n",
      "Batch: 1659. Acc: 0.337338. Loss: 1.894286. Batch_acc: 0.346728. Batch_loss: 1.859685 \n",
      "Batch: 1660. Acc: 0.337352. Loss: 1.894244. Batch_acc: 0.360702. Batch_loss: 1.825298 \n",
      "Batch: 1661. Acc: 0.337352. Loss: 1.894227. Batch_acc: 0.337315. Batch_loss: 1.866304 \n",
      "Batch: 1662. Acc: 0.337354. Loss: 1.894211. Batch_acc: 0.339943. Batch_loss: 1.867963 \n",
      "Batch: 1663. Acc: 0.337355. Loss: 1.894201. Batch_acc: 0.339126. Batch_loss: 1.879221 \n",
      "Batch: 1664. Acc: 0.337354. Loss: 1.894191. Batch_acc: 0.336594. Batch_loss: 1.876976 \n",
      "Batch: 1665. Acc: 0.337358. Loss: 1.894163. Batch_acc: 0.343697. Batch_loss: 1.848862 \n",
      "Batch: 1666. Acc: 0.337370. Loss: 1.894119. Batch_acc: 0.356810. Batch_loss: 1.819494 \n",
      "Batch: 1667. Acc: 0.337385. Loss: 1.894069. Batch_acc: 0.362700. Batch_loss: 1.810908 \n",
      "Batch: 1668. Acc: 0.337386. Loss: 1.894061. Batch_acc: 0.338824. Batch_loss: 1.880818 \n",
      "Batch: 1669. Acc: 0.337398. Loss: 1.894030. Batch_acc: 0.358053. Batch_loss: 1.840868 \n",
      "Batch: 1670. Acc: 0.337412. Loss: 1.894007. Batch_acc: 0.359887. Batch_loss: 1.856451 \n",
      "Batch: 1671. Acc: 0.337427. Loss: 1.893963. Batch_acc: 0.363018. Batch_loss: 1.822491 \n",
      "Batch: 1672. Acc: 0.337442. Loss: 1.893930. Batch_acc: 0.363161. Batch_loss: 1.838487 \n",
      "Batch: 1673. Acc: 0.337446. Loss: 1.893888. Batch_acc: 0.344099. Batch_loss: 1.822135 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1674. Acc: 0.337451. Loss: 1.893886. Batch_acc: 0.344671. Batch_loss: 1.889145 \n",
      "Batch: 1675. Acc: 0.337441. Loss: 1.893897. Batch_acc: 0.320445. Batch_loss: 1.913856 \n",
      "Batch: 1676. Acc: 0.337452. Loss: 1.893856. Batch_acc: 0.355884. Batch_loss: 1.824778 \n",
      "Batch: 1677. Acc: 0.337455. Loss: 1.893838. Batch_acc: 0.342641. Batch_loss: 1.864133 \n",
      "Batch: 1678. Acc: 0.337461. Loss: 1.893798. Batch_acc: 0.346705. Batch_loss: 1.826550 \n",
      "Batch: 1679. Acc: 0.337473. Loss: 1.893764. Batch_acc: 0.358628. Batch_loss: 1.838590 \n",
      "Batch: 1680. Acc: 0.337479. Loss: 1.893749. Batch_acc: 0.346844. Batch_loss: 1.868724 \n",
      "Batch: 1681. Acc: 0.337484. Loss: 1.893741. Batch_acc: 0.345538. Batch_loss: 1.880063 \n",
      "Batch: 1682. Acc: 0.337492. Loss: 1.893706. Batch_acc: 0.351756. Batch_loss: 1.833767 \n",
      "Batch: 1683. Acc: 0.337502. Loss: 1.893659. Batch_acc: 0.354525. Batch_loss: 1.815616 \n",
      "Batch: 1684. Acc: 0.337504. Loss: 1.893641. Batch_acc: 0.340596. Batch_loss: 1.863164 \n",
      "Batch: 1685. Acc: 0.337515. Loss: 1.893603. Batch_acc: 0.355060. Batch_loss: 1.829453 \n",
      "Batch: 1686. Acc: 0.337517. Loss: 1.893592. Batch_acc: 0.341116. Batch_loss: 1.876695 \n",
      "Batch: 1687. Acc: 0.337524. Loss: 1.893577. Batch_acc: 0.349509. Batch_loss: 1.867002 \n",
      "Batch: 1688. Acc: 0.337524. Loss: 1.893571. Batch_acc: 0.338346. Batch_loss: 1.883624 \n",
      "Batch: 1689. Acc: 0.337526. Loss: 1.893567. Batch_acc: 0.340290. Batch_loss: 1.886998 \n",
      "Batch: 1690. Acc: 0.337528. Loss: 1.893566. Batch_acc: 0.340314. Batch_loss: 1.891719 \n",
      "Batch: 1691. Acc: 0.337545. Loss: 1.893519. Batch_acc: 0.366133. Batch_loss: 1.814621 \n",
      "Batch: 1692. Acc: 0.337566. Loss: 1.893498. Batch_acc: 0.373425. Batch_loss: 1.857617 \n",
      "Batch: 1693. Acc: 0.337574. Loss: 1.893479. Batch_acc: 0.351414. Batch_loss: 1.861746 \n",
      "Batch: 1694. Acc: 0.337582. Loss: 1.893443. Batch_acc: 0.352171. Batch_loss: 1.829803 \n",
      "Batch: 1695. Acc: 0.337591. Loss: 1.893424. Batch_acc: 0.351076. Batch_loss: 1.861727 \n",
      "Batch: 1696. Acc: 0.337590. Loss: 1.893420. Batch_acc: 0.336692. Batch_loss: 1.886898 \n",
      "Batch: 1697. Acc: 0.337597. Loss: 1.893386. Batch_acc: 0.349914. Batch_loss: 1.836272 \n",
      "Batch: 1698. Acc: 0.337602. Loss: 1.893364. Batch_acc: 0.344946. Batch_loss: 1.855386 \n",
      "Batch: 1699. Acc: 0.337606. Loss: 1.893349. Batch_acc: 0.345252. Batch_loss: 1.868057 \n",
      "Batch: 1700. Acc: 0.337609. Loss: 1.893340. Batch_acc: 0.343345. Batch_loss: 1.877586 \n",
      "Batch: 1701. Acc: 0.337606. Loss: 1.893344. Batch_acc: 0.332588. Batch_loss: 1.899491 \n",
      "Batch: 1702. Acc: 0.337619. Loss: 1.893310. Batch_acc: 0.358362. Batch_loss: 1.837458 \n",
      "Batch: 1703. Acc: 0.337621. Loss: 1.893308. Batch_acc: 0.341920. Batch_loss: 1.888524 \n",
      "Batch: 1704. Acc: 0.337628. Loss: 1.893305. Batch_acc: 0.349170. Batch_loss: 1.889328 \n",
      "Batch: 1705. Acc: 0.337631. Loss: 1.893294. Batch_acc: 0.342808. Batch_loss: 1.874765 \n",
      "Batch: 1706. Acc: 0.337636. Loss: 1.893274. Batch_acc: 0.346471. Batch_loss: 1.857048 \n",
      "Batch: 1707. Acc: 0.337641. Loss: 1.893260. Batch_acc: 0.346306. Batch_loss: 1.869906 \n",
      "Batch: 1708. Acc: 0.337648. Loss: 1.893246. Batch_acc: 0.348851. Batch_loss: 1.870885 \n",
      "Batch: 1709. Acc: 0.337653. Loss: 1.893220. Batch_acc: 0.346288. Batch_loss: 1.848143 \n",
      "Batch: 1710. Acc: 0.337650. Loss: 1.893211. Batch_acc: 0.332358. Batch_loss: 1.877698 \n",
      "Batch: 1711. Acc: 0.337656. Loss: 1.893199. Batch_acc: 0.348050. Batch_loss: 1.871306 \n",
      "Batch: 1712. Acc: 0.337657. Loss: 1.893202. Batch_acc: 0.338627. Batch_loss: 1.898507 \n",
      "Batch: 1713. Acc: 0.337663. Loss: 1.893200. Batch_acc: 0.348545. Batch_loss: 1.890739 \n",
      "Batch: 1714. Acc: 0.337672. Loss: 1.893182. Batch_acc: 0.352908. Batch_loss: 1.862223 \n",
      "Batch: 1715. Acc: 0.337668. Loss: 1.893189. Batch_acc: 0.331254. Batch_loss: 1.904869 \n",
      "Batch: 1716. Acc: 0.337676. Loss: 1.893169. Batch_acc: 0.350755. Batch_loss: 1.859230 \n",
      "Batch: 1717. Acc: 0.337685. Loss: 1.893163. Batch_acc: 0.354482. Batch_loss: 1.881813 \n",
      "Batch: 1718. Acc: 0.337682. Loss: 1.893163. Batch_acc: 0.332000. Batch_loss: 1.893013 \n",
      "Batch: 1719. Acc: 0.337681. Loss: 1.893170. Batch_acc: 0.335211. Batch_loss: 1.905262 \n",
      "Batch: 1720. Acc: 0.337675. Loss: 1.893161. Batch_acc: 0.327991. Batch_loss: 1.877928 \n",
      "Batch: 1721. Acc: 0.337684. Loss: 1.893125. Batch_acc: 0.353757. Batch_loss: 1.831454 \n",
      "Batch: 1722. Acc: 0.337689. Loss: 1.893106. Batch_acc: 0.346154. Batch_loss: 1.858860 \n",
      "Batch: 1723. Acc: 0.337696. Loss: 1.893089. Batch_acc: 0.349943. Batch_loss: 1.864858 \n",
      "Batch: 1724. Acc: 0.337693. Loss: 1.893082. Batch_acc: 0.332353. Batch_loss: 1.880006 \n",
      "Batch: 1725. Acc: 0.337697. Loss: 1.893049. Batch_acc: 0.343463. Batch_loss: 1.836887 \n",
      "Batch: 1726. Acc: 0.337707. Loss: 1.893032. Batch_acc: 0.355724. Batch_loss: 1.862595 \n",
      "Batch: 1727. Acc: 0.337716. Loss: 1.893000. Batch_acc: 0.352709. Batch_loss: 1.839026 \n",
      "Batch: 1728. Acc: 0.337720. Loss: 1.892961. Batch_acc: 0.345455. Batch_loss: 1.826569 \n",
      "Batch: 1729. Acc: 0.337727. Loss: 1.892939. Batch_acc: 0.348850. Batch_loss: 1.855767 \n",
      "Batch: 1730. Acc: 0.337728. Loss: 1.892912. Batch_acc: 0.340113. Batch_loss: 1.847093 \n",
      "Batch: 1731. Acc: 0.337740. Loss: 1.892873. Batch_acc: 0.357583. Batch_loss: 1.826697 \n",
      "Batch: 1732. Acc: 0.337747. Loss: 1.892860. Batch_acc: 0.349913. Batch_loss: 1.870931 \n",
      "Batch: 1733. Acc: 0.337755. Loss: 1.892825. Batch_acc: 0.350837. Batch_loss: 1.831886 \n",
      "Batch: 1734. Acc: 0.337761. Loss: 1.892793. Batch_acc: 0.348450. Batch_loss: 1.836841 \n",
      "Batch: 1735. Acc: 0.337766. Loss: 1.892756. Batch_acc: 0.347333. Batch_loss: 1.829528 \n",
      "Batch: 1736. Acc: 0.337779. Loss: 1.892711. Batch_acc: 0.359813. Batch_loss: 1.814249 \n",
      "Batch: 1737. Acc: 0.337782. Loss: 1.892694. Batch_acc: 0.343292. Batch_loss: 1.864430 \n",
      "Batch: 1738. Acc: 0.337782. Loss: 1.892708. Batch_acc: 0.337130. Batch_loss: 1.916603 \n",
      "Batch: 1739. Acc: 0.337790. Loss: 1.892690. Batch_acc: 0.351367. Batch_loss: 1.861638 \n",
      "Batch: 1740. Acc: 0.337798. Loss: 1.892668. Batch_acc: 0.352843. Batch_loss: 1.854477 \n",
      "Batch: 1741. Acc: 0.337806. Loss: 1.892648. Batch_acc: 0.351668. Batch_loss: 1.858234 \n",
      "Batch: 1742. Acc: 0.337805. Loss: 1.892629. Batch_acc: 0.334847. Batch_loss: 1.859308 \n",
      "Batch: 1743. Acc: 0.337809. Loss: 1.892600. Batch_acc: 0.346420. Batch_loss: 1.842969 \n",
      "Batch: 1744. Acc: 0.337818. Loss: 1.892586. Batch_acc: 0.353694. Batch_loss: 1.867146 \n",
      "Batch: 1745. Acc: 0.337829. Loss: 1.892546. Batch_acc: 0.355682. Batch_loss: 1.823582 \n",
      "Batch: 1746. Acc: 0.337830. Loss: 1.892540. Batch_acc: 0.340339. Batch_loss: 1.881206 \n",
      "Batch: 1747. Acc: 0.337852. Loss: 1.892502. Batch_acc: 0.375716. Batch_loss: 1.826627 \n",
      "Batch: 1748. Acc: 0.337859. Loss: 1.892479. Batch_acc: 0.350176. Batch_loss: 1.852072 \n",
      "Batch: 1749. Acc: 0.337857. Loss: 1.892452. Batch_acc: 0.334503. Batch_loss: 1.844113 \n",
      "Batch: 1750. Acc: 0.337855. Loss: 1.892438. Batch_acc: 0.333525. Batch_loss: 1.868731 \n",
      "Batch: 1751. Acc: 0.337860. Loss: 1.892419. Batch_acc: 0.346951. Batch_loss: 1.858609 \n",
      "Batch: 1752. Acc: 0.337875. Loss: 1.892392. Batch_acc: 0.363584. Batch_loss: 1.845008 \n",
      "Batch: 1753. Acc: 0.337866. Loss: 1.892407. Batch_acc: 0.322235. Batch_loss: 1.919010 \n",
      "Batch: 1754. Acc: 0.337875. Loss: 1.892382. Batch_acc: 0.354358. Batch_loss: 1.850305 \n",
      "Batch: 1755. Acc: 0.337889. Loss: 1.892351. Batch_acc: 0.360877. Batch_loss: 1.838009 \n",
      "Batch: 1756. Acc: 0.337884. Loss: 1.892335. Batch_acc: 0.329891. Batch_loss: 1.864593 \n",
      "Batch: 1757. Acc: 0.337884. Loss: 1.892308. Batch_acc: 0.337216. Batch_loss: 1.844209 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.33788381943699064. Loss per char: 1.8923078599258518. Time: 1627207811.7546895\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 18, 20, 17, 19, 20, 25,\n",
      "        23, 22, 15, 25, 22, 24, 19,  1, 14,  1, 17, 15, 17, 19, 15,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.337897. Loss: 1.892277. Batch_acc: 0.361239. Batch_loss: 1.837874 \n",
      "Batch: 1759. Acc: 0.337903. Loss: 1.892282. Batch_acc: 0.348585. Batch_loss: 1.902254 \n",
      "Batch: 1760. Acc: 0.337914. Loss: 1.892235. Batch_acc: 0.356941. Batch_loss: 1.809652 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1761. Acc: 0.337915. Loss: 1.892221. Batch_acc: 0.340164. Batch_loss: 1.867214 \n",
      "Batch: 1762. Acc: 0.337916. Loss: 1.892214. Batch_acc: 0.339380. Batch_loss: 1.880267 \n",
      "Batch: 1763. Acc: 0.337923. Loss: 1.892190. Batch_acc: 0.350348. Batch_loss: 1.849363 \n",
      "Batch: 1764. Acc: 0.337933. Loss: 1.892155. Batch_acc: 0.356069. Batch_loss: 1.829911 \n",
      "Batch: 1765. Acc: 0.337942. Loss: 1.892128. Batch_acc: 0.353483. Batch_loss: 1.844915 \n",
      "Batch: 1766. Acc: 0.337945. Loss: 1.892115. Batch_acc: 0.344037. Batch_loss: 1.868630 \n",
      "Batch: 1767. Acc: 0.337947. Loss: 1.892112. Batch_acc: 0.340000. Batch_loss: 1.887750 \n",
      "Batch: 1768. Acc: 0.337944. Loss: 1.892108. Batch_acc: 0.333140. Batch_loss: 1.884059 \n",
      "Batch: 1769. Acc: 0.337940. Loss: 1.892121. Batch_acc: 0.330183. Batch_loss: 1.916830 \n",
      "Batch: 1770. Acc: 0.337932. Loss: 1.892123. Batch_acc: 0.323444. Batch_loss: 1.894297 \n",
      "Batch: 1771. Acc: 0.337926. Loss: 1.892132. Batch_acc: 0.328162. Batch_loss: 1.909688 \n",
      "Batch: 1772. Acc: 0.337929. Loss: 1.892128. Batch_acc: 0.342031. Batch_loss: 1.884579 \n",
      "Batch: 1773. Acc: 0.337930. Loss: 1.892146. Batch_acc: 0.340815. Batch_loss: 1.924862 \n",
      "Batch: 1774. Acc: 0.337940. Loss: 1.892124. Batch_acc: 0.354763. Batch_loss: 1.852255 \n",
      "Batch: 1775. Acc: 0.337937. Loss: 1.892120. Batch_acc: 0.334292. Batch_loss: 1.885609 \n",
      "Batch: 1776. Acc: 0.337932. Loss: 1.892140. Batch_acc: 0.327963. Batch_loss: 1.928433 \n",
      "Batch: 1777. Acc: 0.337941. Loss: 1.892130. Batch_acc: 0.353276. Batch_loss: 1.873862 \n",
      "Batch: 1778. Acc: 0.337940. Loss: 1.892119. Batch_acc: 0.337163. Batch_loss: 1.871990 \n",
      "Batch: 1779. Acc: 0.337945. Loss: 1.892089. Batch_acc: 0.346765. Batch_loss: 1.839871 \n",
      "Batch: 1780. Acc: 0.337955. Loss: 1.892059. Batch_acc: 0.354728. Batch_loss: 1.839789 \n",
      "Batch: 1781. Acc: 0.337970. Loss: 1.892015. Batch_acc: 0.365685. Batch_loss: 1.813374 \n",
      "Batch: 1782. Acc: 0.337980. Loss: 1.891992. Batch_acc: 0.355518. Batch_loss: 1.850432 \n",
      "Batch: 1783. Acc: 0.337983. Loss: 1.891966. Batch_acc: 0.343353. Batch_loss: 1.845863 \n",
      "Batch: 1784. Acc: 0.337982. Loss: 1.891961. Batch_acc: 0.336574. Batch_loss: 1.882190 \n",
      "Batch: 1785. Acc: 0.337983. Loss: 1.891959. Batch_acc: 0.338355. Batch_loss: 1.888918 \n",
      "Batch: 1786. Acc: 0.337992. Loss: 1.891934. Batch_acc: 0.354913. Batch_loss: 1.846932 \n",
      "Batch: 1787. Acc: 0.338011. Loss: 1.891873. Batch_acc: 0.370767. Batch_loss: 1.785405 \n",
      "Batch: 1788. Acc: 0.338018. Loss: 1.891860. Batch_acc: 0.350776. Batch_loss: 1.867397 \n",
      "Batch: 1789. Acc: 0.338033. Loss: 1.891818. Batch_acc: 0.366051. Batch_loss: 1.816300 \n",
      "Batch: 1790. Acc: 0.338034. Loss: 1.891827. Batch_acc: 0.339317. Batch_loss: 1.907848 \n",
      "Batch: 1791. Acc: 0.338036. Loss: 1.891809. Batch_acc: 0.340584. Batch_loss: 1.860210 \n",
      "Batch: 1792. Acc: 0.338047. Loss: 1.891779. Batch_acc: 0.358061. Batch_loss: 1.837392 \n",
      "Batch: 1793. Acc: 0.338056. Loss: 1.891742. Batch_acc: 0.354402. Batch_loss: 1.825867 \n",
      "Batch: 1794. Acc: 0.338066. Loss: 1.891712. Batch_acc: 0.356000. Batch_loss: 1.839802 \n",
      "Batch: 1795. Acc: 0.338075. Loss: 1.891673. Batch_acc: 0.353768. Batch_loss: 1.822490 \n",
      "Batch: 1796. Acc: 0.338082. Loss: 1.891640. Batch_acc: 0.351020. Batch_loss: 1.830785 \n",
      "Batch: 1797. Acc: 0.338087. Loss: 1.891620. Batch_acc: 0.347826. Batch_loss: 1.855872 \n",
      "Batch: 1798. Acc: 0.338087. Loss: 1.891613. Batch_acc: 0.337876. Batch_loss: 1.880398 \n",
      "Batch: 1799. Acc: 0.338088. Loss: 1.891614. Batch_acc: 0.340140. Batch_loss: 1.892476 \n",
      "Batch: 1800. Acc: 0.338091. Loss: 1.891608. Batch_acc: 0.342348. Batch_loss: 1.880445 \n",
      "Batch: 1801. Acc: 0.338092. Loss: 1.891599. Batch_acc: 0.340023. Batch_loss: 1.875695 \n",
      "Batch: 1802. Acc: 0.338098. Loss: 1.891581. Batch_acc: 0.348876. Batch_loss: 1.859853 \n",
      "Batch: 1803. Acc: 0.338105. Loss: 1.891560. Batch_acc: 0.351462. Batch_loss: 1.852794 \n",
      "Batch: 1804. Acc: 0.338117. Loss: 1.891522. Batch_acc: 0.359179. Batch_loss: 1.824854 \n",
      "Batch: 1805. Acc: 0.338131. Loss: 1.891505. Batch_acc: 0.364165. Batch_loss: 1.860071 \n",
      "Batch: 1806. Acc: 0.338150. Loss: 1.891451. Batch_acc: 0.371962. Batch_loss: 1.796184 \n",
      "Batch: 1807. Acc: 0.338150. Loss: 1.891437. Batch_acc: 0.338209. Batch_loss: 1.864611 \n",
      "Batch: 1808. Acc: 0.338150. Loss: 1.891428. Batch_acc: 0.337099. Batch_loss: 1.875479 \n",
      "Batch: 1809. Acc: 0.338158. Loss: 1.891418. Batch_acc: 0.353926. Batch_loss: 1.873259 \n",
      "Batch: 1810. Acc: 0.338173. Loss: 1.891397. Batch_acc: 0.364740. Batch_loss: 1.852401 \n",
      "Batch: 1811. Acc: 0.338187. Loss: 1.891360. Batch_acc: 0.361926. Batch_loss: 1.826793 \n",
      "Batch: 1812. Acc: 0.338196. Loss: 1.891316. Batch_acc: 0.355797. Batch_loss: 1.813274 \n",
      "Batch: 1813. Acc: 0.338204. Loss: 1.891303. Batch_acc: 0.351291. Batch_loss: 1.867963 \n",
      "Batch: 1814. Acc: 0.338209. Loss: 1.891296. Batch_acc: 0.347423. Batch_loss: 1.878343 \n",
      "Batch: 1815. Acc: 0.338216. Loss: 1.891280. Batch_acc: 0.350835. Batch_loss: 1.861275 \n",
      "Batch: 1816. Acc: 0.338217. Loss: 1.891271. Batch_acc: 0.341116. Batch_loss: 1.873960 \n",
      "Batch: 1817. Acc: 0.338230. Loss: 1.891241. Batch_acc: 0.361605. Batch_loss: 1.838548 \n",
      "Batch: 1818. Acc: 0.338224. Loss: 1.891254. Batch_acc: 0.327546. Batch_loss: 1.914034 \n",
      "Batch: 1819. Acc: 0.338236. Loss: 1.891228. Batch_acc: 0.358800. Batch_loss: 1.845406 \n",
      "Batch: 1820. Acc: 0.338236. Loss: 1.891232. Batch_acc: 0.339063. Batch_loss: 1.897889 \n",
      "Batch: 1821. Acc: 0.338243. Loss: 1.891199. Batch_acc: 0.350818. Batch_loss: 1.832346 \n",
      "Batch: 1822. Acc: 0.338252. Loss: 1.891166. Batch_acc: 0.354747. Batch_loss: 1.832106 \n",
      "Batch: 1823. Acc: 0.338261. Loss: 1.891144. Batch_acc: 0.354299. Batch_loss: 1.850116 \n",
      "Batch: 1824. Acc: 0.338273. Loss: 1.891127. Batch_acc: 0.359882. Batch_loss: 1.859836 \n",
      "Batch: 1825. Acc: 0.338275. Loss: 1.891118. Batch_acc: 0.341463. Batch_loss: 1.874384 \n",
      "Batch: 1826. Acc: 0.338287. Loss: 1.891069. Batch_acc: 0.361538. Batch_loss: 1.800615 \n",
      "Batch: 1827. Acc: 0.338289. Loss: 1.891050. Batch_acc: 0.342212. Batch_loss: 1.855231 \n",
      "Batch: 1828. Acc: 0.338293. Loss: 1.891033. Batch_acc: 0.345070. Batch_loss: 1.858829 \n",
      "Batch: 1829. Acc: 0.338291. Loss: 1.891028. Batch_acc: 0.334860. Batch_loss: 1.882075 \n",
      "Batch: 1830. Acc: 0.338292. Loss: 1.891019. Batch_acc: 0.339835. Batch_loss: 1.873897 \n",
      "Batch: 1831. Acc: 0.338304. Loss: 1.891001. Batch_acc: 0.360885. Batch_loss: 1.858556 \n",
      "Batch: 1832. Acc: 0.338317. Loss: 1.890955. Batch_acc: 0.362178. Batch_loss: 1.806362 \n",
      "Batch: 1833. Acc: 0.338324. Loss: 1.890931. Batch_acc: 0.350427. Batch_loss: 1.848626 \n",
      "Batch: 1834. Acc: 0.338334. Loss: 1.890895. Batch_acc: 0.357101. Batch_loss: 1.822453 \n",
      "Batch: 1835. Acc: 0.338334. Loss: 1.890885. Batch_acc: 0.339429. Batch_loss: 1.873863 \n",
      "Batch: 1836. Acc: 0.338338. Loss: 1.890864. Batch_acc: 0.345423. Batch_loss: 1.852125 \n",
      "Batch: 1837. Acc: 0.338342. Loss: 1.890823. Batch_acc: 0.345128. Batch_loss: 1.814333 \n",
      "Batch: 1838. Acc: 0.338342. Loss: 1.890798. Batch_acc: 0.339590. Batch_loss: 1.844632 \n",
      "Batch: 1839. Acc: 0.338347. Loss: 1.890782. Batch_acc: 0.347059. Batch_loss: 1.861479 \n",
      "Batch: 1840. Acc: 0.338336. Loss: 1.890781. Batch_acc: 0.317201. Batch_loss: 1.888410 \n",
      "Batch: 1841. Acc: 0.338345. Loss: 1.890765. Batch_acc: 0.354561. Batch_loss: 1.862023 \n",
      "Batch: 1842. Acc: 0.338346. Loss: 1.890751. Batch_acc: 0.341081. Batch_loss: 1.865045 \n",
      "Batch: 1843. Acc: 0.338361. Loss: 1.890698. Batch_acc: 0.365616. Batch_loss: 1.792832 \n",
      "Batch: 1844. Acc: 0.338372. Loss: 1.890670. Batch_acc: 0.359930. Batch_loss: 1.838597 \n",
      "Batch: 1845. Acc: 0.338370. Loss: 1.890654. Batch_acc: 0.334291. Batch_loss: 1.860425 \n",
      "Batch: 1846. Acc: 0.338376. Loss: 1.890626. Batch_acc: 0.348459. Batch_loss: 1.840777 \n",
      "Batch: 1847. Acc: 0.338385. Loss: 1.890582. Batch_acc: 0.354530. Batch_loss: 1.810670 \n",
      "Batch: 1848. Acc: 0.338396. Loss: 1.890562. Batch_acc: 0.358415. Batch_loss: 1.854620 \n",
      "Batch: 1849. Acc: 0.338403. Loss: 1.890533. Batch_acc: 0.351320. Batch_loss: 1.835790 \n",
      "Batch: 1850. Acc: 0.338412. Loss: 1.890510. Batch_acc: 0.355670. Batch_loss: 1.848900 \n",
      "Batch: 1851. Acc: 0.338420. Loss: 1.890495. Batch_acc: 0.353666. Batch_loss: 1.861926 \n",
      "Batch: 1852. Acc: 0.338426. Loss: 1.890461. Batch_acc: 0.348571. Batch_loss: 1.829247 \n",
      "Batch: 1853. Acc: 0.338426. Loss: 1.890458. Batch_acc: 0.339002. Batch_loss: 1.884490 \n",
      "Batch: 1854. Acc: 0.338432. Loss: 1.890456. Batch_acc: 0.350492. Batch_loss: 1.885759 \n",
      "Batch: 1855. Acc: 0.338431. Loss: 1.890444. Batch_acc: 0.335838. Batch_loss: 1.868740 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1856. Acc: 0.338435. Loss: 1.890421. Batch_acc: 0.345955. Batch_loss: 1.847144 \n",
      "Batch: 1857. Acc: 0.338439. Loss: 1.890419. Batch_acc: 0.345865. Batch_loss: 1.886599 \n",
      "Batch: 1858. Acc: 0.338446. Loss: 1.890407. Batch_acc: 0.352105. Batch_loss: 1.868465 \n",
      "Batch: 1859. Acc: 0.338466. Loss: 1.890360. Batch_acc: 0.374362. Batch_loss: 1.805278 \n",
      "Batch: 1860. Acc: 0.338460. Loss: 1.890370. Batch_acc: 0.327840. Batch_loss: 1.908293 \n",
      "Batch: 1861. Acc: 0.338470. Loss: 1.890339. Batch_acc: 0.356775. Batch_loss: 1.832821 \n",
      "Batch: 1862. Acc: 0.338481. Loss: 1.890308. Batch_acc: 0.358566. Batch_loss: 1.833430 \n",
      "Batch: 1863. Acc: 0.338487. Loss: 1.890292. Batch_acc: 0.349335. Batch_loss: 1.860259 \n",
      "Batch: 1864. Acc: 0.338494. Loss: 1.890254. Batch_acc: 0.350907. Batch_loss: 1.821728 \n",
      "Batch: 1865. Acc: 0.338503. Loss: 1.890224. Batch_acc: 0.355780. Batch_loss: 1.835788 \n",
      "Batch: 1866. Acc: 0.338504. Loss: 1.890231. Batch_acc: 0.340108. Batch_loss: 1.903463 \n",
      "Batch: 1867. Acc: 0.338503. Loss: 1.890234. Batch_acc: 0.337033. Batch_loss: 1.894577 \n",
      "Batch: 1868. Acc: 0.338507. Loss: 1.890232. Batch_acc: 0.344318. Batch_loss: 1.887532 \n",
      "Batch: 1869. Acc: 0.338507. Loss: 1.890244. Batch_acc: 0.339071. Batch_loss: 1.911951 \n",
      "Batch: 1870. Acc: 0.338503. Loss: 1.890241. Batch_acc: 0.331797. Batch_loss: 1.885007 \n",
      "Batch: 1871. Acc: 0.338516. Loss: 1.890200. Batch_acc: 0.361560. Batch_loss: 1.815494 \n",
      "Batch: 1872. Acc: 0.338527. Loss: 1.890166. Batch_acc: 0.360116. Batch_loss: 1.826771 \n",
      "Batch: 1873. Acc: 0.338538. Loss: 1.890150. Batch_acc: 0.359670. Batch_loss: 1.859621 \n",
      "Batch: 1874. Acc: 0.338545. Loss: 1.890119. Batch_acc: 0.351776. Batch_loss: 1.831940 \n",
      "Batch: 1875. Acc: 0.338553. Loss: 1.890112. Batch_acc: 0.352874. Batch_loss: 1.875712 \n",
      "Batch: 1876. Acc: 0.338570. Loss: 1.890074. Batch_acc: 0.368866. Batch_loss: 1.821057 \n",
      "Batch: 1877. Acc: 0.338582. Loss: 1.890049. Batch_acc: 0.362801. Batch_loss: 1.843591 \n",
      "Batch: 1878. Acc: 0.338586. Loss: 1.890029. Batch_acc: 0.345748. Batch_loss: 1.852531 \n",
      "Batch: 1879. Acc: 0.338589. Loss: 1.890010. Batch_acc: 0.343223. Batch_loss: 1.854190 \n",
      "Batch: 1880. Acc: 0.338589. Loss: 1.889993. Batch_acc: 0.338175. Batch_loss: 1.857494 \n",
      "Batch: 1881. Acc: 0.338599. Loss: 1.889968. Batch_acc: 0.357846. Batch_loss: 1.843419 \n",
      "Batch: 1882. Acc: 0.338605. Loss: 1.889946. Batch_acc: 0.350708. Batch_loss: 1.848898 \n",
      "Batch: 1883. Acc: 0.338609. Loss: 1.889949. Batch_acc: 0.346265. Batch_loss: 1.895345 \n",
      "Batch: 1884. Acc: 0.338619. Loss: 1.889915. Batch_acc: 0.356735. Batch_loss: 1.826009 \n",
      "Batch: 1885. Acc: 0.338625. Loss: 1.889889. Batch_acc: 0.349806. Batch_loss: 1.843637 \n",
      "Batch: 1886. Acc: 0.338618. Loss: 1.889898. Batch_acc: 0.323993. Batch_loss: 1.906803 \n",
      "Batch: 1887. Acc: 0.338629. Loss: 1.889874. Batch_acc: 0.359791. Batch_loss: 1.844024 \n",
      "Batch: 1888. Acc: 0.338643. Loss: 1.889842. Batch_acc: 0.366452. Batch_loss: 1.828876 \n",
      "Batch: 1889. Acc: 0.338647. Loss: 1.889819. Batch_acc: 0.345123. Batch_loss: 1.847181 \n",
      "Batch: 1890. Acc: 0.338652. Loss: 1.889782. Batch_acc: 0.349057. Batch_loss: 1.821528 \n",
      "Batch: 1891. Acc: 0.338655. Loss: 1.889767. Batch_acc: 0.342629. Batch_loss: 1.862529 \n",
      "Batch: 1892. Acc: 0.338660. Loss: 1.889744. Batch_acc: 0.349542. Batch_loss: 1.846535 \n",
      "Batch: 1893. Acc: 0.338673. Loss: 1.889722. Batch_acc: 0.362950. Batch_loss: 1.847629 \n",
      "Batch: 1894. Acc: 0.338676. Loss: 1.889696. Batch_acc: 0.344086. Batch_loss: 1.841078 \n",
      "Batch: 1895. Acc: 0.338683. Loss: 1.889679. Batch_acc: 0.351046. Batch_loss: 1.857792 \n",
      "Batch: 1896. Acc: 0.338694. Loss: 1.889631. Batch_acc: 0.360517. Batch_loss: 1.801277 \n",
      "Batch: 1897. Acc: 0.338697. Loss: 1.889615. Batch_acc: 0.344489. Batch_loss: 1.858752 \n",
      "Batch: 1898. Acc: 0.338704. Loss: 1.889584. Batch_acc: 0.351119. Batch_loss: 1.830335 \n",
      "Batch: 1899. Acc: 0.338717. Loss: 1.889544. Batch_acc: 0.362718. Batch_loss: 1.814957 \n",
      "Batch: 1900. Acc: 0.338720. Loss: 1.889528. Batch_acc: 0.344788. Batch_loss: 1.859109 \n",
      "Batch: 1901. Acc: 0.338724. Loss: 1.889507. Batch_acc: 0.346176. Batch_loss: 1.850004 \n",
      "Batch: 1902. Acc: 0.338729. Loss: 1.889475. Batch_acc: 0.347453. Batch_loss: 1.829131 \n",
      "Batch: 1903. Acc: 0.338730. Loss: 1.889466. Batch_acc: 0.340845. Batch_loss: 1.872288 \n",
      "Batch: 1904. Acc: 0.338746. Loss: 1.889416. Batch_acc: 0.369839. Batch_loss: 1.794157 \n",
      "Batch: 1905. Acc: 0.338742. Loss: 1.889408. Batch_acc: 0.331006. Batch_loss: 1.873579 \n",
      "Batch: 1906. Acc: 0.338747. Loss: 1.889393. Batch_acc: 0.348165. Batch_loss: 1.861643 \n",
      "Batch: 1907. Acc: 0.338754. Loss: 1.889373. Batch_acc: 0.352440. Batch_loss: 1.852852 \n",
      "Batch: 1908. Acc: 0.338776. Loss: 1.889319. Batch_acc: 0.378198. Batch_loss: 1.789406 \n",
      "Batch: 1909. Acc: 0.338777. Loss: 1.889333. Batch_acc: 0.340741. Batch_loss: 1.916188 \n",
      "Batch: 1910. Acc: 0.338782. Loss: 1.889297. Batch_acc: 0.349342. Batch_loss: 1.821520 \n",
      "Batch: 1911. Acc: 0.338790. Loss: 1.889264. Batch_acc: 0.353987. Batch_loss: 1.825852 \n",
      "Batch: 1912. Acc: 0.338801. Loss: 1.889243. Batch_acc: 0.359977. Batch_loss: 1.848944 \n",
      "Batch: 1913. Acc: 0.338812. Loss: 1.889197. Batch_acc: 0.359794. Batch_loss: 1.801556 \n",
      "Batch: 1914. Acc: 0.338821. Loss: 1.889174. Batch_acc: 0.354691. Batch_loss: 1.844851 \n",
      "Batch: 1915. Acc: 0.338817. Loss: 1.889156. Batch_acc: 0.331399. Batch_loss: 1.854493 \n",
      "Batch: 1916. Acc: 0.338824. Loss: 1.889129. Batch_acc: 0.352187. Batch_loss: 1.836600 \n",
      "Batch: 1917. Acc: 0.338842. Loss: 1.889104. Batch_acc: 0.372145. Batch_loss: 1.843283 \n",
      "Batch: 1918. Acc: 0.338845. Loss: 1.889075. Batch_acc: 0.345026. Batch_loss: 1.833565 \n",
      "Batch: 1919. Acc: 0.338847. Loss: 1.889070. Batch_acc: 0.343109. Batch_loss: 1.878452 \n",
      "Batch: 1920. Acc: 0.338854. Loss: 1.889049. Batch_acc: 0.351668. Batch_loss: 1.848941 \n",
      "Batch: 1921. Acc: 0.338867. Loss: 1.889018. Batch_acc: 0.363793. Batch_loss: 1.828276 \n",
      "Batch: 1922. Acc: 0.338876. Loss: 1.888976. Batch_acc: 0.356419. Batch_loss: 1.810529 \n",
      "Batch: 1923. Acc: 0.338893. Loss: 1.888951. Batch_acc: 0.370968. Batch_loss: 1.840144 \n",
      "Batch: 1924. Acc: 0.338899. Loss: 1.888925. Batch_acc: 0.351119. Batch_loss: 1.840472 \n",
      "Batch: 1925. Acc: 0.338894. Loss: 1.888920. Batch_acc: 0.328728. Batch_loss: 1.878335 \n",
      "Batch: 1926. Acc: 0.338897. Loss: 1.888905. Batch_acc: 0.344375. Batch_loss: 1.859668 \n",
      "Batch: 1927. Acc: 0.338903. Loss: 1.888869. Batch_acc: 0.350545. Batch_loss: 1.820918 \n",
      "Batch: 1928. Acc: 0.338909. Loss: 1.888839. Batch_acc: 0.351736. Batch_loss: 1.830818 \n",
      "Batch: 1929. Acc: 0.338910. Loss: 1.888838. Batch_acc: 0.340389. Batch_loss: 1.886655 \n",
      "Batch: 1930. Acc: 0.338914. Loss: 1.888823. Batch_acc: 0.346614. Batch_loss: 1.860721 \n",
      "Batch: 1931. Acc: 0.338924. Loss: 1.888791. Batch_acc: 0.357143. Batch_loss: 1.827423 \n",
      "Batch: 1932. Acc: 0.338921. Loss: 1.888774. Batch_acc: 0.334268. Batch_loss: 1.856623 \n",
      "Batch: 1933. Acc: 0.338931. Loss: 1.888750. Batch_acc: 0.358402. Batch_loss: 1.840639 \n",
      "Batch: 1934. Acc: 0.338941. Loss: 1.888718. Batch_acc: 0.359257. Batch_loss: 1.826531 \n",
      "Batch: 1935. Acc: 0.338952. Loss: 1.888700. Batch_acc: 0.359331. Batch_loss: 1.854089 \n",
      "Batch: 1936. Acc: 0.338952. Loss: 1.888701. Batch_acc: 0.339423. Batch_loss: 1.891706 \n",
      "Batch: 1937. Acc: 0.338949. Loss: 1.888706. Batch_acc: 0.330957. Batch_loss: 1.898459 \n",
      "Batch: 1938. Acc: 0.338943. Loss: 1.888713. Batch_acc: 0.329178. Batch_loss: 1.902636 \n",
      "Batch: 1939. Acc: 0.338943. Loss: 1.888708. Batch_acc: 0.337237. Batch_loss: 1.877680 \n",
      "Batch: 1940. Acc: 0.338949. Loss: 1.888694. Batch_acc: 0.352080. Batch_loss: 1.862287 \n",
      "Batch: 1941. Acc: 0.338950. Loss: 1.888670. Batch_acc: 0.341381. Batch_loss: 1.842354 \n",
      "Batch: 1942. Acc: 0.338956. Loss: 1.888662. Batch_acc: 0.349914. Batch_loss: 1.873461 \n",
      "Batch: 1943. Acc: 0.338957. Loss: 1.888662. Batch_acc: 0.340716. Batch_loss: 1.889116 \n",
      "Batch: 1944. Acc: 0.338961. Loss: 1.888644. Batch_acc: 0.347159. Batch_loss: 1.853417 \n",
      "Batch: 1945. Acc: 0.338958. Loss: 1.888641. Batch_acc: 0.331603. Batch_loss: 1.882612 \n",
      "Batch: 1946. Acc: 0.338965. Loss: 1.888618. Batch_acc: 0.352975. Batch_loss: 1.844492 \n",
      "Batch: 1947. Acc: 0.338971. Loss: 1.888575. Batch_acc: 0.350113. Batch_loss: 1.806760 \n",
      "Batch: 1948. Acc: 0.338971. Loss: 1.888569. Batch_acc: 0.339327. Batch_loss: 1.877417 \n",
      "Batch: 1949. Acc: 0.338988. Loss: 1.888537. Batch_acc: 0.373057. Batch_loss: 1.825430 \n",
      "Batch: 1950. Acc: 0.338987. Loss: 1.888541. Batch_acc: 0.336411. Batch_loss: 1.895565 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1951. Acc: 0.338992. Loss: 1.888518. Batch_acc: 0.349686. Batch_loss: 1.843793 \n",
      "Batch: 1952. Acc: 0.338995. Loss: 1.888499. Batch_acc: 0.344749. Batch_loss: 1.852327 \n",
      "Batch: 1953. Acc: 0.339000. Loss: 1.888493. Batch_acc: 0.347263. Batch_loss: 1.876629 \n",
      "Batch: 1954. Acc: 0.339012. Loss: 1.888474. Batch_acc: 0.364281. Batch_loss: 1.850121 \n",
      "Batch: 1955. Acc: 0.339025. Loss: 1.888426. Batch_acc: 0.364613. Batch_loss: 1.796718 \n",
      "Batch: 1956. Acc: 0.339032. Loss: 1.888404. Batch_acc: 0.351443. Batch_loss: 1.846042 \n",
      "Batch: 1957. Acc: 0.339024. Loss: 1.888394. Batch_acc: 0.324009. Batch_loss: 1.869038 \n",
      "Batch: 1958. Acc: 0.339026. Loss: 1.888379. Batch_acc: 0.341890. Batch_loss: 1.857088 \n",
      "Batch: 1959. Acc: 0.339034. Loss: 1.888361. Batch_acc: 0.354353. Batch_loss: 1.854859 \n",
      "Batch: 1960. Acc: 0.339036. Loss: 1.888340. Batch_acc: 0.344186. Batch_loss: 1.847246 \n",
      "Batch: 1961. Acc: 0.339040. Loss: 1.888323. Batch_acc: 0.345393. Batch_loss: 1.854482 \n",
      "Batch: 1962. Acc: 0.339038. Loss: 1.888323. Batch_acc: 0.336252. Batch_loss: 1.889861 \n",
      "Batch: 1963. Acc: 0.339024. Loss: 1.888330. Batch_acc: 0.311419. Batch_loss: 1.900612 \n",
      "Batch: 1964. Acc: 0.339033. Loss: 1.888305. Batch_acc: 0.356164. Batch_loss: 1.840406 \n",
      "Batch: 1965. Acc: 0.339041. Loss: 1.888288. Batch_acc: 0.353575. Batch_loss: 1.855381 \n",
      "Batch: 1966. Acc: 0.339044. Loss: 1.888273. Batch_acc: 0.345843. Batch_loss: 1.859052 \n",
      "Batch: 1967. Acc: 0.339049. Loss: 1.888257. Batch_acc: 0.348797. Batch_loss: 1.855743 \n",
      "Batch: 1968. Acc: 0.339051. Loss: 1.888264. Batch_acc: 0.342990. Batch_loss: 1.902520 \n",
      "Batch: 1969. Acc: 0.339052. Loss: 1.888250. Batch_acc: 0.340563. Batch_loss: 1.860234 \n",
      "Batch: 1970. Acc: 0.339059. Loss: 1.888218. Batch_acc: 0.353784. Batch_loss: 1.826216 \n",
      "Batch: 1971. Acc: 0.339068. Loss: 1.888190. Batch_acc: 0.354892. Batch_loss: 1.834217 \n",
      "Batch: 1972. Acc: 0.339072. Loss: 1.888191. Batch_acc: 0.347800. Batch_loss: 1.891444 \n",
      "Batch: 1973. Acc: 0.339076. Loss: 1.888174. Batch_acc: 0.348028. Batch_loss: 1.853170 \n",
      "Batch: 1974. Acc: 0.339078. Loss: 1.888158. Batch_acc: 0.343003. Batch_loss: 1.856365 \n",
      "Batch: 1975. Acc: 0.339081. Loss: 1.888156. Batch_acc: 0.344484. Batch_loss: 1.885731 \n",
      "Batch: 1976. Acc: 0.339082. Loss: 1.888140. Batch_acc: 0.341449. Batch_loss: 1.854742 \n",
      "Batch: 1977. Acc: 0.339098. Loss: 1.888094. Batch_acc: 0.369196. Batch_loss: 1.798358 \n",
      "Batch: 1978. Acc: 0.339097. Loss: 1.888061. Batch_acc: 0.337745. Batch_loss: 1.824422 \n",
      "Batch: 1979. Acc: 0.339102. Loss: 1.888036. Batch_acc: 0.349296. Batch_loss: 1.839303 \n",
      "Batch: 1980. Acc: 0.339110. Loss: 1.888019. Batch_acc: 0.354577. Batch_loss: 1.852772 \n",
      "Batch: 1981. Acc: 0.339122. Loss: 1.888003. Batch_acc: 0.362894. Batch_loss: 1.857121 \n",
      "Batch: 1982. Acc: 0.339131. Loss: 1.887977. Batch_acc: 0.358104. Batch_loss: 1.834332 \n",
      "Batch: 1983. Acc: 0.339132. Loss: 1.887964. Batch_acc: 0.339953. Batch_loss: 1.863040 \n",
      "Batch: 1984. Acc: 0.339146. Loss: 1.887945. Batch_acc: 0.367067. Batch_loss: 1.849173 \n",
      "Batch: 1985. Acc: 0.339146. Loss: 1.887922. Batch_acc: 0.338533. Batch_loss: 1.842885 \n",
      "Batch: 1986. Acc: 0.339144. Loss: 1.887917. Batch_acc: 0.336634. Batch_loss: 1.877900 \n",
      "Batch: 1987. Acc: 0.339149. Loss: 1.887913. Batch_acc: 0.347333. Batch_loss: 1.879478 \n",
      "Batch: 1988. Acc: 0.339156. Loss: 1.887876. Batch_acc: 0.354784. Batch_loss: 1.815627 \n",
      "Batch: 1989. Acc: 0.339166. Loss: 1.887854. Batch_acc: 0.359485. Batch_loss: 1.843970 \n",
      "Batch: 1990. Acc: 0.339174. Loss: 1.887828. Batch_acc: 0.353443. Batch_loss: 1.835916 \n",
      "Batch: 1991. Acc: 0.339178. Loss: 1.887810. Batch_acc: 0.347021. Batch_loss: 1.852731 \n",
      "Batch: 1992. Acc: 0.339189. Loss: 1.887791. Batch_acc: 0.362335. Batch_loss: 1.849350 \n",
      "Batch: 1993. Acc: 0.339197. Loss: 1.887765. Batch_acc: 0.354008. Batch_loss: 1.835535 \n",
      "Batch: 1994. Acc: 0.339198. Loss: 1.887749. Batch_acc: 0.341135. Batch_loss: 1.855897 \n",
      "Batch: 1995. Acc: 0.339206. Loss: 1.887723. Batch_acc: 0.355135. Batch_loss: 1.834814 \n",
      "Batch: 1996. Acc: 0.339206. Loss: 1.887740. Batch_acc: 0.340188. Batch_loss: 1.922650 \n",
      "Batch: 1997. Acc: 0.339214. Loss: 1.887715. Batch_acc: 0.355353. Batch_loss: 1.837333 \n",
      "Batch: 1998. Acc: 0.339214. Loss: 1.887710. Batch_acc: 0.339623. Batch_loss: 1.879579 \n",
      "Batch: 1999. Acc: 0.339218. Loss: 1.887689. Batch_acc: 0.345708. Batch_loss: 1.843709 \n",
      "Batch: 2000. Acc: 0.339226. Loss: 1.887659. Batch_acc: 0.355556. Batch_loss: 1.829018 \n",
      "Batch: 2001. Acc: 0.339235. Loss: 1.887631. Batch_acc: 0.357961. Batch_loss: 1.830946 \n",
      "Batch: 2002. Acc: 0.339243. Loss: 1.887617. Batch_acc: 0.354081. Batch_loss: 1.860525 \n",
      "Batch: 2003. Acc: 0.339244. Loss: 1.887602. Batch_acc: 0.342043. Batch_loss: 1.856098 \n",
      "Batch: 2004. Acc: 0.339258. Loss: 1.887570. Batch_acc: 0.365922. Batch_loss: 1.825490 \n",
      "Batch: 2005. Acc: 0.339259. Loss: 1.887558. Batch_acc: 0.343061. Batch_loss: 1.861446 \n",
      "Batch: 2006. Acc: 0.339266. Loss: 1.887539. Batch_acc: 0.352601. Batch_loss: 1.850801 \n",
      "Batch: 2007. Acc: 0.339267. Loss: 1.887529. Batch_acc: 0.341519. Batch_loss: 1.867786 \n",
      "Batch: 2008. Acc: 0.339273. Loss: 1.887526. Batch_acc: 0.350612. Batch_loss: 1.880877 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.3392727921470051. Loss per char: 1.8875261796635192. Time: 1627208015.1540108\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 14, 17, 15, 17,\n",
      "        24, 24, 26,  1, 66, 79, 69,  1, 14, 24, 25, 22, 21, 24, 22, 22, 20, 19,\n",
      "        21, 23, 32,  3], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.339269. Loss: 1.887516. Batch_acc: 0.332381. Batch_loss: 1.867007 \n",
      "Batch: 2010. Acc: 0.339277. Loss: 1.887487. Batch_acc: 0.354331. Batch_loss: 1.831162 \n",
      "Batch: 2011. Acc: 0.339280. Loss: 1.887462. Batch_acc: 0.345158. Batch_loss: 1.837836 \n",
      "Batch: 2012. Acc: 0.339287. Loss: 1.887433. Batch_acc: 0.352839. Batch_loss: 1.828887 \n",
      "Batch: 2013. Acc: 0.339285. Loss: 1.887430. Batch_acc: 0.335706. Batch_loss: 1.881255 \n",
      "Batch: 2014. Acc: 0.339287. Loss: 1.887424. Batch_acc: 0.343786. Batch_loss: 1.875158 \n",
      "Batch: 2015. Acc: 0.339299. Loss: 1.887386. Batch_acc: 0.361846. Batch_loss: 1.812018 \n",
      "Batch: 2016. Acc: 0.339304. Loss: 1.887364. Batch_acc: 0.349515. Batch_loss: 1.844324 \n",
      "Batch: 2017. Acc: 0.339307. Loss: 1.887366. Batch_acc: 0.345224. Batch_loss: 1.889942 \n",
      "Batch: 2018. Acc: 0.339318. Loss: 1.887338. Batch_acc: 0.361287. Batch_loss: 1.832146 \n",
      "Batch: 2019. Acc: 0.339331. Loss: 1.887303. Batch_acc: 0.364903. Batch_loss: 1.818290 \n",
      "Batch: 2020. Acc: 0.339335. Loss: 1.887277. Batch_acc: 0.348123. Batch_loss: 1.835356 \n",
      "Batch: 2021. Acc: 0.339342. Loss: 1.887254. Batch_acc: 0.352671. Batch_loss: 1.840003 \n",
      "Batch: 2022. Acc: 0.339346. Loss: 1.887241. Batch_acc: 0.347522. Batch_loss: 1.862419 \n",
      "Batch: 2023. Acc: 0.339355. Loss: 1.887210. Batch_acc: 0.358813. Batch_loss: 1.823924 \n",
      "Batch: 2024. Acc: 0.339365. Loss: 1.887179. Batch_acc: 0.359167. Batch_loss: 1.823589 \n",
      "Batch: 2025. Acc: 0.339369. Loss: 1.887174. Batch_acc: 0.348178. Batch_loss: 1.878556 \n",
      "Batch: 2026. Acc: 0.339378. Loss: 1.887153. Batch_acc: 0.357474. Batch_loss: 1.843537 \n",
      "Batch: 2027. Acc: 0.339384. Loss: 1.887130. Batch_acc: 0.350877. Batch_loss: 1.840314 \n",
      "Batch: 2028. Acc: 0.339389. Loss: 1.887104. Batch_acc: 0.349498. Batch_loss: 1.836295 \n",
      "Batch: 2029. Acc: 0.339396. Loss: 1.887082. Batch_acc: 0.352941. Batch_loss: 1.842225 \n",
      "Batch: 2030. Acc: 0.339403. Loss: 1.887064. Batch_acc: 0.354726. Batch_loss: 1.851686 \n",
      "Batch: 2031. Acc: 0.339400. Loss: 1.887060. Batch_acc: 0.332582. Batch_loss: 1.877211 \n",
      "Batch: 2032. Acc: 0.339402. Loss: 1.887044. Batch_acc: 0.343768. Batch_loss: 1.854600 \n",
      "Batch: 2033. Acc: 0.339413. Loss: 1.887009. Batch_acc: 0.360860. Batch_loss: 1.817145 \n",
      "Batch: 2034. Acc: 0.339426. Loss: 1.886983. Batch_acc: 0.366139. Batch_loss: 1.833024 \n",
      "Batch: 2035. Acc: 0.339430. Loss: 1.886956. Batch_acc: 0.349280. Batch_loss: 1.832603 \n",
      "Batch: 2036. Acc: 0.339445. Loss: 1.886912. Batch_acc: 0.369318. Batch_loss: 1.797019 \n",
      "Batch: 2037. Acc: 0.339460. Loss: 1.886871. Batch_acc: 0.369108. Batch_loss: 1.805307 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2038. Acc: 0.339461. Loss: 1.886868. Batch_acc: 0.340922. Batch_loss: 1.879673 \n",
      "Batch: 2039. Acc: 0.339455. Loss: 1.886867. Batch_acc: 0.328671. Batch_loss: 1.885220 \n",
      "Batch: 2040. Acc: 0.339463. Loss: 1.886829. Batch_acc: 0.354895. Batch_loss: 1.809786 \n",
      "Batch: 2041. Acc: 0.339472. Loss: 1.886797. Batch_acc: 0.357705. Batch_loss: 1.822736 \n",
      "Batch: 2042. Acc: 0.339475. Loss: 1.886792. Batch_acc: 0.345519. Batch_loss: 1.874561 \n",
      "Batch: 2043. Acc: 0.339477. Loss: 1.886775. Batch_acc: 0.343822. Batch_loss: 1.852339 \n",
      "Batch: 2044. Acc: 0.339487. Loss: 1.886752. Batch_acc: 0.359240. Batch_loss: 1.841108 \n",
      "Batch: 2045. Acc: 0.339495. Loss: 1.886725. Batch_acc: 0.356148. Batch_loss: 1.831546 \n",
      "Batch: 2046. Acc: 0.339504. Loss: 1.886689. Batch_acc: 0.358469. Batch_loss: 1.811017 \n",
      "Batch: 2047. Acc: 0.339504. Loss: 1.886688. Batch_acc: 0.338766. Batch_loss: 1.884336 \n",
      "Batch: 2048. Acc: 0.339512. Loss: 1.886664. Batch_acc: 0.356706. Batch_loss: 1.840584 \n",
      "Batch: 2049. Acc: 0.339507. Loss: 1.886662. Batch_acc: 0.328152. Batch_loss: 1.882332 \n",
      "Batch: 2050. Acc: 0.339505. Loss: 1.886645. Batch_acc: 0.336390. Batch_loss: 1.851519 \n",
      "Batch: 2051. Acc: 0.339509. Loss: 1.886627. Batch_acc: 0.346424. Batch_loss: 1.849088 \n",
      "Batch: 2052. Acc: 0.339514. Loss: 1.886607. Batch_acc: 0.350142. Batch_loss: 1.846706 \n",
      "Batch: 2053. Acc: 0.339522. Loss: 1.886578. Batch_acc: 0.355991. Batch_loss: 1.826145 \n",
      "Batch: 2054. Acc: 0.339525. Loss: 1.886560. Batch_acc: 0.345826. Batch_loss: 1.851015 \n",
      "Batch: 2055. Acc: 0.339534. Loss: 1.886526. Batch_acc: 0.357997. Batch_loss: 1.817291 \n",
      "Batch: 2056. Acc: 0.339533. Loss: 1.886516. Batch_acc: 0.336806. Batch_loss: 1.864760 \n",
      "Batch: 2057. Acc: 0.339535. Loss: 1.886515. Batch_acc: 0.345050. Batch_loss: 1.885399 \n",
      "Batch: 2058. Acc: 0.339548. Loss: 1.886485. Batch_acc: 0.365812. Batch_loss: 1.825549 \n",
      "Batch: 2059. Acc: 0.339548. Loss: 1.886476. Batch_acc: 0.338045. Batch_loss: 1.866502 \n",
      "Batch: 2060. Acc: 0.339554. Loss: 1.886440. Batch_acc: 0.354204. Batch_loss: 1.809195 \n",
      "Batch: 2061. Acc: 0.339562. Loss: 1.886406. Batch_acc: 0.354344. Batch_loss: 1.816726 \n",
      "Batch: 2062. Acc: 0.339574. Loss: 1.886372. Batch_acc: 0.366394. Batch_loss: 1.817063 \n",
      "Batch: 2063. Acc: 0.339583. Loss: 1.886328. Batch_acc: 0.356243. Batch_loss: 1.795196 \n",
      "Batch: 2064. Acc: 0.339587. Loss: 1.886319. Batch_acc: 0.347851. Batch_loss: 1.868100 \n",
      "Batch: 2065. Acc: 0.339592. Loss: 1.886298. Batch_acc: 0.350480. Batch_loss: 1.844052 \n",
      "Batch: 2066. Acc: 0.339595. Loss: 1.886268. Batch_acc: 0.344867. Batch_loss: 1.823616 \n",
      "Batch: 2067. Acc: 0.339596. Loss: 1.886257. Batch_acc: 0.343533. Batch_loss: 1.863194 \n",
      "Batch: 2068. Acc: 0.339609. Loss: 1.886218. Batch_acc: 0.365783. Batch_loss: 1.805465 \n",
      "Batch: 2069. Acc: 0.339622. Loss: 1.886177. Batch_acc: 0.365757. Batch_loss: 1.803032 \n",
      "Batch: 2070. Acc: 0.339625. Loss: 1.886168. Batch_acc: 0.345994. Batch_loss: 1.866566 \n",
      "Batch: 2071. Acc: 0.339632. Loss: 1.886147. Batch_acc: 0.354654. Batch_loss: 1.843484 \n",
      "Batch: 2072. Acc: 0.339641. Loss: 1.886108. Batch_acc: 0.359078. Batch_loss: 1.803914 \n",
      "Batch: 2073. Acc: 0.339651. Loss: 1.886087. Batch_acc: 0.359639. Batch_loss: 1.843768 \n",
      "Batch: 2074. Acc: 0.339660. Loss: 1.886053. Batch_acc: 0.357507. Batch_loss: 1.816424 \n",
      "Batch: 2075. Acc: 0.339663. Loss: 1.886024. Batch_acc: 0.345559. Batch_loss: 1.826887 \n",
      "Batch: 2076. Acc: 0.339671. Loss: 1.885987. Batch_acc: 0.356157. Batch_loss: 1.807564 \n",
      "Batch: 2077. Acc: 0.339681. Loss: 1.885952. Batch_acc: 0.360155. Batch_loss: 1.817150 \n",
      "Batch: 2078. Acc: 0.339693. Loss: 1.885911. Batch_acc: 0.363021. Batch_loss: 1.802897 \n",
      "Batch: 2079. Acc: 0.339700. Loss: 1.885874. Batch_acc: 0.355286. Batch_loss: 1.807190 \n",
      "Batch: 2080. Acc: 0.339713. Loss: 1.885839. Batch_acc: 0.367139. Batch_loss: 1.814297 \n",
      "Batch: 2081. Acc: 0.339720. Loss: 1.885820. Batch_acc: 0.352482. Batch_loss: 1.847897 \n",
      "Batch: 2082. Acc: 0.339731. Loss: 1.885802. Batch_acc: 0.363584. Batch_loss: 1.847817 \n",
      "Batch: 2083. Acc: 0.339749. Loss: 1.885766. Batch_acc: 0.377153. Batch_loss: 1.810954 \n",
      "Batch: 2084. Acc: 0.339762. Loss: 1.885727. Batch_acc: 0.366189. Batch_loss: 1.804779 \n",
      "Batch: 2085. Acc: 0.339763. Loss: 1.885710. Batch_acc: 0.342016. Batch_loss: 1.850864 \n",
      "Batch: 2086. Acc: 0.339775. Loss: 1.885679. Batch_acc: 0.363636. Batch_loss: 1.823213 \n",
      "Batch: 2087. Acc: 0.339777. Loss: 1.885656. Batch_acc: 0.344451. Batch_loss: 1.836369 \n",
      "Batch: 2088. Acc: 0.339786. Loss: 1.885636. Batch_acc: 0.359320. Batch_loss: 1.843682 \n",
      "Batch: 2089. Acc: 0.339790. Loss: 1.885618. Batch_acc: 0.348328. Batch_loss: 1.848221 \n",
      "Batch: 2090. Acc: 0.339785. Loss: 1.885611. Batch_acc: 0.329619. Batch_loss: 1.869794 \n",
      "Batch: 2091. Acc: 0.339785. Loss: 1.885600. Batch_acc: 0.339202. Batch_loss: 1.863596 \n",
      "Batch: 2092. Acc: 0.339796. Loss: 1.885576. Batch_acc: 0.362852. Batch_loss: 1.835130 \n",
      "Batch: 2093. Acc: 0.339804. Loss: 1.885550. Batch_acc: 0.355278. Batch_loss: 1.830591 \n",
      "Batch: 2094. Acc: 0.339805. Loss: 1.885538. Batch_acc: 0.343091. Batch_loss: 1.860494 \n",
      "Batch: 2095. Acc: 0.339819. Loss: 1.885500. Batch_acc: 0.368725. Batch_loss: 1.805822 \n",
      "Batch: 2096. Acc: 0.339834. Loss: 1.885453. Batch_acc: 0.370621. Batch_loss: 1.789166 \n",
      "Batch: 2097. Acc: 0.339835. Loss: 1.885443. Batch_acc: 0.341682. Batch_loss: 1.862438 \n",
      "Batch: 2098. Acc: 0.339839. Loss: 1.885429. Batch_acc: 0.348727. Batch_loss: 1.855999 \n",
      "Batch: 2099. Acc: 0.339845. Loss: 1.885413. Batch_acc: 0.353107. Batch_loss: 1.852674 \n",
      "Batch: 2100. Acc: 0.339855. Loss: 1.885383. Batch_acc: 0.359725. Batch_loss: 1.823117 \n",
      "Batch: 2101. Acc: 0.339860. Loss: 1.885357. Batch_acc: 0.350029. Batch_loss: 1.830068 \n",
      "Batch: 2102. Acc: 0.339866. Loss: 1.885331. Batch_acc: 0.353582. Batch_loss: 1.831280 \n",
      "Batch: 2103. Acc: 0.339867. Loss: 1.885318. Batch_acc: 0.341816. Batch_loss: 1.857599 \n",
      "Batch: 2104. Acc: 0.339873. Loss: 1.885297. Batch_acc: 0.353594. Batch_loss: 1.839731 \n",
      "Batch: 2105. Acc: 0.339874. Loss: 1.885295. Batch_acc: 0.341163. Batch_loss: 1.880257 \n",
      "Batch: 2106. Acc: 0.339879. Loss: 1.885271. Batch_acc: 0.350887. Batch_loss: 1.835457 \n",
      "Batch: 2107. Acc: 0.339891. Loss: 1.885256. Batch_acc: 0.364169. Batch_loss: 1.853405 \n",
      "Batch: 2108. Acc: 0.339888. Loss: 1.885264. Batch_acc: 0.334655. Batch_loss: 1.901827 \n",
      "Batch: 2109. Acc: 0.339889. Loss: 1.885255. Batch_acc: 0.341251. Batch_loss: 1.866967 \n",
      "Batch: 2110. Acc: 0.339900. Loss: 1.885230. Batch_acc: 0.362706. Batch_loss: 1.833402 \n",
      "Batch: 2111. Acc: 0.339897. Loss: 1.885216. Batch_acc: 0.335017. Batch_loss: 1.856124 \n",
      "Batch: 2112. Acc: 0.339903. Loss: 1.885202. Batch_acc: 0.352497. Batch_loss: 1.853808 \n",
      "Batch: 2113. Acc: 0.339906. Loss: 1.885186. Batch_acc: 0.344710. Batch_loss: 1.852270 \n",
      "Batch: 2114. Acc: 0.339908. Loss: 1.885172. Batch_acc: 0.345538. Batch_loss: 1.855769 \n",
      "Batch: 2115. Acc: 0.339910. Loss: 1.885160. Batch_acc: 0.342742. Batch_loss: 1.859635 \n",
      "Batch: 2116. Acc: 0.339918. Loss: 1.885143. Batch_acc: 0.358415. Batch_loss: 1.850298 \n",
      "Batch: 2117. Acc: 0.339925. Loss: 1.885134. Batch_acc: 0.355026. Batch_loss: 1.864708 \n",
      "Batch: 2118. Acc: 0.339933. Loss: 1.885111. Batch_acc: 0.357020. Batch_loss: 1.837823 \n",
      "Batch: 2119. Acc: 0.339938. Loss: 1.885091. Batch_acc: 0.348943. Batch_loss: 1.841318 \n",
      "Batch: 2120. Acc: 0.339943. Loss: 1.885084. Batch_acc: 0.352220. Batch_loss: 1.870911 \n",
      "Batch: 2121. Acc: 0.339951. Loss: 1.885058. Batch_acc: 0.356425. Batch_loss: 1.831087 \n",
      "Batch: 2122. Acc: 0.339970. Loss: 1.885023. Batch_acc: 0.380137. Batch_loss: 1.812083 \n",
      "Batch: 2123. Acc: 0.339982. Loss: 1.884990. Batch_acc: 0.363431. Batch_loss: 1.816889 \n",
      "Batch: 2124. Acc: 0.339995. Loss: 1.884960. Batch_acc: 0.367589. Batch_loss: 1.822320 \n",
      "Batch: 2125. Acc: 0.340002. Loss: 1.884936. Batch_acc: 0.354416. Batch_loss: 1.832767 \n",
      "Batch: 2126. Acc: 0.340004. Loss: 1.884918. Batch_acc: 0.344928. Batch_loss: 1.846674 \n",
      "Batch: 2127. Acc: 0.340015. Loss: 1.884885. Batch_acc: 0.363061. Batch_loss: 1.815243 \n",
      "Batch: 2128. Acc: 0.340021. Loss: 1.884877. Batch_acc: 0.353428. Batch_loss: 1.866956 \n",
      "Batch: 2129. Acc: 0.340022. Loss: 1.884869. Batch_acc: 0.341116. Batch_loss: 1.868327 \n",
      "Batch: 2130. Acc: 0.340026. Loss: 1.884855. Batch_acc: 0.348692. Batch_loss: 1.855578 \n",
      "Batch: 2131. Acc: 0.340027. Loss: 1.884850. Batch_acc: 0.342014. Batch_loss: 1.873137 \n",
      "Batch: 2132. Acc: 0.340028. Loss: 1.884852. Batch_acc: 0.342166. Batch_loss: 1.889199 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2133. Acc: 0.340033. Loss: 1.884825. Batch_acc: 0.351716. Batch_loss: 1.828979 \n",
      "Batch: 2134. Acc: 0.340034. Loss: 1.884823. Batch_acc: 0.340987. Batch_loss: 1.880219 \n",
      "Batch: 2135. Acc: 0.340038. Loss: 1.884800. Batch_acc: 0.349051. Batch_loss: 1.835555 \n",
      "Batch: 2136. Acc: 0.340043. Loss: 1.884781. Batch_acc: 0.349859. Batch_loss: 1.845392 \n",
      "Batch: 2137. Acc: 0.340044. Loss: 1.884752. Batch_acc: 0.343520. Batch_loss: 1.824178 \n",
      "Batch: 2138. Acc: 0.340049. Loss: 1.884726. Batch_acc: 0.349630. Batch_loss: 1.829221 \n",
      "Batch: 2139. Acc: 0.340059. Loss: 1.884695. Batch_acc: 0.361254. Batch_loss: 1.820448 \n",
      "Batch: 2140. Acc: 0.340067. Loss: 1.884663. Batch_acc: 0.357635. Batch_loss: 1.816328 \n",
      "Batch: 2141. Acc: 0.340084. Loss: 1.884607. Batch_acc: 0.377294. Batch_loss: 1.765194 \n",
      "Batch: 2142. Acc: 0.340099. Loss: 1.884556. Batch_acc: 0.371281. Batch_loss: 1.774304 \n",
      "Batch: 2143. Acc: 0.340106. Loss: 1.884532. Batch_acc: 0.354048. Batch_loss: 1.833806 \n",
      "Batch: 2144. Acc: 0.340105. Loss: 1.884523. Batch_acc: 0.339644. Batch_loss: 1.866682 \n",
      "Batch: 2145. Acc: 0.340120. Loss: 1.884485. Batch_acc: 0.370392. Batch_loss: 1.801657 \n",
      "Batch: 2146. Acc: 0.340121. Loss: 1.884474. Batch_acc: 0.343370. Batch_loss: 1.861524 \n",
      "Batch: 2147. Acc: 0.340124. Loss: 1.884462. Batch_acc: 0.346597. Batch_loss: 1.857851 \n",
      "Batch: 2148. Acc: 0.340138. Loss: 1.884433. Batch_acc: 0.370222. Batch_loss: 1.823374 \n",
      "Batch: 2149. Acc: 0.340150. Loss: 1.884403. Batch_acc: 0.366548. Batch_loss: 1.816899 \n",
      "Batch: 2150. Acc: 0.340145. Loss: 1.884399. Batch_acc: 0.328087. Batch_loss: 1.876740 \n",
      "Batch: 2151. Acc: 0.340148. Loss: 1.884383. Batch_acc: 0.347089. Batch_loss: 1.849239 \n",
      "Batch: 2152. Acc: 0.340156. Loss: 1.884362. Batch_acc: 0.356856. Batch_loss: 1.840588 \n",
      "Batch: 2153. Acc: 0.340163. Loss: 1.884342. Batch_acc: 0.355182. Batch_loss: 1.841330 \n",
      "Batch: 2154. Acc: 0.340173. Loss: 1.884315. Batch_acc: 0.362739. Batch_loss: 1.825122 \n",
      "Batch: 2155. Acc: 0.340179. Loss: 1.884295. Batch_acc: 0.352088. Batch_loss: 1.842398 \n",
      "Batch: 2156. Acc: 0.340185. Loss: 1.884269. Batch_acc: 0.352601. Batch_loss: 1.827886 \n",
      "Batch: 2157. Acc: 0.340182. Loss: 1.884250. Batch_acc: 0.335063. Batch_loss: 1.842048 \n",
      "Batch: 2158. Acc: 0.340182. Loss: 1.884234. Batch_acc: 0.338652. Batch_loss: 1.849280 \n",
      "Batch: 2159. Acc: 0.340187. Loss: 1.884211. Batch_acc: 0.351673. Batch_loss: 1.836121 \n",
      "Batch: 2160. Acc: 0.340188. Loss: 1.884191. Batch_acc: 0.341590. Batch_loss: 1.839758 \n",
      "Batch: 2161. Acc: 0.340201. Loss: 1.884159. Batch_acc: 0.368063. Batch_loss: 1.816012 \n",
      "Batch: 2162. Acc: 0.340208. Loss: 1.884138. Batch_acc: 0.355226. Batch_loss: 1.838270 \n",
      "Batch: 2163. Acc: 0.340216. Loss: 1.884119. Batch_acc: 0.358304. Batch_loss: 1.843242 \n",
      "Batch: 2164. Acc: 0.340220. Loss: 1.884092. Batch_acc: 0.349742. Batch_loss: 1.826623 \n",
      "Batch: 2165. Acc: 0.340230. Loss: 1.884052. Batch_acc: 0.360360. Batch_loss: 1.799696 \n",
      "Batch: 2166. Acc: 0.340235. Loss: 1.884026. Batch_acc: 0.352144. Batch_loss: 1.828410 \n",
      "Batch: 2167. Acc: 0.340244. Loss: 1.884013. Batch_acc: 0.357223. Batch_loss: 1.855735 \n",
      "Batch: 2168. Acc: 0.340252. Loss: 1.883987. Batch_acc: 0.358405. Batch_loss: 1.827963 \n",
      "Batch: 2169. Acc: 0.340260. Loss: 1.883974. Batch_acc: 0.358166. Batch_loss: 1.855912 \n",
      "Batch: 2170. Acc: 0.340264. Loss: 1.883952. Batch_acc: 0.348468. Batch_loss: 1.838375 \n",
      "Batch: 2171. Acc: 0.340270. Loss: 1.883937. Batch_acc: 0.354312. Batch_loss: 1.850087 \n",
      "Batch: 2172. Acc: 0.340271. Loss: 1.883925. Batch_acc: 0.342227. Batch_loss: 1.857704 \n",
      "Batch: 2173. Acc: 0.340272. Loss: 1.883905. Batch_acc: 0.341750. Batch_loss: 1.840453 \n",
      "Batch: 2174. Acc: 0.340271. Loss: 1.883887. Batch_acc: 0.337923. Batch_loss: 1.843944 \n",
      "Batch: 2175. Acc: 0.340282. Loss: 1.883867. Batch_acc: 0.364111. Batch_loss: 1.840300 \n",
      "Batch: 2176. Acc: 0.340284. Loss: 1.883846. Batch_acc: 0.346087. Batch_loss: 1.838516 \n",
      "Batch: 2177. Acc: 0.340287. Loss: 1.883829. Batch_acc: 0.346963. Batch_loss: 1.846309 \n",
      "Batch: 2178. Acc: 0.340294. Loss: 1.883801. Batch_acc: 0.355478. Batch_loss: 1.820415 \n",
      "Batch: 2179. Acc: 0.340296. Loss: 1.883791. Batch_acc: 0.342808. Batch_loss: 1.862516 \n",
      "Batch: 2180. Acc: 0.340305. Loss: 1.883760. Batch_acc: 0.361095. Batch_loss: 1.817995 \n",
      "Batch: 2181. Acc: 0.340312. Loss: 1.883744. Batch_acc: 0.355429. Batch_loss: 1.847419 \n",
      "Batch: 2182. Acc: 0.340310. Loss: 1.883721. Batch_acc: 0.335652. Batch_loss: 1.834884 \n",
      "Batch: 2183. Acc: 0.340316. Loss: 1.883722. Batch_acc: 0.353977. Batch_loss: 1.884483 \n",
      "Batch: 2184. Acc: 0.340333. Loss: 1.883693. Batch_acc: 0.376083. Batch_loss: 1.820410 \n",
      "Batch: 2185. Acc: 0.340350. Loss: 1.883663. Batch_acc: 0.378118. Batch_loss: 1.819779 \n",
      "Batch: 2186. Acc: 0.340358. Loss: 1.883626. Batch_acc: 0.356816. Batch_loss: 1.801581 \n",
      "Batch: 2187. Acc: 0.340357. Loss: 1.883613. Batch_acc: 0.338286. Batch_loss: 1.855107 \n",
      "Batch: 2188. Acc: 0.340372. Loss: 1.883578. Batch_acc: 0.373092. Batch_loss: 1.810284 \n",
      "Batch: 2189. Acc: 0.340378. Loss: 1.883562. Batch_acc: 0.353730. Batch_loss: 1.846067 \n",
      "Batch: 2190. Acc: 0.340382. Loss: 1.883540. Batch_acc: 0.350176. Batch_loss: 1.834992 \n",
      "Batch: 2191. Acc: 0.340377. Loss: 1.883528. Batch_acc: 0.329055. Batch_loss: 1.857837 \n",
      "Batch: 2192. Acc: 0.340387. Loss: 1.883504. Batch_acc: 0.360582. Batch_loss: 1.832170 \n",
      "Batch: 2193. Acc: 0.340388. Loss: 1.883493. Batch_acc: 0.342841. Batch_loss: 1.858754 \n",
      "Batch: 2194. Acc: 0.340395. Loss: 1.883477. Batch_acc: 0.356362. Batch_loss: 1.848585 \n",
      "Batch: 2195. Acc: 0.340403. Loss: 1.883457. Batch_acc: 0.358192. Batch_loss: 1.840636 \n",
      "Batch: 2196. Acc: 0.340405. Loss: 1.883427. Batch_acc: 0.343360. Batch_loss: 1.817757 \n",
      "Batch: 2197. Acc: 0.340407. Loss: 1.883411. Batch_acc: 0.344646. Batch_loss: 1.847368 \n",
      "Batch: 2198. Acc: 0.340406. Loss: 1.883412. Batch_acc: 0.339578. Batch_loss: 1.886598 \n",
      "Batch: 2199. Acc: 0.340418. Loss: 1.883392. Batch_acc: 0.366117. Batch_loss: 1.839387 \n",
      "Batch: 2200. Acc: 0.340426. Loss: 1.883378. Batch_acc: 0.357432. Batch_loss: 1.851484 \n",
      "Batch: 2201. Acc: 0.340433. Loss: 1.883360. Batch_acc: 0.355581. Batch_loss: 1.845129 \n",
      "Batch: 2202. Acc: 0.340432. Loss: 1.883343. Batch_acc: 0.338125. Batch_loss: 1.844855 \n",
      "Batch: 2203. Acc: 0.340432. Loss: 1.883325. Batch_acc: 0.340672. Batch_loss: 1.844371 \n",
      "Batch: 2204. Acc: 0.340437. Loss: 1.883306. Batch_acc: 0.352941. Batch_loss: 1.840797 \n",
      "Batch: 2205. Acc: 0.340445. Loss: 1.883279. Batch_acc: 0.357766. Batch_loss: 1.823701 \n",
      "Batch: 2206. Acc: 0.340447. Loss: 1.883277. Batch_acc: 0.344068. Batch_loss: 1.879759 \n",
      "Batch: 2207. Acc: 0.340448. Loss: 1.883279. Batch_acc: 0.343037. Batch_loss: 1.886712 \n",
      "Batch: 2208. Acc: 0.340448. Loss: 1.883265. Batch_acc: 0.341216. Batch_loss: 1.852367 \n",
      "Batch: 2209. Acc: 0.340458. Loss: 1.883253. Batch_acc: 0.361800. Batch_loss: 1.856423 \n",
      "Batch: 2210. Acc: 0.340459. Loss: 1.883252. Batch_acc: 0.343053. Batch_loss: 1.882846 \n",
      "Batch: 2211. Acc: 0.340460. Loss: 1.883238. Batch_acc: 0.341067. Batch_loss: 1.850401 \n",
      "Batch: 2212. Acc: 0.340465. Loss: 1.883234. Batch_acc: 0.353175. Batch_loss: 1.874269 \n",
      "Batch: 2213. Acc: 0.340467. Loss: 1.883225. Batch_acc: 0.343023. Batch_loss: 1.864732 \n",
      "Batch: 2214. Acc: 0.340465. Loss: 1.883217. Batch_acc: 0.337995. Batch_loss: 1.863570 \n",
      "Batch: 2215. Acc: 0.340462. Loss: 1.883217. Batch_acc: 0.333714. Batch_loss: 1.885276 \n",
      "Batch: 2216. Acc: 0.340463. Loss: 1.883201. Batch_acc: 0.341618. Batch_loss: 1.845889 \n",
      "Batch: 2217. Acc: 0.340469. Loss: 1.883182. Batch_acc: 0.353846. Batch_loss: 1.842282 \n",
      "Batch: 2218. Acc: 0.340478. Loss: 1.883165. Batch_acc: 0.360158. Batch_loss: 1.845217 \n",
      "Batch: 2219. Acc: 0.340479. Loss: 1.883165. Batch_acc: 0.341969. Batch_loss: 1.885118 \n",
      "Batch: 2220. Acc: 0.340486. Loss: 1.883149. Batch_acc: 0.356328. Batch_loss: 1.847484 \n",
      "Batch: 2221. Acc: 0.340494. Loss: 1.883134. Batch_acc: 0.358437. Batch_loss: 1.849909 \n",
      "Batch: 2222. Acc: 0.340491. Loss: 1.883133. Batch_acc: 0.334664. Batch_loss: 1.880617 \n",
      "Batch: 2223. Acc: 0.340504. Loss: 1.883105. Batch_acc: 0.368571. Batch_loss: 1.820891 \n",
      "Batch: 2224. Acc: 0.340509. Loss: 1.883079. Batch_acc: 0.350510. Batch_loss: 1.825559 \n",
      "Batch: 2225. Acc: 0.340509. Loss: 1.883079. Batch_acc: 0.340719. Batch_loss: 1.883272 \n",
      "Batch: 2226. Acc: 0.340521. Loss: 1.883050. Batch_acc: 0.366952. Batch_loss: 1.820013 \n",
      "Batch: 2227. Acc: 0.340520. Loss: 1.883035. Batch_acc: 0.338252. Batch_loss: 1.850505 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2228. Acc: 0.340522. Loss: 1.883019. Batch_acc: 0.346219. Batch_loss: 1.846800 \n",
      "Batch: 2229. Acc: 0.340527. Loss: 1.882997. Batch_acc: 0.349887. Batch_loss: 1.835805 \n",
      "Batch: 2230. Acc: 0.340528. Loss: 1.882984. Batch_acc: 0.344552. Batch_loss: 1.853959 \n",
      "Batch: 2231. Acc: 0.340530. Loss: 1.882977. Batch_acc: 0.343137. Batch_loss: 1.868101 \n",
      "Batch: 2232. Acc: 0.340529. Loss: 1.882978. Batch_acc: 0.338838. Batch_loss: 1.884010 \n",
      "Batch: 2233. Acc: 0.340535. Loss: 1.882944. Batch_acc: 0.354654. Batch_loss: 1.807769 \n",
      "Batch: 2234. Acc: 0.340541. Loss: 1.882927. Batch_acc: 0.354095. Batch_loss: 1.845336 \n",
      "Batch: 2235. Acc: 0.340552. Loss: 1.882909. Batch_acc: 0.364215. Batch_loss: 1.842346 \n",
      "Batch: 2236. Acc: 0.340553. Loss: 1.882897. Batch_acc: 0.343470. Batch_loss: 1.854415 \n",
      "Batch: 2237. Acc: 0.340549. Loss: 1.882894. Batch_acc: 0.331126. Batch_loss: 1.876975 \n",
      "Batch: 2238. Acc: 0.340556. Loss: 1.882868. Batch_acc: 0.355893. Batch_loss: 1.822041 \n",
      "Batch: 2239. Acc: 0.340561. Loss: 1.882843. Batch_acc: 0.352370. Batch_loss: 1.827997 \n",
      "Batch: 2240. Acc: 0.340574. Loss: 1.882808. Batch_acc: 0.368154. Batch_loss: 1.806533 \n",
      "Batch: 2241. Acc: 0.340576. Loss: 1.882793. Batch_acc: 0.347107. Batch_loss: 1.848799 \n",
      "Batch: 2242. Acc: 0.340580. Loss: 1.882775. Batch_acc: 0.348703. Batch_loss: 1.840770 \n",
      "Batch: 2243. Acc: 0.340582. Loss: 1.882778. Batch_acc: 0.344748. Batch_loss: 1.889855 \n",
      "Batch: 2244. Acc: 0.340585. Loss: 1.882761. Batch_acc: 0.347979. Batch_loss: 1.844707 \n",
      "Batch: 2245. Acc: 0.340585. Loss: 1.882767. Batch_acc: 0.339460. Batch_loss: 1.896043 \n",
      "Batch: 2246. Acc: 0.340594. Loss: 1.882753. Batch_acc: 0.362286. Batch_loss: 1.851938 \n",
      "Batch: 2247. Acc: 0.340603. Loss: 1.882724. Batch_acc: 0.360842. Batch_loss: 1.818234 \n",
      "Batch: 2248. Acc: 0.340613. Loss: 1.882700. Batch_acc: 0.361272. Batch_loss: 1.827814 \n",
      "Batch: 2249. Acc: 0.340614. Loss: 1.882692. Batch_acc: 0.344225. Batch_loss: 1.864603 \n",
      "Batch: 2250. Acc: 0.340619. Loss: 1.882670. Batch_acc: 0.350289. Batch_loss: 1.832374 \n",
      "Batch: 2251. Acc: 0.340620. Loss: 1.882658. Batch_acc: 0.344706. Batch_loss: 1.857114 \n",
      "Batch: 2252. Acc: 0.340626. Loss: 1.882634. Batch_acc: 0.354108. Batch_loss: 1.828297 \n",
      "Batch: 2253. Acc: 0.340633. Loss: 1.882621. Batch_acc: 0.356766. Batch_loss: 1.853725 \n",
      "Batch: 2254. Acc: 0.340639. Loss: 1.882605. Batch_acc: 0.351821. Batch_loss: 1.847190 \n",
      "Batch: 2255. Acc: 0.340642. Loss: 1.882600. Batch_acc: 0.348328. Batch_loss: 1.871250 \n",
      "Batch: 2256. Acc: 0.340652. Loss: 1.882566. Batch_acc: 0.362360. Batch_loss: 1.807887 \n",
      "Batch: 2257. Acc: 0.340650. Loss: 1.882561. Batch_acc: 0.335838. Batch_loss: 1.869549 \n",
      "Batch: 2258. Acc: 0.340647. Loss: 1.882566. Batch_acc: 0.333923. Batch_loss: 1.895198 \n",
      "Batch: 2259. Acc: 0.340652. Loss: 1.882546. Batch_acc: 0.353041. Batch_loss: 1.838028 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.34065236236765656. Loss per char: 1.882545869999492. Time: 1627208218.7629392\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 21, 18, 25, 19,\n",
      "        19, 20, 22, 26, 25, 26, 21, 23,  1, 66, 79, 69,  1, 17, 15, 17, 26, 26,\n",
      "        32,  3,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.340664. Loss: 1.882524. Batch_acc: 0.366108. Batch_loss: 1.833677 \n",
      "Batch: 2261. Acc: 0.340665. Loss: 1.882512. Batch_acc: 0.344509. Batch_loss: 1.854599 \n",
      "Batch: 2262. Acc: 0.340668. Loss: 1.882491. Batch_acc: 0.347410. Batch_loss: 1.836114 \n",
      "Batch: 2263. Acc: 0.340683. Loss: 1.882451. Batch_acc: 0.373060. Batch_loss: 1.795769 \n",
      "Batch: 2264. Acc: 0.340689. Loss: 1.882435. Batch_acc: 0.353307. Batch_loss: 1.845451 \n",
      "Batch: 2265. Acc: 0.340696. Loss: 1.882418. Batch_acc: 0.357268. Batch_loss: 1.844484 \n",
      "Batch: 2266. Acc: 0.340697. Loss: 1.882408. Batch_acc: 0.342641. Batch_loss: 1.859175 \n",
      "Batch: 2267. Acc: 0.340703. Loss: 1.882399. Batch_acc: 0.355478. Batch_loss: 1.862480 \n",
      "Batch: 2268. Acc: 0.340705. Loss: 1.882389. Batch_acc: 0.343874. Batch_loss: 1.860010 \n",
      "Batch: 2269. Acc: 0.340707. Loss: 1.882376. Batch_acc: 0.347021. Batch_loss: 1.851921 \n",
      "Batch: 2270. Acc: 0.340720. Loss: 1.882349. Batch_acc: 0.368239. Batch_loss: 1.822003 \n",
      "Batch: 2271. Acc: 0.340727. Loss: 1.882324. Batch_acc: 0.357719. Batch_loss: 1.825332 \n",
      "Batch: 2272. Acc: 0.340725. Loss: 1.882327. Batch_acc: 0.335795. Batch_loss: 1.887628 \n",
      "Batch: 2273. Acc: 0.340732. Loss: 1.882310. Batch_acc: 0.356692. Batch_loss: 1.844933 \n",
      "Batch: 2274. Acc: 0.340750. Loss: 1.882275. Batch_acc: 0.381901. Batch_loss: 1.801860 \n",
      "Batch: 2275. Acc: 0.340758. Loss: 1.882259. Batch_acc: 0.358252. Batch_loss: 1.847069 \n",
      "Batch: 2276. Acc: 0.340753. Loss: 1.882269. Batch_acc: 0.330291. Batch_loss: 1.904227 \n",
      "Batch: 2277. Acc: 0.340754. Loss: 1.882262. Batch_acc: 0.341363. Batch_loss: 1.865667 \n",
      "Batch: 2278. Acc: 0.340760. Loss: 1.882246. Batch_acc: 0.356282. Batch_loss: 1.846685 \n",
      "Batch: 2279. Acc: 0.340762. Loss: 1.882237. Batch_acc: 0.345665. Batch_loss: 1.861495 \n",
      "Batch: 2280. Acc: 0.340766. Loss: 1.882225. Batch_acc: 0.349123. Batch_loss: 1.855188 \n",
      "Batch: 2281. Acc: 0.340771. Loss: 1.882204. Batch_acc: 0.350967. Batch_loss: 1.833756 \n",
      "Batch: 2282. Acc: 0.340780. Loss: 1.882170. Batch_acc: 0.361777. Batch_loss: 1.804515 \n",
      "Batch: 2283. Acc: 0.340785. Loss: 1.882150. Batch_acc: 0.353483. Batch_loss: 1.836097 \n",
      "Batch: 2284. Acc: 0.340793. Loss: 1.882126. Batch_acc: 0.358074. Batch_loss: 1.826621 \n",
      "Batch: 2285. Acc: 0.340799. Loss: 1.882091. Batch_acc: 0.355518. Batch_loss: 1.804483 \n",
      "Batch: 2286. Acc: 0.340798. Loss: 1.882082. Batch_acc: 0.337987. Batch_loss: 1.859990 \n",
      "Batch: 2287. Acc: 0.340816. Loss: 1.882046. Batch_acc: 0.380653. Batch_loss: 1.801277 \n",
      "Batch: 2288. Acc: 0.340823. Loss: 1.882023. Batch_acc: 0.358053. Batch_loss: 1.829167 \n",
      "Batch: 2289. Acc: 0.340829. Loss: 1.882003. Batch_acc: 0.354131. Batch_loss: 1.836142 \n",
      "Batch: 2290. Acc: 0.340840. Loss: 1.881979. Batch_acc: 0.366197. Batch_loss: 1.827347 \n",
      "Batch: 2291. Acc: 0.340847. Loss: 1.881955. Batch_acc: 0.355362. Batch_loss: 1.825648 \n",
      "Batch: 2292. Acc: 0.340858. Loss: 1.881923. Batch_acc: 0.368575. Batch_loss: 1.808408 \n",
      "Batch: 2293. Acc: 0.340870. Loss: 1.881899. Batch_acc: 0.368390. Batch_loss: 1.826252 \n",
      "Batch: 2294. Acc: 0.340872. Loss: 1.881891. Batch_acc: 0.344807. Batch_loss: 1.863129 \n",
      "Batch: 2295. Acc: 0.340874. Loss: 1.881885. Batch_acc: 0.346535. Batch_loss: 1.867299 \n",
      "Batch: 2296. Acc: 0.340882. Loss: 1.881860. Batch_acc: 0.358841. Batch_loss: 1.824221 \n",
      "Batch: 2297. Acc: 0.340882. Loss: 1.881855. Batch_acc: 0.340413. Batch_loss: 1.872121 \n",
      "Batch: 2298. Acc: 0.340883. Loss: 1.881834. Batch_acc: 0.343912. Batch_loss: 1.831612 \n",
      "Batch: 2299. Acc: 0.340894. Loss: 1.881809. Batch_acc: 0.364265. Batch_loss: 1.826011 \n",
      "Batch: 2300. Acc: 0.340896. Loss: 1.881798. Batch_acc: 0.346310. Batch_loss: 1.854282 \n",
      "Batch: 2301. Acc: 0.340899. Loss: 1.881773. Batch_acc: 0.348943. Batch_loss: 1.826552 \n",
      "Batch: 2302. Acc: 0.340911. Loss: 1.881745. Batch_acc: 0.368421. Batch_loss: 1.816946 \n",
      "Batch: 2303. Acc: 0.340909. Loss: 1.881732. Batch_acc: 0.335656. Batch_loss: 1.851356 \n",
      "Batch: 2304. Acc: 0.340911. Loss: 1.881720. Batch_acc: 0.346109. Batch_loss: 1.852339 \n",
      "Batch: 2305. Acc: 0.340923. Loss: 1.881685. Batch_acc: 0.366629. Batch_loss: 1.803663 \n",
      "Batch: 2306. Acc: 0.340930. Loss: 1.881665. Batch_acc: 0.358501. Batch_loss: 1.834134 \n",
      "Batch: 2307. Acc: 0.340932. Loss: 1.881652. Batch_acc: 0.346286. Batch_loss: 1.852006 \n",
      "Batch: 2308. Acc: 0.340935. Loss: 1.881626. Batch_acc: 0.347622. Batch_loss: 1.819614 \n",
      "Batch: 2309. Acc: 0.340949. Loss: 1.881591. Batch_acc: 0.374269. Batch_loss: 1.800424 \n",
      "Batch: 2310. Acc: 0.340949. Loss: 1.881566. Batch_acc: 0.339120. Batch_loss: 1.822981 \n",
      "Batch: 2311. Acc: 0.340953. Loss: 1.881543. Batch_acc: 0.351009. Batch_loss: 1.829706 \n",
      "Batch: 2312. Acc: 0.340955. Loss: 1.881531. Batch_acc: 0.346466. Batch_loss: 1.853208 \n",
      "Batch: 2313. Acc: 0.340963. Loss: 1.881510. Batch_acc: 0.359700. Batch_loss: 1.833349 \n",
      "Batch: 2314. Acc: 0.340968. Loss: 1.881500. Batch_acc: 0.350083. Batch_loss: 1.859042 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2315. Acc: 0.340980. Loss: 1.881466. Batch_acc: 0.368362. Batch_loss: 1.802763 \n",
      "Batch: 2316. Acc: 0.340991. Loss: 1.881433. Batch_acc: 0.366513. Batch_loss: 1.806064 \n",
      "Batch: 2317. Acc: 0.341002. Loss: 1.881399. Batch_acc: 0.366246. Batch_loss: 1.801900 \n",
      "Batch: 2318. Acc: 0.341003. Loss: 1.881381. Batch_acc: 0.345258. Batch_loss: 1.839547 \n",
      "Batch: 2319. Acc: 0.341013. Loss: 1.881356. Batch_acc: 0.362600. Batch_loss: 1.825043 \n",
      "Batch: 2320. Acc: 0.341013. Loss: 1.881354. Batch_acc: 0.342317. Batch_loss: 1.877327 \n",
      "Batch: 2321. Acc: 0.341018. Loss: 1.881341. Batch_acc: 0.352413. Batch_loss: 1.852098 \n",
      "Batch: 2322. Acc: 0.341020. Loss: 1.881331. Batch_acc: 0.344828. Batch_loss: 1.857309 \n",
      "Batch: 2323. Acc: 0.341027. Loss: 1.881321. Batch_acc: 0.356692. Batch_loss: 1.858770 \n",
      "Batch: 2324. Acc: 0.341038. Loss: 1.881299. Batch_acc: 0.366724. Batch_loss: 1.830327 \n",
      "Batch: 2325. Acc: 0.341040. Loss: 1.881280. Batch_acc: 0.347093. Batch_loss: 1.836462 \n",
      "Batch: 2326. Acc: 0.341046. Loss: 1.881255. Batch_acc: 0.354155. Batch_loss: 1.823482 \n",
      "Batch: 2327. Acc: 0.341049. Loss: 1.881243. Batch_acc: 0.348387. Batch_loss: 1.850869 \n",
      "Batch: 2328. Acc: 0.341054. Loss: 1.881219. Batch_acc: 0.352908. Batch_loss: 1.827960 \n",
      "Batch: 2329. Acc: 0.341061. Loss: 1.881196. Batch_acc: 0.355991. Batch_loss: 1.827613 \n",
      "Batch: 2330. Acc: 0.341069. Loss: 1.881172. Batch_acc: 0.360184. Batch_loss: 1.825353 \n",
      "Batch: 2331. Acc: 0.341067. Loss: 1.881165. Batch_acc: 0.336892. Batch_loss: 1.863421 \n",
      "Batch: 2332. Acc: 0.341074. Loss: 1.881155. Batch_acc: 0.356355. Batch_loss: 1.857176 \n",
      "Batch: 2333. Acc: 0.341075. Loss: 1.881146. Batch_acc: 0.345026. Batch_loss: 1.860139 \n",
      "Batch: 2334. Acc: 0.341075. Loss: 1.881124. Batch_acc: 0.340584. Batch_loss: 1.829482 \n",
      "Batch: 2335. Acc: 0.341073. Loss: 1.881101. Batch_acc: 0.336800. Batch_loss: 1.828961 \n",
      "Batch: 2336. Acc: 0.341081. Loss: 1.881081. Batch_acc: 0.357907. Batch_loss: 1.834036 \n",
      "Batch: 2337. Acc: 0.341095. Loss: 1.881050. Batch_acc: 0.375145. Batch_loss: 1.807691 \n",
      "Batch: 2338. Acc: 0.341105. Loss: 1.881018. Batch_acc: 0.364310. Batch_loss: 1.808060 \n",
      "Batch: 2339. Acc: 0.341118. Loss: 1.880981. Batch_acc: 0.369965. Batch_loss: 1.793567 \n",
      "Batch: 2340. Acc: 0.341122. Loss: 1.880962. Batch_acc: 0.353118. Batch_loss: 1.834198 \n",
      "Batch: 2341. Acc: 0.341132. Loss: 1.880942. Batch_acc: 0.362852. Batch_loss: 1.836138 \n",
      "Batch: 2342. Acc: 0.341135. Loss: 1.880917. Batch_acc: 0.349462. Batch_loss: 1.818506 \n",
      "Batch: 2343. Acc: 0.341142. Loss: 1.880897. Batch_acc: 0.356009. Batch_loss: 1.835580 \n",
      "Batch: 2344. Acc: 0.341147. Loss: 1.880863. Batch_acc: 0.353734. Batch_loss: 1.802250 \n",
      "Batch: 2345. Acc: 0.341150. Loss: 1.880840. Batch_acc: 0.348321. Batch_loss: 1.827966 \n",
      "Batch: 2346. Acc: 0.341157. Loss: 1.880817. Batch_acc: 0.357551. Batch_loss: 1.826445 \n",
      "Batch: 2347. Acc: 0.341169. Loss: 1.880783. Batch_acc: 0.370392. Batch_loss: 1.801111 \n",
      "Batch: 2348. Acc: 0.341176. Loss: 1.880751. Batch_acc: 0.357562. Batch_loss: 1.802097 \n",
      "Batch: 2349. Acc: 0.341182. Loss: 1.880734. Batch_acc: 0.355709. Batch_loss: 1.841109 \n",
      "Batch: 2350. Acc: 0.341183. Loss: 1.880715. Batch_acc: 0.343446. Batch_loss: 1.837474 \n",
      "Batch: 2351. Acc: 0.341187. Loss: 1.880701. Batch_acc: 0.349243. Batch_loss: 1.848280 \n",
      "Batch: 2352. Acc: 0.341190. Loss: 1.880688. Batch_acc: 0.349171. Batch_loss: 1.849492 \n",
      "Batch: 2353. Acc: 0.341204. Loss: 1.880655. Batch_acc: 0.372939. Batch_loss: 1.804217 \n",
      "Batch: 2354. Acc: 0.341202. Loss: 1.880654. Batch_acc: 0.336886. Batch_loss: 1.879463 \n",
      "Batch: 2355. Acc: 0.341210. Loss: 1.880631. Batch_acc: 0.360560. Batch_loss: 1.825292 \n",
      "Batch: 2356. Acc: 0.341215. Loss: 1.880619. Batch_acc: 0.351981. Batch_loss: 1.852646 \n",
      "Batch: 2357. Acc: 0.341219. Loss: 1.880593. Batch_acc: 0.351831. Batch_loss: 1.819745 \n",
      "Batch: 2358. Acc: 0.341228. Loss: 1.880565. Batch_acc: 0.361127. Batch_loss: 1.814290 \n",
      "Batch: 2359. Acc: 0.341231. Loss: 1.880561. Batch_acc: 0.348302. Batch_loss: 1.871278 \n",
      "Batch: 2360. Acc: 0.341236. Loss: 1.880537. Batch_acc: 0.353307. Batch_loss: 1.823410 \n",
      "Batch: 2361. Acc: 0.341238. Loss: 1.880522. Batch_acc: 0.345476. Batch_loss: 1.844986 \n",
      "Batch: 2362. Acc: 0.341240. Loss: 1.880502. Batch_acc: 0.346267. Batch_loss: 1.832624 \n",
      "Batch: 2363. Acc: 0.341244. Loss: 1.880500. Batch_acc: 0.352227. Batch_loss: 1.875735 \n",
      "Batch: 2364. Acc: 0.341246. Loss: 1.880496. Batch_acc: 0.345423. Batch_loss: 1.871573 \n",
      "Batch: 2365. Acc: 0.341251. Loss: 1.880479. Batch_acc: 0.353423. Batch_loss: 1.838590 \n",
      "Batch: 2366. Acc: 0.341254. Loss: 1.880463. Batch_acc: 0.346713. Batch_loss: 1.841303 \n",
      "Batch: 2367. Acc: 0.341247. Loss: 1.880460. Batch_acc: 0.325143. Batch_loss: 1.874273 \n",
      "Batch: 2368. Acc: 0.341254. Loss: 1.880445. Batch_acc: 0.357686. Batch_loss: 1.843237 \n",
      "Batch: 2369. Acc: 0.341253. Loss: 1.880437. Batch_acc: 0.340698. Batch_loss: 1.862049 \n",
      "Batch: 2370. Acc: 0.341259. Loss: 1.880427. Batch_acc: 0.354949. Batch_loss: 1.856511 \n",
      "Batch: 2371. Acc: 0.341267. Loss: 1.880401. Batch_acc: 0.359366. Batch_loss: 1.819372 \n",
      "Batch: 2372. Acc: 0.341273. Loss: 1.880373. Batch_acc: 0.356188. Batch_loss: 1.811099 \n",
      "Batch: 2373. Acc: 0.341278. Loss: 1.880345. Batch_acc: 0.352707. Batch_loss: 1.814461 \n",
      "Batch: 2374. Acc: 0.341280. Loss: 1.880331. Batch_acc: 0.346870. Batch_loss: 1.848916 \n",
      "Batch: 2375. Acc: 0.341286. Loss: 1.880313. Batch_acc: 0.355839. Batch_loss: 1.835093 \n",
      "Batch: 2376. Acc: 0.341295. Loss: 1.880292. Batch_acc: 0.362344. Batch_loss: 1.830036 \n",
      "Batch: 2377. Acc: 0.341304. Loss: 1.880260. Batch_acc: 0.362847. Batch_loss: 1.805539 \n",
      "Batch: 2378. Acc: 0.341309. Loss: 1.880240. Batch_acc: 0.354023. Batch_loss: 1.830802 \n",
      "Batch: 2379. Acc: 0.341317. Loss: 1.880223. Batch_acc: 0.359910. Batch_loss: 1.842614 \n",
      "Batch: 2380. Acc: 0.341321. Loss: 1.880195. Batch_acc: 0.351242. Batch_loss: 1.812721 \n",
      "Batch: 2381. Acc: 0.341324. Loss: 1.880179. Batch_acc: 0.347878. Batch_loss: 1.839758 \n",
      "Batch: 2382. Acc: 0.341322. Loss: 1.880173. Batch_acc: 0.335122. Batch_loss: 1.866547 \n",
      "Batch: 2383. Acc: 0.341320. Loss: 1.880157. Batch_acc: 0.338004. Batch_loss: 1.841601 \n",
      "Batch: 2384. Acc: 0.341325. Loss: 1.880133. Batch_acc: 0.353553. Batch_loss: 1.821517 \n",
      "Batch: 2385. Acc: 0.341327. Loss: 1.880109. Batch_acc: 0.344476. Batch_loss: 1.825043 \n",
      "Batch: 2386. Acc: 0.341333. Loss: 1.880090. Batch_acc: 0.356052. Batch_loss: 1.831625 \n",
      "Batch: 2387. Acc: 0.341337. Loss: 1.880081. Batch_acc: 0.352542. Batch_loss: 1.860659 \n",
      "Batch: 2388. Acc: 0.341346. Loss: 1.880061. Batch_acc: 0.363106. Batch_loss: 1.830476 \n",
      "Batch: 2389. Acc: 0.341346. Loss: 1.880053. Batch_acc: 0.339988. Batch_loss: 1.861795 \n",
      "Batch: 2390. Acc: 0.341348. Loss: 1.880033. Batch_acc: 0.345745. Batch_loss: 1.830780 \n",
      "Batch: 2391. Acc: 0.341361. Loss: 1.880002. Batch_acc: 0.374635. Batch_loss: 1.804158 \n",
      "Batch: 2392. Acc: 0.341365. Loss: 1.879991. Batch_acc: 0.349565. Batch_loss: 1.854449 \n",
      "Batch: 2393. Acc: 0.341371. Loss: 1.879968. Batch_acc: 0.355023. Batch_loss: 1.824142 \n",
      "Batch: 2394. Acc: 0.341380. Loss: 1.879946. Batch_acc: 0.363061. Batch_loss: 1.827729 \n",
      "Batch: 2395. Acc: 0.341383. Loss: 1.879939. Batch_acc: 0.348592. Batch_loss: 1.863501 \n",
      "Batch: 2396. Acc: 0.341387. Loss: 1.879937. Batch_acc: 0.353397. Batch_loss: 1.874776 \n",
      "Batch: 2397. Acc: 0.341390. Loss: 1.879914. Batch_acc: 0.348333. Batch_loss: 1.825266 \n",
      "Batch: 2398. Acc: 0.341401. Loss: 1.879884. Batch_acc: 0.368145. Batch_loss: 1.808802 \n",
      "Batch: 2399. Acc: 0.341404. Loss: 1.879867. Batch_acc: 0.348931. Batch_loss: 1.836995 \n",
      "Batch: 2400. Acc: 0.341403. Loss: 1.879857. Batch_acc: 0.338924. Batch_loss: 1.855709 \n",
      "Batch: 2401. Acc: 0.341416. Loss: 1.879820. Batch_acc: 0.372225. Batch_loss: 1.791957 \n",
      "Batch: 2402. Acc: 0.341429. Loss: 1.879796. Batch_acc: 0.372696. Batch_loss: 1.821700 \n",
      "Batch: 2403. Acc: 0.341434. Loss: 1.879787. Batch_acc: 0.352154. Batch_loss: 1.859961 \n",
      "Batch: 2404. Acc: 0.341437. Loss: 1.879774. Batch_acc: 0.349971. Batch_loss: 1.848277 \n",
      "Batch: 2405. Acc: 0.341437. Loss: 1.879760. Batch_acc: 0.339955. Batch_loss: 1.845010 \n",
      "Batch: 2406. Acc: 0.341445. Loss: 1.879748. Batch_acc: 0.361013. Batch_loss: 1.850055 \n",
      "Batch: 2407. Acc: 0.341456. Loss: 1.879715. Batch_acc: 0.368754. Batch_loss: 1.801586 \n",
      "Batch: 2408. Acc: 0.341468. Loss: 1.879691. Batch_acc: 0.369021. Batch_loss: 1.822753 \n",
      "Batch: 2409. Acc: 0.341475. Loss: 1.879661. Batch_acc: 0.359679. Batch_loss: 1.808169 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2410. Acc: 0.341478. Loss: 1.879639. Batch_acc: 0.347246. Batch_loss: 1.826183 \n",
      "Batch: 2411. Acc: 0.341481. Loss: 1.879625. Batch_acc: 0.349447. Batch_loss: 1.845515 \n",
      "Batch: 2412. Acc: 0.341487. Loss: 1.879609. Batch_acc: 0.356527. Batch_loss: 1.840442 \n",
      "Batch: 2413. Acc: 0.341495. Loss: 1.879592. Batch_acc: 0.360498. Batch_loss: 1.838293 \n",
      "Batch: 2414. Acc: 0.341503. Loss: 1.879572. Batch_acc: 0.360532. Batch_loss: 1.830523 \n",
      "Batch: 2415. Acc: 0.341512. Loss: 1.879546. Batch_acc: 0.363173. Batch_loss: 1.819312 \n",
      "Batch: 2416. Acc: 0.341519. Loss: 1.879526. Batch_acc: 0.357728. Batch_loss: 1.830029 \n",
      "Batch: 2417. Acc: 0.341531. Loss: 1.879500. Batch_acc: 0.370950. Batch_loss: 1.819202 \n",
      "Batch: 2418. Acc: 0.341537. Loss: 1.879469. Batch_acc: 0.355846. Batch_loss: 1.805083 \n",
      "Batch: 2419. Acc: 0.341545. Loss: 1.879438. Batch_acc: 0.360371. Batch_loss: 1.804185 \n",
      "Batch: 2420. Acc: 0.341552. Loss: 1.879412. Batch_acc: 0.357798. Batch_loss: 1.816606 \n",
      "Batch: 2421. Acc: 0.341563. Loss: 1.879377. Batch_acc: 0.369824. Batch_loss: 1.794981 \n",
      "Batch: 2422. Acc: 0.341563. Loss: 1.879373. Batch_acc: 0.341303. Batch_loss: 1.870017 \n",
      "Batch: 2423. Acc: 0.341581. Loss: 1.879336. Batch_acc: 0.383799. Batch_loss: 1.791797 \n",
      "Batch: 2424. Acc: 0.341586. Loss: 1.879307. Batch_acc: 0.353952. Batch_loss: 1.809053 \n",
      "Batch: 2425. Acc: 0.341583. Loss: 1.879301. Batch_acc: 0.332944. Batch_loss: 1.865706 \n",
      "Batch: 2426. Acc: 0.341584. Loss: 1.879286. Batch_acc: 0.344329. Batch_loss: 1.842608 \n",
      "Batch: 2427. Acc: 0.341594. Loss: 1.879270. Batch_acc: 0.364666. Batch_loss: 1.839612 \n",
      "Batch: 2428. Acc: 0.341596. Loss: 1.879242. Batch_acc: 0.348361. Batch_loss: 1.811358 \n",
      "Batch: 2429. Acc: 0.341600. Loss: 1.879228. Batch_acc: 0.350263. Batch_loss: 1.843396 \n",
      "Batch: 2430. Acc: 0.341604. Loss: 1.879200. Batch_acc: 0.351197. Batch_loss: 1.812204 \n",
      "Batch: 2431. Acc: 0.341610. Loss: 1.879174. Batch_acc: 0.356651. Batch_loss: 1.816109 \n",
      "Batch: 2432. Acc: 0.341615. Loss: 1.879152. Batch_acc: 0.353828. Batch_loss: 1.825437 \n",
      "Batch: 2433. Acc: 0.341614. Loss: 1.879131. Batch_acc: 0.338964. Batch_loss: 1.828089 \n",
      "Batch: 2434. Acc: 0.341617. Loss: 1.879112. Batch_acc: 0.348864. Batch_loss: 1.833643 \n",
      "Batch: 2435. Acc: 0.341618. Loss: 1.879100. Batch_acc: 0.344413. Batch_loss: 1.849882 \n",
      "Batch: 2436. Acc: 0.341628. Loss: 1.879069. Batch_acc: 0.365840. Batch_loss: 1.805029 \n",
      "Batch: 2437. Acc: 0.341633. Loss: 1.879041. Batch_acc: 0.352673. Batch_loss: 1.809958 \n",
      "Batch: 2438. Acc: 0.341636. Loss: 1.879028. Batch_acc: 0.349773. Batch_loss: 1.848596 \n",
      "Batch: 2439. Acc: 0.341641. Loss: 1.878999. Batch_acc: 0.354250. Batch_loss: 1.810004 \n",
      "Batch: 2440. Acc: 0.341647. Loss: 1.878981. Batch_acc: 0.356296. Batch_loss: 1.834247 \n",
      "Batch: 2441. Acc: 0.341649. Loss: 1.878972. Batch_acc: 0.346041. Batch_loss: 1.855795 \n",
      "Batch: 2442. Acc: 0.341656. Loss: 1.878954. Batch_acc: 0.357756. Batch_loss: 1.835451 \n",
      "Batch: 2443. Acc: 0.341654. Loss: 1.878948. Batch_acc: 0.336854. Batch_loss: 1.864522 \n",
      "Batch: 2444. Acc: 0.341660. Loss: 1.878924. Batch_acc: 0.355807. Batch_loss: 1.822027 \n",
      "Batch: 2445. Acc: 0.341665. Loss: 1.878892. Batch_acc: 0.353652. Batch_loss: 1.800732 \n",
      "Batch: 2446. Acc: 0.341671. Loss: 1.878864. Batch_acc: 0.357060. Batch_loss: 1.808418 \n",
      "Batch: 2447. Acc: 0.341678. Loss: 1.878836. Batch_acc: 0.359679. Batch_loss: 1.812119 \n",
      "Batch: 2448. Acc: 0.341680. Loss: 1.878833. Batch_acc: 0.345773. Batch_loss: 1.869750 \n",
      "Batch: 2449. Acc: 0.341681. Loss: 1.878831. Batch_acc: 0.344991. Batch_loss: 1.876020 \n",
      "Batch: 2450. Acc: 0.341685. Loss: 1.878810. Batch_acc: 0.351039. Batch_loss: 1.826406 \n",
      "Batch: 2451. Acc: 0.341686. Loss: 1.878798. Batch_acc: 0.344099. Batch_loss: 1.847504 \n",
      "Batch: 2452. Acc: 0.341691. Loss: 1.878791. Batch_acc: 0.354875. Batch_loss: 1.862879 \n",
      "Batch: 2453. Acc: 0.341696. Loss: 1.878770. Batch_acc: 0.353078. Batch_loss: 1.825680 \n",
      "Batch: 2454. Acc: 0.341704. Loss: 1.878747. Batch_acc: 0.361460. Batch_loss: 1.822716 \n",
      "Batch: 2455. Acc: 0.341705. Loss: 1.878735. Batch_acc: 0.342657. Batch_loss: 1.850989 \n",
      "Batch: 2456. Acc: 0.341711. Loss: 1.878721. Batch_acc: 0.356977. Batch_loss: 1.841950 \n",
      "Batch: 2457. Acc: 0.341721. Loss: 1.878690. Batch_acc: 0.366221. Batch_loss: 1.805389 \n",
      "Batch: 2458. Acc: 0.341728. Loss: 1.878665. Batch_acc: 0.357421. Batch_loss: 1.820818 \n",
      "Batch: 2459. Acc: 0.341734. Loss: 1.878641. Batch_acc: 0.358899. Batch_loss: 1.816897 \n",
      "Batch: 2460. Acc: 0.341744. Loss: 1.878603. Batch_acc: 0.364407. Batch_loss: 1.786451 \n",
      "Batch: 2461. Acc: 0.341755. Loss: 1.878580. Batch_acc: 0.369895. Batch_loss: 1.821354 \n",
      "Batch: 2462. Acc: 0.341761. Loss: 1.878557. Batch_acc: 0.355491. Batch_loss: 1.821451 \n",
      "Batch: 2463. Acc: 0.341762. Loss: 1.878555. Batch_acc: 0.344470. Batch_loss: 1.873602 \n",
      "Batch: 2464. Acc: 0.341762. Loss: 1.878543. Batch_acc: 0.343249. Batch_loss: 1.850728 \n",
      "Batch: 2465. Acc: 0.341768. Loss: 1.878527. Batch_acc: 0.354820. Batch_loss: 1.838704 \n",
      "Batch: 2466. Acc: 0.341777. Loss: 1.878507. Batch_acc: 0.363848. Batch_loss: 1.829333 \n",
      "Batch: 2467. Acc: 0.341781. Loss: 1.878491. Batch_acc: 0.353145. Batch_loss: 1.838966 \n",
      "Batch: 2468. Acc: 0.341784. Loss: 1.878488. Batch_acc: 0.348214. Batch_loss: 1.869358 \n",
      "Batch: 2469. Acc: 0.341790. Loss: 1.878473. Batch_acc: 0.358338. Batch_loss: 1.842332 \n",
      "Batch: 2470. Acc: 0.341793. Loss: 1.878461. Batch_acc: 0.347112. Batch_loss: 1.850172 \n",
      "Batch: 2471. Acc: 0.341797. Loss: 1.878443. Batch_acc: 0.353714. Batch_loss: 1.832732 \n",
      "Batch: 2472. Acc: 0.341807. Loss: 1.878405. Batch_acc: 0.366609. Batch_loss: 1.785326 \n",
      "Batch: 2473. Acc: 0.341810. Loss: 1.878396. Batch_acc: 0.347752. Batch_loss: 1.855859 \n",
      "Batch: 2474. Acc: 0.341816. Loss: 1.878386. Batch_acc: 0.356436. Batch_loss: 1.854023 \n",
      "Batch: 2475. Acc: 0.341830. Loss: 1.878346. Batch_acc: 0.375281. Batch_loss: 1.780970 \n",
      "Batch: 2476. Acc: 0.341827. Loss: 1.878345. Batch_acc: 0.336449. Batch_loss: 1.875570 \n",
      "Batch: 2477. Acc: 0.341839. Loss: 1.878309. Batch_acc: 0.369942. Batch_loss: 1.788513 \n",
      "Batch: 2478. Acc: 0.341847. Loss: 1.878293. Batch_acc: 0.362662. Batch_loss: 1.840347 \n",
      "Batch: 2479. Acc: 0.341859. Loss: 1.878273. Batch_acc: 0.370625. Batch_loss: 1.828449 \n",
      "Batch: 2480. Acc: 0.341866. Loss: 1.878248. Batch_acc: 0.360532. Batch_loss: 1.814883 \n",
      "Batch: 2481. Acc: 0.341874. Loss: 1.878224. Batch_acc: 0.361241. Batch_loss: 1.818229 \n",
      "Batch: 2482. Acc: 0.341881. Loss: 1.878204. Batch_acc: 0.358534. Batch_loss: 1.830228 \n",
      "Batch: 2483. Acc: 0.341883. Loss: 1.878186. Batch_acc: 0.348334. Batch_loss: 1.830856 \n",
      "Batch: 2484. Acc: 0.341883. Loss: 1.878174. Batch_acc: 0.341954. Batch_loss: 1.849486 \n",
      "Batch: 2485. Acc: 0.341897. Loss: 1.878147. Batch_acc: 0.376661. Batch_loss: 1.811903 \n",
      "Batch: 2486. Acc: 0.341907. Loss: 1.878115. Batch_acc: 0.366898. Batch_loss: 1.796415 \n",
      "Batch: 2487. Acc: 0.341911. Loss: 1.878099. Batch_acc: 0.350486. Batch_loss: 1.839184 \n",
      "Batch: 2488. Acc: 0.341918. Loss: 1.878081. Batch_acc: 0.360591. Batch_loss: 1.834259 \n",
      "Batch: 2489. Acc: 0.341926. Loss: 1.878055. Batch_acc: 0.360116. Batch_loss: 1.813607 \n",
      "Batch: 2490. Acc: 0.341929. Loss: 1.878038. Batch_acc: 0.350233. Batch_loss: 1.835186 \n",
      "Batch: 2491. Acc: 0.341933. Loss: 1.878022. Batch_acc: 0.351936. Batch_loss: 1.837803 \n",
      "Batch: 2492. Acc: 0.341948. Loss: 1.877987. Batch_acc: 0.379661. Batch_loss: 1.791329 \n",
      "Batch: 2493. Acc: 0.341953. Loss: 1.877967. Batch_acc: 0.353803. Batch_loss: 1.830041 \n",
      "Batch: 2494. Acc: 0.341951. Loss: 1.877971. Batch_acc: 0.336242. Batch_loss: 1.888315 \n",
      "Batch: 2495. Acc: 0.341961. Loss: 1.877949. Batch_acc: 0.366591. Batch_loss: 1.822299 \n",
      "Batch: 2496. Acc: 0.341970. Loss: 1.877934. Batch_acc: 0.364706. Batch_loss: 1.839965 \n",
      "Batch: 2497. Acc: 0.341975. Loss: 1.877925. Batch_acc: 0.353864. Batch_loss: 1.854937 \n",
      "Batch: 2498. Acc: 0.341975. Loss: 1.877911. Batch_acc: 0.344005. Batch_loss: 1.844089 \n",
      "Batch: 2499. Acc: 0.341981. Loss: 1.877896. Batch_acc: 0.355353. Batch_loss: 1.840519 \n",
      "Batch: 2500. Acc: 0.341978. Loss: 1.877890. Batch_acc: 0.335418. Batch_loss: 1.863358 \n",
      "Batch: 2501. Acc: 0.341977. Loss: 1.877885. Batch_acc: 0.338776. Batch_loss: 1.863943 \n",
      "Batch: 2502. Acc: 0.341984. Loss: 1.877862. Batch_acc: 0.359908. Batch_loss: 1.820191 \n",
      "Batch: 2503. Acc: 0.341999. Loss: 1.877822. Batch_acc: 0.379955. Batch_loss: 1.780629 \n",
      "Batch: 2504. Acc: 0.342001. Loss: 1.877798. Batch_acc: 0.345107. Batch_loss: 1.816858 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2505. Acc: 0.342007. Loss: 1.877778. Batch_acc: 0.358566. Batch_loss: 1.827709 \n",
      "Batch: 2506. Acc: 0.342009. Loss: 1.877774. Batch_acc: 0.347098. Batch_loss: 1.866763 \n",
      "Batch: 2507. Acc: 0.342008. Loss: 1.877761. Batch_acc: 0.339677. Batch_loss: 1.845687 \n",
      "Batch: 2508. Acc: 0.342010. Loss: 1.877737. Batch_acc: 0.347009. Batch_loss: 1.818958 \n",
      "Batch: 2509. Acc: 0.342008. Loss: 1.877740. Batch_acc: 0.336232. Batch_loss: 1.883891 \n",
      "Batch: 2510. Acc: 0.342023. Loss: 1.877707. Batch_acc: 0.378488. Batch_loss: 1.795839 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.3420225805416947. Loss per char: 1.8777072397619632. Time: 1627208423.1118298\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 14, 24, 20, 23, 22, 17, 19, 23, 19,  1, 66, 79, 69,\n",
      "         1, 19, 19, 25, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
      "       device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.342031. Loss: 1.877687. Batch_acc: 0.362098. Batch_loss: 1.829072 \n",
      "Batch: 2512. Acc: 0.342033. Loss: 1.877669. Batch_acc: 0.347625. Batch_loss: 1.829638 \n",
      "Batch: 2513. Acc: 0.342035. Loss: 1.877645. Batch_acc: 0.346868. Batch_loss: 1.819110 \n",
      "Batch: 2514. Acc: 0.342044. Loss: 1.877623. Batch_acc: 0.364740. Batch_loss: 1.819948 \n",
      "Batch: 2515. Acc: 0.342048. Loss: 1.877613. Batch_acc: 0.352299. Batch_loss: 1.854681 \n",
      "Batch: 2516. Acc: 0.342057. Loss: 1.877582. Batch_acc: 0.365473. Batch_loss: 1.797454 \n",
      "Batch: 2517. Acc: 0.342063. Loss: 1.877562. Batch_acc: 0.355864. Batch_loss: 1.828192 \n",
      "Batch: 2518. Acc: 0.342071. Loss: 1.877545. Batch_acc: 0.363793. Batch_loss: 1.834235 \n",
      "Batch: 2519. Acc: 0.342065. Loss: 1.877539. Batch_acc: 0.326185. Batch_loss: 1.863162 \n",
      "Batch: 2520. Acc: 0.342070. Loss: 1.877532. Batch_acc: 0.355720. Batch_loss: 1.859943 \n",
      "Batch: 2521. Acc: 0.342068. Loss: 1.877527. Batch_acc: 0.335652. Batch_loss: 1.863926 \n",
      "Batch: 2522. Acc: 0.342082. Loss: 1.877495. Batch_acc: 0.376188. Batch_loss: 1.799024 \n",
      "Batch: 2523. Acc: 0.342081. Loss: 1.877484. Batch_acc: 0.341014. Batch_loss: 1.850844 \n",
      "Batch: 2524. Acc: 0.342084. Loss: 1.877469. Batch_acc: 0.348101. Batch_loss: 1.838638 \n",
      "Batch: 2525. Acc: 0.342088. Loss: 1.877451. Batch_acc: 0.352459. Batch_loss: 1.831446 \n",
      "Batch: 2526. Acc: 0.342082. Loss: 1.877455. Batch_acc: 0.327103. Batch_loss: 1.887427 \n",
      "Batch: 2527. Acc: 0.342086. Loss: 1.877442. Batch_acc: 0.353409. Batch_loss: 1.846511 \n",
      "Batch: 2528. Acc: 0.342091. Loss: 1.877412. Batch_acc: 0.352700. Batch_loss: 1.798175 \n",
      "Batch: 2529. Acc: 0.342092. Loss: 1.877398. Batch_acc: 0.344571. Batch_loss: 1.842787 \n",
      "Batch: 2530. Acc: 0.342097. Loss: 1.877375. Batch_acc: 0.356890. Batch_loss: 1.818933 \n",
      "Batch: 2531. Acc: 0.342111. Loss: 1.877344. Batch_acc: 0.376450. Batch_loss: 1.796315 \n",
      "Batch: 2532. Acc: 0.342122. Loss: 1.877306. Batch_acc: 0.370838. Batch_loss: 1.783246 \n",
      "Batch: 2533. Acc: 0.342127. Loss: 1.877274. Batch_acc: 0.354250. Batch_loss: 1.796528 \n",
      "Batch: 2534. Acc: 0.342132. Loss: 1.877255. Batch_acc: 0.355894. Batch_loss: 1.829472 \n",
      "Batch: 2535. Acc: 0.342132. Loss: 1.877241. Batch_acc: 0.340736. Batch_loss: 1.841706 \n",
      "Batch: 2536. Acc: 0.342142. Loss: 1.877210. Batch_acc: 0.367803. Batch_loss: 1.799545 \n",
      "Batch: 2537. Acc: 0.342151. Loss: 1.877181. Batch_acc: 0.365373. Batch_loss: 1.804127 \n",
      "Batch: 2538. Acc: 0.342161. Loss: 1.877161. Batch_acc: 0.366648. Batch_loss: 1.825534 \n",
      "Batch: 2539. Acc: 0.342166. Loss: 1.877144. Batch_acc: 0.353967. Batch_loss: 1.837292 \n",
      "Batch: 2540. Acc: 0.342176. Loss: 1.877117. Batch_acc: 0.369240. Batch_loss: 1.806306 \n",
      "Batch: 2541. Acc: 0.342187. Loss: 1.877082. Batch_acc: 0.368391. Batch_loss: 1.789762 \n",
      "Batch: 2542. Acc: 0.342192. Loss: 1.877059. Batch_acc: 0.355991. Batch_loss: 1.818153 \n",
      "Batch: 2543. Acc: 0.342206. Loss: 1.877018. Batch_acc: 0.376277. Batch_loss: 1.773827 \n",
      "Batch: 2544. Acc: 0.342214. Loss: 1.876992. Batch_acc: 0.362245. Batch_loss: 1.812802 \n",
      "Batch: 2545. Acc: 0.342226. Loss: 1.876965. Batch_acc: 0.372538. Batch_loss: 1.810641 \n",
      "Batch: 2546. Acc: 0.342228. Loss: 1.876938. Batch_acc: 0.347510. Batch_loss: 1.808009 \n",
      "Batch: 2547. Acc: 0.342237. Loss: 1.876902. Batch_acc: 0.363082. Batch_loss: 1.788749 \n",
      "Batch: 2548. Acc: 0.342246. Loss: 1.876872. Batch_acc: 0.366262. Batch_loss: 1.800315 \n",
      "Batch: 2549. Acc: 0.342251. Loss: 1.876849. Batch_acc: 0.355145. Batch_loss: 1.819502 \n",
      "Batch: 2550. Acc: 0.342253. Loss: 1.876843. Batch_acc: 0.346698. Batch_loss: 1.862933 \n",
      "Batch: 2551. Acc: 0.342260. Loss: 1.876816. Batch_acc: 0.360795. Batch_loss: 1.808442 \n",
      "Batch: 2552. Acc: 0.342269. Loss: 1.876783. Batch_acc: 0.365143. Batch_loss: 1.793348 \n",
      "Batch: 2553. Acc: 0.342273. Loss: 1.876767. Batch_acc: 0.352370. Batch_loss: 1.834591 \n",
      "Batch: 2554. Acc: 0.342282. Loss: 1.876734. Batch_acc: 0.365373. Batch_loss: 1.793575 \n",
      "Batch: 2555. Acc: 0.342288. Loss: 1.876713. Batch_acc: 0.355923. Batch_loss: 1.823158 \n",
      "Batch: 2556. Acc: 0.342296. Loss: 1.876696. Batch_acc: 0.363046. Batch_loss: 1.833054 \n",
      "Batch: 2557. Acc: 0.342312. Loss: 1.876674. Batch_acc: 0.384484. Batch_loss: 1.819115 \n",
      "Batch: 2558. Acc: 0.342329. Loss: 1.876638. Batch_acc: 0.385914. Batch_loss: 1.783632 \n",
      "Batch: 2559. Acc: 0.342336. Loss: 1.876607. Batch_acc: 0.361030. Batch_loss: 1.797131 \n",
      "Batch: 2560. Acc: 0.342342. Loss: 1.876574. Batch_acc: 0.356706. Batch_loss: 1.795285 \n",
      "Batch: 2561. Acc: 0.342355. Loss: 1.876532. Batch_acc: 0.376068. Batch_loss: 1.768143 \n",
      "Batch: 2562. Acc: 0.342360. Loss: 1.876499. Batch_acc: 0.355226. Batch_loss: 1.793333 \n",
      "Batch: 2563. Acc: 0.342364. Loss: 1.876491. Batch_acc: 0.350352. Batch_loss: 1.856776 \n",
      "Batch: 2564. Acc: 0.342368. Loss: 1.876474. Batch_acc: 0.354239. Batch_loss: 1.831769 \n",
      "Batch: 2565. Acc: 0.342365. Loss: 1.876472. Batch_acc: 0.335110. Batch_loss: 1.871958 \n",
      "Batch: 2566. Acc: 0.342378. Loss: 1.876436. Batch_acc: 0.374780. Batch_loss: 1.780063 \n",
      "Batch: 2567. Acc: 0.342377. Loss: 1.876433. Batch_acc: 0.339893. Batch_loss: 1.868633 \n",
      "Batch: 2568. Acc: 0.342387. Loss: 1.876411. Batch_acc: 0.368113. Batch_loss: 1.819566 \n",
      "Batch: 2569. Acc: 0.342386. Loss: 1.876409. Batch_acc: 0.341706. Batch_loss: 1.871076 \n",
      "Batch: 2570. Acc: 0.342392. Loss: 1.876393. Batch_acc: 0.357608. Batch_loss: 1.835598 \n",
      "Batch: 2571. Acc: 0.342399. Loss: 1.876373. Batch_acc: 0.359384. Batch_loss: 1.824174 \n",
      "Batch: 2572. Acc: 0.342404. Loss: 1.876356. Batch_acc: 0.356236. Batch_loss: 1.831254 \n",
      "Batch: 2573. Acc: 0.342416. Loss: 1.876330. Batch_acc: 0.371606. Batch_loss: 1.811112 \n",
      "Batch: 2574. Acc: 0.342420. Loss: 1.876318. Batch_acc: 0.353245. Batch_loss: 1.847093 \n",
      "Batch: 2575. Acc: 0.342427. Loss: 1.876288. Batch_acc: 0.359234. Batch_loss: 1.800247 \n",
      "Batch: 2576. Acc: 0.342430. Loss: 1.876285. Batch_acc: 0.352227. Batch_loss: 1.867537 \n",
      "Batch: 2577. Acc: 0.342435. Loss: 1.876273. Batch_acc: 0.354525. Batch_loss: 1.847020 \n",
      "Batch: 2578. Acc: 0.342444. Loss: 1.876236. Batch_acc: 0.364972. Batch_loss: 1.780915 \n",
      "Batch: 2579. Acc: 0.342452. Loss: 1.876224. Batch_acc: 0.363585. Batch_loss: 1.845171 \n",
      "Batch: 2580. Acc: 0.342455. Loss: 1.876226. Batch_acc: 0.348334. Batch_loss: 1.883129 \n",
      "Batch: 2581. Acc: 0.342458. Loss: 1.876221. Batch_acc: 0.351852. Batch_loss: 1.863010 \n",
      "Batch: 2582. Acc: 0.342464. Loss: 1.876213. Batch_acc: 0.357143. Batch_loss: 1.855226 \n",
      "Batch: 2583. Acc: 0.342471. Loss: 1.876204. Batch_acc: 0.361283. Batch_loss: 1.854891 \n",
      "Batch: 2584. Acc: 0.342469. Loss: 1.876208. Batch_acc: 0.337434. Batch_loss: 1.885191 \n",
      "Batch: 2585. Acc: 0.342476. Loss: 1.876181. Batch_acc: 0.357865. Batch_loss: 1.808156 \n",
      "Batch: 2586. Acc: 0.342485. Loss: 1.876168. Batch_acc: 0.367370. Batch_loss: 1.842094 \n",
      "Batch: 2587. Acc: 0.342493. Loss: 1.876147. Batch_acc: 0.361641. Batch_loss: 1.821660 \n",
      "Batch: 2588. Acc: 0.342495. Loss: 1.876138. Batch_acc: 0.348974. Batch_loss: 1.854078 \n",
      "Batch: 2589. Acc: 0.342493. Loss: 1.876138. Batch_acc: 0.337955. Batch_loss: 1.875667 \n",
      "Batch: 2590. Acc: 0.342499. Loss: 1.876109. Batch_acc: 0.356425. Batch_loss: 1.801915 \n",
      "Batch: 2591. Acc: 0.342506. Loss: 1.876091. Batch_acc: 0.361460. Batch_loss: 1.829071 \n",
      "Batch: 2592. Acc: 0.342516. Loss: 1.876066. Batch_acc: 0.368332. Batch_loss: 1.812517 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2593. Acc: 0.342521. Loss: 1.876036. Batch_acc: 0.353987. Batch_loss: 1.797659 \n",
      "Batch: 2594. Acc: 0.342521. Loss: 1.876023. Batch_acc: 0.342873. Batch_loss: 1.844134 \n",
      "Batch: 2595. Acc: 0.342525. Loss: 1.876011. Batch_acc: 0.353383. Batch_loss: 1.843108 \n",
      "Batch: 2596. Acc: 0.342537. Loss: 1.875987. Batch_acc: 0.373832. Batch_loss: 1.813550 \n",
      "Batch: 2597. Acc: 0.342536. Loss: 1.875973. Batch_acc: 0.340571. Batch_loss: 1.839189 \n",
      "Batch: 2598. Acc: 0.342534. Loss: 1.875979. Batch_acc: 0.336669. Batch_loss: 1.891334 \n",
      "Batch: 2599. Acc: 0.342537. Loss: 1.875959. Batch_acc: 0.351127. Batch_loss: 1.823942 \n",
      "Batch: 2600. Acc: 0.342541. Loss: 1.875943. Batch_acc: 0.354482. Batch_loss: 1.833807 \n",
      "Batch: 2601. Acc: 0.342545. Loss: 1.875946. Batch_acc: 0.351700. Batch_loss: 1.883659 \n",
      "Batch: 2602. Acc: 0.342550. Loss: 1.875929. Batch_acc: 0.355348. Batch_loss: 1.830404 \n",
      "Batch: 2603. Acc: 0.342558. Loss: 1.875917. Batch_acc: 0.364169. Batch_loss: 1.845514 \n",
      "Batch: 2604. Acc: 0.342562. Loss: 1.875906. Batch_acc: 0.354335. Batch_loss: 1.847290 \n",
      "Batch: 2605. Acc: 0.342562. Loss: 1.875894. Batch_acc: 0.341593. Batch_loss: 1.842889 \n",
      "Batch: 2606. Acc: 0.342568. Loss: 1.875878. Batch_acc: 0.357516. Batch_loss: 1.833763 \n",
      "Batch: 2607. Acc: 0.342580. Loss: 1.875851. Batch_acc: 0.374641. Batch_loss: 1.804924 \n",
      "Batch: 2608. Acc: 0.342587. Loss: 1.875823. Batch_acc: 0.360885. Batch_loss: 1.802311 \n",
      "Batch: 2609. Acc: 0.342593. Loss: 1.875803. Batch_acc: 0.358176. Batch_loss: 1.826743 \n",
      "Batch: 2610. Acc: 0.342598. Loss: 1.875787. Batch_acc: 0.355056. Batch_loss: 1.833310 \n",
      "Batch: 2611. Acc: 0.342605. Loss: 1.875765. Batch_acc: 0.360092. Batch_loss: 1.818447 \n",
      "Batch: 2612. Acc: 0.342613. Loss: 1.875736. Batch_acc: 0.364577. Batch_loss: 1.799680 \n",
      "Batch: 2613. Acc: 0.342620. Loss: 1.875720. Batch_acc: 0.360741. Batch_loss: 1.833196 \n",
      "Batch: 2614. Acc: 0.342624. Loss: 1.875704. Batch_acc: 0.353076. Batch_loss: 1.835032 \n",
      "Batch: 2615. Acc: 0.342627. Loss: 1.875683. Batch_acc: 0.350057. Batch_loss: 1.821645 \n",
      "Batch: 2616. Acc: 0.342631. Loss: 1.875660. Batch_acc: 0.354051. Batch_loss: 1.816130 \n",
      "Batch: 2617. Acc: 0.342629. Loss: 1.875645. Batch_acc: 0.337465. Batch_loss: 1.838879 \n",
      "Batch: 2618. Acc: 0.342635. Loss: 1.875627. Batch_acc: 0.357227. Batch_loss: 1.826492 \n",
      "Batch: 2619. Acc: 0.342649. Loss: 1.875591. Batch_acc: 0.379193. Batch_loss: 1.781773 \n",
      "Batch: 2620. Acc: 0.342657. Loss: 1.875573. Batch_acc: 0.362946. Batch_loss: 1.829155 \n",
      "Batch: 2621. Acc: 0.342660. Loss: 1.875562. Batch_acc: 0.350816. Batch_loss: 1.847258 \n",
      "Batch: 2622. Acc: 0.342662. Loss: 1.875555. Batch_acc: 0.347477. Batch_loss: 1.856660 \n",
      "Batch: 2623. Acc: 0.342666. Loss: 1.875541. Batch_acc: 0.354303. Batch_loss: 1.836217 \n",
      "Batch: 2624. Acc: 0.342660. Loss: 1.875544. Batch_acc: 0.326469. Batch_loss: 1.884589 \n",
      "Batch: 2625. Acc: 0.342657. Loss: 1.875531. Batch_acc: 0.333333. Batch_loss: 1.840050 \n",
      "Batch: 2626. Acc: 0.342660. Loss: 1.875519. Batch_acc: 0.351779. Batch_loss: 1.846580 \n",
      "Batch: 2627. Acc: 0.342666. Loss: 1.875508. Batch_acc: 0.357974. Batch_loss: 1.845621 \n",
      "Batch: 2628. Acc: 0.342673. Loss: 1.875484. Batch_acc: 0.362089. Batch_loss: 1.813640 \n",
      "Batch: 2629. Acc: 0.342671. Loss: 1.875476. Batch_acc: 0.337444. Batch_loss: 1.853690 \n",
      "Batch: 2630. Acc: 0.342684. Loss: 1.875440. Batch_acc: 0.376417. Batch_loss: 1.783707 \n",
      "Batch: 2631. Acc: 0.342686. Loss: 1.875431. Batch_acc: 0.347952. Batch_loss: 1.850593 \n",
      "Batch: 2632. Acc: 0.342693. Loss: 1.875415. Batch_acc: 0.360068. Batch_loss: 1.834307 \n",
      "Batch: 2633. Acc: 0.342696. Loss: 1.875390. Batch_acc: 0.350480. Batch_loss: 1.810749 \n",
      "Batch: 2634. Acc: 0.342701. Loss: 1.875375. Batch_acc: 0.356086. Batch_loss: 1.835847 \n",
      "Batch: 2635. Acc: 0.342704. Loss: 1.875362. Batch_acc: 0.349799. Batch_loss: 1.841366 \n",
      "Batch: 2636. Acc: 0.342703. Loss: 1.875362. Batch_acc: 0.341377. Batch_loss: 1.874226 \n",
      "Batch: 2637. Acc: 0.342714. Loss: 1.875346. Batch_acc: 0.369553. Batch_loss: 1.835853 \n",
      "Batch: 2638. Acc: 0.342714. Loss: 1.875340. Batch_acc: 0.342474. Batch_loss: 1.858712 \n",
      "Batch: 2639. Acc: 0.342714. Loss: 1.875325. Batch_acc: 0.344262. Batch_loss: 1.835348 \n",
      "Batch: 2640. Acc: 0.342724. Loss: 1.875297. Batch_acc: 0.368687. Batch_loss: 1.803502 \n",
      "Batch: 2641. Acc: 0.342728. Loss: 1.875285. Batch_acc: 0.351692. Batch_loss: 1.841505 \n",
      "Batch: 2642. Acc: 0.342733. Loss: 1.875259. Batch_acc: 0.356651. Batch_loss: 1.806960 \n",
      "Batch: 2643. Acc: 0.342737. Loss: 1.875239. Batch_acc: 0.354445. Batch_loss: 1.822605 \n",
      "Batch: 2644. Acc: 0.342746. Loss: 1.875205. Batch_acc: 0.365785. Batch_loss: 1.786487 \n",
      "Batch: 2645. Acc: 0.342750. Loss: 1.875195. Batch_acc: 0.353439. Batch_loss: 1.849933 \n",
      "Batch: 2646. Acc: 0.342756. Loss: 1.875164. Batch_acc: 0.357576. Batch_loss: 1.796803 \n",
      "Batch: 2647. Acc: 0.342761. Loss: 1.875152. Batch_acc: 0.355026. Batch_loss: 1.843982 \n",
      "Batch: 2648. Acc: 0.342760. Loss: 1.875140. Batch_acc: 0.340647. Batch_loss: 1.842634 \n",
      "Batch: 2649. Acc: 0.342769. Loss: 1.875107. Batch_acc: 0.367335. Batch_loss: 1.788111 \n",
      "Batch: 2650. Acc: 0.342776. Loss: 1.875083. Batch_acc: 0.359770. Batch_loss: 1.811798 \n",
      "Batch: 2651. Acc: 0.342783. Loss: 1.875062. Batch_acc: 0.362796. Batch_loss: 1.817707 \n",
      "Batch: 2652. Acc: 0.342789. Loss: 1.875054. Batch_acc: 0.359257. Batch_loss: 1.855325 \n",
      "Batch: 2653. Acc: 0.342793. Loss: 1.875045. Batch_acc: 0.352838. Batch_loss: 1.848560 \n",
      "Batch: 2654. Acc: 0.342801. Loss: 1.875016. Batch_acc: 0.364619. Batch_loss: 1.800682 \n",
      "Batch: 2655. Acc: 0.342809. Loss: 1.874996. Batch_acc: 0.361556. Batch_loss: 1.820643 \n",
      "Batch: 2656. Acc: 0.342809. Loss: 1.874984. Batch_acc: 0.343841. Batch_loss: 1.844704 \n",
      "Batch: 2657. Acc: 0.342822. Loss: 1.874944. Batch_acc: 0.377714. Batch_loss: 1.768268 \n",
      "Batch: 2658. Acc: 0.342830. Loss: 1.874916. Batch_acc: 0.364050. Batch_loss: 1.801720 \n",
      "Batch: 2659. Acc: 0.342834. Loss: 1.874896. Batch_acc: 0.352146. Batch_loss: 1.821467 \n",
      "Batch: 2660. Acc: 0.342844. Loss: 1.874860. Batch_acc: 0.370328. Batch_loss: 1.778439 \n",
      "Batch: 2661. Acc: 0.342850. Loss: 1.874843. Batch_acc: 0.358501. Batch_loss: 1.829707 \n",
      "Batch: 2662. Acc: 0.342862. Loss: 1.874817. Batch_acc: 0.375740. Batch_loss: 1.804484 \n",
      "Batch: 2663. Acc: 0.342867. Loss: 1.874799. Batch_acc: 0.356502. Batch_loss: 1.828323 \n",
      "Batch: 2664. Acc: 0.342876. Loss: 1.874777. Batch_acc: 0.366648. Batch_loss: 1.816585 \n",
      "Batch: 2665. Acc: 0.342883. Loss: 1.874754. Batch_acc: 0.361800. Batch_loss: 1.812408 \n",
      "Batch: 2666. Acc: 0.342887. Loss: 1.874736. Batch_acc: 0.353041. Batch_loss: 1.826896 \n",
      "Batch: 2667. Acc: 0.342889. Loss: 1.874728. Batch_acc: 0.347777. Batch_loss: 1.854587 \n",
      "Batch: 2668. Acc: 0.342891. Loss: 1.874697. Batch_acc: 0.348824. Batch_loss: 1.791627 \n",
      "Batch: 2669. Acc: 0.342893. Loss: 1.874681. Batch_acc: 0.347727. Batch_loss: 1.834854 \n",
      "Batch: 2670. Acc: 0.342897. Loss: 1.874668. Batch_acc: 0.354394. Batch_loss: 1.837836 \n",
      "Batch: 2671. Acc: 0.342895. Loss: 1.874667. Batch_acc: 0.335072. Batch_loss: 1.872706 \n",
      "Batch: 2672. Acc: 0.342893. Loss: 1.874664. Batch_acc: 0.337870. Batch_loss: 1.866296 \n",
      "Batch: 2673. Acc: 0.342896. Loss: 1.874650. Batch_acc: 0.352014. Batch_loss: 1.837560 \n",
      "Batch: 2674. Acc: 0.342904. Loss: 1.874624. Batch_acc: 0.363636. Batch_loss: 1.804437 \n",
      "Batch: 2675. Acc: 0.342904. Loss: 1.874616. Batch_acc: 0.343894. Batch_loss: 1.853031 \n",
      "Batch: 2676. Acc: 0.342903. Loss: 1.874615. Batch_acc: 0.338857. Batch_loss: 1.872018 \n",
      "Batch: 2677. Acc: 0.342911. Loss: 1.874593. Batch_acc: 0.364426. Batch_loss: 1.816314 \n",
      "Batch: 2678. Acc: 0.342914. Loss: 1.874575. Batch_acc: 0.351336. Batch_loss: 1.826526 \n",
      "Batch: 2679. Acc: 0.342924. Loss: 1.874547. Batch_acc: 0.371199. Batch_loss: 1.799405 \n",
      "Batch: 2680. Acc: 0.342932. Loss: 1.874517. Batch_acc: 0.364205. Batch_loss: 1.795643 \n",
      "Batch: 2681. Acc: 0.342936. Loss: 1.874503. Batch_acc: 0.353553. Batch_loss: 1.836642 \n",
      "Batch: 2682. Acc: 0.342937. Loss: 1.874485. Batch_acc: 0.344438. Batch_loss: 1.826342 \n",
      "Batch: 2683. Acc: 0.342942. Loss: 1.874471. Batch_acc: 0.357510. Batch_loss: 1.837793 \n",
      "Batch: 2684. Acc: 0.342946. Loss: 1.874459. Batch_acc: 0.351415. Batch_loss: 1.840726 \n",
      "Batch: 2685. Acc: 0.342950. Loss: 1.874440. Batch_acc: 0.355932. Batch_loss: 1.822417 \n",
      "Batch: 2686. Acc: 0.342960. Loss: 1.874415. Batch_acc: 0.369578. Batch_loss: 1.805652 \n",
      "Batch: 2687. Acc: 0.342964. Loss: 1.874408. Batch_acc: 0.353318. Batch_loss: 1.855383 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2688. Acc: 0.342967. Loss: 1.874394. Batch_acc: 0.350806. Batch_loss: 1.836012 \n",
      "Batch: 2689. Acc: 0.342974. Loss: 1.874377. Batch_acc: 0.364108. Batch_loss: 1.828937 \n",
      "Batch: 2690. Acc: 0.342978. Loss: 1.874364. Batch_acc: 0.352804. Batch_loss: 1.837949 \n",
      "Batch: 2691. Acc: 0.342985. Loss: 1.874340. Batch_acc: 0.361144. Batch_loss: 1.810376 \n",
      "Batch: 2692. Acc: 0.342987. Loss: 1.874325. Batch_acc: 0.349254. Batch_loss: 1.833298 \n",
      "Batch: 2693. Acc: 0.342993. Loss: 1.874297. Batch_acc: 0.358176. Batch_loss: 1.799712 \n",
      "Batch: 2694. Acc: 0.342997. Loss: 1.874279. Batch_acc: 0.355009. Batch_loss: 1.826395 \n",
      "Batch: 2695. Acc: 0.343009. Loss: 1.874262. Batch_acc: 0.375214. Batch_loss: 1.827818 \n",
      "Batch: 2696. Acc: 0.343015. Loss: 1.874239. Batch_acc: 0.357510. Batch_loss: 1.813484 \n",
      "Batch: 2697. Acc: 0.343019. Loss: 1.874215. Batch_acc: 0.353443. Batch_loss: 1.810173 \n",
      "Batch: 2698. Acc: 0.343023. Loss: 1.874203. Batch_acc: 0.354545. Batch_loss: 1.840158 \n",
      "Batch: 2699. Acc: 0.343032. Loss: 1.874180. Batch_acc: 0.366800. Batch_loss: 1.813253 \n",
      "Batch: 2700. Acc: 0.343030. Loss: 1.874179. Batch_acc: 0.338569. Batch_loss: 1.872281 \n",
      "Batch: 2701. Acc: 0.343039. Loss: 1.874159. Batch_acc: 0.366782. Batch_loss: 1.818615 \n",
      "Batch: 2702. Acc: 0.343038. Loss: 1.874151. Batch_acc: 0.340537. Batch_loss: 1.853728 \n",
      "Batch: 2703. Acc: 0.343045. Loss: 1.874127. Batch_acc: 0.362109. Batch_loss: 1.808738 \n",
      "Batch: 2704. Acc: 0.343050. Loss: 1.874100. Batch_acc: 0.357555. Batch_loss: 1.801237 \n",
      "Batch: 2705. Acc: 0.343059. Loss: 1.874080. Batch_acc: 0.367521. Batch_loss: 1.819021 \n",
      "Batch: 2706. Acc: 0.343061. Loss: 1.874065. Batch_acc: 0.347826. Batch_loss: 1.833825 \n",
      "Batch: 2707. Acc: 0.343070. Loss: 1.874030. Batch_acc: 0.367963. Batch_loss: 1.778410 \n",
      "Batch: 2708. Acc: 0.343076. Loss: 1.874006. Batch_acc: 0.357766. Batch_loss: 1.808161 \n",
      "Batch: 2709. Acc: 0.343082. Loss: 1.873980. Batch_acc: 0.360540. Batch_loss: 1.803301 \n",
      "Batch: 2710. Acc: 0.343081. Loss: 1.873978. Batch_acc: 0.339679. Batch_loss: 1.867023 \n",
      "Batch: 2711. Acc: 0.343087. Loss: 1.873955. Batch_acc: 0.361340. Batch_loss: 1.810907 \n",
      "Batch: 2712. Acc: 0.343093. Loss: 1.873934. Batch_acc: 0.359142. Batch_loss: 1.814091 \n",
      "Batch: 2713. Acc: 0.343103. Loss: 1.873908. Batch_acc: 0.369666. Batch_loss: 1.803944 \n",
      "Batch: 2714. Acc: 0.343106. Loss: 1.873891. Batch_acc: 0.351289. Batch_loss: 1.829501 \n",
      "Batch: 2715. Acc: 0.343109. Loss: 1.873868. Batch_acc: 0.352773. Batch_loss: 1.811500 \n",
      "Batch: 2716. Acc: 0.343115. Loss: 1.873845. Batch_acc: 0.357846. Batch_loss: 1.809020 \n",
      "Batch: 2717. Acc: 0.343123. Loss: 1.873827. Batch_acc: 0.364053. Batch_loss: 1.826960 \n",
      "Batch: 2718. Acc: 0.343127. Loss: 1.873800. Batch_acc: 0.356441. Batch_loss: 1.800739 \n",
      "Batch: 2719. Acc: 0.343138. Loss: 1.873769. Batch_acc: 0.371758. Batch_loss: 1.789278 \n",
      "Batch: 2720. Acc: 0.343142. Loss: 1.873758. Batch_acc: 0.353043. Batch_loss: 1.841955 \n",
      "Batch: 2721. Acc: 0.343151. Loss: 1.873741. Batch_acc: 0.369375. Batch_loss: 1.826641 \n",
      "Batch: 2722. Acc: 0.343157. Loss: 1.873732. Batch_acc: 0.357883. Batch_loss: 1.850848 \n",
      "Batch: 2723. Acc: 0.343158. Loss: 1.873720. Batch_acc: 0.347926. Batch_loss: 1.839560 \n",
      "Batch: 2724. Acc: 0.343158. Loss: 1.873711. Batch_acc: 0.342197. Batch_loss: 1.848987 \n",
      "Batch: 2725. Acc: 0.343168. Loss: 1.873680. Batch_acc: 0.370690. Batch_loss: 1.789718 \n",
      "Batch: 2726. Acc: 0.343169. Loss: 1.873677. Batch_acc: 0.344746. Batch_loss: 1.866338 \n",
      "Batch: 2727. Acc: 0.343163. Loss: 1.873677. Batch_acc: 0.329047. Batch_loss: 1.873472 \n",
      "Batch: 2728. Acc: 0.343163. Loss: 1.873664. Batch_acc: 0.342987. Batch_loss: 1.838279 \n",
      "Batch: 2729. Acc: 0.343163. Loss: 1.873661. Batch_acc: 0.342199. Batch_loss: 1.863741 \n",
      "Batch: 2730. Acc: 0.343164. Loss: 1.873641. Batch_acc: 0.346705. Batch_loss: 1.819186 \n",
      "Batch: 2731. Acc: 0.343172. Loss: 1.873610. Batch_acc: 0.363431. Batch_loss: 1.790880 \n",
      "Batch: 2732. Acc: 0.343173. Loss: 1.873589. Batch_acc: 0.347144. Batch_loss: 1.818675 \n",
      "Batch: 2733. Acc: 0.343181. Loss: 1.873562. Batch_acc: 0.363006. Batch_loss: 1.799998 \n",
      "Batch: 2734. Acc: 0.343183. Loss: 1.873550. Batch_acc: 0.350344. Batch_loss: 1.840489 \n",
      "Batch: 2735. Acc: 0.343187. Loss: 1.873532. Batch_acc: 0.352632. Batch_loss: 1.822918 \n",
      "Batch: 2736. Acc: 0.343199. Loss: 1.873501. Batch_acc: 0.377239. Batch_loss: 1.787879 \n",
      "Batch: 2737. Acc: 0.343207. Loss: 1.873489. Batch_acc: 0.364118. Batch_loss: 1.840579 \n",
      "Batch: 2738. Acc: 0.343212. Loss: 1.873477. Batch_acc: 0.357877. Batch_loss: 1.840343 \n",
      "Batch: 2739. Acc: 0.343218. Loss: 1.873452. Batch_acc: 0.358727. Batch_loss: 1.805244 \n",
      "Batch: 2740. Acc: 0.343218. Loss: 1.873439. Batch_acc: 0.344281. Batch_loss: 1.839088 \n",
      "Batch: 2741. Acc: 0.343219. Loss: 1.873419. Batch_acc: 0.344948. Batch_loss: 1.817443 \n",
      "Batch: 2742. Acc: 0.343223. Loss: 1.873394. Batch_acc: 0.354445. Batch_loss: 1.804443 \n",
      "Batch: 2743. Acc: 0.343229. Loss: 1.873375. Batch_acc: 0.361508. Batch_loss: 1.821334 \n",
      "Batch: 2744. Acc: 0.343234. Loss: 1.873357. Batch_acc: 0.355043. Batch_loss: 1.824916 \n",
      "Batch: 2745. Acc: 0.343234. Loss: 1.873340. Batch_acc: 0.344946. Batch_loss: 1.826162 \n",
      "Batch: 2746. Acc: 0.343238. Loss: 1.873320. Batch_acc: 0.354467. Batch_loss: 1.819974 \n",
      "Batch: 2747. Acc: 0.343248. Loss: 1.873296. Batch_acc: 0.367622. Batch_loss: 1.807171 \n",
      "Batch: 2748. Acc: 0.343253. Loss: 1.873283. Batch_acc: 0.357306. Batch_loss: 1.837403 \n",
      "Batch: 2749. Acc: 0.343256. Loss: 1.873270. Batch_acc: 0.351972. Batch_loss: 1.837046 \n",
      "Batch: 2750. Acc: 0.343267. Loss: 1.873241. Batch_acc: 0.373608. Batch_loss: 1.796829 \n",
      "Batch: 2751. Acc: 0.343268. Loss: 1.873245. Batch_acc: 0.346713. Batch_loss: 1.885365 \n",
      "Batch: 2752. Acc: 0.343269. Loss: 1.873241. Batch_acc: 0.345745. Batch_loss: 1.862489 \n",
      "Batch: 2753. Acc: 0.343273. Loss: 1.873224. Batch_acc: 0.352364. Batch_loss: 1.825324 \n",
      "Batch: 2754. Acc: 0.343269. Loss: 1.873226. Batch_acc: 0.332779. Batch_loss: 1.877571 \n",
      "Batch: 2755. Acc: 0.343271. Loss: 1.873208. Batch_acc: 0.348955. Batch_loss: 1.824410 \n",
      "Batch: 2756. Acc: 0.343272. Loss: 1.873197. Batch_acc: 0.346424. Batch_loss: 1.844254 \n",
      "Batch: 2757. Acc: 0.343272. Loss: 1.873186. Batch_acc: 0.344808. Batch_loss: 1.840680 \n",
      "Batch: 2758. Acc: 0.343275. Loss: 1.873172. Batch_acc: 0.350344. Batch_loss: 1.835592 \n",
      "Batch: 2759. Acc: 0.343278. Loss: 1.873171. Batch_acc: 0.350930. Batch_loss: 1.871342 \n",
      "Batch: 2760. Acc: 0.343281. Loss: 1.873181. Batch_acc: 0.351244. Batch_loss: 1.898766 \n",
      "Batch: 2761. Acc: 0.343284. Loss: 1.873169. Batch_acc: 0.352144. Batch_loss: 1.841981 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.34328386499181524. Loss per char: 1.8731691844958984. Time: 1627208628.4903967\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 26, 24, 23, 26, 23, 25, 21,\n",
      "        20, 23, 23, 20,  1, 14,  1, 14, 24, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.343290. Loss: 1.873142. Batch_acc: 0.360391. Batch_loss: 1.799013 \n",
      "Batch: 2763. Acc: 0.343294. Loss: 1.873123. Batch_acc: 0.353371. Batch_loss: 1.820333 \n",
      "Batch: 2764. Acc: 0.343304. Loss: 1.873092. Batch_acc: 0.370328. Batch_loss: 1.787771 \n",
      "Batch: 2765. Acc: 0.343307. Loss: 1.873080. Batch_acc: 0.351697. Batch_loss: 1.841627 \n",
      "Batch: 2766. Acc: 0.343312. Loss: 1.873076. Batch_acc: 0.358295. Batch_loss: 1.861734 \n",
      "Batch: 2767. Acc: 0.343317. Loss: 1.873062. Batch_acc: 0.355903. Batch_loss: 1.832843 \n",
      "Batch: 2768. Acc: 0.343316. Loss: 1.873042. Batch_acc: 0.341837. Batch_loss: 1.820671 \n",
      "Batch: 2769. Acc: 0.343320. Loss: 1.873033. Batch_acc: 0.352806. Batch_loss: 1.845796 \n",
      "Batch: 2770. Acc: 0.343326. Loss: 1.873008. Batch_acc: 0.360953. Batch_loss: 1.805592 \n",
      "Batch: 2771. Acc: 0.343336. Loss: 1.872990. Batch_acc: 0.372678. Batch_loss: 1.820283 \n",
      "Batch: 2772. Acc: 0.343336. Loss: 1.872987. Batch_acc: 0.342321. Batch_loss: 1.864610 \n",
      "Batch: 2773. Acc: 0.343344. Loss: 1.872974. Batch_acc: 0.366705. Batch_loss: 1.839023 \n",
      "Batch: 2774. Acc: 0.343352. Loss: 1.872941. Batch_acc: 0.365604. Batch_loss: 1.782708 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2775. Acc: 0.343364. Loss: 1.872920. Batch_acc: 0.375213. Batch_loss: 1.814150 \n",
      "Batch: 2776. Acc: 0.343370. Loss: 1.872895. Batch_acc: 0.359473. Batch_loss: 1.803591 \n",
      "Batch: 2777. Acc: 0.343380. Loss: 1.872871. Batch_acc: 0.372526. Batch_loss: 1.804504 \n",
      "Batch: 2778. Acc: 0.343379. Loss: 1.872884. Batch_acc: 0.339503. Batch_loss: 1.909149 \n",
      "Batch: 2779. Acc: 0.343385. Loss: 1.872867. Batch_acc: 0.359366. Batch_loss: 1.826444 \n",
      "Batch: 2780. Acc: 0.343394. Loss: 1.872842. Batch_acc: 0.367764. Batch_loss: 1.805241 \n",
      "Batch: 2781. Acc: 0.343395. Loss: 1.872834. Batch_acc: 0.347501. Batch_loss: 1.850727 \n",
      "Batch: 2782. Acc: 0.343397. Loss: 1.872821. Batch_acc: 0.347585. Batch_loss: 1.838802 \n",
      "Batch: 2783. Acc: 0.343402. Loss: 1.872794. Batch_acc: 0.359473. Batch_loss: 1.797774 \n",
      "Batch: 2784. Acc: 0.343407. Loss: 1.872781. Batch_acc: 0.355667. Batch_loss: 1.836477 \n",
      "Batch: 2785. Acc: 0.343407. Loss: 1.872772. Batch_acc: 0.344848. Batch_loss: 1.848669 \n",
      "Batch: 2786. Acc: 0.343413. Loss: 1.872755. Batch_acc: 0.359629. Batch_loss: 1.822658 \n",
      "Batch: 2787. Acc: 0.343413. Loss: 1.872744. Batch_acc: 0.341633. Batch_loss: 1.842229 \n",
      "Batch: 2788. Acc: 0.343419. Loss: 1.872720. Batch_acc: 0.360485. Batch_loss: 1.806191 \n",
      "Batch: 2789. Acc: 0.343422. Loss: 1.872700. Batch_acc: 0.353617. Batch_loss: 1.816191 \n",
      "Batch: 2790. Acc: 0.343426. Loss: 1.872691. Batch_acc: 0.353483. Batch_loss: 1.848017 \n",
      "Batch: 2791. Acc: 0.343435. Loss: 1.872663. Batch_acc: 0.370306. Batch_loss: 1.794721 \n",
      "Batch: 2792. Acc: 0.343442. Loss: 1.872637. Batch_acc: 0.362507. Batch_loss: 1.797093 \n",
      "Batch: 2793. Acc: 0.343449. Loss: 1.872616. Batch_acc: 0.363260. Batch_loss: 1.811839 \n",
      "Batch: 2794. Acc: 0.343454. Loss: 1.872612. Batch_acc: 0.356890. Batch_loss: 1.861360 \n",
      "Batch: 2795. Acc: 0.343465. Loss: 1.872580. Batch_acc: 0.373583. Batch_loss: 1.786422 \n",
      "Batch: 2796. Acc: 0.343468. Loss: 1.872564. Batch_acc: 0.352941. Batch_loss: 1.827556 \n",
      "Batch: 2797. Acc: 0.343474. Loss: 1.872537. Batch_acc: 0.360967. Batch_loss: 1.796134 \n",
      "Batch: 2798. Acc: 0.343480. Loss: 1.872524. Batch_acc: 0.360290. Batch_loss: 1.833511 \n",
      "Batch: 2799. Acc: 0.343488. Loss: 1.872497. Batch_acc: 0.366667. Batch_loss: 1.798676 \n",
      "Batch: 2800. Acc: 0.343494. Loss: 1.872464. Batch_acc: 0.358329. Batch_loss: 1.779973 \n",
      "Batch: 2801. Acc: 0.343497. Loss: 1.872446. Batch_acc: 0.353784. Batch_loss: 1.820552 \n",
      "Batch: 2802. Acc: 0.343506. Loss: 1.872425. Batch_acc: 0.366935. Batch_loss: 1.813397 \n",
      "Batch: 2803. Acc: 0.343508. Loss: 1.872421. Batch_acc: 0.349307. Batch_loss: 1.862758 \n",
      "Batch: 2804. Acc: 0.343513. Loss: 1.872400. Batch_acc: 0.358857. Batch_loss: 1.813207 \n",
      "Batch: 2805. Acc: 0.343516. Loss: 1.872393. Batch_acc: 0.351819. Batch_loss: 1.851980 \n",
      "Batch: 2806. Acc: 0.343524. Loss: 1.872369. Batch_acc: 0.364841. Batch_loss: 1.805446 \n",
      "Batch: 2807. Acc: 0.343533. Loss: 1.872339. Batch_acc: 0.368512. Batch_loss: 1.786870 \n",
      "Batch: 2808. Acc: 0.343537. Loss: 1.872327. Batch_acc: 0.356257. Batch_loss: 1.839833 \n",
      "Batch: 2809. Acc: 0.343545. Loss: 1.872307. Batch_acc: 0.364470. Batch_loss: 1.817351 \n",
      "Batch: 2810. Acc: 0.343548. Loss: 1.872287. Batch_acc: 0.353588. Batch_loss: 1.815266 \n",
      "Batch: 2811. Acc: 0.343551. Loss: 1.872283. Batch_acc: 0.351367. Batch_loss: 1.859941 \n",
      "Batch: 2812. Acc: 0.343560. Loss: 1.872261. Batch_acc: 0.367370. Batch_loss: 1.813074 \n",
      "Batch: 2813. Acc: 0.343566. Loss: 1.872245. Batch_acc: 0.360819. Batch_loss: 1.826796 \n",
      "Batch: 2814. Acc: 0.343574. Loss: 1.872225. Batch_acc: 0.366571. Batch_loss: 1.814574 \n",
      "Batch: 2815. Acc: 0.343581. Loss: 1.872203. Batch_acc: 0.363956. Batch_loss: 1.809164 \n",
      "Batch: 2816. Acc: 0.343587. Loss: 1.872185. Batch_acc: 0.359864. Batch_loss: 1.820642 \n",
      "Batch: 2817. Acc: 0.343593. Loss: 1.872159. Batch_acc: 0.362147. Batch_loss: 1.801780 \n",
      "Batch: 2818. Acc: 0.343602. Loss: 1.872127. Batch_acc: 0.368876. Batch_loss: 1.781248 \n",
      "Batch: 2819. Acc: 0.343607. Loss: 1.872113. Batch_acc: 0.358148. Batch_loss: 1.830835 \n",
      "Batch: 2820. Acc: 0.343615. Loss: 1.872091. Batch_acc: 0.365513. Batch_loss: 1.812335 \n",
      "Batch: 2821. Acc: 0.343616. Loss: 1.872073. Batch_acc: 0.346359. Batch_loss: 1.820824 \n",
      "Batch: 2822. Acc: 0.343628. Loss: 1.872039. Batch_acc: 0.375733. Batch_loss: 1.774176 \n",
      "Batch: 2823. Acc: 0.343630. Loss: 1.872031. Batch_acc: 0.350877. Batch_loss: 1.851206 \n",
      "Batch: 2824. Acc: 0.343636. Loss: 1.872009. Batch_acc: 0.359091. Batch_loss: 1.810309 \n",
      "Batch: 2825. Acc: 0.343643. Loss: 1.871985. Batch_acc: 0.364699. Batch_loss: 1.801423 \n",
      "Batch: 2826. Acc: 0.343651. Loss: 1.871964. Batch_acc: 0.367370. Batch_loss: 1.813270 \n",
      "Batch: 2827. Acc: 0.343658. Loss: 1.871939. Batch_acc: 0.362020. Batch_loss: 1.803002 \n",
      "Batch: 2828. Acc: 0.343664. Loss: 1.871923. Batch_acc: 0.361530. Batch_loss: 1.826671 \n",
      "Batch: 2829. Acc: 0.343675. Loss: 1.871910. Batch_acc: 0.372852. Batch_loss: 1.833660 \n",
      "Batch: 2830. Acc: 0.343684. Loss: 1.871880. Batch_acc: 0.369704. Batch_loss: 1.786249 \n",
      "Batch: 2831. Acc: 0.343687. Loss: 1.871880. Batch_acc: 0.352088. Batch_loss: 1.871446 \n",
      "Batch: 2832. Acc: 0.343694. Loss: 1.871865. Batch_acc: 0.363846. Batch_loss: 1.830380 \n",
      "Batch: 2833. Acc: 0.343703. Loss: 1.871839. Batch_acc: 0.368481. Batch_loss: 1.799004 \n",
      "Batch: 2834. Acc: 0.343704. Loss: 1.871820. Batch_acc: 0.347168. Batch_loss: 1.817793 \n",
      "Batch: 2835. Acc: 0.343713. Loss: 1.871790. Batch_acc: 0.369926. Batch_loss: 1.786775 \n",
      "Batch: 2836. Acc: 0.343715. Loss: 1.871776. Batch_acc: 0.350315. Batch_loss: 1.832105 \n",
      "Batch: 2837. Acc: 0.343727. Loss: 1.871745. Batch_acc: 0.374368. Batch_loss: 1.786267 \n",
      "Batch: 2838. Acc: 0.343734. Loss: 1.871729. Batch_acc: 0.365591. Batch_loss: 1.828715 \n",
      "Batch: 2839. Acc: 0.343741. Loss: 1.871714. Batch_acc: 0.362739. Batch_loss: 1.827559 \n",
      "Batch: 2840. Acc: 0.343751. Loss: 1.871687. Batch_acc: 0.371264. Batch_loss: 1.794392 \n",
      "Batch: 2841. Acc: 0.343756. Loss: 1.871669. Batch_acc: 0.358930. Batch_loss: 1.821515 \n",
      "Batch: 2842. Acc: 0.343761. Loss: 1.871648. Batch_acc: 0.358989. Batch_loss: 1.812908 \n",
      "Batch: 2843. Acc: 0.343768. Loss: 1.871634. Batch_acc: 0.362862. Batch_loss: 1.830762 \n",
      "Batch: 2844. Acc: 0.343778. Loss: 1.871610. Batch_acc: 0.370518. Batch_loss: 1.805103 \n",
      "Batch: 2845. Acc: 0.343785. Loss: 1.871582. Batch_acc: 0.366390. Batch_loss: 1.789465 \n",
      "Batch: 2846. Acc: 0.343790. Loss: 1.871570. Batch_acc: 0.358329. Batch_loss: 1.835979 \n",
      "Batch: 2847. Acc: 0.343801. Loss: 1.871548. Batch_acc: 0.375000. Batch_loss: 1.810246 \n",
      "Batch: 2848. Acc: 0.343806. Loss: 1.871525. Batch_acc: 0.357349. Batch_loss: 1.804417 \n",
      "Batch: 2849. Acc: 0.343810. Loss: 1.871509. Batch_acc: 0.356012. Batch_loss: 1.825032 \n",
      "Batch: 2850. Acc: 0.343817. Loss: 1.871498. Batch_acc: 0.362712. Batch_loss: 1.841413 \n",
      "Batch: 2851. Acc: 0.343825. Loss: 1.871461. Batch_acc: 0.366911. Batch_loss: 1.768045 \n",
      "Batch: 2852. Acc: 0.343836. Loss: 1.871435. Batch_acc: 0.372706. Batch_loss: 1.798037 \n",
      "Batch: 2853. Acc: 0.343844. Loss: 1.871405. Batch_acc: 0.366857. Batch_loss: 1.784977 \n",
      "Batch: 2854. Acc: 0.343852. Loss: 1.871375. Batch_acc: 0.368151. Batch_loss: 1.788784 \n",
      "Batch: 2855. Acc: 0.343858. Loss: 1.871364. Batch_acc: 0.360298. Batch_loss: 1.838549 \n",
      "Batch: 2856. Acc: 0.343859. Loss: 1.871350. Batch_acc: 0.346244. Batch_loss: 1.832349 \n",
      "Batch: 2857. Acc: 0.343864. Loss: 1.871331. Batch_acc: 0.359429. Batch_loss: 1.814979 \n",
      "Batch: 2858. Acc: 0.343869. Loss: 1.871308. Batch_acc: 0.357507. Batch_loss: 1.807670 \n",
      "Batch: 2859. Acc: 0.343873. Loss: 1.871298. Batch_acc: 0.355178. Batch_loss: 1.842669 \n",
      "Batch: 2860. Acc: 0.343872. Loss: 1.871289. Batch_acc: 0.341307. Batch_loss: 1.844692 \n",
      "Batch: 2861. Acc: 0.343873. Loss: 1.871278. Batch_acc: 0.345358. Batch_loss: 1.839954 \n",
      "Batch: 2862. Acc: 0.343878. Loss: 1.871260. Batch_acc: 0.359708. Batch_loss: 1.820248 \n",
      "Batch: 2863. Acc: 0.343892. Loss: 1.871228. Batch_acc: 0.382569. Batch_loss: 1.780204 \n",
      "Batch: 2864. Acc: 0.343909. Loss: 1.871187. Batch_acc: 0.391876. Batch_loss: 1.755140 \n",
      "Batch: 2865. Acc: 0.343919. Loss: 1.871151. Batch_acc: 0.371938. Batch_loss: 1.771645 \n",
      "Batch: 2866. Acc: 0.343924. Loss: 1.871131. Batch_acc: 0.357184. Batch_loss: 1.812557 \n",
      "Batch: 2867. Acc: 0.343925. Loss: 1.871122. Batch_acc: 0.348416. Batch_loss: 1.846331 \n",
      "Batch: 2868. Acc: 0.343928. Loss: 1.871113. Batch_acc: 0.350694. Batch_loss: 1.846198 \n",
      "Batch: 2869. Acc: 0.343930. Loss: 1.871090. Batch_acc: 0.350642. Batch_loss: 1.806018 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2870. Acc: 0.343934. Loss: 1.871077. Batch_acc: 0.355439. Batch_loss: 1.832613 \n",
      "Batch: 2871. Acc: 0.343936. Loss: 1.871061. Batch_acc: 0.350492. Batch_loss: 1.825327 \n",
      "Batch: 2872. Acc: 0.343937. Loss: 1.871047. Batch_acc: 0.347600. Batch_loss: 1.831455 \n",
      "Batch: 2873. Acc: 0.343943. Loss: 1.871032. Batch_acc: 0.360855. Batch_loss: 1.827695 \n",
      "Batch: 2874. Acc: 0.343950. Loss: 1.871011. Batch_acc: 0.364416. Batch_loss: 1.810739 \n",
      "Batch: 2875. Acc: 0.343952. Loss: 1.870999. Batch_acc: 0.349040. Batch_loss: 1.835478 \n",
      "Batch: 2876. Acc: 0.343956. Loss: 1.870981. Batch_acc: 0.354227. Batch_loss: 1.819789 \n",
      "Batch: 2877. Acc: 0.343967. Loss: 1.870951. Batch_acc: 0.378107. Batch_loss: 1.781961 \n",
      "Batch: 2878. Acc: 0.343974. Loss: 1.870936. Batch_acc: 0.363794. Batch_loss: 1.828630 \n",
      "Batch: 2879. Acc: 0.343979. Loss: 1.870922. Batch_acc: 0.359292. Batch_loss: 1.829203 \n",
      "Batch: 2880. Acc: 0.343985. Loss: 1.870908. Batch_acc: 0.359978. Batch_loss: 1.831954 \n",
      "Batch: 2881. Acc: 0.343997. Loss: 1.870873. Batch_acc: 0.379189. Batch_loss: 1.767987 \n",
      "Batch: 2882. Acc: 0.343998. Loss: 1.870866. Batch_acc: 0.347877. Batch_loss: 1.848950 \n",
      "Batch: 2883. Acc: 0.344001. Loss: 1.870866. Batch_acc: 0.352736. Batch_loss: 1.869859 \n",
      "Batch: 2884. Acc: 0.344007. Loss: 1.870844. Batch_acc: 0.361095. Batch_loss: 1.807836 \n",
      "Batch: 2885. Acc: 0.344014. Loss: 1.870832. Batch_acc: 0.362478. Batch_loss: 1.834376 \n",
      "Batch: 2886. Acc: 0.344020. Loss: 1.870806. Batch_acc: 0.363584. Batch_loss: 1.797815 \n",
      "Batch: 2887. Acc: 0.344037. Loss: 1.870771. Batch_acc: 0.392135. Batch_loss: 1.770585 \n",
      "Batch: 2888. Acc: 0.344047. Loss: 1.870741. Batch_acc: 0.370996. Batch_loss: 1.783432 \n",
      "Batch: 2889. Acc: 0.344053. Loss: 1.870727. Batch_acc: 0.363318. Batch_loss: 1.830708 \n",
      "Batch: 2890. Acc: 0.344059. Loss: 1.870712. Batch_acc: 0.359725. Batch_loss: 1.826083 \n",
      "Batch: 2891. Acc: 0.344063. Loss: 1.870691. Batch_acc: 0.356939. Batch_loss: 1.809908 \n",
      "Batch: 2892. Acc: 0.344067. Loss: 1.870682. Batch_acc: 0.355233. Batch_loss: 1.845041 \n",
      "Batch: 2893. Acc: 0.344070. Loss: 1.870668. Batch_acc: 0.353248. Batch_loss: 1.830306 \n",
      "Batch: 2894. Acc: 0.344072. Loss: 1.870651. Batch_acc: 0.348494. Batch_loss: 1.821445 \n",
      "Batch: 2895. Acc: 0.344074. Loss: 1.870654. Batch_acc: 0.351809. Batch_loss: 1.877312 \n",
      "Batch: 2896. Acc: 0.344079. Loss: 1.870640. Batch_acc: 0.358407. Batch_loss: 1.832251 \n",
      "Batch: 2897. Acc: 0.344086. Loss: 1.870629. Batch_acc: 0.363427. Batch_loss: 1.837714 \n",
      "Batch: 2898. Acc: 0.344091. Loss: 1.870619. Batch_acc: 0.358556. Batch_loss: 1.841087 \n",
      "Batch: 2899. Acc: 0.344094. Loss: 1.870601. Batch_acc: 0.351894. Batch_loss: 1.819064 \n",
      "Batch: 2900. Acc: 0.344097. Loss: 1.870590. Batch_acc: 0.352941. Batch_loss: 1.840361 \n",
      "Batch: 2901. Acc: 0.344103. Loss: 1.870570. Batch_acc: 0.361305. Batch_loss: 1.812027 \n",
      "Batch: 2902. Acc: 0.344104. Loss: 1.870560. Batch_acc: 0.349143. Batch_loss: 1.839220 \n",
      "Batch: 2903. Acc: 0.344110. Loss: 1.870542. Batch_acc: 0.359481. Batch_loss: 1.819396 \n",
      "Batch: 2904. Acc: 0.344123. Loss: 1.870499. Batch_acc: 0.381271. Batch_loss: 1.750029 \n",
      "Batch: 2905. Acc: 0.344130. Loss: 1.870472. Batch_acc: 0.364277. Batch_loss: 1.791502 \n",
      "Batch: 2906. Acc: 0.344143. Loss: 1.870434. Batch_acc: 0.380634. Batch_loss: 1.762449 \n",
      "Batch: 2907. Acc: 0.344150. Loss: 1.870413. Batch_acc: 0.367074. Batch_loss: 1.808708 \n",
      "Batch: 2908. Acc: 0.344159. Loss: 1.870381. Batch_acc: 0.367463. Batch_loss: 1.779073 \n",
      "Batch: 2909. Acc: 0.344164. Loss: 1.870354. Batch_acc: 0.361432. Batch_loss: 1.792312 \n",
      "Batch: 2910. Acc: 0.344172. Loss: 1.870333. Batch_acc: 0.367418. Batch_loss: 1.807163 \n",
      "Batch: 2911. Acc: 0.344181. Loss: 1.870306. Batch_acc: 0.369131. Batch_loss: 1.792402 \n",
      "Batch: 2912. Acc: 0.344190. Loss: 1.870274. Batch_acc: 0.370074. Batch_loss: 1.776601 \n",
      "Batch: 2913. Acc: 0.344202. Loss: 1.870231. Batch_acc: 0.377983. Batch_loss: 1.751223 \n",
      "Batch: 2914. Acc: 0.344203. Loss: 1.870223. Batch_acc: 0.346667. Batch_loss: 1.849226 \n",
      "Batch: 2915. Acc: 0.344204. Loss: 1.870221. Batch_acc: 0.348718. Batch_loss: 1.864255 \n",
      "Batch: 2916. Acc: 0.344209. Loss: 1.870206. Batch_acc: 0.356904. Batch_loss: 1.826522 \n",
      "Batch: 2917. Acc: 0.344212. Loss: 1.870184. Batch_acc: 0.353977. Batch_loss: 1.806032 \n",
      "Batch: 2918. Acc: 0.344217. Loss: 1.870173. Batch_acc: 0.357925. Batch_loss: 1.838322 \n",
      "Batch: 2919. Acc: 0.344218. Loss: 1.870154. Batch_acc: 0.346644. Batch_loss: 1.815995 \n",
      "Batch: 2920. Acc: 0.344220. Loss: 1.870134. Batch_acc: 0.349886. Batch_loss: 1.811290 \n",
      "Batch: 2921. Acc: 0.344221. Loss: 1.870127. Batch_acc: 0.347876. Batch_loss: 1.849627 \n",
      "Batch: 2922. Acc: 0.344228. Loss: 1.870103. Batch_acc: 0.365143. Batch_loss: 1.801040 \n",
      "Batch: 2923. Acc: 0.344239. Loss: 1.870079. Batch_acc: 0.375573. Batch_loss: 1.798763 \n",
      "Batch: 2924. Acc: 0.344238. Loss: 1.870070. Batch_acc: 0.340870. Batch_loss: 1.845619 \n",
      "Batch: 2925. Acc: 0.344242. Loss: 1.870050. Batch_acc: 0.357728. Batch_loss: 1.808376 \n",
      "Batch: 2926. Acc: 0.344246. Loss: 1.870026. Batch_acc: 0.354821. Batch_loss: 1.802271 \n",
      "Batch: 2927. Acc: 0.344257. Loss: 1.869997. Batch_acc: 0.374859. Batch_loss: 1.787454 \n",
      "Batch: 2928. Acc: 0.344267. Loss: 1.869977. Batch_acc: 0.372891. Batch_loss: 1.809310 \n",
      "Batch: 2929. Acc: 0.344275. Loss: 1.869947. Batch_acc: 0.368095. Batch_loss: 1.783522 \n",
      "Batch: 2930. Acc: 0.344276. Loss: 1.869924. Batch_acc: 0.347302. Batch_loss: 1.805390 \n",
      "Batch: 2931. Acc: 0.344284. Loss: 1.869898. Batch_acc: 0.367463. Batch_loss: 1.792652 \n",
      "Batch: 2932. Acc: 0.344293. Loss: 1.869869. Batch_acc: 0.369565. Batch_loss: 1.786680 \n",
      "Batch: 2933. Acc: 0.344301. Loss: 1.869849. Batch_acc: 0.369565. Batch_loss: 1.810153 \n",
      "Batch: 2934. Acc: 0.344302. Loss: 1.869850. Batch_acc: 0.346359. Batch_loss: 1.872924 \n",
      "Batch: 2935. Acc: 0.344308. Loss: 1.869831. Batch_acc: 0.362791. Batch_loss: 1.814024 \n",
      "Batch: 2936. Acc: 0.344313. Loss: 1.869809. Batch_acc: 0.357102. Batch_loss: 1.805623 \n",
      "Batch: 2937. Acc: 0.344318. Loss: 1.869791. Batch_acc: 0.361283. Batch_loss: 1.818758 \n",
      "Batch: 2938. Acc: 0.344327. Loss: 1.869768. Batch_acc: 0.370370. Batch_loss: 1.801595 \n",
      "Batch: 2939. Acc: 0.344339. Loss: 1.869728. Batch_acc: 0.377753. Batch_loss: 1.755630 \n",
      "Batch: 2940. Acc: 0.344345. Loss: 1.869702. Batch_acc: 0.363324. Batch_loss: 1.793661 \n",
      "Batch: 2941. Acc: 0.344356. Loss: 1.869677. Batch_acc: 0.377087. Batch_loss: 1.795419 \n",
      "Batch: 2942. Acc: 0.344358. Loss: 1.869658. Batch_acc: 0.349160. Batch_loss: 1.814127 \n",
      "Batch: 2943. Acc: 0.344363. Loss: 1.869649. Batch_acc: 0.357798. Batch_loss: 1.840856 \n",
      "Batch: 2944. Acc: 0.344365. Loss: 1.869636. Batch_acc: 0.350174. Batch_loss: 1.832521 \n",
      "Batch: 2945. Acc: 0.344370. Loss: 1.869616. Batch_acc: 0.359223. Batch_loss: 1.809924 \n",
      "Batch: 2946. Acc: 0.344375. Loss: 1.869598. Batch_acc: 0.360184. Batch_loss: 1.818716 \n",
      "Batch: 2947. Acc: 0.344377. Loss: 1.869591. Batch_acc: 0.351020. Batch_loss: 1.846879 \n",
      "Batch: 2948. Acc: 0.344386. Loss: 1.869566. Batch_acc: 0.370175. Batch_loss: 1.796021 \n",
      "Batch: 2949. Acc: 0.344395. Loss: 1.869533. Batch_acc: 0.370246. Batch_loss: 1.774686 \n",
      "Batch: 2950. Acc: 0.344402. Loss: 1.869505. Batch_acc: 0.366919. Batch_loss: 1.786215 \n",
      "Batch: 2951. Acc: 0.344410. Loss: 1.869478. Batch_acc: 0.367147. Batch_loss: 1.787158 \n",
      "Batch: 2952. Acc: 0.344414. Loss: 1.869455. Batch_acc: 0.355271. Batch_loss: 1.803113 \n",
      "Batch: 2953. Acc: 0.344417. Loss: 1.869431. Batch_acc: 0.352975. Batch_loss: 1.798798 \n",
      "Batch: 2954. Acc: 0.344422. Loss: 1.869412. Batch_acc: 0.361481. Batch_loss: 1.811253 \n",
      "Batch: 2955. Acc: 0.344427. Loss: 1.869386. Batch_acc: 0.356732. Batch_loss: 1.794802 \n",
      "Batch: 2956. Acc: 0.344426. Loss: 1.869380. Batch_acc: 0.342693. Batch_loss: 1.851486 \n",
      "Batch: 2957. Acc: 0.344428. Loss: 1.869370. Batch_acc: 0.350619. Batch_loss: 1.838407 \n",
      "Batch: 2958. Acc: 0.344434. Loss: 1.869348. Batch_acc: 0.360998. Batch_loss: 1.803323 \n",
      "Batch: 2959. Acc: 0.344437. Loss: 1.869328. Batch_acc: 0.354785. Batch_loss: 1.812843 \n",
      "Batch: 2960. Acc: 0.344443. Loss: 1.869308. Batch_acc: 0.360571. Batch_loss: 1.809881 \n",
      "Batch: 2961. Acc: 0.344449. Loss: 1.869290. Batch_acc: 0.363585. Batch_loss: 1.815519 \n",
      "Batch: 2962. Acc: 0.344457. Loss: 1.869268. Batch_acc: 0.367882. Batch_loss: 1.805367 \n",
      "Batch: 2963. Acc: 0.344457. Loss: 1.869258. Batch_acc: 0.345286. Batch_loss: 1.840876 \n",
      "Batch: 2964. Acc: 0.344462. Loss: 1.869237. Batch_acc: 0.357766. Batch_loss: 1.806389 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2965. Acc: 0.344467. Loss: 1.869219. Batch_acc: 0.359139. Batch_loss: 1.814297 \n",
      "Batch: 2966. Acc: 0.344469. Loss: 1.869203. Batch_acc: 0.352459. Batch_loss: 1.818927 \n",
      "Batch: 2967. Acc: 0.344477. Loss: 1.869171. Batch_acc: 0.366574. Batch_loss: 1.779841 \n",
      "Batch: 2968. Acc: 0.344480. Loss: 1.869152. Batch_acc: 0.354119. Batch_loss: 1.811079 \n",
      "Batch: 2969. Acc: 0.344492. Loss: 1.869124. Batch_acc: 0.378223. Batch_loss: 1.786052 \n",
      "Batch: 2970. Acc: 0.344503. Loss: 1.869099. Batch_acc: 0.376579. Batch_loss: 1.795043 \n",
      "Batch: 2971. Acc: 0.344506. Loss: 1.869081. Batch_acc: 0.353379. Batch_loss: 1.817363 \n",
      "Batch: 2972. Acc: 0.344502. Loss: 1.869078. Batch_acc: 0.333916. Batch_loss: 1.859966 \n",
      "Batch: 2973. Acc: 0.344503. Loss: 1.869064. Batch_acc: 0.346176. Batch_loss: 1.826713 \n",
      "Batch: 2974. Acc: 0.344506. Loss: 1.869042. Batch_acc: 0.353737. Batch_loss: 1.802065 \n",
      "Batch: 2975. Acc: 0.344510. Loss: 1.869014. Batch_acc: 0.358116. Batch_loss: 1.787153 \n",
      "Batch: 2976. Acc: 0.344515. Loss: 1.868997. Batch_acc: 0.358523. Batch_loss: 1.818690 \n",
      "Batch: 2977. Acc: 0.344527. Loss: 1.868964. Batch_acc: 0.379444. Batch_loss: 1.774732 \n",
      "Batch: 2978. Acc: 0.344534. Loss: 1.868947. Batch_acc: 0.364602. Batch_loss: 1.817194 \n",
      "Batch: 2979. Acc: 0.344538. Loss: 1.868931. Batch_acc: 0.356164. Batch_loss: 1.818890 \n",
      "Batch: 2980. Acc: 0.344540. Loss: 1.868909. Batch_acc: 0.352445. Batch_loss: 1.803820 \n",
      "Batch: 2981. Acc: 0.344544. Loss: 1.868895. Batch_acc: 0.356315. Batch_loss: 1.828570 \n",
      "Batch: 2982. Acc: 0.344554. Loss: 1.868859. Batch_acc: 0.372483. Batch_loss: 1.764020 \n",
      "Batch: 2983. Acc: 0.344560. Loss: 1.868840. Batch_acc: 0.362751. Batch_loss: 1.810615 \n",
      "Batch: 2984. Acc: 0.344564. Loss: 1.868821. Batch_acc: 0.357681. Batch_loss: 1.811745 \n",
      "Batch: 2985. Acc: 0.344576. Loss: 1.868783. Batch_acc: 0.379718. Batch_loss: 1.757782 \n",
      "Batch: 2986. Acc: 0.344583. Loss: 1.868757. Batch_acc: 0.365135. Batch_loss: 1.791654 \n",
      "Batch: 2987. Acc: 0.344587. Loss: 1.868743. Batch_acc: 0.355248. Batch_loss: 1.826458 \n",
      "Batch: 2988. Acc: 0.344591. Loss: 1.868731. Batch_acc: 0.356537. Batch_loss: 1.833662 \n",
      "Batch: 2989. Acc: 0.344598. Loss: 1.868717. Batch_acc: 0.368359. Batch_loss: 1.824103 \n",
      "Batch: 2990. Acc: 0.344604. Loss: 1.868705. Batch_acc: 0.362159. Batch_loss: 1.832812 \n",
      "Batch: 2991. Acc: 0.344604. Loss: 1.868694. Batch_acc: 0.344710. Batch_loss: 1.837402 \n",
      "Batch: 2992. Acc: 0.344614. Loss: 1.868667. Batch_acc: 0.374640. Batch_loss: 1.786530 \n",
      "Batch: 2993. Acc: 0.344622. Loss: 1.868644. Batch_acc: 0.368725. Batch_loss: 1.800995 \n",
      "Batch: 2994. Acc: 0.344619. Loss: 1.868651. Batch_acc: 0.334682. Batch_loss: 1.889806 \n",
      "Batch: 2995. Acc: 0.344618. Loss: 1.868653. Batch_acc: 0.342760. Batch_loss: 1.872631 \n",
      "Batch: 2996. Acc: 0.344621. Loss: 1.868636. Batch_acc: 0.351176. Batch_loss: 1.817767 \n",
      "Batch: 2997. Acc: 0.344623. Loss: 1.868620. Batch_acc: 0.351522. Batch_loss: 1.820105 \n",
      "Batch: 2998. Acc: 0.344627. Loss: 1.868609. Batch_acc: 0.358174. Batch_loss: 1.836811 \n",
      "Batch: 2999. Acc: 0.344633. Loss: 1.868595. Batch_acc: 0.360492. Batch_loss: 1.824526 \n",
      "Batch: 3000. Acc: 0.344641. Loss: 1.868581. Batch_acc: 0.369348. Batch_loss: 1.825114 \n",
      "Batch: 3001. Acc: 0.344645. Loss: 1.868567. Batch_acc: 0.358314. Batch_loss: 1.825602 \n",
      "Batch: 3002. Acc: 0.344652. Loss: 1.868541. Batch_acc: 0.367015. Batch_loss: 1.790395 \n",
      "Batch: 3003. Acc: 0.344658. Loss: 1.868521. Batch_acc: 0.359889. Batch_loss: 1.809423 \n",
      "Batch: 3004. Acc: 0.344659. Loss: 1.868501. Batch_acc: 0.347302. Batch_loss: 1.810611 \n",
      "Batch: 3005. Acc: 0.344666. Loss: 1.868462. Batch_acc: 0.366629. Batch_loss: 1.753885 \n",
      "Batch: 3006. Acc: 0.344674. Loss: 1.868440. Batch_acc: 0.367536. Batch_loss: 1.800923 \n",
      "Batch: 3007. Acc: 0.344679. Loss: 1.868425. Batch_acc: 0.360397. Batch_loss: 1.822621 \n",
      "Batch: 3008. Acc: 0.344686. Loss: 1.868399. Batch_acc: 0.367836. Batch_loss: 1.790294 \n",
      "Batch: 3009. Acc: 0.344690. Loss: 1.868376. Batch_acc: 0.356250. Batch_loss: 1.800326 \n",
      "Batch: 3010. Acc: 0.344691. Loss: 1.868377. Batch_acc: 0.347254. Batch_loss: 1.869883 \n",
      "Batch: 3011. Acc: 0.344698. Loss: 1.868356. Batch_acc: 0.365743. Batch_loss: 1.807958 \n",
      "Batch: 3012. Acc: 0.344705. Loss: 1.868334. Batch_acc: 0.365133. Batch_loss: 1.800519 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.34470510807672855. Loss per char: 1.8683335943961779. Time: 1627208834.1083229\n",
      "Last question is tensor([ 2, 14, 20, 23, 23, 18, 20, 19, 19, 21, 23, 15, 20,  1, 14,  1, 14, 22,\n",
      "        15, 18,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.344714. Loss: 1.868309. Batch_acc: 0.370056. Batch_loss: 1.794206 \n",
      "Batch: 3014. Acc: 0.344722. Loss: 1.868283. Batch_acc: 0.369257. Batch_loss: 1.791143 \n",
      "Batch: 3015. Acc: 0.344728. Loss: 1.868255. Batch_acc: 0.361330. Batch_loss: 1.787718 \n",
      "Batch: 3016. Acc: 0.344731. Loss: 1.868229. Batch_acc: 0.356148. Batch_loss: 1.787709 \n",
      "Batch: 3017. Acc: 0.344745. Loss: 1.868194. Batch_acc: 0.386390. Batch_loss: 1.764133 \n",
      "Batch: 3018. Acc: 0.344751. Loss: 1.868168. Batch_acc: 0.363584. Batch_loss: 1.788433 \n",
      "Batch: 3019. Acc: 0.344758. Loss: 1.868145. Batch_acc: 0.365556. Batch_loss: 1.802882 \n",
      "Batch: 3020. Acc: 0.344762. Loss: 1.868128. Batch_acc: 0.356436. Batch_loss: 1.814135 \n",
      "Batch: 3021. Acc: 0.344762. Loss: 1.868112. Batch_acc: 0.343446. Batch_loss: 1.820357 \n",
      "Batch: 3022. Acc: 0.344768. Loss: 1.868088. Batch_acc: 0.363892. Batch_loss: 1.798185 \n",
      "Batch: 3023. Acc: 0.344772. Loss: 1.868073. Batch_acc: 0.357020. Batch_loss: 1.821241 \n",
      "Batch: 3024. Acc: 0.344783. Loss: 1.868047. Batch_acc: 0.377894. Batch_loss: 1.789071 \n",
      "Batch: 3025. Acc: 0.344788. Loss: 1.868018. Batch_acc: 0.358873. Batch_loss: 1.781970 \n",
      "Batch: 3026. Acc: 0.344791. Loss: 1.868016. Batch_acc: 0.354167. Batch_loss: 1.862788 \n",
      "Batch: 3027. Acc: 0.344799. Loss: 1.867991. Batch_acc: 0.367882. Batch_loss: 1.793137 \n",
      "Batch: 3028. Acc: 0.344805. Loss: 1.867982. Batch_acc: 0.363794. Batch_loss: 1.839924 \n",
      "Batch: 3029. Acc: 0.344809. Loss: 1.867970. Batch_acc: 0.356355. Batch_loss: 1.831932 \n",
      "Batch: 3030. Acc: 0.344817. Loss: 1.867950. Batch_acc: 0.369480. Batch_loss: 1.807701 \n",
      "Batch: 3031. Acc: 0.344823. Loss: 1.867930. Batch_acc: 0.363112. Batch_loss: 1.807733 \n",
      "Batch: 3032. Acc: 0.344827. Loss: 1.867926. Batch_acc: 0.355023. Batch_loss: 1.855636 \n",
      "Batch: 3033. Acc: 0.344833. Loss: 1.867908. Batch_acc: 0.364692. Batch_loss: 1.814792 \n",
      "Batch: 3034. Acc: 0.344836. Loss: 1.867904. Batch_acc: 0.352727. Batch_loss: 1.853027 \n",
      "Batch: 3035. Acc: 0.344845. Loss: 1.867877. Batch_acc: 0.371157. Batch_loss: 1.790679 \n",
      "Batch: 3036. Acc: 0.344849. Loss: 1.867858. Batch_acc: 0.357895. Batch_loss: 1.810186 \n",
      "Batch: 3037. Acc: 0.344847. Loss: 1.867844. Batch_acc: 0.340218. Batch_loss: 1.826082 \n",
      "Batch: 3038. Acc: 0.344853. Loss: 1.867826. Batch_acc: 0.360391. Batch_loss: 1.814600 \n",
      "Batch: 3039. Acc: 0.344854. Loss: 1.867803. Batch_acc: 0.350551. Batch_loss: 1.796657 \n",
      "Batch: 3040. Acc: 0.344859. Loss: 1.867789. Batch_acc: 0.359763. Batch_loss: 1.821911 \n",
      "Batch: 3041. Acc: 0.344864. Loss: 1.867776. Batch_acc: 0.360789. Batch_loss: 1.829944 \n",
      "Batch: 3042. Acc: 0.344876. Loss: 1.867754. Batch_acc: 0.380233. Batch_loss: 1.798899 \n",
      "Batch: 3043. Acc: 0.344877. Loss: 1.867748. Batch_acc: 0.348989. Batch_loss: 1.848920 \n",
      "Batch: 3044. Acc: 0.344872. Loss: 1.867754. Batch_acc: 0.329781. Batch_loss: 1.887293 \n",
      "Batch: 3045. Acc: 0.344874. Loss: 1.867735. Batch_acc: 0.348943. Batch_loss: 1.811339 \n",
      "Batch: 3046. Acc: 0.344883. Loss: 1.867715. Batch_acc: 0.373396. Batch_loss: 1.805690 \n",
      "Batch: 3047. Acc: 0.344886. Loss: 1.867701. Batch_acc: 0.352907. Batch_loss: 1.824474 \n",
      "Batch: 3048. Acc: 0.344888. Loss: 1.867687. Batch_acc: 0.353765. Batch_loss: 1.822853 \n",
      "Batch: 3049. Acc: 0.344897. Loss: 1.867660. Batch_acc: 0.371087. Batch_loss: 1.787047 \n",
      "Batch: 3050. Acc: 0.344907. Loss: 1.867622. Batch_acc: 0.374025. Batch_loss: 1.755035 \n",
      "Batch: 3051. Acc: 0.344910. Loss: 1.867600. Batch_acc: 0.353078. Batch_loss: 1.799335 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3052. Acc: 0.344917. Loss: 1.867576. Batch_acc: 0.369151. Batch_loss: 1.792688 \n",
      "Batch: 3053. Acc: 0.344918. Loss: 1.867560. Batch_acc: 0.347374. Batch_loss: 1.820957 \n",
      "Batch: 3054. Acc: 0.344918. Loss: 1.867552. Batch_acc: 0.342775. Batch_loss: 1.841484 \n",
      "Batch: 3055. Acc: 0.344924. Loss: 1.867531. Batch_acc: 0.365812. Batch_loss: 1.805238 \n",
      "Batch: 3056. Acc: 0.344931. Loss: 1.867499. Batch_acc: 0.365950. Batch_loss: 1.770640 \n",
      "Batch: 3057. Acc: 0.344941. Loss: 1.867472. Batch_acc: 0.374350. Batch_loss: 1.785475 \n",
      "Batch: 3058. Acc: 0.344951. Loss: 1.867444. Batch_acc: 0.375421. Batch_loss: 1.784465 \n",
      "Batch: 3059. Acc: 0.344958. Loss: 1.867419. Batch_acc: 0.366262. Batch_loss: 1.787727 \n",
      "Batch: 3060. Acc: 0.344958. Loss: 1.867410. Batch_acc: 0.345315. Batch_loss: 1.839787 \n",
      "Batch: 3061. Acc: 0.344962. Loss: 1.867379. Batch_acc: 0.355182. Batch_loss: 1.777299 \n",
      "Batch: 3062. Acc: 0.344967. Loss: 1.867361. Batch_acc: 0.361446. Batch_loss: 1.812211 \n",
      "Batch: 3063. Acc: 0.344975. Loss: 1.867333. Batch_acc: 0.369983. Batch_loss: 1.780439 \n",
      "Batch: 3064. Acc: 0.344983. Loss: 1.867312. Batch_acc: 0.367359. Batch_loss: 1.801024 \n",
      "Batch: 3065. Acc: 0.344984. Loss: 1.867302. Batch_acc: 0.350598. Batch_loss: 1.837505 \n",
      "Batch: 3066. Acc: 0.344985. Loss: 1.867292. Batch_acc: 0.346690. Batch_loss: 1.837707 \n",
      "Batch: 3067. Acc: 0.344986. Loss: 1.867277. Batch_acc: 0.348230. Batch_loss: 1.818326 \n",
      "Batch: 3068. Acc: 0.344992. Loss: 1.867258. Batch_acc: 0.363216. Batch_loss: 1.808483 \n",
      "Batch: 3069. Acc: 0.345002. Loss: 1.867232. Batch_acc: 0.376215. Batch_loss: 1.789879 \n",
      "Batch: 3070. Acc: 0.345013. Loss: 1.867204. Batch_acc: 0.376411. Batch_loss: 1.781910 \n",
      "Batch: 3071. Acc: 0.345021. Loss: 1.867166. Batch_acc: 0.370950. Batch_loss: 1.753146 \n",
      "Batch: 3072. Acc: 0.345024. Loss: 1.867141. Batch_acc: 0.353768. Batch_loss: 1.792644 \n",
      "Batch: 3073. Acc: 0.345031. Loss: 1.867116. Batch_acc: 0.366286. Batch_loss: 1.791062 \n",
      "Batch: 3074. Acc: 0.345036. Loss: 1.867089. Batch_acc: 0.361383. Batch_loss: 1.784027 \n",
      "Batch: 3075. Acc: 0.345041. Loss: 1.867071. Batch_acc: 0.359107. Batch_loss: 1.813586 \n",
      "Batch: 3076. Acc: 0.345047. Loss: 1.867050. Batch_acc: 0.364063. Batch_loss: 1.798990 \n",
      "Batch: 3077. Acc: 0.345056. Loss: 1.867024. Batch_acc: 0.371023. Batch_loss: 1.788447 \n",
      "Batch: 3078. Acc: 0.345058. Loss: 1.867009. Batch_acc: 0.352775. Batch_loss: 1.820601 \n",
      "Batch: 3079. Acc: 0.345064. Loss: 1.866983. Batch_acc: 0.363956. Batch_loss: 1.787198 \n",
      "Batch: 3080. Acc: 0.345073. Loss: 1.866954. Batch_acc: 0.371692. Batch_loss: 1.777254 \n",
      "Batch: 3081. Acc: 0.345080. Loss: 1.866927. Batch_acc: 0.366222. Batch_loss: 1.781999 \n",
      "Batch: 3082. Acc: 0.345086. Loss: 1.866904. Batch_acc: 0.363480. Batch_loss: 1.797905 \n",
      "Batch: 3083. Acc: 0.345085. Loss: 1.866901. Batch_acc: 0.344329. Batch_loss: 1.856805 \n",
      "Batch: 3084. Acc: 0.345094. Loss: 1.866876. Batch_acc: 0.372426. Batch_loss: 1.790466 \n",
      "Batch: 3085. Acc: 0.345099. Loss: 1.866864. Batch_acc: 0.359366. Batch_loss: 1.827743 \n",
      "Batch: 3086. Acc: 0.345100. Loss: 1.866851. Batch_acc: 0.348328. Batch_loss: 1.828040 \n",
      "Batch: 3087. Acc: 0.345101. Loss: 1.866837. Batch_acc: 0.349040. Batch_loss: 1.824072 \n",
      "Batch: 3088. Acc: 0.345109. Loss: 1.866813. Batch_acc: 0.370434. Batch_loss: 1.791590 \n",
      "Batch: 3089. Acc: 0.345116. Loss: 1.866787. Batch_acc: 0.364943. Batch_loss: 1.788118 \n",
      "Batch: 3090. Acc: 0.345122. Loss: 1.866766. Batch_acc: 0.363636. Batch_loss: 1.801987 \n",
      "Batch: 3091. Acc: 0.345122. Loss: 1.866763. Batch_acc: 0.344563. Batch_loss: 1.856335 \n",
      "Batch: 3092. Acc: 0.345130. Loss: 1.866737. Batch_acc: 0.369344. Batch_loss: 1.787227 \n",
      "Batch: 3093. Acc: 0.345138. Loss: 1.866710. Batch_acc: 0.369528. Batch_loss: 1.784439 \n",
      "Batch: 3094. Acc: 0.345142. Loss: 1.866697. Batch_acc: 0.359338. Batch_loss: 1.826525 \n",
      "Batch: 3095. Acc: 0.345147. Loss: 1.866684. Batch_acc: 0.359212. Batch_loss: 1.824448 \n",
      "Batch: 3096. Acc: 0.345154. Loss: 1.866657. Batch_acc: 0.367183. Batch_loss: 1.783250 \n",
      "Batch: 3097. Acc: 0.345156. Loss: 1.866647. Batch_acc: 0.351630. Batch_loss: 1.835202 \n",
      "Batch: 3098. Acc: 0.345164. Loss: 1.866623. Batch_acc: 0.371445. Batch_loss: 1.793837 \n",
      "Batch: 3099. Acc: 0.345167. Loss: 1.866603. Batch_acc: 0.352208. Batch_loss: 1.805587 \n",
      "Batch: 3100. Acc: 0.345168. Loss: 1.866594. Batch_acc: 0.349825. Batch_loss: 1.838848 \n",
      "Batch: 3101. Acc: 0.345171. Loss: 1.866578. Batch_acc: 0.353329. Batch_loss: 1.813979 \n",
      "Batch: 3102. Acc: 0.345172. Loss: 1.866568. Batch_acc: 0.349829. Batch_loss: 1.836179 \n",
      "Batch: 3103. Acc: 0.345180. Loss: 1.866539. Batch_acc: 0.368272. Batch_loss: 1.777382 \n",
      "Batch: 3104. Acc: 0.345187. Loss: 1.866509. Batch_acc: 0.366460. Batch_loss: 1.775164 \n",
      "Batch: 3105. Acc: 0.345191. Loss: 1.866494. Batch_acc: 0.357681. Batch_loss: 1.821744 \n",
      "Batch: 3106. Acc: 0.345196. Loss: 1.866476. Batch_acc: 0.361001. Batch_loss: 1.810906 \n",
      "Batch: 3107. Acc: 0.345206. Loss: 1.866449. Batch_acc: 0.375211. Batch_loss: 1.784721 \n",
      "Batch: 3108. Acc: 0.345209. Loss: 1.866442. Batch_acc: 0.356389. Batch_loss: 1.842330 \n",
      "Batch: 3109. Acc: 0.345217. Loss: 1.866420. Batch_acc: 0.368239. Batch_loss: 1.798798 \n",
      "Batch: 3110. Acc: 0.345221. Loss: 1.866402. Batch_acc: 0.357988. Batch_loss: 1.807434 \n",
      "Batch: 3111. Acc: 0.345231. Loss: 1.866373. Batch_acc: 0.378850. Batch_loss: 1.774953 \n",
      "Batch: 3112. Acc: 0.345239. Loss: 1.866343. Batch_acc: 0.367803. Batch_loss: 1.776658 \n",
      "Batch: 3113. Acc: 0.345243. Loss: 1.866325. Batch_acc: 0.357344. Batch_loss: 1.811635 \n",
      "Batch: 3114. Acc: 0.345242. Loss: 1.866321. Batch_acc: 0.342890. Batch_loss: 1.854380 \n",
      "Batch: 3115. Acc: 0.345251. Loss: 1.866294. Batch_acc: 0.372960. Batch_loss: 1.780302 \n",
      "Batch: 3116. Acc: 0.345256. Loss: 1.866262. Batch_acc: 0.362178. Batch_loss: 1.768999 \n",
      "Batch: 3117. Acc: 0.345263. Loss: 1.866242. Batch_acc: 0.366648. Batch_loss: 1.805327 \n",
      "Batch: 3118. Acc: 0.345272. Loss: 1.866216. Batch_acc: 0.372200. Batch_loss: 1.785347 \n",
      "Batch: 3119. Acc: 0.345273. Loss: 1.866196. Batch_acc: 0.349622. Batch_loss: 1.802147 \n",
      "Batch: 3120. Acc: 0.345279. Loss: 1.866175. Batch_acc: 0.363477. Batch_loss: 1.798826 \n",
      "Batch: 3121. Acc: 0.345285. Loss: 1.866152. Batch_acc: 0.363742. Batch_loss: 1.795167 \n",
      "Batch: 3122. Acc: 0.345288. Loss: 1.866139. Batch_acc: 0.356268. Batch_loss: 1.824878 \n",
      "Batch: 3123. Acc: 0.345293. Loss: 1.866120. Batch_acc: 0.359032. Batch_loss: 1.807928 \n",
      "Batch: 3124. Acc: 0.345306. Loss: 1.866095. Batch_acc: 0.384486. Batch_loss: 1.788789 \n",
      "Batch: 3125. Acc: 0.345307. Loss: 1.866084. Batch_acc: 0.349475. Batch_loss: 1.830356 \n",
      "Batch: 3126. Acc: 0.345315. Loss: 1.866059. Batch_acc: 0.369565. Batch_loss: 1.788483 \n",
      "Batch: 3127. Acc: 0.345319. Loss: 1.866040. Batch_acc: 0.359884. Batch_loss: 1.807442 \n",
      "Batch: 3128. Acc: 0.345329. Loss: 1.866016. Batch_acc: 0.373378. Batch_loss: 1.790699 \n",
      "Batch: 3129. Acc: 0.345328. Loss: 1.866010. Batch_acc: 0.344234. Batch_loss: 1.849796 \n",
      "Batch: 3130. Acc: 0.345334. Loss: 1.865983. Batch_acc: 0.363797. Batch_loss: 1.778283 \n",
      "Batch: 3131. Acc: 0.345341. Loss: 1.865959. Batch_acc: 0.367111. Batch_loss: 1.788910 \n",
      "Batch: 3132. Acc: 0.345345. Loss: 1.865942. Batch_acc: 0.358382. Batch_loss: 1.814045 \n",
      "Batch: 3133. Acc: 0.345348. Loss: 1.865922. Batch_acc: 0.355846. Batch_loss: 1.803542 \n",
      "Batch: 3134. Acc: 0.345356. Loss: 1.865897. Batch_acc: 0.367521. Batch_loss: 1.787793 \n",
      "Batch: 3135. Acc: 0.345361. Loss: 1.865877. Batch_acc: 0.361970. Batch_loss: 1.802801 \n",
      "Batch: 3136. Acc: 0.345370. Loss: 1.865850. Batch_acc: 0.372842. Batch_loss: 1.783715 \n",
      "Batch: 3137. Acc: 0.345377. Loss: 1.865824. Batch_acc: 0.367103. Batch_loss: 1.783088 \n",
      "Batch: 3138. Acc: 0.345380. Loss: 1.865813. Batch_acc: 0.356639. Batch_loss: 1.831709 \n",
      "Batch: 3139. Acc: 0.345388. Loss: 1.865779. Batch_acc: 0.368391. Batch_loss: 1.759917 \n",
      "Batch: 3140. Acc: 0.345387. Loss: 1.865770. Batch_acc: 0.344966. Batch_loss: 1.836254 \n",
      "Batch: 3141. Acc: 0.345393. Loss: 1.865756. Batch_acc: 0.363949. Batch_loss: 1.821964 \n",
      "Batch: 3142. Acc: 0.345395. Loss: 1.865750. Batch_acc: 0.350595. Batch_loss: 1.847340 \n",
      "Batch: 3143. Acc: 0.345393. Loss: 1.865750. Batch_acc: 0.338036. Batch_loss: 1.864143 \n",
      "Batch: 3144. Acc: 0.345391. Loss: 1.865744. Batch_acc: 0.340949. Batch_loss: 1.847819 \n",
      "Batch: 3145. Acc: 0.345393. Loss: 1.865734. Batch_acc: 0.350939. Batch_loss: 1.833359 \n",
      "Batch: 3146. Acc: 0.345399. Loss: 1.865708. Batch_acc: 0.364372. Batch_loss: 1.783690 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3147. Acc: 0.345405. Loss: 1.865693. Batch_acc: 0.364437. Batch_loss: 1.818635 \n",
      "Batch: 3148. Acc: 0.345405. Loss: 1.865688. Batch_acc: 0.344552. Batch_loss: 1.847398 \n",
      "Batch: 3149. Acc: 0.345407. Loss: 1.865672. Batch_acc: 0.353345. Batch_loss: 1.816863 \n",
      "Batch: 3150. Acc: 0.345415. Loss: 1.865648. Batch_acc: 0.370996. Batch_loss: 1.790482 \n",
      "Batch: 3151. Acc: 0.345427. Loss: 1.865615. Batch_acc: 0.381356. Batch_loss: 1.760512 \n",
      "Batch: 3152. Acc: 0.345431. Loss: 1.865595. Batch_acc: 0.357183. Batch_loss: 1.805400 \n",
      "Batch: 3153. Acc: 0.345432. Loss: 1.865590. Batch_acc: 0.350318. Batch_loss: 1.848317 \n",
      "Batch: 3154. Acc: 0.345440. Loss: 1.865563. Batch_acc: 0.369641. Batch_loss: 1.779250 \n",
      "Batch: 3155. Acc: 0.345450. Loss: 1.865534. Batch_acc: 0.378256. Batch_loss: 1.775558 \n",
      "Batch: 3156. Acc: 0.345457. Loss: 1.865518. Batch_acc: 0.366780. Batch_loss: 1.816833 \n",
      "Batch: 3157. Acc: 0.345461. Loss: 1.865504. Batch_acc: 0.358554. Batch_loss: 1.822409 \n",
      "Batch: 3158. Acc: 0.345465. Loss: 1.865490. Batch_acc: 0.357349. Batch_loss: 1.820347 \n",
      "Batch: 3159. Acc: 0.345469. Loss: 1.865478. Batch_acc: 0.357562. Batch_loss: 1.826286 \n",
      "Batch: 3160. Acc: 0.345475. Loss: 1.865449. Batch_acc: 0.363936. Batch_loss: 1.778810 \n",
      "Batch: 3161. Acc: 0.345487. Loss: 1.865412. Batch_acc: 0.382470. Batch_loss: 1.751522 \n",
      "Batch: 3162. Acc: 0.345491. Loss: 1.865400. Batch_acc: 0.359557. Batch_loss: 1.825255 \n",
      "Batch: 3163. Acc: 0.345498. Loss: 1.865371. Batch_acc: 0.366108. Batch_loss: 1.774002 \n",
      "Batch: 3164. Acc: 0.345502. Loss: 1.865346. Batch_acc: 0.359179. Batch_loss: 1.787097 \n",
      "Batch: 3165. Acc: 0.345505. Loss: 1.865329. Batch_acc: 0.354821. Batch_loss: 1.812221 \n",
      "Batch: 3166. Acc: 0.345511. Loss: 1.865301. Batch_acc: 0.363426. Batch_loss: 1.777260 \n",
      "Batch: 3167. Acc: 0.345514. Loss: 1.865284. Batch_acc: 0.357018. Batch_loss: 1.810981 \n",
      "Batch: 3168. Acc: 0.345522. Loss: 1.865266. Batch_acc: 0.369603. Batch_loss: 1.807647 \n",
      "Batch: 3169. Acc: 0.345526. Loss: 1.865246. Batch_acc: 0.359229. Batch_loss: 1.801391 \n",
      "Batch: 3170. Acc: 0.345535. Loss: 1.865223. Batch_acc: 0.372446. Batch_loss: 1.789744 \n",
      "Batch: 3171. Acc: 0.345543. Loss: 1.865193. Batch_acc: 0.371965. Batch_loss: 1.775347 \n",
      "Batch: 3172. Acc: 0.345553. Loss: 1.865158. Batch_acc: 0.375285. Batch_loss: 1.753286 \n",
      "Batch: 3173. Acc: 0.345560. Loss: 1.865132. Batch_acc: 0.368483. Batch_loss: 1.781365 \n",
      "Batch: 3174. Acc: 0.345563. Loss: 1.865108. Batch_acc: 0.356895. Batch_loss: 1.789484 \n",
      "Batch: 3175. Acc: 0.345571. Loss: 1.865092. Batch_acc: 0.369385. Batch_loss: 1.811789 \n",
      "Batch: 3176. Acc: 0.345576. Loss: 1.865075. Batch_acc: 0.363479. Batch_loss: 1.811815 \n",
      "Batch: 3177. Acc: 0.345583. Loss: 1.865053. Batch_acc: 0.365450. Batch_loss: 1.795467 \n",
      "Batch: 3178. Acc: 0.345586. Loss: 1.865045. Batch_acc: 0.356699. Batch_loss: 1.839763 \n",
      "Batch: 3179. Acc: 0.345594. Loss: 1.865021. Batch_acc: 0.371247. Batch_loss: 1.789515 \n",
      "Batch: 3180. Acc: 0.345596. Loss: 1.865014. Batch_acc: 0.351831. Batch_loss: 1.840749 \n",
      "Batch: 3181. Acc: 0.345605. Loss: 1.864977. Batch_acc: 0.373439. Batch_loss: 1.751118 \n",
      "Batch: 3182. Acc: 0.345608. Loss: 1.864956. Batch_acc: 0.356453. Batch_loss: 1.798688 \n",
      "Batch: 3183. Acc: 0.345617. Loss: 1.864928. Batch_acc: 0.373607. Batch_loss: 1.772080 \n",
      "Batch: 3184. Acc: 0.345624. Loss: 1.864900. Batch_acc: 0.369167. Batch_loss: 1.774516 \n",
      "Batch: 3185. Acc: 0.345634. Loss: 1.864875. Batch_acc: 0.377358. Batch_loss: 1.785698 \n",
      "Batch: 3186. Acc: 0.345637. Loss: 1.864867. Batch_acc: 0.354503. Batch_loss: 1.840506 \n",
      "Batch: 3187. Acc: 0.345645. Loss: 1.864841. Batch_acc: 0.372322. Batch_loss: 1.780720 \n",
      "Batch: 3188. Acc: 0.345656. Loss: 1.864814. Batch_acc: 0.379673. Batch_loss: 1.778285 \n",
      "Batch: 3189. Acc: 0.345657. Loss: 1.864801. Batch_acc: 0.349537. Batch_loss: 1.823068 \n",
      "Batch: 3190. Acc: 0.345664. Loss: 1.864779. Batch_acc: 0.367111. Batch_loss: 1.793685 \n",
      "Batch: 3191. Acc: 0.345667. Loss: 1.864761. Batch_acc: 0.357390. Batch_loss: 1.805659 \n",
      "Batch: 3192. Acc: 0.345670. Loss: 1.864741. Batch_acc: 0.355301. Batch_loss: 1.800524 \n",
      "Batch: 3193. Acc: 0.345676. Loss: 1.864727. Batch_acc: 0.364880. Batch_loss: 1.823048 \n",
      "Batch: 3194. Acc: 0.345682. Loss: 1.864706. Batch_acc: 0.362040. Batch_loss: 1.796082 \n",
      "Batch: 3195. Acc: 0.345685. Loss: 1.864684. Batch_acc: 0.356492. Batch_loss: 1.797000 \n",
      "Batch: 3196. Acc: 0.345688. Loss: 1.864677. Batch_acc: 0.354497. Batch_loss: 1.840653 \n",
      "Batch: 3197. Acc: 0.345695. Loss: 1.864656. Batch_acc: 0.369528. Batch_loss: 1.800091 \n",
      "Batch: 3198. Acc: 0.345699. Loss: 1.864635. Batch_acc: 0.356978. Batch_loss: 1.796508 \n",
      "Batch: 3199. Acc: 0.345707. Loss: 1.864611. Batch_acc: 0.370435. Batch_loss: 1.785908 \n",
      "Batch: 3200. Acc: 0.345715. Loss: 1.864582. Batch_acc: 0.372920. Batch_loss: 1.773660 \n",
      "Batch: 3201. Acc: 0.345727. Loss: 1.864556. Batch_acc: 0.382035. Batch_loss: 1.781712 \n",
      "Batch: 3202. Acc: 0.345729. Loss: 1.864542. Batch_acc: 0.353524. Batch_loss: 1.817671 \n",
      "Batch: 3203. Acc: 0.345733. Loss: 1.864523. Batch_acc: 0.359729. Batch_loss: 1.804756 \n",
      "Batch: 3204. Acc: 0.345741. Loss: 1.864496. Batch_acc: 0.371087. Batch_loss: 1.780019 \n",
      "Batch: 3205. Acc: 0.345748. Loss: 1.864475. Batch_acc: 0.367698. Batch_loss: 1.798179 \n",
      "Batch: 3206. Acc: 0.345756. Loss: 1.864445. Batch_acc: 0.371281. Batch_loss: 1.768761 \n",
      "Batch: 3207. Acc: 0.345760. Loss: 1.864424. Batch_acc: 0.358841. Batch_loss: 1.797387 \n",
      "Batch: 3208. Acc: 0.345767. Loss: 1.864404. Batch_acc: 0.365676. Batch_loss: 1.801720 \n",
      "Batch: 3209. Acc: 0.345773. Loss: 1.864384. Batch_acc: 0.367429. Batch_loss: 1.800154 \n",
      "Batch: 3210. Acc: 0.345777. Loss: 1.864362. Batch_acc: 0.357766. Batch_loss: 1.791439 \n",
      "Batch: 3211. Acc: 0.345786. Loss: 1.864342. Batch_acc: 0.374080. Batch_loss: 1.802586 \n",
      "Batch: 3212. Acc: 0.345789. Loss: 1.864324. Batch_acc: 0.354913. Batch_loss: 1.804297 \n",
      "Batch: 3213. Acc: 0.345794. Loss: 1.864302. Batch_acc: 0.361538. Batch_loss: 1.791435 \n",
      "Batch: 3214. Acc: 0.345798. Loss: 1.864291. Batch_acc: 0.359511. Batch_loss: 1.830010 \n",
      "Batch: 3215. Acc: 0.345805. Loss: 1.864271. Batch_acc: 0.367580. Batch_loss: 1.799835 \n",
      "Batch: 3216. Acc: 0.345810. Loss: 1.864257. Batch_acc: 0.364069. Batch_loss: 1.817336 \n",
      "Batch: 3217. Acc: 0.345819. Loss: 1.864238. Batch_acc: 0.372279. Batch_loss: 1.805164 \n",
      "Batch: 3218. Acc: 0.345828. Loss: 1.864209. Batch_acc: 0.376215. Batch_loss: 1.769966 \n",
      "Batch: 3219. Acc: 0.345833. Loss: 1.864201. Batch_acc: 0.362605. Batch_loss: 1.839441 \n",
      "Batch: 3220. Acc: 0.345836. Loss: 1.864191. Batch_acc: 0.356589. Batch_loss: 1.829056 \n",
      "Batch: 3221. Acc: 0.345844. Loss: 1.864166. Batch_acc: 0.370286. Batch_loss: 1.783294 \n",
      "Batch: 3222. Acc: 0.345855. Loss: 1.864142. Batch_acc: 0.381892. Batch_loss: 1.786925 \n",
      "Batch: 3223. Acc: 0.345859. Loss: 1.864118. Batch_acc: 0.358329. Batch_loss: 1.788486 \n",
      "Batch: 3224. Acc: 0.345867. Loss: 1.864088. Batch_acc: 0.372852. Batch_loss: 1.766090 \n",
      "Batch: 3225. Acc: 0.345867. Loss: 1.864066. Batch_acc: 0.343714. Batch_loss: 1.794601 \n",
      "Batch: 3226. Acc: 0.345870. Loss: 1.864045. Batch_acc: 0.356296. Batch_loss: 1.795879 \n",
      "Batch: 3227. Acc: 0.345883. Loss: 1.864005. Batch_acc: 0.388921. Batch_loss: 1.737640 \n",
      "Batch: 3228. Acc: 0.345891. Loss: 1.863976. Batch_acc: 0.369590. Batch_loss: 1.769310 \n",
      "Batch: 3229. Acc: 0.345895. Loss: 1.863950. Batch_acc: 0.359977. Batch_loss: 1.779912 \n",
      "Batch: 3230. Acc: 0.345903. Loss: 1.863926. Batch_acc: 0.371920. Batch_loss: 1.785672 \n",
      "Batch: 3231. Acc: 0.345910. Loss: 1.863903. Batch_acc: 0.367605. Batch_loss: 1.790963 \n",
      "Batch: 3232. Acc: 0.345915. Loss: 1.863880. Batch_acc: 0.363846. Batch_loss: 1.788576 \n",
      "Batch: 3233. Acc: 0.345922. Loss: 1.863864. Batch_acc: 0.367876. Batch_loss: 1.813952 \n",
      "Batch: 3234. Acc: 0.345924. Loss: 1.863851. Batch_acc: 0.350604. Batch_loss: 1.821328 \n",
      "Batch: 3235. Acc: 0.345936. Loss: 1.863813. Batch_acc: 0.386750. Batch_loss: 1.741698 \n",
      "Batch: 3236. Acc: 0.345939. Loss: 1.863794. Batch_acc: 0.353784. Batch_loss: 1.803537 \n",
      "Batch: 3237. Acc: 0.345940. Loss: 1.863780. Batch_acc: 0.351101. Batch_loss: 1.815764 \n",
      "Batch: 3238. Acc: 0.345943. Loss: 1.863767. Batch_acc: 0.353145. Batch_loss: 1.823243 \n",
      "Batch: 3239. Acc: 0.345946. Loss: 1.863748. Batch_acc: 0.355846. Batch_loss: 1.803769 \n",
      "Batch: 3240. Acc: 0.345953. Loss: 1.863721. Batch_acc: 0.370497. Batch_loss: 1.776910 \n",
      "Batch: 3241. Acc: 0.345957. Loss: 1.863702. Batch_acc: 0.358405. Batch_loss: 1.801410 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3242. Acc: 0.345963. Loss: 1.863679. Batch_acc: 0.362375. Batch_loss: 1.792999 \n",
      "Batch: 3243. Acc: 0.345977. Loss: 1.863648. Batch_acc: 0.392545. Batch_loss: 1.760575 \n",
      "Batch: 3244. Acc: 0.345988. Loss: 1.863629. Batch_acc: 0.381808. Batch_loss: 1.802964 \n",
      "Batch: 3245. Acc: 0.345997. Loss: 1.863595. Batch_acc: 0.375854. Batch_loss: 1.754453 \n",
      "Batch: 3246. Acc: 0.346006. Loss: 1.863572. Batch_acc: 0.373784. Batch_loss: 1.787290 \n",
      "Batch: 3247. Acc: 0.346010. Loss: 1.863555. Batch_acc: 0.360704. Batch_loss: 1.809690 \n",
      "Batch: 3248. Acc: 0.346009. Loss: 1.863544. Batch_acc: 0.342294. Batch_loss: 1.825137 \n",
      "Batch: 3249. Acc: 0.346018. Loss: 1.863521. Batch_acc: 0.375843. Batch_loss: 1.789998 \n",
      "Batch: 3250. Acc: 0.346025. Loss: 1.863497. Batch_acc: 0.366743. Batch_loss: 1.786542 \n",
      "Batch: 3251. Acc: 0.346034. Loss: 1.863474. Batch_acc: 0.375435. Batch_loss: 1.786991 \n",
      "Batch: 3252. Acc: 0.346040. Loss: 1.863454. Batch_acc: 0.365450. Batch_loss: 1.800556 \n",
      "Batch: 3253. Acc: 0.346048. Loss: 1.863439. Batch_acc: 0.372998. Batch_loss: 1.814497 \n",
      "Batch: 3254. Acc: 0.346052. Loss: 1.863417. Batch_acc: 0.357627. Batch_loss: 1.793700 \n",
      "Batch: 3255. Acc: 0.346066. Loss: 1.863381. Batch_acc: 0.389567. Batch_loss: 1.748663 \n",
      "Batch: 3256. Acc: 0.346067. Loss: 1.863363. Batch_acc: 0.352338. Batch_loss: 1.807036 \n",
      "Batch: 3257. Acc: 0.346071. Loss: 1.863353. Batch_acc: 0.357184. Batch_loss: 1.830381 \n",
      "Batch: 3258. Acc: 0.346078. Loss: 1.863332. Batch_acc: 0.370306. Batch_loss: 1.795589 \n",
      "Batch: 3259. Acc: 0.346082. Loss: 1.863313. Batch_acc: 0.359285. Batch_loss: 1.801073 \n",
      "Batch: 3260. Acc: 0.346088. Loss: 1.863303. Batch_acc: 0.364359. Batch_loss: 1.830045 \n",
      "Batch: 3261. Acc: 0.346097. Loss: 1.863281. Batch_acc: 0.375501. Batch_loss: 1.790899 \n",
      "Batch: 3262. Acc: 0.346102. Loss: 1.863267. Batch_acc: 0.362785. Batch_loss: 1.818553 \n",
      "Batch: 3263. Acc: 0.346107. Loss: 1.863242. Batch_acc: 0.362857. Batch_loss: 1.782149 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.34610727175667955. Loss per char: 1.8632422021274464. Time: 1627209039.5421216\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 19, 24, 26, 21, 18, 25,  1, 14,  1,\n",
      "        18, 15, 20, 21, 26, 25, 23, 18, 22, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.346112. Loss: 1.863223. Batch_acc: 0.360277. Batch_loss: 1.800329 \n",
      "Batch: 3265. Acc: 0.346122. Loss: 1.863203. Batch_acc: 0.377790. Batch_loss: 1.798935 \n",
      "Batch: 3266. Acc: 0.346131. Loss: 1.863176. Batch_acc: 0.376289. Batch_loss: 1.777906 \n",
      "Batch: 3267. Acc: 0.346137. Loss: 1.863158. Batch_acc: 0.366647. Batch_loss: 1.801686 \n",
      "Batch: 3268. Acc: 0.346142. Loss: 1.863137. Batch_acc: 0.361192. Batch_loss: 1.793652 \n",
      "Batch: 3269. Acc: 0.346151. Loss: 1.863102. Batch_acc: 0.377867. Batch_loss: 1.749534 \n",
      "Batch: 3270. Acc: 0.346160. Loss: 1.863068. Batch_acc: 0.372872. Batch_loss: 1.751696 \n",
      "Batch: 3271. Acc: 0.346171. Loss: 1.863029. Batch_acc: 0.383734. Batch_loss: 1.736272 \n",
      "Batch: 3272. Acc: 0.346175. Loss: 1.863009. Batch_acc: 0.358261. Batch_loss: 1.798200 \n",
      "Batch: 3273. Acc: 0.346185. Loss: 1.862977. Batch_acc: 0.379988. Batch_loss: 1.758279 \n",
      "Batch: 3274. Acc: 0.346191. Loss: 1.862960. Batch_acc: 0.366648. Batch_loss: 1.807849 \n",
      "Batch: 3275. Acc: 0.346203. Loss: 1.862934. Batch_acc: 0.385632. Batch_loss: 1.777821 \n",
      "Batch: 3276. Acc: 0.346209. Loss: 1.862905. Batch_acc: 0.363377. Batch_loss: 1.767971 \n",
      "Batch: 3277. Acc: 0.346217. Loss: 1.862893. Batch_acc: 0.373892. Batch_loss: 1.822295 \n",
      "Batch: 3278. Acc: 0.346225. Loss: 1.862876. Batch_acc: 0.372315. Batch_loss: 1.804099 \n",
      "Batch: 3279. Acc: 0.346228. Loss: 1.862859. Batch_acc: 0.359035. Batch_loss: 1.806983 \n",
      "Batch: 3280. Acc: 0.346233. Loss: 1.862828. Batch_acc: 0.360544. Batch_loss: 1.763113 \n",
      "Batch: 3281. Acc: 0.346238. Loss: 1.862808. Batch_acc: 0.361775. Batch_loss: 1.798299 \n",
      "Batch: 3282. Acc: 0.346241. Loss: 1.862797. Batch_acc: 0.357224. Batch_loss: 1.826151 \n",
      "Batch: 3283. Acc: 0.346243. Loss: 1.862788. Batch_acc: 0.353145. Batch_loss: 1.833408 \n",
      "Batch: 3284. Acc: 0.346250. Loss: 1.862767. Batch_acc: 0.370349. Batch_loss: 1.792814 \n",
      "Batch: 3285. Acc: 0.346253. Loss: 1.862765. Batch_acc: 0.355425. Batch_loss: 1.857303 \n",
      "Batch: 3286. Acc: 0.346257. Loss: 1.862759. Batch_acc: 0.358696. Batch_loss: 1.839986 \n",
      "Batch: 3287. Acc: 0.346265. Loss: 1.862737. Batch_acc: 0.372449. Batch_loss: 1.793046 \n",
      "Batch: 3288. Acc: 0.346269. Loss: 1.862715. Batch_acc: 0.360023. Batch_loss: 1.788901 \n",
      "Batch: 3289. Acc: 0.346282. Loss: 1.862680. Batch_acc: 0.389551. Batch_loss: 1.748323 \n",
      "Batch: 3290. Acc: 0.346290. Loss: 1.862659. Batch_acc: 0.373672. Batch_loss: 1.791879 \n",
      "Batch: 3291. Acc: 0.346297. Loss: 1.862634. Batch_acc: 0.367209. Batch_loss: 1.782453 \n",
      "Batch: 3292. Acc: 0.346301. Loss: 1.862616. Batch_acc: 0.358469. Batch_loss: 1.801381 \n",
      "Batch: 3293. Acc: 0.346307. Loss: 1.862588. Batch_acc: 0.366764. Batch_loss: 1.770522 \n",
      "Batch: 3294. Acc: 0.346314. Loss: 1.862567. Batch_acc: 0.370029. Batch_loss: 1.793663 \n",
      "Batch: 3295. Acc: 0.346324. Loss: 1.862530. Batch_acc: 0.378332. Batch_loss: 1.741930 \n",
      "Batch: 3296. Acc: 0.346327. Loss: 1.862513. Batch_acc: 0.357184. Batch_loss: 1.806291 \n",
      "Batch: 3297. Acc: 0.346333. Loss: 1.862490. Batch_acc: 0.364849. Batch_loss: 1.785550 \n",
      "Batch: 3298. Acc: 0.346337. Loss: 1.862470. Batch_acc: 0.359492. Batch_loss: 1.795795 \n",
      "Batch: 3299. Acc: 0.346341. Loss: 1.862453. Batch_acc: 0.361257. Batch_loss: 1.806336 \n",
      "Batch: 3300. Acc: 0.346344. Loss: 1.862441. Batch_acc: 0.356172. Batch_loss: 1.821084 \n",
      "Batch: 3301. Acc: 0.346352. Loss: 1.862411. Batch_acc: 0.371824. Batch_loss: 1.763927 \n",
      "Batch: 3302. Acc: 0.346364. Loss: 1.862384. Batch_acc: 0.385177. Batch_loss: 1.775585 \n",
      "Batch: 3303. Acc: 0.346368. Loss: 1.862367. Batch_acc: 0.361305. Batch_loss: 1.803961 \n",
      "Batch: 3304. Acc: 0.346372. Loss: 1.862344. Batch_acc: 0.358652. Batch_loss: 1.789680 \n",
      "Batch: 3305. Acc: 0.346373. Loss: 1.862327. Batch_acc: 0.350398. Batch_loss: 1.803868 \n",
      "Batch: 3306. Acc: 0.346380. Loss: 1.862301. Batch_acc: 0.368987. Batch_loss: 1.778195 \n",
      "Batch: 3307. Acc: 0.346389. Loss: 1.862274. Batch_acc: 0.378077. Batch_loss: 1.773098 \n",
      "Batch: 3308. Acc: 0.346400. Loss: 1.862250. Batch_acc: 0.379484. Batch_loss: 1.782529 \n",
      "Batch: 3309. Acc: 0.346404. Loss: 1.862223. Batch_acc: 0.361048. Batch_loss: 1.774668 \n",
      "Batch: 3310. Acc: 0.346412. Loss: 1.862197. Batch_acc: 0.371461. Batch_loss: 1.778943 \n",
      "Batch: 3311. Acc: 0.346419. Loss: 1.862156. Batch_acc: 0.368778. Batch_loss: 1.728159 \n",
      "Batch: 3312. Acc: 0.346422. Loss: 1.862135. Batch_acc: 0.358708. Batch_loss: 1.790465 \n",
      "Batch: 3313. Acc: 0.346428. Loss: 1.862112. Batch_acc: 0.365711. Batch_loss: 1.786715 \n",
      "Batch: 3314. Acc: 0.346433. Loss: 1.862087. Batch_acc: 0.361001. Batch_loss: 1.780806 \n",
      "Batch: 3315. Acc: 0.346432. Loss: 1.862079. Batch_acc: 0.345402. Batch_loss: 1.835742 \n",
      "Batch: 3316. Acc: 0.346445. Loss: 1.862042. Batch_acc: 0.386172. Batch_loss: 1.741507 \n",
      "Batch: 3317. Acc: 0.346454. Loss: 1.862017. Batch_acc: 0.378347. Batch_loss: 1.776301 \n",
      "Batch: 3318. Acc: 0.346455. Loss: 1.862008. Batch_acc: 0.349537. Batch_loss: 1.834895 \n",
      "Batch: 3319. Acc: 0.346455. Loss: 1.861993. Batch_acc: 0.346221. Batch_loss: 1.809317 \n",
      "Batch: 3320. Acc: 0.346467. Loss: 1.861967. Batch_acc: 0.386667. Batch_loss: 1.775386 \n",
      "Batch: 3321. Acc: 0.346474. Loss: 1.861950. Batch_acc: 0.369490. Batch_loss: 1.804369 \n",
      "Batch: 3322. Acc: 0.346478. Loss: 1.861942. Batch_acc: 0.361208. Batch_loss: 1.834900 \n",
      "Batch: 3323. Acc: 0.346480. Loss: 1.861930. Batch_acc: 0.351064. Batch_loss: 1.823976 \n",
      "Batch: 3324. Acc: 0.346489. Loss: 1.861909. Batch_acc: 0.377443. Batch_loss: 1.794987 \n",
      "Batch: 3325. Acc: 0.346498. Loss: 1.861879. Batch_acc: 0.374138. Batch_loss: 1.760370 \n",
      "Batch: 3326. Acc: 0.346506. Loss: 1.861864. Batch_acc: 0.373837. Batch_loss: 1.813889 \n",
      "Batch: 3327. Acc: 0.346509. Loss: 1.861841. Batch_acc: 0.358174. Batch_loss: 1.783386 \n",
      "Batch: 3328. Acc: 0.346517. Loss: 1.861821. Batch_acc: 0.374205. Batch_loss: 1.794724 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3329. Acc: 0.346518. Loss: 1.861808. Batch_acc: 0.347497. Batch_loss: 1.816771 \n",
      "Batch: 3330. Acc: 0.346525. Loss: 1.861778. Batch_acc: 0.371278. Batch_loss: 1.762250 \n",
      "Batch: 3331. Acc: 0.346525. Loss: 1.861770. Batch_acc: 0.346903. Batch_loss: 1.833100 \n",
      "Batch: 3332. Acc: 0.346535. Loss: 1.861737. Batch_acc: 0.378563. Batch_loss: 1.752634 \n",
      "Batch: 3333. Acc: 0.346540. Loss: 1.861711. Batch_acc: 0.363167. Batch_loss: 1.775101 \n",
      "Batch: 3334. Acc: 0.346544. Loss: 1.861687. Batch_acc: 0.361144. Batch_loss: 1.781359 \n",
      "Batch: 3335. Acc: 0.346557. Loss: 1.861656. Batch_acc: 0.388289. Batch_loss: 1.758382 \n",
      "Batch: 3336. Acc: 0.346559. Loss: 1.861653. Batch_acc: 0.353114. Batch_loss: 1.854045 \n",
      "Batch: 3337. Acc: 0.346560. Loss: 1.861641. Batch_acc: 0.350551. Batch_loss: 1.820379 \n",
      "Batch: 3338. Acc: 0.346562. Loss: 1.861629. Batch_acc: 0.354349. Batch_loss: 1.820751 \n",
      "Batch: 3339. Acc: 0.346567. Loss: 1.861621. Batch_acc: 0.360674. Batch_loss: 1.836917 \n",
      "Batch: 3340. Acc: 0.346568. Loss: 1.861616. Batch_acc: 0.352032. Batch_loss: 1.842208 \n",
      "Batch: 3341. Acc: 0.346574. Loss: 1.861591. Batch_acc: 0.364780. Batch_loss: 1.778619 \n",
      "Batch: 3342. Acc: 0.346578. Loss: 1.861581. Batch_acc: 0.361812. Batch_loss: 1.830339 \n",
      "Batch: 3343. Acc: 0.346584. Loss: 1.861570. Batch_acc: 0.365965. Batch_loss: 1.823447 \n",
      "Batch: 3344. Acc: 0.346586. Loss: 1.861562. Batch_acc: 0.353182. Batch_loss: 1.835170 \n",
      "Batch: 3345. Acc: 0.346595. Loss: 1.861538. Batch_acc: 0.376571. Batch_loss: 1.781296 \n",
      "Batch: 3346. Acc: 0.346597. Loss: 1.861531. Batch_acc: 0.351977. Batch_loss: 1.840646 \n",
      "Batch: 3347. Acc: 0.346603. Loss: 1.861514. Batch_acc: 0.368091. Batch_loss: 1.804603 \n",
      "Batch: 3348. Acc: 0.346610. Loss: 1.861488. Batch_acc: 0.370307. Batch_loss: 1.775674 \n",
      "Batch: 3349. Acc: 0.346612. Loss: 1.861485. Batch_acc: 0.351464. Batch_loss: 1.848743 \n",
      "Batch: 3350. Acc: 0.346615. Loss: 1.861473. Batch_acc: 0.359184. Batch_loss: 1.823483 \n",
      "Batch: 3351. Acc: 0.346621. Loss: 1.861451. Batch_acc: 0.364277. Batch_loss: 1.784388 \n",
      "Batch: 3352. Acc: 0.346632. Loss: 1.861424. Batch_acc: 0.385945. Batch_loss: 1.772164 \n",
      "Batch: 3353. Acc: 0.346646. Loss: 1.861381. Batch_acc: 0.393764. Batch_loss: 1.713947 \n",
      "Batch: 3354. Acc: 0.346657. Loss: 1.861350. Batch_acc: 0.381351. Batch_loss: 1.761649 \n",
      "Batch: 3355. Acc: 0.346665. Loss: 1.861330. Batch_acc: 0.373030. Batch_loss: 1.794454 \n",
      "Batch: 3356. Acc: 0.346674. Loss: 1.861310. Batch_acc: 0.377183. Batch_loss: 1.794150 \n",
      "Batch: 3357. Acc: 0.346678. Loss: 1.861299. Batch_acc: 0.361257. Batch_loss: 1.821267 \n",
      "Batch: 3358. Acc: 0.346684. Loss: 1.861279. Batch_acc: 0.367381. Batch_loss: 1.797740 \n",
      "Batch: 3359. Acc: 0.346696. Loss: 1.861243. Batch_acc: 0.386076. Batch_loss: 1.737412 \n",
      "Batch: 3360. Acc: 0.346697. Loss: 1.861231. Batch_acc: 0.348476. Batch_loss: 1.823765 \n",
      "Batch: 3361. Acc: 0.346698. Loss: 1.861228. Batch_acc: 0.350558. Batch_loss: 1.851217 \n",
      "Batch: 3362. Acc: 0.346705. Loss: 1.861210. Batch_acc: 0.373310. Batch_loss: 1.796357 \n",
      "Batch: 3363. Acc: 0.346707. Loss: 1.861195. Batch_acc: 0.352598. Batch_loss: 1.810448 \n",
      "Batch: 3364. Acc: 0.346715. Loss: 1.861169. Batch_acc: 0.374016. Batch_loss: 1.775147 \n",
      "Batch: 3365. Acc: 0.346723. Loss: 1.861145. Batch_acc: 0.371984. Batch_loss: 1.779012 \n",
      "Batch: 3366. Acc: 0.346724. Loss: 1.861134. Batch_acc: 0.351383. Batch_loss: 1.823720 \n",
      "Batch: 3367. Acc: 0.346728. Loss: 1.861122. Batch_acc: 0.358372. Batch_loss: 1.821298 \n",
      "Batch: 3368. Acc: 0.346735. Loss: 1.861096. Batch_acc: 0.371445. Batch_loss: 1.774122 \n",
      "Batch: 3369. Acc: 0.346743. Loss: 1.861078. Batch_acc: 0.372832. Batch_loss: 1.800020 \n",
      "Batch: 3370. Acc: 0.346748. Loss: 1.861056. Batch_acc: 0.365826. Batch_loss: 1.787962 \n",
      "Batch: 3371. Acc: 0.346754. Loss: 1.861035. Batch_acc: 0.365573. Batch_loss: 1.788857 \n",
      "Batch: 3372. Acc: 0.346762. Loss: 1.861014. Batch_acc: 0.373928. Batch_loss: 1.793179 \n",
      "Batch: 3373. Acc: 0.346768. Loss: 1.860996. Batch_acc: 0.367914. Batch_loss: 1.799034 \n",
      "Batch: 3374. Acc: 0.346779. Loss: 1.860969. Batch_acc: 0.381679. Batch_loss: 1.767176 \n",
      "Batch: 3375. Acc: 0.346789. Loss: 1.860941. Batch_acc: 0.381473. Batch_loss: 1.768363 \n",
      "Batch: 3376. Acc: 0.346801. Loss: 1.860905. Batch_acc: 0.389603. Batch_loss: 1.735770 \n",
      "Batch: 3377. Acc: 0.346812. Loss: 1.860877. Batch_acc: 0.381246. Batch_loss: 1.770059 \n",
      "Batch: 3378. Acc: 0.346817. Loss: 1.860861. Batch_acc: 0.366009. Batch_loss: 1.806037 \n",
      "Batch: 3379. Acc: 0.346821. Loss: 1.860849. Batch_acc: 0.358286. Batch_loss: 1.820768 \n",
      "Batch: 3380. Acc: 0.346831. Loss: 1.860828. Batch_acc: 0.380615. Batch_loss: 1.786606 \n",
      "Batch: 3381. Acc: 0.346839. Loss: 1.860806. Batch_acc: 0.374638. Batch_loss: 1.787840 \n",
      "Batch: 3382. Acc: 0.346844. Loss: 1.860780. Batch_acc: 0.363737. Batch_loss: 1.774933 \n",
      "Batch: 3383. Acc: 0.346850. Loss: 1.860750. Batch_acc: 0.366571. Batch_loss: 1.758089 \n",
      "Batch: 3384. Acc: 0.346854. Loss: 1.860738. Batch_acc: 0.360162. Batch_loss: 1.820615 \n",
      "Batch: 3385. Acc: 0.346855. Loss: 1.860731. Batch_acc: 0.353007. Batch_loss: 1.837297 \n",
      "Batch: 3386. Acc: 0.346868. Loss: 1.860692. Batch_acc: 0.389391. Batch_loss: 1.731087 \n",
      "Batch: 3387. Acc: 0.346872. Loss: 1.860679. Batch_acc: 0.359931. Batch_loss: 1.815970 \n",
      "Batch: 3388. Acc: 0.346879. Loss: 1.860653. Batch_acc: 0.369128. Batch_loss: 1.776822 \n",
      "Batch: 3389. Acc: 0.346889. Loss: 1.860622. Batch_acc: 0.379528. Batch_loss: 1.756722 \n",
      "Batch: 3390. Acc: 0.346885. Loss: 1.860619. Batch_acc: 0.333333. Batch_loss: 1.849779 \n",
      "Batch: 3391. Acc: 0.346888. Loss: 1.860609. Batch_acc: 0.360190. Batch_loss: 1.826485 \n",
      "Batch: 3392. Acc: 0.346893. Loss: 1.860583. Batch_acc: 0.363998. Batch_loss: 1.771590 \n",
      "Batch: 3393. Acc: 0.346897. Loss: 1.860570. Batch_acc: 0.359842. Batch_loss: 1.817362 \n",
      "Batch: 3394. Acc: 0.346901. Loss: 1.860552. Batch_acc: 0.357778. Batch_loss: 1.800965 \n",
      "Batch: 3395. Acc: 0.346911. Loss: 1.860512. Batch_acc: 0.381143. Batch_loss: 1.727915 \n",
      "Batch: 3396. Acc: 0.346913. Loss: 1.860502. Batch_acc: 0.353919. Batch_loss: 1.823691 \n",
      "Batch: 3397. Acc: 0.346909. Loss: 1.860505. Batch_acc: 0.332941. Batch_loss: 1.872621 \n",
      "Batch: 3398. Acc: 0.346912. Loss: 1.860497. Batch_acc: 0.359005. Batch_loss: 1.831440 \n",
      "Batch: 3399. Acc: 0.346921. Loss: 1.860470. Batch_acc: 0.377574. Batch_loss: 1.767900 \n",
      "Batch: 3400. Acc: 0.346925. Loss: 1.860448. Batch_acc: 0.360252. Batch_loss: 1.786830 \n",
      "Batch: 3401. Acc: 0.346930. Loss: 1.860424. Batch_acc: 0.364009. Batch_loss: 1.777556 \n",
      "Batch: 3402. Acc: 0.346936. Loss: 1.860404. Batch_acc: 0.366686. Batch_loss: 1.792149 \n",
      "Batch: 3403. Acc: 0.346943. Loss: 1.860385. Batch_acc: 0.370006. Batch_loss: 1.796164 \n",
      "Batch: 3404. Acc: 0.346949. Loss: 1.860359. Batch_acc: 0.369318. Batch_loss: 1.772668 \n",
      "Batch: 3405. Acc: 0.346953. Loss: 1.860341. Batch_acc: 0.360837. Batch_loss: 1.797780 \n",
      "Batch: 3406. Acc: 0.346957. Loss: 1.860334. Batch_acc: 0.359976. Batch_loss: 1.834157 \n",
      "Batch: 3407. Acc: 0.346968. Loss: 1.860299. Batch_acc: 0.382614. Batch_loss: 1.745314 \n",
      "Batch: 3408. Acc: 0.346969. Loss: 1.860297. Batch_acc: 0.351590. Batch_loss: 1.856541 \n",
      "Batch: 3409. Acc: 0.346980. Loss: 1.860265. Batch_acc: 0.384309. Batch_loss: 1.749365 \n",
      "Batch: 3410. Acc: 0.346987. Loss: 1.860242. Batch_acc: 0.368627. Batch_loss: 1.784537 \n",
      "Batch: 3411. Acc: 0.346991. Loss: 1.860223. Batch_acc: 0.359742. Batch_loss: 1.793635 \n",
      "Batch: 3412. Acc: 0.346998. Loss: 1.860188. Batch_acc: 0.373151. Batch_loss: 1.743816 \n",
      "Batch: 3413. Acc: 0.347005. Loss: 1.860165. Batch_acc: 0.370141. Batch_loss: 1.783759 \n",
      "Batch: 3414. Acc: 0.347013. Loss: 1.860154. Batch_acc: 0.373778. Batch_loss: 1.821153 \n",
      "Batch: 3415. Acc: 0.347021. Loss: 1.860129. Batch_acc: 0.373853. Batch_loss: 1.776873 \n",
      "Batch: 3416. Acc: 0.347025. Loss: 1.860114. Batch_acc: 0.359840. Batch_loss: 1.808989 \n",
      "Batch: 3417. Acc: 0.347033. Loss: 1.860088. Batch_acc: 0.374016. Batch_loss: 1.772084 \n",
      "Batch: 3418. Acc: 0.347040. Loss: 1.860068. Batch_acc: 0.371707. Batch_loss: 1.793336 \n",
      "Batch: 3419. Acc: 0.347042. Loss: 1.860060. Batch_acc: 0.353392. Batch_loss: 1.832037 \n",
      "Batch: 3420. Acc: 0.347051. Loss: 1.860030. Batch_acc: 0.378745. Batch_loss: 1.758859 \n",
      "Batch: 3421. Acc: 0.347055. Loss: 1.860004. Batch_acc: 0.358757. Batch_loss: 1.772474 \n",
      "Batch: 3422. Acc: 0.347059. Loss: 1.859989. Batch_acc: 0.361418. Batch_loss: 1.807164 \n",
      "Batch: 3423. Acc: 0.347072. Loss: 1.859963. Batch_acc: 0.391633. Batch_loss: 1.771938 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3424. Acc: 0.347078. Loss: 1.859944. Batch_acc: 0.367074. Batch_loss: 1.793361 \n",
      "Batch: 3425. Acc: 0.347079. Loss: 1.859922. Batch_acc: 0.351336. Batch_loss: 1.782011 \n",
      "Batch: 3426. Acc: 0.347090. Loss: 1.859892. Batch_acc: 0.382931. Batch_loss: 1.761550 \n",
      "Batch: 3427. Acc: 0.347106. Loss: 1.859849. Batch_acc: 0.403539. Batch_loss: 1.714079 \n",
      "Batch: 3428. Acc: 0.347106. Loss: 1.859830. Batch_acc: 0.345475. Batch_loss: 1.792769 \n",
      "Batch: 3429. Acc: 0.347110. Loss: 1.859804. Batch_acc: 0.360386. Batch_loss: 1.772839 \n",
      "Batch: 3430. Acc: 0.347114. Loss: 1.859799. Batch_acc: 0.362600. Batch_loss: 1.843103 \n",
      "Batch: 3431. Acc: 0.347121. Loss: 1.859778. Batch_acc: 0.370134. Batch_loss: 1.787028 \n",
      "Batch: 3432. Acc: 0.347127. Loss: 1.859753. Batch_acc: 0.368095. Batch_loss: 1.773913 \n",
      "Batch: 3433. Acc: 0.347130. Loss: 1.859739. Batch_acc: 0.357809. Batch_loss: 1.814209 \n",
      "Batch: 3434. Acc: 0.347140. Loss: 1.859719. Batch_acc: 0.380114. Batch_loss: 1.789348 \n",
      "Batch: 3435. Acc: 0.347141. Loss: 1.859713. Batch_acc: 0.351429. Batch_loss: 1.840935 \n",
      "Batch: 3436. Acc: 0.347149. Loss: 1.859687. Batch_acc: 0.375000. Batch_loss: 1.769713 \n",
      "Batch: 3437. Acc: 0.347153. Loss: 1.859678. Batch_acc: 0.358491. Batch_loss: 1.829953 \n",
      "Batch: 3438. Acc: 0.347162. Loss: 1.859654. Batch_acc: 0.378691. Batch_loss: 1.776842 \n",
      "Batch: 3439. Acc: 0.347171. Loss: 1.859628. Batch_acc: 0.380787. Batch_loss: 1.770802 \n",
      "Batch: 3440. Acc: 0.347170. Loss: 1.859625. Batch_acc: 0.340896. Batch_loss: 1.847826 \n",
      "Batch: 3441. Acc: 0.347174. Loss: 1.859602. Batch_acc: 0.360902. Batch_loss: 1.780322 \n",
      "Batch: 3442. Acc: 0.347181. Loss: 1.859575. Batch_acc: 0.371348. Batch_loss: 1.769558 \n",
      "Batch: 3443. Acc: 0.347182. Loss: 1.859558. Batch_acc: 0.349825. Batch_loss: 1.800297 \n",
      "Batch: 3444. Acc: 0.347190. Loss: 1.859535. Batch_acc: 0.374713. Batch_loss: 1.780846 \n",
      "Batch: 3445. Acc: 0.347203. Loss: 1.859505. Batch_acc: 0.392857. Batch_loss: 1.760958 \n",
      "Batch: 3446. Acc: 0.347211. Loss: 1.859493. Batch_acc: 0.372187. Batch_loss: 1.816272 \n",
      "Batch: 3447. Acc: 0.347216. Loss: 1.859463. Batch_acc: 0.366421. Batch_loss: 1.756888 \n",
      "Batch: 3448. Acc: 0.347224. Loss: 1.859442. Batch_acc: 0.375584. Batch_loss: 1.788276 \n",
      "Batch: 3449. Acc: 0.347230. Loss: 1.859436. Batch_acc: 0.367621. Batch_loss: 1.837043 \n",
      "Batch: 3450. Acc: 0.347238. Loss: 1.859419. Batch_acc: 0.375437. Batch_loss: 1.799841 \n",
      "Batch: 3451. Acc: 0.347246. Loss: 1.859399. Batch_acc: 0.373772. Batch_loss: 1.790464 \n",
      "Batch: 3452. Acc: 0.347248. Loss: 1.859380. Batch_acc: 0.353270. Batch_loss: 1.796412 \n",
      "Batch: 3453. Acc: 0.347258. Loss: 1.859340. Batch_acc: 0.381960. Batch_loss: 1.724287 \n",
      "Batch: 3454. Acc: 0.347265. Loss: 1.859317. Batch_acc: 0.370307. Batch_loss: 1.781045 \n",
      "Batch: 3455. Acc: 0.347266. Loss: 1.859314. Batch_acc: 0.352121. Batch_loss: 1.850685 \n",
      "Batch: 3456. Acc: 0.347271. Loss: 1.859296. Batch_acc: 0.365098. Batch_loss: 1.797059 \n",
      "Batch: 3457. Acc: 0.347274. Loss: 1.859279. Batch_acc: 0.355644. Batch_loss: 1.798798 \n",
      "Batch: 3458. Acc: 0.347281. Loss: 1.859266. Batch_acc: 0.370940. Batch_loss: 1.814421 \n",
      "Batch: 3459. Acc: 0.347284. Loss: 1.859243. Batch_acc: 0.359557. Batch_loss: 1.781903 \n",
      "Batch: 3460. Acc: 0.347294. Loss: 1.859220. Batch_acc: 0.379014. Batch_loss: 1.779929 \n",
      "Batch: 3461. Acc: 0.347299. Loss: 1.859198. Batch_acc: 0.365797. Batch_loss: 1.782227 \n",
      "Batch: 3462. Acc: 0.347305. Loss: 1.859172. Batch_acc: 0.368718. Batch_loss: 1.769167 \n",
      "Batch: 3463. Acc: 0.347309. Loss: 1.859156. Batch_acc: 0.362200. Batch_loss: 1.804009 \n",
      "Batch: 3464. Acc: 0.347314. Loss: 1.859143. Batch_acc: 0.363688. Batch_loss: 1.812718 \n",
      "Batch: 3465. Acc: 0.347323. Loss: 1.859118. Batch_acc: 0.378592. Batch_loss: 1.775583 \n",
      "Batch: 3466. Acc: 0.347330. Loss: 1.859096. Batch_acc: 0.370092. Batch_loss: 1.782956 \n",
      "Batch: 3467. Acc: 0.347333. Loss: 1.859082. Batch_acc: 0.357988. Batch_loss: 1.806921 \n",
      "Batch: 3468. Acc: 0.347338. Loss: 1.859065. Batch_acc: 0.364817. Batch_loss: 1.800209 \n",
      "Batch: 3469. Acc: 0.347342. Loss: 1.859054. Batch_acc: 0.362899. Batch_loss: 1.820289 \n",
      "Batch: 3470. Acc: 0.347352. Loss: 1.859032. Batch_acc: 0.380257. Batch_loss: 1.782014 \n",
      "Batch: 3471. Acc: 0.347357. Loss: 1.859010. Batch_acc: 0.367052. Batch_loss: 1.782838 \n",
      "Batch: 3472. Acc: 0.347365. Loss: 1.858991. Batch_acc: 0.374786. Batch_loss: 1.791907 \n",
      "Batch: 3473. Acc: 0.347374. Loss: 1.858966. Batch_acc: 0.378410. Batch_loss: 1.773283 \n",
      "Batch: 3474. Acc: 0.347380. Loss: 1.858947. Batch_acc: 0.368782. Batch_loss: 1.791844 \n",
      "Batch: 3475. Acc: 0.347383. Loss: 1.858933. Batch_acc: 0.358534. Batch_loss: 1.810183 \n",
      "Batch: 3476. Acc: 0.347390. Loss: 1.858918. Batch_acc: 0.370088. Batch_loss: 1.807799 \n",
      "Batch: 3477. Acc: 0.347393. Loss: 1.858903. Batch_acc: 0.356655. Batch_loss: 1.804850 \n",
      "Batch: 3478. Acc: 0.347399. Loss: 1.858877. Batch_acc: 0.371134. Batch_loss: 1.771709 \n",
      "Batch: 3479. Acc: 0.347405. Loss: 1.858860. Batch_acc: 0.366066. Batch_loss: 1.797415 \n",
      "Batch: 3480. Acc: 0.347404. Loss: 1.858848. Batch_acc: 0.345955. Batch_loss: 1.817367 \n",
      "Batch: 3481. Acc: 0.347418. Loss: 1.858813. Batch_acc: 0.393728. Batch_loss: 1.735288 \n",
      "Batch: 3482. Acc: 0.347424. Loss: 1.858794. Batch_acc: 0.371169. Batch_loss: 1.792917 \n",
      "Batch: 3483. Acc: 0.347426. Loss: 1.858783. Batch_acc: 0.353936. Batch_loss: 1.820360 \n",
      "Batch: 3484. Acc: 0.347430. Loss: 1.858760. Batch_acc: 0.359251. Batch_loss: 1.781992 \n",
      "Batch: 3485. Acc: 0.347439. Loss: 1.858737. Batch_acc: 0.380672. Batch_loss: 1.775980 \n",
      "Batch: 3486. Acc: 0.347448. Loss: 1.858715. Batch_acc: 0.377980. Batch_loss: 1.782277 \n",
      "Batch: 3487. Acc: 0.347457. Loss: 1.858686. Batch_acc: 0.378917. Batch_loss: 1.757078 \n",
      "Batch: 3488. Acc: 0.347463. Loss: 1.858669. Batch_acc: 0.366572. Batch_loss: 1.801806 \n",
      "Batch: 3489. Acc: 0.347470. Loss: 1.858651. Batch_acc: 0.373563. Batch_loss: 1.797256 \n",
      "Batch: 3490. Acc: 0.347474. Loss: 1.858627. Batch_acc: 0.360319. Batch_loss: 1.774593 \n",
      "Batch: 3491. Acc: 0.347482. Loss: 1.858600. Batch_acc: 0.375353. Batch_loss: 1.766118 \n",
      "Batch: 3492. Acc: 0.347493. Loss: 1.858571. Batch_acc: 0.383878. Batch_loss: 1.757689 \n",
      "Batch: 3493. Acc: 0.347501. Loss: 1.858554. Batch_acc: 0.378674. Batch_loss: 1.798879 \n",
      "Batch: 3494. Acc: 0.347504. Loss: 1.858534. Batch_acc: 0.356899. Batch_loss: 1.791752 \n",
      "Batch: 3495. Acc: 0.347510. Loss: 1.858513. Batch_acc: 0.366743. Batch_loss: 1.786167 \n",
      "Batch: 3496. Acc: 0.347516. Loss: 1.858483. Batch_acc: 0.368302. Batch_loss: 1.754314 \n",
      "Batch: 3497. Acc: 0.347524. Loss: 1.858456. Batch_acc: 0.376035. Batch_loss: 1.769098 \n",
      "Batch: 3498. Acc: 0.347527. Loss: 1.858443. Batch_acc: 0.358295. Batch_loss: 1.810294 \n",
      "Batch: 3499. Acc: 0.347530. Loss: 1.858420. Batch_acc: 0.356813. Batch_loss: 1.778538 \n",
      "Batch: 3500. Acc: 0.347533. Loss: 1.858406. Batch_acc: 0.359700. Batch_loss: 1.808585 \n",
      "Batch: 3501. Acc: 0.347545. Loss: 1.858375. Batch_acc: 0.388235. Batch_loss: 1.751761 \n",
      "Batch: 3502. Acc: 0.347549. Loss: 1.858356. Batch_acc: 0.361127. Batch_loss: 1.793473 \n",
      "Batch: 3503. Acc: 0.347559. Loss: 1.858328. Batch_acc: 0.383102. Batch_loss: 1.759388 \n",
      "Batch: 3504. Acc: 0.347570. Loss: 1.858303. Batch_acc: 0.383390. Batch_loss: 1.769641 \n",
      "Batch: 3505. Acc: 0.347578. Loss: 1.858276. Batch_acc: 0.376277. Batch_loss: 1.767159 \n",
      "Batch: 3506. Acc: 0.347583. Loss: 1.858255. Batch_acc: 0.365967. Batch_loss: 1.782695 \n",
      "Batch: 3507. Acc: 0.347590. Loss: 1.858235. Batch_acc: 0.373002. Batch_loss: 1.786695 \n",
      "Batch: 3508. Acc: 0.347596. Loss: 1.858216. Batch_acc: 0.367196. Batch_loss: 1.791116 \n",
      "Batch: 3509. Acc: 0.347602. Loss: 1.858182. Batch_acc: 0.368005. Batch_loss: 1.742039 \n",
      "Batch: 3510. Acc: 0.347603. Loss: 1.858175. Batch_acc: 0.353694. Batch_loss: 1.833851 \n",
      "Batch: 3511. Acc: 0.347607. Loss: 1.858145. Batch_acc: 0.359767. Batch_loss: 1.749189 \n",
      "Batch: 3512. Acc: 0.347614. Loss: 1.858123. Batch_acc: 0.370453. Batch_loss: 1.784505 \n",
      "Batch: 3513. Acc: 0.347616. Loss: 1.858109. Batch_acc: 0.355752. Batch_loss: 1.808441 \n",
      "Batch: 3514. Acc: 0.347622. Loss: 1.858089. Batch_acc: 0.371080. Batch_loss: 1.785470 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.3476223821198069. Loss per char: 1.858088937630626. Time: 1627209244.6648743\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 14, 19, 23, 15, 21, 26, 21, 17,\n",
      "        19, 21, 20, 20,  1, 14,  1, 17, 15, 23, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.347626. Loss: 1.858073. Batch_acc: 0.360438. Batch_loss: 1.800377 \n",
      "Batch: 3516. Acc: 0.347629. Loss: 1.858067. Batch_acc: 0.358633. Batch_loss: 1.837613 \n",
      "Batch: 3517. Acc: 0.347637. Loss: 1.858043. Batch_acc: 0.373243. Batch_loss: 1.777755 \n",
      "Batch: 3518. Acc: 0.347647. Loss: 1.858016. Batch_acc: 0.386038. Batch_loss: 1.759731 \n",
      "Batch: 3519. Acc: 0.347654. Loss: 1.857987. Batch_acc: 0.372930. Batch_loss: 1.756402 \n",
      "Batch: 3520. Acc: 0.347662. Loss: 1.857966. Batch_acc: 0.374230. Batch_loss: 1.783852 \n",
      "Batch: 3521. Acc: 0.347667. Loss: 1.857944. Batch_acc: 0.366289. Batch_loss: 1.777885 \n",
      "Batch: 3522. Acc: 0.347673. Loss: 1.857924. Batch_acc: 0.367201. Batch_loss: 1.785524 \n",
      "Batch: 3523. Acc: 0.347678. Loss: 1.857909. Batch_acc: 0.366222. Batch_loss: 1.804150 \n",
      "Batch: 3524. Acc: 0.347682. Loss: 1.857889. Batch_acc: 0.361397. Batch_loss: 1.786746 \n",
      "Batch: 3525. Acc: 0.347691. Loss: 1.857862. Batch_acc: 0.379511. Batch_loss: 1.763991 \n",
      "Batch: 3526. Acc: 0.347693. Loss: 1.857848. Batch_acc: 0.357635. Batch_loss: 1.806343 \n",
      "Batch: 3527. Acc: 0.347702. Loss: 1.857825. Batch_acc: 0.378824. Batch_loss: 1.776529 \n",
      "Batch: 3528. Acc: 0.347711. Loss: 1.857790. Batch_acc: 0.378531. Batch_loss: 1.737948 \n",
      "Batch: 3529. Acc: 0.347722. Loss: 1.857765. Batch_acc: 0.385606. Batch_loss: 1.766089 \n",
      "Batch: 3530. Acc: 0.347727. Loss: 1.857747. Batch_acc: 0.366571. Batch_loss: 1.794241 \n",
      "Batch: 3531. Acc: 0.347730. Loss: 1.857731. Batch_acc: 0.357840. Batch_loss: 1.801921 \n",
      "Batch: 3532. Acc: 0.347740. Loss: 1.857704. Batch_acc: 0.384525. Batch_loss: 1.759221 \n",
      "Batch: 3533. Acc: 0.347743. Loss: 1.857684. Batch_acc: 0.359492. Batch_loss: 1.787152 \n",
      "Batch: 3534. Acc: 0.347744. Loss: 1.857675. Batch_acc: 0.351655. Batch_loss: 1.823190 \n",
      "Batch: 3535. Acc: 0.347753. Loss: 1.857652. Batch_acc: 0.378691. Batch_loss: 1.778319 \n",
      "Batch: 3536. Acc: 0.347760. Loss: 1.857631. Batch_acc: 0.372696. Batch_loss: 1.781483 \n",
      "Batch: 3537. Acc: 0.347768. Loss: 1.857611. Batch_acc: 0.375854. Batch_loss: 1.789330 \n",
      "Batch: 3538. Acc: 0.347773. Loss: 1.857592. Batch_acc: 0.365162. Batch_loss: 1.787489 \n",
      "Batch: 3539. Acc: 0.347780. Loss: 1.857561. Batch_acc: 0.371059. Batch_loss: 1.751856 \n",
      "Batch: 3540. Acc: 0.347783. Loss: 1.857540. Batch_acc: 0.358613. Batch_loss: 1.782897 \n",
      "Batch: 3541. Acc: 0.347785. Loss: 1.857528. Batch_acc: 0.354494. Batch_loss: 1.813112 \n",
      "Batch: 3542. Acc: 0.347789. Loss: 1.857513. Batch_acc: 0.365283. Batch_loss: 1.803486 \n",
      "Batch: 3543. Acc: 0.347792. Loss: 1.857489. Batch_acc: 0.357510. Batch_loss: 1.773556 \n",
      "Batch: 3544. Acc: 0.347798. Loss: 1.857467. Batch_acc: 0.368852. Batch_loss: 1.778119 \n",
      "Batch: 3545. Acc: 0.347802. Loss: 1.857454. Batch_acc: 0.363426. Batch_loss: 1.811826 \n",
      "Batch: 3546. Acc: 0.347810. Loss: 1.857428. Batch_acc: 0.375071. Batch_loss: 1.767718 \n",
      "Batch: 3547. Acc: 0.347817. Loss: 1.857397. Batch_acc: 0.373514. Batch_loss: 1.746884 \n",
      "Batch: 3548. Acc: 0.347820. Loss: 1.857379. Batch_acc: 0.357020. Batch_loss: 1.795869 \n",
      "Batch: 3549. Acc: 0.347827. Loss: 1.857357. Batch_acc: 0.370645. Batch_loss: 1.777965 \n",
      "Batch: 3550. Acc: 0.347834. Loss: 1.857332. Batch_acc: 0.373821. Batch_loss: 1.768155 \n",
      "Batch: 3551. Acc: 0.347845. Loss: 1.857305. Batch_acc: 0.386792. Batch_loss: 1.762542 \n",
      "Batch: 3552. Acc: 0.347853. Loss: 1.857283. Batch_acc: 0.376623. Batch_loss: 1.777752 \n",
      "Batch: 3553. Acc: 0.347863. Loss: 1.857248. Batch_acc: 0.383049. Batch_loss: 1.737660 \n",
      "Batch: 3554. Acc: 0.347872. Loss: 1.857227. Batch_acc: 0.380224. Batch_loss: 1.781064 \n",
      "Batch: 3555. Acc: 0.347879. Loss: 1.857204. Batch_acc: 0.371116. Batch_loss: 1.776064 \n",
      "Batch: 3556. Acc: 0.347889. Loss: 1.857174. Batch_acc: 0.383099. Batch_loss: 1.753096 \n",
      "Batch: 3557. Acc: 0.347891. Loss: 1.857156. Batch_acc: 0.354072. Batch_loss: 1.794659 \n",
      "Batch: 3558. Acc: 0.347896. Loss: 1.857144. Batch_acc: 0.366189. Batch_loss: 1.813052 \n",
      "Batch: 3559. Acc: 0.347903. Loss: 1.857127. Batch_acc: 0.373081. Batch_loss: 1.797631 \n",
      "Batch: 3560. Acc: 0.347907. Loss: 1.857113. Batch_acc: 0.363745. Batch_loss: 1.801973 \n",
      "Batch: 3561. Acc: 0.347918. Loss: 1.857077. Batch_acc: 0.385529. Batch_loss: 1.732773 \n",
      "Batch: 3562. Acc: 0.347922. Loss: 1.857052. Batch_acc: 0.362637. Batch_loss: 1.767486 \n",
      "Batch: 3563. Acc: 0.347933. Loss: 1.857023. Batch_acc: 0.387755. Batch_loss: 1.753125 \n",
      "Batch: 3564. Acc: 0.347937. Loss: 1.857003. Batch_acc: 0.363844. Batch_loss: 1.784380 \n",
      "Batch: 3565. Acc: 0.347939. Loss: 1.856998. Batch_acc: 0.354142. Batch_loss: 1.839123 \n",
      "Batch: 3566. Acc: 0.347946. Loss: 1.856977. Batch_acc: 0.371845. Batch_loss: 1.784339 \n",
      "Batch: 3567. Acc: 0.347954. Loss: 1.856948. Batch_acc: 0.376363. Batch_loss: 1.754564 \n",
      "Batch: 3568. Acc: 0.347961. Loss: 1.856922. Batch_acc: 0.374194. Batch_loss: 1.760663 \n",
      "Batch: 3569. Acc: 0.347968. Loss: 1.856892. Batch_acc: 0.372145. Batch_loss: 1.754572 \n",
      "Batch: 3570. Acc: 0.347971. Loss: 1.856881. Batch_acc: 0.359274. Batch_loss: 1.817687 \n",
      "Batch: 3571. Acc: 0.347975. Loss: 1.856862. Batch_acc: 0.360771. Batch_loss: 1.786075 \n",
      "Batch: 3572. Acc: 0.347981. Loss: 1.856847. Batch_acc: 0.369412. Batch_loss: 1.802275 \n",
      "Batch: 3573. Acc: 0.347988. Loss: 1.856821. Batch_acc: 0.374437. Batch_loss: 1.765753 \n",
      "Batch: 3574. Acc: 0.347994. Loss: 1.856799. Batch_acc: 0.369214. Batch_loss: 1.780632 \n",
      "Batch: 3575. Acc: 0.348000. Loss: 1.856777. Batch_acc: 0.370220. Batch_loss: 1.778321 \n",
      "Batch: 3576. Acc: 0.348002. Loss: 1.856764. Batch_acc: 0.352311. Batch_loss: 1.810429 \n",
      "Batch: 3577. Acc: 0.348008. Loss: 1.856742. Batch_acc: 0.372066. Batch_loss: 1.777961 \n",
      "Batch: 3578. Acc: 0.348015. Loss: 1.856722. Batch_acc: 0.371396. Batch_loss: 1.784977 \n",
      "Batch: 3579. Acc: 0.348018. Loss: 1.856711. Batch_acc: 0.357102. Batch_loss: 1.817604 \n",
      "Batch: 3580. Acc: 0.348024. Loss: 1.856695. Batch_acc: 0.372458. Batch_loss: 1.800092 \n",
      "Batch: 3581. Acc: 0.348032. Loss: 1.856667. Batch_acc: 0.374434. Batch_loss: 1.757347 \n",
      "Batch: 3582. Acc: 0.348036. Loss: 1.856651. Batch_acc: 0.362515. Batch_loss: 1.798020 \n",
      "Batch: 3583. Acc: 0.348041. Loss: 1.856631. Batch_acc: 0.368084. Batch_loss: 1.785824 \n",
      "Batch: 3584. Acc: 0.348050. Loss: 1.856606. Batch_acc: 0.378488. Batch_loss: 1.764742 \n",
      "Batch: 3585. Acc: 0.348051. Loss: 1.856595. Batch_acc: 0.351788. Batch_loss: 1.817175 \n",
      "Batch: 3586. Acc: 0.348055. Loss: 1.856573. Batch_acc: 0.363116. Batch_loss: 1.779694 \n",
      "Batch: 3587. Acc: 0.348060. Loss: 1.856564. Batch_acc: 0.364951. Batch_loss: 1.823366 \n",
      "Batch: 3588. Acc: 0.348064. Loss: 1.856549. Batch_acc: 0.364009. Batch_loss: 1.802072 \n",
      "Batch: 3589. Acc: 0.348067. Loss: 1.856543. Batch_acc: 0.358613. Batch_loss: 1.835350 \n",
      "Batch: 3590. Acc: 0.348075. Loss: 1.856521. Batch_acc: 0.378112. Batch_loss: 1.774991 \n",
      "Batch: 3591. Acc: 0.348082. Loss: 1.856491. Batch_acc: 0.372516. Batch_loss: 1.752129 \n",
      "Batch: 3592. Acc: 0.348088. Loss: 1.856478. Batch_acc: 0.369654. Batch_loss: 1.807154 \n",
      "Batch: 3593. Acc: 0.348097. Loss: 1.856445. Batch_acc: 0.380551. Batch_loss: 1.740787 \n",
      "Batch: 3594. Acc: 0.348104. Loss: 1.856420. Batch_acc: 0.373583. Batch_loss: 1.768316 \n",
      "Batch: 3595. Acc: 0.348110. Loss: 1.856394. Batch_acc: 0.369014. Batch_loss: 1.765539 \n",
      "Batch: 3596. Acc: 0.348117. Loss: 1.856376. Batch_acc: 0.373083. Batch_loss: 1.791040 \n",
      "Batch: 3597. Acc: 0.348123. Loss: 1.856348. Batch_acc: 0.368871. Batch_loss: 1.758268 \n",
      "Batch: 3598. Acc: 0.348130. Loss: 1.856322. Batch_acc: 0.372449. Batch_loss: 1.763130 \n",
      "Batch: 3599. Acc: 0.348133. Loss: 1.856297. Batch_acc: 0.357835. Batch_loss: 1.768189 \n",
      "Batch: 3600. Acc: 0.348138. Loss: 1.856283. Batch_acc: 0.367914. Batch_loss: 1.805961 \n",
      "Batch: 3601. Acc: 0.348144. Loss: 1.856264. Batch_acc: 0.367418. Batch_loss: 1.786432 \n",
      "Batch: 3602. Acc: 0.348152. Loss: 1.856239. Batch_acc: 0.378165. Batch_loss: 1.768352 \n",
      "Batch: 3603. Acc: 0.348161. Loss: 1.856213. Batch_acc: 0.380233. Batch_loss: 1.762232 \n",
      "Batch: 3604. Acc: 0.348169. Loss: 1.856186. Batch_acc: 0.375431. Batch_loss: 1.757116 \n",
      "Batch: 3605. Acc: 0.348174. Loss: 1.856162. Batch_acc: 0.368786. Batch_loss: 1.769043 \n",
      "Batch: 3606. Acc: 0.348186. Loss: 1.856127. Batch_acc: 0.390717. Batch_loss: 1.727779 \n",
      "Batch: 3607. Acc: 0.348190. Loss: 1.856102. Batch_acc: 0.363374. Batch_loss: 1.766277 \n",
      "Batch: 3608. Acc: 0.348200. Loss: 1.856069. Batch_acc: 0.384793. Batch_loss: 1.737034 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3609. Acc: 0.348200. Loss: 1.856058. Batch_acc: 0.348878. Batch_loss: 1.814429 \n",
      "Batch: 3610. Acc: 0.348210. Loss: 1.856037. Batch_acc: 0.381587. Batch_loss: 1.781352 \n",
      "Batch: 3611. Acc: 0.348220. Loss: 1.856006. Batch_acc: 0.385369. Batch_loss: 1.742012 \n",
      "Batch: 3612. Acc: 0.348227. Loss: 1.855974. Batch_acc: 0.373101. Batch_loss: 1.742631 \n",
      "Batch: 3613. Acc: 0.348230. Loss: 1.855961. Batch_acc: 0.358932. Batch_loss: 1.812956 \n",
      "Batch: 3614. Acc: 0.348238. Loss: 1.855945. Batch_acc: 0.377002. Batch_loss: 1.798331 \n",
      "Batch: 3615. Acc: 0.348248. Loss: 1.855918. Batch_acc: 0.382991. Batch_loss: 1.758802 \n",
      "Batch: 3616. Acc: 0.348260. Loss: 1.855887. Batch_acc: 0.392736. Batch_loss: 1.745958 \n",
      "Batch: 3617. Acc: 0.348262. Loss: 1.855869. Batch_acc: 0.353722. Batch_loss: 1.788722 \n",
      "Batch: 3618. Acc: 0.348265. Loss: 1.855853. Batch_acc: 0.360069. Batch_loss: 1.799981 \n",
      "Batch: 3619. Acc: 0.348273. Loss: 1.855836. Batch_acc: 0.376653. Batch_loss: 1.792924 \n",
      "Batch: 3620. Acc: 0.348282. Loss: 1.855809. Batch_acc: 0.382593. Batch_loss: 1.755057 \n",
      "Batch: 3621. Acc: 0.348286. Loss: 1.855791. Batch_acc: 0.363688. Batch_loss: 1.792748 \n",
      "Batch: 3622. Acc: 0.348294. Loss: 1.855776. Batch_acc: 0.375510. Batch_loss: 1.801566 \n",
      "Batch: 3623. Acc: 0.348304. Loss: 1.855746. Batch_acc: 0.385876. Batch_loss: 1.746740 \n",
      "Batch: 3624. Acc: 0.348306. Loss: 1.855746. Batch_acc: 0.354289. Batch_loss: 1.856534 \n",
      "Batch: 3625. Acc: 0.348312. Loss: 1.855748. Batch_acc: 0.370070. Batch_loss: 1.863769 \n",
      "Batch: 3626. Acc: 0.348317. Loss: 1.855732. Batch_acc: 0.366878. Batch_loss: 1.797088 \n",
      "Batch: 3627. Acc: 0.348325. Loss: 1.855705. Batch_acc: 0.376183. Batch_loss: 1.761912 \n",
      "Batch: 3628. Acc: 0.348329. Loss: 1.855691. Batch_acc: 0.364486. Batch_loss: 1.803666 \n",
      "Batch: 3629. Acc: 0.348330. Loss: 1.855679. Batch_acc: 0.351289. Batch_loss: 1.812178 \n",
      "Batch: 3630. Acc: 0.348336. Loss: 1.855650. Batch_acc: 0.369188. Batch_loss: 1.753119 \n",
      "Batch: 3631. Acc: 0.348345. Loss: 1.855628. Batch_acc: 0.381200. Batch_loss: 1.774688 \n",
      "Batch: 3632. Acc: 0.348352. Loss: 1.855601. Batch_acc: 0.372951. Batch_loss: 1.756122 \n",
      "Batch: 3633. Acc: 0.348359. Loss: 1.855582. Batch_acc: 0.375441. Batch_loss: 1.784249 \n",
      "Batch: 3634. Acc: 0.348364. Loss: 1.855566. Batch_acc: 0.367580. Batch_loss: 1.800394 \n",
      "Batch: 3635. Acc: 0.348366. Loss: 1.855554. Batch_acc: 0.354312. Batch_loss: 1.810839 \n",
      "Batch: 3636. Acc: 0.348371. Loss: 1.855531. Batch_acc: 0.367059. Batch_loss: 1.770265 \n",
      "Batch: 3637. Acc: 0.348376. Loss: 1.855514. Batch_acc: 0.366157. Batch_loss: 1.792348 \n",
      "Batch: 3638. Acc: 0.348386. Loss: 1.855485. Batch_acc: 0.383467. Batch_loss: 1.750292 \n",
      "Batch: 3639. Acc: 0.348396. Loss: 1.855467. Batch_acc: 0.385706. Batch_loss: 1.788540 \n",
      "Batch: 3640. Acc: 0.348403. Loss: 1.855444. Batch_acc: 0.376093. Batch_loss: 1.770979 \n",
      "Batch: 3641. Acc: 0.348408. Loss: 1.855422. Batch_acc: 0.367089. Batch_loss: 1.774928 \n",
      "Batch: 3642. Acc: 0.348416. Loss: 1.855401. Batch_acc: 0.377921. Batch_loss: 1.778015 \n",
      "Batch: 3643. Acc: 0.348420. Loss: 1.855387. Batch_acc: 0.360825. Batch_loss: 1.806234 \n",
      "Batch: 3644. Acc: 0.348419. Loss: 1.855378. Batch_acc: 0.345476. Batch_loss: 1.819849 \n",
      "Batch: 3645. Acc: 0.348424. Loss: 1.855357. Batch_acc: 0.366342. Batch_loss: 1.781281 \n",
      "Batch: 3646. Acc: 0.348427. Loss: 1.855338. Batch_acc: 0.360702. Batch_loss: 1.787328 \n",
      "Batch: 3647. Acc: 0.348439. Loss: 1.855305. Batch_acc: 0.389201. Batch_loss: 1.734239 \n",
      "Batch: 3648. Acc: 0.348442. Loss: 1.855282. Batch_acc: 0.360093. Batch_loss: 1.772763 \n",
      "Batch: 3649. Acc: 0.348445. Loss: 1.855266. Batch_acc: 0.361354. Batch_loss: 1.794437 \n",
      "Batch: 3650. Acc: 0.348448. Loss: 1.855241. Batch_acc: 0.358633. Batch_loss: 1.764103 \n",
      "Batch: 3651. Acc: 0.348460. Loss: 1.855207. Batch_acc: 0.393138. Batch_loss: 1.734138 \n",
      "Batch: 3652. Acc: 0.348462. Loss: 1.855194. Batch_acc: 0.354857. Batch_loss: 1.808318 \n",
      "Batch: 3653. Acc: 0.348469. Loss: 1.855177. Batch_acc: 0.372203. Batch_loss: 1.789118 \n",
      "Batch: 3654. Acc: 0.348469. Loss: 1.855159. Batch_acc: 0.348521. Batch_loss: 1.789739 \n",
      "Batch: 3655. Acc: 0.348473. Loss: 1.855135. Batch_acc: 0.363741. Batch_loss: 1.765083 \n",
      "Batch: 3656. Acc: 0.348482. Loss: 1.855111. Batch_acc: 0.381117. Batch_loss: 1.767121 \n",
      "Batch: 3657. Acc: 0.348487. Loss: 1.855081. Batch_acc: 0.369782. Batch_loss: 1.745662 \n",
      "Batch: 3658. Acc: 0.348493. Loss: 1.855066. Batch_acc: 0.369839. Batch_loss: 1.798664 \n",
      "Batch: 3659. Acc: 0.348498. Loss: 1.855043. Batch_acc: 0.364253. Batch_loss: 1.772129 \n",
      "Batch: 3660. Acc: 0.348504. Loss: 1.855015. Batch_acc: 0.371495. Batch_loss: 1.752488 \n",
      "Batch: 3661. Acc: 0.348509. Loss: 1.855000. Batch_acc: 0.368754. Batch_loss: 1.797727 \n",
      "Batch: 3662. Acc: 0.348512. Loss: 1.854982. Batch_acc: 0.358314. Batch_loss: 1.789156 \n",
      "Batch: 3663. Acc: 0.348511. Loss: 1.854967. Batch_acc: 0.343318. Batch_loss: 1.799665 \n",
      "Batch: 3664. Acc: 0.348517. Loss: 1.854949. Batch_acc: 0.373432. Batch_loss: 1.789428 \n",
      "Batch: 3665. Acc: 0.348525. Loss: 1.854923. Batch_acc: 0.375145. Batch_loss: 1.759624 \n",
      "Batch: 3666. Acc: 0.348527. Loss: 1.854904. Batch_acc: 0.355942. Batch_loss: 1.782981 \n",
      "Batch: 3667. Acc: 0.348530. Loss: 1.854890. Batch_acc: 0.362409. Batch_loss: 1.806998 \n",
      "Batch: 3668. Acc: 0.348539. Loss: 1.854867. Batch_acc: 0.379251. Batch_loss: 1.767969 \n",
      "Batch: 3669. Acc: 0.348547. Loss: 1.854845. Batch_acc: 0.380093. Batch_loss: 1.775465 \n",
      "Batch: 3670. Acc: 0.348556. Loss: 1.854826. Batch_acc: 0.381556. Batch_loss: 1.782768 \n",
      "Batch: 3671. Acc: 0.348565. Loss: 1.854802. Batch_acc: 0.380844. Batch_loss: 1.768432 \n",
      "Batch: 3672. Acc: 0.348574. Loss: 1.854774. Batch_acc: 0.379408. Batch_loss: 1.752396 \n",
      "Batch: 3673. Acc: 0.348581. Loss: 1.854747. Batch_acc: 0.375716. Batch_loss: 1.756596 \n",
      "Batch: 3674. Acc: 0.348590. Loss: 1.854715. Batch_acc: 0.381549. Batch_loss: 1.739901 \n",
      "Batch: 3675. Acc: 0.348598. Loss: 1.854686. Batch_acc: 0.379074. Batch_loss: 1.747318 \n",
      "Batch: 3676. Acc: 0.348603. Loss: 1.854661. Batch_acc: 0.363895. Batch_loss: 1.765357 \n",
      "Batch: 3677. Acc: 0.348610. Loss: 1.854636. Batch_acc: 0.376991. Batch_loss: 1.759406 \n",
      "Batch: 3678. Acc: 0.348616. Loss: 1.854619. Batch_acc: 0.372079. Batch_loss: 1.788289 \n",
      "Batch: 3679. Acc: 0.348624. Loss: 1.854590. Batch_acc: 0.376828. Batch_loss: 1.752645 \n",
      "Batch: 3680. Acc: 0.348631. Loss: 1.854564. Batch_acc: 0.375508. Batch_loss: 1.756981 \n",
      "Batch: 3681. Acc: 0.348638. Loss: 1.854535. Batch_acc: 0.370558. Batch_loss: 1.749624 \n",
      "Batch: 3682. Acc: 0.348643. Loss: 1.854517. Batch_acc: 0.368210. Batch_loss: 1.789912 \n",
      "Batch: 3683. Acc: 0.348650. Loss: 1.854503. Batch_acc: 0.376511. Batch_loss: 1.802069 \n",
      "Batch: 3684. Acc: 0.348658. Loss: 1.854472. Batch_acc: 0.376910. Batch_loss: 1.740637 \n",
      "Batch: 3685. Acc: 0.348665. Loss: 1.854446. Batch_acc: 0.372322. Batch_loss: 1.759152 \n",
      "Batch: 3686. Acc: 0.348671. Loss: 1.854427. Batch_acc: 0.373151. Batch_loss: 1.786106 \n",
      "Batch: 3687. Acc: 0.348671. Loss: 1.854427. Batch_acc: 0.348727. Batch_loss: 1.852739 \n",
      "Batch: 3688. Acc: 0.348679. Loss: 1.854405. Batch_acc: 0.377752. Batch_loss: 1.773781 \n",
      "Batch: 3689. Acc: 0.348686. Loss: 1.854386. Batch_acc: 0.373563. Batch_loss: 1.785310 \n",
      "Batch: 3690. Acc: 0.348693. Loss: 1.854357. Batch_acc: 0.374437. Batch_loss: 1.747365 \n",
      "Batch: 3691. Acc: 0.348699. Loss: 1.854338. Batch_acc: 0.370156. Batch_loss: 1.785316 \n",
      "Batch: 3692. Acc: 0.348706. Loss: 1.854307. Batch_acc: 0.374437. Batch_loss: 1.739998 \n",
      "Batch: 3693. Acc: 0.348715. Loss: 1.854281. Batch_acc: 0.383903. Batch_loss: 1.758039 \n",
      "Batch: 3694. Acc: 0.348718. Loss: 1.854275. Batch_acc: 0.360397. Batch_loss: 1.832907 \n",
      "Batch: 3695. Acc: 0.348724. Loss: 1.854259. Batch_acc: 0.370178. Batch_loss: 1.796024 \n",
      "Batch: 3696. Acc: 0.348732. Loss: 1.854239. Batch_acc: 0.375501. Batch_loss: 1.779496 \n",
      "Batch: 3697. Acc: 0.348740. Loss: 1.854205. Batch_acc: 0.376923. Batch_loss: 1.734390 \n",
      "Batch: 3698. Acc: 0.348743. Loss: 1.854183. Batch_acc: 0.362837. Batch_loss: 1.772475 \n",
      "Batch: 3699. Acc: 0.348748. Loss: 1.854165. Batch_acc: 0.368174. Batch_loss: 1.783642 \n",
      "Batch: 3700. Acc: 0.348751. Loss: 1.854145. Batch_acc: 0.356497. Batch_loss: 1.784664 \n",
      "Batch: 3701. Acc: 0.348758. Loss: 1.854122. Batch_acc: 0.375719. Batch_loss: 1.766555 \n",
      "Batch: 3702. Acc: 0.348763. Loss: 1.854102. Batch_acc: 0.367995. Batch_loss: 1.780458 \n",
      "Batch: 3703. Acc: 0.348769. Loss: 1.854082. Batch_acc: 0.370435. Batch_loss: 1.780721 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3704. Acc: 0.348777. Loss: 1.854064. Batch_acc: 0.380479. Batch_loss: 1.786749 \n",
      "Batch: 3705. Acc: 0.348785. Loss: 1.854040. Batch_acc: 0.378762. Batch_loss: 1.765996 \n",
      "Batch: 3706. Acc: 0.348793. Loss: 1.854019. Batch_acc: 0.374856. Batch_loss: 1.775661 \n",
      "Batch: 3707. Acc: 0.348794. Loss: 1.854000. Batch_acc: 0.354971. Batch_loss: 1.782279 \n",
      "Batch: 3708. Acc: 0.348800. Loss: 1.853980. Batch_acc: 0.371164. Batch_loss: 1.779627 \n",
      "Batch: 3709. Acc: 0.348806. Loss: 1.853958. Batch_acc: 0.372410. Batch_loss: 1.768146 \n",
      "Batch: 3710. Acc: 0.348812. Loss: 1.853934. Batch_acc: 0.368904. Batch_loss: 1.765658 \n",
      "Batch: 3711. Acc: 0.348817. Loss: 1.853926. Batch_acc: 0.366837. Batch_loss: 1.826266 \n",
      "Batch: 3712. Acc: 0.348826. Loss: 1.853903. Batch_acc: 0.381693. Batch_loss: 1.765473 \n",
      "Batch: 3713. Acc: 0.348829. Loss: 1.853888. Batch_acc: 0.363210. Batch_loss: 1.799238 \n",
      "Batch: 3714. Acc: 0.348836. Loss: 1.853865. Batch_acc: 0.372872. Batch_loss: 1.770174 \n",
      "Batch: 3715. Acc: 0.348846. Loss: 1.853835. Batch_acc: 0.384615. Batch_loss: 1.744514 \n",
      "Batch: 3716. Acc: 0.348849. Loss: 1.853823. Batch_acc: 0.361615. Batch_loss: 1.806872 \n",
      "Batch: 3717. Acc: 0.348854. Loss: 1.853802. Batch_acc: 0.367571. Batch_loss: 1.774685 \n",
      "Batch: 3718. Acc: 0.348861. Loss: 1.853779. Batch_acc: 0.375492. Batch_loss: 1.770782 \n",
      "Batch: 3719. Acc: 0.348867. Loss: 1.853752. Batch_acc: 0.370913. Batch_loss: 1.755437 \n",
      "Batch: 3720. Acc: 0.348876. Loss: 1.853723. Batch_acc: 0.379943. Batch_loss: 1.746132 \n",
      "Batch: 3721. Acc: 0.348879. Loss: 1.853704. Batch_acc: 0.361111. Batch_loss: 1.782685 \n",
      "Batch: 3722. Acc: 0.348882. Loss: 1.853691. Batch_acc: 0.360588. Batch_loss: 1.801411 \n",
      "Batch: 3723. Acc: 0.348885. Loss: 1.853669. Batch_acc: 0.361013. Batch_loss: 1.772665 \n",
      "Batch: 3724. Acc: 0.348891. Loss: 1.853644. Batch_acc: 0.370518. Batch_loss: 1.760078 \n",
      "Batch: 3725. Acc: 0.348903. Loss: 1.853607. Batch_acc: 0.392045. Batch_loss: 1.716580 \n",
      "Batch: 3726. Acc: 0.348906. Loss: 1.853589. Batch_acc: 0.360277. Batch_loss: 1.787399 \n",
      "Batch: 3727. Acc: 0.348911. Loss: 1.853575. Batch_acc: 0.366474. Batch_loss: 1.799877 \n",
      "Batch: 3728. Acc: 0.348914. Loss: 1.853557. Batch_acc: 0.361751. Batch_loss: 1.788396 \n",
      "Batch: 3729. Acc: 0.348913. Loss: 1.853554. Batch_acc: 0.346784. Batch_loss: 1.841624 \n",
      "Batch: 3730. Acc: 0.348919. Loss: 1.853529. Batch_acc: 0.371005. Batch_loss: 1.761639 \n",
      "Batch: 3731. Acc: 0.348925. Loss: 1.853509. Batch_acc: 0.368899. Batch_loss: 1.778168 \n",
      "Batch: 3732. Acc: 0.348933. Loss: 1.853488. Batch_acc: 0.379805. Batch_loss: 1.774729 \n",
      "Batch: 3733. Acc: 0.348933. Loss: 1.853478. Batch_acc: 0.348715. Batch_loss: 1.815788 \n",
      "Batch: 3734. Acc: 0.348939. Loss: 1.853456. Batch_acc: 0.372304. Batch_loss: 1.772582 \n",
      "Batch: 3735. Acc: 0.348949. Loss: 1.853430. Batch_acc: 0.384433. Batch_loss: 1.753183 \n",
      "Batch: 3736. Acc: 0.348955. Loss: 1.853404. Batch_acc: 0.371817. Batch_loss: 1.760228 \n",
      "Batch: 3737. Acc: 0.348962. Loss: 1.853385. Batch_acc: 0.376752. Batch_loss: 1.779228 \n",
      "Batch: 3738. Acc: 0.348967. Loss: 1.853361. Batch_acc: 0.367133. Batch_loss: 1.764246 \n",
      "Batch: 3739. Acc: 0.348973. Loss: 1.853347. Batch_acc: 0.371722. Batch_loss: 1.799247 \n",
      "Batch: 3740. Acc: 0.348982. Loss: 1.853321. Batch_acc: 0.381797. Batch_loss: 1.758885 \n",
      "Batch: 3741. Acc: 0.348987. Loss: 1.853294. Batch_acc: 0.368421. Batch_loss: 1.751703 \n",
      "Batch: 3742. Acc: 0.348994. Loss: 1.853267. Batch_acc: 0.375070. Batch_loss: 1.756246 \n",
      "Batch: 3743. Acc: 0.348997. Loss: 1.853252. Batch_acc: 0.357516. Batch_loss: 1.797673 \n",
      "Batch: 3744. Acc: 0.349002. Loss: 1.853234. Batch_acc: 0.368725. Batch_loss: 1.785185 \n",
      "Batch: 3745. Acc: 0.349007. Loss: 1.853219. Batch_acc: 0.368329. Batch_loss: 1.796665 \n",
      "Batch: 3746. Acc: 0.349019. Loss: 1.853177. Batch_acc: 0.391160. Batch_loss: 1.700153 \n",
      "Batch: 3747. Acc: 0.349025. Loss: 1.853162. Batch_acc: 0.372449. Batch_loss: 1.799851 \n",
      "Batch: 3748. Acc: 0.349029. Loss: 1.853144. Batch_acc: 0.365340. Batch_loss: 1.784832 \n",
      "Batch: 3749. Acc: 0.349035. Loss: 1.853127. Batch_acc: 0.370011. Batch_loss: 1.787744 \n",
      "Batch: 3750. Acc: 0.349039. Loss: 1.853115. Batch_acc: 0.365482. Batch_loss: 1.808620 \n",
      "Batch: 3751. Acc: 0.349043. Loss: 1.853103. Batch_acc: 0.362751. Batch_loss: 1.808160 \n",
      "Batch: 3752. Acc: 0.349051. Loss: 1.853082. Batch_acc: 0.379096. Batch_loss: 1.775631 \n",
      "Batch: 3753. Acc: 0.349052. Loss: 1.853073. Batch_acc: 0.351211. Batch_loss: 1.820698 \n",
      "Batch: 3754. Acc: 0.349059. Loss: 1.853050. Batch_acc: 0.374427. Batch_loss: 1.768977 \n",
      "Batch: 3755. Acc: 0.349064. Loss: 1.853031. Batch_acc: 0.369590. Batch_loss: 1.778977 \n",
      "Batch: 3756. Acc: 0.349072. Loss: 1.853018. Batch_acc: 0.376350. Batch_loss: 1.806082 \n",
      "Batch: 3757. Acc: 0.349076. Loss: 1.853000. Batch_acc: 0.366915. Batch_loss: 1.785560 \n",
      "Batch: 3758. Acc: 0.349081. Loss: 1.852985. Batch_acc: 0.365116. Batch_loss: 1.795607 \n",
      "Batch: 3759. Acc: 0.349090. Loss: 1.852958. Batch_acc: 0.383151. Batch_loss: 1.752451 \n",
      "Batch: 3760. Acc: 0.349088. Loss: 1.852956. Batch_acc: 0.343160. Batch_loss: 1.844310 \n",
      "Batch: 3761. Acc: 0.349089. Loss: 1.852942. Batch_acc: 0.351572. Batch_loss: 1.801844 \n",
      "Batch: 3762. Acc: 0.349090. Loss: 1.852931. Batch_acc: 0.353962. Batch_loss: 1.808416 \n",
      "Batch: 3763. Acc: 0.349093. Loss: 1.852922. Batch_acc: 0.362456. Batch_loss: 1.817816 \n",
      "Batch: 3764. Acc: 0.349097. Loss: 1.852901. Batch_acc: 0.363006. Batch_loss: 1.773603 \n",
      "Batch: 3765. Acc: 0.349099. Loss: 1.852886. Batch_acc: 0.357600. Batch_loss: 1.796751 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.349099328565251. Loss per char: 1.852885871615396. Time: 1627209449.8007424\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 23, 21, 26, 22, 19, 22,  1, 85, 66,\n",
      "        76, 70,  1, 66, 88, 66, 90,  1, 19, 15, 17, 23, 25, 21, 20, 19, 32,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.349105. Loss: 1.852884. Batch_acc: 0.373349. Batch_loss: 1.846143 \n",
      "Batch: 3767. Acc: 0.349115. Loss: 1.852857. Batch_acc: 0.385698. Batch_loss: 1.747748 \n",
      "Batch: 3768. Acc: 0.349118. Loss: 1.852841. Batch_acc: 0.360540. Batch_loss: 1.791101 \n",
      "Batch: 3769. Acc: 0.349125. Loss: 1.852833. Batch_acc: 0.373988. Batch_loss: 1.824354 \n",
      "Batch: 3770. Acc: 0.349129. Loss: 1.852819. Batch_acc: 0.365098. Batch_loss: 1.800079 \n",
      "Batch: 3771. Acc: 0.349138. Loss: 1.852789. Batch_acc: 0.382930. Batch_loss: 1.737581 \n",
      "Batch: 3772. Acc: 0.349145. Loss: 1.852761. Batch_acc: 0.377574. Batch_loss: 1.750445 \n",
      "Batch: 3773. Acc: 0.349153. Loss: 1.852739. Batch_acc: 0.378770. Batch_loss: 1.767589 \n",
      "Batch: 3774. Acc: 0.349158. Loss: 1.852716. Batch_acc: 0.367816. Batch_loss: 1.765380 \n",
      "Batch: 3775. Acc: 0.349161. Loss: 1.852698. Batch_acc: 0.359954. Batch_loss: 1.784597 \n",
      "Batch: 3776. Acc: 0.349164. Loss: 1.852683. Batch_acc: 0.359767. Batch_loss: 1.793613 \n",
      "Batch: 3777. Acc: 0.349168. Loss: 1.852661. Batch_acc: 0.365730. Batch_loss: 1.774049 \n",
      "Batch: 3778. Acc: 0.349178. Loss: 1.852631. Batch_acc: 0.386377. Batch_loss: 1.739484 \n",
      "Batch: 3779. Acc: 0.349187. Loss: 1.852611. Batch_acc: 0.382220. Batch_loss: 1.776902 \n",
      "Batch: 3780. Acc: 0.349192. Loss: 1.852590. Batch_acc: 0.369464. Batch_loss: 1.771851 \n",
      "Batch: 3781. Acc: 0.349198. Loss: 1.852570. Batch_acc: 0.370930. Batch_loss: 1.777045 \n",
      "Batch: 3782. Acc: 0.349202. Loss: 1.852560. Batch_acc: 0.364124. Batch_loss: 1.812317 \n",
      "Batch: 3783. Acc: 0.349205. Loss: 1.852542. Batch_acc: 0.361838. Batch_loss: 1.786869 \n",
      "Batch: 3784. Acc: 0.349212. Loss: 1.852515. Batch_acc: 0.374506. Batch_loss: 1.749223 \n",
      "Batch: 3785. Acc: 0.349221. Loss: 1.852496. Batch_acc: 0.384075. Batch_loss: 1.779150 \n",
      "Batch: 3786. Acc: 0.349229. Loss: 1.852471. Batch_acc: 0.381533. Batch_loss: 1.757075 \n",
      "Batch: 3787. Acc: 0.349242. Loss: 1.852440. Batch_acc: 0.397340. Batch_loss: 1.737368 \n",
      "Batch: 3788. Acc: 0.349249. Loss: 1.852420. Batch_acc: 0.375843. Batch_loss: 1.775309 \n",
      "Batch: 3789. Acc: 0.349253. Loss: 1.852409. Batch_acc: 0.365897. Batch_loss: 1.809756 \n",
      "Batch: 3790. Acc: 0.349252. Loss: 1.852399. Batch_acc: 0.345412. Batch_loss: 1.816300 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3791. Acc: 0.349257. Loss: 1.852385. Batch_acc: 0.367416. Batch_loss: 1.798283 \n",
      "Batch: 3792. Acc: 0.349264. Loss: 1.852371. Batch_acc: 0.372970. Batch_loss: 1.799689 \n",
      "Batch: 3793. Acc: 0.349268. Loss: 1.852346. Batch_acc: 0.365079. Batch_loss: 1.760410 \n",
      "Batch: 3794. Acc: 0.349268. Loss: 1.852339. Batch_acc: 0.350581. Batch_loss: 1.824972 \n",
      "Batch: 3795. Acc: 0.349274. Loss: 1.852319. Batch_acc: 0.372593. Batch_loss: 1.776538 \n",
      "Batch: 3796. Acc: 0.349282. Loss: 1.852302. Batch_acc: 0.377934. Batch_loss: 1.788188 \n",
      "Batch: 3797. Acc: 0.349288. Loss: 1.852288. Batch_acc: 0.371087. Batch_loss: 1.798528 \n",
      "Batch: 3798. Acc: 0.349298. Loss: 1.852251. Batch_acc: 0.389655. Batch_loss: 1.711613 \n",
      "Batch: 3799. Acc: 0.349306. Loss: 1.852233. Batch_acc: 0.379608. Batch_loss: 1.783345 \n",
      "Batch: 3800. Acc: 0.349306. Loss: 1.852227. Batch_acc: 0.348904. Batch_loss: 1.829097 \n",
      "Batch: 3801. Acc: 0.349316. Loss: 1.852197. Batch_acc: 0.385569. Batch_loss: 1.740787 \n",
      "Batch: 3802. Acc: 0.349322. Loss: 1.852176. Batch_acc: 0.372225. Batch_loss: 1.774067 \n",
      "Batch: 3803. Acc: 0.349328. Loss: 1.852157. Batch_acc: 0.372434. Batch_loss: 1.778105 \n",
      "Batch: 3804. Acc: 0.349327. Loss: 1.852152. Batch_acc: 0.346154. Batch_loss: 1.832235 \n",
      "Batch: 3805. Acc: 0.349335. Loss: 1.852122. Batch_acc: 0.377778. Batch_loss: 1.743230 \n",
      "Batch: 3806. Acc: 0.349340. Loss: 1.852099. Batch_acc: 0.368119. Batch_loss: 1.762895 \n",
      "Batch: 3807. Acc: 0.349349. Loss: 1.852071. Batch_acc: 0.382638. Batch_loss: 1.746234 \n",
      "Batch: 3808. Acc: 0.349356. Loss: 1.852050. Batch_acc: 0.378502. Batch_loss: 1.774226 \n",
      "Batch: 3809. Acc: 0.349370. Loss: 1.852012. Batch_acc: 0.400000. Batch_loss: 1.712129 \n",
      "Batch: 3810. Acc: 0.349377. Loss: 1.851984. Batch_acc: 0.377598. Batch_loss: 1.743381 \n",
      "Batch: 3811. Acc: 0.349392. Loss: 1.851949. Batch_acc: 0.405344. Batch_loss: 1.720473 \n",
      "Batch: 3812. Acc: 0.349401. Loss: 1.851927. Batch_acc: 0.383140. Batch_loss: 1.765746 \n",
      "Batch: 3813. Acc: 0.349407. Loss: 1.851906. Batch_acc: 0.372526. Batch_loss: 1.771272 \n",
      "Batch: 3814. Acc: 0.349413. Loss: 1.851878. Batch_acc: 0.371332. Batch_loss: 1.748702 \n",
      "Batch: 3815. Acc: 0.349420. Loss: 1.851853. Batch_acc: 0.376350. Batch_loss: 1.756674 \n",
      "Batch: 3816. Acc: 0.349424. Loss: 1.851826. Batch_acc: 0.364903. Batch_loss: 1.754083 \n",
      "Batch: 3817. Acc: 0.349431. Loss: 1.851802. Batch_acc: 0.375719. Batch_loss: 1.758955 \n",
      "Batch: 3818. Acc: 0.349433. Loss: 1.851787. Batch_acc: 0.356937. Batch_loss: 1.794810 \n",
      "Batch: 3819. Acc: 0.349442. Loss: 1.851760. Batch_acc: 0.385284. Batch_loss: 1.747849 \n",
      "Batch: 3820. Acc: 0.349450. Loss: 1.851736. Batch_acc: 0.377790. Batch_loss: 1.761645 \n",
      "Batch: 3821. Acc: 0.349457. Loss: 1.851708. Batch_acc: 0.375854. Batch_loss: 1.745914 \n",
      "Batch: 3822. Acc: 0.349467. Loss: 1.851684. Batch_acc: 0.391559. Batch_loss: 1.755403 \n",
      "Batch: 3823. Acc: 0.349467. Loss: 1.851680. Batch_acc: 0.348906. Batch_loss: 1.836781 \n",
      "Batch: 3824. Acc: 0.349474. Loss: 1.851659. Batch_acc: 0.373280. Batch_loss: 1.773068 \n",
      "Batch: 3825. Acc: 0.349483. Loss: 1.851636. Batch_acc: 0.385924. Batch_loss: 1.762209 \n",
      "Batch: 3826. Acc: 0.349489. Loss: 1.851610. Batch_acc: 0.372470. Batch_loss: 1.751059 \n",
      "Batch: 3827. Acc: 0.349492. Loss: 1.851591. Batch_acc: 0.361257. Batch_loss: 1.777295 \n",
      "Batch: 3828. Acc: 0.349495. Loss: 1.851568. Batch_acc: 0.361221. Batch_loss: 1.764557 \n",
      "Batch: 3829. Acc: 0.349495. Loss: 1.851559. Batch_acc: 0.347676. Batch_loss: 1.818107 \n",
      "Batch: 3830. Acc: 0.349501. Loss: 1.851541. Batch_acc: 0.373161. Batch_loss: 1.782095 \n",
      "Batch: 3831. Acc: 0.349510. Loss: 1.851519. Batch_acc: 0.384571. Batch_loss: 1.764324 \n",
      "Batch: 3832. Acc: 0.349511. Loss: 1.851511. Batch_acc: 0.353349. Batch_loss: 1.823521 \n",
      "Batch: 3833. Acc: 0.349517. Loss: 1.851493. Batch_acc: 0.373083. Batch_loss: 1.782616 \n",
      "Batch: 3834. Acc: 0.349519. Loss: 1.851475. Batch_acc: 0.355923. Batch_loss: 1.781836 \n",
      "Batch: 3835. Acc: 0.349526. Loss: 1.851447. Batch_acc: 0.377598. Batch_loss: 1.745244 \n",
      "Batch: 3836. Acc: 0.349535. Loss: 1.851422. Batch_acc: 0.382035. Batch_loss: 1.757987 \n",
      "Batch: 3837. Acc: 0.349541. Loss: 1.851404. Batch_acc: 0.375145. Batch_loss: 1.778301 \n",
      "Batch: 3838. Acc: 0.349548. Loss: 1.851385. Batch_acc: 0.376147. Batch_loss: 1.778978 \n",
      "Batch: 3839. Acc: 0.349556. Loss: 1.851361. Batch_acc: 0.378453. Batch_loss: 1.765637 \n",
      "Batch: 3840. Acc: 0.349564. Loss: 1.851345. Batch_acc: 0.378719. Batch_loss: 1.790329 \n",
      "Batch: 3841. Acc: 0.349576. Loss: 1.851312. Batch_acc: 0.394128. Batch_loss: 1.723764 \n",
      "Batch: 3842. Acc: 0.349577. Loss: 1.851296. Batch_acc: 0.354286. Batch_loss: 1.791828 \n",
      "Batch: 3843. Acc: 0.349582. Loss: 1.851277. Batch_acc: 0.369767. Batch_loss: 1.776725 \n",
      "Batch: 3844. Acc: 0.349585. Loss: 1.851264. Batch_acc: 0.359721. Batch_loss: 1.800142 \n",
      "Batch: 3845. Acc: 0.349590. Loss: 1.851237. Batch_acc: 0.370884. Batch_loss: 1.748097 \n",
      "Batch: 3846. Acc: 0.349595. Loss: 1.851221. Batch_acc: 0.369159. Batch_loss: 1.789751 \n",
      "Batch: 3847. Acc: 0.349605. Loss: 1.851185. Batch_acc: 0.387906. Batch_loss: 1.714879 \n",
      "Batch: 3848. Acc: 0.349613. Loss: 1.851158. Batch_acc: 0.378227. Batch_loss: 1.747409 \n",
      "Batch: 3849. Acc: 0.349621. Loss: 1.851133. Batch_acc: 0.382095. Batch_loss: 1.754389 \n",
      "Batch: 3850. Acc: 0.349629. Loss: 1.851112. Batch_acc: 0.378256. Batch_loss: 1.771873 \n",
      "Batch: 3851. Acc: 0.349633. Loss: 1.851093. Batch_acc: 0.367096. Batch_loss: 1.779772 \n",
      "Batch: 3852. Acc: 0.349642. Loss: 1.851052. Batch_acc: 0.382979. Batch_loss: 1.701678 \n",
      "Batch: 3853. Acc: 0.349649. Loss: 1.851025. Batch_acc: 0.376093. Batch_loss: 1.743242 \n",
      "Batch: 3854. Acc: 0.349655. Loss: 1.850998. Batch_acc: 0.370475. Batch_loss: 1.751745 \n",
      "Batch: 3855. Acc: 0.349659. Loss: 1.850972. Batch_acc: 0.364465. Batch_loss: 1.750704 \n",
      "Batch: 3856. Acc: 0.349663. Loss: 1.850956. Batch_acc: 0.368601. Batch_loss: 1.788434 \n",
      "Batch: 3857. Acc: 0.349666. Loss: 1.850944. Batch_acc: 0.358329. Batch_loss: 1.804414 \n",
      "Batch: 3858. Acc: 0.349676. Loss: 1.850915. Batch_acc: 0.390930. Batch_loss: 1.741243 \n",
      "Batch: 3859. Acc: 0.349684. Loss: 1.850893. Batch_acc: 0.376836. Batch_loss: 1.768232 \n",
      "Batch: 3860. Acc: 0.349688. Loss: 1.850874. Batch_acc: 0.366628. Batch_loss: 1.775870 \n",
      "Batch: 3861. Acc: 0.349694. Loss: 1.850849. Batch_acc: 0.371332. Batch_loss: 1.756061 \n",
      "Batch: 3862. Acc: 0.349695. Loss: 1.850842. Batch_acc: 0.356430. Batch_loss: 1.824456 \n",
      "Batch: 3863. Acc: 0.349699. Loss: 1.850830. Batch_acc: 0.362412. Batch_loss: 1.801830 \n",
      "Batch: 3864. Acc: 0.349707. Loss: 1.850807. Batch_acc: 0.383673. Batch_loss: 1.761708 \n",
      "Batch: 3865. Acc: 0.349713. Loss: 1.850782. Batch_acc: 0.369663. Batch_loss: 1.754511 \n",
      "Batch: 3866. Acc: 0.349720. Loss: 1.850758. Batch_acc: 0.379392. Batch_loss: 1.758032 \n",
      "Batch: 3867. Acc: 0.349726. Loss: 1.850741. Batch_acc: 0.374212. Batch_loss: 1.784170 \n",
      "Batch: 3868. Acc: 0.349733. Loss: 1.850719. Batch_acc: 0.374928. Batch_loss: 1.767346 \n",
      "Batch: 3869. Acc: 0.349739. Loss: 1.850701. Batch_acc: 0.373848. Batch_loss: 1.778996 \n",
      "Batch: 3870. Acc: 0.349745. Loss: 1.850670. Batch_acc: 0.374007. Batch_loss: 1.734149 \n",
      "Batch: 3871. Acc: 0.349748. Loss: 1.850657. Batch_acc: 0.358491. Batch_loss: 1.799140 \n",
      "Batch: 3872. Acc: 0.349751. Loss: 1.850648. Batch_acc: 0.360837. Batch_loss: 1.814934 \n",
      "Batch: 3873. Acc: 0.349755. Loss: 1.850624. Batch_acc: 0.367052. Batch_loss: 1.756143 \n",
      "Batch: 3874. Acc: 0.349764. Loss: 1.850600. Batch_acc: 0.383039. Batch_loss: 1.759500 \n",
      "Batch: 3875. Acc: 0.349772. Loss: 1.850584. Batch_acc: 0.383162. Batch_loss: 1.787867 \n",
      "Batch: 3876. Acc: 0.349784. Loss: 1.850549. Batch_acc: 0.393818. Batch_loss: 1.718006 \n",
      "Batch: 3877. Acc: 0.349787. Loss: 1.850538. Batch_acc: 0.364002. Batch_loss: 1.808421 \n",
      "Batch: 3878. Acc: 0.349791. Loss: 1.850522. Batch_acc: 0.362178. Batch_loss: 1.787313 \n",
      "Batch: 3879. Acc: 0.349792. Loss: 1.850505. Batch_acc: 0.354072. Batch_loss: 1.786053 \n",
      "Batch: 3880. Acc: 0.349795. Loss: 1.850484. Batch_acc: 0.361949. Batch_loss: 1.767221 \n",
      "Batch: 3881. Acc: 0.349803. Loss: 1.850454. Batch_acc: 0.380379. Batch_loss: 1.736565 \n",
      "Batch: 3882. Acc: 0.349812. Loss: 1.850420. Batch_acc: 0.385576. Batch_loss: 1.718865 \n",
      "Batch: 3883. Acc: 0.349817. Loss: 1.850393. Batch_acc: 0.369777. Batch_loss: 1.743977 \n",
      "Batch: 3884. Acc: 0.349824. Loss: 1.850377. Batch_acc: 0.375147. Batch_loss: 1.786994 \n",
      "Batch: 3885. Acc: 0.349833. Loss: 1.850352. Batch_acc: 0.384971. Batch_loss: 1.752770 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3886. Acc: 0.349830. Loss: 1.850342. Batch_acc: 0.341135. Batch_loss: 1.813420 \n",
      "Batch: 3887. Acc: 0.349838. Loss: 1.850325. Batch_acc: 0.378132. Batch_loss: 1.784279 \n",
      "Batch: 3888. Acc: 0.349841. Loss: 1.850305. Batch_acc: 0.360345. Batch_loss: 1.770621 \n",
      "Batch: 3889. Acc: 0.349848. Loss: 1.850277. Batch_acc: 0.376901. Batch_loss: 1.746296 \n",
      "Batch: 3890. Acc: 0.349852. Loss: 1.850263. Batch_acc: 0.366744. Batch_loss: 1.793715 \n",
      "Batch: 3891. Acc: 0.349859. Loss: 1.850245. Batch_acc: 0.376579. Batch_loss: 1.781813 \n",
      "Batch: 3892. Acc: 0.349863. Loss: 1.850232. Batch_acc: 0.367418. Batch_loss: 1.797824 \n",
      "Batch: 3893. Acc: 0.349871. Loss: 1.850204. Batch_acc: 0.378378. Batch_loss: 1.743412 \n",
      "Batch: 3894. Acc: 0.349877. Loss: 1.850194. Batch_acc: 0.372881. Batch_loss: 1.811186 \n",
      "Batch: 3895. Acc: 0.349881. Loss: 1.850186. Batch_acc: 0.365604. Batch_loss: 1.818094 \n",
      "Batch: 3896. Acc: 0.349887. Loss: 1.850163. Batch_acc: 0.374707. Batch_loss: 1.759699 \n",
      "Batch: 3897. Acc: 0.349897. Loss: 1.850139. Batch_acc: 0.389335. Batch_loss: 1.757230 \n",
      "Batch: 3898. Acc: 0.349897. Loss: 1.850135. Batch_acc: 0.349683. Batch_loss: 1.834153 \n",
      "Batch: 3899. Acc: 0.349903. Loss: 1.850116. Batch_acc: 0.373864. Batch_loss: 1.777315 \n",
      "Batch: 3900. Acc: 0.349908. Loss: 1.850090. Batch_acc: 0.368362. Batch_loss: 1.750462 \n",
      "Batch: 3901. Acc: 0.349910. Loss: 1.850082. Batch_acc: 0.357356. Batch_loss: 1.818387 \n",
      "Batch: 3902. Acc: 0.349913. Loss: 1.850063. Batch_acc: 0.361702. Batch_loss: 1.777499 \n",
      "Batch: 3903. Acc: 0.349916. Loss: 1.850051. Batch_acc: 0.361988. Batch_loss: 1.800925 \n",
      "Batch: 3904. Acc: 0.349922. Loss: 1.850027. Batch_acc: 0.373784. Batch_loss: 1.756564 \n",
      "Batch: 3905. Acc: 0.349928. Loss: 1.850009. Batch_acc: 0.374350. Batch_loss: 1.778472 \n",
      "Batch: 3906. Acc: 0.349936. Loss: 1.849982. Batch_acc: 0.378007. Batch_loss: 1.744653 \n",
      "Batch: 3907. Acc: 0.349941. Loss: 1.849970. Batch_acc: 0.372538. Batch_loss: 1.803333 \n",
      "Batch: 3908. Acc: 0.349943. Loss: 1.849955. Batch_acc: 0.355825. Batch_loss: 1.793592 \n",
      "Batch: 3909. Acc: 0.349951. Loss: 1.849935. Batch_acc: 0.382440. Batch_loss: 1.770231 \n",
      "Batch: 3910. Acc: 0.349955. Loss: 1.849923. Batch_acc: 0.367264. Batch_loss: 1.800854 \n",
      "Batch: 3911. Acc: 0.349961. Loss: 1.849908. Batch_acc: 0.370949. Batch_loss: 1.790019 \n",
      "Batch: 3912. Acc: 0.349970. Loss: 1.849875. Batch_acc: 0.385465. Batch_loss: 1.721889 \n",
      "Batch: 3913. Acc: 0.349977. Loss: 1.849857. Batch_acc: 0.378394. Batch_loss: 1.779173 \n",
      "Batch: 3914. Acc: 0.349982. Loss: 1.849836. Batch_acc: 0.369629. Batch_loss: 1.763184 \n",
      "Batch: 3915. Acc: 0.349990. Loss: 1.849807. Batch_acc: 0.380551. Batch_loss: 1.739895 \n",
      "Batch: 3916. Acc: 0.349996. Loss: 1.849783. Batch_acc: 0.372039. Batch_loss: 1.757687 \n",
      "Batch: 3917. Acc: 0.350004. Loss: 1.849757. Batch_acc: 0.381496. Batch_loss: 1.747048 \n",
      "Batch: 3918. Acc: 0.350012. Loss: 1.849732. Batch_acc: 0.381479. Batch_loss: 1.752094 \n",
      "Batch: 3919. Acc: 0.350020. Loss: 1.849711. Batch_acc: 0.381526. Batch_loss: 1.765273 \n",
      "Batch: 3920. Acc: 0.350021. Loss: 1.849696. Batch_acc: 0.356069. Batch_loss: 1.792783 \n",
      "Batch: 3921. Acc: 0.350027. Loss: 1.849675. Batch_acc: 0.372414. Batch_loss: 1.767845 \n",
      "Batch: 3922. Acc: 0.350037. Loss: 1.849652. Batch_acc: 0.389937. Batch_loss: 1.758070 \n",
      "Batch: 3923. Acc: 0.350042. Loss: 1.849637. Batch_acc: 0.371749. Batch_loss: 1.791239 \n",
      "Batch: 3924. Acc: 0.350049. Loss: 1.849622. Batch_acc: 0.375927. Batch_loss: 1.789925 \n",
      "Batch: 3925. Acc: 0.350059. Loss: 1.849588. Batch_acc: 0.387592. Batch_loss: 1.717146 \n",
      "Batch: 3926. Acc: 0.350064. Loss: 1.849574. Batch_acc: 0.372583. Batch_loss: 1.794098 \n",
      "Batch: 3927. Acc: 0.350072. Loss: 1.849556. Batch_acc: 0.379813. Batch_loss: 1.778884 \n",
      "Batch: 3928. Acc: 0.350078. Loss: 1.849535. Batch_acc: 0.372526. Batch_loss: 1.764291 \n",
      "Batch: 3929. Acc: 0.350080. Loss: 1.849524. Batch_acc: 0.358218. Batch_loss: 1.806458 \n",
      "Batch: 3930. Acc: 0.350084. Loss: 1.849511. Batch_acc: 0.367823. Batch_loss: 1.797781 \n",
      "Batch: 3931. Acc: 0.350088. Loss: 1.849497. Batch_acc: 0.367407. Batch_loss: 1.790582 \n",
      "Batch: 3932. Acc: 0.350091. Loss: 1.849480. Batch_acc: 0.361714. Batch_loss: 1.783033 \n",
      "Batch: 3933. Acc: 0.350102. Loss: 1.849451. Batch_acc: 0.390706. Batch_loss: 1.738984 \n",
      "Batch: 3934. Acc: 0.350112. Loss: 1.849425. Batch_acc: 0.388921. Batch_loss: 1.745862 \n",
      "Batch: 3935. Acc: 0.350118. Loss: 1.849406. Batch_acc: 0.374279. Batch_loss: 1.773248 \n",
      "Batch: 3936. Acc: 0.350127. Loss: 1.849383. Batch_acc: 0.386167. Batch_loss: 1.761574 \n",
      "Batch: 3937. Acc: 0.350132. Loss: 1.849364. Batch_acc: 0.369292. Batch_loss: 1.773912 \n",
      "Batch: 3938. Acc: 0.350136. Loss: 1.849349. Batch_acc: 0.366724. Batch_loss: 1.789088 \n",
      "Batch: 3939. Acc: 0.350142. Loss: 1.849321. Batch_acc: 0.374633. Batch_loss: 1.737583 \n",
      "Batch: 3940. Acc: 0.350149. Loss: 1.849296. Batch_acc: 0.378664. Batch_loss: 1.748110 \n",
      "Batch: 3941. Acc: 0.350159. Loss: 1.849273. Batch_acc: 0.387493. Batch_loss: 1.762085 \n",
      "Batch: 3942. Acc: 0.350159. Loss: 1.849264. Batch_acc: 0.352526. Batch_loss: 1.814947 \n",
      "Batch: 3943. Acc: 0.350165. Loss: 1.849248. Batch_acc: 0.372297. Batch_loss: 1.782587 \n",
      "Batch: 3944. Acc: 0.350173. Loss: 1.849222. Batch_acc: 0.382737. Batch_loss: 1.748946 \n",
      "Batch: 3945. Acc: 0.350178. Loss: 1.849205. Batch_acc: 0.369104. Batch_loss: 1.778577 \n",
      "Batch: 3946. Acc: 0.350186. Loss: 1.849185. Batch_acc: 0.381425. Batch_loss: 1.772371 \n",
      "Batch: 3947. Acc: 0.350194. Loss: 1.849163. Batch_acc: 0.381115. Batch_loss: 1.763703 \n",
      "Batch: 3948. Acc: 0.350197. Loss: 1.849145. Batch_acc: 0.363268. Batch_loss: 1.774481 \n",
      "Batch: 3949. Acc: 0.350205. Loss: 1.849114. Batch_acc: 0.380979. Batch_loss: 1.732764 \n",
      "Batch: 3950. Acc: 0.350211. Loss: 1.849095. Batch_acc: 0.371788. Batch_loss: 1.775215 \n",
      "Batch: 3951. Acc: 0.350218. Loss: 1.849073. Batch_acc: 0.380364. Batch_loss: 1.758754 \n",
      "Batch: 3952. Acc: 0.350227. Loss: 1.849045. Batch_acc: 0.386105. Batch_loss: 1.738167 \n",
      "Batch: 3953. Acc: 0.350233. Loss: 1.849015. Batch_acc: 0.370685. Batch_loss: 1.734517 \n",
      "Batch: 3954. Acc: 0.350237. Loss: 1.849002. Batch_acc: 0.367501. Batch_loss: 1.795112 \n",
      "Batch: 3955. Acc: 0.350245. Loss: 1.848979. Batch_acc: 0.381336. Batch_loss: 1.757483 \n",
      "Batch: 3956. Acc: 0.350249. Loss: 1.848965. Batch_acc: 0.368267. Batch_loss: 1.794163 \n",
      "Batch: 3957. Acc: 0.350253. Loss: 1.848951. Batch_acc: 0.366857. Batch_loss: 1.793062 \n",
      "Batch: 3958. Acc: 0.350261. Loss: 1.848927. Batch_acc: 0.380526. Batch_loss: 1.757660 \n",
      "Batch: 3959. Acc: 0.350267. Loss: 1.848905. Batch_acc: 0.373536. Batch_loss: 1.757682 \n",
      "Batch: 3960. Acc: 0.350271. Loss: 1.848888. Batch_acc: 0.365329. Batch_loss: 1.781051 \n",
      "Batch: 3961. Acc: 0.350278. Loss: 1.848865. Batch_acc: 0.380571. Batch_loss: 1.758492 \n",
      "Batch: 3962. Acc: 0.350283. Loss: 1.848838. Batch_acc: 0.366229. Batch_loss: 1.743493 \n",
      "Batch: 3963. Acc: 0.350285. Loss: 1.848821. Batch_acc: 0.361392. Batch_loss: 1.783299 \n",
      "Batch: 3964. Acc: 0.350289. Loss: 1.848803. Batch_acc: 0.364566. Batch_loss: 1.778370 \n",
      "Batch: 3965. Acc: 0.350293. Loss: 1.848779. Batch_acc: 0.366761. Batch_loss: 1.756214 \n",
      "Batch: 3966. Acc: 0.350302. Loss: 1.848751. Batch_acc: 0.386243. Batch_loss: 1.735317 \n",
      "Batch: 3967. Acc: 0.350315. Loss: 1.848723. Batch_acc: 0.398973. Batch_loss: 1.738388 \n",
      "Batch: 3968. Acc: 0.350318. Loss: 1.848711. Batch_acc: 0.365061. Batch_loss: 1.799351 \n",
      "Batch: 3969. Acc: 0.350326. Loss: 1.848688. Batch_acc: 0.379624. Batch_loss: 1.758612 \n",
      "Batch: 3970. Acc: 0.350337. Loss: 1.848661. Batch_acc: 0.395097. Batch_loss: 1.743571 \n",
      "Batch: 3971. Acc: 0.350345. Loss: 1.848643. Batch_acc: 0.380011. Batch_loss: 1.777790 \n",
      "Batch: 3972. Acc: 0.350352. Loss: 1.848619. Batch_acc: 0.380516. Batch_loss: 1.753962 \n",
      "Batch: 3973. Acc: 0.350357. Loss: 1.848606. Batch_acc: 0.370629. Batch_loss: 1.795253 \n",
      "Batch: 3974. Acc: 0.350364. Loss: 1.848584. Batch_acc: 0.377369. Batch_loss: 1.761206 \n",
      "Batch: 3975. Acc: 0.350375. Loss: 1.848555. Batch_acc: 0.391453. Batch_loss: 1.736195 \n",
      "Batch: 3976. Acc: 0.350380. Loss: 1.848532. Batch_acc: 0.371412. Batch_loss: 1.755410 \n",
      "Batch: 3977. Acc: 0.350383. Loss: 1.848516. Batch_acc: 0.361221. Batch_loss: 1.784378 \n",
      "Batch: 3978. Acc: 0.350387. Loss: 1.848494. Batch_acc: 0.366778. Batch_loss: 1.764696 \n",
      "Batch: 3979. Acc: 0.350395. Loss: 1.848466. Batch_acc: 0.381989. Batch_loss: 1.733612 \n",
      "Batch: 3980. Acc: 0.350395. Loss: 1.848462. Batch_acc: 0.351412. Batch_loss: 1.833205 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3981. Acc: 0.350399. Loss: 1.848453. Batch_acc: 0.369006. Batch_loss: 1.812710 \n",
      "Batch: 3982. Acc: 0.350405. Loss: 1.848427. Batch_acc: 0.374134. Batch_loss: 1.743236 \n",
      "Batch: 3983. Acc: 0.350414. Loss: 1.848403. Batch_acc: 0.384046. Batch_loss: 1.753074 \n",
      "Batch: 3984. Acc: 0.350421. Loss: 1.848374. Batch_acc: 0.378180. Batch_loss: 1.737536 \n",
      "Batch: 3985. Acc: 0.350424. Loss: 1.848363. Batch_acc: 0.364286. Batch_loss: 1.803329 \n",
      "Batch: 3986. Acc: 0.350432. Loss: 1.848333. Batch_acc: 0.378813. Batch_loss: 1.733770 \n",
      "Batch: 3987. Acc: 0.350438. Loss: 1.848315. Batch_acc: 0.373737. Batch_loss: 1.776672 \n",
      "Batch: 3988. Acc: 0.350448. Loss: 1.848279. Batch_acc: 0.392434. Batch_loss: 1.707945 \n",
      "Batch: 3989. Acc: 0.350453. Loss: 1.848249. Batch_acc: 0.369021. Batch_loss: 1.727960 \n",
      "Batch: 3990. Acc: 0.350457. Loss: 1.848236. Batch_acc: 0.364740. Batch_loss: 1.797609 \n",
      "Batch: 3991. Acc: 0.350460. Loss: 1.848225. Batch_acc: 0.363949. Batch_loss: 1.805134 \n",
      "Batch: 3992. Acc: 0.350463. Loss: 1.848208. Batch_acc: 0.363164. Batch_loss: 1.777604 \n",
      "Batch: 3993. Acc: 0.350470. Loss: 1.848187. Batch_acc: 0.375357. Batch_loss: 1.764521 \n",
      "Batch: 3994. Acc: 0.350473. Loss: 1.848173. Batch_acc: 0.363743. Batch_loss: 1.792866 \n",
      "Batch: 3995. Acc: 0.350480. Loss: 1.848144. Batch_acc: 0.381395. Batch_loss: 1.730027 \n",
      "Batch: 3996. Acc: 0.350479. Loss: 1.848139. Batch_acc: 0.344669. Batch_loss: 1.830890 \n",
      "Batch: 3997. Acc: 0.350489. Loss: 1.848116. Batch_acc: 0.389966. Batch_loss: 1.756645 \n",
      "Batch: 3998. Acc: 0.350497. Loss: 1.848091. Batch_acc: 0.381113. Batch_loss: 1.750567 \n",
      "Batch: 3999. Acc: 0.350507. Loss: 1.848063. Batch_acc: 0.390079. Batch_loss: 1.737347 \n",
      "Batch: 4000. Acc: 0.350511. Loss: 1.848042. Batch_acc: 0.367103. Batch_loss: 1.765861 \n",
      "Batch: 4001. Acc: 0.350512. Loss: 1.848034. Batch_acc: 0.354460. Batch_loss: 1.813676 \n",
      "Batch: 4002. Acc: 0.350522. Loss: 1.848004. Batch_acc: 0.388289. Batch_loss: 1.729457 \n",
      "Batch: 4003. Acc: 0.350528. Loss: 1.847986. Batch_acc: 0.378238. Batch_loss: 1.775882 \n",
      "Batch: 4004. Acc: 0.350537. Loss: 1.847948. Batch_acc: 0.384401. Batch_loss: 1.699855 \n",
      "Batch: 4005. Acc: 0.350542. Loss: 1.847928. Batch_acc: 0.369639. Batch_loss: 1.768145 \n",
      "Batch: 4006. Acc: 0.350551. Loss: 1.847903. Batch_acc: 0.386531. Batch_loss: 1.752766 \n",
      "Batch: 4007. Acc: 0.350563. Loss: 1.847877. Batch_acc: 0.398210. Batch_loss: 1.744258 \n",
      "Batch: 4008. Acc: 0.350568. Loss: 1.847862. Batch_acc: 0.367639. Batch_loss: 1.788582 \n",
      "Batch: 4009. Acc: 0.350576. Loss: 1.847837. Batch_acc: 0.384484. Batch_loss: 1.749311 \n",
      "Batch: 4010. Acc: 0.350579. Loss: 1.847827. Batch_acc: 0.360397. Batch_loss: 1.808048 \n",
      "Batch: 4011. Acc: 0.350587. Loss: 1.847798. Batch_acc: 0.384484. Batch_loss: 1.729956 \n",
      "Batch: 4012. Acc: 0.350594. Loss: 1.847773. Batch_acc: 0.377700. Batch_loss: 1.745241 \n",
      "Batch: 4013. Acc: 0.350597. Loss: 1.847759. Batch_acc: 0.363793. Batch_loss: 1.793909 \n",
      "Batch: 4014. Acc: 0.350601. Loss: 1.847749. Batch_acc: 0.364625. Batch_loss: 1.805394 \n",
      "Batch: 4015. Acc: 0.350607. Loss: 1.847717. Batch_acc: 0.376277. Batch_loss: 1.724537 \n",
      "Batch: 4016. Acc: 0.350609. Loss: 1.847707. Batch_acc: 0.358944. Batch_loss: 1.802496 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.35060911084451285. Loss per char: 1.8477066352855405. Time: 1627209655.7327123\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 23, 24, 21, 15, 22, 25, 19, 20, 26,\n",
      "         1, 14,  1, 20, 23, 21, 24, 24, 25, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.350613. Loss: 1.847691. Batch_acc: 0.367526. Batch_loss: 1.783724 \n",
      "Batch: 4018. Acc: 0.350620. Loss: 1.847671. Batch_acc: 0.379127. Batch_loss: 1.764946 \n",
      "Batch: 4019. Acc: 0.350628. Loss: 1.847647. Batch_acc: 0.381871. Batch_loss: 1.751173 \n",
      "Batch: 4020. Acc: 0.350632. Loss: 1.847622. Batch_acc: 0.368116. Batch_loss: 1.744059 \n",
      "Batch: 4021. Acc: 0.350639. Loss: 1.847600. Batch_acc: 0.378271. Batch_loss: 1.762055 \n",
      "Batch: 4022. Acc: 0.350649. Loss: 1.847564. Batch_acc: 0.390940. Batch_loss: 1.705599 \n",
      "Batch: 4023. Acc: 0.350661. Loss: 1.847532. Batch_acc: 0.397332. Batch_loss: 1.718745 \n",
      "Batch: 4024. Acc: 0.350668. Loss: 1.847510. Batch_acc: 0.379587. Batch_loss: 1.758600 \n",
      "Batch: 4025. Acc: 0.350674. Loss: 1.847486. Batch_acc: 0.373487. Batch_loss: 1.752349 \n",
      "Batch: 4026. Acc: 0.350681. Loss: 1.847457. Batch_acc: 0.381228. Batch_loss: 1.729168 \n",
      "Batch: 4027. Acc: 0.350688. Loss: 1.847432. Batch_acc: 0.377153. Batch_loss: 1.744238 \n",
      "Batch: 4028. Acc: 0.350690. Loss: 1.847418. Batch_acc: 0.359246. Batch_loss: 1.791314 \n",
      "Batch: 4029. Acc: 0.350697. Loss: 1.847396. Batch_acc: 0.377545. Batch_loss: 1.759496 \n",
      "Batch: 4030. Acc: 0.350700. Loss: 1.847377. Batch_acc: 0.366222. Batch_loss: 1.767715 \n",
      "Batch: 4031. Acc: 0.350706. Loss: 1.847360. Batch_acc: 0.372861. Batch_loss: 1.778605 \n",
      "Batch: 4032. Acc: 0.350708. Loss: 1.847345. Batch_acc: 0.361739. Batch_loss: 1.784157 \n",
      "Batch: 4033. Acc: 0.350711. Loss: 1.847328. Batch_acc: 0.361432. Batch_loss: 1.780210 \n",
      "Batch: 4034. Acc: 0.350715. Loss: 1.847308. Batch_acc: 0.367418. Batch_loss: 1.767517 \n",
      "Batch: 4035. Acc: 0.350722. Loss: 1.847288. Batch_acc: 0.379230. Batch_loss: 1.765242 \n",
      "Batch: 4036. Acc: 0.350726. Loss: 1.847271. Batch_acc: 0.366825. Batch_loss: 1.776337 \n",
      "Batch: 4037. Acc: 0.350732. Loss: 1.847248. Batch_acc: 0.373874. Batch_loss: 1.754776 \n",
      "Batch: 4038. Acc: 0.350743. Loss: 1.847224. Batch_acc: 0.394554. Batch_loss: 1.750277 \n",
      "Batch: 4039. Acc: 0.350748. Loss: 1.847212. Batch_acc: 0.374113. Batch_loss: 1.796540 \n",
      "Batch: 4040. Acc: 0.350751. Loss: 1.847193. Batch_acc: 0.361565. Batch_loss: 1.769728 \n",
      "Batch: 4041. Acc: 0.350755. Loss: 1.847176. Batch_acc: 0.366092. Batch_loss: 1.776656 \n",
      "Batch: 4042. Acc: 0.350756. Loss: 1.847165. Batch_acc: 0.355543. Batch_loss: 1.804566 \n",
      "Batch: 4043. Acc: 0.350759. Loss: 1.847148. Batch_acc: 0.363014. Batch_loss: 1.781594 \n",
      "Batch: 4044. Acc: 0.350764. Loss: 1.847133. Batch_acc: 0.372161. Batch_loss: 1.785054 \n",
      "Batch: 4045. Acc: 0.350770. Loss: 1.847110. Batch_acc: 0.374490. Batch_loss: 1.753590 \n",
      "Batch: 4046. Acc: 0.350777. Loss: 1.847087. Batch_acc: 0.378668. Batch_loss: 1.753485 \n",
      "Batch: 4047. Acc: 0.350783. Loss: 1.847073. Batch_acc: 0.373403. Batch_loss: 1.790552 \n",
      "Batch: 4048. Acc: 0.350789. Loss: 1.847045. Batch_acc: 0.375214. Batch_loss: 1.735309 \n",
      "Batch: 4049. Acc: 0.350795. Loss: 1.847018. Batch_acc: 0.377904. Batch_loss: 1.740749 \n",
      "Batch: 4050. Acc: 0.350801. Loss: 1.846998. Batch_acc: 0.372717. Batch_loss: 1.765641 \n",
      "Batch: 4051. Acc: 0.350807. Loss: 1.846979. Batch_acc: 0.377672. Batch_loss: 1.767060 \n",
      "Batch: 4052. Acc: 0.350813. Loss: 1.846962. Batch_acc: 0.373798. Batch_loss: 1.774323 \n",
      "Batch: 4053. Acc: 0.350821. Loss: 1.846936. Batch_acc: 0.382844. Batch_loss: 1.741951 \n",
      "Batch: 4054. Acc: 0.350824. Loss: 1.846915. Batch_acc: 0.365654. Batch_loss: 1.762028 \n",
      "Batch: 4055. Acc: 0.350831. Loss: 1.846892. Batch_acc: 0.376910. Batch_loss: 1.755201 \n",
      "Batch: 4056. Acc: 0.350834. Loss: 1.846866. Batch_acc: 0.365340. Batch_loss: 1.736056 \n",
      "Batch: 4057. Acc: 0.350845. Loss: 1.846832. Batch_acc: 0.394857. Batch_loss: 1.712536 \n",
      "Batch: 4058. Acc: 0.350852. Loss: 1.846812. Batch_acc: 0.379532. Batch_loss: 1.762233 \n",
      "Batch: 4059. Acc: 0.350857. Loss: 1.846789. Batch_acc: 0.371656. Batch_loss: 1.754853 \n",
      "Batch: 4060. Acc: 0.350868. Loss: 1.846760. Batch_acc: 0.393701. Batch_loss: 1.732899 \n",
      "Batch: 4061. Acc: 0.350872. Loss: 1.846744. Batch_acc: 0.364976. Batch_loss: 1.781135 \n",
      "Batch: 4062. Acc: 0.350877. Loss: 1.846725. Batch_acc: 0.374787. Batch_loss: 1.770427 \n",
      "Batch: 4063. Acc: 0.350885. Loss: 1.846698. Batch_acc: 0.379661. Batch_loss: 1.738081 \n",
      "Batch: 4064. Acc: 0.350894. Loss: 1.846671. Batch_acc: 0.389114. Batch_loss: 1.736292 \n",
      "Batch: 4065. Acc: 0.350898. Loss: 1.846648. Batch_acc: 0.368573. Batch_loss: 1.751860 \n",
      "Batch: 4066. Acc: 0.350903. Loss: 1.846629. Batch_acc: 0.368005. Batch_loss: 1.769668 \n",
      "Batch: 4067. Acc: 0.350904. Loss: 1.846613. Batch_acc: 0.356930. Batch_loss: 1.778457 \n",
      "Batch: 4068. Acc: 0.350913. Loss: 1.846585. Batch_acc: 0.385011. Batch_loss: 1.733993 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4069. Acc: 0.350920. Loss: 1.846559. Batch_acc: 0.381361. Batch_loss: 1.742815 \n",
      "Batch: 4070. Acc: 0.350928. Loss: 1.846538. Batch_acc: 0.381977. Batch_loss: 1.760179 \n",
      "Batch: 4071. Acc: 0.350938. Loss: 1.846510. Batch_acc: 0.394181. Batch_loss: 1.731626 \n",
      "Batch: 4072. Acc: 0.350942. Loss: 1.846494. Batch_acc: 0.365252. Batch_loss: 1.784169 \n",
      "Batch: 4073. Acc: 0.350945. Loss: 1.846479. Batch_acc: 0.364108. Batch_loss: 1.783799 \n",
      "Batch: 4074. Acc: 0.350953. Loss: 1.846456. Batch_acc: 0.382942. Batch_loss: 1.753148 \n",
      "Batch: 4075. Acc: 0.350962. Loss: 1.846423. Batch_acc: 0.388249. Batch_loss: 1.710899 \n",
      "Batch: 4076. Acc: 0.350973. Loss: 1.846387. Batch_acc: 0.396780. Batch_loss: 1.701538 \n",
      "Batch: 4077. Acc: 0.350980. Loss: 1.846360. Batch_acc: 0.378830. Batch_loss: 1.741088 \n",
      "Batch: 4078. Acc: 0.350984. Loss: 1.846346. Batch_acc: 0.367052. Batch_loss: 1.787832 \n",
      "Batch: 4079. Acc: 0.350990. Loss: 1.846320. Batch_acc: 0.374208. Batch_loss: 1.739734 \n",
      "Batch: 4080. Acc: 0.350993. Loss: 1.846293. Batch_acc: 0.364524. Batch_loss: 1.735888 \n",
      "Batch: 4081. Acc: 0.350994. Loss: 1.846281. Batch_acc: 0.354802. Batch_loss: 1.796705 \n",
      "Batch: 4082. Acc: 0.350999. Loss: 1.846263. Batch_acc: 0.369266. Batch_loss: 1.772922 \n",
      "Batch: 4083. Acc: 0.351003. Loss: 1.846248. Batch_acc: 0.367723. Batch_loss: 1.784869 \n",
      "Batch: 4084. Acc: 0.351009. Loss: 1.846220. Batch_acc: 0.376167. Batch_loss: 1.738424 \n",
      "Batch: 4085. Acc: 0.351017. Loss: 1.846201. Batch_acc: 0.382554. Batch_loss: 1.770495 \n",
      "Batch: 4086. Acc: 0.351017. Loss: 1.846194. Batch_acc: 0.352571. Batch_loss: 1.817962 \n",
      "Batch: 4087. Acc: 0.351015. Loss: 1.846196. Batch_acc: 0.340621. Batch_loss: 1.854245 \n",
      "Batch: 4088. Acc: 0.351020. Loss: 1.846178. Batch_acc: 0.370865. Batch_loss: 1.770420 \n",
      "Batch: 4089. Acc: 0.351026. Loss: 1.846157. Batch_acc: 0.376518. Batch_loss: 1.758722 \n",
      "Batch: 4090. Acc: 0.351035. Loss: 1.846131. Batch_acc: 0.385255. Batch_loss: 1.743841 \n",
      "Batch: 4091. Acc: 0.351037. Loss: 1.846121. Batch_acc: 0.361045. Batch_loss: 1.804246 \n",
      "Batch: 4092. Acc: 0.351041. Loss: 1.846103. Batch_acc: 0.366269. Batch_loss: 1.774021 \n",
      "Batch: 4093. Acc: 0.351047. Loss: 1.846079. Batch_acc: 0.376846. Batch_loss: 1.745460 \n",
      "Batch: 4094. Acc: 0.351049. Loss: 1.846066. Batch_acc: 0.360571. Batch_loss: 1.793049 \n",
      "Batch: 4095. Acc: 0.351051. Loss: 1.846060. Batch_acc: 0.356395. Batch_loss: 1.820594 \n",
      "Batch: 4096. Acc: 0.351057. Loss: 1.846039. Batch_acc: 0.378521. Batch_loss: 1.758366 \n",
      "Batch: 4097. Acc: 0.351056. Loss: 1.846025. Batch_acc: 0.345821. Batch_loss: 1.789809 \n",
      "Batch: 4098. Acc: 0.351065. Loss: 1.845992. Batch_acc: 0.387152. Batch_loss: 1.712873 \n",
      "Batch: 4099. Acc: 0.351066. Loss: 1.845981. Batch_acc: 0.354895. Batch_loss: 1.797214 \n",
      "Batch: 4100. Acc: 0.351075. Loss: 1.845955. Batch_acc: 0.388823. Batch_loss: 1.736575 \n",
      "Batch: 4101. Acc: 0.351079. Loss: 1.845934. Batch_acc: 0.367630. Batch_loss: 1.761557 \n",
      "Batch: 4102. Acc: 0.351083. Loss: 1.845909. Batch_acc: 0.369292. Batch_loss: 1.744249 \n",
      "Batch: 4103. Acc: 0.351085. Loss: 1.845900. Batch_acc: 0.357539. Batch_loss: 1.806739 \n",
      "Batch: 4104. Acc: 0.351094. Loss: 1.845875. Batch_acc: 0.388792. Batch_loss: 1.745733 \n",
      "Batch: 4105. Acc: 0.351101. Loss: 1.845852. Batch_acc: 0.380224. Batch_loss: 1.746050 \n",
      "Batch: 4106. Acc: 0.351107. Loss: 1.845823. Batch_acc: 0.374861. Batch_loss: 1.732608 \n",
      "Batch: 4107. Acc: 0.351111. Loss: 1.845800. Batch_acc: 0.369275. Batch_loss: 1.750348 \n",
      "Batch: 4108. Acc: 0.351117. Loss: 1.845781. Batch_acc: 0.374122. Batch_loss: 1.766086 \n",
      "Batch: 4109. Acc: 0.351126. Loss: 1.845746. Batch_acc: 0.388546. Batch_loss: 1.706396 \n",
      "Batch: 4110. Acc: 0.351134. Loss: 1.845720. Batch_acc: 0.385440. Batch_loss: 1.739600 \n",
      "Batch: 4111. Acc: 0.351142. Loss: 1.845686. Batch_acc: 0.383053. Batch_loss: 1.702632 \n",
      "Batch: 4112. Acc: 0.351149. Loss: 1.845663. Batch_acc: 0.380491. Batch_loss: 1.752164 \n",
      "Batch: 4113. Acc: 0.351155. Loss: 1.845635. Batch_acc: 0.373272. Batch_loss: 1.733771 \n",
      "Batch: 4114. Acc: 0.351160. Loss: 1.845613. Batch_acc: 0.371591. Batch_loss: 1.753960 \n",
      "Batch: 4115. Acc: 0.351166. Loss: 1.845594. Batch_acc: 0.378664. Batch_loss: 1.765121 \n",
      "Batch: 4116. Acc: 0.351177. Loss: 1.845559. Batch_acc: 0.393277. Batch_loss: 1.708380 \n",
      "Batch: 4117. Acc: 0.351182. Loss: 1.845539. Batch_acc: 0.372901. Batch_loss: 1.759881 \n",
      "Batch: 4118. Acc: 0.351194. Loss: 1.845509. Batch_acc: 0.400114. Batch_loss: 1.721856 \n",
      "Batch: 4119. Acc: 0.351198. Loss: 1.845495. Batch_acc: 0.370220. Batch_loss: 1.790207 \n",
      "Batch: 4120. Acc: 0.351205. Loss: 1.845473. Batch_acc: 0.377414. Batch_loss: 1.753691 \n",
      "Batch: 4121. Acc: 0.351209. Loss: 1.845456. Batch_acc: 0.368999. Batch_loss: 1.773466 \n",
      "Batch: 4122. Acc: 0.351219. Loss: 1.845428. Batch_acc: 0.392555. Batch_loss: 1.731452 \n",
      "Batch: 4123. Acc: 0.351227. Loss: 1.845406. Batch_acc: 0.382604. Batch_loss: 1.757258 \n",
      "Batch: 4124. Acc: 0.351238. Loss: 1.845369. Batch_acc: 0.395728. Batch_loss: 1.694020 \n",
      "Batch: 4125. Acc: 0.351243. Loss: 1.845353. Batch_acc: 0.372571. Batch_loss: 1.779608 \n",
      "Batch: 4126. Acc: 0.351250. Loss: 1.845328. Batch_acc: 0.379651. Batch_loss: 1.744351 \n",
      "Batch: 4127. Acc: 0.351256. Loss: 1.845308. Batch_acc: 0.378205. Batch_loss: 1.761956 \n",
      "Batch: 4128. Acc: 0.351266. Loss: 1.845286. Batch_acc: 0.390698. Batch_loss: 1.753086 \n",
      "Batch: 4129. Acc: 0.351271. Loss: 1.845266. Batch_acc: 0.374481. Batch_loss: 1.760443 \n",
      "Batch: 4130. Acc: 0.351278. Loss: 1.845244. Batch_acc: 0.379092. Batch_loss: 1.751960 \n",
      "Batch: 4131. Acc: 0.351283. Loss: 1.845222. Batch_acc: 0.371134. Batch_loss: 1.757188 \n",
      "Batch: 4132. Acc: 0.351287. Loss: 1.845210. Batch_acc: 0.366800. Batch_loss: 1.794573 \n",
      "Batch: 4133. Acc: 0.351293. Loss: 1.845190. Batch_acc: 0.377980. Batch_loss: 1.763128 \n",
      "Batch: 4134. Acc: 0.351301. Loss: 1.845164. Batch_acc: 0.383884. Batch_loss: 1.740603 \n",
      "Batch: 4135. Acc: 0.351302. Loss: 1.845150. Batch_acc: 0.355309. Batch_loss: 1.788576 \n",
      "Batch: 4136. Acc: 0.351310. Loss: 1.845135. Batch_acc: 0.383140. Batch_loss: 1.780319 \n",
      "Batch: 4137. Acc: 0.351314. Loss: 1.845118. Batch_acc: 0.367015. Batch_loss: 1.775737 \n",
      "Batch: 4138. Acc: 0.351322. Loss: 1.845090. Batch_acc: 0.385763. Batch_loss: 1.729018 \n",
      "Batch: 4139. Acc: 0.351329. Loss: 1.845064. Batch_acc: 0.379930. Batch_loss: 1.734150 \n",
      "Batch: 4140. Acc: 0.351335. Loss: 1.845041. Batch_acc: 0.374506. Batch_loss: 1.751738 \n",
      "Batch: 4141. Acc: 0.351341. Loss: 1.845011. Batch_acc: 0.378084. Batch_loss: 1.721119 \n",
      "Batch: 4142. Acc: 0.351345. Loss: 1.844989. Batch_acc: 0.368932. Batch_loss: 1.755974 \n",
      "Batch: 4143. Acc: 0.351350. Loss: 1.844966. Batch_acc: 0.372639. Batch_loss: 1.750249 \n",
      "Batch: 4144. Acc: 0.351356. Loss: 1.844946. Batch_acc: 0.374050. Batch_loss: 1.760278 \n",
      "Batch: 4145. Acc: 0.351371. Loss: 1.844910. Batch_acc: 0.412478. Batch_loss: 1.695420 \n",
      "Batch: 4146. Acc: 0.351382. Loss: 1.844874. Batch_acc: 0.395939. Batch_loss: 1.699768 \n",
      "Batch: 4147. Acc: 0.351384. Loss: 1.844860. Batch_acc: 0.363218. Batch_loss: 1.784912 \n",
      "Batch: 4148. Acc: 0.351390. Loss: 1.844841. Batch_acc: 0.376350. Batch_loss: 1.767140 \n",
      "Batch: 4149. Acc: 0.351394. Loss: 1.844829. Batch_acc: 0.365953. Batch_loss: 1.797001 \n",
      "Batch: 4150. Acc: 0.351399. Loss: 1.844811. Batch_acc: 0.372414. Batch_loss: 1.768372 \n",
      "Batch: 4151. Acc: 0.351407. Loss: 1.844787. Batch_acc: 0.381726. Batch_loss: 1.749508 \n",
      "Batch: 4152. Acc: 0.351412. Loss: 1.844763. Batch_acc: 0.374927. Batch_loss: 1.741161 \n",
      "Batch: 4153. Acc: 0.351419. Loss: 1.844739. Batch_acc: 0.378348. Batch_loss: 1.747039 \n",
      "Batch: 4154. Acc: 0.351425. Loss: 1.844720. Batch_acc: 0.375723. Batch_loss: 1.765106 \n",
      "Batch: 4155. Acc: 0.351427. Loss: 1.844707. Batch_acc: 0.362242. Batch_loss: 1.790278 \n",
      "Batch: 4156. Acc: 0.351431. Loss: 1.844692. Batch_acc: 0.368938. Batch_loss: 1.783064 \n",
      "Batch: 4157. Acc: 0.351440. Loss: 1.844670. Batch_acc: 0.386246. Batch_loss: 1.751074 \n",
      "Batch: 4158. Acc: 0.351445. Loss: 1.844653. Batch_acc: 0.374046. Batch_loss: 1.771700 \n",
      "Batch: 4159. Acc: 0.351452. Loss: 1.844625. Batch_acc: 0.379390. Batch_loss: 1.730317 \n",
      "Batch: 4160. Acc: 0.351458. Loss: 1.844611. Batch_acc: 0.377527. Batch_loss: 1.783968 \n",
      "Batch: 4161. Acc: 0.351468. Loss: 1.844582. Batch_acc: 0.392023. Batch_loss: 1.724659 \n",
      "Batch: 4162. Acc: 0.351468. Loss: 1.844573. Batch_acc: 0.354513. Batch_loss: 1.806577 \n",
      "Batch: 4163. Acc: 0.351470. Loss: 1.844564. Batch_acc: 0.358081. Batch_loss: 1.805567 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4164. Acc: 0.351478. Loss: 1.844540. Batch_acc: 0.385698. Batch_loss: 1.743141 \n",
      "Batch: 4165. Acc: 0.351483. Loss: 1.844513. Batch_acc: 0.371062. Batch_loss: 1.730128 \n",
      "Batch: 4166. Acc: 0.351484. Loss: 1.844505. Batch_acc: 0.355453. Batch_loss: 1.814284 \n",
      "Batch: 4167. Acc: 0.351490. Loss: 1.844485. Batch_acc: 0.377533. Batch_loss: 1.758490 \n",
      "Batch: 4168. Acc: 0.351497. Loss: 1.844459. Batch_acc: 0.382369. Batch_loss: 1.737746 \n",
      "Batch: 4169. Acc: 0.351505. Loss: 1.844437. Batch_acc: 0.385326. Batch_loss: 1.754334 \n",
      "Batch: 4170. Acc: 0.351508. Loss: 1.844424. Batch_acc: 0.361127. Batch_loss: 1.789876 \n",
      "Batch: 4171. Acc: 0.351514. Loss: 1.844408. Batch_acc: 0.378935. Batch_loss: 1.777225 \n",
      "Batch: 4172. Acc: 0.351522. Loss: 1.844388. Batch_acc: 0.383476. Batch_loss: 1.762081 \n",
      "Batch: 4173. Acc: 0.351527. Loss: 1.844371. Batch_acc: 0.371667. Batch_loss: 1.774071 \n",
      "Batch: 4174. Acc: 0.351528. Loss: 1.844360. Batch_acc: 0.357469. Batch_loss: 1.800322 \n",
      "Batch: 4175. Acc: 0.351535. Loss: 1.844334. Batch_acc: 0.379427. Batch_loss: 1.737652 \n",
      "Batch: 4176. Acc: 0.351543. Loss: 1.844315. Batch_acc: 0.382286. Batch_loss: 1.763855 \n",
      "Batch: 4177. Acc: 0.351552. Loss: 1.844283. Batch_acc: 0.389581. Batch_loss: 1.714368 \n",
      "Batch: 4178. Acc: 0.351558. Loss: 1.844261. Batch_acc: 0.378284. Batch_loss: 1.752656 \n",
      "Batch: 4179. Acc: 0.351566. Loss: 1.844232. Batch_acc: 0.381818. Batch_loss: 1.723809 \n",
      "Batch: 4180. Acc: 0.351570. Loss: 1.844213. Batch_acc: 0.370264. Batch_loss: 1.765835 \n",
      "Batch: 4181. Acc: 0.351577. Loss: 1.844184. Batch_acc: 0.381414. Batch_loss: 1.722333 \n",
      "Batch: 4182. Acc: 0.351586. Loss: 1.844154. Batch_acc: 0.387848. Batch_loss: 1.721284 \n",
      "Batch: 4183. Acc: 0.351591. Loss: 1.844137. Batch_acc: 0.374780. Batch_loss: 1.769062 \n",
      "Batch: 4184. Acc: 0.351598. Loss: 1.844119. Batch_acc: 0.377259. Batch_loss: 1.770321 \n",
      "Batch: 4185. Acc: 0.351602. Loss: 1.844099. Batch_acc: 0.369295. Batch_loss: 1.756347 \n",
      "Batch: 4186. Acc: 0.351609. Loss: 1.844070. Batch_acc: 0.382470. Batch_loss: 1.725359 \n",
      "Batch: 4187. Acc: 0.351614. Loss: 1.844047. Batch_acc: 0.370895. Batch_loss: 1.747134 \n",
      "Batch: 4188. Acc: 0.351620. Loss: 1.844023. Batch_acc: 0.377687. Batch_loss: 1.745685 \n",
      "Batch: 4189. Acc: 0.351626. Loss: 1.844007. Batch_acc: 0.376450. Batch_loss: 1.775203 \n",
      "Batch: 4190. Acc: 0.351635. Loss: 1.843980. Batch_acc: 0.388085. Batch_loss: 1.735620 \n",
      "Batch: 4191. Acc: 0.351642. Loss: 1.843960. Batch_acc: 0.379624. Batch_loss: 1.760914 \n",
      "Batch: 4192. Acc: 0.351648. Loss: 1.843938. Batch_acc: 0.380194. Batch_loss: 1.750752 \n",
      "Batch: 4193. Acc: 0.351655. Loss: 1.843920. Batch_acc: 0.379988. Batch_loss: 1.766084 \n",
      "Batch: 4194. Acc: 0.351663. Loss: 1.843891. Batch_acc: 0.383995. Batch_loss: 1.724529 \n",
      "Batch: 4195. Acc: 0.351671. Loss: 1.843866. Batch_acc: 0.387135. Batch_loss: 1.736769 \n",
      "Batch: 4196. Acc: 0.351677. Loss: 1.843847. Batch_acc: 0.377412. Batch_loss: 1.765350 \n",
      "Batch: 4197. Acc: 0.351684. Loss: 1.843827. Batch_acc: 0.378056. Batch_loss: 1.761849 \n",
      "Batch: 4198. Acc: 0.351689. Loss: 1.843808. Batch_acc: 0.371781. Batch_loss: 1.763169 \n",
      "Batch: 4199. Acc: 0.351691. Loss: 1.843790. Batch_acc: 0.363221. Batch_loss: 1.771600 \n",
      "Batch: 4200. Acc: 0.351700. Loss: 1.843768. Batch_acc: 0.387283. Batch_loss: 1.749231 \n",
      "Batch: 4201. Acc: 0.351712. Loss: 1.843728. Batch_acc: 0.401357. Batch_loss: 1.679334 \n",
      "Batch: 4202. Acc: 0.351725. Loss: 1.843687. Batch_acc: 0.405879. Batch_loss: 1.673529 \n",
      "Batch: 4203. Acc: 0.351738. Loss: 1.843651. Batch_acc: 0.407260. Batch_loss: 1.696063 \n",
      "Batch: 4204. Acc: 0.351745. Loss: 1.843627. Batch_acc: 0.378331. Batch_loss: 1.742375 \n",
      "Batch: 4205. Acc: 0.351753. Loss: 1.843595. Batch_acc: 0.386535. Batch_loss: 1.706734 \n",
      "Batch: 4206. Acc: 0.351756. Loss: 1.843578. Batch_acc: 0.364849. Batch_loss: 1.771656 \n",
      "Batch: 4207. Acc: 0.351765. Loss: 1.843547. Batch_acc: 0.388060. Batch_loss: 1.712519 \n",
      "Batch: 4208. Acc: 0.351771. Loss: 1.843517. Batch_acc: 0.379070. Batch_loss: 1.714851 \n",
      "Batch: 4209. Acc: 0.351774. Loss: 1.843498. Batch_acc: 0.363795. Batch_loss: 1.763129 \n",
      "Batch: 4210. Acc: 0.351782. Loss: 1.843474. Batch_acc: 0.384793. Batch_loss: 1.742147 \n",
      "Batch: 4211. Acc: 0.351789. Loss: 1.843445. Batch_acc: 0.383446. Batch_loss: 1.726910 \n",
      "Batch: 4212. Acc: 0.351796. Loss: 1.843427. Batch_acc: 0.377953. Batch_loss: 1.769130 \n",
      "Batch: 4213. Acc: 0.351803. Loss: 1.843402. Batch_acc: 0.383793. Batch_loss: 1.739773 \n",
      "Batch: 4214. Acc: 0.351808. Loss: 1.843378. Batch_acc: 0.368927. Batch_loss: 1.744832 \n",
      "Batch: 4215. Acc: 0.351815. Loss: 1.843358. Batch_acc: 0.381479. Batch_loss: 1.755996 \n",
      "Batch: 4216. Acc: 0.351818. Loss: 1.843339. Batch_acc: 0.366181. Batch_loss: 1.761108 \n",
      "Batch: 4217. Acc: 0.351822. Loss: 1.843320. Batch_acc: 0.369006. Batch_loss: 1.762767 \n",
      "Batch: 4218. Acc: 0.351826. Loss: 1.843295. Batch_acc: 0.370201. Batch_loss: 1.737439 \n",
      "Batch: 4219. Acc: 0.351834. Loss: 1.843266. Batch_acc: 0.384309. Batch_loss: 1.724774 \n",
      "Batch: 4220. Acc: 0.351838. Loss: 1.843250. Batch_acc: 0.366532. Batch_loss: 1.772776 \n",
      "Batch: 4221. Acc: 0.351841. Loss: 1.843233. Batch_acc: 0.364475. Batch_loss: 1.772371 \n",
      "Batch: 4222. Acc: 0.351847. Loss: 1.843209. Batch_acc: 0.377316. Batch_loss: 1.746307 \n",
      "Batch: 4223. Acc: 0.351851. Loss: 1.843194. Batch_acc: 0.370654. Batch_loss: 1.774711 \n",
      "Batch: 4224. Acc: 0.351859. Loss: 1.843165. Batch_acc: 0.384971. Batch_loss: 1.722913 \n",
      "Batch: 4225. Acc: 0.351868. Loss: 1.843138. Batch_acc: 0.389177. Batch_loss: 1.728478 \n",
      "Batch: 4226. Acc: 0.351876. Loss: 1.843108. Batch_acc: 0.386521. Batch_loss: 1.713460 \n",
      "Batch: 4227. Acc: 0.351882. Loss: 1.843086. Batch_acc: 0.377586. Batch_loss: 1.753481 \n",
      "Batch: 4228. Acc: 0.351887. Loss: 1.843064. Batch_acc: 0.372805. Batch_loss: 1.749728 \n",
      "Batch: 4229. Acc: 0.351894. Loss: 1.843043. Batch_acc: 0.383324. Batch_loss: 1.755190 \n",
      "Batch: 4230. Acc: 0.351901. Loss: 1.843028. Batch_acc: 0.378146. Batch_loss: 1.778154 \n",
      "Batch: 4231. Acc: 0.351905. Loss: 1.843005. Batch_acc: 0.368938. Batch_loss: 1.745031 \n",
      "Batch: 4232. Acc: 0.351907. Loss: 1.843003. Batch_acc: 0.360540. Batch_loss: 1.833128 \n",
      "Batch: 4233. Acc: 0.351916. Loss: 1.842981. Batch_acc: 0.392501. Batch_loss: 1.751934 \n",
      "Batch: 4234. Acc: 0.351926. Loss: 1.842950. Batch_acc: 0.393563. Batch_loss: 1.714533 \n",
      "Batch: 4235. Acc: 0.351931. Loss: 1.842931. Batch_acc: 0.371626. Batch_loss: 1.759088 \n",
      "Batch: 4236. Acc: 0.351939. Loss: 1.842909. Batch_acc: 0.385549. Batch_loss: 1.752712 \n",
      "Batch: 4237. Acc: 0.351948. Loss: 1.842879. Batch_acc: 0.391279. Batch_loss: 1.714026 \n",
      "Batch: 4238. Acc: 0.351952. Loss: 1.842868. Batch_acc: 0.372174. Batch_loss: 1.795700 \n",
      "Batch: 4239. Acc: 0.351959. Loss: 1.842843. Batch_acc: 0.380814. Batch_loss: 1.734026 \n",
      "Batch: 4240. Acc: 0.351968. Loss: 1.842818. Batch_acc: 0.391304. Batch_loss: 1.735308 \n",
      "Batch: 4241. Acc: 0.351980. Loss: 1.842784. Batch_acc: 0.401231. Batch_loss: 1.703566 \n",
      "Batch: 4242. Acc: 0.351986. Loss: 1.842761. Batch_acc: 0.374495. Batch_loss: 1.744751 \n",
      "Batch: 4243. Acc: 0.351994. Loss: 1.842725. Batch_acc: 0.387902. Batch_loss: 1.696587 \n",
      "Batch: 4244. Acc: 0.352001. Loss: 1.842698. Batch_acc: 0.380194. Batch_loss: 1.727463 \n",
      "Batch: 4245. Acc: 0.352008. Loss: 1.842670. Batch_acc: 0.382353. Batch_loss: 1.723310 \n",
      "Batch: 4246. Acc: 0.352019. Loss: 1.842642. Batch_acc: 0.396034. Batch_loss: 1.726301 \n",
      "Batch: 4247. Acc: 0.352024. Loss: 1.842626. Batch_acc: 0.373386. Batch_loss: 1.774874 \n",
      "Batch: 4248. Acc: 0.352031. Loss: 1.842597. Batch_acc: 0.383220. Batch_loss: 1.723531 \n",
      "Batch: 4249. Acc: 0.352038. Loss: 1.842577. Batch_acc: 0.379710. Batch_loss: 1.757905 \n",
      "Batch: 4250. Acc: 0.352043. Loss: 1.842557. Batch_acc: 0.374416. Batch_loss: 1.755595 \n",
      "Batch: 4251. Acc: 0.352049. Loss: 1.842539. Batch_acc: 0.377907. Batch_loss: 1.763459 \n",
      "Batch: 4252. Acc: 0.352054. Loss: 1.842521. Batch_acc: 0.374928. Batch_loss: 1.767855 \n",
      "Batch: 4253. Acc: 0.352059. Loss: 1.842502. Batch_acc: 0.373425. Batch_loss: 1.762703 \n",
      "Batch: 4254. Acc: 0.352062. Loss: 1.842494. Batch_acc: 0.361210. Batch_loss: 1.806061 \n",
      "Batch: 4255. Acc: 0.352069. Loss: 1.842471. Batch_acc: 0.383472. Batch_loss: 1.739862 \n",
      "Batch: 4256. Acc: 0.352079. Loss: 1.842432. Batch_acc: 0.395457. Batch_loss: 1.674880 \n",
      "Batch: 4257. Acc: 0.352082. Loss: 1.842415. Batch_acc: 0.365202. Batch_loss: 1.766852 \n",
      "Batch: 4258. Acc: 0.352087. Loss: 1.842390. Batch_acc: 0.375785. Batch_loss: 1.739201 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4259. Acc: 0.352099. Loss: 1.842358. Batch_acc: 0.400916. Batch_loss: 1.705341 \n",
      "Batch: 4260. Acc: 0.352110. Loss: 1.842335. Batch_acc: 0.398625. Batch_loss: 1.743257 \n",
      "Batch: 4261. Acc: 0.352116. Loss: 1.842314. Batch_acc: 0.378268. Batch_loss: 1.755084 \n",
      "Batch: 4262. Acc: 0.352119. Loss: 1.842298. Batch_acc: 0.365276. Batch_loss: 1.773393 \n",
      "Batch: 4263. Acc: 0.352120. Loss: 1.842292. Batch_acc: 0.357061. Batch_loss: 1.818755 \n",
      "Batch: 4264. Acc: 0.352129. Loss: 1.842266. Batch_acc: 0.389145. Batch_loss: 1.728313 \n",
      "Batch: 4265. Acc: 0.352134. Loss: 1.842252. Batch_acc: 0.374341. Batch_loss: 1.781033 \n",
      "Batch: 4266. Acc: 0.352136. Loss: 1.842247. Batch_acc: 0.361405. Batch_loss: 1.822868 \n",
      "Batch: 4267. Acc: 0.352143. Loss: 1.842221. Batch_acc: 0.379867. Batch_loss: 1.734846 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.3521429699684466. Loss per char: 1.8422209572140695. Time: 1627209860.70443\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 20, 24, 26, 25, 17, 17, 18, 17, 25, 20,  1, 66, 79,\n",
      "        69,  1, 14, 25, 15, 17, 25, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.352153. Loss: 1.842199. Batch_acc: 0.393939. Batch_loss: 1.748652 \n",
      "Batch: 4269. Acc: 0.352161. Loss: 1.842178. Batch_acc: 0.386298. Batch_loss: 1.754171 \n",
      "Batch: 4270. Acc: 0.352169. Loss: 1.842153. Batch_acc: 0.388215. Batch_loss: 1.734341 \n",
      "Batch: 4271. Acc: 0.352175. Loss: 1.842140. Batch_acc: 0.376450. Batch_loss: 1.785481 \n",
      "Batch: 4272. Acc: 0.352180. Loss: 1.842125. Batch_acc: 0.374272. Batch_loss: 1.777506 \n",
      "Batch: 4273. Acc: 0.352185. Loss: 1.842103. Batch_acc: 0.372549. Batch_loss: 1.746004 \n",
      "Batch: 4274. Acc: 0.352191. Loss: 1.842081. Batch_acc: 0.381034. Batch_loss: 1.751731 \n",
      "Batch: 4275. Acc: 0.352195. Loss: 1.842066. Batch_acc: 0.366589. Batch_loss: 1.775053 \n",
      "Batch: 4276. Acc: 0.352202. Loss: 1.842043. Batch_acc: 0.383324. Batch_loss: 1.744474 \n",
      "Batch: 4277. Acc: 0.352207. Loss: 1.842017. Batch_acc: 0.373341. Batch_loss: 1.727723 \n",
      "Batch: 4278. Acc: 0.352210. Loss: 1.841999. Batch_acc: 0.365659. Batch_loss: 1.766485 \n",
      "Batch: 4279. Acc: 0.352214. Loss: 1.841980. Batch_acc: 0.370286. Batch_loss: 1.759964 \n",
      "Batch: 4280. Acc: 0.352225. Loss: 1.841945. Batch_acc: 0.398215. Batch_loss: 1.696790 \n",
      "Batch: 4281. Acc: 0.352229. Loss: 1.841927. Batch_acc: 0.366492. Batch_loss: 1.764517 \n",
      "Batch: 4282. Acc: 0.352234. Loss: 1.841912. Batch_acc: 0.373761. Batch_loss: 1.776513 \n",
      "Batch: 4283. Acc: 0.352241. Loss: 1.841895. Batch_acc: 0.382709. Batch_loss: 1.770099 \n",
      "Batch: 4284. Acc: 0.352250. Loss: 1.841870. Batch_acc: 0.391915. Batch_loss: 1.738178 \n",
      "Batch: 4285. Acc: 0.352253. Loss: 1.841853. Batch_acc: 0.364602. Batch_loss: 1.765039 \n",
      "Batch: 4286. Acc: 0.352259. Loss: 1.841833. Batch_acc: 0.376511. Batch_loss: 1.756833 \n",
      "Batch: 4287. Acc: 0.352263. Loss: 1.841807. Batch_acc: 0.371365. Batch_loss: 1.733284 \n",
      "Batch: 4288. Acc: 0.352271. Loss: 1.841780. Batch_acc: 0.383506. Batch_loss: 1.726130 \n",
      "Batch: 4289. Acc: 0.352275. Loss: 1.841765. Batch_acc: 0.369831. Batch_loss: 1.776190 \n",
      "Batch: 4290. Acc: 0.352279. Loss: 1.841749. Batch_acc: 0.372232. Batch_loss: 1.770344 \n",
      "Batch: 4291. Acc: 0.352285. Loss: 1.841725. Batch_acc: 0.377208. Batch_loss: 1.742568 \n",
      "Batch: 4292. Acc: 0.352297. Loss: 1.841696. Batch_acc: 0.403244. Batch_loss: 1.715842 \n",
      "Batch: 4293. Acc: 0.352306. Loss: 1.841668. Batch_acc: 0.392918. Batch_loss: 1.720085 \n",
      "Batch: 4294. Acc: 0.352314. Loss: 1.841648. Batch_acc: 0.384220. Batch_loss: 1.755454 \n",
      "Batch: 4295. Acc: 0.352314. Loss: 1.841645. Batch_acc: 0.354877. Batch_loss: 1.832242 \n",
      "Batch: 4296. Acc: 0.352324. Loss: 1.841614. Batch_acc: 0.394573. Batch_loss: 1.709387 \n",
      "Batch: 4297. Acc: 0.352337. Loss: 1.841581. Batch_acc: 0.403135. Batch_loss: 1.702973 \n",
      "Batch: 4298. Acc: 0.352340. Loss: 1.841561. Batch_acc: 0.369048. Batch_loss: 1.755231 \n",
      "Batch: 4299. Acc: 0.352347. Loss: 1.841543. Batch_acc: 0.379813. Batch_loss: 1.764946 \n",
      "Batch: 4300. Acc: 0.352349. Loss: 1.841528. Batch_acc: 0.362396. Batch_loss: 1.773313 \n",
      "Batch: 4301. Acc: 0.352356. Loss: 1.841501. Batch_acc: 0.380702. Batch_loss: 1.726927 \n",
      "Batch: 4302. Acc: 0.352366. Loss: 1.841471. Batch_acc: 0.399422. Batch_loss: 1.711305 \n",
      "Batch: 4303. Acc: 0.352374. Loss: 1.841451. Batch_acc: 0.384434. Batch_loss: 1.752902 \n",
      "Batch: 4304. Acc: 0.352379. Loss: 1.841437. Batch_acc: 0.373678. Batch_loss: 1.779326 \n",
      "Batch: 4305. Acc: 0.352386. Loss: 1.841411. Batch_acc: 0.384480. Batch_loss: 1.725372 \n",
      "Batch: 4306. Acc: 0.352389. Loss: 1.841401. Batch_acc: 0.367081. Batch_loss: 1.799918 \n",
      "Batch: 4307. Acc: 0.352393. Loss: 1.841385. Batch_acc: 0.370865. Batch_loss: 1.769006 \n",
      "Batch: 4308. Acc: 0.352403. Loss: 1.841361. Batch_acc: 0.392312. Batch_loss: 1.738917 \n",
      "Batch: 4309. Acc: 0.352408. Loss: 1.841338. Batch_acc: 0.376812. Batch_loss: 1.741958 \n",
      "Batch: 4310. Acc: 0.352418. Loss: 1.841310. Batch_acc: 0.394094. Batch_loss: 1.722538 \n",
      "Batch: 4311. Acc: 0.352424. Loss: 1.841291. Batch_acc: 0.376157. Batch_loss: 1.761100 \n",
      "Batch: 4312. Acc: 0.352424. Loss: 1.841279. Batch_acc: 0.353722. Batch_loss: 1.790333 \n",
      "Batch: 4313. Acc: 0.352428. Loss: 1.841274. Batch_acc: 0.368513. Batch_loss: 1.816417 \n",
      "Batch: 4314. Acc: 0.352435. Loss: 1.841248. Batch_acc: 0.384928. Batch_loss: 1.728209 \n",
      "Batch: 4315. Acc: 0.352444. Loss: 1.841219. Batch_acc: 0.389890. Batch_loss: 1.716125 \n",
      "Batch: 4316. Acc: 0.352451. Loss: 1.841206. Batch_acc: 0.384831. Batch_loss: 1.784707 \n",
      "Batch: 4317. Acc: 0.352457. Loss: 1.841192. Batch_acc: 0.378121. Batch_loss: 1.779636 \n",
      "Batch: 4318. Acc: 0.352458. Loss: 1.841182. Batch_acc: 0.356303. Batch_loss: 1.798904 \n",
      "Batch: 4319. Acc: 0.352460. Loss: 1.841175. Batch_acc: 0.361439. Batch_loss: 1.811252 \n",
      "Batch: 4320. Acc: 0.352467. Loss: 1.841151. Batch_acc: 0.379783. Batch_loss: 1.741081 \n",
      "Batch: 4321. Acc: 0.352474. Loss: 1.841122. Batch_acc: 0.384396. Batch_loss: 1.715012 \n",
      "Batch: 4322. Acc: 0.352482. Loss: 1.841100. Batch_acc: 0.387826. Batch_loss: 1.743840 \n",
      "Batch: 4323. Acc: 0.352485. Loss: 1.841089. Batch_acc: 0.363054. Batch_loss: 1.795467 \n",
      "Batch: 4324. Acc: 0.352491. Loss: 1.841057. Batch_acc: 0.381984. Batch_loss: 1.701189 \n",
      "Batch: 4325. Acc: 0.352497. Loss: 1.841040. Batch_acc: 0.377391. Batch_loss: 1.768659 \n",
      "Batch: 4326. Acc: 0.352503. Loss: 1.841015. Batch_acc: 0.377283. Batch_loss: 1.732799 \n",
      "Batch: 4327. Acc: 0.352508. Loss: 1.840990. Batch_acc: 0.374490. Batch_loss: 1.732481 \n",
      "Batch: 4328. Acc: 0.352516. Loss: 1.840964. Batch_acc: 0.385772. Batch_loss: 1.727570 \n",
      "Batch: 4329. Acc: 0.352523. Loss: 1.840938. Batch_acc: 0.386535. Batch_loss: 1.725872 \n",
      "Batch: 4330. Acc: 0.352531. Loss: 1.840908. Batch_acc: 0.383708. Batch_loss: 1.715443 \n",
      "Batch: 4331. Acc: 0.352537. Loss: 1.840886. Batch_acc: 0.380872. Batch_loss: 1.748953 \n",
      "Batch: 4332. Acc: 0.352547. Loss: 1.840859. Batch_acc: 0.392507. Batch_loss: 1.723946 \n",
      "Batch: 4333. Acc: 0.352555. Loss: 1.840832. Batch_acc: 0.387650. Batch_loss: 1.721696 \n",
      "Batch: 4334. Acc: 0.352561. Loss: 1.840815. Batch_acc: 0.377752. Batch_loss: 1.767142 \n",
      "Batch: 4335. Acc: 0.352566. Loss: 1.840798. Batch_acc: 0.374146. Batch_loss: 1.767688 \n",
      "Batch: 4336. Acc: 0.352574. Loss: 1.840765. Batch_acc: 0.390878. Batch_loss: 1.695829 \n",
      "Batch: 4337. Acc: 0.352578. Loss: 1.840746. Batch_acc: 0.369577. Batch_loss: 1.761750 \n",
      "Batch: 4338. Acc: 0.352587. Loss: 1.840717. Batch_acc: 0.389049. Batch_loss: 1.716166 \n",
      "Batch: 4339. Acc: 0.352596. Loss: 1.840686. Batch_acc: 0.394318. Batch_loss: 1.707477 \n",
      "Batch: 4340. Acc: 0.352600. Loss: 1.840668. Batch_acc: 0.366456. Batch_loss: 1.762331 \n",
      "Batch: 4341. Acc: 0.352606. Loss: 1.840647. Batch_acc: 0.378551. Batch_loss: 1.746756 \n",
      "Batch: 4342. Acc: 0.352609. Loss: 1.840633. Batch_acc: 0.367561. Batch_loss: 1.780802 \n",
      "Batch: 4343. Acc: 0.352621. Loss: 1.840594. Batch_acc: 0.404695. Batch_loss: 1.677206 \n",
      "Batch: 4344. Acc: 0.352630. Loss: 1.840565. Batch_acc: 0.390371. Batch_loss: 1.713205 \n",
      "Batch: 4345. Acc: 0.352643. Loss: 1.840538. Batch_acc: 0.408443. Batch_loss: 1.721345 \n",
      "Batch: 4346. Acc: 0.352647. Loss: 1.840517. Batch_acc: 0.370305. Batch_loss: 1.748132 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4347. Acc: 0.352653. Loss: 1.840490. Batch_acc: 0.379754. Batch_loss: 1.723733 \n",
      "Batch: 4348. Acc: 0.352661. Loss: 1.840465. Batch_acc: 0.388699. Batch_loss: 1.731450 \n",
      "Batch: 4349. Acc: 0.352667. Loss: 1.840448. Batch_acc: 0.376157. Batch_loss: 1.766744 \n",
      "Batch: 4350. Acc: 0.352676. Loss: 1.840420. Batch_acc: 0.391553. Batch_loss: 1.718169 \n",
      "Batch: 4351. Acc: 0.352682. Loss: 1.840397. Batch_acc: 0.379777. Batch_loss: 1.737621 \n",
      "Batch: 4352. Acc: 0.352688. Loss: 1.840376. Batch_acc: 0.379549. Batch_loss: 1.747876 \n",
      "Batch: 4353. Acc: 0.352691. Loss: 1.840356. Batch_acc: 0.367621. Batch_loss: 1.752082 \n",
      "Batch: 4354. Acc: 0.352697. Loss: 1.840332. Batch_acc: 0.377506. Batch_loss: 1.739664 \n",
      "Batch: 4355. Acc: 0.352700. Loss: 1.840317. Batch_acc: 0.366279. Batch_loss: 1.777188 \n",
      "Batch: 4356. Acc: 0.352703. Loss: 1.840296. Batch_acc: 0.364310. Batch_loss: 1.749770 \n",
      "Batch: 4357. Acc: 0.352710. Loss: 1.840278. Batch_acc: 0.383227. Batch_loss: 1.757955 \n",
      "Batch: 4358. Acc: 0.352715. Loss: 1.840264. Batch_acc: 0.374427. Batch_loss: 1.778117 \n",
      "Batch: 4359. Acc: 0.352722. Loss: 1.840236. Batch_acc: 0.382743. Batch_loss: 1.726102 \n",
      "Batch: 4360. Acc: 0.352730. Loss: 1.840212. Batch_acc: 0.386798. Batch_loss: 1.733946 \n",
      "Batch: 4361. Acc: 0.352737. Loss: 1.840183. Batch_acc: 0.383616. Batch_loss: 1.716223 \n",
      "Batch: 4362. Acc: 0.352741. Loss: 1.840158. Batch_acc: 0.371041. Batch_loss: 1.731737 \n",
      "Batch: 4363. Acc: 0.352747. Loss: 1.840137. Batch_acc: 0.377163. Batch_loss: 1.746746 \n",
      "Batch: 4364. Acc: 0.352753. Loss: 1.840119. Batch_acc: 0.378788. Batch_loss: 1.762616 \n",
      "Batch: 4365. Acc: 0.352761. Loss: 1.840089. Batch_acc: 0.388604. Batch_loss: 1.709011 \n",
      "Batch: 4366. Acc: 0.352769. Loss: 1.840066. Batch_acc: 0.386139. Batch_loss: 1.738570 \n",
      "Batch: 4367. Acc: 0.352774. Loss: 1.840043. Batch_acc: 0.376919. Batch_loss: 1.743429 \n",
      "Batch: 4368. Acc: 0.352784. Loss: 1.840018. Batch_acc: 0.393226. Batch_loss: 1.729293 \n",
      "Batch: 4369. Acc: 0.352789. Loss: 1.839996. Batch_acc: 0.374856. Batch_loss: 1.746556 \n",
      "Batch: 4370. Acc: 0.352793. Loss: 1.839986. Batch_acc: 0.373248. Batch_loss: 1.794094 \n",
      "Batch: 4371. Acc: 0.352799. Loss: 1.839966. Batch_acc: 0.377739. Batch_loss: 1.751607 \n",
      "Batch: 4372. Acc: 0.352804. Loss: 1.839940. Batch_acc: 0.376661. Batch_loss: 1.727994 \n",
      "Batch: 4373. Acc: 0.352811. Loss: 1.839916. Batch_acc: 0.381839. Batch_loss: 1.735939 \n",
      "Batch: 4374. Acc: 0.352818. Loss: 1.839898. Batch_acc: 0.381797. Batch_loss: 1.762483 \n",
      "Batch: 4375. Acc: 0.352823. Loss: 1.839876. Batch_acc: 0.375441. Batch_loss: 1.740028 \n",
      "Batch: 4376. Acc: 0.352827. Loss: 1.839857. Batch_acc: 0.369679. Batch_loss: 1.754251 \n",
      "Batch: 4377. Acc: 0.352833. Loss: 1.839839. Batch_acc: 0.382319. Batch_loss: 1.762276 \n",
      "Batch: 4378. Acc: 0.352839. Loss: 1.839815. Batch_acc: 0.379014. Batch_loss: 1.736183 \n",
      "Batch: 4379. Acc: 0.352846. Loss: 1.839795. Batch_acc: 0.381119. Batch_loss: 1.748444 \n",
      "Batch: 4380. Acc: 0.352852. Loss: 1.839771. Batch_acc: 0.378977. Batch_loss: 1.737808 \n",
      "Batch: 4381. Acc: 0.352856. Loss: 1.839745. Batch_acc: 0.371478. Batch_loss: 1.727036 \n",
      "Batch: 4382. Acc: 0.352865. Loss: 1.839715. Batch_acc: 0.391378. Batch_loss: 1.707717 \n",
      "Batch: 4383. Acc: 0.352870. Loss: 1.839701. Batch_acc: 0.376395. Batch_loss: 1.777697 \n",
      "Batch: 4384. Acc: 0.352881. Loss: 1.839673. Batch_acc: 0.399657. Batch_loss: 1.716797 \n",
      "Batch: 4385. Acc: 0.352885. Loss: 1.839660. Batch_acc: 0.369679. Batch_loss: 1.781214 \n",
      "Batch: 4386. Acc: 0.352889. Loss: 1.839644. Batch_acc: 0.371182. Batch_loss: 1.771068 \n",
      "Batch: 4387. Acc: 0.352892. Loss: 1.839627. Batch_acc: 0.365107. Batch_loss: 1.766450 \n",
      "Batch: 4388. Acc: 0.352899. Loss: 1.839605. Batch_acc: 0.384178. Batch_loss: 1.743442 \n",
      "Batch: 4389. Acc: 0.352911. Loss: 1.839567. Batch_acc: 0.403857. Batch_loss: 1.671735 \n",
      "Batch: 4390. Acc: 0.352914. Loss: 1.839550. Batch_acc: 0.368177. Batch_loss: 1.765874 \n",
      "Batch: 4391. Acc: 0.352919. Loss: 1.839528. Batch_acc: 0.373607. Batch_loss: 1.743060 \n",
      "Batch: 4392. Acc: 0.352926. Loss: 1.839494. Batch_acc: 0.386912. Batch_loss: 1.690668 \n",
      "Batch: 4393. Acc: 0.352933. Loss: 1.839469. Batch_acc: 0.382041. Batch_loss: 1.731897 \n",
      "Batch: 4394. Acc: 0.352944. Loss: 1.839435. Batch_acc: 0.401396. Batch_loss: 1.686419 \n",
      "Batch: 4395. Acc: 0.352950. Loss: 1.839413. Batch_acc: 0.379819. Batch_loss: 1.744932 \n",
      "Batch: 4396. Acc: 0.352955. Loss: 1.839395. Batch_acc: 0.373239. Batch_loss: 1.758717 \n",
      "Batch: 4397. Acc: 0.352961. Loss: 1.839371. Batch_acc: 0.379271. Batch_loss: 1.736248 \n",
      "Batch: 4398. Acc: 0.352966. Loss: 1.839351. Batch_acc: 0.376945. Batch_loss: 1.748379 \n",
      "Batch: 4399. Acc: 0.352970. Loss: 1.839336. Batch_acc: 0.368451. Batch_loss: 1.776126 \n",
      "Batch: 4400. Acc: 0.352976. Loss: 1.839311. Batch_acc: 0.377551. Batch_loss: 1.730850 \n",
      "Batch: 4401. Acc: 0.352981. Loss: 1.839295. Batch_acc: 0.376853. Batch_loss: 1.769750 \n",
      "Batch: 4402. Acc: 0.352984. Loss: 1.839275. Batch_acc: 0.366800. Batch_loss: 1.749299 \n",
      "Batch: 4403. Acc: 0.352989. Loss: 1.839250. Batch_acc: 0.371924. Batch_loss: 1.732338 \n",
      "Batch: 4404. Acc: 0.352991. Loss: 1.839239. Batch_acc: 0.363531. Batch_loss: 1.790765 \n",
      "Batch: 4405. Acc: 0.353000. Loss: 1.839206. Batch_acc: 0.389538. Batch_loss: 1.701028 \n",
      "Batch: 4406. Acc: 0.353008. Loss: 1.839181. Batch_acc: 0.389177. Batch_loss: 1.726526 \n",
      "Batch: 4407. Acc: 0.353014. Loss: 1.839159. Batch_acc: 0.378882. Batch_loss: 1.743566 \n",
      "Batch: 4408. Acc: 0.353019. Loss: 1.839131. Batch_acc: 0.374645. Batch_loss: 1.716630 \n",
      "Batch: 4409. Acc: 0.353026. Loss: 1.839111. Batch_acc: 0.383076. Batch_loss: 1.751689 \n",
      "Batch: 4410. Acc: 0.353027. Loss: 1.839095. Batch_acc: 0.358523. Batch_loss: 1.770954 \n",
      "Batch: 4411. Acc: 0.353030. Loss: 1.839075. Batch_acc: 0.367903. Batch_loss: 1.751391 \n",
      "Batch: 4412. Acc: 0.353035. Loss: 1.839056. Batch_acc: 0.374556. Batch_loss: 1.751415 \n",
      "Batch: 4413. Acc: 0.353039. Loss: 1.839033. Batch_acc: 0.372493. Batch_loss: 1.740094 \n",
      "Batch: 4414. Acc: 0.353049. Loss: 1.839008. Batch_acc: 0.395203. Batch_loss: 1.726573 \n",
      "Batch: 4415. Acc: 0.353052. Loss: 1.838993. Batch_acc: 0.365485. Batch_loss: 1.772550 \n",
      "Batch: 4416. Acc: 0.353059. Loss: 1.838965. Batch_acc: 0.383944. Batch_loss: 1.714930 \n",
      "Batch: 4417. Acc: 0.353066. Loss: 1.838945. Batch_acc: 0.386766. Batch_loss: 1.751539 \n",
      "Batch: 4418. Acc: 0.353072. Loss: 1.838923. Batch_acc: 0.376277. Batch_loss: 1.741818 \n",
      "Batch: 4419. Acc: 0.353083. Loss: 1.838892. Batch_acc: 0.403299. Batch_loss: 1.702853 \n",
      "Batch: 4420. Acc: 0.353090. Loss: 1.838871. Batch_acc: 0.384344. Batch_loss: 1.746137 \n",
      "Batch: 4421. Acc: 0.353101. Loss: 1.838845. Batch_acc: 0.401515. Batch_loss: 1.722151 \n",
      "Batch: 4422. Acc: 0.353108. Loss: 1.838824. Batch_acc: 0.382286. Batch_loss: 1.744637 \n",
      "Batch: 4423. Acc: 0.353114. Loss: 1.838802. Batch_acc: 0.381432. Batch_loss: 1.745792 \n",
      "Batch: 4424. Acc: 0.353121. Loss: 1.838778. Batch_acc: 0.382979. Batch_loss: 1.730840 \n",
      "Batch: 4425. Acc: 0.353127. Loss: 1.838760. Batch_acc: 0.378440. Batch_loss: 1.762716 \n",
      "Batch: 4426. Acc: 0.353128. Loss: 1.838752. Batch_acc: 0.358664. Batch_loss: 1.803452 \n",
      "Batch: 4427. Acc: 0.353130. Loss: 1.838747. Batch_acc: 0.362884. Batch_loss: 1.815635 \n",
      "Batch: 4428. Acc: 0.353136. Loss: 1.838731. Batch_acc: 0.377348. Batch_loss: 1.767004 \n",
      "Batch: 4429. Acc: 0.353142. Loss: 1.838714. Batch_acc: 0.380397. Batch_loss: 1.762099 \n",
      "Batch: 4430. Acc: 0.353149. Loss: 1.838692. Batch_acc: 0.388662. Batch_loss: 1.740450 \n",
      "Batch: 4431. Acc: 0.353158. Loss: 1.838668. Batch_acc: 0.388729. Batch_loss: 1.730763 \n",
      "Batch: 4432. Acc: 0.353164. Loss: 1.838645. Batch_acc: 0.384430. Batch_loss: 1.732812 \n",
      "Batch: 4433. Acc: 0.353170. Loss: 1.838624. Batch_acc: 0.381008. Batch_loss: 1.744302 \n",
      "Batch: 4434. Acc: 0.353174. Loss: 1.838608. Batch_acc: 0.368000. Batch_loss: 1.769264 \n",
      "Batch: 4435. Acc: 0.353183. Loss: 1.838581. Batch_acc: 0.395617. Batch_loss: 1.717757 \n",
      "Batch: 4436. Acc: 0.353189. Loss: 1.838557. Batch_acc: 0.379130. Batch_loss: 1.733237 \n",
      "Batch: 4437. Acc: 0.353199. Loss: 1.838530. Batch_acc: 0.396942. Batch_loss: 1.720580 \n",
      "Batch: 4438. Acc: 0.353205. Loss: 1.838510. Batch_acc: 0.380090. Batch_loss: 1.748706 \n",
      "Batch: 4439. Acc: 0.353210. Loss: 1.838490. Batch_acc: 0.373203. Batch_loss: 1.751885 \n",
      "Batch: 4440. Acc: 0.353213. Loss: 1.838471. Batch_acc: 0.366222. Batch_loss: 1.750352 \n",
      "Batch: 4441. Acc: 0.353213. Loss: 1.838457. Batch_acc: 0.353881. Batch_loss: 1.776097 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4442. Acc: 0.353225. Loss: 1.838423. Batch_acc: 0.407237. Batch_loss: 1.690349 \n",
      "Batch: 4443. Acc: 0.353233. Loss: 1.838402. Batch_acc: 0.388889. Batch_loss: 1.745826 \n",
      "Batch: 4444. Acc: 0.353239. Loss: 1.838382. Batch_acc: 0.381648. Batch_loss: 1.744459 \n",
      "Batch: 4445. Acc: 0.353243. Loss: 1.838362. Batch_acc: 0.368632. Batch_loss: 1.753691 \n",
      "Batch: 4446. Acc: 0.353249. Loss: 1.838336. Batch_acc: 0.380170. Batch_loss: 1.722252 \n",
      "Batch: 4447. Acc: 0.353258. Loss: 1.838306. Batch_acc: 0.393397. Batch_loss: 1.707386 \n",
      "Batch: 4448. Acc: 0.353263. Loss: 1.838284. Batch_acc: 0.374434. Batch_loss: 1.744498 \n",
      "Batch: 4449. Acc: 0.353270. Loss: 1.838256. Batch_acc: 0.384660. Batch_loss: 1.712934 \n",
      "Batch: 4450. Acc: 0.353275. Loss: 1.838234. Batch_acc: 0.376728. Batch_loss: 1.739624 \n",
      "Batch: 4451. Acc: 0.353284. Loss: 1.838213. Batch_acc: 0.391407. Batch_loss: 1.744543 \n",
      "Batch: 4452. Acc: 0.353289. Loss: 1.838188. Batch_acc: 0.375421. Batch_loss: 1.729044 \n",
      "Batch: 4453. Acc: 0.353300. Loss: 1.838160. Batch_acc: 0.402642. Batch_loss: 1.712922 \n",
      "Batch: 4454. Acc: 0.353307. Loss: 1.838138. Batch_acc: 0.385836. Batch_loss: 1.741855 \n",
      "Batch: 4455. Acc: 0.353315. Loss: 1.838114. Batch_acc: 0.386377. Batch_loss: 1.729927 \n",
      "Batch: 4456. Acc: 0.353327. Loss: 1.838076. Batch_acc: 0.406019. Batch_loss: 1.672299 \n",
      "Batch: 4457. Acc: 0.353336. Loss: 1.838048. Batch_acc: 0.394008. Batch_loss: 1.713816 \n",
      "Batch: 4458. Acc: 0.353342. Loss: 1.838024. Batch_acc: 0.378472. Batch_loss: 1.732804 \n",
      "Batch: 4459. Acc: 0.353348. Loss: 1.837999. Batch_acc: 0.383506. Batch_loss: 1.726777 \n",
      "Batch: 4460. Acc: 0.353354. Loss: 1.837979. Batch_acc: 0.378664. Batch_loss: 1.746567 \n",
      "Batch: 4461. Acc: 0.353357. Loss: 1.837965. Batch_acc: 0.365782. Batch_loss: 1.774564 \n",
      "Batch: 4462. Acc: 0.353366. Loss: 1.837938. Batch_acc: 0.393271. Batch_loss: 1.715534 \n",
      "Batch: 4463. Acc: 0.353370. Loss: 1.837919. Batch_acc: 0.374007. Batch_loss: 1.753271 \n",
      "Batch: 4464. Acc: 0.353376. Loss: 1.837899. Batch_acc: 0.376820. Batch_loss: 1.745849 \n",
      "Batch: 4465. Acc: 0.353376. Loss: 1.837888. Batch_acc: 0.354857. Batch_loss: 1.791610 \n",
      "Batch: 4466. Acc: 0.353383. Loss: 1.837863. Batch_acc: 0.383554. Batch_loss: 1.723207 \n",
      "Batch: 4467. Acc: 0.353386. Loss: 1.837844. Batch_acc: 0.367925. Batch_loss: 1.751561 \n",
      "Batch: 4468. Acc: 0.353391. Loss: 1.837827. Batch_acc: 0.378458. Batch_loss: 1.761418 \n",
      "Batch: 4469. Acc: 0.353397. Loss: 1.837807. Batch_acc: 0.378668. Batch_loss: 1.749511 \n",
      "Batch: 4470. Acc: 0.353401. Loss: 1.837787. Batch_acc: 0.373108. Batch_loss: 1.745870 \n",
      "Batch: 4471. Acc: 0.353412. Loss: 1.837758. Batch_acc: 0.402650. Batch_loss: 1.710098 \n",
      "Batch: 4472. Acc: 0.353419. Loss: 1.837739. Batch_acc: 0.384660. Batch_loss: 1.753692 \n",
      "Batch: 4473. Acc: 0.353428. Loss: 1.837714. Batch_acc: 0.390091. Batch_loss: 1.725894 \n",
      "Batch: 4474. Acc: 0.353435. Loss: 1.837690. Batch_acc: 0.388104. Batch_loss: 1.727961 \n",
      "Batch: 4475. Acc: 0.353440. Loss: 1.837671. Batch_acc: 0.377214. Batch_loss: 1.748628 \n",
      "Batch: 4476. Acc: 0.353446. Loss: 1.837650. Batch_acc: 0.378814. Batch_loss: 1.744439 \n",
      "Batch: 4477. Acc: 0.353451. Loss: 1.837628. Batch_acc: 0.375281. Batch_loss: 1.742815 \n",
      "Batch: 4478. Acc: 0.353458. Loss: 1.837603. Batch_acc: 0.384437. Batch_loss: 1.723735 \n",
      "Batch: 4479. Acc: 0.353464. Loss: 1.837590. Batch_acc: 0.382370. Batch_loss: 1.781466 \n",
      "Batch: 4480. Acc: 0.353469. Loss: 1.837573. Batch_acc: 0.374638. Batch_loss: 1.759642 \n",
      "Batch: 4481. Acc: 0.353472. Loss: 1.837564. Batch_acc: 0.367015. Batch_loss: 1.796788 \n",
      "Batch: 4482. Acc: 0.353476. Loss: 1.837549. Batch_acc: 0.372515. Batch_loss: 1.768513 \n",
      "Batch: 4483. Acc: 0.353483. Loss: 1.837526. Batch_acc: 0.385135. Batch_loss: 1.737952 \n",
      "Batch: 4484. Acc: 0.353487. Loss: 1.837511. Batch_acc: 0.371396. Batch_loss: 1.770803 \n",
      "Batch: 4485. Acc: 0.353492. Loss: 1.837495. Batch_acc: 0.376152. Batch_loss: 1.763002 \n",
      "Batch: 4486. Acc: 0.353498. Loss: 1.837478. Batch_acc: 0.378409. Batch_loss: 1.763696 \n",
      "Batch: 4487. Acc: 0.353505. Loss: 1.837456. Batch_acc: 0.385284. Batch_loss: 1.737104 \n",
      "Batch: 4488. Acc: 0.353513. Loss: 1.837428. Batch_acc: 0.387133. Batch_loss: 1.714043 \n",
      "Batch: 4489. Acc: 0.353517. Loss: 1.837407. Batch_acc: 0.373487. Batch_loss: 1.745277 \n",
      "Batch: 4490. Acc: 0.353524. Loss: 1.837383. Batch_acc: 0.383352. Batch_loss: 1.728476 \n",
      "Batch: 4491. Acc: 0.353530. Loss: 1.837356. Batch_acc: 0.379608. Batch_loss: 1.717492 \n",
      "Batch: 4492. Acc: 0.353539. Loss: 1.837330. Batch_acc: 0.393414. Batch_loss: 1.720734 \n",
      "Batch: 4493. Acc: 0.353547. Loss: 1.837301. Batch_acc: 0.390368. Batch_loss: 1.709580 \n",
      "Batch: 4494. Acc: 0.353556. Loss: 1.837276. Batch_acc: 0.393265. Batch_loss: 1.723590 \n",
      "Batch: 4495. Acc: 0.353561. Loss: 1.837257. Batch_acc: 0.377907. Batch_loss: 1.749804 \n",
      "Batch: 4496. Acc: 0.353571. Loss: 1.837227. Batch_acc: 0.395548. Batch_loss: 1.705785 \n",
      "Batch: 4497. Acc: 0.353575. Loss: 1.837211. Batch_acc: 0.374182. Batch_loss: 1.761729 \n",
      "Batch: 4498. Acc: 0.353577. Loss: 1.837201. Batch_acc: 0.364162. Batch_loss: 1.792353 \n",
      "Batch: 4499. Acc: 0.353586. Loss: 1.837174. Batch_acc: 0.391075. Batch_loss: 1.711530 \n",
      "Batch: 4500. Acc: 0.353587. Loss: 1.837157. Batch_acc: 0.359437. Batch_loss: 1.763511 \n",
      "Batch: 4501. Acc: 0.353593. Loss: 1.837139. Batch_acc: 0.379673. Batch_loss: 1.753821 \n",
      "Batch: 4502. Acc: 0.353602. Loss: 1.837109. Batch_acc: 0.394707. Batch_loss: 1.703031 \n",
      "Batch: 4503. Acc: 0.353606. Loss: 1.837089. Batch_acc: 0.371681. Batch_loss: 1.750715 \n",
      "Batch: 4504. Acc: 0.353610. Loss: 1.837071. Batch_acc: 0.370544. Batch_loss: 1.753342 \n",
      "Batch: 4505. Acc: 0.353616. Loss: 1.837057. Batch_acc: 0.382016. Batch_loss: 1.772856 \n",
      "Batch: 4506. Acc: 0.353626. Loss: 1.837030. Batch_acc: 0.399529. Batch_loss: 1.713670 \n",
      "Batch: 4507. Acc: 0.353631. Loss: 1.837013. Batch_acc: 0.377883. Batch_loss: 1.759424 \n",
      "Batch: 4508. Acc: 0.353633. Loss: 1.837000. Batch_acc: 0.363533. Batch_loss: 1.776589 \n",
      "Batch: 4509. Acc: 0.353639. Loss: 1.836983. Batch_acc: 0.378813. Batch_loss: 1.766194 \n",
      "Batch: 4510. Acc: 0.353642. Loss: 1.836971. Batch_acc: 0.368301. Batch_loss: 1.780265 \n",
      "Batch: 4511. Acc: 0.353649. Loss: 1.836947. Batch_acc: 0.386905. Batch_loss: 1.726706 \n",
      "Batch: 4512. Acc: 0.353660. Loss: 1.836917. Batch_acc: 0.399545. Batch_loss: 1.703031 \n",
      "Batch: 4513. Acc: 0.353670. Loss: 1.836883. Batch_acc: 0.398442. Batch_loss: 1.687239 \n",
      "Batch: 4514. Acc: 0.353676. Loss: 1.836862. Batch_acc: 0.382387. Batch_loss: 1.743174 \n",
      "Batch: 4515. Acc: 0.353682. Loss: 1.836840. Batch_acc: 0.379193. Batch_loss: 1.737712 \n",
      "Batch: 4516. Acc: 0.353692. Loss: 1.836806. Batch_acc: 0.397100. Batch_loss: 1.689991 \n",
      "Batch: 4517. Acc: 0.353700. Loss: 1.836782. Batch_acc: 0.390570. Batch_loss: 1.726393 \n",
      "Batch: 4518. Acc: 0.353708. Loss: 1.836750. Batch_acc: 0.390083. Batch_loss: 1.696532 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.35370841310547. Loss per char: 1.836749758825988. Time: 1627210066.2514038\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 14, 26, 24, 25,\n",
      "        20, 15, 26, 26, 19,  1, 66, 79, 69,  1, 14, 18, 23, 20, 24, 20, 17, 19,\n",
      "        32,  3,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.353714. Loss: 1.836724. Batch_acc: 0.379761. Batch_loss: 1.721341 \n",
      "Batch: 4520. Acc: 0.353718. Loss: 1.836702. Batch_acc: 0.371105. Batch_loss: 1.738173 \n",
      "Batch: 4521. Acc: 0.353724. Loss: 1.836681. Batch_acc: 0.381977. Batch_loss: 1.741483 \n",
      "Batch: 4522. Acc: 0.353734. Loss: 1.836645. Batch_acc: 0.395623. Batch_loss: 1.677633 \n",
      "Batch: 4523. Acc: 0.353742. Loss: 1.836616. Batch_acc: 0.390710. Batch_loss: 1.711196 \n",
      "Batch: 4524. Acc: 0.353751. Loss: 1.836591. Batch_acc: 0.394374. Batch_loss: 1.726488 \n",
      "Batch: 4525. Acc: 0.353757. Loss: 1.836578. Batch_acc: 0.380059. Batch_loss: 1.776824 \n",
      "Batch: 4526. Acc: 0.353767. Loss: 1.836549. Batch_acc: 0.397831. Batch_loss: 1.702523 \n",
      "Batch: 4527. Acc: 0.353775. Loss: 1.836525. Batch_acc: 0.392623. Batch_loss: 1.725654 \n",
      "Batch: 4528. Acc: 0.353781. Loss: 1.836507. Batch_acc: 0.381964. Batch_loss: 1.753778 \n",
      "Batch: 4529. Acc: 0.353789. Loss: 1.836483. Batch_acc: 0.385935. Batch_loss: 1.731680 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4530. Acc: 0.353789. Loss: 1.836471. Batch_acc: 0.356978. Batch_loss: 1.779174 \n",
      "Batch: 4531. Acc: 0.353796. Loss: 1.836452. Batch_acc: 0.384971. Batch_loss: 1.752787 \n",
      "Batch: 4532. Acc: 0.353800. Loss: 1.836432. Batch_acc: 0.372187. Batch_loss: 1.742682 \n",
      "Batch: 4533. Acc: 0.353807. Loss: 1.836412. Batch_acc: 0.386338. Batch_loss: 1.749014 \n",
      "Batch: 4534. Acc: 0.353813. Loss: 1.836397. Batch_acc: 0.379390. Batch_loss: 1.765498 \n",
      "Batch: 4535. Acc: 0.353820. Loss: 1.836372. Batch_acc: 0.383446. Batch_loss: 1.726755 \n",
      "Batch: 4536. Acc: 0.353828. Loss: 1.836341. Batch_acc: 0.389685. Batch_loss: 1.695718 \n",
      "Batch: 4537. Acc: 0.353831. Loss: 1.836328. Batch_acc: 0.368451. Batch_loss: 1.777593 \n",
      "Batch: 4538. Acc: 0.353836. Loss: 1.836305. Batch_acc: 0.377921. Batch_loss: 1.730271 \n",
      "Batch: 4539. Acc: 0.353844. Loss: 1.836272. Batch_acc: 0.392584. Batch_loss: 1.681897 \n",
      "Batch: 4540. Acc: 0.353855. Loss: 1.836238. Batch_acc: 0.399662. Batch_loss: 1.685440 \n",
      "Batch: 4541. Acc: 0.353863. Loss: 1.836204. Batch_acc: 0.390661. Batch_loss: 1.683694 \n",
      "Batch: 4542. Acc: 0.353870. Loss: 1.836183. Batch_acc: 0.386167. Batch_loss: 1.740288 \n",
      "Batch: 4543. Acc: 0.353877. Loss: 1.836157. Batch_acc: 0.384888. Batch_loss: 1.717247 \n",
      "Batch: 4544. Acc: 0.353883. Loss: 1.836130. Batch_acc: 0.382075. Batch_loss: 1.707537 \n",
      "Batch: 4545. Acc: 0.353886. Loss: 1.836116. Batch_acc: 0.369096. Batch_loss: 1.770936 \n",
      "Batch: 4546. Acc: 0.353897. Loss: 1.836090. Batch_acc: 0.405590. Batch_loss: 1.720088 \n",
      "Batch: 4547. Acc: 0.353906. Loss: 1.836068. Batch_acc: 0.390930. Batch_loss: 1.735675 \n",
      "Batch: 4548. Acc: 0.353913. Loss: 1.836048. Batch_acc: 0.386457. Batch_loss: 1.743870 \n",
      "Batch: 4549. Acc: 0.353920. Loss: 1.836028. Batch_acc: 0.385955. Batch_loss: 1.743894 \n",
      "Batch: 4550. Acc: 0.353923. Loss: 1.836008. Batch_acc: 0.368237. Batch_loss: 1.745023 \n",
      "Batch: 4551. Acc: 0.353932. Loss: 1.835981. Batch_acc: 0.393818. Batch_loss: 1.712026 \n",
      "Batch: 4552. Acc: 0.353938. Loss: 1.835957. Batch_acc: 0.384702. Batch_loss: 1.730334 \n",
      "Batch: 4553. Acc: 0.353946. Loss: 1.835930. Batch_acc: 0.389052. Batch_loss: 1.713074 \n",
      "Batch: 4554. Acc: 0.353954. Loss: 1.835908. Batch_acc: 0.390387. Batch_loss: 1.730417 \n",
      "Batch: 4555. Acc: 0.353957. Loss: 1.835886. Batch_acc: 0.367536. Batch_loss: 1.737945 \n",
      "Batch: 4556. Acc: 0.353961. Loss: 1.835865. Batch_acc: 0.374927. Batch_loss: 1.738344 \n",
      "Batch: 4557. Acc: 0.353972. Loss: 1.835832. Batch_acc: 0.401267. Batch_loss: 1.685724 \n",
      "Batch: 4558. Acc: 0.353982. Loss: 1.835806. Batch_acc: 0.399533. Batch_loss: 1.712333 \n",
      "Batch: 4559. Acc: 0.353990. Loss: 1.835783. Batch_acc: 0.390607. Batch_loss: 1.731298 \n",
      "Batch: 4560. Acc: 0.353996. Loss: 1.835765. Batch_acc: 0.381724. Batch_loss: 1.756443 \n",
      "Batch: 4561. Acc: 0.354004. Loss: 1.835742. Batch_acc: 0.390598. Batch_loss: 1.725896 \n",
      "Batch: 4562. Acc: 0.354015. Loss: 1.835706. Batch_acc: 0.407514. Batch_loss: 1.672558 \n",
      "Batch: 4563. Acc: 0.354022. Loss: 1.835692. Batch_acc: 0.384660. Batch_loss: 1.771211 \n",
      "Batch: 4564. Acc: 0.354027. Loss: 1.835673. Batch_acc: 0.378235. Batch_loss: 1.748358 \n",
      "Batch: 4565. Acc: 0.354031. Loss: 1.835651. Batch_acc: 0.370220. Batch_loss: 1.732529 \n",
      "Batch: 4566. Acc: 0.354039. Loss: 1.835627. Batch_acc: 0.392606. Batch_loss: 1.722769 \n",
      "Batch: 4567. Acc: 0.354044. Loss: 1.835604. Batch_acc: 0.374651. Batch_loss: 1.734740 \n",
      "Batch: 4568. Acc: 0.354049. Loss: 1.835587. Batch_acc: 0.378042. Batch_loss: 1.761430 \n",
      "Batch: 4569. Acc: 0.354059. Loss: 1.835558. Batch_acc: 0.398295. Batch_loss: 1.704181 \n",
      "Batch: 4570. Acc: 0.354066. Loss: 1.835527. Batch_acc: 0.387413. Batch_loss: 1.692012 \n",
      "Batch: 4571. Acc: 0.354070. Loss: 1.835507. Batch_acc: 0.372660. Batch_loss: 1.744736 \n",
      "Batch: 4572. Acc: 0.354074. Loss: 1.835489. Batch_acc: 0.372284. Batch_loss: 1.752203 \n",
      "Batch: 4573. Acc: 0.354079. Loss: 1.835474. Batch_acc: 0.375726. Batch_loss: 1.765314 \n",
      "Batch: 4574. Acc: 0.354084. Loss: 1.835453. Batch_acc: 0.376532. Batch_loss: 1.739049 \n",
      "Batch: 4575. Acc: 0.354091. Loss: 1.835430. Batch_acc: 0.389335. Batch_loss: 1.731260 \n",
      "Batch: 4576. Acc: 0.354095. Loss: 1.835414. Batch_acc: 0.372039. Batch_loss: 1.759602 \n",
      "Batch: 4577. Acc: 0.354100. Loss: 1.835396. Batch_acc: 0.378084. Batch_loss: 1.753849 \n",
      "Batch: 4578. Acc: 0.354110. Loss: 1.835369. Batch_acc: 0.398064. Batch_loss: 1.712416 \n",
      "Batch: 4579. Acc: 0.354120. Loss: 1.835348. Batch_acc: 0.397590. Batch_loss: 1.739815 \n",
      "Batch: 4580. Acc: 0.354125. Loss: 1.835330. Batch_acc: 0.379532. Batch_loss: 1.750665 \n",
      "Batch: 4581. Acc: 0.354132. Loss: 1.835302. Batch_acc: 0.384571. Batch_loss: 1.707237 \n",
      "Batch: 4582. Acc: 0.354138. Loss: 1.835285. Batch_acc: 0.384293. Batch_loss: 1.755278 \n",
      "Batch: 4583. Acc: 0.354150. Loss: 1.835261. Batch_acc: 0.408801. Batch_loss: 1.726499 \n",
      "Batch: 4584. Acc: 0.354154. Loss: 1.835246. Batch_acc: 0.371641. Batch_loss: 1.764752 \n",
      "Batch: 4585. Acc: 0.354162. Loss: 1.835224. Batch_acc: 0.392918. Batch_loss: 1.736414 \n",
      "Batch: 4586. Acc: 0.354171. Loss: 1.835197. Batch_acc: 0.396183. Batch_loss: 1.709453 \n",
      "Batch: 4587. Acc: 0.354175. Loss: 1.835183. Batch_acc: 0.369328. Batch_loss: 1.769753 \n",
      "Batch: 4588. Acc: 0.354180. Loss: 1.835162. Batch_acc: 0.379797. Batch_loss: 1.744018 \n",
      "Batch: 4589. Acc: 0.354188. Loss: 1.835134. Batch_acc: 0.391155. Batch_loss: 1.704616 \n",
      "Batch: 4590. Acc: 0.354192. Loss: 1.835117. Batch_acc: 0.370413. Batch_loss: 1.755200 \n",
      "Batch: 4591. Acc: 0.354201. Loss: 1.835091. Batch_acc: 0.396723. Batch_loss: 1.716319 \n",
      "Batch: 4592. Acc: 0.354207. Loss: 1.835074. Batch_acc: 0.379988. Batch_loss: 1.757488 \n",
      "Batch: 4593. Acc: 0.354217. Loss: 1.835042. Batch_acc: 0.401709. Batch_loss: 1.690164 \n",
      "Batch: 4594. Acc: 0.354227. Loss: 1.835012. Batch_acc: 0.398091. Batch_loss: 1.696551 \n",
      "Batch: 4595. Acc: 0.354235. Loss: 1.834990. Batch_acc: 0.391052. Batch_loss: 1.733907 \n",
      "Batch: 4596. Acc: 0.354239. Loss: 1.834968. Batch_acc: 0.371544. Batch_loss: 1.734206 \n",
      "Batch: 4597. Acc: 0.354242. Loss: 1.834955. Batch_acc: 0.367771. Batch_loss: 1.778300 \n",
      "Batch: 4598. Acc: 0.354249. Loss: 1.834935. Batch_acc: 0.386298. Batch_loss: 1.742961 \n",
      "Batch: 4599. Acc: 0.354251. Loss: 1.834930. Batch_acc: 0.366077. Batch_loss: 1.809027 \n",
      "Batch: 4600. Acc: 0.354261. Loss: 1.834900. Batch_acc: 0.398851. Batch_loss: 1.696998 \n",
      "Batch: 4601. Acc: 0.354262. Loss: 1.834885. Batch_acc: 0.361789. Batch_loss: 1.767762 \n",
      "Batch: 4602. Acc: 0.354267. Loss: 1.834863. Batch_acc: 0.373869. Batch_loss: 1.732490 \n",
      "Batch: 4603. Acc: 0.354276. Loss: 1.834834. Batch_acc: 0.395012. Batch_loss: 1.700669 \n",
      "Batch: 4604. Acc: 0.354280. Loss: 1.834821. Batch_acc: 0.373333. Batch_loss: 1.775016 \n",
      "Batch: 4605. Acc: 0.354286. Loss: 1.834792. Batch_acc: 0.384660. Batch_loss: 1.700227 \n",
      "Batch: 4606. Acc: 0.354293. Loss: 1.834770. Batch_acc: 0.383673. Batch_loss: 1.735068 \n",
      "Batch: 4607. Acc: 0.354300. Loss: 1.834756. Batch_acc: 0.389723. Batch_loss: 1.770809 \n",
      "Batch: 4608. Acc: 0.354308. Loss: 1.834729. Batch_acc: 0.392111. Batch_loss: 1.705080 \n",
      "Batch: 4609. Acc: 0.354316. Loss: 1.834709. Batch_acc: 0.392065. Batch_loss: 1.741468 \n",
      "Batch: 4610. Acc: 0.354324. Loss: 1.834685. Batch_acc: 0.389908. Batch_loss: 1.726909 \n",
      "Batch: 4611. Acc: 0.354330. Loss: 1.834670. Batch_acc: 0.379613. Batch_loss: 1.765943 \n",
      "Batch: 4612. Acc: 0.354336. Loss: 1.834648. Batch_acc: 0.386087. Batch_loss: 1.729686 \n",
      "Batch: 4613. Acc: 0.354342. Loss: 1.834629. Batch_acc: 0.382016. Batch_loss: 1.749508 \n",
      "Batch: 4614. Acc: 0.354353. Loss: 1.834592. Batch_acc: 0.401955. Batch_loss: 1.664011 \n",
      "Batch: 4615. Acc: 0.354365. Loss: 1.834565. Batch_acc: 0.408751. Batch_loss: 1.707645 \n",
      "Batch: 4616. Acc: 0.354369. Loss: 1.834549. Batch_acc: 0.375286. Batch_loss: 1.761672 \n",
      "Batch: 4617. Acc: 0.354378. Loss: 1.834526. Batch_acc: 0.394276. Batch_loss: 1.725875 \n",
      "Batch: 4618. Acc: 0.354384. Loss: 1.834503. Batch_acc: 0.385017. Batch_loss: 1.726353 \n",
      "Batch: 4619. Acc: 0.354393. Loss: 1.834472. Batch_acc: 0.397252. Batch_loss: 1.694483 \n",
      "Batch: 4620. Acc: 0.354404. Loss: 1.834437. Batch_acc: 0.403509. Batch_loss: 1.673244 \n",
      "Batch: 4621. Acc: 0.354412. Loss: 1.834417. Batch_acc: 0.389370. Batch_loss: 1.741345 \n",
      "Batch: 4622. Acc: 0.354416. Loss: 1.834400. Batch_acc: 0.375793. Batch_loss: 1.758369 \n",
      "Batch: 4623. Acc: 0.354424. Loss: 1.834376. Batch_acc: 0.391782. Batch_loss: 1.720690 \n",
      "Batch: 4624. Acc: 0.354430. Loss: 1.834355. Batch_acc: 0.381371. Batch_loss: 1.734953 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4625. Acc: 0.354437. Loss: 1.834329. Batch_acc: 0.386054. Batch_loss: 1.716416 \n",
      "Batch: 4626. Acc: 0.354442. Loss: 1.834312. Batch_acc: 0.376820. Batch_loss: 1.756577 \n",
      "Batch: 4627. Acc: 0.354446. Loss: 1.834295. Batch_acc: 0.372053. Batch_loss: 1.753340 \n",
      "Batch: 4628. Acc: 0.354453. Loss: 1.834270. Batch_acc: 0.387514. Batch_loss: 1.723847 \n",
      "Batch: 4629. Acc: 0.354461. Loss: 1.834241. Batch_acc: 0.394242. Batch_loss: 1.697518 \n",
      "Batch: 4630. Acc: 0.354466. Loss: 1.834220. Batch_acc: 0.375655. Batch_loss: 1.735706 \n",
      "Batch: 4631. Acc: 0.354473. Loss: 1.834197. Batch_acc: 0.389959. Batch_loss: 1.722780 \n",
      "Batch: 4632. Acc: 0.354480. Loss: 1.834177. Batch_acc: 0.387287. Batch_loss: 1.740745 \n",
      "Batch: 4633. Acc: 0.354487. Loss: 1.834157. Batch_acc: 0.384390. Batch_loss: 1.738327 \n",
      "Batch: 4634. Acc: 0.354493. Loss: 1.834133. Batch_acc: 0.383295. Batch_loss: 1.723724 \n",
      "Batch: 4635. Acc: 0.354496. Loss: 1.834117. Batch_acc: 0.366173. Batch_loss: 1.763028 \n",
      "Batch: 4636. Acc: 0.354503. Loss: 1.834091. Batch_acc: 0.391003. Batch_loss: 1.713489 \n",
      "Batch: 4637. Acc: 0.354511. Loss: 1.834067. Batch_acc: 0.389869. Batch_loss: 1.720711 \n",
      "Batch: 4638. Acc: 0.354519. Loss: 1.834044. Batch_acc: 0.390029. Batch_loss: 1.726882 \n",
      "Batch: 4639. Acc: 0.354525. Loss: 1.834026. Batch_acc: 0.384923. Batch_loss: 1.749902 \n",
      "Batch: 4640. Acc: 0.354528. Loss: 1.834016. Batch_acc: 0.367118. Batch_loss: 1.786855 \n",
      "Batch: 4641. Acc: 0.354534. Loss: 1.833990. Batch_acc: 0.382919. Batch_loss: 1.718225 \n",
      "Batch: 4642. Acc: 0.354541. Loss: 1.833964. Batch_acc: 0.385452. Batch_loss: 1.710014 \n",
      "Batch: 4643. Acc: 0.354548. Loss: 1.833939. Batch_acc: 0.386628. Batch_loss: 1.720789 \n",
      "Batch: 4644. Acc: 0.354552. Loss: 1.833923. Batch_acc: 0.375144. Batch_loss: 1.758208 \n",
      "Batch: 4645. Acc: 0.354560. Loss: 1.833900. Batch_acc: 0.390909. Batch_loss: 1.729969 \n",
      "Batch: 4646. Acc: 0.354573. Loss: 1.833864. Batch_acc: 0.416054. Batch_loss: 1.668989 \n",
      "Batch: 4647. Acc: 0.354578. Loss: 1.833845. Batch_acc: 0.373988. Batch_loss: 1.745574 \n",
      "Batch: 4648. Acc: 0.354586. Loss: 1.833819. Batch_acc: 0.393003. Batch_loss: 1.711161 \n",
      "Batch: 4649. Acc: 0.354595. Loss: 1.833795. Batch_acc: 0.395028. Batch_loss: 1.723154 \n",
      "Batch: 4650. Acc: 0.354601. Loss: 1.833771. Batch_acc: 0.383205. Batch_loss: 1.722307 \n",
      "Batch: 4651. Acc: 0.354610. Loss: 1.833749. Batch_acc: 0.395349. Batch_loss: 1.733247 \n",
      "Batch: 4652. Acc: 0.354620. Loss: 1.833721. Batch_acc: 0.400689. Batch_loss: 1.701886 \n",
      "Batch: 4653. Acc: 0.354626. Loss: 1.833700. Batch_acc: 0.384300. Batch_loss: 1.736024 \n",
      "Batch: 4654. Acc: 0.354632. Loss: 1.833679. Batch_acc: 0.384136. Batch_loss: 1.736432 \n",
      "Batch: 4655. Acc: 0.354644. Loss: 1.833644. Batch_acc: 0.409347. Batch_loss: 1.673086 \n",
      "Batch: 4656. Acc: 0.354651. Loss: 1.833614. Batch_acc: 0.385279. Batch_loss: 1.692299 \n",
      "Batch: 4657. Acc: 0.354663. Loss: 1.833582. Batch_acc: 0.409480. Batch_loss: 1.689014 \n",
      "Batch: 4658. Acc: 0.354671. Loss: 1.833561. Batch_acc: 0.393850. Batch_loss: 1.732905 \n",
      "Batch: 4659. Acc: 0.354679. Loss: 1.833536. Batch_acc: 0.390509. Batch_loss: 1.717325 \n",
      "Batch: 4660. Acc: 0.354684. Loss: 1.833517. Batch_acc: 0.378917. Batch_loss: 1.743673 \n",
      "Batch: 4661. Acc: 0.354689. Loss: 1.833498. Batch_acc: 0.379270. Batch_loss: 1.747577 \n",
      "Batch: 4662. Acc: 0.354694. Loss: 1.833480. Batch_acc: 0.379291. Batch_loss: 1.746831 \n",
      "Batch: 4663. Acc: 0.354703. Loss: 1.833455. Batch_acc: 0.396366. Batch_loss: 1.721143 \n",
      "Batch: 4664. Acc: 0.354705. Loss: 1.833441. Batch_acc: 0.360741. Batch_loss: 1.767609 \n",
      "Batch: 4665. Acc: 0.354714. Loss: 1.833414. Batch_acc: 0.399302. Batch_loss: 1.705265 \n",
      "Batch: 4666. Acc: 0.354724. Loss: 1.833392. Batch_acc: 0.401739. Batch_loss: 1.727041 \n",
      "Batch: 4667. Acc: 0.354733. Loss: 1.833371. Batch_acc: 0.395280. Batch_loss: 1.734081 \n",
      "Batch: 4668. Acc: 0.354741. Loss: 1.833345. Batch_acc: 0.390546. Batch_loss: 1.713342 \n",
      "Batch: 4669. Acc: 0.354748. Loss: 1.833321. Batch_acc: 0.388222. Batch_loss: 1.723782 \n",
      "Batch: 4670. Acc: 0.354753. Loss: 1.833300. Batch_acc: 0.379849. Batch_loss: 1.736125 \n",
      "Batch: 4671. Acc: 0.354757. Loss: 1.833281. Batch_acc: 0.374080. Batch_loss: 1.746442 \n",
      "Batch: 4672. Acc: 0.354763. Loss: 1.833264. Batch_acc: 0.379882. Batch_loss: 1.751162 \n",
      "Batch: 4673. Acc: 0.354766. Loss: 1.833251. Batch_acc: 0.370392. Batch_loss: 1.767005 \n",
      "Batch: 4674. Acc: 0.354770. Loss: 1.833233. Batch_acc: 0.374076. Batch_loss: 1.751271 \n",
      "Batch: 4675. Acc: 0.354773. Loss: 1.833217. Batch_acc: 0.368954. Batch_loss: 1.760449 \n",
      "Batch: 4676. Acc: 0.354777. Loss: 1.833191. Batch_acc: 0.374640. Batch_loss: 1.713111 \n",
      "Batch: 4677. Acc: 0.354782. Loss: 1.833172. Batch_acc: 0.378084. Batch_loss: 1.744389 \n",
      "Batch: 4678. Acc: 0.354794. Loss: 1.833137. Batch_acc: 0.407199. Batch_loss: 1.671715 \n",
      "Batch: 4679. Acc: 0.354798. Loss: 1.833116. Batch_acc: 0.376593. Batch_loss: 1.735493 \n",
      "Batch: 4680. Acc: 0.354806. Loss: 1.833088. Batch_acc: 0.391379. Batch_loss: 1.702571 \n",
      "Batch: 4681. Acc: 0.354814. Loss: 1.833063. Batch_acc: 0.389595. Batch_loss: 1.713165 \n",
      "Batch: 4682. Acc: 0.354821. Loss: 1.833034. Batch_acc: 0.389937. Batch_loss: 1.700408 \n",
      "Batch: 4683. Acc: 0.354828. Loss: 1.833011. Batch_acc: 0.389860. Batch_loss: 1.723992 \n",
      "Batch: 4684. Acc: 0.354839. Loss: 1.832981. Batch_acc: 0.405980. Batch_loss: 1.692650 \n",
      "Batch: 4685. Acc: 0.354846. Loss: 1.832960. Batch_acc: 0.387152. Batch_loss: 1.734548 \n",
      "Batch: 4686. Acc: 0.354853. Loss: 1.832938. Batch_acc: 0.387471. Batch_loss: 1.726767 \n",
      "Batch: 4687. Acc: 0.354858. Loss: 1.832924. Batch_acc: 0.400000. Batch_loss: 1.706967 \n",
      "[Training]  loss: 1.8329242163823047, ppl:  6.252143, accuracy: 35.486 %, elapse: 3851959.185ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.6742015378549306,  ppl:  5.33453, accuracy: 40.965 %, elapse: 37957.894ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1086.376428604126ms\n",
      "[ Epoch: 2 / 8, Run Batch: 9376 / None]\n",
      "Batch: 0. Acc: 0.379511. Loss: 1.744545. Batch_acc: 0.379511. Batch_loss: 1.744545 \n",
      "Batch: 1. Acc: 0.390173. Loss: 1.724140. Batch_acc: 0.400689. Batch_loss: 1.704016 \n",
      "Batch: 2. Acc: 0.389144. Loss: 1.721261. Batch_acc: 0.387133. Batch_loss: 1.715640 \n",
      "Batch: 3. Acc: 0.382060. Loss: 1.739770. Batch_acc: 0.360142. Batch_loss: 1.797038 \n",
      "Batch: 4. Acc: 0.383202. Loss: 1.735595. Batch_acc: 0.387767. Batch_loss: 1.718918 \n",
      "Batch: 5. Acc: 0.385923. Loss: 1.729495. Batch_acc: 0.399317. Batch_loss: 1.699460 \n",
      "Batch: 6. Acc: 0.388186. Loss: 1.730221. Batch_acc: 0.401593. Batch_loss: 1.734522 \n",
      "Batch: 7. Acc: 0.388361. Loss: 1.727011. Batch_acc: 0.389595. Batch_loss: 1.704422 \n",
      "Batch: 8. Acc: 0.388686. Loss: 1.727571. Batch_acc: 0.391382. Batch_loss: 1.732234 \n",
      "Batch: 9. Acc: 0.389762. Loss: 1.723978. Batch_acc: 0.399424. Batch_loss: 1.691724 \n",
      "Batch: 10. Acc: 0.389338. Loss: 1.723968. Batch_acc: 0.385143. Batch_loss: 1.723866 \n",
      "Batch: 11. Acc: 0.391652. Loss: 1.718023. Batch_acc: 0.417396. Batch_loss: 1.651881 \n",
      "Batch: 12. Acc: 0.392824. Loss: 1.717723. Batch_acc: 0.406977. Batch_loss: 1.714100 \n",
      "Batch: 13. Acc: 0.392247. Loss: 1.716306. Batch_acc: 0.384878. Batch_loss: 1.698188 \n",
      "Batch: 14. Acc: 0.391462. Loss: 1.718587. Batch_acc: 0.380428. Batch_loss: 1.750624 \n",
      "Batch: 15. Acc: 0.390888. Loss: 1.720821. Batch_acc: 0.382128. Batch_loss: 1.754943 \n",
      "Batch: 16. Acc: 0.391730. Loss: 1.718881. Batch_acc: 0.405020. Batch_loss: 1.688240 \n",
      "Batch: 17. Acc: 0.391285. Loss: 1.718873. Batch_acc: 0.383827. Batch_loss: 1.718751 \n",
      "Batch: 18. Acc: 0.390674. Loss: 1.720521. Batch_acc: 0.379532. Batch_loss: 1.750563 \n",
      "Batch: 19. Acc: 0.390056. Loss: 1.722241. Batch_acc: 0.378092. Batch_loss: 1.755569 \n",
      "Batch: 20. Acc: 0.391402. Loss: 1.720730. Batch_acc: 0.417800. Batch_loss: 1.691094 \n",
      "Batch: 21. Acc: 0.391635. Loss: 1.719823. Batch_acc: 0.396532. Batch_loss: 1.700771 \n",
      "Batch: 22. Acc: 0.392789. Loss: 1.717968. Batch_acc: 0.417657. Batch_loss: 1.677977 \n",
      "Batch: 23. Acc: 0.393316. Loss: 1.717064. Batch_acc: 0.405207. Batch_loss: 1.696681 \n",
      "Batch: 24. Acc: 0.392630. Loss: 1.718764. Batch_acc: 0.375740. Batch_loss: 1.760625 \n",
      "Batch: 25. Acc: 0.392387. Loss: 1.718909. Batch_acc: 0.386441. Batch_loss: 1.722465 \n",
      "Batch: 26. Acc: 0.392360. Loss: 1.717620. Batch_acc: 0.391671. Batch_loss: 1.684912 \n",
      "Batch: 27. Acc: 0.392493. Loss: 1.717460. Batch_acc: 0.396074. Batch_loss: 1.713140 \n",
      "Batch: 28. Acc: 0.392443. Loss: 1.716775. Batch_acc: 0.391026. Batch_loss: 1.697363 \n",
      "Batch: 29. Acc: 0.392182. Loss: 1.717815. Batch_acc: 0.384615. Batch_loss: 1.748082 \n",
      "Batch: 30. Acc: 0.392650. Loss: 1.716257. Batch_acc: 0.406701. Batch_loss: 1.669426 \n",
      "Batch: 31. Acc: 0.392022. Loss: 1.716688. Batch_acc: 0.372795. Batch_loss: 1.729873 \n",
      "Batch: 32. Acc: 0.392014. Loss: 1.716718. Batch_acc: 0.391770. Batch_loss: 1.717663 \n",
      "Batch: 33. Acc: 0.392069. Loss: 1.716112. Batch_acc: 0.393871. Batch_loss: 1.696392 \n",
      "Batch: 34. Acc: 0.391804. Loss: 1.715923. Batch_acc: 0.382745. Batch_loss: 1.709475 \n",
      "Batch: 35. Acc: 0.391784. Loss: 1.716087. Batch_acc: 0.391052. Batch_loss: 1.721865 \n",
      "Batch: 36. Acc: 0.392123. Loss: 1.715547. Batch_acc: 0.404403. Batch_loss: 1.696005 \n",
      "Batch: 37. Acc: 0.392279. Loss: 1.715324. Batch_acc: 0.397965. Batch_loss: 1.707218 \n",
      "Batch: 38. Acc: 0.392358. Loss: 1.715270. Batch_acc: 0.395270. Batch_loss: 1.713247 \n",
      "Batch: 39. Acc: 0.392506. Loss: 1.714789. Batch_acc: 0.398190. Batch_loss: 1.696364 \n",
      "Batch: 40. Acc: 0.392304. Loss: 1.714843. Batch_acc: 0.384217. Batch_loss: 1.717015 \n",
      "Batch: 41. Acc: 0.392644. Loss: 1.713388. Batch_acc: 0.406128. Batch_loss: 1.655592 \n",
      "Batch: 42. Acc: 0.392300. Loss: 1.713701. Batch_acc: 0.377993. Batch_loss: 1.726744 \n",
      "Batch: 43. Acc: 0.392167. Loss: 1.713910. Batch_acc: 0.386324. Batch_loss: 1.723063 \n",
      "Batch: 44. Acc: 0.392049. Loss: 1.713661. Batch_acc: 0.386675. Batch_loss: 1.702301 \n",
      "Batch: 45. Acc: 0.392582. Loss: 1.712739. Batch_acc: 0.416149. Batch_loss: 1.672011 \n",
      "Batch: 46. Acc: 0.392862. Loss: 1.712078. Batch_acc: 0.405780. Batch_loss: 1.681533 \n",
      "Batch: 47. Acc: 0.393018. Loss: 1.711429. Batch_acc: 0.400226. Batch_loss: 1.681420 \n",
      "Batch: 48. Acc: 0.392624. Loss: 1.712365. Batch_acc: 0.373550. Batch_loss: 1.757700 \n",
      "Batch: 49. Acc: 0.392527. Loss: 1.712637. Batch_acc: 0.387719. Batch_loss: 1.726229 \n",
      "Batch: 50. Acc: 0.392156. Loss: 1.713071. Batch_acc: 0.373714. Batch_loss: 1.734619 \n",
      "Batch: 51. Acc: 0.392229. Loss: 1.712935. Batch_acc: 0.396028. Batch_loss: 1.705879 \n",
      "Batch: 52. Acc: 0.391936. Loss: 1.713223. Batch_acc: 0.376975. Batch_loss: 1.727893 \n",
      "Batch: 53. Acc: 0.391594. Loss: 1.713709. Batch_acc: 0.373494. Batch_loss: 1.739432 \n",
      "Batch: 54. Acc: 0.391651. Loss: 1.713611. Batch_acc: 0.394664. Batch_loss: 1.708512 \n",
      "Batch: 55. Acc: 0.391805. Loss: 1.713151. Batch_acc: 0.400348. Batch_loss: 1.687615 \n",
      "Batch: 56. Acc: 0.391684. Loss: 1.713240. Batch_acc: 0.384966. Batch_loss: 1.718191 \n",
      "Batch: 57. Acc: 0.391519. Loss: 1.713629. Batch_acc: 0.382151. Batch_loss: 1.735676 \n",
      "Batch: 58. Acc: 0.391552. Loss: 1.713436. Batch_acc: 0.393433. Batch_loss: 1.702210 \n",
      "Batch: 59. Acc: 0.391197. Loss: 1.713986. Batch_acc: 0.369871. Batch_loss: 1.747119 \n",
      "Batch: 60. Acc: 0.391155. Loss: 1.714973. Batch_acc: 0.388565. Batch_loss: 1.775064 \n",
      "Batch: 61. Acc: 0.391127. Loss: 1.714918. Batch_acc: 0.389406. Batch_loss: 1.711543 \n",
      "Batch: 62. Acc: 0.390898. Loss: 1.715428. Batch_acc: 0.376395. Batch_loss: 1.747729 \n",
      "Batch: 63. Acc: 0.390854. Loss: 1.716464. Batch_acc: 0.388077. Batch_loss: 1.782748 \n",
      "Batch: 64. Acc: 0.390700. Loss: 1.716612. Batch_acc: 0.380645. Batch_loss: 1.726293 \n",
      "Batch: 65. Acc: 0.390604. Loss: 1.716645. Batch_acc: 0.384161. Batch_loss: 1.718801 \n",
      "Batch: 66. Acc: 0.390491. Loss: 1.717079. Batch_acc: 0.383065. Batch_loss: 1.745726 \n",
      "Batch: 67. Acc: 0.390579. Loss: 1.717414. Batch_acc: 0.396290. Batch_loss: 1.739383 \n",
      "Batch: 68. Acc: 0.390740. Loss: 1.717144. Batch_acc: 0.401869. Batch_loss: 1.698458 \n",
      "Batch: 69. Acc: 0.390921. Loss: 1.716648. Batch_acc: 0.403621. Batch_loss: 1.681939 \n",
      "Batch: 70. Acc: 0.390796. Loss: 1.717008. Batch_acc: 0.382067. Batch_loss: 1.742039 \n",
      "Batch: 71. Acc: 0.390924. Loss: 1.716717. Batch_acc: 0.400116. Batch_loss: 1.695918 \n",
      "Batch: 72. Acc: 0.390650. Loss: 1.717474. Batch_acc: 0.369855. Batch_loss: 1.774781 \n",
      "Batch: 73. Acc: 0.390510. Loss: 1.717442. Batch_acc: 0.380410. Batch_loss: 1.715149 \n",
      "Batch: 74. Acc: 0.390517. Loss: 1.717666. Batch_acc: 0.391101. Batch_loss: 1.734438 \n",
      "Batch: 75. Acc: 0.390407. Loss: 1.718281. Batch_acc: 0.382062. Batch_loss: 1.764920 \n",
      "Batch: 76. Acc: 0.390392. Loss: 1.718491. Batch_acc: 0.389235. Batch_loss: 1.734184 \n",
      "Batch: 77. Acc: 0.390618. Loss: 1.717730. Batch_acc: 0.408116. Batch_loss: 1.658826 \n",
      "Batch: 78. Acc: 0.390539. Loss: 1.717538. Batch_acc: 0.384393. Batch_loss: 1.702492 \n",
      "Batch: 79. Acc: 0.390704. Loss: 1.717277. Batch_acc: 0.403361. Batch_loss: 1.697193 \n",
      "Batch: 80. Acc: 0.390486. Loss: 1.717698. Batch_acc: 0.372812. Batch_loss: 1.751850 \n",
      "Batch: 81. Acc: 0.390532. Loss: 1.718092. Batch_acc: 0.394198. Batch_loss: 1.749581 \n",
      "Batch: 82. Acc: 0.390668. Loss: 1.717843. Batch_acc: 0.401575. Batch_loss: 1.697887 \n",
      "Batch: 83. Acc: 0.390587. Loss: 1.717783. Batch_acc: 0.383959. Batch_loss: 1.712848 \n",
      "Batch: 84. Acc: 0.390662. Loss: 1.717480. Batch_acc: 0.396907. Batch_loss: 1.692202 \n",
      "Batch: 85. Acc: 0.390771. Loss: 1.717544. Batch_acc: 0.400000. Batch_loss: 1.722999 \n",
      "Batch: 86. Acc: 0.390923. Loss: 1.717395. Batch_acc: 0.403879. Batch_loss: 1.704714 \n",
      "Batch: 87. Acc: 0.390785. Loss: 1.718001. Batch_acc: 0.378427. Batch_loss: 1.772528 \n",
      "Batch: 88. Acc: 0.390554. Loss: 1.718283. Batch_acc: 0.370349. Batch_loss: 1.742988 \n",
      "Batch: 89. Acc: 0.390396. Loss: 1.718190. Batch_acc: 0.376557. Batch_loss: 1.709991 \n",
      "Batch: 90. Acc: 0.390469. Loss: 1.718130. Batch_acc: 0.397008. Batch_loss: 1.712766 \n",
      "Batch: 91. Acc: 0.390366. Loss: 1.718599. Batch_acc: 0.380952. Batch_loss: 1.761612 \n",
      "Batch: 92. Acc: 0.390345. Loss: 1.718732. Batch_acc: 0.388377. Batch_loss: 1.731023 \n",
      "Batch: 93. Acc: 0.390288. Loss: 1.718813. Batch_acc: 0.385097. Batch_loss: 1.726233 \n",
      "Batch: 94. Acc: 0.390203. Loss: 1.718948. Batch_acc: 0.382353. Batch_loss: 1.731405 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.390158. Loss: 1.718905. Batch_acc: 0.385748. Batch_loss: 1.714752 \n",
      "Batch: 96. Acc: 0.390177. Loss: 1.718798. Batch_acc: 0.391954. Batch_loss: 1.708478 \n",
      "Batch: 97. Acc: 0.390196. Loss: 1.718869. Batch_acc: 0.392055. Batch_loss: 1.725795 \n",
      "Batch: 98. Acc: 0.390093. Loss: 1.719064. Batch_acc: 0.380170. Batch_loss: 1.737883 \n",
      "Batch: 99. Acc: 0.390229. Loss: 1.718568. Batch_acc: 0.403691. Batch_loss: 1.669396 \n",
      "Batch: 100. Acc: 0.390426. Loss: 1.718109. Batch_acc: 0.410138. Batch_loss: 1.672101 \n",
      "Batch: 101. Acc: 0.390320. Loss: 1.718271. Batch_acc: 0.379725. Batch_loss: 1.734562 \n",
      "Batch: 102. Acc: 0.390508. Loss: 1.717715. Batch_acc: 0.409453. Batch_loss: 1.661689 \n",
      "Batch: 103. Acc: 0.390232. Loss: 1.718078. Batch_acc: 0.361579. Batch_loss: 1.755745 \n",
      "Batch: 104. Acc: 0.390243. Loss: 1.717982. Batch_acc: 0.391354. Batch_loss: 1.708009 \n",
      "Batch: 105. Acc: 0.390393. Loss: 1.717922. Batch_acc: 0.405846. Batch_loss: 1.711712 \n",
      "Batch: 106. Acc: 0.390221. Loss: 1.718064. Batch_acc: 0.371462. Batch_loss: 1.733531 \n",
      "Batch: 107. Acc: 0.390203. Loss: 1.717896. Batch_acc: 0.388383. Batch_loss: 1.700139 \n",
      "Batch: 108. Acc: 0.390194. Loss: 1.717777. Batch_acc: 0.389180. Batch_loss: 1.704716 \n",
      "Batch: 109. Acc: 0.390186. Loss: 1.717810. Batch_acc: 0.389330. Batch_loss: 1.721358 \n",
      "Batch: 110. Acc: 0.390200. Loss: 1.717767. Batch_acc: 0.391740. Batch_loss: 1.712893 \n",
      "Batch: 111. Acc: 0.390220. Loss: 1.718022. Batch_acc: 0.392496. Batch_loss: 1.747343 \n",
      "Batch: 112. Acc: 0.390217. Loss: 1.718067. Batch_acc: 0.389898. Batch_loss: 1.723082 \n",
      "Batch: 113. Acc: 0.390245. Loss: 1.718104. Batch_acc: 0.393296. Batch_loss: 1.722100 \n",
      "Batch: 114. Acc: 0.390233. Loss: 1.718046. Batch_acc: 0.388857. Batch_loss: 1.711501 \n",
      "Batch: 115. Acc: 0.390063. Loss: 1.718146. Batch_acc: 0.370793. Batch_loss: 1.729536 \n",
      "Batch: 116. Acc: 0.390044. Loss: 1.718030. Batch_acc: 0.387802. Batch_loss: 1.704556 \n",
      "Batch: 117. Acc: 0.389927. Loss: 1.718157. Batch_acc: 0.375674. Batch_loss: 1.733605 \n",
      "Batch: 118. Acc: 0.389936. Loss: 1.718181. Batch_acc: 0.391003. Batch_loss: 1.720983 \n",
      "Batch: 119. Acc: 0.389737. Loss: 1.718631. Batch_acc: 0.365610. Batch_loss: 1.773205 \n",
      "Batch: 120. Acc: 0.389728. Loss: 1.718829. Batch_acc: 0.388631. Batch_loss: 1.742789 \n",
      "Batch: 121. Acc: 0.389668. Loss: 1.718978. Batch_acc: 0.382353. Batch_loss: 1.737115 \n",
      "Batch: 122. Acc: 0.389857. Loss: 1.718591. Batch_acc: 0.412125. Batch_loss: 1.672965 \n",
      "Batch: 123. Acc: 0.389870. Loss: 1.718643. Batch_acc: 0.391525. Batch_loss: 1.724933 \n",
      "Batch: 124. Acc: 0.389885. Loss: 1.718513. Batch_acc: 0.391657. Batch_loss: 1.702234 \n",
      "Batch: 125. Acc: 0.389844. Loss: 1.718730. Batch_acc: 0.384750. Batch_loss: 1.746120 \n",
      "Batch: 126. Acc: 0.390032. Loss: 1.718219. Batch_acc: 0.413555. Batch_loss: 1.654043 \n",
      "Batch: 127. Acc: 0.389936. Loss: 1.718244. Batch_acc: 0.377635. Batch_loss: 1.721484 \n",
      "Batch: 128. Acc: 0.389885. Loss: 1.718166. Batch_acc: 0.383390. Batch_loss: 1.708238 \n",
      "Batch: 129. Acc: 0.389829. Loss: 1.718081. Batch_acc: 0.382353. Batch_loss: 1.706692 \n",
      "Batch: 130. Acc: 0.389869. Loss: 1.717961. Batch_acc: 0.395040. Batch_loss: 1.702314 \n",
      "Batch: 131. Acc: 0.389984. Loss: 1.717827. Batch_acc: 0.405063. Batch_loss: 1.700384 \n",
      "Batch: 132. Acc: 0.389850. Loss: 1.718242. Batch_acc: 0.371581. Batch_loss: 1.774796 \n",
      "Batch: 133. Acc: 0.389842. Loss: 1.718049. Batch_acc: 0.388763. Batch_loss: 1.692726 \n",
      "Batch: 134. Acc: 0.389873. Loss: 1.717695. Batch_acc: 0.394097. Batch_loss: 1.670051 \n",
      "Batch: 135. Acc: 0.389948. Loss: 1.717770. Batch_acc: 0.400234. Batch_loss: 1.727968 \n",
      "Batch: 136. Acc: 0.389796. Loss: 1.718033. Batch_acc: 0.369492. Batch_loss: 1.753120 \n",
      "Batch: 137. Acc: 0.389738. Loss: 1.718050. Batch_acc: 0.381797. Batch_loss: 1.720376 \n",
      "Batch: 138. Acc: 0.389773. Loss: 1.717966. Batch_acc: 0.394470. Batch_loss: 1.706657 \n",
      "Batch: 139. Acc: 0.389797. Loss: 1.717900. Batch_acc: 0.393232. Batch_loss: 1.708557 \n",
      "Batch: 140. Acc: 0.389811. Loss: 1.717696. Batch_acc: 0.391776. Batch_loss: 1.689461 \n",
      "Batch: 141. Acc: 0.389841. Loss: 1.717715. Batch_acc: 0.394169. Batch_loss: 1.720373 \n",
      "Batch: 142. Acc: 0.389932. Loss: 1.717364. Batch_acc: 0.402738. Batch_loss: 1.668015 \n",
      "Batch: 143. Acc: 0.389960. Loss: 1.717251. Batch_acc: 0.393836. Batch_loss: 1.701268 \n",
      "Batch: 144. Acc: 0.389937. Loss: 1.717094. Batch_acc: 0.386728. Batch_loss: 1.694645 \n",
      "Batch: 145. Acc: 0.389958. Loss: 1.717158. Batch_acc: 0.392877. Batch_loss: 1.726225 \n",
      "Batch: 146. Acc: 0.390010. Loss: 1.717153. Batch_acc: 0.397523. Batch_loss: 1.716451 \n",
      "Batch: 147. Acc: 0.389993. Loss: 1.717202. Batch_acc: 0.387450. Batch_loss: 1.724346 \n",
      "Batch: 148. Acc: 0.389901. Loss: 1.717310. Batch_acc: 0.376491. Batch_loss: 1.733168 \n",
      "Batch: 149. Acc: 0.389735. Loss: 1.717672. Batch_acc: 0.364387. Batch_loss: 1.772869 \n",
      "Batch: 150. Acc: 0.389582. Loss: 1.718002. Batch_acc: 0.366571. Batch_loss: 1.767594 \n",
      "Batch: 151. Acc: 0.389435. Loss: 1.718270. Batch_acc: 0.367241. Batch_loss: 1.758537 \n",
      "Batch: 152. Acc: 0.389383. Loss: 1.718432. Batch_acc: 0.381503. Batch_loss: 1.743239 \n",
      "Batch: 153. Acc: 0.389207. Loss: 1.718997. Batch_acc: 0.362817. Batch_loss: 1.803600 \n",
      "Batch: 154. Acc: 0.389122. Loss: 1.719265. Batch_acc: 0.376083. Batch_loss: 1.760675 \n",
      "Batch: 155. Acc: 0.389238. Loss: 1.718941. Batch_acc: 0.406944. Batch_loss: 1.669253 \n",
      "Batch: 156. Acc: 0.389192. Loss: 1.719054. Batch_acc: 0.382155. Batch_loss: 1.736323 \n",
      "Batch: 157. Acc: 0.389102. Loss: 1.719264. Batch_acc: 0.374927. Batch_loss: 1.752425 \n",
      "Batch: 158. Acc: 0.389136. Loss: 1.719105. Batch_acc: 0.394511. Batch_loss: 1.694091 \n",
      "Batch: 159. Acc: 0.389091. Loss: 1.719222. Batch_acc: 0.382173. Batch_loss: 1.737267 \n",
      "Batch: 160. Acc: 0.389207. Loss: 1.719082. Batch_acc: 0.407513. Batch_loss: 1.697035 \n",
      "Batch: 161. Acc: 0.389310. Loss: 1.718860. Batch_acc: 0.406195. Batch_loss: 1.682480 \n",
      "Batch: 162. Acc: 0.389378. Loss: 1.718694. Batch_acc: 0.400000. Batch_loss: 1.692556 \n",
      "Batch: 163. Acc: 0.389468. Loss: 1.718634. Batch_acc: 0.403966. Batch_loss: 1.709021 \n",
      "Batch: 164. Acc: 0.389539. Loss: 1.718518. Batch_acc: 0.401408. Batch_loss: 1.699125 \n",
      "Batch: 165. Acc: 0.389480. Loss: 1.718545. Batch_acc: 0.379769. Batch_loss: 1.722914 \n",
      "Batch: 166. Acc: 0.389455. Loss: 1.718347. Batch_acc: 0.385311. Batch_loss: 1.686034 \n",
      "Batch: 167. Acc: 0.389437. Loss: 1.718125. Batch_acc: 0.386507. Batch_loss: 1.681414 \n",
      "Batch: 168. Acc: 0.389362. Loss: 1.718411. Batch_acc: 0.376787. Batch_loss: 1.766071 \n",
      "Batch: 169. Acc: 0.389409. Loss: 1.718341. Batch_acc: 0.397260. Batch_loss: 1.706615 \n",
      "Batch: 170. Acc: 0.389361. Loss: 1.718417. Batch_acc: 0.381437. Batch_loss: 1.731129 \n",
      "Batch: 171. Acc: 0.389324. Loss: 1.718420. Batch_acc: 0.382831. Batch_loss: 1.719008 \n",
      "Batch: 172. Acc: 0.389234. Loss: 1.718582. Batch_acc: 0.374007. Batch_loss: 1.746017 \n",
      "Batch: 173. Acc: 0.389309. Loss: 1.718327. Batch_acc: 0.402312. Batch_loss: 1.674082 \n",
      "Batch: 174. Acc: 0.389226. Loss: 1.718317. Batch_acc: 0.374710. Batch_loss: 1.716479 \n",
      "Batch: 175. Acc: 0.389214. Loss: 1.718452. Batch_acc: 0.387097. Batch_loss: 1.742171 \n",
      "Batch: 176. Acc: 0.389233. Loss: 1.718520. Batch_acc: 0.392751. Batch_loss: 1.730784 \n",
      "Batch: 177. Acc: 0.389083. Loss: 1.718936. Batch_acc: 0.362269. Batch_loss: 1.793123 \n",
      "Batch: 178. Acc: 0.389033. Loss: 1.719048. Batch_acc: 0.380093. Batch_loss: 1.739208 \n",
      "Batch: 179. Acc: 0.389037. Loss: 1.719061. Batch_acc: 0.389685. Batch_loss: 1.721212 \n",
      "Batch: 180. Acc: 0.389258. Loss: 1.718703. Batch_acc: 0.428330. Batch_loss: 1.655660 \n",
      "Batch: 181. Acc: 0.389284. Loss: 1.718562. Batch_acc: 0.393974. Batch_loss: 1.693259 \n",
      "Batch: 182. Acc: 0.389238. Loss: 1.718554. Batch_acc: 0.380760. Batch_loss: 1.717017 \n",
      "Batch: 183. Acc: 0.389232. Loss: 1.718483. Batch_acc: 0.388102. Batch_loss: 1.705682 \n",
      "Batch: 184. Acc: 0.389386. Loss: 1.718101. Batch_acc: 0.417671. Batch_loss: 1.648133 \n",
      "Batch: 185. Acc: 0.389377. Loss: 1.718143. Batch_acc: 0.387826. Batch_loss: 1.725895 \n",
      "Batch: 186. Acc: 0.389304. Loss: 1.718185. Batch_acc: 0.375649. Batch_loss: 1.726143 \n",
      "Batch: 187. Acc: 0.389255. Loss: 1.718113. Batch_acc: 0.380137. Batch_loss: 1.704714 \n",
      "Batch: 188. Acc: 0.389137. Loss: 1.718400. Batch_acc: 0.367125. Batch_loss: 1.772003 \n",
      "Batch: 189. Acc: 0.389126. Loss: 1.718471. Batch_acc: 0.386891. Batch_loss: 1.732096 \n",
      "Batch: 190. Acc: 0.389133. Loss: 1.718388. Batch_acc: 0.390580. Batch_loss: 1.702616 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.389100. Loss: 1.718580. Batch_acc: 0.382593. Batch_loss: 1.755769 \n",
      "Batch: 192. Acc: 0.389031. Loss: 1.718681. Batch_acc: 0.375584. Batch_loss: 1.738454 \n",
      "Batch: 193. Acc: 0.389071. Loss: 1.718671. Batch_acc: 0.396699. Batch_loss: 1.716795 \n",
      "Batch: 194. Acc: 0.389140. Loss: 1.718531. Batch_acc: 0.402509. Batch_loss: 1.691629 \n",
      "Batch: 195. Acc: 0.389194. Loss: 1.718487. Batch_acc: 0.400000. Batch_loss: 1.709486 \n",
      "Batch: 196. Acc: 0.389161. Loss: 1.718478. Batch_acc: 0.382772. Batch_loss: 1.716751 \n",
      "Batch: 197. Acc: 0.389096. Loss: 1.718421. Batch_acc: 0.376088. Batch_loss: 1.707264 \n",
      "Batch: 198. Acc: 0.389132. Loss: 1.718420. Batch_acc: 0.396313. Batch_loss: 1.718207 \n",
      "Batch: 199. Acc: 0.389105. Loss: 1.718355. Batch_acc: 0.383833. Batch_loss: 1.705504 \n",
      "Batch: 200. Acc: 0.389087. Loss: 1.718317. Batch_acc: 0.385417. Batch_loss: 1.710787 \n",
      "Batch: 201. Acc: 0.389071. Loss: 1.718230. Batch_acc: 0.385975. Batch_loss: 1.700816 \n",
      "Batch: 202. Acc: 0.389001. Loss: 1.718304. Batch_acc: 0.374784. Batch_loss: 1.733224 \n",
      "Batch: 203. Acc: 0.389043. Loss: 1.718144. Batch_acc: 0.397583. Batch_loss: 1.685719 \n",
      "Batch: 204. Acc: 0.388987. Loss: 1.718411. Batch_acc: 0.377088. Batch_loss: 1.774932 \n",
      "Batch: 205. Acc: 0.389000. Loss: 1.718424. Batch_acc: 0.391652. Batch_loss: 1.721152 \n",
      "Batch: 206. Acc: 0.389033. Loss: 1.718371. Batch_acc: 0.395762. Batch_loss: 1.707319 \n",
      "Batch: 207. Acc: 0.389048. Loss: 1.718405. Batch_acc: 0.392330. Batch_loss: 1.725777 \n",
      "Batch: 208. Acc: 0.389040. Loss: 1.718446. Batch_acc: 0.387280. Batch_loss: 1.726829 \n",
      "Batch: 209. Acc: 0.389035. Loss: 1.718407. Batch_acc: 0.388042. Batch_loss: 1.710003 \n",
      "Batch: 210. Acc: 0.389145. Loss: 1.718104. Batch_acc: 0.412205. Batch_loss: 1.654599 \n",
      "Batch: 211. Acc: 0.389129. Loss: 1.718083. Batch_acc: 0.385723. Batch_loss: 1.713469 \n",
      "Batch: 212. Acc: 0.389245. Loss: 1.717807. Batch_acc: 0.414072. Batch_loss: 1.659182 \n",
      "Batch: 213. Acc: 0.389280. Loss: 1.717692. Batch_acc: 0.396661. Batch_loss: 1.693314 \n",
      "Batch: 214. Acc: 0.389283. Loss: 1.717523. Batch_acc: 0.389937. Batch_loss: 1.681645 \n",
      "Batch: 215. Acc: 0.389367. Loss: 1.717266. Batch_acc: 0.407344. Batch_loss: 1.661999 \n",
      "Batch: 216. Acc: 0.389291. Loss: 1.717371. Batch_acc: 0.372595. Batch_loss: 1.740463 \n",
      "Batch: 217. Acc: 0.389301. Loss: 1.717464. Batch_acc: 0.391577. Batch_loss: 1.737479 \n",
      "Batch: 218. Acc: 0.389308. Loss: 1.717401. Batch_acc: 0.390732. Batch_loss: 1.703560 \n",
      "Batch: 219. Acc: 0.389348. Loss: 1.717377. Batch_acc: 0.398261. Batch_loss: 1.712092 \n",
      "Batch: 220. Acc: 0.389330. Loss: 1.717296. Batch_acc: 0.385236. Batch_loss: 1.699496 \n",
      "Batch: 221. Acc: 0.389300. Loss: 1.717344. Batch_acc: 0.382794. Batch_loss: 1.727962 \n",
      "Batch: 222. Acc: 0.389351. Loss: 1.717222. Batch_acc: 0.400458. Batch_loss: 1.690272 \n",
      "Batch: 223. Acc: 0.389407. Loss: 1.717215. Batch_acc: 0.402212. Batch_loss: 1.715758 \n",
      "Batch: 224. Acc: 0.389421. Loss: 1.717314. Batch_acc: 0.392470. Batch_loss: 1.739221 \n",
      "Batch: 225. Acc: 0.389378. Loss: 1.717491. Batch_acc: 0.379433. Batch_loss: 1.758373 \n",
      "Batch: 226. Acc: 0.389296. Loss: 1.717656. Batch_acc: 0.370018. Batch_loss: 1.756262 \n",
      "Batch: 227. Acc: 0.389320. Loss: 1.717634. Batch_acc: 0.394813. Batch_loss: 1.712693 \n",
      "Batch: 228. Acc: 0.389307. Loss: 1.717705. Batch_acc: 0.386364. Batch_loss: 1.733516 \n",
      "Batch: 229. Acc: 0.389294. Loss: 1.717668. Batch_acc: 0.386416. Batch_loss: 1.709464 \n",
      "Batch: 230. Acc: 0.389265. Loss: 1.717767. Batch_acc: 0.382604. Batch_loss: 1.740234 \n",
      "Batch: 231. Acc: 0.389303. Loss: 1.717563. Batch_acc: 0.398058. Batch_loss: 1.670689 \n",
      "Batch: 232. Acc: 0.389389. Loss: 1.717545. Batch_acc: 0.409702. Batch_loss: 1.713325 \n",
      "Batch: 233. Acc: 0.389371. Loss: 1.717543. Batch_acc: 0.385147. Batch_loss: 1.717095 \n",
      "Batch: 234. Acc: 0.389385. Loss: 1.717650. Batch_acc: 0.392775. Batch_loss: 1.742509 \n",
      "Batch: 235. Acc: 0.389360. Loss: 1.717834. Batch_acc: 0.383467. Batch_loss: 1.761101 \n",
      "Batch: 236. Acc: 0.389348. Loss: 1.717891. Batch_acc: 0.386338. Batch_loss: 1.731288 \n",
      "Batch: 237. Acc: 0.389349. Loss: 1.717846. Batch_acc: 0.389618. Batch_loss: 1.707190 \n",
      "Batch: 238. Acc: 0.389446. Loss: 1.717612. Batch_acc: 0.412365. Batch_loss: 1.662727 \n",
      "Batch: 239. Acc: 0.389369. Loss: 1.717626. Batch_acc: 0.371005. Batch_loss: 1.721011 \n",
      "Batch: 240. Acc: 0.389424. Loss: 1.717495. Batch_acc: 0.402494. Batch_loss: 1.686573 \n",
      "Batch: 241. Acc: 0.389480. Loss: 1.717323. Batch_acc: 0.403002. Batch_loss: 1.675554 \n",
      "Batch: 242. Acc: 0.389505. Loss: 1.717365. Batch_acc: 0.395429. Batch_loss: 1.727651 \n",
      "Batch: 243. Acc: 0.389470. Loss: 1.717286. Batch_acc: 0.380897. Batch_loss: 1.697787 \n",
      "Batch: 244. Acc: 0.389414. Loss: 1.717278. Batch_acc: 0.375862. Batch_loss: 1.715251 \n",
      "Batch: 245. Acc: 0.389458. Loss: 1.717166. Batch_acc: 0.400348. Batch_loss: 1.689472 \n",
      "Batch: 246. Acc: 0.389512. Loss: 1.716969. Batch_acc: 0.402370. Batch_loss: 1.669471 \n",
      "Batch: 247. Acc: 0.389650. Loss: 1.716691. Batch_acc: 0.423671. Batch_loss: 1.648561 \n",
      "Batch: 248. Acc: 0.389692. Loss: 1.716692. Batch_acc: 0.399886. Batch_loss: 1.717030 \n",
      "Batch: 249. Acc: 0.389622. Loss: 1.716879. Batch_acc: 0.371958. Batch_loss: 1.763706 \n",
      "Batch: 250. Acc: 0.389621. Loss: 1.716905. Batch_acc: 0.389595. Batch_loss: 1.723388 \n",
      "Batch: 251. Acc: 0.389627. Loss: 1.716887. Batch_acc: 0.391055. Batch_loss: 1.712358 \n",
      "Checkpointing on batch: 251. Accuracy: 0.389627113071591. Loss per char: 1.7168868806319322. Time: 1627210486.3247495\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 17, 15, 17, 20, 19, 23,  1, 85,\n",
      "        66, 76, 70,  1, 66, 88, 66, 90,  1, 14, 18, 22, 17, 17, 25, 15, 21, 19,\n",
      "        22, 18, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.389656. Loss: 1.716747. Batch_acc: 0.396880. Batch_loss: 1.681252 \n",
      "Batch: 253. Acc: 0.389699. Loss: 1.716637. Batch_acc: 0.400455. Batch_loss: 1.689308 \n",
      "Batch: 254. Acc: 0.389667. Loss: 1.716727. Batch_acc: 0.381671. Batch_loss: 1.739709 \n",
      "Batch: 255. Acc: 0.389712. Loss: 1.716643. Batch_acc: 0.401030. Batch_loss: 1.695338 \n",
      "Batch: 256. Acc: 0.389704. Loss: 1.716544. Batch_acc: 0.387778. Batch_loss: 1.691265 \n",
      "Batch: 257. Acc: 0.389704. Loss: 1.716639. Batch_acc: 0.389610. Batch_loss: 1.741750 \n",
      "Batch: 258. Acc: 0.389680. Loss: 1.716640. Batch_acc: 0.383333. Batch_loss: 1.716984 \n",
      "Batch: 259. Acc: 0.389684. Loss: 1.716632. Batch_acc: 0.390751. Batch_loss: 1.714619 \n",
      "Batch: 260. Acc: 0.389653. Loss: 1.716680. Batch_acc: 0.381776. Batch_loss: 1.729113 \n",
      "Batch: 261. Acc: 0.389674. Loss: 1.716639. Batch_acc: 0.395083. Batch_loss: 1.705856 \n",
      "Batch: 262. Acc: 0.389648. Loss: 1.716726. Batch_acc: 0.382659. Batch_loss: 1.739791 \n",
      "Batch: 263. Acc: 0.389626. Loss: 1.716756. Batch_acc: 0.384041. Batch_loss: 1.724485 \n",
      "Batch: 264. Acc: 0.389509. Loss: 1.717005. Batch_acc: 0.358696. Batch_loss: 1.782542 \n",
      "Batch: 265. Acc: 0.389503. Loss: 1.717113. Batch_acc: 0.387802. Batch_loss: 1.745573 \n",
      "Batch: 266. Acc: 0.389507. Loss: 1.717038. Batch_acc: 0.390706. Batch_loss: 1.697183 \n",
      "Batch: 267. Acc: 0.389507. Loss: 1.717078. Batch_acc: 0.389450. Batch_loss: 1.727463 \n",
      "Batch: 268. Acc: 0.389554. Loss: 1.716880. Batch_acc: 0.402193. Batch_loss: 1.663762 \n",
      "Batch: 269. Acc: 0.389579. Loss: 1.716892. Batch_acc: 0.396141. Batch_loss: 1.719965 \n",
      "Batch: 270. Acc: 0.389565. Loss: 1.716933. Batch_acc: 0.385757. Batch_loss: 1.728442 \n",
      "Batch: 271. Acc: 0.389636. Loss: 1.716715. Batch_acc: 0.408277. Batch_loss: 1.659361 \n",
      "Batch: 272. Acc: 0.389670. Loss: 1.716701. Batch_acc: 0.398763. Batch_loss: 1.712900 \n",
      "Batch: 273. Acc: 0.389676. Loss: 1.716718. Batch_acc: 0.391430. Batch_loss: 1.721370 \n",
      "Batch: 274. Acc: 0.389654. Loss: 1.716712. Batch_acc: 0.383498. Batch_loss: 1.715014 \n",
      "Batch: 275. Acc: 0.389629. Loss: 1.716656. Batch_acc: 0.382906. Batch_loss: 1.701500 \n",
      "Batch: 276. Acc: 0.389657. Loss: 1.716664. Batch_acc: 0.397316. Batch_loss: 1.718956 \n",
      "Batch: 277. Acc: 0.389638. Loss: 1.716586. Batch_acc: 0.384437. Batch_loss: 1.694750 \n",
      "Batch: 278. Acc: 0.389532. Loss: 1.716820. Batch_acc: 0.360069. Batch_loss: 1.781981 \n",
      "Batch: 279. Acc: 0.389577. Loss: 1.716788. Batch_acc: 0.401972. Batch_loss: 1.707787 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.389569. Loss: 1.716757. Batch_acc: 0.387619. Batch_loss: 1.708456 \n",
      "Batch: 281. Acc: 0.389612. Loss: 1.716710. Batch_acc: 0.401357. Batch_loss: 1.703499 \n",
      "Batch: 282. Acc: 0.389621. Loss: 1.716637. Batch_acc: 0.392168. Batch_loss: 1.695811 \n",
      "Batch: 283. Acc: 0.389588. Loss: 1.716727. Batch_acc: 0.380208. Batch_loss: 1.742515 \n",
      "Batch: 284. Acc: 0.389674. Loss: 1.716429. Batch_acc: 0.413370. Batch_loss: 1.634472 \n",
      "Batch: 285. Acc: 0.389727. Loss: 1.716363. Batch_acc: 0.404789. Batch_loss: 1.697593 \n",
      "Batch: 286. Acc: 0.389722. Loss: 1.716372. Batch_acc: 0.388095. Batch_loss: 1.718930 \n",
      "Batch: 287. Acc: 0.389770. Loss: 1.716312. Batch_acc: 0.403723. Batch_loss: 1.699118 \n",
      "Batch: 288. Acc: 0.389796. Loss: 1.716193. Batch_acc: 0.397059. Batch_loss: 1.682476 \n",
      "Batch: 289. Acc: 0.389783. Loss: 1.716225. Batch_acc: 0.386183. Batch_loss: 1.725266 \n",
      "Batch: 290. Acc: 0.389873. Loss: 1.716007. Batch_acc: 0.415445. Batch_loss: 1.654119 \n",
      "Batch: 291. Acc: 0.389890. Loss: 1.716046. Batch_acc: 0.394890. Batch_loss: 1.727280 \n",
      "Batch: 292. Acc: 0.389855. Loss: 1.716090. Batch_acc: 0.379592. Batch_loss: 1.729121 \n",
      "Batch: 293. Acc: 0.389877. Loss: 1.716071. Batch_acc: 0.396130. Batch_loss: 1.710741 \n",
      "Batch: 294. Acc: 0.389852. Loss: 1.716153. Batch_acc: 0.382507. Batch_loss: 1.740602 \n",
      "Batch: 295. Acc: 0.389846. Loss: 1.716239. Batch_acc: 0.388136. Batch_loss: 1.741059 \n",
      "Batch: 296. Acc: 0.389888. Loss: 1.716206. Batch_acc: 0.402155. Batch_loss: 1.706753 \n",
      "Batch: 297. Acc: 0.389889. Loss: 1.716122. Batch_acc: 0.390145. Batch_loss: 1.690905 \n",
      "Batch: 298. Acc: 0.389858. Loss: 1.716154. Batch_acc: 0.380282. Batch_loss: 1.725871 \n",
      "Batch: 299. Acc: 0.389861. Loss: 1.716141. Batch_acc: 0.390920. Batch_loss: 1.712029 \n",
      "Batch: 300. Acc: 0.389846. Loss: 1.716151. Batch_acc: 0.385236. Batch_loss: 1.719302 \n",
      "Batch: 301. Acc: 0.389897. Loss: 1.716021. Batch_acc: 0.405390. Batch_loss: 1.676807 \n",
      "Batch: 302. Acc: 0.389900. Loss: 1.716083. Batch_acc: 0.390553. Batch_loss: 1.735024 \n",
      "Batch: 303. Acc: 0.389902. Loss: 1.716080. Batch_acc: 0.390798. Batch_loss: 1.715022 \n",
      "Batch: 304. Acc: 0.389889. Loss: 1.716055. Batch_acc: 0.385854. Batch_loss: 1.708509 \n",
      "Batch: 305. Acc: 0.389920. Loss: 1.715893. Batch_acc: 0.399209. Batch_loss: 1.667441 \n",
      "Batch: 306. Acc: 0.389974. Loss: 1.715804. Batch_acc: 0.406286. Batch_loss: 1.688699 \n",
      "Batch: 307. Acc: 0.389935. Loss: 1.715844. Batch_acc: 0.377957. Batch_loss: 1.728271 \n",
      "Batch: 308. Acc: 0.389864. Loss: 1.715974. Batch_acc: 0.367431. Batch_loss: 1.756722 \n",
      "Batch: 309. Acc: 0.389864. Loss: 1.715985. Batch_acc: 0.390063. Batch_loss: 1.719438 \n",
      "Batch: 310. Acc: 0.389894. Loss: 1.715866. Batch_acc: 0.399072. Batch_loss: 1.678834 \n",
      "Batch: 311. Acc: 0.389907. Loss: 1.715868. Batch_acc: 0.394111. Batch_loss: 1.716485 \n",
      "Batch: 312. Acc: 0.389956. Loss: 1.715752. Batch_acc: 0.404762. Batch_loss: 1.680024 \n",
      "Batch: 313. Acc: 0.389945. Loss: 1.715777. Batch_acc: 0.386704. Batch_loss: 1.723220 \n",
      "Batch: 314. Acc: 0.389963. Loss: 1.715716. Batch_acc: 0.395662. Batch_loss: 1.696220 \n",
      "Batch: 315. Acc: 0.389980. Loss: 1.715718. Batch_acc: 0.395457. Batch_loss: 1.716370 \n",
      "Batch: 316. Acc: 0.389966. Loss: 1.715804. Batch_acc: 0.385606. Batch_loss: 1.743311 \n",
      "Batch: 317. Acc: 0.389982. Loss: 1.715751. Batch_acc: 0.394944. Batch_loss: 1.699467 \n",
      "Batch: 318. Acc: 0.389939. Loss: 1.715777. Batch_acc: 0.375878. Batch_loss: 1.724218 \n",
      "Batch: 319. Acc: 0.389917. Loss: 1.715733. Batch_acc: 0.383065. Batch_loss: 1.701597 \n",
      "Batch: 320. Acc: 0.389954. Loss: 1.715614. Batch_acc: 0.401602. Batch_loss: 1.677642 \n",
      "Batch: 321. Acc: 0.389942. Loss: 1.715562. Batch_acc: 0.386246. Batch_loss: 1.698910 \n",
      "Batch: 322. Acc: 0.389957. Loss: 1.715453. Batch_acc: 0.394632. Batch_loss: 1.680823 \n",
      "Batch: 323. Acc: 0.389978. Loss: 1.715452. Batch_acc: 0.396718. Batch_loss: 1.715009 \n",
      "Batch: 324. Acc: 0.389957. Loss: 1.715454. Batch_acc: 0.383053. Batch_loss: 1.716106 \n",
      "Batch: 325. Acc: 0.389964. Loss: 1.715469. Batch_acc: 0.392101. Batch_loss: 1.720326 \n",
      "Batch: 326. Acc: 0.389965. Loss: 1.715442. Batch_acc: 0.390299. Batch_loss: 1.707006 \n",
      "Batch: 327. Acc: 0.390035. Loss: 1.715298. Batch_acc: 0.412671. Batch_loss: 1.668327 \n",
      "Batch: 328. Acc: 0.390027. Loss: 1.715338. Batch_acc: 0.387720. Batch_loss: 1.728419 \n",
      "Batch: 329. Acc: 0.390087. Loss: 1.715193. Batch_acc: 0.409535. Batch_loss: 1.667682 \n",
      "Batch: 330. Acc: 0.390117. Loss: 1.715107. Batch_acc: 0.400116. Batch_loss: 1.686328 \n",
      "Batch: 331. Acc: 0.390099. Loss: 1.715090. Batch_acc: 0.384171. Batch_loss: 1.709528 \n",
      "Batch: 332. Acc: 0.390092. Loss: 1.715118. Batch_acc: 0.387719. Batch_loss: 1.724654 \n",
      "Batch: 333. Acc: 0.390064. Loss: 1.715258. Batch_acc: 0.380526. Batch_loss: 1.763727 \n",
      "Batch: 334. Acc: 0.390076. Loss: 1.715099. Batch_acc: 0.394097. Batch_loss: 1.661635 \n",
      "Batch: 335. Acc: 0.390092. Loss: 1.715075. Batch_acc: 0.395509. Batch_loss: 1.707041 \n",
      "Batch: 336. Acc: 0.390167. Loss: 1.714864. Batch_acc: 0.414648. Batch_loss: 1.645324 \n",
      "Batch: 337. Acc: 0.390162. Loss: 1.714857. Batch_acc: 0.388473. Batch_loss: 1.712611 \n",
      "Batch: 338. Acc: 0.390088. Loss: 1.715042. Batch_acc: 0.365242. Batch_loss: 1.776761 \n",
      "Batch: 339. Acc: 0.390075. Loss: 1.714924. Batch_acc: 0.385681. Batch_loss: 1.674740 \n",
      "Batch: 340. Acc: 0.390070. Loss: 1.714838. Batch_acc: 0.388531. Batch_loss: 1.685226 \n",
      "Batch: 341. Acc: 0.390030. Loss: 1.714828. Batch_acc: 0.376375. Batch_loss: 1.711445 \n",
      "Batch: 342. Acc: 0.390010. Loss: 1.714907. Batch_acc: 0.382844. Batch_loss: 1.741975 \n",
      "Batch: 343. Acc: 0.390079. Loss: 1.714802. Batch_acc: 0.413913. Batch_loss: 1.678488 \n",
      "Batch: 344. Acc: 0.390054. Loss: 1.714836. Batch_acc: 0.381684. Batch_loss: 1.726166 \n",
      "Batch: 345. Acc: 0.390090. Loss: 1.714689. Batch_acc: 0.402364. Batch_loss: 1.665153 \n",
      "Batch: 346. Acc: 0.390106. Loss: 1.714724. Batch_acc: 0.395548. Batch_loss: 1.726797 \n",
      "Batch: 347. Acc: 0.390136. Loss: 1.714687. Batch_acc: 0.400460. Batch_loss: 1.701972 \n",
      "Batch: 348. Acc: 0.390154. Loss: 1.714719. Batch_acc: 0.396412. Batch_loss: 1.725969 \n",
      "Batch: 349. Acc: 0.390105. Loss: 1.714795. Batch_acc: 0.372711. Batch_loss: 1.742029 \n",
      "Batch: 350. Acc: 0.390180. Loss: 1.714561. Batch_acc: 0.415642. Batch_loss: 1.635054 \n",
      "Batch: 351. Acc: 0.390194. Loss: 1.714506. Batch_acc: 0.395091. Batch_loss: 1.694726 \n",
      "Batch: 352. Acc: 0.390197. Loss: 1.714464. Batch_acc: 0.391405. Batch_loss: 1.699611 \n",
      "Batch: 353. Acc: 0.390210. Loss: 1.714424. Batch_acc: 0.394783. Batch_loss: 1.700037 \n",
      "Batch: 354. Acc: 0.390144. Loss: 1.714426. Batch_acc: 0.366820. Batch_loss: 1.715157 \n",
      "Batch: 355. Acc: 0.390161. Loss: 1.714446. Batch_acc: 0.396130. Batch_loss: 1.721416 \n",
      "Batch: 356. Acc: 0.390134. Loss: 1.714489. Batch_acc: 0.380466. Batch_loss: 1.729873 \n",
      "Batch: 357. Acc: 0.390135. Loss: 1.714490. Batch_acc: 0.390732. Batch_loss: 1.714678 \n",
      "Batch: 358. Acc: 0.390156. Loss: 1.714459. Batch_acc: 0.397400. Batch_loss: 1.703565 \n",
      "Batch: 359. Acc: 0.390193. Loss: 1.714314. Batch_acc: 0.403529. Batch_loss: 1.662721 \n",
      "Batch: 360. Acc: 0.390217. Loss: 1.714228. Batch_acc: 0.398731. Batch_loss: 1.683062 \n",
      "Batch: 361. Acc: 0.390243. Loss: 1.714163. Batch_acc: 0.399430. Batch_loss: 1.691056 \n",
      "Batch: 362. Acc: 0.390277. Loss: 1.714103. Batch_acc: 0.402778. Batch_loss: 1.692197 \n",
      "Batch: 363. Acc: 0.390293. Loss: 1.714049. Batch_acc: 0.396161. Batch_loss: 1.694130 \n",
      "Batch: 364. Acc: 0.390292. Loss: 1.714035. Batch_acc: 0.390006. Batch_loss: 1.709230 \n",
      "Batch: 365. Acc: 0.390250. Loss: 1.714184. Batch_acc: 0.375282. Batch_loss: 1.767494 \n",
      "Batch: 366. Acc: 0.390272. Loss: 1.714157. Batch_acc: 0.398266. Batch_loss: 1.704199 \n",
      "Batch: 367. Acc: 0.390256. Loss: 1.714127. Batch_acc: 0.384214. Batch_loss: 1.702999 \n",
      "Batch: 368. Acc: 0.390301. Loss: 1.713972. Batch_acc: 0.406944. Batch_loss: 1.657362 \n",
      "Batch: 369. Acc: 0.390352. Loss: 1.713937. Batch_acc: 0.409117. Batch_loss: 1.700944 \n",
      "Batch: 370. Acc: 0.390362. Loss: 1.713880. Batch_acc: 0.393939. Batch_loss: 1.692690 \n",
      "Batch: 371. Acc: 0.390425. Loss: 1.713686. Batch_acc: 0.413598. Batch_loss: 1.642718 \n",
      "Batch: 372. Acc: 0.390375. Loss: 1.713733. Batch_acc: 0.371328. Batch_loss: 1.731651 \n",
      "Batch: 373. Acc: 0.390411. Loss: 1.713650. Batch_acc: 0.403649. Batch_loss: 1.683055 \n",
      "Batch: 374. Acc: 0.390367. Loss: 1.713658. Batch_acc: 0.373913. Batch_loss: 1.716789 \n",
      "Batch: 375. Acc: 0.390398. Loss: 1.713576. Batch_acc: 0.402080. Batch_loss: 1.682333 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.390425. Loss: 1.713519. Batch_acc: 0.400339. Batch_loss: 1.692664 \n",
      "Batch: 377. Acc: 0.390382. Loss: 1.713583. Batch_acc: 0.374648. Batch_loss: 1.737122 \n",
      "Batch: 378. Acc: 0.390403. Loss: 1.713514. Batch_acc: 0.398047. Batch_loss: 1.687632 \n",
      "Batch: 379. Acc: 0.390419. Loss: 1.713457. Batch_acc: 0.396610. Batch_loss: 1.692092 \n",
      "Batch: 380. Acc: 0.390413. Loss: 1.713403. Batch_acc: 0.388181. Batch_loss: 1.692692 \n",
      "Batch: 381. Acc: 0.390431. Loss: 1.713326. Batch_acc: 0.397050. Batch_loss: 1.684509 \n",
      "Batch: 382. Acc: 0.390403. Loss: 1.713377. Batch_acc: 0.379290. Batch_loss: 1.733350 \n",
      "Batch: 383. Acc: 0.390430. Loss: 1.713313. Batch_acc: 0.400691. Batch_loss: 1.688792 \n",
      "Batch: 384. Acc: 0.390474. Loss: 1.713268. Batch_acc: 0.407365. Batch_loss: 1.696189 \n",
      "Batch: 385. Acc: 0.390500. Loss: 1.713189. Batch_acc: 0.400699. Batch_loss: 1.682118 \n",
      "Batch: 386. Acc: 0.390467. Loss: 1.713304. Batch_acc: 0.377765. Batch_loss: 1.758391 \n",
      "Batch: 387. Acc: 0.390465. Loss: 1.713307. Batch_acc: 0.389542. Batch_loss: 1.714358 \n",
      "Batch: 388. Acc: 0.390425. Loss: 1.713446. Batch_acc: 0.374855. Batch_loss: 1.767739 \n",
      "Batch: 389. Acc: 0.390377. Loss: 1.713523. Batch_acc: 0.371006. Batch_loss: 1.744369 \n",
      "Batch: 390. Acc: 0.390447. Loss: 1.713439. Batch_acc: 0.418743. Batch_loss: 1.679572 \n",
      "Batch: 391. Acc: 0.390424. Loss: 1.713477. Batch_acc: 0.381609. Batch_loss: 1.728576 \n",
      "Batch: 392. Acc: 0.390411. Loss: 1.713483. Batch_acc: 0.385108. Batch_loss: 1.715820 \n",
      "Batch: 393. Acc: 0.390395. Loss: 1.713515. Batch_acc: 0.384083. Batch_loss: 1.726092 \n",
      "Batch: 394. Acc: 0.390484. Loss: 1.713390. Batch_acc: 0.425170. Batch_loss: 1.664649 \n",
      "Batch: 395. Acc: 0.390513. Loss: 1.713378. Batch_acc: 0.401588. Batch_loss: 1.708828 \n",
      "Batch: 396. Acc: 0.390530. Loss: 1.713390. Batch_acc: 0.397400. Batch_loss: 1.717983 \n",
      "Batch: 397. Acc: 0.390522. Loss: 1.713338. Batch_acc: 0.387004. Batch_loss: 1.692810 \n",
      "Batch: 398. Acc: 0.390514. Loss: 1.713314. Batch_acc: 0.387732. Batch_loss: 1.703811 \n",
      "Batch: 399. Acc: 0.390518. Loss: 1.713315. Batch_acc: 0.392055. Batch_loss: 1.714095 \n",
      "Batch: 400. Acc: 0.390530. Loss: 1.713309. Batch_acc: 0.395161. Batch_loss: 1.710895 \n",
      "Batch: 401. Acc: 0.390528. Loss: 1.713229. Batch_acc: 0.389994. Batch_loss: 1.681464 \n",
      "Batch: 402. Acc: 0.390503. Loss: 1.713276. Batch_acc: 0.380410. Batch_loss: 1.731792 \n",
      "Batch: 403. Acc: 0.390468. Loss: 1.713373. Batch_acc: 0.376152. Batch_loss: 1.752418 \n",
      "Batch: 404. Acc: 0.390535. Loss: 1.713201. Batch_acc: 0.417470. Batch_loss: 1.644843 \n",
      "Batch: 405. Acc: 0.390582. Loss: 1.713049. Batch_acc: 0.409513. Batch_loss: 1.650879 \n",
      "Batch: 406. Acc: 0.390569. Loss: 1.713063. Batch_acc: 0.385423. Batch_loss: 1.718772 \n",
      "Batch: 407. Acc: 0.390537. Loss: 1.713080. Batch_acc: 0.377650. Batch_loss: 1.720072 \n",
      "Batch: 408. Acc: 0.390510. Loss: 1.713062. Batch_acc: 0.379191. Batch_loss: 1.705667 \n",
      "Batch: 409. Acc: 0.390501. Loss: 1.713072. Batch_acc: 0.386744. Batch_loss: 1.717188 \n",
      "Batch: 410. Acc: 0.390546. Loss: 1.713027. Batch_acc: 0.408443. Batch_loss: 1.695604 \n",
      "Batch: 411. Acc: 0.390560. Loss: 1.712966. Batch_acc: 0.396161. Batch_loss: 1.687435 \n",
      "Batch: 412. Acc: 0.390513. Loss: 1.712991. Batch_acc: 0.371298. Batch_loss: 1.723278 \n",
      "Batch: 413. Acc: 0.390490. Loss: 1.712991. Batch_acc: 0.381254. Batch_loss: 1.712838 \n",
      "Batch: 414. Acc: 0.390519. Loss: 1.712916. Batch_acc: 0.402545. Batch_loss: 1.681732 \n",
      "Batch: 415. Acc: 0.390546. Loss: 1.712906. Batch_acc: 0.401485. Batch_loss: 1.708988 \n",
      "Batch: 416. Acc: 0.390506. Loss: 1.713033. Batch_acc: 0.374063. Batch_loss: 1.765999 \n",
      "Batch: 417. Acc: 0.390554. Loss: 1.712896. Batch_acc: 0.410550. Batch_loss: 1.655936 \n",
      "Batch: 418. Acc: 0.390563. Loss: 1.712874. Batch_acc: 0.394203. Batch_loss: 1.703364 \n",
      "Batch: 419. Acc: 0.390600. Loss: 1.712774. Batch_acc: 0.405692. Batch_loss: 1.672098 \n",
      "Batch: 420. Acc: 0.390559. Loss: 1.712872. Batch_acc: 0.373048. Batch_loss: 1.754394 \n",
      "Batch: 421. Acc: 0.390555. Loss: 1.712897. Batch_acc: 0.389054. Batch_loss: 1.723919 \n",
      "Batch: 422. Acc: 0.390588. Loss: 1.712850. Batch_acc: 0.404075. Batch_loss: 1.693138 \n",
      "Batch: 423. Acc: 0.390537. Loss: 1.712955. Batch_acc: 0.368514. Batch_loss: 1.758503 \n",
      "Batch: 424. Acc: 0.390537. Loss: 1.713009. Batch_acc: 0.390679. Batch_loss: 1.736147 \n",
      "Batch: 425. Acc: 0.390545. Loss: 1.712987. Batch_acc: 0.393728. Batch_loss: 1.703487 \n",
      "Batch: 426. Acc: 0.390578. Loss: 1.712880. Batch_acc: 0.404412. Batch_loss: 1.668019 \n",
      "Batch: 427. Acc: 0.390579. Loss: 1.712865. Batch_acc: 0.391033. Batch_loss: 1.706274 \n",
      "Batch: 428. Acc: 0.390557. Loss: 1.712887. Batch_acc: 0.381065. Batch_loss: 1.722930 \n",
      "Batch: 429. Acc: 0.390545. Loss: 1.712901. Batch_acc: 0.385352. Batch_loss: 1.718493 \n",
      "Batch: 430. Acc: 0.390578. Loss: 1.712825. Batch_acc: 0.404997. Batch_loss: 1.679765 \n",
      "Batch: 431. Acc: 0.390573. Loss: 1.712845. Batch_acc: 0.388388. Batch_loss: 1.721530 \n",
      "Batch: 432. Acc: 0.390545. Loss: 1.712881. Batch_acc: 0.378613. Batch_loss: 1.728312 \n",
      "Batch: 433. Acc: 0.390535. Loss: 1.712881. Batch_acc: 0.385885. Batch_loss: 1.712895 \n",
      "Batch: 434. Acc: 0.390528. Loss: 1.712870. Batch_acc: 0.387574. Batch_loss: 1.708232 \n",
      "Batch: 435. Acc: 0.390556. Loss: 1.712792. Batch_acc: 0.402707. Batch_loss: 1.679302 \n",
      "Batch: 436. Acc: 0.390613. Loss: 1.712655. Batch_acc: 0.414525. Batch_loss: 1.654678 \n",
      "Batch: 437. Acc: 0.390660. Loss: 1.712581. Batch_acc: 0.411392. Batch_loss: 1.680159 \n",
      "Batch: 438. Acc: 0.390654. Loss: 1.712606. Batch_acc: 0.387861. Batch_loss: 1.723915 \n",
      "Batch: 439. Acc: 0.390609. Loss: 1.712641. Batch_acc: 0.370544. Batch_loss: 1.727998 \n",
      "Batch: 440. Acc: 0.390631. Loss: 1.712610. Batch_acc: 0.400347. Batch_loss: 1.698850 \n",
      "Batch: 441. Acc: 0.390610. Loss: 1.712591. Batch_acc: 0.381549. Batch_loss: 1.704263 \n",
      "Batch: 442. Acc: 0.390606. Loss: 1.712617. Batch_acc: 0.388727. Batch_loss: 1.724482 \n",
      "Batch: 443. Acc: 0.390604. Loss: 1.712608. Batch_acc: 0.389773. Batch_loss: 1.708600 \n",
      "Batch: 444. Acc: 0.390599. Loss: 1.712550. Batch_acc: 0.388350. Batch_loss: 1.686786 \n",
      "Batch: 445. Acc: 0.390640. Loss: 1.712463. Batch_acc: 0.408554. Batch_loss: 1.674748 \n",
      "Batch: 446. Acc: 0.390620. Loss: 1.712510. Batch_acc: 0.381640. Batch_loss: 1.733652 \n",
      "Batch: 447. Acc: 0.390628. Loss: 1.712433. Batch_acc: 0.394286. Batch_loss: 1.678075 \n",
      "Batch: 448. Acc: 0.390670. Loss: 1.712342. Batch_acc: 0.409431. Batch_loss: 1.671617 \n",
      "Batch: 449. Acc: 0.390694. Loss: 1.712223. Batch_acc: 0.401143. Batch_loss: 1.658898 \n",
      "Batch: 450. Acc: 0.390642. Loss: 1.712355. Batch_acc: 0.367698. Batch_loss: 1.771772 \n",
      "Batch: 451. Acc: 0.390680. Loss: 1.712285. Batch_acc: 0.407666. Batch_loss: 1.680481 \n",
      "Batch: 452. Acc: 0.390700. Loss: 1.712224. Batch_acc: 0.400117. Batch_loss: 1.683935 \n",
      "Batch: 453. Acc: 0.390724. Loss: 1.712257. Batch_acc: 0.401472. Batch_loss: 1.726962 \n",
      "Batch: 454. Acc: 0.390738. Loss: 1.712162. Batch_acc: 0.396780. Batch_loss: 1.669387 \n",
      "Batch: 455. Acc: 0.390744. Loss: 1.712110. Batch_acc: 0.393714. Batch_loss: 1.688638 \n",
      "Batch: 456. Acc: 0.390691. Loss: 1.712186. Batch_acc: 0.366040. Batch_loss: 1.747413 \n",
      "Batch: 457. Acc: 0.390717. Loss: 1.712144. Batch_acc: 0.402665. Batch_loss: 1.692851 \n",
      "Batch: 458. Acc: 0.390714. Loss: 1.712117. Batch_acc: 0.389304. Batch_loss: 1.699790 \n",
      "Batch: 459. Acc: 0.390683. Loss: 1.712184. Batch_acc: 0.375601. Batch_loss: 1.744364 \n",
      "Batch: 460. Acc: 0.390713. Loss: 1.712166. Batch_acc: 0.404694. Batch_loss: 1.703629 \n",
      "Batch: 461. Acc: 0.390715. Loss: 1.712165. Batch_acc: 0.391671. Batch_loss: 1.711879 \n",
      "Batch: 462. Acc: 0.390739. Loss: 1.712103. Batch_acc: 0.401705. Batch_loss: 1.683562 \n",
      "Batch: 463. Acc: 0.390795. Loss: 1.712016. Batch_acc: 0.416146. Batch_loss: 1.672383 \n",
      "Batch: 464. Acc: 0.390828. Loss: 1.711950. Batch_acc: 0.405789. Batch_loss: 1.681529 \n",
      "Batch: 465. Acc: 0.390796. Loss: 1.712028. Batch_acc: 0.376023. Batch_loss: 1.749177 \n",
      "Batch: 466. Acc: 0.390782. Loss: 1.712012. Batch_acc: 0.383949. Batch_loss: 1.704349 \n",
      "Batch: 467. Acc: 0.390823. Loss: 1.711833. Batch_acc: 0.409892. Batch_loss: 1.629384 \n",
      "Batch: 468. Acc: 0.390800. Loss: 1.711899. Batch_acc: 0.379908. Batch_loss: 1.743078 \n",
      "Batch: 469. Acc: 0.390779. Loss: 1.711809. Batch_acc: 0.381332. Batch_loss: 1.670012 \n",
      "Batch: 470. Acc: 0.390776. Loss: 1.711778. Batch_acc: 0.389370. Batch_loss: 1.697062 \n",
      "Batch: 471. Acc: 0.390761. Loss: 1.711799. Batch_acc: 0.383538. Batch_loss: 1.721661 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.390766. Loss: 1.711781. Batch_acc: 0.393041. Batch_loss: 1.703323 \n",
      "Batch: 473. Acc: 0.390750. Loss: 1.711842. Batch_acc: 0.382880. Batch_loss: 1.740907 \n",
      "Batch: 474. Acc: 0.390749. Loss: 1.711837. Batch_acc: 0.390399. Batch_loss: 1.709617 \n",
      "Batch: 475. Acc: 0.390747. Loss: 1.711874. Batch_acc: 0.389988. Batch_loss: 1.729787 \n",
      "Batch: 476. Acc: 0.390766. Loss: 1.711805. Batch_acc: 0.399768. Batch_loss: 1.678417 \n",
      "Batch: 477. Acc: 0.390781. Loss: 1.711729. Batch_acc: 0.398041. Batch_loss: 1.675648 \n",
      "Batch: 478. Acc: 0.390778. Loss: 1.711730. Batch_acc: 0.389426. Batch_loss: 1.711851 \n",
      "Batch: 479. Acc: 0.390812. Loss: 1.711692. Batch_acc: 0.406606. Batch_loss: 1.694034 \n",
      "Batch: 480. Acc: 0.390845. Loss: 1.711666. Batch_acc: 0.406799. Batch_loss: 1.699298 \n",
      "Batch: 481. Acc: 0.390863. Loss: 1.711653. Batch_acc: 0.399196. Batch_loss: 1.705197 \n",
      "Batch: 482. Acc: 0.390865. Loss: 1.711619. Batch_acc: 0.391700. Batch_loss: 1.695673 \n",
      "Batch: 483. Acc: 0.390863. Loss: 1.711655. Batch_acc: 0.390075. Batch_loss: 1.729024 \n",
      "Batch: 484. Acc: 0.390832. Loss: 1.711674. Batch_acc: 0.375579. Batch_loss: 1.720950 \n",
      "Batch: 485. Acc: 0.390842. Loss: 1.711615. Batch_acc: 0.395642. Batch_loss: 1.682923 \n",
      "Batch: 486. Acc: 0.390863. Loss: 1.711574. Batch_acc: 0.401153. Batch_loss: 1.691870 \n",
      "Batch: 487. Acc: 0.390837. Loss: 1.711589. Batch_acc: 0.378253. Batch_loss: 1.718723 \n",
      "Batch: 488. Acc: 0.390853. Loss: 1.711501. Batch_acc: 0.398847. Batch_loss: 1.668703 \n",
      "Batch: 489. Acc: 0.390819. Loss: 1.711497. Batch_acc: 0.374286. Batch_loss: 1.709525 \n",
      "Batch: 490. Acc: 0.390810. Loss: 1.711536. Batch_acc: 0.386271. Batch_loss: 1.730503 \n",
      "Batch: 491. Acc: 0.390852. Loss: 1.711424. Batch_acc: 0.411867. Batch_loss: 1.655820 \n",
      "Batch: 492. Acc: 0.390885. Loss: 1.711377. Batch_acc: 0.407256. Batch_loss: 1.687845 \n",
      "Batch: 493. Acc: 0.390883. Loss: 1.711364. Batch_acc: 0.389869. Batch_loss: 1.705237 \n",
      "Batch: 494. Acc: 0.390892. Loss: 1.711335. Batch_acc: 0.395376. Batch_loss: 1.696757 \n",
      "Batch: 495. Acc: 0.390923. Loss: 1.711342. Batch_acc: 0.406323. Batch_loss: 1.715112 \n",
      "Batch: 496. Acc: 0.390952. Loss: 1.711292. Batch_acc: 0.405780. Batch_loss: 1.686119 \n",
      "Batch: 497. Acc: 0.390910. Loss: 1.711313. Batch_acc: 0.370159. Batch_loss: 1.721861 \n",
      "Batch: 498. Acc: 0.390935. Loss: 1.711267. Batch_acc: 0.402825. Batch_loss: 1.688467 \n",
      "Batch: 499. Acc: 0.390959. Loss: 1.711230. Batch_acc: 0.402951. Batch_loss: 1.693138 \n",
      "Batch: 500. Acc: 0.390964. Loss: 1.711176. Batch_acc: 0.393623. Batch_loss: 1.684219 \n",
      "Batch: 501. Acc: 0.390947. Loss: 1.711277. Batch_acc: 0.382336. Batch_loss: 1.762069 \n",
      "Batch: 502. Acc: 0.390917. Loss: 1.711318. Batch_acc: 0.375223. Batch_loss: 1.732738 \n",
      "Checkpointing on batch: 502. Accuracy: 0.3909170119926452. Loss per char: 1.7113179235523717. Time: 1627210690.7610667\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 18, 17, 19, 22, 22, 26, 15,\n",
      "        25,  1, 14,  1, 14, 19, 20, 26, 17, 26, 17, 20, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.390947. Loss: 1.711209. Batch_acc: 0.405714. Batch_loss: 1.657011 \n",
      "Batch: 504. Acc: 0.390925. Loss: 1.711247. Batch_acc: 0.380330. Batch_loss: 1.730142 \n",
      "Batch: 505. Acc: 0.390974. Loss: 1.711160. Batch_acc: 0.415659. Batch_loss: 1.666850 \n",
      "Batch: 506. Acc: 0.390960. Loss: 1.711137. Batch_acc: 0.383489. Batch_loss: 1.699200 \n",
      "Batch: 507. Acc: 0.390898. Loss: 1.711252. Batch_acc: 0.359629. Batch_loss: 1.770396 \n",
      "Batch: 508. Acc: 0.390874. Loss: 1.711321. Batch_acc: 0.378619. Batch_loss: 1.745113 \n",
      "Batch: 509. Acc: 0.390930. Loss: 1.711194. Batch_acc: 0.419392. Batch_loss: 1.646922 \n",
      "Batch: 510. Acc: 0.390954. Loss: 1.711178. Batch_acc: 0.403226. Batch_loss: 1.702588 \n",
      "Batch: 511. Acc: 0.390984. Loss: 1.711114. Batch_acc: 0.406250. Batch_loss: 1.678971 \n",
      "Batch: 512. Acc: 0.391015. Loss: 1.711059. Batch_acc: 0.407321. Batch_loss: 1.682616 \n",
      "Batch: 513. Acc: 0.391023. Loss: 1.710996. Batch_acc: 0.395142. Batch_loss: 1.678011 \n",
      "Batch: 514. Acc: 0.391039. Loss: 1.710895. Batch_acc: 0.398864. Batch_loss: 1.659458 \n",
      "Batch: 515. Acc: 0.391013. Loss: 1.710908. Batch_acc: 0.377816. Batch_loss: 1.717772 \n",
      "Batch: 516. Acc: 0.391025. Loss: 1.710916. Batch_acc: 0.396916. Batch_loss: 1.714871 \n",
      "Batch: 517. Acc: 0.391003. Loss: 1.710927. Batch_acc: 0.379725. Batch_loss: 1.716751 \n",
      "Batch: 518. Acc: 0.390956. Loss: 1.710974. Batch_acc: 0.366255. Batch_loss: 1.735482 \n",
      "Batch: 519. Acc: 0.390933. Loss: 1.711081. Batch_acc: 0.378911. Batch_loss: 1.767276 \n",
      "Batch: 520. Acc: 0.390935. Loss: 1.711050. Batch_acc: 0.392068. Batch_loss: 1.695116 \n",
      "Batch: 521. Acc: 0.390971. Loss: 1.711010. Batch_acc: 0.410017. Batch_loss: 1.689713 \n",
      "Batch: 522. Acc: 0.390943. Loss: 1.711025. Batch_acc: 0.375936. Batch_loss: 1.718975 \n",
      "Batch: 523. Acc: 0.390961. Loss: 1.711005. Batch_acc: 0.400571. Batch_loss: 1.700455 \n",
      "Batch: 524. Acc: 0.390978. Loss: 1.710964. Batch_acc: 0.399654. Batch_loss: 1.689779 \n",
      "Batch: 525. Acc: 0.390974. Loss: 1.710939. Batch_acc: 0.389044. Batch_loss: 1.697780 \n",
      "Batch: 526. Acc: 0.390991. Loss: 1.710887. Batch_acc: 0.399774. Batch_loss: 1.684242 \n",
      "Batch: 527. Acc: 0.391010. Loss: 1.710819. Batch_acc: 0.401036. Batch_loss: 1.675035 \n",
      "Batch: 528. Acc: 0.391049. Loss: 1.710726. Batch_acc: 0.411199. Batch_loss: 1.662612 \n",
      "Batch: 529. Acc: 0.391076. Loss: 1.710768. Batch_acc: 0.405451. Batch_loss: 1.732557 \n",
      "Batch: 530. Acc: 0.391119. Loss: 1.710610. Batch_acc: 0.413696. Batch_loss: 1.627988 \n",
      "Batch: 531. Acc: 0.391136. Loss: 1.710503. Batch_acc: 0.399664. Batch_loss: 1.655271 \n",
      "Batch: 532. Acc: 0.391161. Loss: 1.710398. Batch_acc: 0.404475. Batch_loss: 1.654843 \n",
      "Batch: 533. Acc: 0.391186. Loss: 1.710291. Batch_acc: 0.404243. Batch_loss: 1.653244 \n",
      "Batch: 534. Acc: 0.391167. Loss: 1.710327. Batch_acc: 0.380980. Batch_loss: 1.729852 \n",
      "Batch: 535. Acc: 0.391144. Loss: 1.710377. Batch_acc: 0.378474. Batch_loss: 1.738118 \n",
      "Batch: 536. Acc: 0.391181. Loss: 1.710319. Batch_acc: 0.411323. Batch_loss: 1.678683 \n",
      "Batch: 537. Acc: 0.391238. Loss: 1.710230. Batch_acc: 0.422419. Batch_loss: 1.661129 \n",
      "Batch: 538. Acc: 0.391234. Loss: 1.710187. Batch_acc: 0.389330. Batch_loss: 1.687796 \n",
      "Batch: 539. Acc: 0.391283. Loss: 1.710115. Batch_acc: 0.417832. Batch_loss: 1.670542 \n",
      "Batch: 540. Acc: 0.391293. Loss: 1.710079. Batch_acc: 0.396742. Batch_loss: 1.690660 \n",
      "Batch: 541. Acc: 0.391287. Loss: 1.710081. Batch_acc: 0.388120. Batch_loss: 1.710779 \n",
      "Batch: 542. Acc: 0.391299. Loss: 1.710120. Batch_acc: 0.397681. Batch_loss: 1.731387 \n",
      "Batch: 543. Acc: 0.391306. Loss: 1.710137. Batch_acc: 0.395294. Batch_loss: 1.719666 \n",
      "Batch: 544. Acc: 0.391294. Loss: 1.710135. Batch_acc: 0.385264. Batch_loss: 1.709203 \n",
      "Batch: 545. Acc: 0.391326. Loss: 1.710041. Batch_acc: 0.408347. Batch_loss: 1.659859 \n",
      "Batch: 546. Acc: 0.391288. Loss: 1.710172. Batch_acc: 0.370831. Batch_loss: 1.780340 \n",
      "Batch: 547. Acc: 0.391292. Loss: 1.710179. Batch_acc: 0.393574. Batch_loss: 1.714052 \n",
      "Batch: 548. Acc: 0.391279. Loss: 1.710161. Batch_acc: 0.384083. Batch_loss: 1.700177 \n",
      "Batch: 549. Acc: 0.391273. Loss: 1.710154. Batch_acc: 0.387826. Batch_loss: 1.706489 \n",
      "Batch: 550. Acc: 0.391297. Loss: 1.710114. Batch_acc: 0.404231. Batch_loss: 1.688242 \n",
      "Batch: 551. Acc: 0.391274. Loss: 1.710114. Batch_acc: 0.378641. Batch_loss: 1.710132 \n",
      "Batch: 552. Acc: 0.391252. Loss: 1.710157. Batch_acc: 0.379032. Batch_loss: 1.733775 \n",
      "Batch: 553. Acc: 0.391254. Loss: 1.710118. Batch_acc: 0.392652. Batch_loss: 1.688602 \n",
      "Batch: 554. Acc: 0.391226. Loss: 1.710207. Batch_acc: 0.375221. Batch_loss: 1.760711 \n",
      "Batch: 555. Acc: 0.391266. Loss: 1.710133. Batch_acc: 0.414159. Batch_loss: 1.667908 \n",
      "Batch: 556. Acc: 0.391269. Loss: 1.710042. Batch_acc: 0.393064. Batch_loss: 1.659487 \n",
      "Batch: 557. Acc: 0.391309. Loss: 1.709927. Batch_acc: 0.413256. Batch_loss: 1.645541 \n",
      "Batch: 558. Acc: 0.391310. Loss: 1.709871. Batch_acc: 0.391800. Batch_loss: 1.679265 \n",
      "Batch: 559. Acc: 0.391301. Loss: 1.709900. Batch_acc: 0.386531. Batch_loss: 1.725740 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 560. Acc: 0.391316. Loss: 1.709835. Batch_acc: 0.399886. Batch_loss: 1.673678 \n",
      "Batch: 561. Acc: 0.391336. Loss: 1.709800. Batch_acc: 0.402530. Batch_loss: 1.689962 \n",
      "Batch: 562. Acc: 0.391351. Loss: 1.709768. Batch_acc: 0.399317. Batch_loss: 1.692099 \n",
      "Batch: 563. Acc: 0.391336. Loss: 1.709801. Batch_acc: 0.382761. Batch_loss: 1.729053 \n",
      "Batch: 564. Acc: 0.391353. Loss: 1.709816. Batch_acc: 0.401048. Batch_loss: 1.718644 \n",
      "Batch: 565. Acc: 0.391327. Loss: 1.709840. Batch_acc: 0.376511. Batch_loss: 1.723378 \n",
      "Batch: 566. Acc: 0.391330. Loss: 1.709775. Batch_acc: 0.393080. Batch_loss: 1.673288 \n",
      "Batch: 567. Acc: 0.391338. Loss: 1.709731. Batch_acc: 0.396074. Batch_loss: 1.684591 \n",
      "Batch: 568. Acc: 0.391365. Loss: 1.709614. Batch_acc: 0.405968. Batch_loss: 1.644930 \n",
      "Batch: 569. Acc: 0.391353. Loss: 1.709581. Batch_acc: 0.385051. Batch_loss: 1.690985 \n",
      "Batch: 570. Acc: 0.391395. Loss: 1.709535. Batch_acc: 0.415652. Batch_loss: 1.682986 \n",
      "Batch: 571. Acc: 0.391389. Loss: 1.709574. Batch_acc: 0.387858. Batch_loss: 1.731520 \n",
      "Batch: 572. Acc: 0.391394. Loss: 1.709562. Batch_acc: 0.394128. Batch_loss: 1.702465 \n",
      "Batch: 573. Acc: 0.391362. Loss: 1.709646. Batch_acc: 0.372372. Batch_loss: 1.759968 \n",
      "Batch: 574. Acc: 0.391351. Loss: 1.709697. Batch_acc: 0.385057. Batch_loss: 1.738861 \n",
      "Batch: 575. Acc: 0.391381. Loss: 1.709671. Batch_acc: 0.408751. Batch_loss: 1.695102 \n",
      "Batch: 576. Acc: 0.391368. Loss: 1.709674. Batch_acc: 0.383593. Batch_loss: 1.711242 \n",
      "Batch: 577. Acc: 0.391378. Loss: 1.709623. Batch_acc: 0.396982. Batch_loss: 1.679901 \n",
      "Batch: 578. Acc: 0.391365. Loss: 1.709686. Batch_acc: 0.383721. Batch_loss: 1.746731 \n",
      "Batch: 579. Acc: 0.391332. Loss: 1.709735. Batch_acc: 0.371955. Batch_loss: 1.738992 \n",
      "Batch: 580. Acc: 0.391333. Loss: 1.709758. Batch_acc: 0.392076. Batch_loss: 1.723282 \n",
      "Batch: 581. Acc: 0.391348. Loss: 1.709744. Batch_acc: 0.399886. Batch_loss: 1.701953 \n",
      "Batch: 582. Acc: 0.391336. Loss: 1.709756. Batch_acc: 0.384302. Batch_loss: 1.716729 \n",
      "Batch: 583. Acc: 0.391326. Loss: 1.709801. Batch_acc: 0.385064. Batch_loss: 1.736222 \n",
      "Batch: 584. Acc: 0.391312. Loss: 1.709768. Batch_acc: 0.383257. Batch_loss: 1.690689 \n",
      "Batch: 585. Acc: 0.391324. Loss: 1.709713. Batch_acc: 0.398415. Batch_loss: 1.677896 \n",
      "Batch: 586. Acc: 0.391330. Loss: 1.709670. Batch_acc: 0.394614. Batch_loss: 1.683976 \n",
      "Batch: 587. Acc: 0.391351. Loss: 1.709604. Batch_acc: 0.404133. Batch_loss: 1.670918 \n",
      "Batch: 588. Acc: 0.391359. Loss: 1.709592. Batch_acc: 0.395692. Batch_loss: 1.703110 \n",
      "Batch: 589. Acc: 0.391352. Loss: 1.709546. Batch_acc: 0.387352. Batch_loss: 1.682477 \n",
      "Batch: 590. Acc: 0.391379. Loss: 1.709530. Batch_acc: 0.407516. Batch_loss: 1.700087 \n",
      "Batch: 591. Acc: 0.391358. Loss: 1.709584. Batch_acc: 0.378652. Batch_loss: 1.742557 \n",
      "Batch: 592. Acc: 0.391428. Loss: 1.709464. Batch_acc: 0.431538. Batch_loss: 1.640497 \n",
      "Batch: 593. Acc: 0.391440. Loss: 1.709387. Batch_acc: 0.398513. Batch_loss: 1.663893 \n",
      "Batch: 594. Acc: 0.391478. Loss: 1.709273. Batch_acc: 0.413988. Batch_loss: 1.642733 \n",
      "Batch: 595. Acc: 0.391485. Loss: 1.709226. Batch_acc: 0.395642. Batch_loss: 1.681224 \n",
      "Batch: 596. Acc: 0.391499. Loss: 1.709175. Batch_acc: 0.399763. Batch_loss: 1.678072 \n",
      "Batch: 597. Acc: 0.391535. Loss: 1.709140. Batch_acc: 0.413256. Batch_loss: 1.687972 \n",
      "Batch: 598. Acc: 0.391563. Loss: 1.709102. Batch_acc: 0.408467. Batch_loss: 1.686611 \n",
      "Batch: 599. Acc: 0.391541. Loss: 1.709111. Batch_acc: 0.378098. Batch_loss: 1.714609 \n",
      "Batch: 600. Acc: 0.391541. Loss: 1.709106. Batch_acc: 0.391624. Batch_loss: 1.706417 \n",
      "Batch: 601. Acc: 0.391583. Loss: 1.709022. Batch_acc: 0.416384. Batch_loss: 1.658969 \n",
      "Batch: 602. Acc: 0.391581. Loss: 1.709038. Batch_acc: 0.390041. Batch_loss: 1.719522 \n",
      "Batch: 603. Acc: 0.391580. Loss: 1.709040. Batch_acc: 0.390965. Batch_loss: 1.709856 \n",
      "Batch: 604. Acc: 0.391572. Loss: 1.709051. Batch_acc: 0.386964. Batch_loss: 1.716051 \n",
      "Batch: 605. Acc: 0.391601. Loss: 1.708977. Batch_acc: 0.408530. Batch_loss: 1.665144 \n",
      "Batch: 606. Acc: 0.391637. Loss: 1.708896. Batch_acc: 0.413068. Batch_loss: 1.660296 \n",
      "Batch: 607. Acc: 0.391627. Loss: 1.708904. Batch_acc: 0.385831. Batch_loss: 1.714273 \n",
      "Batch: 608. Acc: 0.391636. Loss: 1.708886. Batch_acc: 0.396871. Batch_loss: 1.697746 \n",
      "Batch: 609. Acc: 0.391619. Loss: 1.708928. Batch_acc: 0.381037. Batch_loss: 1.734883 \n",
      "Batch: 610. Acc: 0.391653. Loss: 1.708820. Batch_acc: 0.412066. Batch_loss: 1.643526 \n",
      "Batch: 611. Acc: 0.391651. Loss: 1.708782. Batch_acc: 0.390930. Batch_loss: 1.685530 \n",
      "Batch: 612. Acc: 0.391665. Loss: 1.708731. Batch_acc: 0.400114. Batch_loss: 1.678367 \n",
      "Batch: 613. Acc: 0.391661. Loss: 1.708750. Batch_acc: 0.388666. Batch_loss: 1.720387 \n",
      "Batch: 614. Acc: 0.391630. Loss: 1.708819. Batch_acc: 0.372315. Batch_loss: 1.752262 \n",
      "Batch: 615. Acc: 0.391648. Loss: 1.708775. Batch_acc: 0.402494. Batch_loss: 1.682405 \n",
      "Batch: 616. Acc: 0.391659. Loss: 1.708687. Batch_acc: 0.398411. Batch_loss: 1.654883 \n",
      "Batch: 617. Acc: 0.391643. Loss: 1.708730. Batch_acc: 0.381839. Batch_loss: 1.735997 \n",
      "Batch: 618. Acc: 0.391621. Loss: 1.708800. Batch_acc: 0.377980. Batch_loss: 1.751074 \n",
      "Batch: 619. Acc: 0.391607. Loss: 1.708809. Batch_acc: 0.383016. Batch_loss: 1.714572 \n",
      "Batch: 620. Acc: 0.391640. Loss: 1.708758. Batch_acc: 0.412069. Batch_loss: 1.677342 \n",
      "Batch: 621. Acc: 0.391671. Loss: 1.708670. Batch_acc: 0.410000. Batch_loss: 1.655935 \n",
      "Batch: 622. Acc: 0.391676. Loss: 1.708645. Batch_acc: 0.394890. Batch_loss: 1.692792 \n",
      "Batch: 623. Acc: 0.391673. Loss: 1.708643. Batch_acc: 0.390104. Batch_loss: 1.707573 \n",
      "Batch: 624. Acc: 0.391694. Loss: 1.708634. Batch_acc: 0.404340. Batch_loss: 1.702710 \n",
      "Batch: 625. Acc: 0.391718. Loss: 1.708613. Batch_acc: 0.406481. Batch_loss: 1.695708 \n",
      "Batch: 626. Acc: 0.391729. Loss: 1.708565. Batch_acc: 0.399072. Batch_loss: 1.678643 \n",
      "Batch: 627. Acc: 0.391756. Loss: 1.708537. Batch_acc: 0.408324. Batch_loss: 1.691155 \n",
      "Batch: 628. Acc: 0.391760. Loss: 1.708504. Batch_acc: 0.394342. Batch_loss: 1.687724 \n",
      "Batch: 629. Acc: 0.391784. Loss: 1.708482. Batch_acc: 0.406232. Batch_loss: 1.694742 \n",
      "Batch: 630. Acc: 0.391800. Loss: 1.708416. Batch_acc: 0.401776. Batch_loss: 1.668196 \n",
      "Batch: 631. Acc: 0.391808. Loss: 1.708369. Batch_acc: 0.396982. Batch_loss: 1.678289 \n",
      "Batch: 632. Acc: 0.391859. Loss: 1.708179. Batch_acc: 0.423777. Batch_loss: 1.589949 \n",
      "Batch: 633. Acc: 0.391871. Loss: 1.708129. Batch_acc: 0.399090. Batch_loss: 1.676874 \n",
      "Batch: 634. Acc: 0.391878. Loss: 1.708187. Batch_acc: 0.396723. Batch_loss: 1.745606 \n",
      "Batch: 635. Acc: 0.391917. Loss: 1.708082. Batch_acc: 0.415825. Batch_loss: 1.642431 \n",
      "Batch: 636. Acc: 0.391955. Loss: 1.708012. Batch_acc: 0.415853. Batch_loss: 1.664002 \n",
      "Batch: 637. Acc: 0.391963. Loss: 1.707963. Batch_acc: 0.396934. Batch_loss: 1.676730 \n",
      "Batch: 638. Acc: 0.391965. Loss: 1.707918. Batch_acc: 0.393271. Batch_loss: 1.679023 \n",
      "Batch: 639. Acc: 0.391977. Loss: 1.707889. Batch_acc: 0.399766. Batch_loss: 1.689317 \n",
      "Batch: 640. Acc: 0.391994. Loss: 1.707902. Batch_acc: 0.402960. Batch_loss: 1.716082 \n",
      "Batch: 641. Acc: 0.391995. Loss: 1.707890. Batch_acc: 0.392980. Batch_loss: 1.700137 \n",
      "Batch: 642. Acc: 0.391993. Loss: 1.707890. Batch_acc: 0.390258. Batch_loss: 1.707765 \n",
      "Batch: 643. Acc: 0.392002. Loss: 1.707901. Batch_acc: 0.397900. Batch_loss: 1.715353 \n",
      "Batch: 644. Acc: 0.391999. Loss: 1.707899. Batch_acc: 0.390188. Batch_loss: 1.706292 \n",
      "Batch: 645. Acc: 0.392005. Loss: 1.707924. Batch_acc: 0.396259. Batch_loss: 1.724881 \n",
      "Batch: 646. Acc: 0.392007. Loss: 1.707914. Batch_acc: 0.392754. Batch_loss: 1.701018 \n",
      "Batch: 647. Acc: 0.392007. Loss: 1.707839. Batch_acc: 0.392009. Batch_loss: 1.659383 \n",
      "Batch: 648. Acc: 0.391996. Loss: 1.707833. Batch_acc: 0.384754. Batch_loss: 1.703613 \n",
      "Batch: 649. Acc: 0.392006. Loss: 1.707795. Batch_acc: 0.398175. Batch_loss: 1.683143 \n",
      "Batch: 650. Acc: 0.392024. Loss: 1.707745. Batch_acc: 0.403659. Batch_loss: 1.675312 \n",
      "Batch: 651. Acc: 0.392042. Loss: 1.707704. Batch_acc: 0.403608. Batch_loss: 1.681761 \n",
      "Batch: 652. Acc: 0.392031. Loss: 1.707753. Batch_acc: 0.384709. Batch_loss: 1.741440 \n",
      "Batch: 653. Acc: 0.392003. Loss: 1.707816. Batch_acc: 0.373928. Batch_loss: 1.749109 \n",
      "Batch: 654. Acc: 0.392022. Loss: 1.707797. Batch_acc: 0.404171. Batch_loss: 1.695240 \n",
      "Batch: 655. Acc: 0.392029. Loss: 1.707804. Batch_acc: 0.396661. Batch_loss: 1.712530 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 656. Acc: 0.392028. Loss: 1.707774. Batch_acc: 0.391202. Batch_loss: 1.687483 \n",
      "Batch: 657. Acc: 0.391988. Loss: 1.707882. Batch_acc: 0.365429. Batch_loss: 1.779570 \n",
      "Batch: 658. Acc: 0.392009. Loss: 1.707807. Batch_acc: 0.405360. Batch_loss: 1.659850 \n",
      "Batch: 659. Acc: 0.392011. Loss: 1.707823. Batch_acc: 0.393811. Batch_loss: 1.719440 \n",
      "Batch: 660. Acc: 0.392019. Loss: 1.707797. Batch_acc: 0.396999. Batch_loss: 1.690367 \n",
      "Batch: 661. Acc: 0.392053. Loss: 1.707713. Batch_acc: 0.415061. Batch_loss: 1.651481 \n",
      "Batch: 662. Acc: 0.392051. Loss: 1.707680. Batch_acc: 0.390679. Batch_loss: 1.685964 \n",
      "Batch: 663. Acc: 0.392062. Loss: 1.707666. Batch_acc: 0.399534. Batch_loss: 1.697922 \n",
      "Batch: 664. Acc: 0.392055. Loss: 1.707707. Batch_acc: 0.387479. Batch_loss: 1.734732 \n",
      "Batch: 665. Acc: 0.392048. Loss: 1.707723. Batch_acc: 0.387336. Batch_loss: 1.718012 \n",
      "Batch: 666. Acc: 0.392053. Loss: 1.707782. Batch_acc: 0.395415. Batch_loss: 1.746933 \n",
      "Batch: 667. Acc: 0.392081. Loss: 1.707682. Batch_acc: 0.410011. Batch_loss: 1.642443 \n",
      "Batch: 668. Acc: 0.392068. Loss: 1.707697. Batch_acc: 0.383362. Batch_loss: 1.717840 \n",
      "Batch: 669. Acc: 0.392080. Loss: 1.707711. Batch_acc: 0.400235. Batch_loss: 1.717025 \n",
      "Batch: 670. Acc: 0.392112. Loss: 1.707631. Batch_acc: 0.413713. Batch_loss: 1.654065 \n",
      "Batch: 671. Acc: 0.392128. Loss: 1.707559. Batch_acc: 0.402723. Batch_loss: 1.659624 \n",
      "Batch: 672. Acc: 0.392113. Loss: 1.707548. Batch_acc: 0.382100. Batch_loss: 1.700094 \n",
      "Batch: 673. Acc: 0.392112. Loss: 1.707559. Batch_acc: 0.391354. Batch_loss: 1.715160 \n",
      "Batch: 674. Acc: 0.392143. Loss: 1.707498. Batch_acc: 0.413793. Batch_loss: 1.665322 \n",
      "Batch: 675. Acc: 0.392164. Loss: 1.707473. Batch_acc: 0.406820. Batch_loss: 1.690269 \n",
      "Batch: 676. Acc: 0.392194. Loss: 1.707446. Batch_acc: 0.412281. Batch_loss: 1.688710 \n",
      "Batch: 677. Acc: 0.392200. Loss: 1.707415. Batch_acc: 0.396512. Batch_loss: 1.686695 \n",
      "Batch: 678. Acc: 0.392203. Loss: 1.707430. Batch_acc: 0.394100. Batch_loss: 1.717996 \n",
      "Batch: 679. Acc: 0.392210. Loss: 1.707416. Batch_acc: 0.397306. Batch_loss: 1.697669 \n",
      "Batch: 680. Acc: 0.392221. Loss: 1.707361. Batch_acc: 0.399304. Batch_loss: 1.669516 \n",
      "Batch: 681. Acc: 0.392234. Loss: 1.707304. Batch_acc: 0.401133. Batch_loss: 1.669450 \n",
      "Batch: 682. Acc: 0.392236. Loss: 1.707294. Batch_acc: 0.393647. Batch_loss: 1.700232 \n",
      "Batch: 683. Acc: 0.392219. Loss: 1.707309. Batch_acc: 0.380926. Batch_loss: 1.717584 \n",
      "Batch: 684. Acc: 0.392246. Loss: 1.707236. Batch_acc: 0.409910. Batch_loss: 1.658125 \n",
      "Batch: 685. Acc: 0.392257. Loss: 1.707214. Batch_acc: 0.400000. Batch_loss: 1.692387 \n",
      "Batch: 686. Acc: 0.392272. Loss: 1.707158. Batch_acc: 0.402567. Batch_loss: 1.668101 \n",
      "Batch: 687. Acc: 0.392287. Loss: 1.707145. Batch_acc: 0.402357. Batch_loss: 1.698302 \n",
      "Batch: 688. Acc: 0.392328. Loss: 1.707073. Batch_acc: 0.419989. Batch_loss: 1.659197 \n",
      "Batch: 689. Acc: 0.392355. Loss: 1.707032. Batch_acc: 0.410839. Batch_loss: 1.678542 \n",
      "Batch: 690. Acc: 0.392362. Loss: 1.706959. Batch_acc: 0.397245. Batch_loss: 1.656567 \n",
      "Batch: 691. Acc: 0.392348. Loss: 1.706992. Batch_acc: 0.382701. Batch_loss: 1.730600 \n",
      "Batch: 692. Acc: 0.392344. Loss: 1.706969. Batch_acc: 0.389365. Batch_loss: 1.691124 \n",
      "Batch: 693. Acc: 0.392375. Loss: 1.706889. Batch_acc: 0.413616. Batch_loss: 1.651389 \n",
      "Batch: 694. Acc: 0.392395. Loss: 1.706842. Batch_acc: 0.406499. Batch_loss: 1.674439 \n",
      "Batch: 695. Acc: 0.392388. Loss: 1.706820. Batch_acc: 0.387263. Batch_loss: 1.692008 \n",
      "Batch: 696. Acc: 0.392403. Loss: 1.706732. Batch_acc: 0.403207. Batch_loss: 1.645468 \n",
      "Batch: 697. Acc: 0.392436. Loss: 1.706664. Batch_acc: 0.414593. Batch_loss: 1.660135 \n",
      "Batch: 698. Acc: 0.392422. Loss: 1.706695. Batch_acc: 0.383188. Batch_loss: 1.728687 \n",
      "Batch: 699. Acc: 0.392441. Loss: 1.706656. Batch_acc: 0.405941. Batch_loss: 1.678788 \n",
      "Batch: 700. Acc: 0.392440. Loss: 1.706640. Batch_acc: 0.391747. Batch_loss: 1.695919 \n",
      "Batch: 701. Acc: 0.392460. Loss: 1.706544. Batch_acc: 0.405980. Batch_loss: 1.638919 \n",
      "Batch: 702. Acc: 0.392454. Loss: 1.706543. Batch_acc: 0.388033. Batch_loss: 1.705600 \n",
      "Batch: 703. Acc: 0.392466. Loss: 1.706500. Batch_acc: 0.401388. Batch_loss: 1.676379 \n",
      "Batch: 704. Acc: 0.392475. Loss: 1.706466. Batch_acc: 0.398731. Batch_loss: 1.682586 \n",
      "Batch: 705. Acc: 0.392469. Loss: 1.706492. Batch_acc: 0.388304. Batch_loss: 1.725021 \n",
      "Batch: 706. Acc: 0.392462. Loss: 1.706516. Batch_acc: 0.387529. Batch_loss: 1.723492 \n",
      "Batch: 707. Acc: 0.392483. Loss: 1.706492. Batch_acc: 0.407472. Batch_loss: 1.689405 \n",
      "Batch: 708. Acc: 0.392509. Loss: 1.706450. Batch_acc: 0.411182. Batch_loss: 1.676598 \n",
      "Batch: 709. Acc: 0.392507. Loss: 1.706433. Batch_acc: 0.390689. Batch_loss: 1.693981 \n",
      "Batch: 710. Acc: 0.392548. Loss: 1.706404. Batch_acc: 0.422184. Batch_loss: 1.685262 \n",
      "Batch: 711. Acc: 0.392536. Loss: 1.706414. Batch_acc: 0.383793. Batch_loss: 1.713619 \n",
      "Batch: 712. Acc: 0.392549. Loss: 1.706376. Batch_acc: 0.401858. Batch_loss: 1.679026 \n",
      "Batch: 713. Acc: 0.392551. Loss: 1.706332. Batch_acc: 0.394292. Batch_loss: 1.674712 \n",
      "Batch: 714. Acc: 0.392550. Loss: 1.706318. Batch_acc: 0.391525. Batch_loss: 1.696284 \n",
      "Batch: 715. Acc: 0.392563. Loss: 1.706331. Batch_acc: 0.401984. Batch_loss: 1.715465 \n",
      "Batch: 716. Acc: 0.392542. Loss: 1.706365. Batch_acc: 0.377930. Batch_loss: 1.730802 \n",
      "Batch: 717. Acc: 0.392521. Loss: 1.706385. Batch_acc: 0.377116. Batch_loss: 1.720785 \n",
      "Batch: 718. Acc: 0.392521. Loss: 1.706388. Batch_acc: 0.392290. Batch_loss: 1.708613 \n",
      "Batch: 719. Acc: 0.392536. Loss: 1.706338. Batch_acc: 0.403767. Batch_loss: 1.669511 \n",
      "Batch: 720. Acc: 0.392540. Loss: 1.706312. Batch_acc: 0.395881. Batch_loss: 1.687897 \n",
      "Batch: 721. Acc: 0.392589. Loss: 1.706204. Batch_acc: 0.427910. Batch_loss: 1.627799 \n",
      "Batch: 722. Acc: 0.392581. Loss: 1.706186. Batch_acc: 0.386496. Batch_loss: 1.693180 \n",
      "Batch: 723. Acc: 0.392591. Loss: 1.706171. Batch_acc: 0.400114. Batch_loss: 1.695601 \n",
      "Batch: 724. Acc: 0.392592. Loss: 1.706189. Batch_acc: 0.393443. Batch_loss: 1.719111 \n",
      "Batch: 725. Acc: 0.392612. Loss: 1.706158. Batch_acc: 0.407131. Batch_loss: 1.683687 \n",
      "Batch: 726. Acc: 0.392623. Loss: 1.706124. Batch_acc: 0.400233. Batch_loss: 1.681352 \n",
      "Batch: 727. Acc: 0.392654. Loss: 1.706079. Batch_acc: 0.415158. Batch_loss: 1.674015 \n",
      "Batch: 728. Acc: 0.392654. Loss: 1.706090. Batch_acc: 0.392434. Batch_loss: 1.713724 \n",
      "Batch: 729. Acc: 0.392661. Loss: 1.706080. Batch_acc: 0.398019. Batch_loss: 1.698299 \n",
      "Batch: 730. Acc: 0.392669. Loss: 1.706025. Batch_acc: 0.398143. Batch_loss: 1.665719 \n",
      "Batch: 731. Acc: 0.392687. Loss: 1.706005. Batch_acc: 0.406232. Batch_loss: 1.691824 \n",
      "Batch: 732. Acc: 0.392697. Loss: 1.705992. Batch_acc: 0.400234. Batch_loss: 1.696232 \n",
      "Batch: 733. Acc: 0.392682. Loss: 1.705965. Batch_acc: 0.381336. Batch_loss: 1.686068 \n",
      "Batch: 734. Acc: 0.392689. Loss: 1.705951. Batch_acc: 0.397793. Batch_loss: 1.695089 \n",
      "Batch: 735. Acc: 0.392711. Loss: 1.705864. Batch_acc: 0.409117. Batch_loss: 1.642847 \n",
      "Batch: 736. Acc: 0.392718. Loss: 1.705880. Batch_acc: 0.397583. Batch_loss: 1.717391 \n",
      "Batch: 737. Acc: 0.392735. Loss: 1.705876. Batch_acc: 0.405649. Batch_loss: 1.703383 \n",
      "Batch: 738. Acc: 0.392713. Loss: 1.705906. Batch_acc: 0.376319. Batch_loss: 1.728465 \n",
      "Batch: 739. Acc: 0.392717. Loss: 1.705901. Batch_acc: 0.395535. Batch_loss: 1.702099 \n",
      "Batch: 740. Acc: 0.392683. Loss: 1.705978. Batch_acc: 0.367141. Batch_loss: 1.764759 \n",
      "Batch: 741. Acc: 0.392723. Loss: 1.705885. Batch_acc: 0.421680. Batch_loss: 1.637790 \n",
      "Batch: 742. Acc: 0.392739. Loss: 1.705889. Batch_acc: 0.404968. Batch_loss: 1.709005 \n",
      "Batch: 743. Acc: 0.392717. Loss: 1.705937. Batch_acc: 0.375804. Batch_loss: 1.741761 \n",
      "Batch: 744. Acc: 0.392748. Loss: 1.705877. Batch_acc: 0.415481. Batch_loss: 1.662067 \n",
      "Batch: 745. Acc: 0.392754. Loss: 1.705841. Batch_acc: 0.397527. Batch_loss: 1.678275 \n",
      "Batch: 746. Acc: 0.392745. Loss: 1.705828. Batch_acc: 0.385831. Batch_loss: 1.696030 \n",
      "Batch: 747. Acc: 0.392749. Loss: 1.705838. Batch_acc: 0.395942. Batch_loss: 1.713199 \n",
      "Batch: 748. Acc: 0.392775. Loss: 1.705770. Batch_acc: 0.411933. Batch_loss: 1.654792 \n",
      "Batch: 749. Acc: 0.392780. Loss: 1.705779. Batch_acc: 0.396366. Batch_loss: 1.712708 \n",
      "Batch: 750. Acc: 0.392784. Loss: 1.705757. Batch_acc: 0.395667. Batch_loss: 1.689616 \n",
      "Batch: 751. Acc: 0.392790. Loss: 1.705733. Batch_acc: 0.397912. Batch_loss: 1.687171 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 752. Acc: 0.392811. Loss: 1.705658. Batch_acc: 0.408257. Batch_loss: 1.649251 \n",
      "Batch: 753. Acc: 0.392808. Loss: 1.705619. Batch_acc: 0.390759. Batch_loss: 1.676916 \n",
      "Checkpointing on batch: 753. Accuracy: 0.39280814130064845. Loss per char: 1.7056190737305426. Time: 1627210888.3105576\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 14, 17, 15, 17,\n",
      "        21, 19, 20, 25, 23, 25, 23, 25, 23, 23, 26, 18, 19, 23,  1, 66, 79, 69,\n",
      "         1, 14, 18, 15, 20, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.392799. Loss: 1.705609. Batch_acc: 0.386167. Batch_loss: 1.698139 \n",
      "Batch: 755. Acc: 0.392813. Loss: 1.705570. Batch_acc: 0.403180. Batch_loss: 1.676731 \n",
      "Batch: 756. Acc: 0.392824. Loss: 1.705501. Batch_acc: 0.401039. Batch_loss: 1.652736 \n",
      "Batch: 757. Acc: 0.392816. Loss: 1.705501. Batch_acc: 0.386667. Batch_loss: 1.705530 \n",
      "Batch: 758. Acc: 0.392808. Loss: 1.705496. Batch_acc: 0.386621. Batch_loss: 1.701730 \n",
      "Batch: 759. Acc: 0.392821. Loss: 1.705489. Batch_acc: 0.403386. Batch_loss: 1.700071 \n",
      "Batch: 760. Acc: 0.392817. Loss: 1.705502. Batch_acc: 0.389528. Batch_loss: 1.715154 \n",
      "Batch: 761. Acc: 0.392819. Loss: 1.705482. Batch_acc: 0.394448. Batch_loss: 1.690817 \n",
      "Batch: 762. Acc: 0.392799. Loss: 1.705517. Batch_acc: 0.376761. Batch_loss: 1.732658 \n",
      "Batch: 763. Acc: 0.392794. Loss: 1.705521. Batch_acc: 0.389535. Batch_loss: 1.708595 \n",
      "Batch: 764. Acc: 0.392809. Loss: 1.705540. Batch_acc: 0.404231. Batch_loss: 1.719715 \n",
      "Batch: 765. Acc: 0.392842. Loss: 1.705486. Batch_acc: 0.417376. Batch_loss: 1.664848 \n",
      "Batch: 766. Acc: 0.392878. Loss: 1.705437. Batch_acc: 0.420441. Batch_loss: 1.667096 \n",
      "Batch: 767. Acc: 0.392888. Loss: 1.705400. Batch_acc: 0.400554. Batch_loss: 1.678064 \n",
      "Batch: 768. Acc: 0.392886. Loss: 1.705432. Batch_acc: 0.391430. Batch_loss: 1.730808 \n",
      "Batch: 769. Acc: 0.392889. Loss: 1.705409. Batch_acc: 0.395349. Batch_loss: 1.687389 \n",
      "Batch: 770. Acc: 0.392900. Loss: 1.705380. Batch_acc: 0.400798. Batch_loss: 1.683005 \n",
      "Batch: 771. Acc: 0.392889. Loss: 1.705380. Batch_acc: 0.384843. Batch_loss: 1.705599 \n",
      "Batch: 772. Acc: 0.392907. Loss: 1.705334. Batch_acc: 0.406358. Batch_loss: 1.669341 \n",
      "Batch: 773. Acc: 0.392886. Loss: 1.705317. Batch_acc: 0.376471. Batch_loss: 1.692420 \n",
      "Batch: 774. Acc: 0.392915. Loss: 1.705217. Batch_acc: 0.414935. Batch_loss: 1.629521 \n",
      "Batch: 775. Acc: 0.392924. Loss: 1.705155. Batch_acc: 0.399647. Batch_loss: 1.655767 \n",
      "Batch: 776. Acc: 0.392952. Loss: 1.705105. Batch_acc: 0.414523. Batch_loss: 1.666518 \n",
      "Batch: 777. Acc: 0.392946. Loss: 1.705106. Batch_acc: 0.388289. Batch_loss: 1.706290 \n",
      "Batch: 778. Acc: 0.392926. Loss: 1.705170. Batch_acc: 0.377193. Batch_loss: 1.755824 \n",
      "Batch: 779. Acc: 0.392940. Loss: 1.705119. Batch_acc: 0.404000. Batch_loss: 1.664993 \n",
      "Batch: 780. Acc: 0.392962. Loss: 1.705037. Batch_acc: 0.410168. Batch_loss: 1.641351 \n",
      "Batch: 781. Acc: 0.392962. Loss: 1.705013. Batch_acc: 0.393148. Batch_loss: 1.685937 \n",
      "Batch: 782. Acc: 0.392983. Loss: 1.704957. Batch_acc: 0.408805. Batch_loss: 1.661494 \n",
      "Batch: 783. Acc: 0.393004. Loss: 1.704887. Batch_acc: 0.409453. Batch_loss: 1.650619 \n",
      "Batch: 784. Acc: 0.393013. Loss: 1.704847. Batch_acc: 0.400000. Batch_loss: 1.673256 \n",
      "Batch: 785. Acc: 0.393040. Loss: 1.704810. Batch_acc: 0.414648. Batch_loss: 1.675838 \n",
      "Batch: 786. Acc: 0.393044. Loss: 1.704798. Batch_acc: 0.396226. Batch_loss: 1.695057 \n",
      "Batch: 787. Acc: 0.393054. Loss: 1.704766. Batch_acc: 0.400580. Batch_loss: 1.679487 \n",
      "Batch: 788. Acc: 0.393052. Loss: 1.704759. Batch_acc: 0.391933. Batch_loss: 1.698906 \n",
      "Batch: 789. Acc: 0.393061. Loss: 1.704714. Batch_acc: 0.399656. Batch_loss: 1.669617 \n",
      "Batch: 790. Acc: 0.393065. Loss: 1.704651. Batch_acc: 0.396433. Batch_loss: 1.654663 \n",
      "Batch: 791. Acc: 0.393081. Loss: 1.704613. Batch_acc: 0.405374. Batch_loss: 1.674696 \n",
      "Batch: 792. Acc: 0.393095. Loss: 1.704602. Batch_acc: 0.404488. Batch_loss: 1.695987 \n",
      "Batch: 793. Acc: 0.393120. Loss: 1.704541. Batch_acc: 0.413043. Batch_loss: 1.655250 \n",
      "Batch: 794. Acc: 0.393126. Loss: 1.704533. Batch_acc: 0.397759. Batch_loss: 1.697926 \n",
      "Batch: 795. Acc: 0.393144. Loss: 1.704491. Batch_acc: 0.407219. Batch_loss: 1.672032 \n",
      "Batch: 796. Acc: 0.393134. Loss: 1.704531. Batch_acc: 0.385194. Batch_loss: 1.736916 \n",
      "Batch: 797. Acc: 0.393143. Loss: 1.704496. Batch_acc: 0.400689. Batch_loss: 1.676233 \n",
      "Batch: 798. Acc: 0.393148. Loss: 1.704479. Batch_acc: 0.397413. Batch_loss: 1.690921 \n",
      "Batch: 799. Acc: 0.393159. Loss: 1.704470. Batch_acc: 0.401357. Batch_loss: 1.696998 \n",
      "Batch: 800. Acc: 0.393154. Loss: 1.704474. Batch_acc: 0.388757. Batch_loss: 1.708277 \n",
      "Batch: 801. Acc: 0.393145. Loss: 1.704463. Batch_acc: 0.386036. Batch_loss: 1.695626 \n",
      "Batch: 802. Acc: 0.393182. Loss: 1.704398. Batch_acc: 0.423475. Batch_loss: 1.651678 \n",
      "Batch: 803. Acc: 0.393208. Loss: 1.704362. Batch_acc: 0.413873. Batch_loss: 1.675544 \n",
      "Batch: 804. Acc: 0.393223. Loss: 1.704328. Batch_acc: 0.405436. Batch_loss: 1.677667 \n",
      "Batch: 805. Acc: 0.393210. Loss: 1.704348. Batch_acc: 0.382056. Batch_loss: 1.721234 \n",
      "Batch: 806. Acc: 0.393206. Loss: 1.704385. Batch_acc: 0.390230. Batch_loss: 1.732810 \n",
      "Batch: 807. Acc: 0.393231. Loss: 1.704333. Batch_acc: 0.412994. Batch_loss: 1.663373 \n",
      "Batch: 808. Acc: 0.393212. Loss: 1.704348. Batch_acc: 0.377569. Batch_loss: 1.717039 \n",
      "Batch: 809. Acc: 0.393205. Loss: 1.704379. Batch_acc: 0.387507. Batch_loss: 1.729507 \n",
      "Batch: 810. Acc: 0.393216. Loss: 1.704364. Batch_acc: 0.402086. Batch_loss: 1.691674 \n",
      "Batch: 811. Acc: 0.393227. Loss: 1.704336. Batch_acc: 0.402043. Batch_loss: 1.681301 \n",
      "Batch: 812. Acc: 0.393238. Loss: 1.704278. Batch_acc: 0.403055. Batch_loss: 1.655546 \n",
      "Batch: 813. Acc: 0.393271. Loss: 1.704188. Batch_acc: 0.418775. Batch_loss: 1.633126 \n",
      "Batch: 814. Acc: 0.393260. Loss: 1.704178. Batch_acc: 0.384918. Batch_loss: 1.696153 \n",
      "Batch: 815. Acc: 0.393292. Loss: 1.704108. Batch_acc: 0.419544. Batch_loss: 1.645825 \n",
      "Batch: 816. Acc: 0.393320. Loss: 1.704047. Batch_acc: 0.416431. Batch_loss: 1.655040 \n",
      "Batch: 817. Acc: 0.393336. Loss: 1.704026. Batch_acc: 0.406036. Batch_loss: 1.687017 \n",
      "Batch: 818. Acc: 0.393360. Loss: 1.704015. Batch_acc: 0.412365. Batch_loss: 1.695417 \n",
      "Batch: 819. Acc: 0.393358. Loss: 1.704013. Batch_acc: 0.392019. Batch_loss: 1.702649 \n",
      "Batch: 820. Acc: 0.393367. Loss: 1.703956. Batch_acc: 0.400113. Batch_loss: 1.658096 \n",
      "Batch: 821. Acc: 0.393372. Loss: 1.703917. Batch_acc: 0.398030. Batch_loss: 1.671754 \n",
      "Batch: 822. Acc: 0.393378. Loss: 1.703915. Batch_acc: 0.397793. Batch_loss: 1.702437 \n",
      "Batch: 823. Acc: 0.393384. Loss: 1.703887. Batch_acc: 0.399077. Batch_loss: 1.680493 \n",
      "Batch: 824. Acc: 0.393399. Loss: 1.703863. Batch_acc: 0.405993. Batch_loss: 1.683966 \n",
      "Batch: 825. Acc: 0.393397. Loss: 1.703849. Batch_acc: 0.391608. Batch_loss: 1.691979 \n",
      "Batch: 826. Acc: 0.393413. Loss: 1.703813. Batch_acc: 0.406178. Batch_loss: 1.673817 \n",
      "Batch: 827. Acc: 0.393419. Loss: 1.703767. Batch_acc: 0.398857. Batch_loss: 1.666304 \n",
      "Batch: 828. Acc: 0.393455. Loss: 1.703691. Batch_acc: 0.423256. Batch_loss: 1.640120 \n",
      "Batch: 829. Acc: 0.393470. Loss: 1.703653. Batch_acc: 0.405771. Batch_loss: 1.671189 \n",
      "Batch: 830. Acc: 0.393501. Loss: 1.703593. Batch_acc: 0.421053. Batch_loss: 1.652386 \n",
      "Batch: 831. Acc: 0.393518. Loss: 1.703575. Batch_acc: 0.407534. Batch_loss: 1.688485 \n",
      "Batch: 832. Acc: 0.393533. Loss: 1.703507. Batch_acc: 0.405405. Batch_loss: 1.646937 \n",
      "Batch: 833. Acc: 0.393546. Loss: 1.703473. Batch_acc: 0.404375. Batch_loss: 1.675570 \n",
      "Batch: 834. Acc: 0.393550. Loss: 1.703460. Batch_acc: 0.396864. Batch_loss: 1.692020 \n",
      "Batch: 835. Acc: 0.393560. Loss: 1.703420. Batch_acc: 0.402174. Batch_loss: 1.670437 \n",
      "Batch: 836. Acc: 0.393566. Loss: 1.703417. Batch_acc: 0.398496. Batch_loss: 1.701046 \n",
      "Batch: 837. Acc: 0.393543. Loss: 1.703417. Batch_acc: 0.374645. Batch_loss: 1.703356 \n",
      "Batch: 838. Acc: 0.393543. Loss: 1.703413. Batch_acc: 0.393537. Batch_loss: 1.700021 \n",
      "Batch: 839. Acc: 0.393566. Loss: 1.703361. Batch_acc: 0.412407. Batch_loss: 1.659989 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 840. Acc: 0.393561. Loss: 1.703366. Batch_acc: 0.389773. Batch_loss: 1.707396 \n",
      "Batch: 841. Acc: 0.393592. Loss: 1.703293. Batch_acc: 0.418881. Batch_loss: 1.642949 \n",
      "Batch: 842. Acc: 0.393593. Loss: 1.703275. Batch_acc: 0.394406. Batch_loss: 1.688153 \n",
      "Batch: 843. Acc: 0.393612. Loss: 1.703241. Batch_acc: 0.409220. Batch_loss: 1.674693 \n",
      "Batch: 844. Acc: 0.393620. Loss: 1.703170. Batch_acc: 0.400822. Batch_loss: 1.642629 \n",
      "Batch: 845. Acc: 0.393611. Loss: 1.703173. Batch_acc: 0.386025. Batch_loss: 1.705222 \n",
      "Batch: 846. Acc: 0.393624. Loss: 1.703125. Batch_acc: 0.405279. Batch_loss: 1.661734 \n",
      "Batch: 847. Acc: 0.393629. Loss: 1.703106. Batch_acc: 0.397681. Batch_loss: 1.687239 \n",
      "Batch: 848. Acc: 0.393649. Loss: 1.703077. Batch_acc: 0.410285. Batch_loss: 1.678859 \n",
      "Batch: 849. Acc: 0.393655. Loss: 1.703025. Batch_acc: 0.398424. Batch_loss: 1.660291 \n",
      "Batch: 850. Acc: 0.393662. Loss: 1.703024. Batch_acc: 0.399554. Batch_loss: 1.701581 \n",
      "Batch: 851. Acc: 0.393705. Loss: 1.702923. Batch_acc: 0.430206. Batch_loss: 1.618124 \n",
      "Batch: 852. Acc: 0.393702. Loss: 1.702942. Batch_acc: 0.391078. Batch_loss: 1.719016 \n",
      "Batch: 853. Acc: 0.393707. Loss: 1.702919. Batch_acc: 0.397640. Batch_loss: 1.683168 \n",
      "Batch: 854. Acc: 0.393701. Loss: 1.702911. Batch_acc: 0.388695. Batch_loss: 1.695250 \n",
      "Batch: 855. Acc: 0.393696. Loss: 1.702924. Batch_acc: 0.389671. Batch_loss: 1.714660 \n",
      "Batch: 856. Acc: 0.393685. Loss: 1.702903. Batch_acc: 0.384442. Batch_loss: 1.684953 \n",
      "Batch: 857. Acc: 0.393706. Loss: 1.702837. Batch_acc: 0.411628. Batch_loss: 1.646089 \n",
      "Batch: 858. Acc: 0.393705. Loss: 1.702833. Batch_acc: 0.393084. Batch_loss: 1.699557 \n",
      "Batch: 859. Acc: 0.393723. Loss: 1.702794. Batch_acc: 0.409195. Batch_loss: 1.668849 \n",
      "Batch: 860. Acc: 0.393727. Loss: 1.702810. Batch_acc: 0.396752. Batch_loss: 1.716767 \n",
      "Batch: 861. Acc: 0.393714. Loss: 1.702845. Batch_acc: 0.382604. Batch_loss: 1.732971 \n",
      "Batch: 862. Acc: 0.393689. Loss: 1.702878. Batch_acc: 0.371645. Batch_loss: 1.731087 \n",
      "Batch: 863. Acc: 0.393682. Loss: 1.702906. Batch_acc: 0.387916. Batch_loss: 1.727416 \n",
      "Batch: 864. Acc: 0.393698. Loss: 1.702877. Batch_acc: 0.407942. Batch_loss: 1.676720 \n",
      "Batch: 865. Acc: 0.393713. Loss: 1.702840. Batch_acc: 0.407472. Batch_loss: 1.669580 \n",
      "Batch: 866. Acc: 0.393705. Loss: 1.702866. Batch_acc: 0.386841. Batch_loss: 1.725395 \n",
      "Batch: 867. Acc: 0.393727. Loss: 1.702856. Batch_acc: 0.412100. Batch_loss: 1.694417 \n",
      "Batch: 868. Acc: 0.393726. Loss: 1.702859. Batch_acc: 0.393271. Batch_loss: 1.705497 \n",
      "Batch: 869. Acc: 0.393740. Loss: 1.702807. Batch_acc: 0.405756. Batch_loss: 1.658319 \n",
      "Batch: 870. Acc: 0.393725. Loss: 1.702869. Batch_acc: 0.380403. Batch_loss: 1.756901 \n",
      "Batch: 871. Acc: 0.393758. Loss: 1.702793. Batch_acc: 0.422197. Batch_loss: 1.636865 \n",
      "Batch: 872. Acc: 0.393743. Loss: 1.702838. Batch_acc: 0.380869. Batch_loss: 1.743170 \n",
      "Batch: 873. Acc: 0.393740. Loss: 1.702815. Batch_acc: 0.390982. Batch_loss: 1.682582 \n",
      "Batch: 874. Acc: 0.393740. Loss: 1.702844. Batch_acc: 0.393357. Batch_loss: 1.728242 \n",
      "Batch: 875. Acc: 0.393746. Loss: 1.702816. Batch_acc: 0.398870. Batch_loss: 1.679036 \n",
      "Batch: 876. Acc: 0.393770. Loss: 1.702753. Batch_acc: 0.414704. Batch_loss: 1.647622 \n",
      "Batch: 877. Acc: 0.393808. Loss: 1.702651. Batch_acc: 0.427190. Batch_loss: 1.614450 \n",
      "Batch: 878. Acc: 0.393828. Loss: 1.702598. Batch_acc: 0.411464. Batch_loss: 1.656973 \n",
      "Batch: 879. Acc: 0.393825. Loss: 1.702603. Batch_acc: 0.391279. Batch_loss: 1.706886 \n",
      "Batch: 880. Acc: 0.393853. Loss: 1.702545. Batch_acc: 0.417894. Batch_loss: 1.651794 \n",
      "Batch: 881. Acc: 0.393830. Loss: 1.702577. Batch_acc: 0.373152. Batch_loss: 1.732036 \n",
      "Batch: 882. Acc: 0.393827. Loss: 1.702612. Batch_acc: 0.390851. Batch_loss: 1.733893 \n",
      "Batch: 883. Acc: 0.393853. Loss: 1.702554. Batch_acc: 0.416290. Batch_loss: 1.652141 \n",
      "Batch: 884. Acc: 0.393861. Loss: 1.702565. Batch_acc: 0.401159. Batch_loss: 1.711838 \n",
      "Batch: 885. Acc: 0.393899. Loss: 1.702502. Batch_acc: 0.426585. Batch_loss: 1.649109 \n",
      "Batch: 886. Acc: 0.393906. Loss: 1.702505. Batch_acc: 0.399657. Batch_loss: 1.704935 \n",
      "Batch: 887. Acc: 0.393922. Loss: 1.702470. Batch_acc: 0.407679. Batch_loss: 1.672238 \n",
      "Batch: 888. Acc: 0.393886. Loss: 1.702550. Batch_acc: 0.361589. Batch_loss: 1.774992 \n",
      "Batch: 889. Acc: 0.393888. Loss: 1.702550. Batch_acc: 0.395020. Batch_loss: 1.703076 \n",
      "Batch: 890. Acc: 0.393912. Loss: 1.702538. Batch_acc: 0.415509. Batch_loss: 1.691265 \n",
      "Batch: 891. Acc: 0.393941. Loss: 1.702497. Batch_acc: 0.419874. Batch_loss: 1.666326 \n",
      "Batch: 892. Acc: 0.393949. Loss: 1.702474. Batch_acc: 0.400689. Batch_loss: 1.682500 \n",
      "Batch: 893. Acc: 0.393968. Loss: 1.702453. Batch_acc: 0.411199. Batch_loss: 1.683246 \n",
      "Batch: 894. Acc: 0.393967. Loss: 1.702474. Batch_acc: 0.393357. Batch_loss: 1.721614 \n",
      "Batch: 895. Acc: 0.393978. Loss: 1.702461. Batch_acc: 0.403835. Batch_loss: 1.690896 \n",
      "Batch: 896. Acc: 0.394002. Loss: 1.702394. Batch_acc: 0.414882. Batch_loss: 1.643643 \n",
      "Batch: 897. Acc: 0.394016. Loss: 1.702385. Batch_acc: 0.406304. Batch_loss: 1.694097 \n",
      "Batch: 898. Acc: 0.394003. Loss: 1.702423. Batch_acc: 0.382542. Batch_loss: 1.737647 \n",
      "Batch: 899. Acc: 0.393984. Loss: 1.702468. Batch_acc: 0.376669. Batch_loss: 1.743166 \n",
      "Batch: 900. Acc: 0.394004. Loss: 1.702446. Batch_acc: 0.412002. Batch_loss: 1.682743 \n",
      "Batch: 901. Acc: 0.393992. Loss: 1.702425. Batch_acc: 0.382759. Batch_loss: 1.683029 \n",
      "Batch: 902. Acc: 0.393989. Loss: 1.702424. Batch_acc: 0.391837. Batch_loss: 1.701623 \n",
      "Batch: 903. Acc: 0.394008. Loss: 1.702370. Batch_acc: 0.410673. Batch_loss: 1.653649 \n",
      "Batch: 904. Acc: 0.394021. Loss: 1.702315. Batch_acc: 0.405923. Batch_loss: 1.652323 \n",
      "Batch: 905. Acc: 0.394022. Loss: 1.702322. Batch_acc: 0.394968. Batch_loss: 1.708614 \n",
      "Batch: 906. Acc: 0.394001. Loss: 1.702371. Batch_acc: 0.375000. Batch_loss: 1.747178 \n",
      "Batch: 907. Acc: 0.394007. Loss: 1.702340. Batch_acc: 0.399187. Batch_loss: 1.673815 \n",
      "Batch: 908. Acc: 0.393998. Loss: 1.702375. Batch_acc: 0.385714. Batch_loss: 1.735274 \n",
      "Batch: 909. Acc: 0.393991. Loss: 1.702389. Batch_acc: 0.388060. Batch_loss: 1.714988 \n",
      "Batch: 910. Acc: 0.393954. Loss: 1.702453. Batch_acc: 0.359302. Batch_loss: 1.761229 \n",
      "Batch: 911. Acc: 0.393964. Loss: 1.702428. Batch_acc: 0.404101. Batch_loss: 1.678819 \n",
      "Batch: 912. Acc: 0.393970. Loss: 1.702401. Batch_acc: 0.399546. Batch_loss: 1.677969 \n",
      "Batch: 913. Acc: 0.393971. Loss: 1.702390. Batch_acc: 0.394604. Batch_loss: 1.692617 \n",
      "Batch: 914. Acc: 0.393978. Loss: 1.702353. Batch_acc: 0.400000. Batch_loss: 1.667930 \n",
      "Batch: 915. Acc: 0.393969. Loss: 1.702363. Batch_acc: 0.386507. Batch_loss: 1.712066 \n",
      "Batch: 916. Acc: 0.393997. Loss: 1.702292. Batch_acc: 0.418304. Batch_loss: 1.638456 \n",
      "Batch: 917. Acc: 0.393999. Loss: 1.702260. Batch_acc: 0.396152. Batch_loss: 1.673602 \n",
      "Batch: 918. Acc: 0.394012. Loss: 1.702250. Batch_acc: 0.406268. Batch_loss: 1.693029 \n",
      "Batch: 919. Acc: 0.394023. Loss: 1.702256. Batch_acc: 0.403835. Batch_loss: 1.707337 \n",
      "Batch: 920. Acc: 0.394033. Loss: 1.702221. Batch_acc: 0.403590. Batch_loss: 1.670267 \n",
      "Batch: 921. Acc: 0.394050. Loss: 1.702147. Batch_acc: 0.409271. Batch_loss: 1.634723 \n",
      "Batch: 922. Acc: 0.394056. Loss: 1.702123. Batch_acc: 0.400117. Batch_loss: 1.679848 \n",
      "Batch: 923. Acc: 0.394065. Loss: 1.702087. Batch_acc: 0.402110. Batch_loss: 1.668692 \n",
      "Batch: 924. Acc: 0.394056. Loss: 1.702110. Batch_acc: 0.386402. Batch_loss: 1.722952 \n",
      "Batch: 925. Acc: 0.394054. Loss: 1.702113. Batch_acc: 0.392303. Batch_loss: 1.704808 \n",
      "Batch: 926. Acc: 0.394092. Loss: 1.701995. Batch_acc: 0.427379. Batch_loss: 1.596472 \n",
      "Batch: 927. Acc: 0.394087. Loss: 1.702008. Batch_acc: 0.389455. Batch_loss: 1.714502 \n",
      "Batch: 928. Acc: 0.394097. Loss: 1.701960. Batch_acc: 0.403371. Batch_loss: 1.657794 \n",
      "Batch: 929. Acc: 0.394112. Loss: 1.701916. Batch_acc: 0.408377. Batch_loss: 1.661376 \n",
      "Batch: 930. Acc: 0.394098. Loss: 1.701923. Batch_acc: 0.380925. Batch_loss: 1.708304 \n",
      "Batch: 931. Acc: 0.394085. Loss: 1.701929. Batch_acc: 0.381390. Batch_loss: 1.707697 \n",
      "Batch: 932. Acc: 0.394080. Loss: 1.701939. Batch_acc: 0.390046. Batch_loss: 1.710511 \n",
      "Batch: 933. Acc: 0.394084. Loss: 1.701908. Batch_acc: 0.397894. Batch_loss: 1.673252 \n",
      "Batch: 934. Acc: 0.394113. Loss: 1.701802. Batch_acc: 0.420666. Batch_loss: 1.604669 \n",
      "Batch: 935. Acc: 0.394128. Loss: 1.701771. Batch_acc: 0.408353. Batch_loss: 1.671878 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 936. Acc: 0.394120. Loss: 1.701773. Batch_acc: 0.386098. Batch_loss: 1.704190 \n",
      "Batch: 937. Acc: 0.394120. Loss: 1.701763. Batch_acc: 0.394490. Batch_loss: 1.691840 \n",
      "Batch: 938. Acc: 0.394125. Loss: 1.701765. Batch_acc: 0.398530. Batch_loss: 1.703851 \n",
      "Batch: 939. Acc: 0.394128. Loss: 1.701734. Batch_acc: 0.397118. Batch_loss: 1.672970 \n",
      "Batch: 940. Acc: 0.394130. Loss: 1.701673. Batch_acc: 0.395868. Batch_loss: 1.645365 \n",
      "Batch: 941. Acc: 0.394132. Loss: 1.701657. Batch_acc: 0.395833. Batch_loss: 1.686813 \n",
      "Batch: 942. Acc: 0.394163. Loss: 1.701588. Batch_acc: 0.422448. Batch_loss: 1.637515 \n",
      "Batch: 943. Acc: 0.394192. Loss: 1.701493. Batch_acc: 0.422108. Batch_loss: 1.612732 \n",
      "Batch: 944. Acc: 0.394194. Loss: 1.701496. Batch_acc: 0.396172. Batch_loss: 1.704728 \n",
      "Batch: 945. Acc: 0.394197. Loss: 1.701486. Batch_acc: 0.397110. Batch_loss: 1.691313 \n",
      "Batch: 946. Acc: 0.394192. Loss: 1.701461. Batch_acc: 0.388824. Batch_loss: 1.678162 \n",
      "Batch: 947. Acc: 0.394216. Loss: 1.701429. Batch_acc: 0.417100. Batch_loss: 1.670773 \n",
      "Batch: 948. Acc: 0.394235. Loss: 1.701360. Batch_acc: 0.411932. Batch_loss: 1.636393 \n",
      "Batch: 949. Acc: 0.394250. Loss: 1.701332. Batch_acc: 0.408856. Batch_loss: 1.675391 \n",
      "Batch: 950. Acc: 0.394269. Loss: 1.701325. Batch_acc: 0.412407. Batch_loss: 1.694757 \n",
      "Batch: 951. Acc: 0.394264. Loss: 1.701295. Batch_acc: 0.389486. Batch_loss: 1.670770 \n",
      "Batch: 952. Acc: 0.394259. Loss: 1.701273. Batch_acc: 0.388825. Batch_loss: 1.680900 \n",
      "Batch: 953. Acc: 0.394263. Loss: 1.701269. Batch_acc: 0.397936. Batch_loss: 1.697558 \n",
      "Batch: 954. Acc: 0.394264. Loss: 1.701273. Batch_acc: 0.395199. Batch_loss: 1.705377 \n",
      "Batch: 955. Acc: 0.394276. Loss: 1.701250. Batch_acc: 0.406323. Batch_loss: 1.678747 \n",
      "Batch: 956. Acc: 0.394286. Loss: 1.701212. Batch_acc: 0.403318. Batch_loss: 1.664505 \n",
      "Batch: 957. Acc: 0.394301. Loss: 1.701221. Batch_acc: 0.409323. Batch_loss: 1.709709 \n",
      "Batch: 958. Acc: 0.394298. Loss: 1.701218. Batch_acc: 0.390698. Batch_loss: 1.698296 \n",
      "Batch: 959. Acc: 0.394292. Loss: 1.701211. Batch_acc: 0.388953. Batch_loss: 1.694485 \n",
      "Batch: 960. Acc: 0.394301. Loss: 1.701156. Batch_acc: 0.402432. Batch_loss: 1.648786 \n",
      "Batch: 961. Acc: 0.394319. Loss: 1.701105. Batch_acc: 0.411697. Batch_loss: 1.652191 \n",
      "Batch: 962. Acc: 0.394318. Loss: 1.701080. Batch_acc: 0.393471. Batch_loss: 1.676943 \n",
      "Batch: 963. Acc: 0.394326. Loss: 1.701060. Batch_acc: 0.402062. Batch_loss: 1.682031 \n",
      "Batch: 964. Acc: 0.394342. Loss: 1.701023. Batch_acc: 0.409977. Batch_loss: 1.665319 \n",
      "Batch: 965. Acc: 0.394356. Loss: 1.701014. Batch_acc: 0.407407. Batch_loss: 1.692516 \n",
      "Batch: 966. Acc: 0.394346. Loss: 1.700999. Batch_acc: 0.385363. Batch_loss: 1.686141 \n",
      "Batch: 967. Acc: 0.394357. Loss: 1.700980. Batch_acc: 0.404776. Batch_loss: 1.682806 \n",
      "Batch: 968. Acc: 0.394356. Loss: 1.700954. Batch_acc: 0.392899. Batch_loss: 1.675419 \n",
      "Batch: 969. Acc: 0.394363. Loss: 1.700925. Batch_acc: 0.402001. Batch_loss: 1.671759 \n",
      "Batch: 970. Acc: 0.394357. Loss: 1.700921. Batch_acc: 0.388498. Batch_loss: 1.697693 \n",
      "Batch: 971. Acc: 0.394391. Loss: 1.700878. Batch_acc: 0.427823. Batch_loss: 1.658530 \n",
      "Batch: 972. Acc: 0.394405. Loss: 1.700848. Batch_acc: 0.407237. Batch_loss: 1.671447 \n",
      "Batch: 973. Acc: 0.394407. Loss: 1.700838. Batch_acc: 0.396880. Batch_loss: 1.691444 \n",
      "Batch: 974. Acc: 0.394411. Loss: 1.700837. Batch_acc: 0.397727. Batch_loss: 1.699879 \n",
      "Batch: 975. Acc: 0.394417. Loss: 1.700797. Batch_acc: 0.400467. Batch_loss: 1.661171 \n",
      "Batch: 976. Acc: 0.394424. Loss: 1.700795. Batch_acc: 0.401021. Batch_loss: 1.698592 \n",
      "Batch: 977. Acc: 0.394448. Loss: 1.700749. Batch_acc: 0.417714. Batch_loss: 1.655913 \n",
      "Batch: 978. Acc: 0.394457. Loss: 1.700714. Batch_acc: 0.403519. Batch_loss: 1.667425 \n",
      "Batch: 979. Acc: 0.394478. Loss: 1.700682. Batch_acc: 0.414962. Batch_loss: 1.668649 \n",
      "Batch: 980. Acc: 0.394488. Loss: 1.700672. Batch_acc: 0.404830. Batch_loss: 1.691185 \n",
      "Batch: 981. Acc: 0.394504. Loss: 1.700661. Batch_acc: 0.410256. Batch_loss: 1.689694 \n",
      "Batch: 982. Acc: 0.394519. Loss: 1.700601. Batch_acc: 0.408347. Batch_loss: 1.642785 \n",
      "Batch: 983. Acc: 0.394543. Loss: 1.700545. Batch_acc: 0.418591. Batch_loss: 1.645721 \n",
      "Batch: 984. Acc: 0.394563. Loss: 1.700528. Batch_acc: 0.413734. Batch_loss: 1.684012 \n",
      "Batch: 985. Acc: 0.394587. Loss: 1.700450. Batch_acc: 0.418275. Batch_loss: 1.624322 \n",
      "Batch: 986. Acc: 0.394586. Loss: 1.700455. Batch_acc: 0.393692. Batch_loss: 1.706074 \n",
      "Batch: 987. Acc: 0.394600. Loss: 1.700393. Batch_acc: 0.408353. Batch_loss: 1.638444 \n",
      "Batch: 988. Acc: 0.394611. Loss: 1.700358. Batch_acc: 0.405358. Batch_loss: 1.665228 \n",
      "Batch: 989. Acc: 0.394625. Loss: 1.700298. Batch_acc: 0.408627. Batch_loss: 1.641988 \n",
      "Batch: 990. Acc: 0.394616. Loss: 1.700321. Batch_acc: 0.384795. Batch_loss: 1.722767 \n",
      "Batch: 991. Acc: 0.394618. Loss: 1.700326. Batch_acc: 0.396727. Batch_loss: 1.705326 \n",
      "Batch: 992. Acc: 0.394629. Loss: 1.700326. Batch_acc: 0.405755. Batch_loss: 1.700979 \n",
      "Batch: 993. Acc: 0.394615. Loss: 1.700310. Batch_acc: 0.380705. Batch_loss: 1.684142 \n",
      "Batch: 994. Acc: 0.394610. Loss: 1.700274. Batch_acc: 0.390380. Batch_loss: 1.665517 \n",
      "Batch: 995. Acc: 0.394612. Loss: 1.700281. Batch_acc: 0.396443. Batch_loss: 1.706742 \n",
      "Batch: 996. Acc: 0.394624. Loss: 1.700218. Batch_acc: 0.406485. Batch_loss: 1.637375 \n",
      "Batch: 997. Acc: 0.394638. Loss: 1.700203. Batch_acc: 0.408772. Batch_loss: 1.685251 \n",
      "Batch: 998. Acc: 0.394654. Loss: 1.700176. Batch_acc: 0.410983. Batch_loss: 1.672806 \n",
      "Batch: 999. Acc: 0.394663. Loss: 1.700135. Batch_acc: 0.402994. Batch_loss: 1.658846 \n",
      "Batch: 1000. Acc: 0.394683. Loss: 1.700078. Batch_acc: 0.415743. Batch_loss: 1.642671 \n",
      "Batch: 1001. Acc: 0.394705. Loss: 1.700006. Batch_acc: 0.416198. Batch_loss: 1.629851 \n",
      "Batch: 1002. Acc: 0.394695. Loss: 1.700027. Batch_acc: 0.384178. Batch_loss: 1.720743 \n",
      "Batch: 1003. Acc: 0.394724. Loss: 1.699968. Batch_acc: 0.424382. Batch_loss: 1.640293 \n",
      "Batch: 1004. Acc: 0.394740. Loss: 1.699921. Batch_acc: 0.410408. Batch_loss: 1.651367 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.39473961512954814. Loss per char: 1.6999205152140682. Time: 1627211093.3551037\n",
      "Last question is tensor([ 2, 14, 23, 24, 23,  1, 12,  1, 14, 19, 23, 19, 22, 24, 21, 21, 20, 17,\n",
      "        26, 18, 21,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.394754. Loss: 1.699886. Batch_acc: 0.409326. Batch_loss: 1.664898 \n",
      "Batch: 1006. Acc: 0.394773. Loss: 1.699831. Batch_acc: 0.413517. Batch_loss: 1.645548 \n",
      "Batch: 1007. Acc: 0.394768. Loss: 1.699872. Batch_acc: 0.390145. Batch_loss: 1.741467 \n",
      "Batch: 1008. Acc: 0.394807. Loss: 1.699792. Batch_acc: 0.432660. Batch_loss: 1.620257 \n",
      "Batch: 1009. Acc: 0.394838. Loss: 1.699720. Batch_acc: 0.425799. Batch_loss: 1.627768 \n",
      "Batch: 1010. Acc: 0.394851. Loss: 1.699680. Batch_acc: 0.408772. Batch_loss: 1.658919 \n",
      "Batch: 1011. Acc: 0.394853. Loss: 1.699668. Batch_acc: 0.396699. Batch_loss: 1.687941 \n",
      "Batch: 1012. Acc: 0.394845. Loss: 1.699646. Batch_acc: 0.386908. Batch_loss: 1.676692 \n",
      "Batch: 1013. Acc: 0.394842. Loss: 1.699672. Batch_acc: 0.391691. Batch_loss: 1.726882 \n",
      "Batch: 1014. Acc: 0.394847. Loss: 1.699651. Batch_acc: 0.399314. Batch_loss: 1.678153 \n",
      "Batch: 1015. Acc: 0.394830. Loss: 1.699683. Batch_acc: 0.377106. Batch_loss: 1.732929 \n",
      "Batch: 1016. Acc: 0.394848. Loss: 1.699614. Batch_acc: 0.413364. Batch_loss: 1.630650 \n",
      "Batch: 1017. Acc: 0.394854. Loss: 1.699563. Batch_acc: 0.401060. Batch_loss: 1.646433 \n",
      "Batch: 1018. Acc: 0.394867. Loss: 1.699524. Batch_acc: 0.407843. Batch_loss: 1.661266 \n",
      "Batch: 1019. Acc: 0.394851. Loss: 1.699545. Batch_acc: 0.379118. Batch_loss: 1.720080 \n",
      "Batch: 1020. Acc: 0.394855. Loss: 1.699495. Batch_acc: 0.398633. Batch_loss: 1.649294 \n",
      "Batch: 1021. Acc: 0.394860. Loss: 1.699492. Batch_acc: 0.400000. Batch_loss: 1.696176 \n",
      "Batch: 1022. Acc: 0.394866. Loss: 1.699443. Batch_acc: 0.401476. Batch_loss: 1.649684 \n",
      "Batch: 1023. Acc: 0.394866. Loss: 1.699424. Batch_acc: 0.394991. Batch_loss: 1.680738 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1024. Acc: 0.394859. Loss: 1.699415. Batch_acc: 0.386550. Batch_loss: 1.689415 \n",
      "Batch: 1025. Acc: 0.394876. Loss: 1.699370. Batch_acc: 0.413068. Batch_loss: 1.654033 \n",
      "Batch: 1026. Acc: 0.394883. Loss: 1.699313. Batch_acc: 0.401729. Batch_loss: 1.640265 \n",
      "Batch: 1027. Acc: 0.394882. Loss: 1.699282. Batch_acc: 0.393605. Batch_loss: 1.667104 \n",
      "Batch: 1028. Acc: 0.394887. Loss: 1.699285. Batch_acc: 0.399655. Batch_loss: 1.702819 \n",
      "Batch: 1029. Acc: 0.394889. Loss: 1.699261. Batch_acc: 0.396889. Batch_loss: 1.674556 \n",
      "Batch: 1030. Acc: 0.394900. Loss: 1.699228. Batch_acc: 0.406303. Batch_loss: 1.666281 \n",
      "Batch: 1031. Acc: 0.394914. Loss: 1.699209. Batch_acc: 0.408884. Batch_loss: 1.679757 \n",
      "Batch: 1032. Acc: 0.394910. Loss: 1.699211. Batch_acc: 0.391354. Batch_loss: 1.700850 \n",
      "Batch: 1033. Acc: 0.394926. Loss: 1.699176. Batch_acc: 0.411489. Batch_loss: 1.662051 \n",
      "Batch: 1034. Acc: 0.394932. Loss: 1.699165. Batch_acc: 0.400919. Batch_loss: 1.688093 \n",
      "Batch: 1035. Acc: 0.394945. Loss: 1.699150. Batch_acc: 0.408986. Batch_loss: 1.684230 \n",
      "Batch: 1036. Acc: 0.394967. Loss: 1.699096. Batch_acc: 0.416953. Batch_loss: 1.643518 \n",
      "Batch: 1037. Acc: 0.394965. Loss: 1.699069. Batch_acc: 0.392998. Batch_loss: 1.671287 \n",
      "Batch: 1038. Acc: 0.394957. Loss: 1.699055. Batch_acc: 0.387356. Batch_loss: 1.684477 \n",
      "Batch: 1039. Acc: 0.394958. Loss: 1.699033. Batch_acc: 0.395916. Batch_loss: 1.675900 \n",
      "Batch: 1040. Acc: 0.394956. Loss: 1.699040. Batch_acc: 0.392734. Batch_loss: 1.706682 \n",
      "Batch: 1041. Acc: 0.394982. Loss: 1.698970. Batch_acc: 0.421831. Batch_loss: 1.626671 \n",
      "Batch: 1042. Acc: 0.394979. Loss: 1.698983. Batch_acc: 0.392123. Batch_loss: 1.713086 \n",
      "Batch: 1043. Acc: 0.394979. Loss: 1.698951. Batch_acc: 0.394135. Batch_loss: 1.664434 \n",
      "Batch: 1044. Acc: 0.394987. Loss: 1.698939. Batch_acc: 0.403540. Batch_loss: 1.686324 \n",
      "Batch: 1045. Acc: 0.395008. Loss: 1.698881. Batch_acc: 0.416525. Batch_loss: 1.639261 \n",
      "Batch: 1046. Acc: 0.395002. Loss: 1.698856. Batch_acc: 0.389330. Batch_loss: 1.673283 \n",
      "Batch: 1047. Acc: 0.394988. Loss: 1.698881. Batch_acc: 0.380339. Batch_loss: 1.725279 \n",
      "Batch: 1048. Acc: 0.395000. Loss: 1.698855. Batch_acc: 0.407618. Batch_loss: 1.671915 \n",
      "Batch: 1049. Acc: 0.395025. Loss: 1.698811. Batch_acc: 0.421144. Batch_loss: 1.652560 \n",
      "Batch: 1050. Acc: 0.395057. Loss: 1.698738. Batch_acc: 0.428082. Batch_loss: 1.623004 \n",
      "Batch: 1051. Acc: 0.395077. Loss: 1.698689. Batch_acc: 0.416570. Batch_loss: 1.646766 \n",
      "Batch: 1052. Acc: 0.395085. Loss: 1.698666. Batch_acc: 0.403011. Batch_loss: 1.673824 \n",
      "Batch: 1053. Acc: 0.395097. Loss: 1.698646. Batch_acc: 0.407728. Batch_loss: 1.678343 \n",
      "Batch: 1054. Acc: 0.395103. Loss: 1.698635. Batch_acc: 0.402080. Batch_loss: 1.686152 \n",
      "Batch: 1055. Acc: 0.395103. Loss: 1.698643. Batch_acc: 0.394675. Batch_loss: 1.708103 \n",
      "Batch: 1056. Acc: 0.395078. Loss: 1.698689. Batch_acc: 0.368605. Batch_loss: 1.747532 \n",
      "Batch: 1057. Acc: 0.395081. Loss: 1.698692. Batch_acc: 0.398383. Batch_loss: 1.701882 \n",
      "Batch: 1058. Acc: 0.395103. Loss: 1.698646. Batch_acc: 0.418361. Batch_loss: 1.649841 \n",
      "Batch: 1059. Acc: 0.395125. Loss: 1.698606. Batch_acc: 0.418485. Batch_loss: 1.655537 \n",
      "Batch: 1060. Acc: 0.395126. Loss: 1.698584. Batch_acc: 0.396226. Batch_loss: 1.675751 \n",
      "Batch: 1061. Acc: 0.395140. Loss: 1.698556. Batch_acc: 0.409666. Batch_loss: 1.669142 \n",
      "Batch: 1062. Acc: 0.395146. Loss: 1.698508. Batch_acc: 0.401714. Batch_loss: 1.647081 \n",
      "Batch: 1063. Acc: 0.395157. Loss: 1.698497. Batch_acc: 0.406303. Batch_loss: 1.687907 \n",
      "Batch: 1064. Acc: 0.395155. Loss: 1.698487. Batch_acc: 0.393084. Batch_loss: 1.687436 \n",
      "Batch: 1065. Acc: 0.395199. Loss: 1.698382. Batch_acc: 0.441160. Batch_loss: 1.587449 \n",
      "Batch: 1066. Acc: 0.395203. Loss: 1.698355. Batch_acc: 0.399885. Batch_loss: 1.669770 \n",
      "Batch: 1067. Acc: 0.395220. Loss: 1.698314. Batch_acc: 0.413214. Batch_loss: 1.655963 \n",
      "Batch: 1068. Acc: 0.395232. Loss: 1.698298. Batch_acc: 0.407805. Batch_loss: 1.682041 \n",
      "Batch: 1069. Acc: 0.395237. Loss: 1.698277. Batch_acc: 0.399885. Batch_loss: 1.675539 \n",
      "Batch: 1070. Acc: 0.395251. Loss: 1.698238. Batch_acc: 0.410526. Batch_loss: 1.655573 \n",
      "Batch: 1071. Acc: 0.395240. Loss: 1.698238. Batch_acc: 0.383714. Batch_loss: 1.698668 \n",
      "Batch: 1072. Acc: 0.395245. Loss: 1.698206. Batch_acc: 0.400924. Batch_loss: 1.663435 \n",
      "Batch: 1073. Acc: 0.395247. Loss: 1.698183. Batch_acc: 0.397135. Batch_loss: 1.673885 \n",
      "Batch: 1074. Acc: 0.395266. Loss: 1.698143. Batch_acc: 0.415279. Batch_loss: 1.655252 \n",
      "Batch: 1075. Acc: 0.395275. Loss: 1.698136. Batch_acc: 0.405310. Batch_loss: 1.690522 \n",
      "Batch: 1076. Acc: 0.395273. Loss: 1.698149. Batch_acc: 0.393112. Batch_loss: 1.712396 \n",
      "Batch: 1077. Acc: 0.395290. Loss: 1.698146. Batch_acc: 0.413911. Batch_loss: 1.695240 \n",
      "Batch: 1078. Acc: 0.395293. Loss: 1.698165. Batch_acc: 0.398589. Batch_loss: 1.718833 \n",
      "Batch: 1079. Acc: 0.395287. Loss: 1.698162. Batch_acc: 0.388546. Batch_loss: 1.694594 \n",
      "Batch: 1080. Acc: 0.395286. Loss: 1.698150. Batch_acc: 0.394309. Batch_loss: 1.685799 \n",
      "Batch: 1081. Acc: 0.395287. Loss: 1.698146. Batch_acc: 0.396381. Batch_loss: 1.693717 \n",
      "Batch: 1082. Acc: 0.395296. Loss: 1.698120. Batch_acc: 0.404692. Batch_loss: 1.668685 \n",
      "Batch: 1083. Acc: 0.395286. Loss: 1.698138. Batch_acc: 0.385241. Batch_loss: 1.718559 \n",
      "Batch: 1084. Acc: 0.395296. Loss: 1.698122. Batch_acc: 0.405789. Batch_loss: 1.680380 \n",
      "Batch: 1085. Acc: 0.395306. Loss: 1.698087. Batch_acc: 0.405848. Batch_loss: 1.659840 \n",
      "Batch: 1086. Acc: 0.395302. Loss: 1.698092. Batch_acc: 0.391608. Batch_loss: 1.703342 \n",
      "Batch: 1087. Acc: 0.395320. Loss: 1.698038. Batch_acc: 0.414620. Batch_loss: 1.638538 \n",
      "Batch: 1088. Acc: 0.395325. Loss: 1.698035. Batch_acc: 0.400695. Batch_loss: 1.694546 \n",
      "Batch: 1089. Acc: 0.395340. Loss: 1.697988. Batch_acc: 0.412178. Batch_loss: 1.646110 \n",
      "Batch: 1090. Acc: 0.395348. Loss: 1.697967. Batch_acc: 0.404416. Batch_loss: 1.674712 \n",
      "Batch: 1091. Acc: 0.395358. Loss: 1.697965. Batch_acc: 0.405655. Batch_loss: 1.695816 \n",
      "Batch: 1092. Acc: 0.395370. Loss: 1.697927. Batch_acc: 0.409117. Batch_loss: 1.656361 \n",
      "Batch: 1093. Acc: 0.395353. Loss: 1.697961. Batch_acc: 0.375372. Batch_loss: 1.736421 \n",
      "Batch: 1094. Acc: 0.395344. Loss: 1.697973. Batch_acc: 0.386531. Batch_loss: 1.710461 \n",
      "Batch: 1095. Acc: 0.395356. Loss: 1.697934. Batch_acc: 0.408746. Batch_loss: 1.655178 \n",
      "Batch: 1096. Acc: 0.395347. Loss: 1.697944. Batch_acc: 0.384615. Batch_loss: 1.708754 \n",
      "Batch: 1097. Acc: 0.395363. Loss: 1.697906. Batch_acc: 0.413310. Batch_loss: 1.655563 \n",
      "Batch: 1098. Acc: 0.395381. Loss: 1.697860. Batch_acc: 0.415517. Batch_loss: 1.647519 \n",
      "Batch: 1099. Acc: 0.395367. Loss: 1.697898. Batch_acc: 0.379228. Batch_loss: 1.740775 \n",
      "Batch: 1100. Acc: 0.395392. Loss: 1.697844. Batch_acc: 0.422639. Batch_loss: 1.639287 \n",
      "Batch: 1101. Acc: 0.395414. Loss: 1.697778. Batch_acc: 0.419097. Batch_loss: 1.626306 \n",
      "Batch: 1102. Acc: 0.395418. Loss: 1.697749. Batch_acc: 0.400231. Batch_loss: 1.665619 \n",
      "Batch: 1103. Acc: 0.395430. Loss: 1.697714. Batch_acc: 0.408163. Batch_loss: 1.658086 \n",
      "Batch: 1104. Acc: 0.395447. Loss: 1.697684. Batch_acc: 0.415040. Batch_loss: 1.664466 \n",
      "Batch: 1105. Acc: 0.395468. Loss: 1.697600. Batch_acc: 0.418591. Batch_loss: 1.605063 \n",
      "Batch: 1106. Acc: 0.395494. Loss: 1.697546. Batch_acc: 0.424069. Batch_loss: 1.637922 \n",
      "Batch: 1107. Acc: 0.395482. Loss: 1.697560. Batch_acc: 0.381395. Batch_loss: 1.712760 \n",
      "Batch: 1108. Acc: 0.395482. Loss: 1.697554. Batch_acc: 0.395553. Batch_loss: 1.691820 \n",
      "Batch: 1109. Acc: 0.395488. Loss: 1.697552. Batch_acc: 0.403011. Batch_loss: 1.695018 \n",
      "Batch: 1110. Acc: 0.395487. Loss: 1.697542. Batch_acc: 0.394080. Batch_loss: 1.686000 \n",
      "Batch: 1111. Acc: 0.395484. Loss: 1.697542. Batch_acc: 0.391844. Batch_loss: 1.697827 \n",
      "Batch: 1112. Acc: 0.395496. Loss: 1.697515. Batch_acc: 0.408886. Batch_loss: 1.667935 \n",
      "Batch: 1113. Acc: 0.395506. Loss: 1.697492. Batch_acc: 0.406587. Batch_loss: 1.672722 \n",
      "Batch: 1114. Acc: 0.395498. Loss: 1.697498. Batch_acc: 0.385894. Batch_loss: 1.703306 \n",
      "Batch: 1115. Acc: 0.395505. Loss: 1.697462. Batch_acc: 0.403712. Batch_loss: 1.657309 \n",
      "Batch: 1116. Acc: 0.395515. Loss: 1.697448. Batch_acc: 0.406426. Batch_loss: 1.681911 \n",
      "Batch: 1117. Acc: 0.395506. Loss: 1.697429. Batch_acc: 0.385723. Batch_loss: 1.677074 \n",
      "Batch: 1118. Acc: 0.395518. Loss: 1.697420. Batch_acc: 0.408691. Batch_loss: 1.686512 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1119. Acc: 0.395532. Loss: 1.697365. Batch_acc: 0.411396. Batch_loss: 1.637112 \n",
      "Batch: 1120. Acc: 0.395545. Loss: 1.697310. Batch_acc: 0.409750. Batch_loss: 1.634266 \n",
      "Batch: 1121. Acc: 0.395562. Loss: 1.697260. Batch_acc: 0.414181. Batch_loss: 1.642789 \n",
      "Batch: 1122. Acc: 0.395559. Loss: 1.697228. Batch_acc: 0.392268. Batch_loss: 1.662067 \n",
      "Batch: 1123. Acc: 0.395551. Loss: 1.697213. Batch_acc: 0.386728. Batch_loss: 1.680430 \n",
      "Batch: 1124. Acc: 0.395551. Loss: 1.697204. Batch_acc: 0.396290. Batch_loss: 1.686917 \n",
      "Batch: 1125. Acc: 0.395566. Loss: 1.697159. Batch_acc: 0.411179. Batch_loss: 1.649172 \n",
      "Batch: 1126. Acc: 0.395591. Loss: 1.697076. Batch_acc: 0.424069. Batch_loss: 1.603175 \n",
      "Batch: 1127. Acc: 0.395610. Loss: 1.697043. Batch_acc: 0.416146. Batch_loss: 1.660582 \n",
      "Batch: 1128. Acc: 0.395595. Loss: 1.697051. Batch_acc: 0.378860. Batch_loss: 1.706890 \n",
      "Batch: 1129. Acc: 0.395614. Loss: 1.697004. Batch_acc: 0.416667. Batch_loss: 1.642269 \n",
      "Batch: 1130. Acc: 0.395628. Loss: 1.696946. Batch_acc: 0.411864. Batch_loss: 1.632467 \n",
      "Batch: 1131. Acc: 0.395609. Loss: 1.696982. Batch_acc: 0.373684. Batch_loss: 1.738405 \n",
      "Batch: 1132. Acc: 0.395623. Loss: 1.696965. Batch_acc: 0.411834. Batch_loss: 1.677561 \n",
      "Batch: 1133. Acc: 0.395623. Loss: 1.696931. Batch_acc: 0.395531. Batch_loss: 1.658903 \n",
      "Batch: 1134. Acc: 0.395619. Loss: 1.696920. Batch_acc: 0.390839. Batch_loss: 1.684337 \n",
      "Batch: 1135. Acc: 0.395623. Loss: 1.696912. Batch_acc: 0.400347. Batch_loss: 1.688364 \n",
      "Batch: 1136. Acc: 0.395635. Loss: 1.696876. Batch_acc: 0.409012. Batch_loss: 1.655616 \n",
      "Batch: 1137. Acc: 0.395639. Loss: 1.696859. Batch_acc: 0.399883. Batch_loss: 1.677505 \n",
      "Batch: 1138. Acc: 0.395641. Loss: 1.696858. Batch_acc: 0.398159. Batch_loss: 1.695224 \n",
      "Batch: 1139. Acc: 0.395660. Loss: 1.696809. Batch_acc: 0.417346. Batch_loss: 1.639925 \n",
      "Batch: 1140. Acc: 0.395666. Loss: 1.696827. Batch_acc: 0.403569. Batch_loss: 1.717236 \n",
      "Batch: 1141. Acc: 0.395682. Loss: 1.696815. Batch_acc: 0.412993. Batch_loss: 1.683084 \n",
      "Batch: 1142. Acc: 0.395688. Loss: 1.696778. Batch_acc: 0.402778. Batch_loss: 1.654411 \n",
      "Batch: 1143. Acc: 0.395669. Loss: 1.696804. Batch_acc: 0.373380. Batch_loss: 1.727571 \n",
      "Batch: 1144. Acc: 0.395662. Loss: 1.696821. Batch_acc: 0.388000. Batch_loss: 1.715974 \n",
      "Batch: 1145. Acc: 0.395649. Loss: 1.696857. Batch_acc: 0.381828. Batch_loss: 1.737254 \n",
      "Batch: 1146. Acc: 0.395663. Loss: 1.696863. Batch_acc: 0.411014. Batch_loss: 1.703259 \n",
      "Batch: 1147. Acc: 0.395661. Loss: 1.696876. Batch_acc: 0.393008. Batch_loss: 1.713108 \n",
      "Batch: 1148. Acc: 0.395658. Loss: 1.696854. Batch_acc: 0.392455. Batch_loss: 1.671617 \n",
      "Batch: 1149. Acc: 0.395675. Loss: 1.696817. Batch_acc: 0.415332. Batch_loss: 1.654262 \n",
      "Batch: 1150. Acc: 0.395689. Loss: 1.696791. Batch_acc: 0.411731. Batch_loss: 1.667489 \n",
      "Batch: 1151. Acc: 0.395702. Loss: 1.696749. Batch_acc: 0.411060. Batch_loss: 1.647942 \n",
      "Batch: 1152. Acc: 0.395693. Loss: 1.696761. Batch_acc: 0.384479. Batch_loss: 1.711576 \n",
      "Batch: 1153. Acc: 0.395684. Loss: 1.696782. Batch_acc: 0.386076. Batch_loss: 1.720390 \n",
      "Batch: 1154. Acc: 0.395674. Loss: 1.696802. Batch_acc: 0.382954. Batch_loss: 1.720423 \n",
      "Batch: 1155. Acc: 0.395677. Loss: 1.696765. Batch_acc: 0.399884. Batch_loss: 1.654053 \n",
      "Batch: 1156. Acc: 0.395685. Loss: 1.696733. Batch_acc: 0.404991. Batch_loss: 1.660523 \n",
      "Batch: 1157. Acc: 0.395692. Loss: 1.696710. Batch_acc: 0.402874. Batch_loss: 1.670051 \n",
      "Batch: 1158. Acc: 0.395693. Loss: 1.696705. Batch_acc: 0.397668. Batch_loss: 1.690458 \n",
      "Batch: 1159. Acc: 0.395681. Loss: 1.696724. Batch_acc: 0.381121. Batch_loss: 1.719752 \n",
      "Batch: 1160. Acc: 0.395683. Loss: 1.696714. Batch_acc: 0.398159. Batch_loss: 1.684949 \n",
      "Batch: 1161. Acc: 0.395681. Loss: 1.696721. Batch_acc: 0.393397. Batch_loss: 1.704823 \n",
      "Batch: 1162. Acc: 0.395687. Loss: 1.696735. Batch_acc: 0.402056. Batch_loss: 1.713071 \n",
      "Batch: 1163. Acc: 0.395682. Loss: 1.696747. Batch_acc: 0.389879. Batch_loss: 1.710731 \n",
      "Batch: 1164. Acc: 0.395668. Loss: 1.696783. Batch_acc: 0.379918. Batch_loss: 1.739141 \n",
      "Batch: 1165. Acc: 0.395659. Loss: 1.696802. Batch_acc: 0.385529. Batch_loss: 1.717905 \n",
      "Batch: 1166. Acc: 0.395677. Loss: 1.696744. Batch_acc: 0.415307. Batch_loss: 1.631315 \n",
      "Batch: 1167. Acc: 0.395680. Loss: 1.696739. Batch_acc: 0.399769. Batch_loss: 1.690935 \n",
      "Batch: 1168. Acc: 0.395685. Loss: 1.696741. Batch_acc: 0.401630. Batch_loss: 1.699451 \n",
      "Batch: 1169. Acc: 0.395692. Loss: 1.696709. Batch_acc: 0.403328. Batch_loss: 1.658818 \n",
      "Batch: 1170. Acc: 0.395699. Loss: 1.696680. Batch_acc: 0.403569. Batch_loss: 1.662586 \n",
      "Batch: 1171. Acc: 0.395696. Loss: 1.696686. Batch_acc: 0.392959. Batch_loss: 1.703575 \n",
      "Batch: 1172. Acc: 0.395708. Loss: 1.696662. Batch_acc: 0.409426. Batch_loss: 1.668709 \n",
      "Batch: 1173. Acc: 0.395709. Loss: 1.696664. Batch_acc: 0.397314. Batch_loss: 1.698881 \n",
      "Batch: 1174. Acc: 0.395711. Loss: 1.696680. Batch_acc: 0.397268. Batch_loss: 1.716627 \n",
      "Batch: 1175. Acc: 0.395709. Loss: 1.696694. Batch_acc: 0.393750. Batch_loss: 1.713215 \n",
      "Batch: 1176. Acc: 0.395714. Loss: 1.696681. Batch_acc: 0.401917. Batch_loss: 1.681011 \n",
      "Batch: 1177. Acc: 0.395713. Loss: 1.696656. Batch_acc: 0.394220. Batch_loss: 1.667099 \n",
      "Batch: 1178. Acc: 0.395726. Loss: 1.696625. Batch_acc: 0.411458. Batch_loss: 1.660452 \n",
      "Batch: 1179. Acc: 0.395728. Loss: 1.696615. Batch_acc: 0.398030. Batch_loss: 1.685165 \n",
      "Batch: 1180. Acc: 0.395745. Loss: 1.696548. Batch_acc: 0.415934. Batch_loss: 1.615938 \n",
      "Batch: 1181. Acc: 0.395761. Loss: 1.696518. Batch_acc: 0.414634. Batch_loss: 1.660848 \n",
      "Batch: 1182. Acc: 0.395779. Loss: 1.696497. Batch_acc: 0.416714. Batch_loss: 1.671607 \n",
      "Batch: 1183. Acc: 0.395782. Loss: 1.696435. Batch_acc: 0.399440. Batch_loss: 1.625400 \n",
      "Batch: 1184. Acc: 0.395773. Loss: 1.696451. Batch_acc: 0.384438. Batch_loss: 1.714699 \n",
      "Batch: 1185. Acc: 0.395773. Loss: 1.696446. Batch_acc: 0.396433. Batch_loss: 1.690516 \n",
      "Batch: 1186. Acc: 0.395786. Loss: 1.696415. Batch_acc: 0.410508. Batch_loss: 1.660439 \n",
      "Batch: 1187. Acc: 0.395803. Loss: 1.696371. Batch_acc: 0.417149. Batch_loss: 1.642810 \n",
      "Batch: 1188. Acc: 0.395798. Loss: 1.696361. Batch_acc: 0.390162. Batch_loss: 1.685731 \n",
      "Batch: 1189. Acc: 0.395807. Loss: 1.696312. Batch_acc: 0.405512. Batch_loss: 1.639156 \n",
      "Batch: 1190. Acc: 0.395825. Loss: 1.696281. Batch_acc: 0.416906. Batch_loss: 1.658985 \n",
      "Batch: 1191. Acc: 0.395830. Loss: 1.696265. Batch_acc: 0.402770. Batch_loss: 1.677612 \n",
      "Batch: 1192. Acc: 0.395836. Loss: 1.696269. Batch_acc: 0.402728. Batch_loss: 1.701489 \n",
      "Batch: 1193. Acc: 0.395845. Loss: 1.696231. Batch_acc: 0.405830. Batch_loss: 1.651958 \n",
      "Batch: 1194. Acc: 0.395850. Loss: 1.696209. Batch_acc: 0.402149. Batch_loss: 1.670189 \n",
      "Batch: 1195. Acc: 0.395849. Loss: 1.696194. Batch_acc: 0.394706. Batch_loss: 1.677188 \n",
      "Batch: 1196. Acc: 0.395861. Loss: 1.696145. Batch_acc: 0.410508. Batch_loss: 1.637729 \n",
      "Batch: 1197. Acc: 0.395882. Loss: 1.696087. Batch_acc: 0.419588. Batch_loss: 1.629396 \n",
      "Batch: 1198. Acc: 0.395891. Loss: 1.696059. Batch_acc: 0.406701. Batch_loss: 1.661960 \n",
      "Batch: 1199. Acc: 0.395893. Loss: 1.696041. Batch_acc: 0.398857. Batch_loss: 1.674749 \n",
      "Batch: 1200. Acc: 0.395894. Loss: 1.696023. Batch_acc: 0.396501. Batch_loss: 1.673680 \n",
      "Batch: 1201. Acc: 0.395895. Loss: 1.696015. Batch_acc: 0.397862. Batch_loss: 1.686560 \n",
      "Batch: 1202. Acc: 0.395906. Loss: 1.695977. Batch_acc: 0.408459. Batch_loss: 1.649671 \n",
      "Batch: 1203. Acc: 0.395906. Loss: 1.695972. Batch_acc: 0.396798. Batch_loss: 1.690767 \n",
      "Batch: 1204. Acc: 0.395906. Loss: 1.695954. Batch_acc: 0.395894. Batch_loss: 1.673124 \n",
      "Batch: 1205. Acc: 0.395908. Loss: 1.695937. Batch_acc: 0.397624. Batch_loss: 1.675939 \n",
      "Batch: 1206. Acc: 0.395915. Loss: 1.695925. Batch_acc: 0.404291. Batch_loss: 1.681842 \n",
      "Batch: 1207. Acc: 0.395936. Loss: 1.695850. Batch_acc: 0.421053. Batch_loss: 1.606548 \n",
      "Batch: 1208. Acc: 0.395941. Loss: 1.695826. Batch_acc: 0.402125. Batch_loss: 1.667579 \n",
      "Batch: 1209. Acc: 0.395974. Loss: 1.695749. Batch_acc: 0.433910. Batch_loss: 1.605390 \n",
      "Batch: 1210. Acc: 0.395980. Loss: 1.695754. Batch_acc: 0.403458. Batch_loss: 1.702647 \n",
      "Batch: 1211. Acc: 0.395982. Loss: 1.695728. Batch_acc: 0.398492. Batch_loss: 1.664133 \n",
      "Batch: 1212. Acc: 0.396002. Loss: 1.695697. Batch_acc: 0.420441. Batch_loss: 1.657110 \n",
      "Batch: 1213. Acc: 0.396026. Loss: 1.695627. Batch_acc: 0.424277. Batch_loss: 1.612703 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1214. Acc: 0.396022. Loss: 1.695648. Batch_acc: 0.391148. Batch_loss: 1.721267 \n",
      "Batch: 1215. Acc: 0.396034. Loss: 1.695625. Batch_acc: 0.411085. Batch_loss: 1.667980 \n",
      "Batch: 1216. Acc: 0.396038. Loss: 1.695606. Batch_acc: 0.400819. Batch_loss: 1.671860 \n",
      "Batch: 1217. Acc: 0.396038. Loss: 1.695594. Batch_acc: 0.396443. Batch_loss: 1.680908 \n",
      "Batch: 1218. Acc: 0.396036. Loss: 1.695590. Batch_acc: 0.392837. Batch_loss: 1.691288 \n",
      "Batch: 1219. Acc: 0.396038. Loss: 1.695582. Batch_acc: 0.398496. Batch_loss: 1.685054 \n",
      "Batch: 1220. Acc: 0.396045. Loss: 1.695570. Batch_acc: 0.405093. Batch_loss: 1.681743 \n",
      "Batch: 1221. Acc: 0.396054. Loss: 1.695565. Batch_acc: 0.407599. Batch_loss: 1.688585 \n",
      "Batch: 1222. Acc: 0.396067. Loss: 1.695533. Batch_acc: 0.411664. Batch_loss: 1.657305 \n",
      "Batch: 1223. Acc: 0.396064. Loss: 1.695527. Batch_acc: 0.392383. Batch_loss: 1.687476 \n",
      "Batch: 1224. Acc: 0.396084. Loss: 1.695480. Batch_acc: 0.419573. Batch_loss: 1.640375 \n",
      "Batch: 1225. Acc: 0.396092. Loss: 1.695461. Batch_acc: 0.406523. Batch_loss: 1.671147 \n",
      "Batch: 1226. Acc: 0.396116. Loss: 1.695397. Batch_acc: 0.424501. Batch_loss: 1.617412 \n",
      "Batch: 1227. Acc: 0.396126. Loss: 1.695354. Batch_acc: 0.408830. Batch_loss: 1.643517 \n",
      "Batch: 1228. Acc: 0.396148. Loss: 1.695283. Batch_acc: 0.421607. Batch_loss: 1.610629 \n",
      "Batch: 1229. Acc: 0.396153. Loss: 1.695265. Batch_acc: 0.402162. Batch_loss: 1.674502 \n",
      "Batch: 1230. Acc: 0.396169. Loss: 1.695210. Batch_acc: 0.415489. Batch_loss: 1.628261 \n",
      "Batch: 1231. Acc: 0.396176. Loss: 1.695181. Batch_acc: 0.404694. Batch_loss: 1.659264 \n",
      "Batch: 1232. Acc: 0.396182. Loss: 1.695157. Batch_acc: 0.404527. Batch_loss: 1.665503 \n",
      "Batch: 1233. Acc: 0.396189. Loss: 1.695109. Batch_acc: 0.404968. Batch_loss: 1.636068 \n",
      "Batch: 1234. Acc: 0.396197. Loss: 1.695073. Batch_acc: 0.405721. Batch_loss: 1.650192 \n",
      "Batch: 1235. Acc: 0.396207. Loss: 1.695059. Batch_acc: 0.408443. Batch_loss: 1.677032 \n",
      "Batch: 1236. Acc: 0.396219. Loss: 1.695002. Batch_acc: 0.411625. Batch_loss: 1.622611 \n",
      "Batch: 1237. Acc: 0.396231. Loss: 1.694973. Batch_acc: 0.410848. Batch_loss: 1.659317 \n",
      "Batch: 1238. Acc: 0.396239. Loss: 1.694916. Batch_acc: 0.405512. Batch_loss: 1.625993 \n",
      "Batch: 1239. Acc: 0.396248. Loss: 1.694902. Batch_acc: 0.408033. Batch_loss: 1.677385 \n",
      "Batch: 1240. Acc: 0.396259. Loss: 1.694862. Batch_acc: 0.409966. Batch_loss: 1.646067 \n",
      "Batch: 1241. Acc: 0.396275. Loss: 1.694804. Batch_acc: 0.415393. Batch_loss: 1.624369 \n",
      "Batch: 1242. Acc: 0.396282. Loss: 1.694792. Batch_acc: 0.405546. Batch_loss: 1.679611 \n",
      "Batch: 1243. Acc: 0.396291. Loss: 1.694774. Batch_acc: 0.407470. Batch_loss: 1.672330 \n",
      "Batch: 1244. Acc: 0.396310. Loss: 1.694726. Batch_acc: 0.418927. Batch_loss: 1.635608 \n",
      "Batch: 1245. Acc: 0.396309. Loss: 1.694725. Batch_acc: 0.395700. Batch_loss: 1.693012 \n",
      "Batch: 1246. Acc: 0.396330. Loss: 1.694674. Batch_acc: 0.422444. Batch_loss: 1.630348 \n",
      "Batch: 1247. Acc: 0.396332. Loss: 1.694641. Batch_acc: 0.399547. Batch_loss: 1.653174 \n",
      "Batch: 1248. Acc: 0.396352. Loss: 1.694579. Batch_acc: 0.420448. Batch_loss: 1.618211 \n",
      "Batch: 1249. Acc: 0.396352. Loss: 1.694575. Batch_acc: 0.396742. Batch_loss: 1.689192 \n",
      "Batch: 1250. Acc: 0.396361. Loss: 1.694541. Batch_acc: 0.407429. Batch_loss: 1.652358 \n",
      "Batch: 1251. Acc: 0.396388. Loss: 1.694478. Batch_acc: 0.429621. Batch_loss: 1.616828 \n",
      "Batch: 1252. Acc: 0.396406. Loss: 1.694455. Batch_acc: 0.418799. Batch_loss: 1.667204 \n",
      "Batch: 1253. Acc: 0.396428. Loss: 1.694413. Batch_acc: 0.423739. Batch_loss: 1.641262 \n",
      "Batch: 1254. Acc: 0.396433. Loss: 1.694402. Batch_acc: 0.402794. Batch_loss: 1.680451 \n",
      "Batch: 1255. Acc: 0.396466. Loss: 1.694326. Batch_acc: 0.437033. Batch_loss: 1.599170 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.39646560920264967. Loss per char: 1.6943258417551978. Time: 1627211297.0384514\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 25, 24, 20, 22, 21, 15, 18, 17,\n",
      "        22, 21, 23, 25, 21, 19,  1, 78, 74, 79, 86, 84,  1, 23, 32,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.396476. Loss: 1.694300. Batch_acc: 0.410122. Batch_loss: 1.661775 \n",
      "Batch: 1257. Acc: 0.396481. Loss: 1.694295. Batch_acc: 0.401961. Batch_loss: 1.687235 \n",
      "Batch: 1258. Acc: 0.396481. Loss: 1.694301. Batch_acc: 0.397101. Batch_loss: 1.702754 \n",
      "Batch: 1259. Acc: 0.396494. Loss: 1.694263. Batch_acc: 0.412559. Batch_loss: 1.644638 \n",
      "Batch: 1260. Acc: 0.396505. Loss: 1.694241. Batch_acc: 0.410767. Batch_loss: 1.666108 \n",
      "Batch: 1261. Acc: 0.396492. Loss: 1.694269. Batch_acc: 0.379724. Batch_loss: 1.731891 \n",
      "Batch: 1262. Acc: 0.396507. Loss: 1.694213. Batch_acc: 0.414718. Batch_loss: 1.623339 \n",
      "Batch: 1263. Acc: 0.396502. Loss: 1.694241. Batch_acc: 0.390925. Batch_loss: 1.730442 \n",
      "Batch: 1264. Acc: 0.396511. Loss: 1.694221. Batch_acc: 0.407986. Batch_loss: 1.668437 \n",
      "Batch: 1265. Acc: 0.396521. Loss: 1.694200. Batch_acc: 0.409333. Batch_loss: 1.667922 \n",
      "Batch: 1266. Acc: 0.396518. Loss: 1.694207. Batch_acc: 0.392464. Batch_loss: 1.702874 \n",
      "Batch: 1267. Acc: 0.396534. Loss: 1.694170. Batch_acc: 0.416667. Batch_loss: 1.646150 \n",
      "Batch: 1268. Acc: 0.396550. Loss: 1.694122. Batch_acc: 0.417627. Batch_loss: 1.633662 \n",
      "Batch: 1269. Acc: 0.396573. Loss: 1.694071. Batch_acc: 0.425606. Batch_loss: 1.629801 \n",
      "Batch: 1270. Acc: 0.396586. Loss: 1.694039. Batch_acc: 0.412400. Batch_loss: 1.653969 \n",
      "Batch: 1271. Acc: 0.396589. Loss: 1.694006. Batch_acc: 0.400573. Batch_loss: 1.651074 \n",
      "Batch: 1272. Acc: 0.396604. Loss: 1.693978. Batch_acc: 0.415995. Batch_loss: 1.659197 \n",
      "Batch: 1273. Acc: 0.396604. Loss: 1.693963. Batch_acc: 0.396433. Batch_loss: 1.675306 \n",
      "Batch: 1274. Acc: 0.396612. Loss: 1.693925. Batch_acc: 0.407155. Batch_loss: 1.645792 \n",
      "Batch: 1275. Acc: 0.396627. Loss: 1.693893. Batch_acc: 0.414845. Batch_loss: 1.653040 \n",
      "Batch: 1276. Acc: 0.396624. Loss: 1.693843. Batch_acc: 0.392694. Batch_loss: 1.630997 \n",
      "Batch: 1277. Acc: 0.396621. Loss: 1.693853. Batch_acc: 0.392960. Batch_loss: 1.706078 \n",
      "Batch: 1278. Acc: 0.396645. Loss: 1.693771. Batch_acc: 0.427083. Batch_loss: 1.588460 \n",
      "Batch: 1279. Acc: 0.396666. Loss: 1.693721. Batch_acc: 0.423333. Batch_loss: 1.631521 \n",
      "Batch: 1280. Acc: 0.396663. Loss: 1.693691. Batch_acc: 0.393103. Batch_loss: 1.655677 \n",
      "Batch: 1281. Acc: 0.396672. Loss: 1.693655. Batch_acc: 0.408023. Batch_loss: 1.648137 \n",
      "Batch: 1282. Acc: 0.396692. Loss: 1.693622. Batch_acc: 0.422693. Batch_loss: 1.650261 \n",
      "Batch: 1283. Acc: 0.396705. Loss: 1.693572. Batch_acc: 0.412680. Batch_loss: 1.628555 \n",
      "Batch: 1284. Acc: 0.396722. Loss: 1.693540. Batch_acc: 0.419355. Batch_loss: 1.652857 \n",
      "Batch: 1285. Acc: 0.396742. Loss: 1.693511. Batch_acc: 0.422519. Batch_loss: 1.655888 \n",
      "Batch: 1286. Acc: 0.396749. Loss: 1.693485. Batch_acc: 0.405296. Batch_loss: 1.660423 \n",
      "Batch: 1287. Acc: 0.396766. Loss: 1.693425. Batch_acc: 0.418828. Batch_loss: 1.617710 \n",
      "Batch: 1288. Acc: 0.396765. Loss: 1.693446. Batch_acc: 0.395642. Batch_loss: 1.719754 \n",
      "Batch: 1289. Acc: 0.396786. Loss: 1.693404. Batch_acc: 0.423502. Batch_loss: 1.638801 \n",
      "Batch: 1290. Acc: 0.396787. Loss: 1.693399. Batch_acc: 0.398605. Batch_loss: 1.687414 \n",
      "Batch: 1291. Acc: 0.396792. Loss: 1.693394. Batch_acc: 0.402685. Batch_loss: 1.687167 \n",
      "Batch: 1292. Acc: 0.396800. Loss: 1.693398. Batch_acc: 0.407841. Batch_loss: 1.699073 \n",
      "Batch: 1293. Acc: 0.396818. Loss: 1.693351. Batch_acc: 0.419229. Batch_loss: 1.633639 \n",
      "Batch: 1294. Acc: 0.396829. Loss: 1.693313. Batch_acc: 0.410315. Batch_loss: 1.644715 \n",
      "Batch: 1295. Acc: 0.396826. Loss: 1.693309. Batch_acc: 0.393087. Batch_loss: 1.688080 \n",
      "Batch: 1296. Acc: 0.396845. Loss: 1.693266. Batch_acc: 0.421848. Batch_loss: 1.636268 \n",
      "Batch: 1297. Acc: 0.396847. Loss: 1.693233. Batch_acc: 0.399538. Batch_loss: 1.650480 \n",
      "Batch: 1298. Acc: 0.396847. Loss: 1.693188. Batch_acc: 0.397245. Batch_loss: 1.635291 \n",
      "Batch: 1299. Acc: 0.396853. Loss: 1.693185. Batch_acc: 0.404540. Batch_loss: 1.688663 \n",
      "Batch: 1300. Acc: 0.396877. Loss: 1.693121. Batch_acc: 0.426954. Batch_loss: 1.612145 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1301. Acc: 0.396886. Loss: 1.693105. Batch_acc: 0.409038. Batch_loss: 1.671690 \n",
      "Batch: 1302. Acc: 0.396893. Loss: 1.693074. Batch_acc: 0.406162. Batch_loss: 1.653670 \n",
      "Batch: 1303. Acc: 0.396901. Loss: 1.693055. Batch_acc: 0.407055. Batch_loss: 1.669255 \n",
      "Batch: 1304. Acc: 0.396915. Loss: 1.692985. Batch_acc: 0.413832. Batch_loss: 1.604835 \n",
      "Batch: 1305. Acc: 0.396917. Loss: 1.692984. Batch_acc: 0.400697. Batch_loss: 1.691036 \n",
      "Batch: 1306. Acc: 0.396924. Loss: 1.692957. Batch_acc: 0.405158. Batch_loss: 1.658252 \n",
      "Batch: 1307. Acc: 0.396941. Loss: 1.692918. Batch_acc: 0.418803. Batch_loss: 1.642638 \n",
      "Batch: 1308. Acc: 0.396936. Loss: 1.692912. Batch_acc: 0.390898. Batch_loss: 1.684904 \n",
      "Batch: 1309. Acc: 0.396937. Loss: 1.692913. Batch_acc: 0.398330. Batch_loss: 1.693889 \n",
      "Batch: 1310. Acc: 0.396948. Loss: 1.692885. Batch_acc: 0.411054. Batch_loss: 1.656288 \n",
      "Batch: 1311. Acc: 0.396962. Loss: 1.692811. Batch_acc: 0.415629. Batch_loss: 1.596739 \n",
      "Batch: 1312. Acc: 0.396956. Loss: 1.692827. Batch_acc: 0.388420. Batch_loss: 1.713881 \n",
      "Batch: 1313. Acc: 0.396969. Loss: 1.692789. Batch_acc: 0.413930. Batch_loss: 1.643631 \n",
      "Batch: 1314. Acc: 0.396976. Loss: 1.692759. Batch_acc: 0.406023. Batch_loss: 1.654264 \n",
      "Batch: 1315. Acc: 0.396988. Loss: 1.692748. Batch_acc: 0.412698. Batch_loss: 1.678470 \n",
      "Batch: 1316. Acc: 0.396996. Loss: 1.692745. Batch_acc: 0.408590. Batch_loss: 1.687892 \n",
      "Batch: 1317. Acc: 0.397005. Loss: 1.692729. Batch_acc: 0.408270. Batch_loss: 1.671676 \n",
      "Batch: 1318. Acc: 0.397005. Loss: 1.692693. Batch_acc: 0.397590. Batch_loss: 1.646036 \n",
      "Batch: 1319. Acc: 0.397016. Loss: 1.692638. Batch_acc: 0.411400. Batch_loss: 1.621018 \n",
      "Batch: 1320. Acc: 0.397033. Loss: 1.692571. Batch_acc: 0.419189. Batch_loss: 1.605518 \n",
      "Batch: 1321. Acc: 0.397034. Loss: 1.692529. Batch_acc: 0.397714. Batch_loss: 1.637389 \n",
      "Batch: 1322. Acc: 0.397047. Loss: 1.692482. Batch_acc: 0.414171. Batch_loss: 1.629422 \n",
      "Batch: 1323. Acc: 0.397045. Loss: 1.692465. Batch_acc: 0.395415. Batch_loss: 1.669784 \n",
      "Batch: 1324. Acc: 0.397062. Loss: 1.692424. Batch_acc: 0.419097. Batch_loss: 1.638818 \n",
      "Batch: 1325. Acc: 0.397063. Loss: 1.692413. Batch_acc: 0.398734. Batch_loss: 1.678485 \n",
      "Batch: 1326. Acc: 0.397078. Loss: 1.692359. Batch_acc: 0.416667. Batch_loss: 1.621027 \n",
      "Batch: 1327. Acc: 0.397087. Loss: 1.692330. Batch_acc: 0.408442. Batch_loss: 1.652162 \n",
      "Batch: 1328. Acc: 0.397094. Loss: 1.692296. Batch_acc: 0.406944. Batch_loss: 1.647461 \n",
      "Batch: 1329. Acc: 0.397092. Loss: 1.692284. Batch_acc: 0.394629. Batch_loss: 1.676500 \n",
      "Batch: 1330. Acc: 0.397110. Loss: 1.692245. Batch_acc: 0.421083. Batch_loss: 1.640567 \n",
      "Batch: 1331. Acc: 0.397121. Loss: 1.692221. Batch_acc: 0.411248. Batch_loss: 1.660043 \n",
      "Batch: 1332. Acc: 0.397116. Loss: 1.692213. Batch_acc: 0.390302. Batch_loss: 1.681468 \n",
      "Batch: 1333. Acc: 0.397117. Loss: 1.692219. Batch_acc: 0.398360. Batch_loss: 1.699938 \n",
      "Batch: 1334. Acc: 0.397124. Loss: 1.692184. Batch_acc: 0.406693. Batch_loss: 1.646641 \n",
      "Batch: 1335. Acc: 0.397138. Loss: 1.692118. Batch_acc: 0.415235. Batch_loss: 1.603919 \n",
      "Batch: 1336. Acc: 0.397139. Loss: 1.692118. Batch_acc: 0.398854. Batch_loss: 1.692549 \n",
      "Batch: 1337. Acc: 0.397133. Loss: 1.692103. Batch_acc: 0.388793. Batch_loss: 1.672070 \n",
      "Batch: 1338. Acc: 0.397138. Loss: 1.692077. Batch_acc: 0.403529. Batch_loss: 1.657225 \n",
      "Batch: 1339. Acc: 0.397142. Loss: 1.692061. Batch_acc: 0.403217. Batch_loss: 1.670353 \n",
      "Batch: 1340. Acc: 0.397167. Loss: 1.691992. Batch_acc: 0.430946. Batch_loss: 1.599696 \n",
      "Batch: 1341. Acc: 0.397171. Loss: 1.691973. Batch_acc: 0.402370. Batch_loss: 1.667474 \n",
      "Batch: 1342. Acc: 0.397186. Loss: 1.691955. Batch_acc: 0.416290. Batch_loss: 1.668500 \n",
      "Batch: 1343. Acc: 0.397191. Loss: 1.691931. Batch_acc: 0.404407. Batch_loss: 1.657664 \n",
      "Batch: 1344. Acc: 0.397188. Loss: 1.691926. Batch_acc: 0.392694. Batch_loss: 1.685552 \n",
      "Batch: 1345. Acc: 0.397179. Loss: 1.691937. Batch_acc: 0.385465. Batch_loss: 1.707274 \n",
      "Batch: 1346. Acc: 0.397184. Loss: 1.691918. Batch_acc: 0.404481. Batch_loss: 1.666221 \n",
      "Batch: 1347. Acc: 0.397191. Loss: 1.691907. Batch_acc: 0.406429. Batch_loss: 1.677048 \n",
      "Batch: 1348. Acc: 0.397197. Loss: 1.691900. Batch_acc: 0.405202. Batch_loss: 1.682174 \n",
      "Batch: 1349. Acc: 0.397201. Loss: 1.691896. Batch_acc: 0.402730. Batch_loss: 1.686182 \n",
      "Batch: 1350. Acc: 0.397214. Loss: 1.691867. Batch_acc: 0.414261. Batch_loss: 1.653601 \n",
      "Batch: 1351. Acc: 0.397216. Loss: 1.691871. Batch_acc: 0.399075. Batch_loss: 1.696994 \n",
      "Batch: 1352. Acc: 0.397237. Loss: 1.691816. Batch_acc: 0.426538. Batch_loss: 1.618805 \n",
      "Batch: 1353. Acc: 0.397244. Loss: 1.691807. Batch_acc: 0.406177. Batch_loss: 1.678892 \n",
      "Batch: 1354. Acc: 0.397233. Loss: 1.691811. Batch_acc: 0.382880. Batch_loss: 1.697271 \n",
      "Batch: 1355. Acc: 0.397234. Loss: 1.691805. Batch_acc: 0.398397. Batch_loss: 1.684190 \n",
      "Batch: 1356. Acc: 0.397252. Loss: 1.691756. Batch_acc: 0.421546. Batch_loss: 1.623973 \n",
      "Batch: 1357. Acc: 0.397277. Loss: 1.691688. Batch_acc: 0.430095. Batch_loss: 1.601746 \n",
      "Batch: 1358. Acc: 0.397305. Loss: 1.691626. Batch_acc: 0.435180. Batch_loss: 1.607219 \n",
      "Batch: 1359. Acc: 0.397308. Loss: 1.691632. Batch_acc: 0.402074. Batch_loss: 1.701069 \n",
      "Batch: 1360. Acc: 0.397323. Loss: 1.691613. Batch_acc: 0.418465. Batch_loss: 1.664076 \n",
      "Batch: 1361. Acc: 0.397332. Loss: 1.691581. Batch_acc: 0.409639. Batch_loss: 1.648402 \n",
      "Batch: 1362. Acc: 0.397331. Loss: 1.691575. Batch_acc: 0.395243. Batch_loss: 1.683763 \n",
      "Batch: 1363. Acc: 0.397343. Loss: 1.691530. Batch_acc: 0.413754. Batch_loss: 1.631452 \n",
      "Batch: 1364. Acc: 0.397361. Loss: 1.691490. Batch_acc: 0.421053. Batch_loss: 1.637380 \n",
      "Batch: 1365. Acc: 0.397374. Loss: 1.691454. Batch_acc: 0.415796. Batch_loss: 1.641531 \n",
      "Batch: 1366. Acc: 0.397382. Loss: 1.691416. Batch_acc: 0.408443. Batch_loss: 1.640353 \n",
      "Batch: 1367. Acc: 0.397393. Loss: 1.691397. Batch_acc: 0.412261. Batch_loss: 1.666081 \n",
      "Batch: 1368. Acc: 0.397396. Loss: 1.691389. Batch_acc: 0.400822. Batch_loss: 1.679436 \n",
      "Batch: 1369. Acc: 0.397402. Loss: 1.691390. Batch_acc: 0.405533. Batch_loss: 1.693333 \n",
      "Batch: 1370. Acc: 0.397404. Loss: 1.691368. Batch_acc: 0.400932. Batch_loss: 1.660807 \n",
      "Batch: 1371. Acc: 0.397425. Loss: 1.691330. Batch_acc: 0.425754. Batch_loss: 1.638371 \n",
      "Batch: 1372. Acc: 0.397435. Loss: 1.691305. Batch_acc: 0.412075. Batch_loss: 1.657335 \n",
      "Batch: 1373. Acc: 0.397439. Loss: 1.691266. Batch_acc: 0.402199. Batch_loss: 1.636822 \n",
      "Batch: 1374. Acc: 0.397442. Loss: 1.691266. Batch_acc: 0.401520. Batch_loss: 1.691692 \n",
      "Batch: 1375. Acc: 0.397458. Loss: 1.691224. Batch_acc: 0.419746. Batch_loss: 1.632415 \n",
      "Batch: 1376. Acc: 0.397458. Loss: 1.691223. Batch_acc: 0.397465. Batch_loss: 1.690877 \n",
      "Batch: 1377. Acc: 0.397451. Loss: 1.691228. Batch_acc: 0.387529. Batch_loss: 1.697512 \n",
      "Batch: 1378. Acc: 0.397447. Loss: 1.691229. Batch_acc: 0.392412. Batch_loss: 1.693497 \n",
      "Batch: 1379. Acc: 0.397455. Loss: 1.691194. Batch_acc: 0.409091. Batch_loss: 1.642823 \n",
      "Batch: 1380. Acc: 0.397463. Loss: 1.691187. Batch_acc: 0.408483. Batch_loss: 1.680889 \n",
      "Batch: 1381. Acc: 0.397471. Loss: 1.691170. Batch_acc: 0.407701. Batch_loss: 1.668842 \n",
      "Batch: 1382. Acc: 0.397494. Loss: 1.691113. Batch_acc: 0.428097. Batch_loss: 1.614922 \n",
      "Batch: 1383. Acc: 0.397513. Loss: 1.691058. Batch_acc: 0.424051. Batch_loss: 1.615504 \n",
      "Batch: 1384. Acc: 0.397516. Loss: 1.691072. Batch_acc: 0.401472. Batch_loss: 1.710286 \n",
      "Batch: 1385. Acc: 0.397509. Loss: 1.691079. Batch_acc: 0.387464. Batch_loss: 1.700495 \n",
      "Batch: 1386. Acc: 0.397513. Loss: 1.691057. Batch_acc: 0.403670. Batch_loss: 1.660422 \n",
      "Batch: 1387. Acc: 0.397518. Loss: 1.691037. Batch_acc: 0.404858. Batch_loss: 1.662787 \n",
      "Batch: 1388. Acc: 0.397541. Loss: 1.691006. Batch_acc: 0.428407. Batch_loss: 1.648326 \n",
      "Batch: 1389. Acc: 0.397545. Loss: 1.690995. Batch_acc: 0.404077. Batch_loss: 1.674795 \n",
      "Batch: 1390. Acc: 0.397565. Loss: 1.690951. Batch_acc: 0.424814. Batch_loss: 1.630347 \n",
      "Batch: 1391. Acc: 0.397577. Loss: 1.690938. Batch_acc: 0.415184. Batch_loss: 1.672103 \n",
      "Batch: 1392. Acc: 0.397599. Loss: 1.690877. Batch_acc: 0.426947. Batch_loss: 1.607148 \n",
      "Batch: 1393. Acc: 0.397605. Loss: 1.690833. Batch_acc: 0.406002. Batch_loss: 1.630602 \n",
      "Batch: 1394. Acc: 0.397626. Loss: 1.690794. Batch_acc: 0.428740. Batch_loss: 1.635511 \n",
      "Batch: 1395. Acc: 0.397628. Loss: 1.690784. Batch_acc: 0.400000. Batch_loss: 1.675830 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1396. Acc: 0.397641. Loss: 1.690756. Batch_acc: 0.415570. Batch_loss: 1.651994 \n",
      "Batch: 1397. Acc: 0.397660. Loss: 1.690703. Batch_acc: 0.424175. Batch_loss: 1.619411 \n",
      "Batch: 1398. Acc: 0.397664. Loss: 1.690672. Batch_acc: 0.401950. Batch_loss: 1.646979 \n",
      "Batch: 1399. Acc: 0.397682. Loss: 1.690613. Batch_acc: 0.422925. Batch_loss: 1.609652 \n",
      "Batch: 1400. Acc: 0.397690. Loss: 1.690589. Batch_acc: 0.409779. Batch_loss: 1.656196 \n",
      "Batch: 1401. Acc: 0.397693. Loss: 1.690566. Batch_acc: 0.400922. Batch_loss: 1.659235 \n",
      "Batch: 1402. Acc: 0.397706. Loss: 1.690513. Batch_acc: 0.416716. Batch_loss: 1.612954 \n",
      "Batch: 1403. Acc: 0.397723. Loss: 1.690479. Batch_acc: 0.421707. Batch_loss: 1.644267 \n",
      "Batch: 1404. Acc: 0.397733. Loss: 1.690460. Batch_acc: 0.410623. Batch_loss: 1.663835 \n",
      "Batch: 1405. Acc: 0.397745. Loss: 1.690434. Batch_acc: 0.415245. Batch_loss: 1.653766 \n",
      "Batch: 1406. Acc: 0.397749. Loss: 1.690410. Batch_acc: 0.402425. Batch_loss: 1.656677 \n",
      "Batch: 1407. Acc: 0.397745. Loss: 1.690433. Batch_acc: 0.393087. Batch_loss: 1.724426 \n",
      "Batch: 1408. Acc: 0.397746. Loss: 1.690410. Batch_acc: 0.398360. Batch_loss: 1.656535 \n",
      "Batch: 1409. Acc: 0.397748. Loss: 1.690382. Batch_acc: 0.401187. Batch_loss: 1.649554 \n",
      "Batch: 1410. Acc: 0.397745. Loss: 1.690362. Batch_acc: 0.393322. Batch_loss: 1.662899 \n",
      "Batch: 1411. Acc: 0.397739. Loss: 1.690366. Batch_acc: 0.389052. Batch_loss: 1.696200 \n",
      "Batch: 1412. Acc: 0.397748. Loss: 1.690354. Batch_acc: 0.411092. Batch_loss: 1.673222 \n",
      "Batch: 1413. Acc: 0.397756. Loss: 1.690333. Batch_acc: 0.408554. Batch_loss: 1.662383 \n",
      "Batch: 1414. Acc: 0.397762. Loss: 1.690308. Batch_acc: 0.406197. Batch_loss: 1.654879 \n",
      "Batch: 1415. Acc: 0.397771. Loss: 1.690289. Batch_acc: 0.409426. Batch_loss: 1.664237 \n",
      "Batch: 1416. Acc: 0.397782. Loss: 1.690248. Batch_acc: 0.414089. Batch_loss: 1.631714 \n",
      "Batch: 1417. Acc: 0.397790. Loss: 1.690215. Batch_acc: 0.409040. Batch_loss: 1.645161 \n",
      "Batch: 1418. Acc: 0.397777. Loss: 1.690252. Batch_acc: 0.378922. Batch_loss: 1.744140 \n",
      "Batch: 1419. Acc: 0.397782. Loss: 1.690226. Batch_acc: 0.403947. Batch_loss: 1.653285 \n",
      "Batch: 1420. Acc: 0.397782. Loss: 1.690247. Batch_acc: 0.398053. Batch_loss: 1.719950 \n",
      "Batch: 1421. Acc: 0.397791. Loss: 1.690231. Batch_acc: 0.411060. Batch_loss: 1.667720 \n",
      "Batch: 1422. Acc: 0.397803. Loss: 1.690178. Batch_acc: 0.413754. Batch_loss: 1.616371 \n",
      "Batch: 1423. Acc: 0.397822. Loss: 1.690136. Batch_acc: 0.424971. Batch_loss: 1.630001 \n",
      "Batch: 1424. Acc: 0.397830. Loss: 1.690127. Batch_acc: 0.408960. Batch_loss: 1.677594 \n",
      "Batch: 1425. Acc: 0.397839. Loss: 1.690107. Batch_acc: 0.410418. Batch_loss: 1.662123 \n",
      "Batch: 1426. Acc: 0.397843. Loss: 1.690098. Batch_acc: 0.403352. Batch_loss: 1.677291 \n",
      "Batch: 1427. Acc: 0.397858. Loss: 1.690055. Batch_acc: 0.420566. Batch_loss: 1.627801 \n",
      "Batch: 1428. Acc: 0.397862. Loss: 1.690045. Batch_acc: 0.402312. Batch_loss: 1.676294 \n",
      "Batch: 1429. Acc: 0.397852. Loss: 1.690092. Batch_acc: 0.384121. Batch_loss: 1.758103 \n",
      "Batch: 1430. Acc: 0.397870. Loss: 1.690047. Batch_acc: 0.422947. Batch_loss: 1.626460 \n",
      "Batch: 1431. Acc: 0.397879. Loss: 1.690006. Batch_acc: 0.410539. Batch_loss: 1.632329 \n",
      "Batch: 1432. Acc: 0.397876. Loss: 1.689998. Batch_acc: 0.394198. Batch_loss: 1.677764 \n",
      "Batch: 1433. Acc: 0.397876. Loss: 1.689996. Batch_acc: 0.397487. Batch_loss: 1.688033 \n",
      "Batch: 1434. Acc: 0.397889. Loss: 1.689983. Batch_acc: 0.416329. Batch_loss: 1.670574 \n",
      "Batch: 1435. Acc: 0.397910. Loss: 1.689944. Batch_acc: 0.428167. Batch_loss: 1.634765 \n",
      "Batch: 1436. Acc: 0.397906. Loss: 1.689934. Batch_acc: 0.391480. Batch_loss: 1.675339 \n",
      "Batch: 1437. Acc: 0.397919. Loss: 1.689896. Batch_acc: 0.416620. Batch_loss: 1.637518 \n",
      "Batch: 1438. Acc: 0.397925. Loss: 1.689871. Batch_acc: 0.406094. Batch_loss: 1.655111 \n",
      "Batch: 1439. Acc: 0.397941. Loss: 1.689823. Batch_acc: 0.420993. Batch_loss: 1.621386 \n",
      "Batch: 1440. Acc: 0.397938. Loss: 1.689816. Batch_acc: 0.392818. Batch_loss: 1.680457 \n",
      "Batch: 1441. Acc: 0.397949. Loss: 1.689745. Batch_acc: 0.414045. Batch_loss: 1.589484 \n",
      "Batch: 1442. Acc: 0.397950. Loss: 1.689747. Batch_acc: 0.398970. Batch_loss: 1.692851 \n",
      "Batch: 1443. Acc: 0.397977. Loss: 1.689688. Batch_acc: 0.436795. Batch_loss: 1.606792 \n",
      "Batch: 1444. Acc: 0.397975. Loss: 1.689696. Batch_acc: 0.394752. Batch_loss: 1.701118 \n",
      "Batch: 1445. Acc: 0.397991. Loss: 1.689661. Batch_acc: 0.420670. Batch_loss: 1.639748 \n",
      "Batch: 1446. Acc: 0.397981. Loss: 1.689691. Batch_acc: 0.383429. Batch_loss: 1.732886 \n",
      "Batch: 1447. Acc: 0.397976. Loss: 1.689707. Batch_acc: 0.390909. Batch_loss: 1.713786 \n",
      "Batch: 1448. Acc: 0.397979. Loss: 1.689727. Batch_acc: 0.402384. Batch_loss: 1.717035 \n",
      "Batch: 1449. Acc: 0.397992. Loss: 1.689669. Batch_acc: 0.416715. Batch_loss: 1.606053 \n",
      "Batch: 1450. Acc: 0.397999. Loss: 1.689640. Batch_acc: 0.407872. Batch_loss: 1.648109 \n",
      "Batch: 1451. Acc: 0.398011. Loss: 1.689630. Batch_acc: 0.415718. Batch_loss: 1.675235 \n",
      "Batch: 1452. Acc: 0.398012. Loss: 1.689619. Batch_acc: 0.398526. Batch_loss: 1.674271 \n",
      "Batch: 1453. Acc: 0.398030. Loss: 1.689574. Batch_acc: 0.425408. Batch_loss: 1.623069 \n",
      "Batch: 1454. Acc: 0.398033. Loss: 1.689579. Batch_acc: 0.401966. Batch_loss: 1.696671 \n",
      "Batch: 1455. Acc: 0.398057. Loss: 1.689525. Batch_acc: 0.432371. Batch_loss: 1.611833 \n",
      "Batch: 1456. Acc: 0.398064. Loss: 1.689503. Batch_acc: 0.408960. Batch_loss: 1.658213 \n",
      "Batch: 1457. Acc: 0.398064. Loss: 1.689478. Batch_acc: 0.397887. Batch_loss: 1.651790 \n",
      "Batch: 1458. Acc: 0.398078. Loss: 1.689456. Batch_acc: 0.418066. Batch_loss: 1.657014 \n",
      "Batch: 1459. Acc: 0.398101. Loss: 1.689431. Batch_acc: 0.432905. Batch_loss: 1.652237 \n",
      "Batch: 1460. Acc: 0.398103. Loss: 1.689452. Batch_acc: 0.400567. Batch_loss: 1.721022 \n",
      "Batch: 1461. Acc: 0.398096. Loss: 1.689455. Batch_acc: 0.387041. Batch_loss: 1.692781 \n",
      "Batch: 1462. Acc: 0.398101. Loss: 1.689443. Batch_acc: 0.405839. Batch_loss: 1.672072 \n",
      "Batch: 1463. Acc: 0.398104. Loss: 1.689466. Batch_acc: 0.402404. Batch_loss: 1.722606 \n",
      "Batch: 1464. Acc: 0.398115. Loss: 1.689431. Batch_acc: 0.414997. Batch_loss: 1.638867 \n",
      "Batch: 1465. Acc: 0.398112. Loss: 1.689458. Batch_acc: 0.393710. Batch_loss: 1.729452 \n",
      "Batch: 1466. Acc: 0.398117. Loss: 1.689440. Batch_acc: 0.405056. Batch_loss: 1.663266 \n",
      "Batch: 1467. Acc: 0.398132. Loss: 1.689405. Batch_acc: 0.419795. Batch_loss: 1.638636 \n",
      "Batch: 1468. Acc: 0.398150. Loss: 1.689363. Batch_acc: 0.423634. Batch_loss: 1.629643 \n",
      "Batch: 1469. Acc: 0.398145. Loss: 1.689361. Batch_acc: 0.389870. Batch_loss: 1.686667 \n",
      "Batch: 1470. Acc: 0.398148. Loss: 1.689361. Batch_acc: 0.403846. Batch_loss: 1.689935 \n",
      "Batch: 1471. Acc: 0.398160. Loss: 1.689315. Batch_acc: 0.414997. Batch_loss: 1.621175 \n",
      "Batch: 1472. Acc: 0.398164. Loss: 1.689308. Batch_acc: 0.404267. Batch_loss: 1.680338 \n",
      "Batch: 1473. Acc: 0.398157. Loss: 1.689318. Batch_acc: 0.388477. Batch_loss: 1.703767 \n",
      "Batch: 1474. Acc: 0.398177. Loss: 1.689276. Batch_acc: 0.426286. Batch_loss: 1.627797 \n",
      "Batch: 1475. Acc: 0.398179. Loss: 1.689260. Batch_acc: 0.401551. Batch_loss: 1.664515 \n",
      "Batch: 1476. Acc: 0.398182. Loss: 1.689262. Batch_acc: 0.403356. Batch_loss: 1.692602 \n",
      "Batch: 1477. Acc: 0.398188. Loss: 1.689232. Batch_acc: 0.406481. Batch_loss: 1.645085 \n",
      "Batch: 1478. Acc: 0.398192. Loss: 1.689229. Batch_acc: 0.404930. Batch_loss: 1.684067 \n",
      "Batch: 1479. Acc: 0.398196. Loss: 1.689222. Batch_acc: 0.402620. Batch_loss: 1.680043 \n",
      "Batch: 1480. Acc: 0.398204. Loss: 1.689185. Batch_acc: 0.410375. Batch_loss: 1.634063 \n",
      "Batch: 1481. Acc: 0.398213. Loss: 1.689137. Batch_acc: 0.411327. Batch_loss: 1.617926 \n",
      "Batch: 1482. Acc: 0.398223. Loss: 1.689129. Batch_acc: 0.413233. Batch_loss: 1.677118 \n",
      "Batch: 1483. Acc: 0.398230. Loss: 1.689103. Batch_acc: 0.408483. Batch_loss: 1.650984 \n",
      "Batch: 1484. Acc: 0.398219. Loss: 1.689097. Batch_acc: 0.381755. Batch_loss: 1.679893 \n",
      "Batch: 1485. Acc: 0.398230. Loss: 1.689076. Batch_acc: 0.415420. Batch_loss: 1.657526 \n",
      "Batch: 1486. Acc: 0.398246. Loss: 1.689025. Batch_acc: 0.421141. Batch_loss: 1.614929 \n",
      "Batch: 1487. Acc: 0.398240. Loss: 1.689035. Batch_acc: 0.389082. Batch_loss: 1.704215 \n",
      "Batch: 1488. Acc: 0.398232. Loss: 1.689046. Batch_acc: 0.386721. Batch_loss: 1.705300 \n",
      "Batch: 1489. Acc: 0.398246. Loss: 1.689026. Batch_acc: 0.418512. Batch_loss: 1.660827 \n",
      "Batch: 1490. Acc: 0.398250. Loss: 1.689031. Batch_acc: 0.404776. Batch_loss: 1.695513 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1491. Acc: 0.398257. Loss: 1.689004. Batch_acc: 0.408780. Batch_loss: 1.649717 \n",
      "Batch: 1492. Acc: 0.398257. Loss: 1.688988. Batch_acc: 0.398010. Batch_loss: 1.665635 \n",
      "Batch: 1493. Acc: 0.398260. Loss: 1.688958. Batch_acc: 0.402874. Batch_loss: 1.644556 \n",
      "Batch: 1494. Acc: 0.398276. Loss: 1.688923. Batch_acc: 0.421558. Batch_loss: 1.636990 \n",
      "Batch: 1495. Acc: 0.398282. Loss: 1.688890. Batch_acc: 0.407364. Batch_loss: 1.639807 \n",
      "Batch: 1496. Acc: 0.398308. Loss: 1.688834. Batch_acc: 0.436854. Batch_loss: 1.605365 \n",
      "Batch: 1497. Acc: 0.398315. Loss: 1.688850. Batch_acc: 0.408962. Batch_loss: 1.712454 \n",
      "Batch: 1498. Acc: 0.398322. Loss: 1.688843. Batch_acc: 0.407679. Batch_loss: 1.678105 \n",
      "Batch: 1499. Acc: 0.398326. Loss: 1.688851. Batch_acc: 0.404243. Batch_loss: 1.700765 \n",
      "Batch: 1500. Acc: 0.398335. Loss: 1.688818. Batch_acc: 0.411798. Batch_loss: 1.639565 \n",
      "Batch: 1501. Acc: 0.398342. Loss: 1.688806. Batch_acc: 0.409198. Batch_loss: 1.669831 \n",
      "Batch: 1502. Acc: 0.398345. Loss: 1.688788. Batch_acc: 0.403756. Batch_loss: 1.661980 \n",
      "Batch: 1503. Acc: 0.398350. Loss: 1.688768. Batch_acc: 0.405906. Batch_loss: 1.657791 \n",
      "Batch: 1504. Acc: 0.398351. Loss: 1.688755. Batch_acc: 0.400000. Batch_loss: 1.668998 \n",
      "Batch: 1505. Acc: 0.398349. Loss: 1.688748. Batch_acc: 0.394259. Batch_loss: 1.677721 \n",
      "Batch: 1506. Acc: 0.398360. Loss: 1.688733. Batch_acc: 0.415456. Batch_loss: 1.666162 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.3983598407645014. Loss per char: 1.6887329030996077. Time: 1627211501.3048248\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 22, 20, 17, 21, 17, 15, 17, 23, 22, 20, 25,  1, 66,\n",
      "        79, 69,  1, 14, 17, 15, 21, 25, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.398362. Loss: 1.688732. Batch_acc: 0.401744. Batch_loss: 1.687452 \n",
      "Batch: 1508. Acc: 0.398372. Loss: 1.688713. Batch_acc: 0.413271. Batch_loss: 1.660047 \n",
      "Batch: 1509. Acc: 0.398383. Loss: 1.688708. Batch_acc: 0.414827. Batch_loss: 1.681054 \n",
      "Batch: 1510. Acc: 0.398382. Loss: 1.688721. Batch_acc: 0.396670. Batch_loss: 1.707540 \n",
      "Batch: 1511. Acc: 0.398398. Loss: 1.688684. Batch_acc: 0.422639. Batch_loss: 1.633263 \n",
      "Batch: 1512. Acc: 0.398400. Loss: 1.688671. Batch_acc: 0.401853. Batch_loss: 1.670090 \n",
      "Batch: 1513. Acc: 0.398396. Loss: 1.688669. Batch_acc: 0.392523. Batch_loss: 1.684830 \n",
      "Batch: 1514. Acc: 0.398406. Loss: 1.688649. Batch_acc: 0.412918. Batch_loss: 1.659227 \n",
      "Batch: 1515. Acc: 0.398411. Loss: 1.688631. Batch_acc: 0.406094. Batch_loss: 1.662452 \n",
      "Batch: 1516. Acc: 0.398432. Loss: 1.688570. Batch_acc: 0.429545. Batch_loss: 1.596446 \n",
      "Batch: 1517. Acc: 0.398446. Loss: 1.688551. Batch_acc: 0.419774. Batch_loss: 1.660742 \n",
      "Batch: 1518. Acc: 0.398462. Loss: 1.688515. Batch_acc: 0.421233. Batch_loss: 1.633276 \n",
      "Batch: 1519. Acc: 0.398476. Loss: 1.688473. Batch_acc: 0.420105. Batch_loss: 1.625182 \n",
      "Batch: 1520. Acc: 0.398486. Loss: 1.688458. Batch_acc: 0.414286. Batch_loss: 1.664959 \n",
      "Batch: 1521. Acc: 0.398505. Loss: 1.688401. Batch_acc: 0.427227. Batch_loss: 1.604491 \n",
      "Batch: 1522. Acc: 0.398520. Loss: 1.688364. Batch_acc: 0.420441. Batch_loss: 1.631965 \n",
      "Batch: 1523. Acc: 0.398529. Loss: 1.688329. Batch_acc: 0.411895. Batch_loss: 1.636015 \n",
      "Batch: 1524. Acc: 0.398530. Loss: 1.688329. Batch_acc: 0.399884. Batch_loss: 1.689043 \n",
      "Batch: 1525. Acc: 0.398547. Loss: 1.688272. Batch_acc: 0.424913. Batch_loss: 1.600167 \n",
      "Batch: 1526. Acc: 0.398563. Loss: 1.688253. Batch_acc: 0.422360. Batch_loss: 1.660189 \n",
      "Batch: 1527. Acc: 0.398573. Loss: 1.688247. Batch_acc: 0.414462. Batch_loss: 1.677742 \n",
      "Batch: 1528. Acc: 0.398572. Loss: 1.688231. Batch_acc: 0.396862. Batch_loss: 1.663697 \n",
      "Batch: 1529. Acc: 0.398567. Loss: 1.688222. Batch_acc: 0.391710. Batch_loss: 1.675423 \n",
      "Batch: 1530. Acc: 0.398574. Loss: 1.688221. Batch_acc: 0.409091. Batch_loss: 1.686716 \n",
      "Batch: 1531. Acc: 0.398578. Loss: 1.688212. Batch_acc: 0.404243. Batch_loss: 1.673867 \n",
      "Batch: 1532. Acc: 0.398592. Loss: 1.688199. Batch_acc: 0.421237. Batch_loss: 1.667536 \n",
      "Batch: 1533. Acc: 0.398610. Loss: 1.688154. Batch_acc: 0.425411. Batch_loss: 1.620625 \n",
      "Batch: 1534. Acc: 0.398605. Loss: 1.688151. Batch_acc: 0.390341. Batch_loss: 1.682755 \n",
      "Batch: 1535. Acc: 0.398624. Loss: 1.688088. Batch_acc: 0.428329. Batch_loss: 1.594298 \n",
      "Batch: 1536. Acc: 0.398639. Loss: 1.688062. Batch_acc: 0.420838. Batch_loss: 1.647198 \n",
      "Batch: 1537. Acc: 0.398646. Loss: 1.688063. Batch_acc: 0.409297. Batch_loss: 1.689192 \n",
      "Batch: 1538. Acc: 0.398655. Loss: 1.688041. Batch_acc: 0.413153. Batch_loss: 1.655712 \n",
      "Batch: 1539. Acc: 0.398662. Loss: 1.688028. Batch_acc: 0.409624. Batch_loss: 1.666470 \n",
      "Batch: 1540. Acc: 0.398669. Loss: 1.687995. Batch_acc: 0.408907. Batch_loss: 1.636943 \n",
      "Batch: 1541. Acc: 0.398682. Loss: 1.687956. Batch_acc: 0.418644. Batch_loss: 1.629147 \n",
      "Batch: 1542. Acc: 0.398684. Loss: 1.687952. Batch_acc: 0.402292. Batch_loss: 1.681912 \n",
      "Batch: 1543. Acc: 0.398700. Loss: 1.687919. Batch_acc: 0.421646. Batch_loss: 1.638002 \n",
      "Batch: 1544. Acc: 0.398704. Loss: 1.687896. Batch_acc: 0.406414. Batch_loss: 1.652847 \n",
      "Batch: 1545. Acc: 0.398714. Loss: 1.687872. Batch_acc: 0.413434. Batch_loss: 1.649269 \n",
      "Batch: 1546. Acc: 0.398709. Loss: 1.687858. Batch_acc: 0.391029. Batch_loss: 1.666303 \n",
      "Batch: 1547. Acc: 0.398720. Loss: 1.687813. Batch_acc: 0.416142. Batch_loss: 1.618802 \n",
      "Batch: 1548. Acc: 0.398734. Loss: 1.687799. Batch_acc: 0.419781. Batch_loss: 1.666013 \n",
      "Batch: 1549. Acc: 0.398732. Loss: 1.687812. Batch_acc: 0.396194. Batch_loss: 1.709069 \n",
      "Batch: 1550. Acc: 0.398747. Loss: 1.687774. Batch_acc: 0.420694. Batch_loss: 1.628486 \n",
      "Batch: 1551. Acc: 0.398750. Loss: 1.687773. Batch_acc: 0.403966. Batch_loss: 1.685980 \n",
      "Batch: 1552. Acc: 0.398757. Loss: 1.687734. Batch_acc: 0.409687. Batch_loss: 1.627987 \n",
      "Batch: 1553. Acc: 0.398768. Loss: 1.687708. Batch_acc: 0.416865. Batch_loss: 1.646802 \n",
      "Batch: 1554. Acc: 0.398783. Loss: 1.687684. Batch_acc: 0.421507. Batch_loss: 1.650514 \n",
      "Batch: 1555. Acc: 0.398789. Loss: 1.687672. Batch_acc: 0.408023. Batch_loss: 1.668264 \n",
      "Batch: 1556. Acc: 0.398801. Loss: 1.687642. Batch_acc: 0.416573. Batch_loss: 1.643358 \n",
      "Batch: 1557. Acc: 0.398812. Loss: 1.687610. Batch_acc: 0.416764. Batch_loss: 1.635788 \n",
      "Batch: 1558. Acc: 0.398806. Loss: 1.687611. Batch_acc: 0.389723. Batch_loss: 1.689767 \n",
      "Batch: 1559. Acc: 0.398811. Loss: 1.687600. Batch_acc: 0.406398. Batch_loss: 1.670606 \n",
      "Batch: 1560. Acc: 0.398806. Loss: 1.687621. Batch_acc: 0.391279. Batch_loss: 1.720177 \n",
      "Batch: 1561. Acc: 0.398810. Loss: 1.687592. Batch_acc: 0.404580. Batch_loss: 1.641819 \n",
      "Batch: 1562. Acc: 0.398817. Loss: 1.687570. Batch_acc: 0.409983. Batch_loss: 1.654299 \n",
      "Batch: 1563. Acc: 0.398825. Loss: 1.687546. Batch_acc: 0.411150. Batch_loss: 1.649733 \n",
      "Batch: 1564. Acc: 0.398809. Loss: 1.687562. Batch_acc: 0.373248. Batch_loss: 1.712150 \n",
      "Batch: 1565. Acc: 0.398818. Loss: 1.687561. Batch_acc: 0.413310. Batch_loss: 1.685662 \n",
      "Batch: 1566. Acc: 0.398834. Loss: 1.687509. Batch_acc: 0.422990. Batch_loss: 1.607941 \n",
      "Batch: 1567. Acc: 0.398840. Loss: 1.687480. Batch_acc: 0.408726. Batch_loss: 1.641439 \n",
      "Batch: 1568. Acc: 0.398840. Loss: 1.687481. Batch_acc: 0.399420. Batch_loss: 1.688892 \n",
      "Batch: 1569. Acc: 0.398842. Loss: 1.687464. Batch_acc: 0.401616. Batch_loss: 1.662031 \n",
      "Batch: 1570. Acc: 0.398851. Loss: 1.687454. Batch_acc: 0.412266. Batch_loss: 1.672010 \n",
      "Batch: 1571. Acc: 0.398864. Loss: 1.687434. Batch_acc: 0.420290. Batch_loss: 1.655517 \n",
      "Batch: 1572. Acc: 0.398871. Loss: 1.687418. Batch_acc: 0.409013. Batch_loss: 1.661530 \n",
      "Batch: 1573. Acc: 0.398869. Loss: 1.687401. Batch_acc: 0.395586. Batch_loss: 1.662195 \n",
      "Batch: 1574. Acc: 0.398859. Loss: 1.687421. Batch_acc: 0.383903. Batch_loss: 1.717803 \n",
      "Batch: 1575. Acc: 0.398859. Loss: 1.687418. Batch_acc: 0.398993. Batch_loss: 1.683632 \n",
      "Batch: 1576. Acc: 0.398861. Loss: 1.687422. Batch_acc: 0.401493. Batch_loss: 1.693856 \n",
      "Batch: 1577. Acc: 0.398867. Loss: 1.687413. Batch_acc: 0.407887. Batch_loss: 1.672060 \n",
      "Batch: 1578. Acc: 0.398860. Loss: 1.687429. Batch_acc: 0.389235. Batch_loss: 1.713131 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1579. Acc: 0.398859. Loss: 1.687439. Batch_acc: 0.396680. Batch_loss: 1.702330 \n",
      "Batch: 1580. Acc: 0.398878. Loss: 1.687401. Batch_acc: 0.428654. Batch_loss: 1.628203 \n",
      "Batch: 1581. Acc: 0.398878. Loss: 1.687389. Batch_acc: 0.399315. Batch_loss: 1.668017 \n",
      "Batch: 1582. Acc: 0.398890. Loss: 1.687363. Batch_acc: 0.418140. Batch_loss: 1.647354 \n",
      "Batch: 1583. Acc: 0.398887. Loss: 1.687373. Batch_acc: 0.393939. Batch_loss: 1.702454 \n",
      "Batch: 1584. Acc: 0.398894. Loss: 1.687344. Batch_acc: 0.409275. Batch_loss: 1.640855 \n",
      "Batch: 1585. Acc: 0.398899. Loss: 1.687336. Batch_acc: 0.406846. Batch_loss: 1.674334 \n",
      "Batch: 1586. Acc: 0.398899. Loss: 1.687352. Batch_acc: 0.399651. Batch_loss: 1.713902 \n",
      "Batch: 1587. Acc: 0.398914. Loss: 1.687319. Batch_acc: 0.423739. Batch_loss: 1.633119 \n",
      "Batch: 1588. Acc: 0.398925. Loss: 1.687299. Batch_acc: 0.415737. Batch_loss: 1.654675 \n",
      "Batch: 1589. Acc: 0.398928. Loss: 1.687289. Batch_acc: 0.404353. Batch_loss: 1.671957 \n",
      "Batch: 1590. Acc: 0.398926. Loss: 1.687282. Batch_acc: 0.395069. Batch_loss: 1.675380 \n",
      "Batch: 1591. Acc: 0.398926. Loss: 1.687281. Batch_acc: 0.399419. Batch_loss: 1.686542 \n",
      "Batch: 1592. Acc: 0.398942. Loss: 1.687254. Batch_acc: 0.424610. Batch_loss: 1.643200 \n",
      "Batch: 1593. Acc: 0.398962. Loss: 1.687204. Batch_acc: 0.430126. Batch_loss: 1.608326 \n",
      "Batch: 1594. Acc: 0.398972. Loss: 1.687184. Batch_acc: 0.415249. Batch_loss: 1.654846 \n",
      "Batch: 1595. Acc: 0.398974. Loss: 1.687181. Batch_acc: 0.402404. Batch_loss: 1.681776 \n",
      "Batch: 1596. Acc: 0.398985. Loss: 1.687158. Batch_acc: 0.416858. Batch_loss: 1.650536 \n",
      "Batch: 1597. Acc: 0.398991. Loss: 1.687159. Batch_acc: 0.408019. Batch_loss: 1.689453 \n",
      "Batch: 1598. Acc: 0.398995. Loss: 1.687142. Batch_acc: 0.406504. Batch_loss: 1.658920 \n",
      "Batch: 1599. Acc: 0.399005. Loss: 1.687136. Batch_acc: 0.414634. Batch_loss: 1.677744 \n",
      "Batch: 1600. Acc: 0.399016. Loss: 1.687090. Batch_acc: 0.416329. Batch_loss: 1.612910 \n",
      "Batch: 1601. Acc: 0.399031. Loss: 1.687062. Batch_acc: 0.422792. Batch_loss: 1.642099 \n",
      "Batch: 1602. Acc: 0.399034. Loss: 1.687035. Batch_acc: 0.403769. Batch_loss: 1.645372 \n",
      "Batch: 1603. Acc: 0.399046. Loss: 1.687003. Batch_acc: 0.418315. Batch_loss: 1.635619 \n",
      "Batch: 1604. Acc: 0.399052. Loss: 1.686971. Batch_acc: 0.408175. Batch_loss: 1.635554 \n",
      "Batch: 1605. Acc: 0.399060. Loss: 1.686932. Batch_acc: 0.411899. Batch_loss: 1.625199 \n",
      "Batch: 1606. Acc: 0.399065. Loss: 1.686903. Batch_acc: 0.407407. Batch_loss: 1.639234 \n",
      "Batch: 1607. Acc: 0.399071. Loss: 1.686877. Batch_acc: 0.409679. Batch_loss: 1.646880 \n",
      "Batch: 1608. Acc: 0.399088. Loss: 1.686840. Batch_acc: 0.424986. Batch_loss: 1.626310 \n",
      "Batch: 1609. Acc: 0.399094. Loss: 1.686844. Batch_acc: 0.408671. Batch_loss: 1.693808 \n",
      "Batch: 1610. Acc: 0.399095. Loss: 1.686864. Batch_acc: 0.401635. Batch_loss: 1.719877 \n",
      "Batch: 1611. Acc: 0.399090. Loss: 1.686855. Batch_acc: 0.391718. Batch_loss: 1.673003 \n",
      "Batch: 1612. Acc: 0.399106. Loss: 1.686848. Batch_acc: 0.424539. Batch_loss: 1.675032 \n",
      "Batch: 1613. Acc: 0.399106. Loss: 1.686834. Batch_acc: 0.399212. Batch_loss: 1.665222 \n",
      "Batch: 1614. Acc: 0.399115. Loss: 1.686802. Batch_acc: 0.412807. Batch_loss: 1.635664 \n",
      "Batch: 1615. Acc: 0.399126. Loss: 1.686757. Batch_acc: 0.416858. Batch_loss: 1.614038 \n",
      "Batch: 1616. Acc: 0.399137. Loss: 1.686728. Batch_acc: 0.416905. Batch_loss: 1.639692 \n",
      "Batch: 1617. Acc: 0.399133. Loss: 1.686767. Batch_acc: 0.392479. Batch_loss: 1.751871 \n",
      "Batch: 1618. Acc: 0.399127. Loss: 1.686773. Batch_acc: 0.389180. Batch_loss: 1.695659 \n",
      "Batch: 1619. Acc: 0.399122. Loss: 1.686781. Batch_acc: 0.390920. Batch_loss: 1.700864 \n",
      "Batch: 1620. Acc: 0.399129. Loss: 1.686755. Batch_acc: 0.410035. Batch_loss: 1.645142 \n",
      "Batch: 1621. Acc: 0.399138. Loss: 1.686738. Batch_acc: 0.415358. Batch_loss: 1.658458 \n",
      "Batch: 1622. Acc: 0.399146. Loss: 1.686705. Batch_acc: 0.410684. Batch_loss: 1.633184 \n",
      "Batch: 1623. Acc: 0.399150. Loss: 1.686678. Batch_acc: 0.405634. Batch_loss: 1.644027 \n",
      "Batch: 1624. Acc: 0.399174. Loss: 1.686628. Batch_acc: 0.439977. Batch_loss: 1.604030 \n",
      "Batch: 1625. Acc: 0.399194. Loss: 1.686590. Batch_acc: 0.430699. Batch_loss: 1.625599 \n",
      "Batch: 1626. Acc: 0.399218. Loss: 1.686511. Batch_acc: 0.437856. Batch_loss: 1.557947 \n",
      "Batch: 1627. Acc: 0.399228. Loss: 1.686480. Batch_acc: 0.416054. Batch_loss: 1.637777 \n",
      "Batch: 1628. Acc: 0.399246. Loss: 1.686413. Batch_acc: 0.428994. Batch_loss: 1.573613 \n",
      "Batch: 1629. Acc: 0.399247. Loss: 1.686418. Batch_acc: 0.400580. Batch_loss: 1.695619 \n",
      "Batch: 1630. Acc: 0.399258. Loss: 1.686402. Batch_acc: 0.418129. Batch_loss: 1.659281 \n",
      "Batch: 1631. Acc: 0.399262. Loss: 1.686403. Batch_acc: 0.404268. Batch_loss: 1.688008 \n",
      "Batch: 1632. Acc: 0.399265. Loss: 1.686391. Batch_acc: 0.404381. Batch_loss: 1.665693 \n",
      "Batch: 1633. Acc: 0.399275. Loss: 1.686353. Batch_acc: 0.416146. Batch_loss: 1.626205 \n",
      "Batch: 1634. Acc: 0.399272. Loss: 1.686345. Batch_acc: 0.394614. Batch_loss: 1.673214 \n",
      "Batch: 1635. Acc: 0.399286. Loss: 1.686301. Batch_acc: 0.422311. Batch_loss: 1.614447 \n",
      "Batch: 1636. Acc: 0.399307. Loss: 1.686240. Batch_acc: 0.433486. Batch_loss: 1.586520 \n",
      "Batch: 1637. Acc: 0.399316. Loss: 1.686224. Batch_acc: 0.413233. Batch_loss: 1.659363 \n",
      "Batch: 1638. Acc: 0.399324. Loss: 1.686189. Batch_acc: 0.412680. Batch_loss: 1.628955 \n",
      "Batch: 1639. Acc: 0.399334. Loss: 1.686152. Batch_acc: 0.415939. Batch_loss: 1.625112 \n",
      "Batch: 1640. Acc: 0.399345. Loss: 1.686111. Batch_acc: 0.416906. Batch_loss: 1.618775 \n",
      "Batch: 1641. Acc: 0.399365. Loss: 1.686061. Batch_acc: 0.432309. Batch_loss: 1.604421 \n",
      "Batch: 1642. Acc: 0.399378. Loss: 1.686017. Batch_acc: 0.420697. Batch_loss: 1.615932 \n",
      "Batch: 1643. Acc: 0.399389. Loss: 1.686006. Batch_acc: 0.416955. Batch_loss: 1.668819 \n",
      "Batch: 1644. Acc: 0.399402. Loss: 1.685976. Batch_acc: 0.421113. Batch_loss: 1.636142 \n",
      "Batch: 1645. Acc: 0.399407. Loss: 1.685954. Batch_acc: 0.407279. Batch_loss: 1.650116 \n",
      "Batch: 1646. Acc: 0.399415. Loss: 1.685936. Batch_acc: 0.412301. Batch_loss: 1.656826 \n",
      "Batch: 1647. Acc: 0.399416. Loss: 1.685923. Batch_acc: 0.401989. Batch_loss: 1.663435 \n",
      "Batch: 1648. Acc: 0.399408. Loss: 1.685916. Batch_acc: 0.385203. Batch_loss: 1.673470 \n",
      "Batch: 1649. Acc: 0.399420. Loss: 1.685894. Batch_acc: 0.420070. Batch_loss: 1.649390 \n",
      "Batch: 1650. Acc: 0.399420. Loss: 1.685894. Batch_acc: 0.398271. Batch_loss: 1.685682 \n",
      "Batch: 1651. Acc: 0.399434. Loss: 1.685869. Batch_acc: 0.423977. Batch_loss: 1.644425 \n",
      "Batch: 1652. Acc: 0.399431. Loss: 1.685868. Batch_acc: 0.394094. Batch_loss: 1.684191 \n",
      "Batch: 1653. Acc: 0.399444. Loss: 1.685825. Batch_acc: 0.421884. Batch_loss: 1.613992 \n",
      "Batch: 1654. Acc: 0.399452. Loss: 1.685794. Batch_acc: 0.411661. Batch_loss: 1.632638 \n",
      "Batch: 1655. Acc: 0.399449. Loss: 1.685808. Batch_acc: 0.394585. Batch_loss: 1.709747 \n",
      "Batch: 1656. Acc: 0.399457. Loss: 1.685762. Batch_acc: 0.412781. Batch_loss: 1.608342 \n",
      "Batch: 1657. Acc: 0.399466. Loss: 1.685733. Batch_acc: 0.414676. Batch_loss: 1.639856 \n",
      "Batch: 1658. Acc: 0.399475. Loss: 1.685710. Batch_acc: 0.413934. Batch_loss: 1.645976 \n",
      "Batch: 1659. Acc: 0.399482. Loss: 1.685698. Batch_acc: 0.412311. Batch_loss: 1.666247 \n",
      "Batch: 1660. Acc: 0.399503. Loss: 1.685656. Batch_acc: 0.433633. Batch_loss: 1.617506 \n",
      "Batch: 1661. Acc: 0.399504. Loss: 1.685644. Batch_acc: 0.401579. Batch_loss: 1.664788 \n",
      "Batch: 1662. Acc: 0.399506. Loss: 1.685621. Batch_acc: 0.402080. Batch_loss: 1.648869 \n",
      "Batch: 1663. Acc: 0.399518. Loss: 1.685594. Batch_acc: 0.419633. Batch_loss: 1.639189 \n",
      "Batch: 1664. Acc: 0.399525. Loss: 1.685584. Batch_acc: 0.410826. Batch_loss: 1.669243 \n",
      "Batch: 1665. Acc: 0.399523. Loss: 1.685599. Batch_acc: 0.395322. Batch_loss: 1.712195 \n",
      "Batch: 1666. Acc: 0.399534. Loss: 1.685579. Batch_acc: 0.417465. Batch_loss: 1.652311 \n",
      "Batch: 1667. Acc: 0.399544. Loss: 1.685561. Batch_acc: 0.416999. Batch_loss: 1.655637 \n",
      "Batch: 1668. Acc: 0.399547. Loss: 1.685562. Batch_acc: 0.404268. Batch_loss: 1.687949 \n",
      "Batch: 1669. Acc: 0.399559. Loss: 1.685535. Batch_acc: 0.421021. Batch_loss: 1.639471 \n",
      "Batch: 1670. Acc: 0.399565. Loss: 1.685529. Batch_acc: 0.408884. Batch_loss: 1.673987 \n",
      "Batch: 1671. Acc: 0.399562. Loss: 1.685542. Batch_acc: 0.393992. Batch_loss: 1.707344 \n",
      "Batch: 1672. Acc: 0.399566. Loss: 1.685529. Batch_acc: 0.405879. Batch_loss: 1.665642 \n",
      "Batch: 1673. Acc: 0.399572. Loss: 1.685521. Batch_acc: 0.409611. Batch_loss: 1.671256 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1674. Acc: 0.399573. Loss: 1.685532. Batch_acc: 0.401515. Batch_loss: 1.704756 \n",
      "Batch: 1675. Acc: 0.399576. Loss: 1.685528. Batch_acc: 0.405099. Batch_loss: 1.679016 \n",
      "Batch: 1676. Acc: 0.399578. Loss: 1.685523. Batch_acc: 0.403064. Batch_loss: 1.677072 \n",
      "Batch: 1677. Acc: 0.399587. Loss: 1.685505. Batch_acc: 0.413969. Batch_loss: 1.655687 \n",
      "Batch: 1678. Acc: 0.399591. Loss: 1.685491. Batch_acc: 0.407168. Batch_loss: 1.661285 \n",
      "Batch: 1679. Acc: 0.399599. Loss: 1.685456. Batch_acc: 0.413069. Batch_loss: 1.626273 \n",
      "Batch: 1680. Acc: 0.399615. Loss: 1.685430. Batch_acc: 0.425937. Batch_loss: 1.640395 \n",
      "Batch: 1681. Acc: 0.399622. Loss: 1.685420. Batch_acc: 0.412286. Batch_loss: 1.669454 \n",
      "Batch: 1682. Acc: 0.399632. Loss: 1.685394. Batch_acc: 0.415686. Batch_loss: 1.642009 \n",
      "Batch: 1683. Acc: 0.399648. Loss: 1.685363. Batch_acc: 0.426258. Batch_loss: 1.633313 \n",
      "Batch: 1684. Acc: 0.399682. Loss: 1.685281. Batch_acc: 0.455407. Batch_loss: 1.551240 \n",
      "Batch: 1685. Acc: 0.399695. Loss: 1.685236. Batch_acc: 0.422854. Batch_loss: 1.609416 \n",
      "Batch: 1686. Acc: 0.399710. Loss: 1.685188. Batch_acc: 0.424036. Batch_loss: 1.604796 \n",
      "Batch: 1687. Acc: 0.399715. Loss: 1.685171. Batch_acc: 0.407925. Batch_loss: 1.656443 \n",
      "Batch: 1688. Acc: 0.399731. Loss: 1.685132. Batch_acc: 0.426941. Batch_loss: 1.619338 \n",
      "Batch: 1689. Acc: 0.399737. Loss: 1.685113. Batch_acc: 0.410149. Batch_loss: 1.652363 \n",
      "Batch: 1690. Acc: 0.399752. Loss: 1.685062. Batch_acc: 0.425197. Batch_loss: 1.599916 \n",
      "Batch: 1691. Acc: 0.399759. Loss: 1.685053. Batch_acc: 0.411799. Batch_loss: 1.669568 \n",
      "Batch: 1692. Acc: 0.399769. Loss: 1.685031. Batch_acc: 0.416571. Batch_loss: 1.648249 \n",
      "Batch: 1693. Acc: 0.399776. Loss: 1.685012. Batch_acc: 0.410928. Batch_loss: 1.652763 \n",
      "Batch: 1694. Acc: 0.399775. Loss: 1.685010. Batch_acc: 0.398041. Batch_loss: 1.682201 \n",
      "Batch: 1695. Acc: 0.399781. Loss: 1.684992. Batch_acc: 0.409807. Batch_loss: 1.653722 \n",
      "Batch: 1696. Acc: 0.399783. Loss: 1.684979. Batch_acc: 0.403955. Batch_loss: 1.664333 \n",
      "Batch: 1697. Acc: 0.399788. Loss: 1.684980. Batch_acc: 0.407783. Batch_loss: 1.685924 \n",
      "Batch: 1698. Acc: 0.399799. Loss: 1.684965. Batch_acc: 0.416995. Batch_loss: 1.659667 \n",
      "Batch: 1699. Acc: 0.399813. Loss: 1.684925. Batch_acc: 0.424539. Batch_loss: 1.617774 \n",
      "Batch: 1700. Acc: 0.399816. Loss: 1.684928. Batch_acc: 0.405565. Batch_loss: 1.689237 \n",
      "Batch: 1701. Acc: 0.399810. Loss: 1.684933. Batch_acc: 0.388468. Batch_loss: 1.694102 \n",
      "Batch: 1702. Acc: 0.399823. Loss: 1.684875. Batch_acc: 0.422034. Batch_loss: 1.588684 \n",
      "Batch: 1703. Acc: 0.399827. Loss: 1.684875. Batch_acc: 0.406977. Batch_loss: 1.683428 \n",
      "Batch: 1704. Acc: 0.399822. Loss: 1.684877. Batch_acc: 0.391075. Batch_loss: 1.688761 \n",
      "Batch: 1705. Acc: 0.399835. Loss: 1.684827. Batch_acc: 0.421264. Batch_loss: 1.600347 \n",
      "Batch: 1706. Acc: 0.399831. Loss: 1.684828. Batch_acc: 0.393489. Batch_loss: 1.686427 \n",
      "Batch: 1707. Acc: 0.399828. Loss: 1.684804. Batch_acc: 0.395230. Batch_loss: 1.643604 \n",
      "Batch: 1708. Acc: 0.399836. Loss: 1.684792. Batch_acc: 0.413056. Batch_loss: 1.664034 \n",
      "Batch: 1709. Acc: 0.399847. Loss: 1.684755. Batch_acc: 0.417995. Batch_loss: 1.623208 \n",
      "Batch: 1710. Acc: 0.399857. Loss: 1.684750. Batch_acc: 0.417381. Batch_loss: 1.675839 \n",
      "Batch: 1711. Acc: 0.399858. Loss: 1.684747. Batch_acc: 0.402037. Batch_loss: 1.678724 \n",
      "Batch: 1712. Acc: 0.399867. Loss: 1.684735. Batch_acc: 0.414440. Batch_loss: 1.664422 \n",
      "Batch: 1713. Acc: 0.399874. Loss: 1.684701. Batch_acc: 0.412707. Batch_loss: 1.626928 \n",
      "Batch: 1714. Acc: 0.399868. Loss: 1.684675. Batch_acc: 0.389174. Batch_loss: 1.641198 \n",
      "Batch: 1715. Acc: 0.399867. Loss: 1.684674. Batch_acc: 0.397924. Batch_loss: 1.683123 \n",
      "Batch: 1716. Acc: 0.399875. Loss: 1.684646. Batch_acc: 0.413265. Batch_loss: 1.636591 \n",
      "Batch: 1717. Acc: 0.399896. Loss: 1.684585. Batch_acc: 0.436531. Batch_loss: 1.580566 \n",
      "Batch: 1718. Acc: 0.399905. Loss: 1.684565. Batch_acc: 0.415323. Batch_loss: 1.649401 \n",
      "Batch: 1719. Acc: 0.399914. Loss: 1.684521. Batch_acc: 0.414857. Batch_loss: 1.610718 \n",
      "Batch: 1720. Acc: 0.399924. Loss: 1.684484. Batch_acc: 0.417091. Batch_loss: 1.621126 \n",
      "Batch: 1721. Acc: 0.399938. Loss: 1.684438. Batch_acc: 0.424610. Batch_loss: 1.605355 \n",
      "Batch: 1722. Acc: 0.399953. Loss: 1.684395. Batch_acc: 0.425446. Batch_loss: 1.610746 \n",
      "Batch: 1723. Acc: 0.399960. Loss: 1.684391. Batch_acc: 0.411492. Batch_loss: 1.676078 \n",
      "Batch: 1724. Acc: 0.399971. Loss: 1.684342. Batch_acc: 0.419318. Batch_loss: 1.600879 \n",
      "Batch: 1725. Acc: 0.399990. Loss: 1.684302. Batch_acc: 0.432247. Batch_loss: 1.615042 \n",
      "Batch: 1726. Acc: 0.400000. Loss: 1.684261. Batch_acc: 0.417910. Batch_loss: 1.614201 \n",
      "Batch: 1727. Acc: 0.399998. Loss: 1.684267. Batch_acc: 0.396216. Batch_loss: 1.694568 \n",
      "Batch: 1728. Acc: 0.399990. Loss: 1.684263. Batch_acc: 0.385935. Batch_loss: 1.677478 \n",
      "Batch: 1729. Acc: 0.400004. Loss: 1.684212. Batch_acc: 0.425421. Batch_loss: 1.593886 \n",
      "Batch: 1730. Acc: 0.400006. Loss: 1.684187. Batch_acc: 0.403235. Batch_loss: 1.642396 \n",
      "Batch: 1731. Acc: 0.400020. Loss: 1.684151. Batch_acc: 0.423455. Batch_loss: 1.619924 \n",
      "Batch: 1732. Acc: 0.400030. Loss: 1.684135. Batch_acc: 0.418754. Batch_loss: 1.657041 \n",
      "Batch: 1733. Acc: 0.400034. Loss: 1.684125. Batch_acc: 0.406322. Batch_loss: 1.666457 \n",
      "Batch: 1734. Acc: 0.400047. Loss: 1.684092. Batch_acc: 0.422429. Batch_loss: 1.625736 \n",
      "Batch: 1735. Acc: 0.400052. Loss: 1.684083. Batch_acc: 0.408660. Batch_loss: 1.668385 \n",
      "Batch: 1736. Acc: 0.400066. Loss: 1.684034. Batch_acc: 0.424697. Batch_loss: 1.599995 \n",
      "Batch: 1737. Acc: 0.400059. Loss: 1.684035. Batch_acc: 0.387755. Batch_loss: 1.684996 \n",
      "Batch: 1738. Acc: 0.400067. Loss: 1.684021. Batch_acc: 0.414535. Batch_loss: 1.658854 \n",
      "Batch: 1739. Acc: 0.400077. Loss: 1.683987. Batch_acc: 0.417226. Batch_loss: 1.626907 \n",
      "Batch: 1740. Acc: 0.400082. Loss: 1.683953. Batch_acc: 0.408353. Batch_loss: 1.623856 \n",
      "Batch: 1741. Acc: 0.400088. Loss: 1.683937. Batch_acc: 0.409734. Batch_loss: 1.656900 \n",
      "Batch: 1742. Acc: 0.400100. Loss: 1.683891. Batch_acc: 0.421849. Batch_loss: 1.605979 \n",
      "Batch: 1743. Acc: 0.400114. Loss: 1.683833. Batch_acc: 0.423208. Batch_loss: 1.584834 \n",
      "Batch: 1744. Acc: 0.400115. Loss: 1.683832. Batch_acc: 0.402199. Batch_loss: 1.681750 \n",
      "Batch: 1745. Acc: 0.400133. Loss: 1.683796. Batch_acc: 0.431716. Batch_loss: 1.621966 \n",
      "Batch: 1746. Acc: 0.400146. Loss: 1.683744. Batch_acc: 0.421569. Batch_loss: 1.592439 \n",
      "Batch: 1747. Acc: 0.400142. Loss: 1.683747. Batch_acc: 0.393605. Batch_loss: 1.688803 \n",
      "Batch: 1748. Acc: 0.400157. Loss: 1.683703. Batch_acc: 0.426156. Batch_loss: 1.609458 \n",
      "Batch: 1749. Acc: 0.400177. Loss: 1.683655. Batch_acc: 0.434321. Batch_loss: 1.600608 \n",
      "Batch: 1750. Acc: 0.400190. Loss: 1.683642. Batch_acc: 0.421822. Batch_loss: 1.662079 \n",
      "Batch: 1751. Acc: 0.400184. Loss: 1.683648. Batch_acc: 0.390359. Batch_loss: 1.693963 \n",
      "Batch: 1752. Acc: 0.400191. Loss: 1.683643. Batch_acc: 0.411467. Batch_loss: 1.675504 \n",
      "Batch: 1753. Acc: 0.400184. Loss: 1.683638. Batch_acc: 0.387377. Batch_loss: 1.675284 \n",
      "Batch: 1754. Acc: 0.400200. Loss: 1.683609. Batch_acc: 0.428074. Batch_loss: 1.632627 \n",
      "Batch: 1755. Acc: 0.400201. Loss: 1.683605. Batch_acc: 0.402292. Batch_loss: 1.675179 \n",
      "Batch: 1756. Acc: 0.400203. Loss: 1.683602. Batch_acc: 0.404817. Batch_loss: 1.678603 \n",
      "Batch: 1757. Acc: 0.400214. Loss: 1.683592. Batch_acc: 0.418631. Batch_loss: 1.666088 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.4002140532154622. Loss per char: 1.6835917970763652. Time: 1627211705.7537663\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 14, 19, 25, 23,\n",
      "        17, 18, 23, 15, 21, 22, 24, 20, 20,  1, 66, 79, 69,  1, 14, 23, 15, 22,\n",
      "        20, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.400216. Loss: 1.683577. Batch_acc: 0.403087. Batch_loss: 1.657350 \n",
      "Batch: 1759. Acc: 0.400229. Loss: 1.683538. Batch_acc: 0.424000. Batch_loss: 1.615829 \n",
      "Batch: 1760. Acc: 0.400239. Loss: 1.683499. Batch_acc: 0.416159. Batch_loss: 1.617321 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1761. Acc: 0.400237. Loss: 1.683490. Batch_acc: 0.397347. Batch_loss: 1.667771 \n",
      "Batch: 1762. Acc: 0.400252. Loss: 1.683457. Batch_acc: 0.425411. Batch_loss: 1.626466 \n",
      "Batch: 1763. Acc: 0.400268. Loss: 1.683426. Batch_acc: 0.428492. Batch_loss: 1.630440 \n",
      "Batch: 1764. Acc: 0.400271. Loss: 1.683413. Batch_acc: 0.405468. Batch_loss: 1.660554 \n",
      "Batch: 1765. Acc: 0.400274. Loss: 1.683415. Batch_acc: 0.404997. Batch_loss: 1.687029 \n",
      "Batch: 1766. Acc: 0.400285. Loss: 1.683401. Batch_acc: 0.419852. Batch_loss: 1.658779 \n",
      "Batch: 1767. Acc: 0.400295. Loss: 1.683372. Batch_acc: 0.417758. Batch_loss: 1.632036 \n",
      "Batch: 1768. Acc: 0.400308. Loss: 1.683359. Batch_acc: 0.424779. Batch_loss: 1.659532 \n",
      "Batch: 1769. Acc: 0.400326. Loss: 1.683326. Batch_acc: 0.431986. Batch_loss: 1.625779 \n",
      "Batch: 1770. Acc: 0.400340. Loss: 1.683289. Batch_acc: 0.423950. Batch_loss: 1.618532 \n",
      "Batch: 1771. Acc: 0.400340. Loss: 1.683288. Batch_acc: 0.400697. Batch_loss: 1.681383 \n",
      "Batch: 1772. Acc: 0.400350. Loss: 1.683237. Batch_acc: 0.417750. Batch_loss: 1.594835 \n",
      "Batch: 1773. Acc: 0.400370. Loss: 1.683205. Batch_acc: 0.435867. Batch_loss: 1.624341 \n",
      "Batch: 1774. Acc: 0.400374. Loss: 1.683196. Batch_acc: 0.407932. Batch_loss: 1.668320 \n",
      "Batch: 1775. Acc: 0.400385. Loss: 1.683171. Batch_acc: 0.419524. Batch_loss: 1.637860 \n",
      "Batch: 1776. Acc: 0.400405. Loss: 1.683130. Batch_acc: 0.436188. Batch_loss: 1.612199 \n",
      "Batch: 1777. Acc: 0.400400. Loss: 1.683094. Batch_acc: 0.392224. Batch_loss: 1.618211 \n",
      "Batch: 1778. Acc: 0.400412. Loss: 1.683075. Batch_acc: 0.420415. Batch_loss: 1.649060 \n",
      "Batch: 1779. Acc: 0.400423. Loss: 1.683045. Batch_acc: 0.419648. Batch_loss: 1.631896 \n",
      "Batch: 1780. Acc: 0.400425. Loss: 1.683035. Batch_acc: 0.404000. Batch_loss: 1.663882 \n",
      "Batch: 1781. Acc: 0.400425. Loss: 1.683024. Batch_acc: 0.400340. Batch_loss: 1.664733 \n",
      "Batch: 1782. Acc: 0.400438. Loss: 1.682979. Batch_acc: 0.425178. Batch_loss: 1.599550 \n",
      "Batch: 1783. Acc: 0.400447. Loss: 1.682933. Batch_acc: 0.415954. Batch_loss: 1.602525 \n",
      "Batch: 1784. Acc: 0.400456. Loss: 1.682886. Batch_acc: 0.416111. Batch_loss: 1.602188 \n",
      "Batch: 1785. Acc: 0.400453. Loss: 1.682878. Batch_acc: 0.395467. Batch_loss: 1.667876 \n",
      "Batch: 1786. Acc: 0.400457. Loss: 1.682860. Batch_acc: 0.406685. Batch_loss: 1.651882 \n",
      "Batch: 1787. Acc: 0.400458. Loss: 1.682855. Batch_acc: 0.403328. Batch_loss: 1.673607 \n",
      "Batch: 1788. Acc: 0.400461. Loss: 1.682838. Batch_acc: 0.404846. Batch_loss: 1.652229 \n",
      "Batch: 1789. Acc: 0.400466. Loss: 1.682807. Batch_acc: 0.410704. Batch_loss: 1.629114 \n",
      "Batch: 1790. Acc: 0.400465. Loss: 1.682801. Batch_acc: 0.398276. Batch_loss: 1.670610 \n",
      "Batch: 1791. Acc: 0.400481. Loss: 1.682768. Batch_acc: 0.429070. Batch_loss: 1.623582 \n",
      "Batch: 1792. Acc: 0.400489. Loss: 1.682745. Batch_acc: 0.414621. Batch_loss: 1.643577 \n",
      "Batch: 1793. Acc: 0.400499. Loss: 1.682729. Batch_acc: 0.417595. Batch_loss: 1.653282 \n",
      "Batch: 1794. Acc: 0.400510. Loss: 1.682694. Batch_acc: 0.420935. Batch_loss: 1.621670 \n",
      "Batch: 1795. Acc: 0.400511. Loss: 1.682679. Batch_acc: 0.400922. Batch_loss: 1.655521 \n",
      "Batch: 1796. Acc: 0.400516. Loss: 1.682661. Batch_acc: 0.410928. Batch_loss: 1.651422 \n",
      "Batch: 1797. Acc: 0.400518. Loss: 1.682654. Batch_acc: 0.404040. Batch_loss: 1.670321 \n",
      "Batch: 1798. Acc: 0.400530. Loss: 1.682628. Batch_acc: 0.420666. Batch_loss: 1.636244 \n",
      "Batch: 1799. Acc: 0.400526. Loss: 1.682629. Batch_acc: 0.393886. Batch_loss: 1.683528 \n",
      "Batch: 1800. Acc: 0.400541. Loss: 1.682588. Batch_acc: 0.427915. Batch_loss: 1.609302 \n",
      "Batch: 1801. Acc: 0.400559. Loss: 1.682545. Batch_acc: 0.432247. Batch_loss: 1.606766 \n",
      "Batch: 1802. Acc: 0.400570. Loss: 1.682534. Batch_acc: 0.419931. Batch_loss: 1.661212 \n",
      "Batch: 1803. Acc: 0.400577. Loss: 1.682522. Batch_acc: 0.413146. Batch_loss: 1.661001 \n",
      "Batch: 1804. Acc: 0.400595. Loss: 1.682468. Batch_acc: 0.433409. Batch_loss: 1.587829 \n",
      "Batch: 1805. Acc: 0.400607. Loss: 1.682434. Batch_acc: 0.421938. Batch_loss: 1.620116 \n",
      "Batch: 1806. Acc: 0.400611. Loss: 1.682421. Batch_acc: 0.407386. Batch_loss: 1.657716 \n",
      "Batch: 1807. Acc: 0.400614. Loss: 1.682384. Batch_acc: 0.406285. Batch_loss: 1.618405 \n",
      "Batch: 1808. Acc: 0.400618. Loss: 1.682360. Batch_acc: 0.408392. Batch_loss: 1.637499 \n",
      "Batch: 1809. Acc: 0.400627. Loss: 1.682332. Batch_acc: 0.416766. Batch_loss: 1.629635 \n",
      "Batch: 1810. Acc: 0.400637. Loss: 1.682302. Batch_acc: 0.418671. Batch_loss: 1.628366 \n",
      "Batch: 1811. Acc: 0.400653. Loss: 1.682252. Batch_acc: 0.431044. Batch_loss: 1.590976 \n",
      "Batch: 1812. Acc: 0.400653. Loss: 1.682244. Batch_acc: 0.400580. Batch_loss: 1.668240 \n",
      "Batch: 1813. Acc: 0.400659. Loss: 1.682216. Batch_acc: 0.410154. Batch_loss: 1.630559 \n",
      "Batch: 1814. Acc: 0.400675. Loss: 1.682175. Batch_acc: 0.429790. Batch_loss: 1.609562 \n",
      "Batch: 1815. Acc: 0.400696. Loss: 1.682104. Batch_acc: 0.438063. Batch_loss: 1.555021 \n",
      "Batch: 1816. Acc: 0.400712. Loss: 1.682061. Batch_acc: 0.429476. Batch_loss: 1.604288 \n",
      "Batch: 1817. Acc: 0.400726. Loss: 1.682033. Batch_acc: 0.425703. Batch_loss: 1.631585 \n",
      "Batch: 1818. Acc: 0.400732. Loss: 1.682007. Batch_acc: 0.413395. Batch_loss: 1.634786 \n",
      "Batch: 1819. Acc: 0.400742. Loss: 1.681973. Batch_acc: 0.418213. Batch_loss: 1.619601 \n",
      "Batch: 1820. Acc: 0.400751. Loss: 1.681929. Batch_acc: 0.416762. Batch_loss: 1.602294 \n",
      "Batch: 1821. Acc: 0.400756. Loss: 1.681922. Batch_acc: 0.410959. Batch_loss: 1.668080 \n",
      "Batch: 1822. Acc: 0.400773. Loss: 1.681866. Batch_acc: 0.430265. Batch_loss: 1.581615 \n",
      "Batch: 1823. Acc: 0.400786. Loss: 1.681837. Batch_acc: 0.425656. Batch_loss: 1.628160 \n",
      "Batch: 1824. Acc: 0.400789. Loss: 1.681819. Batch_acc: 0.406600. Batch_loss: 1.649097 \n",
      "Batch: 1825. Acc: 0.400799. Loss: 1.681790. Batch_acc: 0.418192. Batch_loss: 1.629377 \n",
      "Batch: 1826. Acc: 0.400807. Loss: 1.681774. Batch_acc: 0.415986. Batch_loss: 1.651915 \n",
      "Batch: 1827. Acc: 0.400804. Loss: 1.681763. Batch_acc: 0.395033. Batch_loss: 1.661116 \n",
      "Batch: 1828. Acc: 0.400824. Loss: 1.681718. Batch_acc: 0.437716. Batch_loss: 1.599697 \n",
      "Batch: 1829. Acc: 0.400829. Loss: 1.681704. Batch_acc: 0.409038. Batch_loss: 1.654430 \n",
      "Batch: 1830. Acc: 0.400835. Loss: 1.681691. Batch_acc: 0.412944. Batch_loss: 1.659154 \n",
      "Batch: 1831. Acc: 0.400846. Loss: 1.681653. Batch_acc: 0.421083. Batch_loss: 1.612046 \n",
      "Batch: 1832. Acc: 0.400844. Loss: 1.681644. Batch_acc: 0.396338. Batch_loss: 1.665055 \n",
      "Batch: 1833. Acc: 0.400853. Loss: 1.681612. Batch_acc: 0.417633. Batch_loss: 1.622625 \n",
      "Batch: 1834. Acc: 0.400864. Loss: 1.681565. Batch_acc: 0.421454. Batch_loss: 1.593893 \n",
      "Batch: 1835. Acc: 0.400865. Loss: 1.681545. Batch_acc: 0.403123. Batch_loss: 1.644371 \n",
      "Batch: 1836. Acc: 0.400872. Loss: 1.681517. Batch_acc: 0.413280. Batch_loss: 1.629448 \n",
      "Batch: 1837. Acc: 0.400894. Loss: 1.681445. Batch_acc: 0.441431. Batch_loss: 1.549821 \n",
      "Batch: 1838. Acc: 0.400881. Loss: 1.681461. Batch_acc: 0.376471. Batch_loss: 1.711039 \n",
      "Batch: 1839. Acc: 0.400892. Loss: 1.681424. Batch_acc: 0.420784. Batch_loss: 1.614129 \n",
      "Batch: 1840. Acc: 0.400907. Loss: 1.681371. Batch_acc: 0.427511. Batch_loss: 1.584005 \n",
      "Batch: 1841. Acc: 0.400923. Loss: 1.681323. Batch_acc: 0.430365. Batch_loss: 1.594730 \n",
      "Batch: 1842. Acc: 0.400918. Loss: 1.681329. Batch_acc: 0.393001. Batch_loss: 1.691370 \n",
      "Batch: 1843. Acc: 0.400928. Loss: 1.681296. Batch_acc: 0.418420. Batch_loss: 1.622712 \n",
      "Batch: 1844. Acc: 0.400941. Loss: 1.681256. Batch_acc: 0.425029. Batch_loss: 1.607292 \n",
      "Batch: 1845. Acc: 0.400943. Loss: 1.681236. Batch_acc: 0.403737. Batch_loss: 1.643576 \n",
      "Batch: 1846. Acc: 0.400936. Loss: 1.681274. Batch_acc: 0.388502. Batch_loss: 1.753471 \n",
      "Batch: 1847. Acc: 0.400959. Loss: 1.681207. Batch_acc: 0.442614. Batch_loss: 1.558357 \n",
      "Batch: 1848. Acc: 0.400962. Loss: 1.681201. Batch_acc: 0.406448. Batch_loss: 1.669538 \n",
      "Batch: 1849. Acc: 0.400967. Loss: 1.681179. Batch_acc: 0.410911. Batch_loss: 1.640166 \n",
      "Batch: 1850. Acc: 0.400979. Loss: 1.681136. Batch_acc: 0.423362. Batch_loss: 1.603559 \n",
      "Batch: 1851. Acc: 0.400988. Loss: 1.681118. Batch_acc: 0.417910. Batch_loss: 1.647555 \n",
      "Batch: 1852. Acc: 0.401002. Loss: 1.681094. Batch_acc: 0.426370. Batch_loss: 1.637145 \n",
      "Batch: 1853. Acc: 0.401006. Loss: 1.681076. Batch_acc: 0.408152. Batch_loss: 1.647318 \n",
      "Batch: 1854. Acc: 0.401023. Loss: 1.681035. Batch_acc: 0.432819. Batch_loss: 1.604693 \n",
      "Batch: 1855. Acc: 0.401027. Loss: 1.681004. Batch_acc: 0.407857. Batch_loss: 1.623078 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1856. Acc: 0.401036. Loss: 1.680977. Batch_acc: 0.416908. Batch_loss: 1.631066 \n",
      "Batch: 1857. Acc: 0.401027. Loss: 1.680979. Batch_acc: 0.385151. Batch_loss: 1.685020 \n",
      "Batch: 1858. Acc: 0.401036. Loss: 1.680962. Batch_acc: 0.418645. Batch_loss: 1.649558 \n",
      "Batch: 1859. Acc: 0.401039. Loss: 1.680928. Batch_acc: 0.406322. Batch_loss: 1.617287 \n",
      "Batch: 1860. Acc: 0.401045. Loss: 1.680922. Batch_acc: 0.411007. Batch_loss: 1.669350 \n",
      "Batch: 1861. Acc: 0.401059. Loss: 1.680884. Batch_acc: 0.429332. Batch_loss: 1.608859 \n",
      "Batch: 1862. Acc: 0.401071. Loss: 1.680844. Batch_acc: 0.421998. Batch_loss: 1.607260 \n",
      "Batch: 1863. Acc: 0.401070. Loss: 1.680833. Batch_acc: 0.400114. Batch_loss: 1.660604 \n",
      "Batch: 1864. Acc: 0.401086. Loss: 1.680784. Batch_acc: 0.430661. Batch_loss: 1.588331 \n",
      "Batch: 1865. Acc: 0.401090. Loss: 1.680757. Batch_acc: 0.408175. Batch_loss: 1.629572 \n",
      "Batch: 1866. Acc: 0.401092. Loss: 1.680740. Batch_acc: 0.404707. Batch_loss: 1.650516 \n",
      "Batch: 1867. Acc: 0.401108. Loss: 1.680705. Batch_acc: 0.431103. Batch_loss: 1.614213 \n",
      "Batch: 1868. Acc: 0.401112. Loss: 1.680690. Batch_acc: 0.408646. Batch_loss: 1.653701 \n",
      "Batch: 1869. Acc: 0.401116. Loss: 1.680662. Batch_acc: 0.408128. Batch_loss: 1.627952 \n",
      "Batch: 1870. Acc: 0.401132. Loss: 1.680627. Batch_acc: 0.431134. Batch_loss: 1.614934 \n",
      "Batch: 1871. Acc: 0.401136. Loss: 1.680627. Batch_acc: 0.409010. Batch_loss: 1.680527 \n",
      "Batch: 1872. Acc: 0.401149. Loss: 1.680597. Batch_acc: 0.425799. Batch_loss: 1.625747 \n",
      "Batch: 1873. Acc: 0.401165. Loss: 1.680541. Batch_acc: 0.430161. Batch_loss: 1.579507 \n",
      "Batch: 1874. Acc: 0.401175. Loss: 1.680512. Batch_acc: 0.420382. Batch_loss: 1.624145 \n",
      "Batch: 1875. Acc: 0.401171. Loss: 1.680499. Batch_acc: 0.393852. Batch_loss: 1.656675 \n",
      "Batch: 1876. Acc: 0.401169. Loss: 1.680501. Batch_acc: 0.396887. Batch_loss: 1.684005 \n",
      "Batch: 1877. Acc: 0.401180. Loss: 1.680468. Batch_acc: 0.422350. Batch_loss: 1.618802 \n",
      "Batch: 1878. Acc: 0.401195. Loss: 1.680418. Batch_acc: 0.429064. Batch_loss: 1.587483 \n",
      "Batch: 1879. Acc: 0.401200. Loss: 1.680397. Batch_acc: 0.409710. Batch_loss: 1.638624 \n",
      "Batch: 1880. Acc: 0.401204. Loss: 1.680381. Batch_acc: 0.409143. Batch_loss: 1.650572 \n",
      "Batch: 1881. Acc: 0.401207. Loss: 1.680366. Batch_acc: 0.407095. Batch_loss: 1.653362 \n",
      "Batch: 1882. Acc: 0.401212. Loss: 1.680346. Batch_acc: 0.411156. Batch_loss: 1.642587 \n",
      "Batch: 1883. Acc: 0.401227. Loss: 1.680306. Batch_acc: 0.429476. Batch_loss: 1.604432 \n",
      "Batch: 1884. Acc: 0.401233. Loss: 1.680287. Batch_acc: 0.411458. Batch_loss: 1.644984 \n",
      "Batch: 1885. Acc: 0.401245. Loss: 1.680243. Batch_acc: 0.424344. Batch_loss: 1.598714 \n",
      "Batch: 1886. Acc: 0.401255. Loss: 1.680227. Batch_acc: 0.418565. Batch_loss: 1.650625 \n",
      "Batch: 1887. Acc: 0.401250. Loss: 1.680231. Batch_acc: 0.393296. Batch_loss: 1.687179 \n",
      "Batch: 1888. Acc: 0.401252. Loss: 1.680219. Batch_acc: 0.403813. Batch_loss: 1.658535 \n",
      "Batch: 1889. Acc: 0.401267. Loss: 1.680191. Batch_acc: 0.430040. Batch_loss: 1.628159 \n",
      "Batch: 1890. Acc: 0.401269. Loss: 1.680188. Batch_acc: 0.405839. Batch_loss: 1.673505 \n",
      "Batch: 1891. Acc: 0.401276. Loss: 1.680168. Batch_acc: 0.414481. Batch_loss: 1.643369 \n",
      "Batch: 1892. Acc: 0.401291. Loss: 1.680116. Batch_acc: 0.428247. Batch_loss: 1.582402 \n",
      "Batch: 1893. Acc: 0.401302. Loss: 1.680073. Batch_acc: 0.422171. Batch_loss: 1.598376 \n",
      "Batch: 1894. Acc: 0.401316. Loss: 1.680045. Batch_acc: 0.428163. Batch_loss: 1.628611 \n",
      "Batch: 1895. Acc: 0.401319. Loss: 1.680017. Batch_acc: 0.407085. Batch_loss: 1.626402 \n",
      "Batch: 1896. Acc: 0.401323. Loss: 1.679995. Batch_acc: 0.408681. Batch_loss: 1.639410 \n",
      "Batch: 1897. Acc: 0.401322. Loss: 1.679987. Batch_acc: 0.399884. Batch_loss: 1.663880 \n",
      "Batch: 1898. Acc: 0.401329. Loss: 1.679950. Batch_acc: 0.413948. Batch_loss: 1.610563 \n",
      "Batch: 1899. Acc: 0.401335. Loss: 1.679931. Batch_acc: 0.412587. Batch_loss: 1.643272 \n",
      "Batch: 1900. Acc: 0.401335. Loss: 1.679926. Batch_acc: 0.400701. Batch_loss: 1.670834 \n",
      "Batch: 1901. Acc: 0.401328. Loss: 1.679945. Batch_acc: 0.388000. Batch_loss: 1.716508 \n",
      "Batch: 1902. Acc: 0.401332. Loss: 1.679932. Batch_acc: 0.409798. Batch_loss: 1.655730 \n",
      "Batch: 1903. Acc: 0.401358. Loss: 1.679877. Batch_acc: 0.449014. Batch_loss: 1.576589 \n",
      "Batch: 1904. Acc: 0.401370. Loss: 1.679831. Batch_acc: 0.424539. Batch_loss: 1.592903 \n",
      "Batch: 1905. Acc: 0.401367. Loss: 1.679840. Batch_acc: 0.395455. Batch_loss: 1.696027 \n",
      "Batch: 1906. Acc: 0.401377. Loss: 1.679800. Batch_acc: 0.421412. Batch_loss: 1.603526 \n",
      "Batch: 1907. Acc: 0.401380. Loss: 1.679790. Batch_acc: 0.406106. Batch_loss: 1.662326 \n",
      "Batch: 1908. Acc: 0.401397. Loss: 1.679743. Batch_acc: 0.433798. Batch_loss: 1.588167 \n",
      "Batch: 1909. Acc: 0.401408. Loss: 1.679703. Batch_acc: 0.423274. Batch_loss: 1.604775 \n",
      "Batch: 1910. Acc: 0.401410. Loss: 1.679672. Batch_acc: 0.405327. Batch_loss: 1.618580 \n",
      "Batch: 1911. Acc: 0.401418. Loss: 1.679654. Batch_acc: 0.416716. Batch_loss: 1.645852 \n",
      "Batch: 1912. Acc: 0.401432. Loss: 1.679628. Batch_acc: 0.427107. Batch_loss: 1.629671 \n",
      "Batch: 1913. Acc: 0.401448. Loss: 1.679579. Batch_acc: 0.433467. Batch_loss: 1.587617 \n",
      "Batch: 1914. Acc: 0.401462. Loss: 1.679526. Batch_acc: 0.427838. Batch_loss: 1.577730 \n",
      "Batch: 1915. Acc: 0.401476. Loss: 1.679509. Batch_acc: 0.426313. Batch_loss: 1.648553 \n",
      "Batch: 1916. Acc: 0.401485. Loss: 1.679490. Batch_acc: 0.420105. Batch_loss: 1.642772 \n",
      "Batch: 1917. Acc: 0.401500. Loss: 1.679440. Batch_acc: 0.429944. Batch_loss: 1.584025 \n",
      "Batch: 1918. Acc: 0.401512. Loss: 1.679413. Batch_acc: 0.424539. Batch_loss: 1.628948 \n",
      "Batch: 1919. Acc: 0.401520. Loss: 1.679395. Batch_acc: 0.416860. Batch_loss: 1.643104 \n",
      "Batch: 1920. Acc: 0.401531. Loss: 1.679347. Batch_acc: 0.421857. Batch_loss: 1.588351 \n",
      "Batch: 1921. Acc: 0.401523. Loss: 1.679350. Batch_acc: 0.387372. Batch_loss: 1.685521 \n",
      "Batch: 1922. Acc: 0.401521. Loss: 1.679347. Batch_acc: 0.395893. Batch_loss: 1.674042 \n",
      "Batch: 1923. Acc: 0.401526. Loss: 1.679330. Batch_acc: 0.411258. Batch_loss: 1.646126 \n",
      "Batch: 1924. Acc: 0.401523. Loss: 1.679353. Batch_acc: 0.396181. Batch_loss: 1.725410 \n",
      "Batch: 1925. Acc: 0.401536. Loss: 1.679309. Batch_acc: 0.425978. Batch_loss: 1.596126 \n",
      "Batch: 1926. Acc: 0.401549. Loss: 1.679265. Batch_acc: 0.426454. Batch_loss: 1.595567 \n",
      "Batch: 1927. Acc: 0.401549. Loss: 1.679243. Batch_acc: 0.402809. Batch_loss: 1.637675 \n",
      "Batch: 1928. Acc: 0.401561. Loss: 1.679202. Batch_acc: 0.424004. Batch_loss: 1.601271 \n",
      "Batch: 1929. Acc: 0.401575. Loss: 1.679155. Batch_acc: 0.427464. Batch_loss: 1.592308 \n",
      "Batch: 1930. Acc: 0.401589. Loss: 1.679120. Batch_acc: 0.428486. Batch_loss: 1.609306 \n",
      "Batch: 1931. Acc: 0.401586. Loss: 1.679099. Batch_acc: 0.396718. Batch_loss: 1.640187 \n",
      "Batch: 1932. Acc: 0.401589. Loss: 1.679075. Batch_acc: 0.407155. Batch_loss: 1.632700 \n",
      "Batch: 1933. Acc: 0.401600. Loss: 1.679044. Batch_acc: 0.422551. Batch_loss: 1.619958 \n",
      "Batch: 1934. Acc: 0.401606. Loss: 1.679017. Batch_acc: 0.412918. Batch_loss: 1.627009 \n",
      "Batch: 1935. Acc: 0.401620. Loss: 1.678993. Batch_acc: 0.429313. Batch_loss: 1.632359 \n",
      "Batch: 1936. Acc: 0.401619. Loss: 1.678979. Batch_acc: 0.400000. Batch_loss: 1.651240 \n",
      "Batch: 1937. Acc: 0.401628. Loss: 1.678948. Batch_acc: 0.417796. Batch_loss: 1.616392 \n",
      "Batch: 1938. Acc: 0.401626. Loss: 1.678952. Batch_acc: 0.398601. Batch_loss: 1.686659 \n",
      "Batch: 1939. Acc: 0.401627. Loss: 1.678948. Batch_acc: 0.403037. Batch_loss: 1.671140 \n",
      "Batch: 1940. Acc: 0.401625. Loss: 1.678936. Batch_acc: 0.398415. Batch_loss: 1.656126 \n",
      "Batch: 1941. Acc: 0.401636. Loss: 1.678895. Batch_acc: 0.422582. Batch_loss: 1.602594 \n",
      "Batch: 1942. Acc: 0.401643. Loss: 1.678869. Batch_acc: 0.415666. Batch_loss: 1.627766 \n",
      "Batch: 1943. Acc: 0.401642. Loss: 1.678862. Batch_acc: 0.398719. Batch_loss: 1.666536 \n",
      "Batch: 1944. Acc: 0.401645. Loss: 1.678841. Batch_acc: 0.406655. Batch_loss: 1.638596 \n",
      "Batch: 1945. Acc: 0.401648. Loss: 1.678822. Batch_acc: 0.409170. Batch_loss: 1.641666 \n",
      "Batch: 1946. Acc: 0.401650. Loss: 1.678828. Batch_acc: 0.404317. Batch_loss: 1.689101 \n",
      "Batch: 1947. Acc: 0.401658. Loss: 1.678799. Batch_acc: 0.417944. Batch_loss: 1.624654 \n",
      "Batch: 1948. Acc: 0.401661. Loss: 1.678787. Batch_acc: 0.406322. Batch_loss: 1.654138 \n",
      "Batch: 1949. Acc: 0.401669. Loss: 1.678748. Batch_acc: 0.418182. Batch_loss: 1.604915 \n",
      "Batch: 1950. Acc: 0.401685. Loss: 1.678718. Batch_acc: 0.433048. Batch_loss: 1.619531 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1951. Acc: 0.401686. Loss: 1.678698. Batch_acc: 0.401901. Batch_loss: 1.641667 \n",
      "Batch: 1952. Acc: 0.401688. Loss: 1.678693. Batch_acc: 0.406523. Batch_loss: 1.667603 \n",
      "Batch: 1953. Acc: 0.401701. Loss: 1.678656. Batch_acc: 0.427912. Batch_loss: 1.607092 \n",
      "Batch: 1954. Acc: 0.401708. Loss: 1.678617. Batch_acc: 0.414031. Batch_loss: 1.603362 \n",
      "Batch: 1955. Acc: 0.401714. Loss: 1.678604. Batch_acc: 0.414605. Batch_loss: 1.650522 \n",
      "Batch: 1956. Acc: 0.401726. Loss: 1.678581. Batch_acc: 0.426042. Batch_loss: 1.634966 \n",
      "Batch: 1957. Acc: 0.401727. Loss: 1.678562. Batch_acc: 0.402279. Batch_loss: 1.641922 \n",
      "Batch: 1958. Acc: 0.401738. Loss: 1.678530. Batch_acc: 0.423571. Batch_loss: 1.613402 \n",
      "Batch: 1959. Acc: 0.401751. Loss: 1.678507. Batch_acc: 0.427095. Batch_loss: 1.633469 \n",
      "Batch: 1960. Acc: 0.401758. Loss: 1.678477. Batch_acc: 0.416714. Batch_loss: 1.620236 \n",
      "Batch: 1961. Acc: 0.401754. Loss: 1.678494. Batch_acc: 0.393764. Batch_loss: 1.712913 \n",
      "Batch: 1962. Acc: 0.401765. Loss: 1.678473. Batch_acc: 0.422235. Batch_loss: 1.635098 \n",
      "Batch: 1963. Acc: 0.401768. Loss: 1.678447. Batch_acc: 0.408151. Batch_loss: 1.627519 \n",
      "Batch: 1964. Acc: 0.401770. Loss: 1.678437. Batch_acc: 0.405251. Batch_loss: 1.657632 \n",
      "Batch: 1965. Acc: 0.401779. Loss: 1.678406. Batch_acc: 0.419795. Batch_loss: 1.618359 \n",
      "Batch: 1966. Acc: 0.401783. Loss: 1.678387. Batch_acc: 0.410693. Batch_loss: 1.640813 \n",
      "Batch: 1967. Acc: 0.401807. Loss: 1.678337. Batch_acc: 0.448576. Batch_loss: 1.578975 \n",
      "Batch: 1968. Acc: 0.401810. Loss: 1.678321. Batch_acc: 0.407179. Batch_loss: 1.648400 \n",
      "Batch: 1969. Acc: 0.401807. Loss: 1.678316. Batch_acc: 0.396194. Batch_loss: 1.668391 \n",
      "Batch: 1970. Acc: 0.401808. Loss: 1.678304. Batch_acc: 0.404789. Batch_loss: 1.655041 \n",
      "Batch: 1971. Acc: 0.401816. Loss: 1.678274. Batch_acc: 0.416327. Batch_loss: 1.617686 \n",
      "Batch: 1972. Acc: 0.401826. Loss: 1.678235. Batch_acc: 0.422616. Batch_loss: 1.600966 \n",
      "Batch: 1973. Acc: 0.401836. Loss: 1.678203. Batch_acc: 0.422248. Batch_loss: 1.615795 \n",
      "Batch: 1974. Acc: 0.401847. Loss: 1.678175. Batch_acc: 0.422987. Batch_loss: 1.621257 \n",
      "Batch: 1975. Acc: 0.401864. Loss: 1.678156. Batch_acc: 0.433668. Batch_loss: 1.642111 \n",
      "Batch: 1976. Acc: 0.401874. Loss: 1.678122. Batch_acc: 0.422108. Batch_loss: 1.611006 \n",
      "Batch: 1977. Acc: 0.401889. Loss: 1.678075. Batch_acc: 0.431818. Batch_loss: 1.586084 \n",
      "Batch: 1978. Acc: 0.401899. Loss: 1.678037. Batch_acc: 0.420904. Batch_loss: 1.603813 \n",
      "Batch: 1979. Acc: 0.401907. Loss: 1.678019. Batch_acc: 0.418338. Batch_loss: 1.642241 \n",
      "Batch: 1980. Acc: 0.401926. Loss: 1.677957. Batch_acc: 0.437749. Batch_loss: 1.558294 \n",
      "Batch: 1981. Acc: 0.401942. Loss: 1.677915. Batch_acc: 0.434459. Batch_loss: 1.594552 \n",
      "Batch: 1982. Acc: 0.401942. Loss: 1.677911. Batch_acc: 0.402537. Batch_loss: 1.670303 \n",
      "Batch: 1983. Acc: 0.401954. Loss: 1.677886. Batch_acc: 0.424242. Batch_loss: 1.627736 \n",
      "Batch: 1984. Acc: 0.401964. Loss: 1.677852. Batch_acc: 0.421982. Batch_loss: 1.611534 \n",
      "Batch: 1985. Acc: 0.401968. Loss: 1.677834. Batch_acc: 0.410047. Batch_loss: 1.642104 \n",
      "Batch: 1986. Acc: 0.401985. Loss: 1.677787. Batch_acc: 0.435927. Batch_loss: 1.583576 \n",
      "Batch: 1987. Acc: 0.401993. Loss: 1.677771. Batch_acc: 0.417589. Batch_loss: 1.646151 \n",
      "Batch: 1988. Acc: 0.402003. Loss: 1.677736. Batch_acc: 0.422803. Batch_loss: 1.607140 \n",
      "Batch: 1989. Acc: 0.402012. Loss: 1.677696. Batch_acc: 0.420501. Batch_loss: 1.596685 \n",
      "Batch: 1990. Acc: 0.402011. Loss: 1.677691. Batch_acc: 0.399425. Batch_loss: 1.666904 \n",
      "Batch: 1991. Acc: 0.402019. Loss: 1.677673. Batch_acc: 0.418975. Batch_loss: 1.641283 \n",
      "Batch: 1992. Acc: 0.402030. Loss: 1.677637. Batch_acc: 0.423894. Batch_loss: 1.605768 \n",
      "Batch: 1993. Acc: 0.402046. Loss: 1.677602. Batch_acc: 0.433623. Batch_loss: 1.607989 \n",
      "Batch: 1994. Acc: 0.402056. Loss: 1.677559. Batch_acc: 0.421294. Batch_loss: 1.591640 \n",
      "Batch: 1995. Acc: 0.402070. Loss: 1.677531. Batch_acc: 0.431203. Batch_loss: 1.621863 \n",
      "Batch: 1996. Acc: 0.402072. Loss: 1.677524. Batch_acc: 0.405034. Batch_loss: 1.664154 \n",
      "Batch: 1997. Acc: 0.402077. Loss: 1.677505. Batch_acc: 0.413671. Batch_loss: 1.637905 \n",
      "Batch: 1998. Acc: 0.402087. Loss: 1.677461. Batch_acc: 0.421053. Batch_loss: 1.590926 \n",
      "Batch: 1999. Acc: 0.402091. Loss: 1.677443. Batch_acc: 0.410848. Batch_loss: 1.642255 \n",
      "Batch: 2000. Acc: 0.402099. Loss: 1.677404. Batch_acc: 0.417894. Batch_loss: 1.599925 \n",
      "Batch: 2001. Acc: 0.402093. Loss: 1.677414. Batch_acc: 0.388173. Batch_loss: 1.697984 \n",
      "Batch: 2002. Acc: 0.402105. Loss: 1.677373. Batch_acc: 0.426907. Batch_loss: 1.593846 \n",
      "Batch: 2003. Acc: 0.402113. Loss: 1.677352. Batch_acc: 0.418361. Batch_loss: 1.636148 \n",
      "Batch: 2004. Acc: 0.402111. Loss: 1.677342. Batch_acc: 0.398618. Batch_loss: 1.655806 \n",
      "Batch: 2005. Acc: 0.402121. Loss: 1.677315. Batch_acc: 0.422478. Batch_loss: 1.622598 \n",
      "Batch: 2006. Acc: 0.402124. Loss: 1.677295. Batch_acc: 0.407219. Batch_loss: 1.638857 \n",
      "Batch: 2007. Acc: 0.402139. Loss: 1.677243. Batch_acc: 0.432752. Batch_loss: 1.576098 \n",
      "Batch: 2008. Acc: 0.402141. Loss: 1.677238. Batch_acc: 0.405405. Batch_loss: 1.666341 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.4021409735805899. Loss per char: 1.6772380338249613. Time: 1627211909.237757\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 19, 19, 22, 22, 24, 19, 19, 24,\n",
      "        21,  1, 71, 83, 80, 78,  1, 14, 22, 18, 22, 17, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.402137. Loss: 1.677218. Batch_acc: 0.393167. Batch_loss: 1.637099 \n",
      "Batch: 2010. Acc: 0.402145. Loss: 1.677202. Batch_acc: 0.419820. Batch_loss: 1.642411 \n",
      "Batch: 2011. Acc: 0.402151. Loss: 1.677186. Batch_acc: 0.413577. Batch_loss: 1.646429 \n",
      "Batch: 2012. Acc: 0.402158. Loss: 1.677156. Batch_acc: 0.417620. Batch_loss: 1.617296 \n",
      "Batch: 2013. Acc: 0.402167. Loss: 1.677127. Batch_acc: 0.420125. Batch_loss: 1.618725 \n",
      "Batch: 2014. Acc: 0.402171. Loss: 1.677119. Batch_acc: 0.408985. Batch_loss: 1.661326 \n",
      "Batch: 2015. Acc: 0.402172. Loss: 1.677105. Batch_acc: 0.403769. Batch_loss: 1.648152 \n",
      "Batch: 2016. Acc: 0.402174. Loss: 1.677094. Batch_acc: 0.407386. Batch_loss: 1.655135 \n",
      "Batch: 2017. Acc: 0.402201. Loss: 1.677047. Batch_acc: 0.454960. Batch_loss: 1.582593 \n",
      "Batch: 2018. Acc: 0.402211. Loss: 1.677012. Batch_acc: 0.423550. Batch_loss: 1.605790 \n",
      "Batch: 2019. Acc: 0.402217. Loss: 1.676995. Batch_acc: 0.414194. Batch_loss: 1.643391 \n",
      "Batch: 2020. Acc: 0.402228. Loss: 1.676978. Batch_acc: 0.423777. Batch_loss: 1.642021 \n",
      "Batch: 2021. Acc: 0.402239. Loss: 1.676941. Batch_acc: 0.425592. Batch_loss: 1.603561 \n",
      "Batch: 2022. Acc: 0.402247. Loss: 1.676917. Batch_acc: 0.417657. Batch_loss: 1.628549 \n",
      "Batch: 2023. Acc: 0.402250. Loss: 1.676896. Batch_acc: 0.408755. Batch_loss: 1.635691 \n",
      "Batch: 2024. Acc: 0.402264. Loss: 1.676847. Batch_acc: 0.429728. Batch_loss: 1.577290 \n",
      "Batch: 2025. Acc: 0.402275. Loss: 1.676832. Batch_acc: 0.423444. Batch_loss: 1.646746 \n",
      "Batch: 2026. Acc: 0.402287. Loss: 1.676786. Batch_acc: 0.427147. Batch_loss: 1.586393 \n",
      "Batch: 2027. Acc: 0.402303. Loss: 1.676753. Batch_acc: 0.432524. Batch_loss: 1.612229 \n",
      "Batch: 2028. Acc: 0.402304. Loss: 1.676754. Batch_acc: 0.406196. Batch_loss: 1.677867 \n",
      "Batch: 2029. Acc: 0.402312. Loss: 1.676729. Batch_acc: 0.417295. Batch_loss: 1.626168 \n",
      "Batch: 2030. Acc: 0.402310. Loss: 1.676720. Batch_acc: 0.398019. Batch_loss: 1.657950 \n",
      "Batch: 2031. Acc: 0.402314. Loss: 1.676707. Batch_acc: 0.411866. Batch_loss: 1.651054 \n",
      "Batch: 2032. Acc: 0.402325. Loss: 1.676680. Batch_acc: 0.424312. Batch_loss: 1.621608 \n",
      "Batch: 2033. Acc: 0.402330. Loss: 1.676665. Batch_acc: 0.411597. Batch_loss: 1.646671 \n",
      "Batch: 2034. Acc: 0.402331. Loss: 1.676648. Batch_acc: 0.403901. Batch_loss: 1.642116 \n",
      "Batch: 2035. Acc: 0.402334. Loss: 1.676629. Batch_acc: 0.409726. Batch_loss: 1.639915 \n",
      "Batch: 2036. Acc: 0.402346. Loss: 1.676605. Batch_acc: 0.424619. Batch_loss: 1.627883 \n",
      "Batch: 2037. Acc: 0.402352. Loss: 1.676590. Batch_acc: 0.416376. Batch_loss: 1.645086 \n",
      "Batch: 2038. Acc: 0.402360. Loss: 1.676553. Batch_acc: 0.418224. Batch_loss: 1.599844 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2039. Acc: 0.402362. Loss: 1.676542. Batch_acc: 0.405855. Batch_loss: 1.654572 \n",
      "Batch: 2040. Acc: 0.402355. Loss: 1.676553. Batch_acc: 0.387861. Batch_loss: 1.698637 \n",
      "Batch: 2041. Acc: 0.402358. Loss: 1.676532. Batch_acc: 0.410023. Batch_loss: 1.634984 \n",
      "Batch: 2042. Acc: 0.402371. Loss: 1.676502. Batch_acc: 0.427124. Batch_loss: 1.615846 \n",
      "Batch: 2043. Acc: 0.402376. Loss: 1.676479. Batch_acc: 0.412791. Batch_loss: 1.629658 \n",
      "Batch: 2044. Acc: 0.402378. Loss: 1.676471. Batch_acc: 0.407407. Batch_loss: 1.659843 \n",
      "Batch: 2045. Acc: 0.402375. Loss: 1.676474. Batch_acc: 0.396074. Batch_loss: 1.683802 \n",
      "Batch: 2046. Acc: 0.402387. Loss: 1.676436. Batch_acc: 0.426022. Batch_loss: 1.598279 \n",
      "Batch: 2047. Acc: 0.402393. Loss: 1.676404. Batch_acc: 0.416370. Batch_loss: 1.608539 \n",
      "Batch: 2048. Acc: 0.402406. Loss: 1.676369. Batch_acc: 0.427673. Batch_loss: 1.604271 \n",
      "Batch: 2049. Acc: 0.402412. Loss: 1.676345. Batch_acc: 0.414869. Batch_loss: 1.629435 \n",
      "Batch: 2050. Acc: 0.402426. Loss: 1.676310. Batch_acc: 0.430028. Batch_loss: 1.605352 \n",
      "Batch: 2051. Acc: 0.402437. Loss: 1.676275. Batch_acc: 0.426295. Batch_loss: 1.603801 \n",
      "Batch: 2052. Acc: 0.402452. Loss: 1.676231. Batch_acc: 0.431741. Batch_loss: 1.587457 \n",
      "Batch: 2053. Acc: 0.402453. Loss: 1.676193. Batch_acc: 0.404618. Batch_loss: 1.602912 \n",
      "Batch: 2054. Acc: 0.402459. Loss: 1.676173. Batch_acc: 0.415448. Batch_loss: 1.633628 \n",
      "Batch: 2055. Acc: 0.402469. Loss: 1.676144. Batch_acc: 0.423143. Batch_loss: 1.616515 \n",
      "Batch: 2056. Acc: 0.402486. Loss: 1.676114. Batch_acc: 0.436353. Batch_loss: 1.614138 \n",
      "Batch: 2057. Acc: 0.402487. Loss: 1.676118. Batch_acc: 0.405187. Batch_loss: 1.685597 \n",
      "Batch: 2058. Acc: 0.402504. Loss: 1.676070. Batch_acc: 0.436860. Batch_loss: 1.577255 \n",
      "Batch: 2059. Acc: 0.402510. Loss: 1.676066. Batch_acc: 0.415750. Batch_loss: 1.668119 \n",
      "Batch: 2060. Acc: 0.402512. Loss: 1.676054. Batch_acc: 0.406363. Batch_loss: 1.650527 \n",
      "Batch: 2061. Acc: 0.402513. Loss: 1.676042. Batch_acc: 0.403207. Batch_loss: 1.649570 \n",
      "Batch: 2062. Acc: 0.402528. Loss: 1.676019. Batch_acc: 0.433824. Batch_loss: 1.630892 \n",
      "Batch: 2063. Acc: 0.402538. Loss: 1.675996. Batch_acc: 0.424690. Batch_loss: 1.627067 \n",
      "Batch: 2064. Acc: 0.402548. Loss: 1.675977. Batch_acc: 0.423011. Batch_loss: 1.635986 \n",
      "Batch: 2065. Acc: 0.402556. Loss: 1.675957. Batch_acc: 0.419080. Batch_loss: 1.635662 \n",
      "Batch: 2066. Acc: 0.402562. Loss: 1.675942. Batch_acc: 0.414451. Batch_loss: 1.643628 \n",
      "Batch: 2067. Acc: 0.402573. Loss: 1.675940. Batch_acc: 0.424156. Batch_loss: 1.672516 \n",
      "Batch: 2068. Acc: 0.402578. Loss: 1.675910. Batch_acc: 0.414425. Batch_loss: 1.613960 \n",
      "Batch: 2069. Acc: 0.402604. Loss: 1.675842. Batch_acc: 0.455280. Batch_loss: 1.534659 \n",
      "Batch: 2070. Acc: 0.402603. Loss: 1.675829. Batch_acc: 0.401635. Batch_loss: 1.648927 \n",
      "Batch: 2071. Acc: 0.402618. Loss: 1.675793. Batch_acc: 0.433071. Batch_loss: 1.602502 \n",
      "Batch: 2072. Acc: 0.402630. Loss: 1.675763. Batch_acc: 0.426239. Batch_loss: 1.612281 \n",
      "Batch: 2073. Acc: 0.402633. Loss: 1.675760. Batch_acc: 0.408676. Batch_loss: 1.669991 \n",
      "Batch: 2074. Acc: 0.402646. Loss: 1.675724. Batch_acc: 0.429988. Batch_loss: 1.600153 \n",
      "Batch: 2075. Acc: 0.402648. Loss: 1.675705. Batch_acc: 0.407662. Batch_loss: 1.635989 \n",
      "Batch: 2076. Acc: 0.402654. Loss: 1.675685. Batch_acc: 0.415027. Batch_loss: 1.633192 \n",
      "Batch: 2077. Acc: 0.402662. Loss: 1.675669. Batch_acc: 0.419300. Batch_loss: 1.643515 \n",
      "Batch: 2078. Acc: 0.402669. Loss: 1.675657. Batch_acc: 0.417295. Batch_loss: 1.649851 \n",
      "Batch: 2079. Acc: 0.402679. Loss: 1.675620. Batch_acc: 0.423786. Batch_loss: 1.601902 \n",
      "Batch: 2080. Acc: 0.402673. Loss: 1.675631. Batch_acc: 0.388468. Batch_loss: 1.697430 \n",
      "Batch: 2081. Acc: 0.402689. Loss: 1.675590. Batch_acc: 0.436384. Batch_loss: 1.594250 \n",
      "Batch: 2082. Acc: 0.402699. Loss: 1.675557. Batch_acc: 0.423011. Batch_loss: 1.607458 \n",
      "Batch: 2083. Acc: 0.402713. Loss: 1.675519. Batch_acc: 0.430358. Batch_loss: 1.597033 \n",
      "Batch: 2084. Acc: 0.402715. Loss: 1.675509. Batch_acc: 0.408270. Batch_loss: 1.653068 \n",
      "Batch: 2085. Acc: 0.402719. Loss: 1.675499. Batch_acc: 0.411092. Batch_loss: 1.655083 \n",
      "Batch: 2086. Acc: 0.402729. Loss: 1.675474. Batch_acc: 0.423403. Batch_loss: 1.625623 \n",
      "Batch: 2087. Acc: 0.402748. Loss: 1.675419. Batch_acc: 0.441551. Batch_loss: 1.558762 \n",
      "Batch: 2088. Acc: 0.402740. Loss: 1.675443. Batch_acc: 0.386006. Batch_loss: 1.727317 \n",
      "Batch: 2089. Acc: 0.402744. Loss: 1.675426. Batch_acc: 0.412236. Batch_loss: 1.639943 \n",
      "Batch: 2090. Acc: 0.402743. Loss: 1.675432. Batch_acc: 0.400000. Batch_loss: 1.687703 \n",
      "Batch: 2091. Acc: 0.402750. Loss: 1.675404. Batch_acc: 0.418224. Batch_loss: 1.616583 \n",
      "Batch: 2092. Acc: 0.402749. Loss: 1.675397. Batch_acc: 0.400681. Batch_loss: 1.660940 \n",
      "Batch: 2093. Acc: 0.402748. Loss: 1.675403. Batch_acc: 0.398844. Batch_loss: 1.686349 \n",
      "Batch: 2094. Acc: 0.402757. Loss: 1.675367. Batch_acc: 0.420879. Batch_loss: 1.604022 \n",
      "Batch: 2095. Acc: 0.402767. Loss: 1.675339. Batch_acc: 0.424697. Batch_loss: 1.616382 \n",
      "Batch: 2096. Acc: 0.402761. Loss: 1.675348. Batch_acc: 0.390046. Batch_loss: 1.693805 \n",
      "Batch: 2097. Acc: 0.402770. Loss: 1.675318. Batch_acc: 0.421269. Batch_loss: 1.611014 \n",
      "Batch: 2098. Acc: 0.402777. Loss: 1.675289. Batch_acc: 0.418350. Batch_loss: 1.614202 \n",
      "Batch: 2099. Acc: 0.402779. Loss: 1.675280. Batch_acc: 0.407364. Batch_loss: 1.657863 \n",
      "Batch: 2100. Acc: 0.402782. Loss: 1.675267. Batch_acc: 0.407534. Batch_loss: 1.646501 \n",
      "Batch: 2101. Acc: 0.402795. Loss: 1.675233. Batch_acc: 0.430114. Batch_loss: 1.604886 \n",
      "Batch: 2102. Acc: 0.402810. Loss: 1.675202. Batch_acc: 0.435132. Batch_loss: 1.610537 \n",
      "Batch: 2103. Acc: 0.402827. Loss: 1.675161. Batch_acc: 0.439123. Batch_loss: 1.589947 \n",
      "Batch: 2104. Acc: 0.402831. Loss: 1.675152. Batch_acc: 0.409694. Batch_loss: 1.656070 \n",
      "Batch: 2105. Acc: 0.402833. Loss: 1.675141. Batch_acc: 0.408721. Batch_loss: 1.649984 \n",
      "Batch: 2106. Acc: 0.402840. Loss: 1.675117. Batch_acc: 0.416475. Batch_loss: 1.625280 \n",
      "Batch: 2107. Acc: 0.402836. Loss: 1.675107. Batch_acc: 0.395213. Batch_loss: 1.653594 \n",
      "Batch: 2108. Acc: 0.402846. Loss: 1.675072. Batch_acc: 0.424105. Batch_loss: 1.601973 \n",
      "Batch: 2109. Acc: 0.402848. Loss: 1.675059. Batch_acc: 0.406463. Batch_loss: 1.647911 \n",
      "Batch: 2110. Acc: 0.402857. Loss: 1.675039. Batch_acc: 0.422040. Batch_loss: 1.632860 \n",
      "Batch: 2111. Acc: 0.402864. Loss: 1.675021. Batch_acc: 0.417332. Batch_loss: 1.636188 \n",
      "Batch: 2112. Acc: 0.402860. Loss: 1.675025. Batch_acc: 0.395003. Batch_loss: 1.685622 \n",
      "Batch: 2113. Acc: 0.402861. Loss: 1.675020. Batch_acc: 0.404624. Batch_loss: 1.663538 \n",
      "Batch: 2114. Acc: 0.402866. Loss: 1.675021. Batch_acc: 0.413043. Batch_loss: 1.677412 \n",
      "Batch: 2115. Acc: 0.402873. Loss: 1.674986. Batch_acc: 0.417595. Batch_loss: 1.600271 \n",
      "Batch: 2116. Acc: 0.402880. Loss: 1.674960. Batch_acc: 0.419075. Batch_loss: 1.618702 \n",
      "Batch: 2117. Acc: 0.402883. Loss: 1.674947. Batch_acc: 0.408716. Batch_loss: 1.646393 \n",
      "Batch: 2118. Acc: 0.402891. Loss: 1.674930. Batch_acc: 0.419896. Batch_loss: 1.639441 \n",
      "Batch: 2119. Acc: 0.402894. Loss: 1.674912. Batch_acc: 0.408859. Batch_loss: 1.636336 \n",
      "Batch: 2120. Acc: 0.402900. Loss: 1.674884. Batch_acc: 0.416618. Batch_loss: 1.616448 \n",
      "Batch: 2121. Acc: 0.402913. Loss: 1.674860. Batch_acc: 0.430962. Batch_loss: 1.621593 \n",
      "Batch: 2122. Acc: 0.402927. Loss: 1.674818. Batch_acc: 0.432127. Batch_loss: 1.586806 \n",
      "Batch: 2123. Acc: 0.402948. Loss: 1.674766. Batch_acc: 0.448517. Batch_loss: 1.564037 \n",
      "Batch: 2124. Acc: 0.402953. Loss: 1.674766. Batch_acc: 0.411798. Batch_loss: 1.674394 \n",
      "Batch: 2125. Acc: 0.402969. Loss: 1.674728. Batch_acc: 0.437140. Batch_loss: 1.593097 \n",
      "Batch: 2126. Acc: 0.402968. Loss: 1.674721. Batch_acc: 0.402480. Batch_loss: 1.660240 \n",
      "Batch: 2127. Acc: 0.402967. Loss: 1.674701. Batch_acc: 0.401033. Batch_loss: 1.631750 \n",
      "Batch: 2128. Acc: 0.402970. Loss: 1.674691. Batch_acc: 0.409064. Batch_loss: 1.652421 \n",
      "Batch: 2129. Acc: 0.402985. Loss: 1.674644. Batch_acc: 0.436353. Batch_loss: 1.573345 \n",
      "Batch: 2130. Acc: 0.403000. Loss: 1.674618. Batch_acc: 0.434499. Batch_loss: 1.617456 \n",
      "Batch: 2131. Acc: 0.403003. Loss: 1.674608. Batch_acc: 0.410903. Batch_loss: 1.652819 \n",
      "Batch: 2132. Acc: 0.403012. Loss: 1.674577. Batch_acc: 0.420874. Batch_loss: 1.609689 \n",
      "Batch: 2133. Acc: 0.403020. Loss: 1.674562. Batch_acc: 0.420746. Batch_loss: 1.640355 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2134. Acc: 0.403018. Loss: 1.674557. Batch_acc: 0.398955. Batch_loss: 1.664203 \n",
      "Batch: 2135. Acc: 0.403029. Loss: 1.674516. Batch_acc: 0.424634. Batch_loss: 1.589408 \n",
      "Batch: 2136. Acc: 0.403038. Loss: 1.674495. Batch_acc: 0.423256. Batch_loss: 1.628652 \n",
      "Batch: 2137. Acc: 0.403050. Loss: 1.674469. Batch_acc: 0.428237. Batch_loss: 1.617636 \n",
      "Batch: 2138. Acc: 0.403058. Loss: 1.674449. Batch_acc: 0.421144. Batch_loss: 1.632362 \n",
      "Batch: 2139. Acc: 0.403075. Loss: 1.674408. Batch_acc: 0.439630. Batch_loss: 1.585475 \n",
      "Batch: 2140. Acc: 0.403084. Loss: 1.674370. Batch_acc: 0.421580. Batch_loss: 1.595664 \n",
      "Batch: 2141. Acc: 0.403098. Loss: 1.674346. Batch_acc: 0.432870. Batch_loss: 1.623032 \n",
      "Batch: 2142. Acc: 0.403103. Loss: 1.674325. Batch_acc: 0.413673. Batch_loss: 1.628874 \n",
      "Batch: 2143. Acc: 0.403110. Loss: 1.674302. Batch_acc: 0.419336. Batch_loss: 1.625560 \n",
      "Batch: 2144. Acc: 0.403113. Loss: 1.674292. Batch_acc: 0.408501. Batch_loss: 1.652416 \n",
      "Batch: 2145. Acc: 0.403127. Loss: 1.674255. Batch_acc: 0.434100. Batch_loss: 1.596837 \n",
      "Batch: 2146. Acc: 0.403137. Loss: 1.674222. Batch_acc: 0.424018. Batch_loss: 1.603564 \n",
      "Batch: 2147. Acc: 0.403148. Loss: 1.674191. Batch_acc: 0.427083. Batch_loss: 1.607828 \n",
      "Batch: 2148. Acc: 0.403149. Loss: 1.674181. Batch_acc: 0.404954. Batch_loss: 1.652509 \n",
      "Batch: 2149. Acc: 0.403155. Loss: 1.674157. Batch_acc: 0.415509. Batch_loss: 1.621280 \n",
      "Batch: 2150. Acc: 0.403154. Loss: 1.674135. Batch_acc: 0.400914. Batch_loss: 1.627316 \n",
      "Batch: 2151. Acc: 0.403158. Loss: 1.674116. Batch_acc: 0.412744. Batch_loss: 1.633178 \n",
      "Batch: 2152. Acc: 0.403164. Loss: 1.674097. Batch_acc: 0.415853. Batch_loss: 1.634806 \n",
      "Batch: 2153. Acc: 0.403168. Loss: 1.674076. Batch_acc: 0.411628. Batch_loss: 1.628056 \n",
      "Batch: 2154. Acc: 0.403178. Loss: 1.674039. Batch_acc: 0.424120. Batch_loss: 1.593725 \n",
      "Batch: 2155. Acc: 0.403178. Loss: 1.674037. Batch_acc: 0.403509. Batch_loss: 1.670183 \n",
      "Batch: 2156. Acc: 0.403185. Loss: 1.674013. Batch_acc: 0.417736. Batch_loss: 1.621829 \n",
      "Batch: 2157. Acc: 0.403201. Loss: 1.673974. Batch_acc: 0.438325. Batch_loss: 1.588424 \n",
      "Batch: 2158. Acc: 0.403203. Loss: 1.673969. Batch_acc: 0.407010. Batch_loss: 1.664664 \n",
      "Batch: 2159. Acc: 0.403209. Loss: 1.673950. Batch_acc: 0.416913. Batch_loss: 1.631546 \n",
      "Batch: 2160. Acc: 0.403220. Loss: 1.673922. Batch_acc: 0.426928. Batch_loss: 1.612973 \n",
      "Batch: 2161. Acc: 0.403232. Loss: 1.673888. Batch_acc: 0.430548. Batch_loss: 1.599993 \n",
      "Batch: 2162. Acc: 0.403238. Loss: 1.673869. Batch_acc: 0.415158. Batch_loss: 1.633473 \n",
      "Batch: 2163. Acc: 0.403244. Loss: 1.673837. Batch_acc: 0.416084. Batch_loss: 1.603792 \n",
      "Batch: 2164. Acc: 0.403244. Loss: 1.673834. Batch_acc: 0.403318. Batch_loss: 1.667856 \n",
      "Batch: 2165. Acc: 0.403252. Loss: 1.673809. Batch_acc: 0.421694. Batch_loss: 1.618522 \n",
      "Batch: 2166. Acc: 0.403261. Loss: 1.673788. Batch_acc: 0.422222. Batch_loss: 1.629448 \n",
      "Batch: 2167. Acc: 0.403267. Loss: 1.673771. Batch_acc: 0.416764. Batch_loss: 1.635384 \n",
      "Batch: 2168. Acc: 0.403277. Loss: 1.673748. Batch_acc: 0.423143. Batch_loss: 1.624035 \n",
      "Batch: 2169. Acc: 0.403283. Loss: 1.673732. Batch_acc: 0.416716. Batch_loss: 1.638570 \n",
      "Batch: 2170. Acc: 0.403289. Loss: 1.673727. Batch_acc: 0.417196. Batch_loss: 1.664194 \n",
      "Batch: 2171. Acc: 0.403290. Loss: 1.673734. Batch_acc: 0.404887. Batch_loss: 1.688055 \n",
      "Batch: 2172. Acc: 0.403298. Loss: 1.673704. Batch_acc: 0.421231. Batch_loss: 1.609245 \n",
      "Batch: 2173. Acc: 0.403301. Loss: 1.673688. Batch_acc: 0.410256. Batch_loss: 1.637653 \n",
      "Batch: 2174. Acc: 0.403319. Loss: 1.673641. Batch_acc: 0.441259. Batch_loss: 1.575404 \n",
      "Batch: 2175. Acc: 0.403330. Loss: 1.673617. Batch_acc: 0.426495. Batch_loss: 1.622791 \n",
      "Batch: 2176. Acc: 0.403332. Loss: 1.673599. Batch_acc: 0.407728. Batch_loss: 1.633848 \n",
      "Batch: 2177. Acc: 0.403340. Loss: 1.673569. Batch_acc: 0.420561. Batch_loss: 1.606813 \n",
      "Batch: 2178. Acc: 0.403342. Loss: 1.673557. Batch_acc: 0.408324. Batch_loss: 1.647874 \n",
      "Batch: 2179. Acc: 0.403343. Loss: 1.673537. Batch_acc: 0.404304. Batch_loss: 1.630420 \n",
      "Batch: 2180. Acc: 0.403358. Loss: 1.673487. Batch_acc: 0.437105. Batch_loss: 1.564395 \n",
      "Batch: 2181. Acc: 0.403366. Loss: 1.673468. Batch_acc: 0.420528. Batch_loss: 1.632721 \n",
      "Batch: 2182. Acc: 0.403369. Loss: 1.673452. Batch_acc: 0.409535. Batch_loss: 1.637500 \n",
      "Batch: 2183. Acc: 0.403373. Loss: 1.673442. Batch_acc: 0.412336. Batch_loss: 1.652339 \n",
      "Batch: 2184. Acc: 0.403382. Loss: 1.673430. Batch_acc: 0.422746. Batch_loss: 1.646835 \n",
      "Batch: 2185. Acc: 0.403383. Loss: 1.673410. Batch_acc: 0.405634. Batch_loss: 1.630943 \n",
      "Batch: 2186. Acc: 0.403386. Loss: 1.673391. Batch_acc: 0.411659. Batch_loss: 1.629740 \n",
      "Batch: 2187. Acc: 0.403394. Loss: 1.673381. Batch_acc: 0.419487. Batch_loss: 1.651001 \n",
      "Batch: 2188. Acc: 0.403405. Loss: 1.673352. Batch_acc: 0.429408. Batch_loss: 1.608300 \n",
      "Batch: 2189. Acc: 0.403418. Loss: 1.673325. Batch_acc: 0.431235. Batch_loss: 1.613234 \n",
      "Batch: 2190. Acc: 0.403437. Loss: 1.673283. Batch_acc: 0.444253. Batch_loss: 1.582149 \n",
      "Batch: 2191. Acc: 0.403442. Loss: 1.673259. Batch_acc: 0.415737. Batch_loss: 1.619597 \n",
      "Batch: 2192. Acc: 0.403445. Loss: 1.673246. Batch_acc: 0.410181. Batch_loss: 1.643267 \n",
      "Batch: 2193. Acc: 0.403454. Loss: 1.673216. Batch_acc: 0.422247. Batch_loss: 1.609201 \n",
      "Batch: 2194. Acc: 0.403457. Loss: 1.673212. Batch_acc: 0.409687. Batch_loss: 1.663753 \n",
      "Batch: 2195. Acc: 0.403470. Loss: 1.673181. Batch_acc: 0.432558. Batch_loss: 1.604728 \n",
      "Batch: 2196. Acc: 0.403482. Loss: 1.673152. Batch_acc: 0.429728. Batch_loss: 1.609859 \n",
      "Batch: 2197. Acc: 0.403492. Loss: 1.673132. Batch_acc: 0.427089. Batch_loss: 1.628920 \n",
      "Batch: 2198. Acc: 0.403500. Loss: 1.673109. Batch_acc: 0.420571. Batch_loss: 1.623215 \n",
      "Batch: 2199. Acc: 0.403503. Loss: 1.673092. Batch_acc: 0.409817. Batch_loss: 1.635805 \n",
      "Batch: 2200. Acc: 0.403508. Loss: 1.673082. Batch_acc: 0.414523. Batch_loss: 1.650401 \n",
      "Batch: 2201. Acc: 0.403522. Loss: 1.673047. Batch_acc: 0.434203. Batch_loss: 1.595690 \n",
      "Batch: 2202. Acc: 0.403535. Loss: 1.673016. Batch_acc: 0.432113. Batch_loss: 1.605803 \n",
      "Batch: 2203. Acc: 0.403542. Loss: 1.672989. Batch_acc: 0.418118. Batch_loss: 1.613784 \n",
      "Batch: 2204. Acc: 0.403560. Loss: 1.672939. Batch_acc: 0.444068. Batch_loss: 1.565570 \n",
      "Batch: 2205. Acc: 0.403569. Loss: 1.672917. Batch_acc: 0.422693. Batch_loss: 1.622160 \n",
      "Batch: 2206. Acc: 0.403571. Loss: 1.672902. Batch_acc: 0.408186. Batch_loss: 1.641373 \n",
      "Batch: 2207. Acc: 0.403579. Loss: 1.672887. Batch_acc: 0.421053. Batch_loss: 1.637564 \n",
      "Batch: 2208. Acc: 0.403586. Loss: 1.672864. Batch_acc: 0.420838. Batch_loss: 1.621467 \n",
      "Batch: 2209. Acc: 0.403586. Loss: 1.672859. Batch_acc: 0.403064. Batch_loss: 1.661613 \n",
      "Batch: 2210. Acc: 0.403595. Loss: 1.672815. Batch_acc: 0.422657. Batch_loss: 1.576389 \n",
      "Batch: 2211. Acc: 0.403605. Loss: 1.672782. Batch_acc: 0.426370. Batch_loss: 1.600849 \n",
      "Batch: 2212. Acc: 0.403605. Loss: 1.672775. Batch_acc: 0.403791. Batch_loss: 1.657234 \n",
      "Batch: 2213. Acc: 0.403599. Loss: 1.672775. Batch_acc: 0.390173. Batch_loss: 1.671103 \n",
      "Batch: 2214. Acc: 0.403605. Loss: 1.672758. Batch_acc: 0.417341. Batch_loss: 1.636123 \n",
      "Batch: 2215. Acc: 0.403604. Loss: 1.672766. Batch_acc: 0.400240. Batch_loss: 1.690085 \n",
      "Batch: 2216. Acc: 0.403610. Loss: 1.672753. Batch_acc: 0.416327. Batch_loss: 1.643502 \n",
      "Batch: 2217. Acc: 0.403616. Loss: 1.672722. Batch_acc: 0.416812. Batch_loss: 1.604948 \n",
      "Batch: 2218. Acc: 0.403623. Loss: 1.672700. Batch_acc: 0.419373. Batch_loss: 1.623878 \n",
      "Batch: 2219. Acc: 0.403630. Loss: 1.672681. Batch_acc: 0.420841. Batch_loss: 1.630009 \n",
      "Batch: 2220. Acc: 0.403634. Loss: 1.672667. Batch_acc: 0.411833. Batch_loss: 1.642941 \n",
      "Batch: 2221. Acc: 0.403627. Loss: 1.672679. Batch_acc: 0.386760. Batch_loss: 1.699002 \n",
      "Batch: 2222. Acc: 0.403627. Loss: 1.672673. Batch_acc: 0.404988. Batch_loss: 1.657633 \n",
      "Batch: 2223. Acc: 0.403642. Loss: 1.672634. Batch_acc: 0.436200. Batch_loss: 1.589513 \n",
      "Batch: 2224. Acc: 0.403652. Loss: 1.672593. Batch_acc: 0.424759. Batch_loss: 1.581190 \n",
      "Batch: 2225. Acc: 0.403666. Loss: 1.672562. Batch_acc: 0.436077. Batch_loss: 1.602438 \n",
      "Batch: 2226. Acc: 0.403673. Loss: 1.672527. Batch_acc: 0.419226. Batch_loss: 1.597096 \n",
      "Batch: 2227. Acc: 0.403686. Loss: 1.672493. Batch_acc: 0.431530. Batch_loss: 1.596548 \n",
      "Batch: 2228. Acc: 0.403694. Loss: 1.672474. Batch_acc: 0.422197. Batch_loss: 1.629416 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2229. Acc: 0.403692. Loss: 1.672476. Batch_acc: 0.397856. Batch_loss: 1.677031 \n",
      "Batch: 2230. Acc: 0.403693. Loss: 1.672460. Batch_acc: 0.406106. Batch_loss: 1.636924 \n",
      "Batch: 2231. Acc: 0.403700. Loss: 1.672434. Batch_acc: 0.418919. Batch_loss: 1.616488 \n",
      "Batch: 2232. Acc: 0.403702. Loss: 1.672418. Batch_acc: 0.408651. Batch_loss: 1.636516 \n",
      "Batch: 2233. Acc: 0.403710. Loss: 1.672393. Batch_acc: 0.422633. Batch_loss: 1.617068 \n",
      "Batch: 2234. Acc: 0.403704. Loss: 1.672398. Batch_acc: 0.390679. Batch_loss: 1.682768 \n",
      "Batch: 2235. Acc: 0.403711. Loss: 1.672380. Batch_acc: 0.419318. Batch_loss: 1.632371 \n",
      "Batch: 2236. Acc: 0.403726. Loss: 1.672346. Batch_acc: 0.436691. Batch_loss: 1.597024 \n",
      "Batch: 2237. Acc: 0.403740. Loss: 1.672304. Batch_acc: 0.434279. Batch_loss: 1.578820 \n",
      "Batch: 2238. Acc: 0.403754. Loss: 1.672256. Batch_acc: 0.433673. Batch_loss: 1.566461 \n",
      "Batch: 2239. Acc: 0.403759. Loss: 1.672232. Batch_acc: 0.416714. Batch_loss: 1.617423 \n",
      "Batch: 2240. Acc: 0.403769. Loss: 1.672203. Batch_acc: 0.425978. Batch_loss: 1.608519 \n",
      "Batch: 2241. Acc: 0.403783. Loss: 1.672169. Batch_acc: 0.432387. Batch_loss: 1.598045 \n",
      "Batch: 2242. Acc: 0.403806. Loss: 1.672108. Batch_acc: 0.454289. Batch_loss: 1.539708 \n",
      "Batch: 2243. Acc: 0.403809. Loss: 1.672087. Batch_acc: 0.410497. Batch_loss: 1.626821 \n",
      "Batch: 2244. Acc: 0.403814. Loss: 1.672062. Batch_acc: 0.415981. Batch_loss: 1.614874 \n",
      "Batch: 2245. Acc: 0.403806. Loss: 1.672064. Batch_acc: 0.385549. Batch_loss: 1.676134 \n",
      "Batch: 2246. Acc: 0.403811. Loss: 1.672049. Batch_acc: 0.415638. Batch_loss: 1.638011 \n",
      "Batch: 2247. Acc: 0.403827. Loss: 1.672010. Batch_acc: 0.439817. Batch_loss: 1.584063 \n",
      "Batch: 2248. Acc: 0.403844. Loss: 1.671970. Batch_acc: 0.439977. Batch_loss: 1.584552 \n",
      "Batch: 2249. Acc: 0.403852. Loss: 1.671938. Batch_acc: 0.421625. Batch_loss: 1.599430 \n",
      "Batch: 2250. Acc: 0.403867. Loss: 1.671898. Batch_acc: 0.437751. Batch_loss: 1.583041 \n",
      "Batch: 2251. Acc: 0.403881. Loss: 1.671863. Batch_acc: 0.436499. Batch_loss: 1.593285 \n",
      "Batch: 2252. Acc: 0.403882. Loss: 1.671856. Batch_acc: 0.406523. Batch_loss: 1.655380 \n",
      "Batch: 2253. Acc: 0.403879. Loss: 1.671850. Batch_acc: 0.395189. Batch_loss: 1.657727 \n",
      "Batch: 2254. Acc: 0.403880. Loss: 1.671840. Batch_acc: 0.408127. Batch_loss: 1.648815 \n",
      "Batch: 2255. Acc: 0.403885. Loss: 1.671819. Batch_acc: 0.413972. Batch_loss: 1.625232 \n",
      "Batch: 2256. Acc: 0.403897. Loss: 1.671783. Batch_acc: 0.430034. Batch_loss: 1.591036 \n",
      "Batch: 2257. Acc: 0.403906. Loss: 1.671756. Batch_acc: 0.425893. Batch_loss: 1.610258 \n",
      "Batch: 2258. Acc: 0.403909. Loss: 1.671722. Batch_acc: 0.409702. Batch_loss: 1.593728 \n",
      "Batch: 2259. Acc: 0.403916. Loss: 1.671704. Batch_acc: 0.419781. Batch_loss: 1.629853 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.4039156516089878. Loss per char: 1.6717037305085067. Time: 1627212113.372208\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 18, 18, 25, 18, 22, 20, 25,\n",
      "        22, 21, 21, 17, 23,  1, 81, 77, 86, 84,  1, 14, 18, 32,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.403925. Loss: 1.671676. Batch_acc: 0.424452. Batch_loss: 1.609967 \n",
      "Batch: 2261. Acc: 0.403928. Loss: 1.671665. Batch_acc: 0.411593. Batch_loss: 1.645617 \n",
      "Batch: 2262. Acc: 0.403930. Loss: 1.671653. Batch_acc: 0.408467. Batch_loss: 1.643515 \n",
      "Batch: 2263. Acc: 0.403945. Loss: 1.671617. Batch_acc: 0.436684. Batch_loss: 1.591910 \n",
      "Batch: 2264. Acc: 0.403941. Loss: 1.671617. Batch_acc: 0.396433. Batch_loss: 1.671026 \n",
      "Batch: 2265. Acc: 0.403946. Loss: 1.671599. Batch_acc: 0.415592. Batch_loss: 1.629665 \n",
      "Batch: 2266. Acc: 0.403965. Loss: 1.671543. Batch_acc: 0.446357. Batch_loss: 1.546471 \n",
      "Batch: 2267. Acc: 0.403968. Loss: 1.671537. Batch_acc: 0.409687. Batch_loss: 1.658298 \n",
      "Batch: 2268. Acc: 0.403982. Loss: 1.671494. Batch_acc: 0.436702. Batch_loss: 1.573414 \n",
      "Batch: 2269. Acc: 0.403991. Loss: 1.671472. Batch_acc: 0.423845. Batch_loss: 1.620699 \n",
      "Batch: 2270. Acc: 0.404009. Loss: 1.671433. Batch_acc: 0.447024. Batch_loss: 1.579650 \n",
      "Batch: 2271. Acc: 0.404017. Loss: 1.671409. Batch_acc: 0.420809. Batch_loss: 1.617995 \n",
      "Batch: 2272. Acc: 0.404024. Loss: 1.671379. Batch_acc: 0.421412. Batch_loss: 1.603581 \n",
      "Batch: 2273. Acc: 0.404039. Loss: 1.671340. Batch_acc: 0.436116. Batch_loss: 1.582249 \n",
      "Batch: 2274. Acc: 0.404039. Loss: 1.671348. Batch_acc: 0.404195. Batch_loss: 1.690438 \n",
      "Batch: 2275. Acc: 0.404050. Loss: 1.671316. Batch_acc: 0.429138. Batch_loss: 1.599307 \n",
      "Batch: 2276. Acc: 0.404059. Loss: 1.671287. Batch_acc: 0.424855. Batch_loss: 1.606069 \n",
      "Batch: 2277. Acc: 0.404069. Loss: 1.671248. Batch_acc: 0.426999. Batch_loss: 1.580316 \n",
      "Batch: 2278. Acc: 0.404070. Loss: 1.671225. Batch_acc: 0.407599. Batch_loss: 1.620051 \n",
      "Batch: 2279. Acc: 0.404073. Loss: 1.671220. Batch_acc: 0.410975. Batch_loss: 1.658476 \n",
      "Batch: 2280. Acc: 0.404077. Loss: 1.671206. Batch_acc: 0.411765. Batch_loss: 1.639277 \n",
      "Batch: 2281. Acc: 0.404090. Loss: 1.671164. Batch_acc: 0.434203. Batch_loss: 1.575187 \n",
      "Batch: 2282. Acc: 0.404104. Loss: 1.671128. Batch_acc: 0.436000. Batch_loss: 1.589476 \n",
      "Batch: 2283. Acc: 0.404122. Loss: 1.671083. Batch_acc: 0.445209. Batch_loss: 1.568927 \n",
      "Batch: 2284. Acc: 0.404126. Loss: 1.671070. Batch_acc: 0.412844. Batch_loss: 1.641020 \n",
      "Batch: 2285. Acc: 0.404130. Loss: 1.671057. Batch_acc: 0.414269. Batch_loss: 1.640472 \n",
      "Batch: 2286. Acc: 0.404145. Loss: 1.671009. Batch_acc: 0.438387. Batch_loss: 1.563373 \n",
      "Batch: 2287. Acc: 0.404154. Loss: 1.670986. Batch_acc: 0.422925. Batch_loss: 1.618292 \n",
      "Batch: 2288. Acc: 0.404164. Loss: 1.670961. Batch_acc: 0.426928. Batch_loss: 1.614899 \n",
      "Batch: 2289. Acc: 0.404168. Loss: 1.670955. Batch_acc: 0.413655. Batch_loss: 1.656160 \n",
      "Batch: 2290. Acc: 0.404169. Loss: 1.670949. Batch_acc: 0.406740. Batch_loss: 1.658716 \n",
      "Batch: 2291. Acc: 0.404181. Loss: 1.670921. Batch_acc: 0.430760. Batch_loss: 1.607641 \n",
      "Batch: 2292. Acc: 0.404193. Loss: 1.670894. Batch_acc: 0.432574. Batch_loss: 1.606729 \n",
      "Batch: 2293. Acc: 0.404196. Loss: 1.670884. Batch_acc: 0.411492. Batch_loss: 1.648334 \n",
      "Batch: 2294. Acc: 0.404210. Loss: 1.670840. Batch_acc: 0.435009. Batch_loss: 1.570300 \n",
      "Batch: 2295. Acc: 0.404224. Loss: 1.670798. Batch_acc: 0.437358. Batch_loss: 1.574140 \n",
      "Batch: 2296. Acc: 0.404236. Loss: 1.670775. Batch_acc: 0.430885. Batch_loss: 1.618072 \n",
      "Batch: 2297. Acc: 0.404252. Loss: 1.670735. Batch_acc: 0.441718. Batch_loss: 1.580985 \n",
      "Batch: 2298. Acc: 0.404261. Loss: 1.670717. Batch_acc: 0.423362. Batch_loss: 1.629782 \n",
      "Batch: 2299. Acc: 0.404281. Loss: 1.670678. Batch_acc: 0.449413. Batch_loss: 1.583397 \n",
      "Batch: 2300. Acc: 0.404285. Loss: 1.670653. Batch_acc: 0.413714. Batch_loss: 1.614697 \n",
      "Batch: 2301. Acc: 0.404285. Loss: 1.670635. Batch_acc: 0.404533. Batch_loss: 1.628407 \n",
      "Batch: 2302. Acc: 0.404295. Loss: 1.670609. Batch_acc: 0.427647. Batch_loss: 1.610301 \n",
      "Batch: 2303. Acc: 0.404303. Loss: 1.670584. Batch_acc: 0.422197. Batch_loss: 1.613147 \n",
      "Batch: 2304. Acc: 0.404319. Loss: 1.670542. Batch_acc: 0.440563. Batch_loss: 1.575379 \n",
      "Batch: 2305. Acc: 0.404332. Loss: 1.670516. Batch_acc: 0.432432. Batch_loss: 1.613689 \n",
      "Batch: 2306. Acc: 0.404338. Loss: 1.670487. Batch_acc: 0.419186. Batch_loss: 1.600761 \n",
      "Batch: 2307. Acc: 0.404338. Loss: 1.670474. Batch_acc: 0.404968. Batch_loss: 1.641652 \n",
      "Batch: 2308. Acc: 0.404339. Loss: 1.670480. Batch_acc: 0.405611. Batch_loss: 1.683588 \n",
      "Batch: 2309. Acc: 0.404348. Loss: 1.670464. Batch_acc: 0.425115. Batch_loss: 1.635174 \n",
      "Batch: 2310. Acc: 0.404360. Loss: 1.670433. Batch_acc: 0.434127. Batch_loss: 1.597956 \n",
      "Batch: 2311. Acc: 0.404362. Loss: 1.670425. Batch_acc: 0.407666. Batch_loss: 1.651258 \n",
      "Batch: 2312. Acc: 0.404374. Loss: 1.670373. Batch_acc: 0.431362. Batch_loss: 1.554238 \n",
      "Batch: 2313. Acc: 0.404378. Loss: 1.670358. Batch_acc: 0.414374. Batch_loss: 1.636831 \n",
      "Batch: 2314. Acc: 0.404384. Loss: 1.670345. Batch_acc: 0.416192. Batch_loss: 1.639946 \n",
      "Batch: 2315. Acc: 0.404397. Loss: 1.670301. Batch_acc: 0.435868. Batch_loss: 1.570456 \n",
      "Batch: 2316. Acc: 0.404413. Loss: 1.670249. Batch_acc: 0.440456. Batch_loss: 1.549226 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2317. Acc: 0.404423. Loss: 1.670218. Batch_acc: 0.426211. Batch_loss: 1.599794 \n",
      "Batch: 2318. Acc: 0.404434. Loss: 1.670198. Batch_acc: 0.432224. Batch_loss: 1.622796 \n",
      "Batch: 2319. Acc: 0.404441. Loss: 1.670169. Batch_acc: 0.420331. Batch_loss: 1.602821 \n",
      "Batch: 2320. Acc: 0.404442. Loss: 1.670152. Batch_acc: 0.407706. Batch_loss: 1.631176 \n",
      "Batch: 2321. Acc: 0.404449. Loss: 1.670108. Batch_acc: 0.420545. Batch_loss: 1.567791 \n",
      "Batch: 2322. Acc: 0.404459. Loss: 1.670084. Batch_acc: 0.426659. Batch_loss: 1.618169 \n",
      "Batch: 2323. Acc: 0.404471. Loss: 1.670051. Batch_acc: 0.431792. Batch_loss: 1.592138 \n",
      "Batch: 2324. Acc: 0.404472. Loss: 1.670048. Batch_acc: 0.407602. Batch_loss: 1.661937 \n",
      "Batch: 2325. Acc: 0.404479. Loss: 1.670019. Batch_acc: 0.419318. Batch_loss: 1.603494 \n",
      "Batch: 2326. Acc: 0.404491. Loss: 1.669989. Batch_acc: 0.433221. Batch_loss: 1.601659 \n",
      "Batch: 2327. Acc: 0.404499. Loss: 1.669970. Batch_acc: 0.423208. Batch_loss: 1.625464 \n",
      "Batch: 2328. Acc: 0.404516. Loss: 1.669932. Batch_acc: 0.442242. Batch_loss: 1.583322 \n",
      "Batch: 2329. Acc: 0.404512. Loss: 1.669931. Batch_acc: 0.394383. Batch_loss: 1.668021 \n",
      "Batch: 2330. Acc: 0.404529. Loss: 1.669871. Batch_acc: 0.444832. Batch_loss: 1.528653 \n",
      "Batch: 2331. Acc: 0.404528. Loss: 1.669863. Batch_acc: 0.402312. Batch_loss: 1.651630 \n",
      "Batch: 2332. Acc: 0.404538. Loss: 1.669839. Batch_acc: 0.428324. Batch_loss: 1.612252 \n",
      "Batch: 2333. Acc: 0.404538. Loss: 1.669827. Batch_acc: 0.404353. Batch_loss: 1.642849 \n",
      "Batch: 2334. Acc: 0.404551. Loss: 1.669793. Batch_acc: 0.435409. Batch_loss: 1.589476 \n",
      "Batch: 2335. Acc: 0.404563. Loss: 1.669756. Batch_acc: 0.431507. Batch_loss: 1.583592 \n",
      "Batch: 2336. Acc: 0.404556. Loss: 1.669765. Batch_acc: 0.387647. Batch_loss: 1.692115 \n",
      "Batch: 2337. Acc: 0.404572. Loss: 1.669740. Batch_acc: 0.442375. Batch_loss: 1.611493 \n",
      "Batch: 2338. Acc: 0.404575. Loss: 1.669721. Batch_acc: 0.411429. Batch_loss: 1.625227 \n",
      "Batch: 2339. Acc: 0.404585. Loss: 1.669695. Batch_acc: 0.428977. Batch_loss: 1.609017 \n",
      "Batch: 2340. Acc: 0.404593. Loss: 1.669663. Batch_acc: 0.424032. Batch_loss: 1.595648 \n",
      "Batch: 2341. Acc: 0.404599. Loss: 1.669649. Batch_acc: 0.418671. Batch_loss: 1.636208 \n",
      "Batch: 2342. Acc: 0.404602. Loss: 1.669638. Batch_acc: 0.411458. Batch_loss: 1.643826 \n",
      "Batch: 2343. Acc: 0.404620. Loss: 1.669590. Batch_acc: 0.446295. Batch_loss: 1.557584 \n",
      "Batch: 2344. Acc: 0.404627. Loss: 1.669565. Batch_acc: 0.420841. Batch_loss: 1.610146 \n",
      "Batch: 2345. Acc: 0.404631. Loss: 1.669551. Batch_acc: 0.414393. Batch_loss: 1.635902 \n",
      "Batch: 2346. Acc: 0.404634. Loss: 1.669538. Batch_acc: 0.411327. Batch_loss: 1.641029 \n",
      "Batch: 2347. Acc: 0.404639. Loss: 1.669517. Batch_acc: 0.416384. Batch_loss: 1.621042 \n",
      "Batch: 2348. Acc: 0.404650. Loss: 1.669486. Batch_acc: 0.429621. Batch_loss: 1.597037 \n",
      "Batch: 2349. Acc: 0.404661. Loss: 1.669455. Batch_acc: 0.429392. Batch_loss: 1.595812 \n",
      "Batch: 2350. Acc: 0.404669. Loss: 1.669427. Batch_acc: 0.423320. Batch_loss: 1.605767 \n",
      "Batch: 2351. Acc: 0.404674. Loss: 1.669398. Batch_acc: 0.416955. Batch_loss: 1.599223 \n",
      "Batch: 2352. Acc: 0.404675. Loss: 1.669393. Batch_acc: 0.408434. Batch_loss: 1.657635 \n",
      "Batch: 2353. Acc: 0.404676. Loss: 1.669387. Batch_acc: 0.407038. Batch_loss: 1.654674 \n",
      "Batch: 2354. Acc: 0.404677. Loss: 1.669380. Batch_acc: 0.407281. Batch_loss: 1.655271 \n",
      "Batch: 2355. Acc: 0.404680. Loss: 1.669376. Batch_acc: 0.410600. Batch_loss: 1.658805 \n",
      "Batch: 2356. Acc: 0.404689. Loss: 1.669346. Batch_acc: 0.426941. Batch_loss: 1.599441 \n",
      "Batch: 2357. Acc: 0.404698. Loss: 1.669320. Batch_acc: 0.425014. Batch_loss: 1.607749 \n",
      "Batch: 2358. Acc: 0.404700. Loss: 1.669320. Batch_acc: 0.410600. Batch_loss: 1.669616 \n",
      "Batch: 2359. Acc: 0.404705. Loss: 1.669308. Batch_acc: 0.415323. Batch_loss: 1.641408 \n",
      "Batch: 2360. Acc: 0.404702. Loss: 1.669304. Batch_acc: 0.397406. Batch_loss: 1.657553 \n",
      "Batch: 2361. Acc: 0.404710. Loss: 1.669283. Batch_acc: 0.423099. Batch_loss: 1.622518 \n",
      "Batch: 2362. Acc: 0.404722. Loss: 1.669244. Batch_acc: 0.433066. Batch_loss: 1.575774 \n",
      "Batch: 2363. Acc: 0.404749. Loss: 1.669182. Batch_acc: 0.467733. Batch_loss: 1.524540 \n",
      "Batch: 2364. Acc: 0.404766. Loss: 1.669138. Batch_acc: 0.444444. Batch_loss: 1.565574 \n",
      "Batch: 2365. Acc: 0.404767. Loss: 1.669127. Batch_acc: 0.407110. Batch_loss: 1.643560 \n",
      "Batch: 2366. Acc: 0.404770. Loss: 1.669123. Batch_acc: 0.412281. Batch_loss: 1.659033 \n",
      "Batch: 2367. Acc: 0.404773. Loss: 1.669105. Batch_acc: 0.412240. Batch_loss: 1.626509 \n",
      "Batch: 2368. Acc: 0.404784. Loss: 1.669080. Batch_acc: 0.430380. Batch_loss: 1.610816 \n",
      "Batch: 2369. Acc: 0.404789. Loss: 1.669061. Batch_acc: 0.417678. Batch_loss: 1.622800 \n",
      "Batch: 2370. Acc: 0.404799. Loss: 1.669024. Batch_acc: 0.427602. Batch_loss: 1.582771 \n",
      "Batch: 2371. Acc: 0.404813. Loss: 1.668994. Batch_acc: 0.437681. Batch_loss: 1.598599 \n",
      "Batch: 2372. Acc: 0.404824. Loss: 1.668959. Batch_acc: 0.430796. Batch_loss: 1.585602 \n",
      "Batch: 2373. Acc: 0.404826. Loss: 1.668949. Batch_acc: 0.409759. Batch_loss: 1.643060 \n",
      "Batch: 2374. Acc: 0.404828. Loss: 1.668951. Batch_acc: 0.411014. Batch_loss: 1.673830 \n",
      "Batch: 2375. Acc: 0.404837. Loss: 1.668919. Batch_acc: 0.426907. Batch_loss: 1.592215 \n",
      "Batch: 2376. Acc: 0.404857. Loss: 1.668865. Batch_acc: 0.450456. Batch_loss: 1.542408 \n",
      "Batch: 2377. Acc: 0.404864. Loss: 1.668845. Batch_acc: 0.420870. Batch_loss: 1.620415 \n",
      "Batch: 2378. Acc: 0.404868. Loss: 1.668822. Batch_acc: 0.415882. Batch_loss: 1.612068 \n",
      "Batch: 2379. Acc: 0.404880. Loss: 1.668774. Batch_acc: 0.432644. Batch_loss: 1.558657 \n",
      "Batch: 2380. Acc: 0.404894. Loss: 1.668739. Batch_acc: 0.439053. Batch_loss: 1.583023 \n",
      "Batch: 2381. Acc: 0.404899. Loss: 1.668729. Batch_acc: 0.417442. Batch_loss: 1.644638 \n",
      "Batch: 2382. Acc: 0.404910. Loss: 1.668700. Batch_acc: 0.430120. Batch_loss: 1.600119 \n",
      "Batch: 2383. Acc: 0.404915. Loss: 1.668680. Batch_acc: 0.417678. Batch_loss: 1.621556 \n",
      "Batch: 2384. Acc: 0.404920. Loss: 1.668661. Batch_acc: 0.416862. Batch_loss: 1.621739 \n",
      "Batch: 2385. Acc: 0.404921. Loss: 1.668654. Batch_acc: 0.406760. Batch_loss: 1.651884 \n",
      "Batch: 2386. Acc: 0.404929. Loss: 1.668623. Batch_acc: 0.425408. Batch_loss: 1.594380 \n",
      "Batch: 2387. Acc: 0.404927. Loss: 1.668617. Batch_acc: 0.398424. Batch_loss: 1.654418 \n",
      "Batch: 2388. Acc: 0.404941. Loss: 1.668581. Batch_acc: 0.439907. Batch_loss: 1.581193 \n",
      "Batch: 2389. Acc: 0.404941. Loss: 1.668560. Batch_acc: 0.405533. Batch_loss: 1.616914 \n",
      "Batch: 2390. Acc: 0.404953. Loss: 1.668513. Batch_acc: 0.433198. Batch_loss: 1.555860 \n",
      "Batch: 2391. Acc: 0.404970. Loss: 1.668469. Batch_acc: 0.444952. Batch_loss: 1.563286 \n",
      "Batch: 2392. Acc: 0.404990. Loss: 1.668420. Batch_acc: 0.451774. Batch_loss: 1.556104 \n",
      "Batch: 2393. Acc: 0.404994. Loss: 1.668409. Batch_acc: 0.413434. Batch_loss: 1.642282 \n",
      "Batch: 2394. Acc: 0.404995. Loss: 1.668401. Batch_acc: 0.407216. Batch_loss: 1.649644 \n",
      "Batch: 2395. Acc: 0.405003. Loss: 1.668378. Batch_acc: 0.424348. Batch_loss: 1.613307 \n",
      "Batch: 2396. Acc: 0.405012. Loss: 1.668356. Batch_acc: 0.427463. Batch_loss: 1.611787 \n",
      "Batch: 2397. Acc: 0.405024. Loss: 1.668328. Batch_acc: 0.435233. Batch_loss: 1.602061 \n",
      "Batch: 2398. Acc: 0.405035. Loss: 1.668283. Batch_acc: 0.429692. Batch_loss: 1.564538 \n",
      "Batch: 2399. Acc: 0.405036. Loss: 1.668272. Batch_acc: 0.408931. Batch_loss: 1.639943 \n",
      "Batch: 2400. Acc: 0.405046. Loss: 1.668238. Batch_acc: 0.428404. Batch_loss: 1.585219 \n",
      "Batch: 2401. Acc: 0.405047. Loss: 1.668234. Batch_acc: 0.408426. Batch_loss: 1.659114 \n",
      "Batch: 2402. Acc: 0.405054. Loss: 1.668223. Batch_acc: 0.420991. Batch_loss: 1.640044 \n",
      "Batch: 2403. Acc: 0.405057. Loss: 1.668209. Batch_acc: 0.412870. Batch_loss: 1.636870 \n",
      "Batch: 2404. Acc: 0.405061. Loss: 1.668188. Batch_acc: 0.413773. Batch_loss: 1.615472 \n",
      "Batch: 2405. Acc: 0.405061. Loss: 1.668175. Batch_acc: 0.405993. Batch_loss: 1.638287 \n",
      "Batch: 2406. Acc: 0.405078. Loss: 1.668131. Batch_acc: 0.445614. Batch_loss: 1.560613 \n",
      "Batch: 2407. Acc: 0.405087. Loss: 1.668099. Batch_acc: 0.427018. Batch_loss: 1.589646 \n",
      "Batch: 2408. Acc: 0.405097. Loss: 1.668065. Batch_acc: 0.429780. Batch_loss: 1.589225 \n",
      "Batch: 2409. Acc: 0.405107. Loss: 1.668032. Batch_acc: 0.429316. Batch_loss: 1.587328 \n",
      "Batch: 2410. Acc: 0.405112. Loss: 1.668012. Batch_acc: 0.417146. Batch_loss: 1.619388 \n",
      "Batch: 2411. Acc: 0.405116. Loss: 1.668007. Batch_acc: 0.414718. Batch_loss: 1.656425 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2412. Acc: 0.405118. Loss: 1.667999. Batch_acc: 0.409827. Batch_loss: 1.647586 \n",
      "Batch: 2413. Acc: 0.405136. Loss: 1.667954. Batch_acc: 0.447309. Batch_loss: 1.562369 \n",
      "Batch: 2414. Acc: 0.405142. Loss: 1.667927. Batch_acc: 0.419908. Batch_loss: 1.604572 \n",
      "Batch: 2415. Acc: 0.405152. Loss: 1.667902. Batch_acc: 0.428084. Batch_loss: 1.607354 \n",
      "Batch: 2416. Acc: 0.405152. Loss: 1.667894. Batch_acc: 0.405122. Batch_loss: 1.648915 \n",
      "Batch: 2417. Acc: 0.405154. Loss: 1.667884. Batch_acc: 0.409247. Batch_loss: 1.643295 \n",
      "Batch: 2418. Acc: 0.405162. Loss: 1.667857. Batch_acc: 0.425799. Batch_loss: 1.604128 \n",
      "Batch: 2419. Acc: 0.405173. Loss: 1.667828. Batch_acc: 0.430387. Batch_loss: 1.596323 \n",
      "Batch: 2420. Acc: 0.405181. Loss: 1.667804. Batch_acc: 0.424036. Batch_loss: 1.611186 \n",
      "Batch: 2421. Acc: 0.405190. Loss: 1.667775. Batch_acc: 0.428740. Batch_loss: 1.595136 \n",
      "Batch: 2422. Acc: 0.405195. Loss: 1.667758. Batch_acc: 0.416716. Batch_loss: 1.626674 \n",
      "Batch: 2423. Acc: 0.405210. Loss: 1.667714. Batch_acc: 0.442352. Batch_loss: 1.560221 \n",
      "Batch: 2424. Acc: 0.405220. Loss: 1.667688. Batch_acc: 0.429901. Batch_loss: 1.604280 \n",
      "Batch: 2425. Acc: 0.405236. Loss: 1.667650. Batch_acc: 0.443678. Batch_loss: 1.576943 \n",
      "Batch: 2426. Acc: 0.405251. Loss: 1.667610. Batch_acc: 0.441468. Batch_loss: 1.567704 \n",
      "Batch: 2427. Acc: 0.405260. Loss: 1.667565. Batch_acc: 0.426667. Batch_loss: 1.559299 \n",
      "Batch: 2428. Acc: 0.405267. Loss: 1.667545. Batch_acc: 0.423690. Batch_loss: 1.617825 \n",
      "Batch: 2429. Acc: 0.405273. Loss: 1.667520. Batch_acc: 0.420188. Batch_loss: 1.606029 \n",
      "Batch: 2430. Acc: 0.405277. Loss: 1.667504. Batch_acc: 0.414789. Batch_loss: 1.628303 \n",
      "Batch: 2431. Acc: 0.405286. Loss: 1.667481. Batch_acc: 0.427119. Batch_loss: 1.613448 \n",
      "Batch: 2432. Acc: 0.405304. Loss: 1.667437. Batch_acc: 0.446459. Batch_loss: 1.561321 \n",
      "Batch: 2433. Acc: 0.405309. Loss: 1.667421. Batch_acc: 0.419633. Batch_loss: 1.629800 \n",
      "Batch: 2434. Acc: 0.405320. Loss: 1.667398. Batch_acc: 0.430564. Batch_loss: 1.609710 \n",
      "Batch: 2435. Acc: 0.405322. Loss: 1.667382. Batch_acc: 0.409666. Batch_loss: 1.627793 \n",
      "Batch: 2436. Acc: 0.405330. Loss: 1.667356. Batch_acc: 0.425071. Batch_loss: 1.604738 \n",
      "Batch: 2437. Acc: 0.405330. Loss: 1.667352. Batch_acc: 0.405248. Batch_loss: 1.659639 \n",
      "Batch: 2438. Acc: 0.405345. Loss: 1.667330. Batch_acc: 0.444183. Batch_loss: 1.611100 \n",
      "Batch: 2439. Acc: 0.405345. Loss: 1.667327. Batch_acc: 0.403559. Batch_loss: 1.660896 \n",
      "Batch: 2440. Acc: 0.405347. Loss: 1.667324. Batch_acc: 0.411231. Batch_loss: 1.659220 \n",
      "Batch: 2441. Acc: 0.405350. Loss: 1.667300. Batch_acc: 0.412930. Batch_loss: 1.607619 \n",
      "Batch: 2442. Acc: 0.405362. Loss: 1.667266. Batch_acc: 0.433749. Batch_loss: 1.585438 \n",
      "Batch: 2443. Acc: 0.405377. Loss: 1.667234. Batch_acc: 0.442297. Batch_loss: 1.590462 \n",
      "Batch: 2444. Acc: 0.405387. Loss: 1.667218. Batch_acc: 0.428490. Batch_loss: 1.628243 \n",
      "Batch: 2445. Acc: 0.405391. Loss: 1.667203. Batch_acc: 0.417249. Batch_loss: 1.630818 \n",
      "Batch: 2446. Acc: 0.405408. Loss: 1.667157. Batch_acc: 0.446809. Batch_loss: 1.554030 \n",
      "Batch: 2447. Acc: 0.405408. Loss: 1.667149. Batch_acc: 0.403569. Batch_loss: 1.648107 \n",
      "Batch: 2448. Acc: 0.405410. Loss: 1.667126. Batch_acc: 0.410734. Batch_loss: 1.610537 \n",
      "Batch: 2449. Acc: 0.405418. Loss: 1.667094. Batch_acc: 0.424140. Batch_loss: 1.591401 \n",
      "Batch: 2450. Acc: 0.405429. Loss: 1.667064. Batch_acc: 0.433161. Batch_loss: 1.593113 \n",
      "Batch: 2451. Acc: 0.405441. Loss: 1.667035. Batch_acc: 0.435006. Batch_loss: 1.597500 \n",
      "Batch: 2452. Acc: 0.405437. Loss: 1.667036. Batch_acc: 0.395870. Batch_loss: 1.669405 \n",
      "Batch: 2453. Acc: 0.405440. Loss: 1.667032. Batch_acc: 0.412214. Batch_loss: 1.655632 \n",
      "Batch: 2454. Acc: 0.405451. Loss: 1.667007. Batch_acc: 0.431350. Batch_loss: 1.606423 \n",
      "Batch: 2455. Acc: 0.405457. Loss: 1.666977. Batch_acc: 0.422055. Batch_loss: 1.594636 \n",
      "Batch: 2456. Acc: 0.405465. Loss: 1.666946. Batch_acc: 0.424363. Batch_loss: 1.590525 \n",
      "Batch: 2457. Acc: 0.405467. Loss: 1.666945. Batch_acc: 0.408881. Batch_loss: 1.664976 \n",
      "Batch: 2458. Acc: 0.405469. Loss: 1.666944. Batch_acc: 0.412485. Batch_loss: 1.664115 \n",
      "Batch: 2459. Acc: 0.405484. Loss: 1.666909. Batch_acc: 0.440181. Batch_loss: 1.584056 \n",
      "Batch: 2460. Acc: 0.405489. Loss: 1.666903. Batch_acc: 0.418485. Batch_loss: 1.651240 \n",
      "Batch: 2461. Acc: 0.405496. Loss: 1.666879. Batch_acc: 0.422105. Batch_loss: 1.607175 \n",
      "Batch: 2462. Acc: 0.405504. Loss: 1.666858. Batch_acc: 0.425580. Batch_loss: 1.614896 \n",
      "Batch: 2463. Acc: 0.405510. Loss: 1.666845. Batch_acc: 0.419839. Batch_loss: 1.635898 \n",
      "Batch: 2464. Acc: 0.405517. Loss: 1.666820. Batch_acc: 0.422819. Batch_loss: 1.605629 \n",
      "Batch: 2465. Acc: 0.405518. Loss: 1.666802. Batch_acc: 0.408780. Batch_loss: 1.624458 \n",
      "Batch: 2466. Acc: 0.405525. Loss: 1.666784. Batch_acc: 0.421454. Batch_loss: 1.620251 \n",
      "Batch: 2467. Acc: 0.405540. Loss: 1.666754. Batch_acc: 0.443407. Batch_loss: 1.591529 \n",
      "Batch: 2468. Acc: 0.405541. Loss: 1.666739. Batch_acc: 0.407666. Batch_loss: 1.629516 \n",
      "Batch: 2469. Acc: 0.405544. Loss: 1.666742. Batch_acc: 0.414409. Batch_loss: 1.673761 \n",
      "Batch: 2470. Acc: 0.405556. Loss: 1.666710. Batch_acc: 0.434286. Batch_loss: 1.587911 \n",
      "Batch: 2471. Acc: 0.405559. Loss: 1.666701. Batch_acc: 0.412877. Batch_loss: 1.644892 \n",
      "Batch: 2472. Acc: 0.405562. Loss: 1.666695. Batch_acc: 0.414466. Batch_loss: 1.652005 \n",
      "Batch: 2473. Acc: 0.405570. Loss: 1.666667. Batch_acc: 0.422622. Batch_loss: 1.597647 \n",
      "Batch: 2474. Acc: 0.405579. Loss: 1.666633. Batch_acc: 0.428979. Batch_loss: 1.584395 \n",
      "Batch: 2475. Acc: 0.405588. Loss: 1.666593. Batch_acc: 0.426629. Batch_loss: 1.568200 \n",
      "Batch: 2476. Acc: 0.405593. Loss: 1.666576. Batch_acc: 0.419847. Batch_loss: 1.623325 \n",
      "Batch: 2477. Acc: 0.405604. Loss: 1.666545. Batch_acc: 0.431920. Batch_loss: 1.593470 \n",
      "Batch: 2478. Acc: 0.405610. Loss: 1.666533. Batch_acc: 0.420323. Batch_loss: 1.636775 \n",
      "Batch: 2479. Acc: 0.405616. Loss: 1.666512. Batch_acc: 0.419467. Batch_loss: 1.613019 \n",
      "Batch: 2480. Acc: 0.405622. Loss: 1.666494. Batch_acc: 0.421902. Batch_loss: 1.621523 \n",
      "Batch: 2481. Acc: 0.405632. Loss: 1.666458. Batch_acc: 0.429954. Batch_loss: 1.580142 \n",
      "Batch: 2482. Acc: 0.405634. Loss: 1.666448. Batch_acc: 0.409562. Batch_loss: 1.640378 \n",
      "Batch: 2483. Acc: 0.405645. Loss: 1.666417. Batch_acc: 0.432671. Batch_loss: 1.591985 \n",
      "Batch: 2484. Acc: 0.405660. Loss: 1.666366. Batch_acc: 0.441860. Batch_loss: 1.542139 \n",
      "Batch: 2485. Acc: 0.405667. Loss: 1.666342. Batch_acc: 0.422503. Batch_loss: 1.606641 \n",
      "Batch: 2486. Acc: 0.405677. Loss: 1.666313. Batch_acc: 0.430226. Batch_loss: 1.593528 \n",
      "Batch: 2487. Acc: 0.405686. Loss: 1.666287. Batch_acc: 0.428330. Batch_loss: 1.603556 \n",
      "Batch: 2488. Acc: 0.405693. Loss: 1.666263. Batch_acc: 0.423856. Batch_loss: 1.606313 \n",
      "Batch: 2489. Acc: 0.405699. Loss: 1.666232. Batch_acc: 0.420778. Batch_loss: 1.588420 \n",
      "Batch: 2490. Acc: 0.405716. Loss: 1.666180. Batch_acc: 0.447475. Batch_loss: 1.536103 \n",
      "Batch: 2491. Acc: 0.405719. Loss: 1.666167. Batch_acc: 0.413994. Batch_loss: 1.632549 \n",
      "Batch: 2492. Acc: 0.405741. Loss: 1.666107. Batch_acc: 0.459213. Batch_loss: 1.518266 \n",
      "Batch: 2493. Acc: 0.405751. Loss: 1.666084. Batch_acc: 0.430516. Batch_loss: 1.607760 \n",
      "Batch: 2494. Acc: 0.405762. Loss: 1.666041. Batch_acc: 0.433679. Batch_loss: 1.558617 \n",
      "Batch: 2495. Acc: 0.405767. Loss: 1.666027. Batch_acc: 0.418994. Batch_loss: 1.633662 \n",
      "Batch: 2496. Acc: 0.405771. Loss: 1.666010. Batch_acc: 0.415127. Batch_loss: 1.623925 \n",
      "Batch: 2497. Acc: 0.405775. Loss: 1.666002. Batch_acc: 0.416569. Batch_loss: 1.645242 \n",
      "Batch: 2498. Acc: 0.405787. Loss: 1.665972. Batch_acc: 0.435294. Batch_loss: 1.592304 \n",
      "Batch: 2499. Acc: 0.405796. Loss: 1.665939. Batch_acc: 0.428243. Batch_loss: 1.583371 \n",
      "Batch: 2500. Acc: 0.405795. Loss: 1.665936. Batch_acc: 0.402770. Batch_loss: 1.657690 \n",
      "Batch: 2501. Acc: 0.405804. Loss: 1.665911. Batch_acc: 0.426570. Batch_loss: 1.605080 \n",
      "Batch: 2502. Acc: 0.405811. Loss: 1.665881. Batch_acc: 0.423926. Batch_loss: 1.591672 \n",
      "Batch: 2503. Acc: 0.405818. Loss: 1.665849. Batch_acc: 0.424191. Batch_loss: 1.585432 \n",
      "Batch: 2504. Acc: 0.405827. Loss: 1.665835. Batch_acc: 0.428078. Batch_loss: 1.631229 \n",
      "Batch: 2505. Acc: 0.405827. Loss: 1.665830. Batch_acc: 0.403970. Batch_loss: 1.652927 \n",
      "Batch: 2506. Acc: 0.405838. Loss: 1.665793. Batch_acc: 0.433314. Batch_loss: 1.573003 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2507. Acc: 0.405845. Loss: 1.665779. Batch_acc: 0.423253. Batch_loss: 1.632751 \n",
      "Batch: 2508. Acc: 0.405851. Loss: 1.665747. Batch_acc: 0.422145. Batch_loss: 1.584323 \n",
      "Batch: 2509. Acc: 0.405857. Loss: 1.665733. Batch_acc: 0.420593. Batch_loss: 1.629211 \n",
      "Batch: 2510. Acc: 0.405866. Loss: 1.665715. Batch_acc: 0.427920. Batch_loss: 1.621565 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.40586567507844157. Loss per char: 1.665714741661791. Time: 1627212316.9207256\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 21, 19, 19, 20, 20, 23, 22, 19, 26,\n",
      "        25, 26, 26,  1, 77, 70, 84, 84,  1, 85, 73, 66, 79,  1, 21, 22, 15, 21,\n",
      "        32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.405868. Loss: 1.665705. Batch_acc: 0.411731. Batch_loss: 1.642363 \n",
      "Batch: 2512. Acc: 0.405877. Loss: 1.665689. Batch_acc: 0.429243. Batch_loss: 1.623627 \n",
      "Batch: 2513. Acc: 0.405889. Loss: 1.665648. Batch_acc: 0.436604. Batch_loss: 1.562390 \n",
      "Batch: 2514. Acc: 0.405898. Loss: 1.665631. Batch_acc: 0.428738. Batch_loss: 1.622296 \n",
      "Batch: 2515. Acc: 0.405898. Loss: 1.665617. Batch_acc: 0.406103. Batch_loss: 1.629704 \n",
      "Batch: 2516. Acc: 0.405896. Loss: 1.665613. Batch_acc: 0.400227. Batch_loss: 1.655379 \n",
      "Batch: 2517. Acc: 0.405910. Loss: 1.665573. Batch_acc: 0.441040. Batch_loss: 1.565196 \n",
      "Batch: 2518. Acc: 0.405917. Loss: 1.665541. Batch_acc: 0.424225. Batch_loss: 1.586610 \n",
      "Batch: 2519. Acc: 0.405929. Loss: 1.665515. Batch_acc: 0.435164. Batch_loss: 1.599808 \n",
      "Batch: 2520. Acc: 0.405944. Loss: 1.665487. Batch_acc: 0.445100. Batch_loss: 1.592488 \n",
      "Batch: 2521. Acc: 0.405957. Loss: 1.665460. Batch_acc: 0.440023. Batch_loss: 1.595948 \n",
      "Batch: 2522. Acc: 0.405966. Loss: 1.665436. Batch_acc: 0.428738. Batch_loss: 1.604364 \n",
      "Batch: 2523. Acc: 0.405979. Loss: 1.665394. Batch_acc: 0.437607. Batch_loss: 1.561765 \n",
      "Batch: 2524. Acc: 0.405991. Loss: 1.665361. Batch_acc: 0.436960. Batch_loss: 1.580704 \n",
      "Batch: 2525. Acc: 0.406000. Loss: 1.665332. Batch_acc: 0.427666. Batch_loss: 1.591138 \n",
      "Batch: 2526. Acc: 0.406006. Loss: 1.665295. Batch_acc: 0.422616. Batch_loss: 1.574434 \n",
      "Batch: 2527. Acc: 0.406018. Loss: 1.665259. Batch_acc: 0.436086. Batch_loss: 1.575459 \n",
      "Batch: 2528. Acc: 0.406022. Loss: 1.665254. Batch_acc: 0.414374. Batch_loss: 1.653650 \n",
      "Batch: 2529. Acc: 0.406022. Loss: 1.665247. Batch_acc: 0.407471. Batch_loss: 1.646262 \n",
      "Batch: 2530. Acc: 0.406037. Loss: 1.665215. Batch_acc: 0.442263. Batch_loss: 1.583586 \n",
      "Batch: 2531. Acc: 0.406051. Loss: 1.665183. Batch_acc: 0.442185. Batch_loss: 1.584435 \n",
      "Batch: 2532. Acc: 0.406055. Loss: 1.665180. Batch_acc: 0.416378. Batch_loss: 1.656294 \n",
      "Batch: 2533. Acc: 0.406063. Loss: 1.665147. Batch_acc: 0.426379. Batch_loss: 1.583276 \n",
      "Batch: 2534. Acc: 0.406069. Loss: 1.665127. Batch_acc: 0.422209. Batch_loss: 1.615308 \n",
      "Batch: 2535. Acc: 0.406083. Loss: 1.665093. Batch_acc: 0.440835. Batch_loss: 1.576984 \n",
      "Batch: 2536. Acc: 0.406079. Loss: 1.665108. Batch_acc: 0.396303. Batch_loss: 1.702967 \n",
      "Batch: 2537. Acc: 0.406079. Loss: 1.665108. Batch_acc: 0.405958. Batch_loss: 1.665280 \n",
      "Batch: 2538. Acc: 0.406087. Loss: 1.665085. Batch_acc: 0.426117. Batch_loss: 1.607576 \n",
      "Batch: 2539. Acc: 0.406091. Loss: 1.665065. Batch_acc: 0.415358. Batch_loss: 1.614510 \n",
      "Batch: 2540. Acc: 0.406098. Loss: 1.665046. Batch_acc: 0.423982. Batch_loss: 1.614765 \n",
      "Batch: 2541. Acc: 0.406109. Loss: 1.665022. Batch_acc: 0.434050. Batch_loss: 1.605524 \n",
      "Batch: 2542. Acc: 0.406120. Loss: 1.664990. Batch_acc: 0.435437. Batch_loss: 1.582074 \n",
      "Batch: 2543. Acc: 0.406123. Loss: 1.664969. Batch_acc: 0.412907. Batch_loss: 1.611784 \n",
      "Batch: 2544. Acc: 0.406129. Loss: 1.664951. Batch_acc: 0.422045. Batch_loss: 1.618985 \n",
      "Batch: 2545. Acc: 0.406136. Loss: 1.664922. Batch_acc: 0.423292. Batch_loss: 1.594029 \n",
      "Batch: 2546. Acc: 0.406139. Loss: 1.664908. Batch_acc: 0.414016. Batch_loss: 1.626840 \n",
      "Batch: 2547. Acc: 0.406145. Loss: 1.664892. Batch_acc: 0.422543. Batch_loss: 1.625202 \n",
      "Batch: 2548. Acc: 0.406157. Loss: 1.664853. Batch_acc: 0.436280. Batch_loss: 1.565324 \n",
      "Batch: 2549. Acc: 0.406169. Loss: 1.664823. Batch_acc: 0.437609. Batch_loss: 1.586903 \n",
      "Batch: 2550. Acc: 0.406172. Loss: 1.664805. Batch_acc: 0.413793. Batch_loss: 1.618991 \n",
      "Batch: 2551. Acc: 0.406182. Loss: 1.664787. Batch_acc: 0.431257. Batch_loss: 1.619543 \n",
      "Batch: 2552. Acc: 0.406188. Loss: 1.664763. Batch_acc: 0.421992. Batch_loss: 1.602993 \n",
      "Batch: 2553. Acc: 0.406195. Loss: 1.664753. Batch_acc: 0.422815. Batch_loss: 1.639799 \n",
      "Batch: 2554. Acc: 0.406199. Loss: 1.664730. Batch_acc: 0.417744. Batch_loss: 1.604754 \n",
      "Batch: 2555. Acc: 0.406201. Loss: 1.664726. Batch_acc: 0.411799. Batch_loss: 1.654269 \n",
      "Batch: 2556. Acc: 0.406221. Loss: 1.664681. Batch_acc: 0.454958. Batch_loss: 1.550816 \n",
      "Batch: 2557. Acc: 0.406233. Loss: 1.664628. Batch_acc: 0.437710. Batch_loss: 1.531868 \n",
      "Batch: 2558. Acc: 0.406235. Loss: 1.664612. Batch_acc: 0.411295. Batch_loss: 1.625615 \n",
      "Batch: 2559. Acc: 0.406251. Loss: 1.664566. Batch_acc: 0.444761. Batch_loss: 1.546978 \n",
      "Batch: 2560. Acc: 0.406264. Loss: 1.664526. Batch_acc: 0.440805. Batch_loss: 1.562926 \n",
      "Batch: 2561. Acc: 0.406270. Loss: 1.664494. Batch_acc: 0.422184. Batch_loss: 1.582513 \n",
      "Batch: 2562. Acc: 0.406266. Loss: 1.664489. Batch_acc: 0.393868. Batch_loss: 1.649264 \n",
      "Batch: 2563. Acc: 0.406278. Loss: 1.664449. Batch_acc: 0.436788. Batch_loss: 1.563719 \n",
      "Batch: 2564. Acc: 0.406292. Loss: 1.664430. Batch_acc: 0.444062. Batch_loss: 1.615135 \n",
      "Batch: 2565. Acc: 0.406298. Loss: 1.664417. Batch_acc: 0.420507. Batch_loss: 1.632049 \n",
      "Batch: 2566. Acc: 0.406308. Loss: 1.664391. Batch_acc: 0.432203. Batch_loss: 1.599577 \n",
      "Batch: 2567. Acc: 0.406322. Loss: 1.664368. Batch_acc: 0.443103. Batch_loss: 1.603778 \n",
      "Batch: 2568. Acc: 0.406336. Loss: 1.664335. Batch_acc: 0.440462. Batch_loss: 1.579260 \n",
      "Batch: 2569. Acc: 0.406343. Loss: 1.664311. Batch_acc: 0.424242. Batch_loss: 1.603379 \n",
      "Batch: 2570. Acc: 0.406344. Loss: 1.664289. Batch_acc: 0.410795. Batch_loss: 1.608863 \n",
      "Batch: 2571. Acc: 0.406351. Loss: 1.664267. Batch_acc: 0.424032. Batch_loss: 1.606516 \n",
      "Batch: 2572. Acc: 0.406358. Loss: 1.664249. Batch_acc: 0.423889. Batch_loss: 1.619302 \n",
      "Batch: 2573. Acc: 0.406368. Loss: 1.664216. Batch_acc: 0.431475. Batch_loss: 1.578861 \n",
      "Batch: 2574. Acc: 0.406380. Loss: 1.664184. Batch_acc: 0.438035. Batch_loss: 1.582258 \n",
      "Batch: 2575. Acc: 0.406391. Loss: 1.664154. Batch_acc: 0.431643. Batch_loss: 1.589906 \n",
      "Batch: 2576. Acc: 0.406390. Loss: 1.664143. Batch_acc: 0.405467. Batch_loss: 1.635649 \n",
      "Batch: 2577. Acc: 0.406405. Loss: 1.664117. Batch_acc: 0.443396. Batch_loss: 1.599516 \n",
      "Batch: 2578. Acc: 0.406419. Loss: 1.664077. Batch_acc: 0.442242. Batch_loss: 1.563092 \n",
      "Batch: 2579. Acc: 0.406424. Loss: 1.664056. Batch_acc: 0.419943. Batch_loss: 1.611004 \n",
      "Batch: 2580. Acc: 0.406437. Loss: 1.664018. Batch_acc: 0.437326. Batch_loss: 1.569129 \n",
      "Batch: 2581. Acc: 0.406443. Loss: 1.663996. Batch_acc: 0.423543. Batch_loss: 1.606143 \n",
      "Batch: 2582. Acc: 0.406445. Loss: 1.663978. Batch_acc: 0.409639. Batch_loss: 1.617386 \n",
      "Batch: 2583. Acc: 0.406450. Loss: 1.663963. Batch_acc: 0.419628. Batch_loss: 1.625535 \n",
      "Batch: 2584. Acc: 0.406451. Loss: 1.663947. Batch_acc: 0.409639. Batch_loss: 1.622646 \n",
      "Batch: 2585. Acc: 0.406461. Loss: 1.663915. Batch_acc: 0.430986. Batch_loss: 1.582965 \n",
      "Batch: 2586. Acc: 0.406473. Loss: 1.663882. Batch_acc: 0.437814. Batch_loss: 1.582723 \n",
      "Batch: 2587. Acc: 0.406483. Loss: 1.663847. Batch_acc: 0.431172. Batch_loss: 1.572606 \n",
      "Batch: 2588. Acc: 0.406488. Loss: 1.663818. Batch_acc: 0.418172. Batch_loss: 1.592139 \n",
      "Batch: 2589. Acc: 0.406493. Loss: 1.663801. Batch_acc: 0.420658. Batch_loss: 1.618543 \n",
      "Batch: 2590. Acc: 0.406504. Loss: 1.663773. Batch_acc: 0.433865. Batch_loss: 1.592705 \n",
      "Batch: 2591. Acc: 0.406506. Loss: 1.663763. Batch_acc: 0.412347. Batch_loss: 1.637507 \n",
      "Batch: 2592. Acc: 0.406522. Loss: 1.663716. Batch_acc: 0.448103. Batch_loss: 1.544058 \n",
      "Batch: 2593. Acc: 0.406534. Loss: 1.663684. Batch_acc: 0.437217. Batch_loss: 1.582206 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2594. Acc: 0.406537. Loss: 1.663671. Batch_acc: 0.414261. Batch_loss: 1.631047 \n",
      "Batch: 2595. Acc: 0.406543. Loss: 1.663661. Batch_acc: 0.421323. Batch_loss: 1.638474 \n",
      "Batch: 2596. Acc: 0.406561. Loss: 1.663618. Batch_acc: 0.453855. Batch_loss: 1.550327 \n",
      "Batch: 2597. Acc: 0.406581. Loss: 1.663557. Batch_acc: 0.456410. Batch_loss: 1.504930 \n",
      "Batch: 2598. Acc: 0.406598. Loss: 1.663519. Batch_acc: 0.450395. Batch_loss: 1.567602 \n",
      "Batch: 2599. Acc: 0.406599. Loss: 1.663503. Batch_acc: 0.410562. Batch_loss: 1.623708 \n",
      "Batch: 2600. Acc: 0.406619. Loss: 1.663469. Batch_acc: 0.456734. Batch_loss: 1.574408 \n",
      "Batch: 2601. Acc: 0.406631. Loss: 1.663429. Batch_acc: 0.437183. Batch_loss: 1.562560 \n",
      "Batch: 2602. Acc: 0.406641. Loss: 1.663400. Batch_acc: 0.433721. Batch_loss: 1.584994 \n",
      "Batch: 2603. Acc: 0.406653. Loss: 1.663372. Batch_acc: 0.436374. Batch_loss: 1.594012 \n",
      "Batch: 2604. Acc: 0.406657. Loss: 1.663348. Batch_acc: 0.417520. Batch_loss: 1.601674 \n",
      "Batch: 2605. Acc: 0.406663. Loss: 1.663326. Batch_acc: 0.421625. Batch_loss: 1.604742 \n",
      "Batch: 2606. Acc: 0.406661. Loss: 1.663328. Batch_acc: 0.401388. Batch_loss: 1.670081 \n",
      "Batch: 2607. Acc: 0.406664. Loss: 1.663312. Batch_acc: 0.415934. Batch_loss: 1.619834 \n",
      "Batch: 2608. Acc: 0.406673. Loss: 1.663283. Batch_acc: 0.429960. Batch_loss: 1.589080 \n",
      "Batch: 2609. Acc: 0.406684. Loss: 1.663249. Batch_acc: 0.435809. Batch_loss: 1.573075 \n",
      "Batch: 2610. Acc: 0.406687. Loss: 1.663246. Batch_acc: 0.413421. Batch_loss: 1.654353 \n",
      "Batch: 2611. Acc: 0.406694. Loss: 1.663224. Batch_acc: 0.425307. Batch_loss: 1.609800 \n",
      "Batch: 2612. Acc: 0.406699. Loss: 1.663195. Batch_acc: 0.419319. Batch_loss: 1.588133 \n",
      "Batch: 2613. Acc: 0.406717. Loss: 1.663149. Batch_acc: 0.452894. Batch_loss: 1.544346 \n",
      "Batch: 2614. Acc: 0.406726. Loss: 1.663133. Batch_acc: 0.431182. Batch_loss: 1.623517 \n",
      "Batch: 2615. Acc: 0.406734. Loss: 1.663113. Batch_acc: 0.427759. Batch_loss: 1.609981 \n",
      "Batch: 2616. Acc: 0.406740. Loss: 1.663085. Batch_acc: 0.420347. Batch_loss: 1.591537 \n",
      "Batch: 2617. Acc: 0.406744. Loss: 1.663064. Batch_acc: 0.417627. Batch_loss: 1.609701 \n",
      "Batch: 2618. Acc: 0.406753. Loss: 1.663035. Batch_acc: 0.429780. Batch_loss: 1.587538 \n",
      "Batch: 2619. Acc: 0.406751. Loss: 1.663028. Batch_acc: 0.402418. Batch_loss: 1.644683 \n",
      "Batch: 2620. Acc: 0.406762. Loss: 1.663005. Batch_acc: 0.434240. Batch_loss: 1.604285 \n",
      "Batch: 2621. Acc: 0.406769. Loss: 1.662984. Batch_acc: 0.425201. Batch_loss: 1.607853 \n",
      "Batch: 2622. Acc: 0.406775. Loss: 1.662971. Batch_acc: 0.422105. Batch_loss: 1.626568 \n",
      "Batch: 2623. Acc: 0.406776. Loss: 1.662948. Batch_acc: 0.408959. Batch_loss: 1.604124 \n",
      "Batch: 2624. Acc: 0.406783. Loss: 1.662937. Batch_acc: 0.426286. Batch_loss: 1.634180 \n",
      "Batch: 2625. Acc: 0.406793. Loss: 1.662902. Batch_acc: 0.434158. Batch_loss: 1.571026 \n",
      "Batch: 2626. Acc: 0.406803. Loss: 1.662884. Batch_acc: 0.432273. Batch_loss: 1.614174 \n",
      "Batch: 2627. Acc: 0.406805. Loss: 1.662880. Batch_acc: 0.411014. Batch_loss: 1.651835 \n",
      "Batch: 2628. Acc: 0.406819. Loss: 1.662829. Batch_acc: 0.445146. Batch_loss: 1.528035 \n",
      "Batch: 2629. Acc: 0.406830. Loss: 1.662800. Batch_acc: 0.436019. Batch_loss: 1.584138 \n",
      "Batch: 2630. Acc: 0.406839. Loss: 1.662774. Batch_acc: 0.431025. Batch_loss: 1.596537 \n",
      "Batch: 2631. Acc: 0.406846. Loss: 1.662757. Batch_acc: 0.424713. Batch_loss: 1.617719 \n",
      "Batch: 2632. Acc: 0.406848. Loss: 1.662743. Batch_acc: 0.411258. Batch_loss: 1.625253 \n",
      "Batch: 2633. Acc: 0.406860. Loss: 1.662715. Batch_acc: 0.440717. Batch_loss: 1.588912 \n",
      "Batch: 2634. Acc: 0.406859. Loss: 1.662715. Batch_acc: 0.402915. Batch_loss: 1.661595 \n",
      "Batch: 2635. Acc: 0.406863. Loss: 1.662696. Batch_acc: 0.416955. Batch_loss: 1.613676 \n",
      "Batch: 2636. Acc: 0.406871. Loss: 1.662664. Batch_acc: 0.427820. Batch_loss: 1.577480 \n",
      "Batch: 2637. Acc: 0.406873. Loss: 1.662661. Batch_acc: 0.413813. Batch_loss: 1.653294 \n",
      "Batch: 2638. Acc: 0.406878. Loss: 1.662635. Batch_acc: 0.420216. Batch_loss: 1.596651 \n",
      "Batch: 2639. Acc: 0.406892. Loss: 1.662600. Batch_acc: 0.442735. Batch_loss: 1.569886 \n",
      "Batch: 2640. Acc: 0.406909. Loss: 1.662552. Batch_acc: 0.451722. Batch_loss: 1.537090 \n",
      "Batch: 2641. Acc: 0.406919. Loss: 1.662524. Batch_acc: 0.433201. Batch_loss: 1.591211 \n",
      "Batch: 2642. Acc: 0.406923. Loss: 1.662510. Batch_acc: 0.417196. Batch_loss: 1.624697 \n",
      "Batch: 2643. Acc: 0.406925. Loss: 1.662484. Batch_acc: 0.412543. Batch_loss: 1.594501 \n",
      "Batch: 2644. Acc: 0.406933. Loss: 1.662456. Batch_acc: 0.426428. Batch_loss: 1.586453 \n",
      "Batch: 2645. Acc: 0.406936. Loss: 1.662440. Batch_acc: 0.416427. Batch_loss: 1.620535 \n",
      "Batch: 2646. Acc: 0.406939. Loss: 1.662429. Batch_acc: 0.412680. Batch_loss: 1.634840 \n",
      "Batch: 2647. Acc: 0.406946. Loss: 1.662403. Batch_acc: 0.426445. Batch_loss: 1.593489 \n",
      "Batch: 2648. Acc: 0.406954. Loss: 1.662378. Batch_acc: 0.429388. Batch_loss: 1.595825 \n",
      "Batch: 2649. Acc: 0.406956. Loss: 1.662371. Batch_acc: 0.410673. Batch_loss: 1.644434 \n",
      "Batch: 2650. Acc: 0.406958. Loss: 1.662367. Batch_acc: 0.412744. Batch_loss: 1.652377 \n",
      "Batch: 2651. Acc: 0.406973. Loss: 1.662341. Batch_acc: 0.446574. Batch_loss: 1.592830 \n",
      "Batch: 2652. Acc: 0.406984. Loss: 1.662305. Batch_acc: 0.436522. Batch_loss: 1.564574 \n",
      "Batch: 2653. Acc: 0.406993. Loss: 1.662280. Batch_acc: 0.432155. Batch_loss: 1.595686 \n",
      "Batch: 2654. Acc: 0.407001. Loss: 1.662262. Batch_acc: 0.428655. Batch_loss: 1.614341 \n",
      "Batch: 2655. Acc: 0.407008. Loss: 1.662246. Batch_acc: 0.423699. Batch_loss: 1.619399 \n",
      "Batch: 2656. Acc: 0.407021. Loss: 1.662218. Batch_acc: 0.442604. Batch_loss: 1.589489 \n",
      "Batch: 2657. Acc: 0.407034. Loss: 1.662190. Batch_acc: 0.440341. Batch_loss: 1.588108 \n",
      "Batch: 2658. Acc: 0.407049. Loss: 1.662148. Batch_acc: 0.446833. Batch_loss: 1.549744 \n",
      "Batch: 2659. Acc: 0.407061. Loss: 1.662114. Batch_acc: 0.440483. Batch_loss: 1.571513 \n",
      "Batch: 2660. Acc: 0.407078. Loss: 1.662075. Batch_acc: 0.449307. Batch_loss: 1.563189 \n",
      "Batch: 2661. Acc: 0.407091. Loss: 1.662042. Batch_acc: 0.441913. Batch_loss: 1.573786 \n",
      "Batch: 2662. Acc: 0.407099. Loss: 1.662018. Batch_acc: 0.427379. Batch_loss: 1.600928 \n",
      "Batch: 2663. Acc: 0.407108. Loss: 1.661985. Batch_acc: 0.432292. Batch_loss: 1.574278 \n",
      "Batch: 2664. Acc: 0.407118. Loss: 1.661967. Batch_acc: 0.434195. Batch_loss: 1.612804 \n",
      "Batch: 2665. Acc: 0.407132. Loss: 1.661937. Batch_acc: 0.442783. Batch_loss: 1.580156 \n",
      "Batch: 2666. Acc: 0.407147. Loss: 1.661887. Batch_acc: 0.447533. Batch_loss: 1.531180 \n",
      "Batch: 2667. Acc: 0.407158. Loss: 1.661854. Batch_acc: 0.435751. Batch_loss: 1.573843 \n",
      "Batch: 2668. Acc: 0.407162. Loss: 1.661840. Batch_acc: 0.418255. Batch_loss: 1.625178 \n",
      "Batch: 2669. Acc: 0.407166. Loss: 1.661821. Batch_acc: 0.417824. Batch_loss: 1.611198 \n",
      "Batch: 2670. Acc: 0.407174. Loss: 1.661794. Batch_acc: 0.427379. Batch_loss: 1.592190 \n",
      "Batch: 2671. Acc: 0.407181. Loss: 1.661781. Batch_acc: 0.426220. Batch_loss: 1.625623 \n",
      "Batch: 2672. Acc: 0.407187. Loss: 1.661749. Batch_acc: 0.424399. Batch_loss: 1.576701 \n",
      "Batch: 2673. Acc: 0.407190. Loss: 1.661745. Batch_acc: 0.414815. Batch_loss: 1.650788 \n",
      "Batch: 2674. Acc: 0.407194. Loss: 1.661719. Batch_acc: 0.418052. Batch_loss: 1.589125 \n",
      "Batch: 2675. Acc: 0.407199. Loss: 1.661689. Batch_acc: 0.421687. Batch_loss: 1.581660 \n",
      "Batch: 2676. Acc: 0.407208. Loss: 1.661658. Batch_acc: 0.430563. Batch_loss: 1.582035 \n",
      "Batch: 2677. Acc: 0.407221. Loss: 1.661629. Batch_acc: 0.441058. Batch_loss: 1.585238 \n",
      "Batch: 2678. Acc: 0.407231. Loss: 1.661610. Batch_acc: 0.436202. Batch_loss: 1.608360 \n",
      "Batch: 2679. Acc: 0.407233. Loss: 1.661605. Batch_acc: 0.411629. Batch_loss: 1.649099 \n",
      "Batch: 2680. Acc: 0.407247. Loss: 1.661566. Batch_acc: 0.442265. Batch_loss: 1.558817 \n",
      "Batch: 2681. Acc: 0.407248. Loss: 1.661546. Batch_acc: 0.411319. Batch_loss: 1.606521 \n",
      "Batch: 2682. Acc: 0.407260. Loss: 1.661515. Batch_acc: 0.439125. Batch_loss: 1.575317 \n",
      "Batch: 2683. Acc: 0.407259. Loss: 1.661511. Batch_acc: 0.405374. Batch_loss: 1.651845 \n",
      "Batch: 2684. Acc: 0.407263. Loss: 1.661505. Batch_acc: 0.419042. Batch_loss: 1.645591 \n",
      "Batch: 2685. Acc: 0.407269. Loss: 1.661492. Batch_acc: 0.422877. Batch_loss: 1.625957 \n",
      "Batch: 2686. Acc: 0.407268. Loss: 1.661486. Batch_acc: 0.404817. Batch_loss: 1.646867 \n",
      "Batch: 2687. Acc: 0.407272. Loss: 1.661475. Batch_acc: 0.416426. Batch_loss: 1.630710 \n",
      "Batch: 2688. Acc: 0.407285. Loss: 1.661442. Batch_acc: 0.443875. Batch_loss: 1.573117 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2689. Acc: 0.407300. Loss: 1.661406. Batch_acc: 0.445528. Batch_loss: 1.564214 \n",
      "Batch: 2690. Acc: 0.407315. Loss: 1.661366. Batch_acc: 0.448198. Batch_loss: 1.558220 \n",
      "Batch: 2691. Acc: 0.407322. Loss: 1.661351. Batch_acc: 0.426454. Batch_loss: 1.620973 \n",
      "Batch: 2692. Acc: 0.407332. Loss: 1.661315. Batch_acc: 0.433333. Batch_loss: 1.563327 \n",
      "Batch: 2693. Acc: 0.407335. Loss: 1.661296. Batch_acc: 0.416331. Batch_loss: 1.609720 \n",
      "Batch: 2694. Acc: 0.407345. Loss: 1.661272. Batch_acc: 0.433644. Batch_loss: 1.597842 \n",
      "Batch: 2695. Acc: 0.407347. Loss: 1.661262. Batch_acc: 0.413495. Batch_loss: 1.633206 \n",
      "Batch: 2696. Acc: 0.407350. Loss: 1.661245. Batch_acc: 0.414832. Batch_loss: 1.614069 \n",
      "Batch: 2697. Acc: 0.407349. Loss: 1.661255. Batch_acc: 0.405755. Batch_loss: 1.689893 \n",
      "Batch: 2698. Acc: 0.407352. Loss: 1.661242. Batch_acc: 0.413569. Batch_loss: 1.626248 \n",
      "Batch: 2699. Acc: 0.407350. Loss: 1.661244. Batch_acc: 0.402497. Batch_loss: 1.665928 \n",
      "Batch: 2700. Acc: 0.407354. Loss: 1.661229. Batch_acc: 0.417367. Batch_loss: 1.621728 \n",
      "Batch: 2701. Acc: 0.407365. Loss: 1.661196. Batch_acc: 0.438325. Batch_loss: 1.572714 \n",
      "Batch: 2702. Acc: 0.407372. Loss: 1.661183. Batch_acc: 0.424539. Batch_loss: 1.625570 \n",
      "Batch: 2703. Acc: 0.407371. Loss: 1.661175. Batch_acc: 0.406957. Batch_loss: 1.639143 \n",
      "Batch: 2704. Acc: 0.407379. Loss: 1.661155. Batch_acc: 0.428408. Batch_loss: 1.608728 \n",
      "Batch: 2705. Acc: 0.407387. Loss: 1.661137. Batch_acc: 0.429553. Batch_loss: 1.610170 \n",
      "Batch: 2706. Acc: 0.407397. Loss: 1.661100. Batch_acc: 0.433409. Batch_loss: 1.563779 \n",
      "Batch: 2707. Acc: 0.407407. Loss: 1.661074. Batch_acc: 0.435362. Batch_loss: 1.589587 \n",
      "Batch: 2708. Acc: 0.407424. Loss: 1.661037. Batch_acc: 0.449148. Batch_loss: 1.566233 \n",
      "Batch: 2709. Acc: 0.407429. Loss: 1.661019. Batch_acc: 0.423371. Batch_loss: 1.610687 \n",
      "Batch: 2710. Acc: 0.407430. Loss: 1.661012. Batch_acc: 0.409722. Batch_loss: 1.641779 \n",
      "Batch: 2711. Acc: 0.407432. Loss: 1.660992. Batch_acc: 0.413652. Batch_loss: 1.605344 \n",
      "Batch: 2712. Acc: 0.407443. Loss: 1.660967. Batch_acc: 0.436077. Batch_loss: 1.592818 \n",
      "Batch: 2713. Acc: 0.407450. Loss: 1.660955. Batch_acc: 0.425594. Batch_loss: 1.628886 \n",
      "Batch: 2714. Acc: 0.407462. Loss: 1.660920. Batch_acc: 0.441807. Batch_loss: 1.565391 \n",
      "Batch: 2715. Acc: 0.407471. Loss: 1.660895. Batch_acc: 0.430665. Batch_loss: 1.592915 \n",
      "Batch: 2716. Acc: 0.407477. Loss: 1.660886. Batch_acc: 0.423829. Batch_loss: 1.637290 \n",
      "Batch: 2717. Acc: 0.407478. Loss: 1.660877. Batch_acc: 0.410119. Batch_loss: 1.634897 \n",
      "Batch: 2718. Acc: 0.407487. Loss: 1.660849. Batch_acc: 0.432972. Batch_loss: 1.587106 \n",
      "Batch: 2719. Acc: 0.407491. Loss: 1.660840. Batch_acc: 0.417360. Batch_loss: 1.633092 \n",
      "Batch: 2720. Acc: 0.407502. Loss: 1.660813. Batch_acc: 0.438123. Batch_loss: 1.587221 \n",
      "Batch: 2721. Acc: 0.407505. Loss: 1.660795. Batch_acc: 0.415614. Batch_loss: 1.612622 \n",
      "Batch: 2722. Acc: 0.407514. Loss: 1.660770. Batch_acc: 0.433314. Batch_loss: 1.589297 \n",
      "Batch: 2723. Acc: 0.407515. Loss: 1.660764. Batch_acc: 0.412040. Batch_loss: 1.645677 \n",
      "Batch: 2724. Acc: 0.407525. Loss: 1.660742. Batch_acc: 0.433471. Batch_loss: 1.596984 \n",
      "Batch: 2725. Acc: 0.407537. Loss: 1.660710. Batch_acc: 0.441700. Batch_loss: 1.574974 \n",
      "Batch: 2726. Acc: 0.407539. Loss: 1.660698. Batch_acc: 0.413199. Batch_loss: 1.625710 \n",
      "Batch: 2727. Acc: 0.407549. Loss: 1.660687. Batch_acc: 0.433219. Batch_loss: 1.631952 \n",
      "Batch: 2728. Acc: 0.407558. Loss: 1.660655. Batch_acc: 0.432289. Batch_loss: 1.570974 \n",
      "Batch: 2729. Acc: 0.407562. Loss: 1.660633. Batch_acc: 0.418673. Batch_loss: 1.598585 \n",
      "Batch: 2730. Acc: 0.407575. Loss: 1.660594. Batch_acc: 0.443690. Batch_loss: 1.555016 \n",
      "Batch: 2731. Acc: 0.407584. Loss: 1.660565. Batch_acc: 0.433872. Batch_loss: 1.578718 \n",
      "Batch: 2732. Acc: 0.407591. Loss: 1.660547. Batch_acc: 0.425532. Batch_loss: 1.611465 \n",
      "Batch: 2733. Acc: 0.407595. Loss: 1.660535. Batch_acc: 0.418472. Batch_loss: 1.629803 \n",
      "Batch: 2734. Acc: 0.407590. Loss: 1.660541. Batch_acc: 0.393939. Batch_loss: 1.677056 \n",
      "Batch: 2735. Acc: 0.407603. Loss: 1.660512. Batch_acc: 0.444318. Batch_loss: 1.582140 \n",
      "Batch: 2736. Acc: 0.407613. Loss: 1.660483. Batch_acc: 0.432793. Batch_loss: 1.580929 \n",
      "Batch: 2737. Acc: 0.407624. Loss: 1.660440. Batch_acc: 0.438506. Batch_loss: 1.542906 \n",
      "Batch: 2738. Acc: 0.407625. Loss: 1.660442. Batch_acc: 0.411525. Batch_loss: 1.664870 \n",
      "Batch: 2739. Acc: 0.407635. Loss: 1.660408. Batch_acc: 0.432612. Batch_loss: 1.571349 \n",
      "Batch: 2740. Acc: 0.407646. Loss: 1.660378. Batch_acc: 0.439197. Batch_loss: 1.575981 \n",
      "Batch: 2741. Acc: 0.407651. Loss: 1.660363. Batch_acc: 0.420534. Batch_loss: 1.618091 \n",
      "Batch: 2742. Acc: 0.407652. Loss: 1.660355. Batch_acc: 0.410745. Batch_loss: 1.637123 \n",
      "Batch: 2743. Acc: 0.407657. Loss: 1.660335. Batch_acc: 0.421992. Batch_loss: 1.607182 \n",
      "Batch: 2744. Acc: 0.407666. Loss: 1.660311. Batch_acc: 0.433177. Batch_loss: 1.593261 \n",
      "Batch: 2745. Acc: 0.407678. Loss: 1.660265. Batch_acc: 0.441296. Batch_loss: 1.533321 \n",
      "Batch: 2746. Acc: 0.407684. Loss: 1.660253. Batch_acc: 0.424941. Batch_loss: 1.625291 \n",
      "Batch: 2747. Acc: 0.407694. Loss: 1.660229. Batch_acc: 0.434733. Batch_loss: 1.595679 \n",
      "Batch: 2748. Acc: 0.407697. Loss: 1.660223. Batch_acc: 0.415991. Batch_loss: 1.643137 \n",
      "Batch: 2749. Acc: 0.407704. Loss: 1.660203. Batch_acc: 0.427578. Batch_loss: 1.603860 \n",
      "Batch: 2750. Acc: 0.407714. Loss: 1.660171. Batch_acc: 0.434455. Batch_loss: 1.572223 \n",
      "Batch: 2751. Acc: 0.407719. Loss: 1.660155. Batch_acc: 0.420682. Batch_loss: 1.613878 \n",
      "Batch: 2752. Acc: 0.407727. Loss: 1.660120. Batch_acc: 0.432005. Batch_loss: 1.563880 \n",
      "Batch: 2753. Acc: 0.407733. Loss: 1.660091. Batch_acc: 0.423671. Batch_loss: 1.578996 \n",
      "Batch: 2754. Acc: 0.407743. Loss: 1.660068. Batch_acc: 0.436428. Batch_loss: 1.596729 \n",
      "Batch: 2755. Acc: 0.407743. Loss: 1.660068. Batch_acc: 0.406028. Batch_loss: 1.659027 \n",
      "Batch: 2756. Acc: 0.407755. Loss: 1.660032. Batch_acc: 0.439954. Batch_loss: 1.562849 \n",
      "Batch: 2757. Acc: 0.407761. Loss: 1.660011. Batch_acc: 0.424769. Batch_loss: 1.600051 \n",
      "Batch: 2758. Acc: 0.407772. Loss: 1.659987. Batch_acc: 0.438607. Batch_loss: 1.595894 \n",
      "Batch: 2759. Acc: 0.407781. Loss: 1.659964. Batch_acc: 0.432050. Batch_loss: 1.596553 \n",
      "Batch: 2760. Acc: 0.407790. Loss: 1.659941. Batch_acc: 0.433182. Batch_loss: 1.598564 \n",
      "Batch: 2761. Acc: 0.407800. Loss: 1.659907. Batch_acc: 0.435678. Batch_loss: 1.564895 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.4078003644574618. Loss per char: 1.6599067252328121. Time: 1627212521.7318707\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 14, 21,  1, 66,\n",
      "        79, 69,  1, 17, 15, 21, 17, 18, 26, 22, 21, 17, 19, 20, 21, 26, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.407801. Loss: 1.659889. Batch_acc: 0.408187. Batch_loss: 1.610577 \n",
      "Batch: 2763. Acc: 0.407808. Loss: 1.659875. Batch_acc: 0.429809. Batch_loss: 1.620136 \n",
      "Batch: 2764. Acc: 0.407812. Loss: 1.659861. Batch_acc: 0.416572. Batch_loss: 1.621519 \n",
      "Batch: 2765. Acc: 0.407818. Loss: 1.659840. Batch_acc: 0.425436. Batch_loss: 1.602893 \n",
      "Batch: 2766. Acc: 0.407836. Loss: 1.659801. Batch_acc: 0.458140. Batch_loss: 1.551545 \n",
      "Batch: 2767. Acc: 0.407857. Loss: 1.659756. Batch_acc: 0.466822. Batch_loss: 1.534914 \n",
      "Batch: 2768. Acc: 0.407854. Loss: 1.659752. Batch_acc: 0.399535. Batch_loss: 1.647402 \n",
      "Batch: 2769. Acc: 0.407868. Loss: 1.659711. Batch_acc: 0.446163. Batch_loss: 1.546667 \n",
      "Batch: 2770. Acc: 0.407870. Loss: 1.659700. Batch_acc: 0.412944. Batch_loss: 1.628977 \n",
      "Batch: 2771. Acc: 0.407879. Loss: 1.659673. Batch_acc: 0.433107. Batch_loss: 1.585830 \n",
      "Batch: 2772. Acc: 0.407885. Loss: 1.659650. Batch_acc: 0.424900. Batch_loss: 1.597493 \n",
      "Batch: 2773. Acc: 0.407882. Loss: 1.659664. Batch_acc: 0.397793. Batch_loss: 1.698605 \n",
      "Batch: 2774. Acc: 0.407886. Loss: 1.659652. Batch_acc: 0.419118. Batch_loss: 1.625321 \n",
      "Batch: 2775. Acc: 0.407893. Loss: 1.659632. Batch_acc: 0.427742. Batch_loss: 1.604551 \n",
      "Batch: 2776. Acc: 0.407905. Loss: 1.659601. Batch_acc: 0.441211. Batch_loss: 1.571615 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2777. Acc: 0.407916. Loss: 1.659565. Batch_acc: 0.438189. Batch_loss: 1.560097 \n",
      "Batch: 2778. Acc: 0.407927. Loss: 1.659542. Batch_acc: 0.439438. Batch_loss: 1.593120 \n",
      "Batch: 2779. Acc: 0.407930. Loss: 1.659530. Batch_acc: 0.417627. Batch_loss: 1.628483 \n",
      "Batch: 2780. Acc: 0.407941. Loss: 1.659496. Batch_acc: 0.438364. Batch_loss: 1.563685 \n",
      "Batch: 2781. Acc: 0.407945. Loss: 1.659496. Batch_acc: 0.419318. Batch_loss: 1.659503 \n",
      "Batch: 2782. Acc: 0.407954. Loss: 1.659473. Batch_acc: 0.433066. Batch_loss: 1.596233 \n",
      "Batch: 2783. Acc: 0.407970. Loss: 1.659431. Batch_acc: 0.450704. Batch_loss: 1.543524 \n",
      "Batch: 2784. Acc: 0.407967. Loss: 1.659426. Batch_acc: 0.398621. Batch_loss: 1.647090 \n",
      "Batch: 2785. Acc: 0.407965. Loss: 1.659415. Batch_acc: 0.404028. Batch_loss: 1.628569 \n",
      "Batch: 2786. Acc: 0.407971. Loss: 1.659392. Batch_acc: 0.423032. Batch_loss: 1.595004 \n",
      "Batch: 2787. Acc: 0.407982. Loss: 1.659363. Batch_acc: 0.440620. Batch_loss: 1.578812 \n",
      "Batch: 2788. Acc: 0.408000. Loss: 1.659315. Batch_acc: 0.455849. Batch_loss: 1.525109 \n",
      "Batch: 2789. Acc: 0.408012. Loss: 1.659281. Batch_acc: 0.442396. Batch_loss: 1.565416 \n",
      "Batch: 2790. Acc: 0.408027. Loss: 1.659262. Batch_acc: 0.449015. Batch_loss: 1.603204 \n",
      "Batch: 2791. Acc: 0.408033. Loss: 1.659241. Batch_acc: 0.424944. Batch_loss: 1.602007 \n",
      "Batch: 2792. Acc: 0.408040. Loss: 1.659220. Batch_acc: 0.427993. Batch_loss: 1.600408 \n",
      "Batch: 2793. Acc: 0.408050. Loss: 1.659193. Batch_acc: 0.437647. Batch_loss: 1.583572 \n",
      "Batch: 2794. Acc: 0.408061. Loss: 1.659167. Batch_acc: 0.438576. Batch_loss: 1.587384 \n",
      "Batch: 2795. Acc: 0.408068. Loss: 1.659149. Batch_acc: 0.427516. Batch_loss: 1.608251 \n",
      "Batch: 2796. Acc: 0.408081. Loss: 1.659116. Batch_acc: 0.444574. Batch_loss: 1.564967 \n",
      "Batch: 2797. Acc: 0.408086. Loss: 1.659105. Batch_acc: 0.422494. Batch_loss: 1.627365 \n",
      "Batch: 2798. Acc: 0.408088. Loss: 1.659103. Batch_acc: 0.414435. Batch_loss: 1.654008 \n",
      "Batch: 2799. Acc: 0.408093. Loss: 1.659093. Batch_acc: 0.421737. Batch_loss: 1.631140 \n",
      "Batch: 2800. Acc: 0.408106. Loss: 1.659064. Batch_acc: 0.444256. Batch_loss: 1.579577 \n",
      "Batch: 2801. Acc: 0.408113. Loss: 1.659033. Batch_acc: 0.428156. Batch_loss: 1.571648 \n",
      "Batch: 2802. Acc: 0.408130. Loss: 1.658988. Batch_acc: 0.453772. Batch_loss: 1.532872 \n",
      "Batch: 2803. Acc: 0.408136. Loss: 1.658967. Batch_acc: 0.424565. Batch_loss: 1.602793 \n",
      "Batch: 2804. Acc: 0.408135. Loss: 1.658959. Batch_acc: 0.406177. Batch_loss: 1.634996 \n",
      "Batch: 2805. Acc: 0.408145. Loss: 1.658934. Batch_acc: 0.437059. Batch_loss: 1.588622 \n",
      "Batch: 2806. Acc: 0.408165. Loss: 1.658882. Batch_acc: 0.463642. Batch_loss: 1.510275 \n",
      "Batch: 2807. Acc: 0.408172. Loss: 1.658867. Batch_acc: 0.427336. Batch_loss: 1.615910 \n",
      "Batch: 2808. Acc: 0.408185. Loss: 1.658829. Batch_acc: 0.446031. Batch_loss: 1.552837 \n",
      "Batch: 2809. Acc: 0.408206. Loss: 1.658779. Batch_acc: 0.465845. Batch_loss: 1.524377 \n",
      "Batch: 2810. Acc: 0.408218. Loss: 1.658753. Batch_acc: 0.442185. Batch_loss: 1.584475 \n",
      "Batch: 2811. Acc: 0.408230. Loss: 1.658716. Batch_acc: 0.440945. Batch_loss: 1.556602 \n",
      "Batch: 2812. Acc: 0.408240. Loss: 1.658689. Batch_acc: 0.434047. Batch_loss: 1.585267 \n",
      "Batch: 2813. Acc: 0.408251. Loss: 1.658673. Batch_acc: 0.439820. Batch_loss: 1.613691 \n",
      "Batch: 2814. Acc: 0.408253. Loss: 1.658653. Batch_acc: 0.412735. Batch_loss: 1.601864 \n",
      "Batch: 2815. Acc: 0.408265. Loss: 1.658616. Batch_acc: 0.442548. Batch_loss: 1.557527 \n",
      "Batch: 2816. Acc: 0.408272. Loss: 1.658598. Batch_acc: 0.428086. Batch_loss: 1.607135 \n",
      "Batch: 2817. Acc: 0.408279. Loss: 1.658571. Batch_acc: 0.426521. Batch_loss: 1.584243 \n",
      "Batch: 2818. Acc: 0.408283. Loss: 1.658558. Batch_acc: 0.421391. Batch_loss: 1.619049 \n",
      "Batch: 2819. Acc: 0.408288. Loss: 1.658541. Batch_acc: 0.422693. Batch_loss: 1.610033 \n",
      "Batch: 2820. Acc: 0.408291. Loss: 1.658518. Batch_acc: 0.416571. Batch_loss: 1.594822 \n",
      "Batch: 2821. Acc: 0.408300. Loss: 1.658494. Batch_acc: 0.431920. Batch_loss: 1.592582 \n",
      "Batch: 2822. Acc: 0.408305. Loss: 1.658477. Batch_acc: 0.423099. Batch_loss: 1.609766 \n",
      "Batch: 2823. Acc: 0.408318. Loss: 1.658451. Batch_acc: 0.444189. Batch_loss: 1.585531 \n",
      "Batch: 2824. Acc: 0.408325. Loss: 1.658432. Batch_acc: 0.429145. Batch_loss: 1.603756 \n",
      "Batch: 2825. Acc: 0.408326. Loss: 1.658416. Batch_acc: 0.411199. Batch_loss: 1.616098 \n",
      "Batch: 2826. Acc: 0.408335. Loss: 1.658391. Batch_acc: 0.433659. Batch_loss: 1.586092 \n",
      "Batch: 2827. Acc: 0.408339. Loss: 1.658378. Batch_acc: 0.418037. Batch_loss: 1.622742 \n",
      "Batch: 2828. Acc: 0.408342. Loss: 1.658364. Batch_acc: 0.418415. Batch_loss: 1.618834 \n",
      "Batch: 2829. Acc: 0.408355. Loss: 1.658332. Batch_acc: 0.445026. Batch_loss: 1.566358 \n",
      "Batch: 2830. Acc: 0.408363. Loss: 1.658303. Batch_acc: 0.432401. Batch_loss: 1.575622 \n",
      "Batch: 2831. Acc: 0.408372. Loss: 1.658285. Batch_acc: 0.431585. Batch_loss: 1.608261 \n",
      "Batch: 2832. Acc: 0.408383. Loss: 1.658252. Batch_acc: 0.442421. Batch_loss: 1.561831 \n",
      "Batch: 2833. Acc: 0.408389. Loss: 1.658235. Batch_acc: 0.425556. Batch_loss: 1.609680 \n",
      "Batch: 2834. Acc: 0.408399. Loss: 1.658229. Batch_acc: 0.434955. Batch_loss: 1.641310 \n",
      "Batch: 2835. Acc: 0.408404. Loss: 1.658229. Batch_acc: 0.422559. Batch_loss: 1.658326 \n",
      "Batch: 2836. Acc: 0.408413. Loss: 1.658206. Batch_acc: 0.433314. Batch_loss: 1.593127 \n",
      "Batch: 2837. Acc: 0.408425. Loss: 1.658173. Batch_acc: 0.444002. Batch_loss: 1.567069 \n",
      "Batch: 2838. Acc: 0.408431. Loss: 1.658153. Batch_acc: 0.425115. Batch_loss: 1.601297 \n",
      "Batch: 2839. Acc: 0.408436. Loss: 1.658130. Batch_acc: 0.423011. Batch_loss: 1.593125 \n",
      "Batch: 2840. Acc: 0.408443. Loss: 1.658104. Batch_acc: 0.427991. Batch_loss: 1.582083 \n",
      "Batch: 2841. Acc: 0.408454. Loss: 1.658072. Batch_acc: 0.437500. Batch_loss: 1.569226 \n",
      "Batch: 2842. Acc: 0.408459. Loss: 1.658061. Batch_acc: 0.424279. Batch_loss: 1.625637 \n",
      "Batch: 2843. Acc: 0.408467. Loss: 1.658035. Batch_acc: 0.431609. Batch_loss: 1.582380 \n",
      "Batch: 2844. Acc: 0.408474. Loss: 1.658021. Batch_acc: 0.427820. Batch_loss: 1.618285 \n",
      "Batch: 2845. Acc: 0.408480. Loss: 1.658003. Batch_acc: 0.424673. Batch_loss: 1.607771 \n",
      "Batch: 2846. Acc: 0.408486. Loss: 1.657987. Batch_acc: 0.425947. Batch_loss: 1.612901 \n",
      "Batch: 2847. Acc: 0.408498. Loss: 1.657950. Batch_acc: 0.441616. Batch_loss: 1.555261 \n",
      "Batch: 2848. Acc: 0.408503. Loss: 1.657932. Batch_acc: 0.423413. Batch_loss: 1.608135 \n",
      "Batch: 2849. Acc: 0.408504. Loss: 1.657918. Batch_acc: 0.412907. Batch_loss: 1.617860 \n",
      "Batch: 2850. Acc: 0.408516. Loss: 1.657896. Batch_acc: 0.439148. Batch_loss: 1.594985 \n",
      "Batch: 2851. Acc: 0.408522. Loss: 1.657879. Batch_acc: 0.427829. Batch_loss: 1.610058 \n",
      "Batch: 2852. Acc: 0.408531. Loss: 1.657855. Batch_acc: 0.432339. Batch_loss: 1.590715 \n",
      "Batch: 2853. Acc: 0.408543. Loss: 1.657837. Batch_acc: 0.443746. Batch_loss: 1.606529 \n",
      "Batch: 2854. Acc: 0.408550. Loss: 1.657810. Batch_acc: 0.430260. Batch_loss: 1.578675 \n",
      "Batch: 2855. Acc: 0.408558. Loss: 1.657782. Batch_acc: 0.431182. Batch_loss: 1.579026 \n",
      "Batch: 2856. Acc: 0.408572. Loss: 1.657742. Batch_acc: 0.447964. Batch_loss: 1.544482 \n",
      "Batch: 2857. Acc: 0.408580. Loss: 1.657715. Batch_acc: 0.430365. Batch_loss: 1.578235 \n",
      "Batch: 2858. Acc: 0.408587. Loss: 1.657700. Batch_acc: 0.428898. Batch_loss: 1.614552 \n",
      "Batch: 2859. Acc: 0.408591. Loss: 1.657689. Batch_acc: 0.419337. Batch_loss: 1.625907 \n",
      "Batch: 2860. Acc: 0.408604. Loss: 1.657662. Batch_acc: 0.445539. Batch_loss: 1.580129 \n",
      "Batch: 2861. Acc: 0.408613. Loss: 1.657630. Batch_acc: 0.434321. Batch_loss: 1.568759 \n",
      "Batch: 2862. Acc: 0.408626. Loss: 1.657585. Batch_acc: 0.446481. Batch_loss: 1.525303 \n",
      "Batch: 2863. Acc: 0.408632. Loss: 1.657557. Batch_acc: 0.426267. Batch_loss: 1.577250 \n",
      "Batch: 2864. Acc: 0.408643. Loss: 1.657538. Batch_acc: 0.438927. Batch_loss: 1.605443 \n",
      "Batch: 2865. Acc: 0.408650. Loss: 1.657515. Batch_acc: 0.429561. Batch_loss: 1.589702 \n",
      "Batch: 2866. Acc: 0.408660. Loss: 1.657481. Batch_acc: 0.436888. Batch_loss: 1.561045 \n",
      "Batch: 2867. Acc: 0.408666. Loss: 1.657455. Batch_acc: 0.428241. Batch_loss: 1.581782 \n",
      "Batch: 2868. Acc: 0.408669. Loss: 1.657440. Batch_acc: 0.416760. Batch_loss: 1.615154 \n",
      "Batch: 2869. Acc: 0.408675. Loss: 1.657419. Batch_acc: 0.423583. Batch_loss: 1.598003 \n",
      "Batch: 2870. Acc: 0.408685. Loss: 1.657385. Batch_acc: 0.438758. Batch_loss: 1.560119 \n",
      "Batch: 2871. Acc: 0.408694. Loss: 1.657350. Batch_acc: 0.434327. Batch_loss: 1.559586 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2872. Acc: 0.408707. Loss: 1.657325. Batch_acc: 0.443369. Batch_loss: 1.587800 \n",
      "Batch: 2873. Acc: 0.408717. Loss: 1.657302. Batch_acc: 0.438607. Batch_loss: 1.590576 \n",
      "Batch: 2874. Acc: 0.408725. Loss: 1.657282. Batch_acc: 0.432624. Batch_loss: 1.598613 \n",
      "Batch: 2875. Acc: 0.408735. Loss: 1.657257. Batch_acc: 0.438471. Batch_loss: 1.582968 \n",
      "Batch: 2876. Acc: 0.408742. Loss: 1.657244. Batch_acc: 0.429078. Batch_loss: 1.619289 \n",
      "Batch: 2877. Acc: 0.408748. Loss: 1.657226. Batch_acc: 0.425099. Batch_loss: 1.604949 \n",
      "Batch: 2878. Acc: 0.408760. Loss: 1.657199. Batch_acc: 0.442604. Batch_loss: 1.580484 \n",
      "Batch: 2879. Acc: 0.408764. Loss: 1.657178. Batch_acc: 0.421535. Batch_loss: 1.597545 \n",
      "Batch: 2880. Acc: 0.408774. Loss: 1.657153. Batch_acc: 0.436980. Batch_loss: 1.581494 \n",
      "Batch: 2881. Acc: 0.408776. Loss: 1.657144. Batch_acc: 0.416520. Batch_loss: 1.631016 \n",
      "Batch: 2882. Acc: 0.408786. Loss: 1.657122. Batch_acc: 0.437428. Batch_loss: 1.593112 \n",
      "Batch: 2883. Acc: 0.408791. Loss: 1.657090. Batch_acc: 0.423556. Batch_loss: 1.567536 \n",
      "Batch: 2884. Acc: 0.408799. Loss: 1.657065. Batch_acc: 0.431044. Batch_loss: 1.583267 \n",
      "Batch: 2885. Acc: 0.408810. Loss: 1.657026. Batch_acc: 0.439749. Batch_loss: 1.547156 \n",
      "Batch: 2886. Acc: 0.408813. Loss: 1.657022. Batch_acc: 0.418008. Batch_loss: 1.645773 \n",
      "Batch: 2887. Acc: 0.408818. Loss: 1.657009. Batch_acc: 0.422854. Batch_loss: 1.617158 \n",
      "Batch: 2888. Acc: 0.408815. Loss: 1.657016. Batch_acc: 0.401744. Batch_loss: 1.678985 \n",
      "Batch: 2889. Acc: 0.408829. Loss: 1.656995. Batch_acc: 0.450146. Batch_loss: 1.596013 \n",
      "Batch: 2890. Acc: 0.408834. Loss: 1.656982. Batch_acc: 0.422841. Batch_loss: 1.620063 \n",
      "Batch: 2891. Acc: 0.408850. Loss: 1.656939. Batch_acc: 0.453864. Batch_loss: 1.532932 \n",
      "Batch: 2892. Acc: 0.408856. Loss: 1.656919. Batch_acc: 0.424873. Batch_loss: 1.598518 \n",
      "Batch: 2893. Acc: 0.408858. Loss: 1.656912. Batch_acc: 0.417051. Batch_loss: 1.636922 \n",
      "Batch: 2894. Acc: 0.408866. Loss: 1.656892. Batch_acc: 0.429651. Batch_loss: 1.597889 \n",
      "Batch: 2895. Acc: 0.408873. Loss: 1.656865. Batch_acc: 0.429224. Batch_loss: 1.580283 \n",
      "Batch: 2896. Acc: 0.408889. Loss: 1.656826. Batch_acc: 0.454339. Batch_loss: 1.546480 \n",
      "Batch: 2897. Acc: 0.408891. Loss: 1.656814. Batch_acc: 0.414592. Batch_loss: 1.620155 \n",
      "Batch: 2898. Acc: 0.408905. Loss: 1.656776. Batch_acc: 0.452896. Batch_loss: 1.545956 \n",
      "Batch: 2899. Acc: 0.408915. Loss: 1.656749. Batch_acc: 0.437647. Batch_loss: 1.576978 \n",
      "Batch: 2900. Acc: 0.408918. Loss: 1.656746. Batch_acc: 0.417910. Batch_loss: 1.646720 \n",
      "Batch: 2901. Acc: 0.408919. Loss: 1.656736. Batch_acc: 0.411834. Batch_loss: 1.627414 \n",
      "Batch: 2902. Acc: 0.408922. Loss: 1.656728. Batch_acc: 0.415802. Batch_loss: 1.632147 \n",
      "Batch: 2903. Acc: 0.408920. Loss: 1.656717. Batch_acc: 0.404255. Batch_loss: 1.626539 \n",
      "Batch: 2904. Acc: 0.408933. Loss: 1.656685. Batch_acc: 0.444567. Batch_loss: 1.567639 \n",
      "Batch: 2905. Acc: 0.408934. Loss: 1.656675. Batch_acc: 0.413813. Batch_loss: 1.626773 \n",
      "Batch: 2906. Acc: 0.408945. Loss: 1.656643. Batch_acc: 0.439258. Batch_loss: 1.565957 \n",
      "Batch: 2907. Acc: 0.408947. Loss: 1.656635. Batch_acc: 0.413733. Batch_loss: 1.634096 \n",
      "Batch: 2908. Acc: 0.408960. Loss: 1.656603. Batch_acc: 0.446652. Batch_loss: 1.563504 \n",
      "Batch: 2909. Acc: 0.408977. Loss: 1.656563. Batch_acc: 0.458940. Batch_loss: 1.539234 \n",
      "Batch: 2910. Acc: 0.408987. Loss: 1.656545. Batch_acc: 0.437753. Batch_loss: 1.604888 \n",
      "Batch: 2911. Acc: 0.408989. Loss: 1.656532. Batch_acc: 0.416235. Batch_loss: 1.617172 \n",
      "Batch: 2912. Acc: 0.408989. Loss: 1.656515. Batch_acc: 0.408082. Batch_loss: 1.607037 \n",
      "Batch: 2913. Acc: 0.408997. Loss: 1.656493. Batch_acc: 0.433371. Batch_loss: 1.594935 \n",
      "Batch: 2914. Acc: 0.409006. Loss: 1.656473. Batch_acc: 0.434855. Batch_loss: 1.599330 \n",
      "Batch: 2915. Acc: 0.409004. Loss: 1.656478. Batch_acc: 0.402225. Batch_loss: 1.671325 \n",
      "Batch: 2916. Acc: 0.409016. Loss: 1.656453. Batch_acc: 0.444318. Batch_loss: 1.583574 \n",
      "Batch: 2917. Acc: 0.409027. Loss: 1.656430. Batch_acc: 0.438348. Batch_loss: 1.591070 \n",
      "Batch: 2918. Acc: 0.409036. Loss: 1.656398. Batch_acc: 0.435678. Batch_loss: 1.561873 \n",
      "Batch: 2919. Acc: 0.409042. Loss: 1.656381. Batch_acc: 0.426934. Batch_loss: 1.607842 \n",
      "Batch: 2920. Acc: 0.409051. Loss: 1.656348. Batch_acc: 0.436133. Batch_loss: 1.560304 \n",
      "Batch: 2921. Acc: 0.409060. Loss: 1.656327. Batch_acc: 0.434018. Batch_loss: 1.593227 \n",
      "Batch: 2922. Acc: 0.409074. Loss: 1.656290. Batch_acc: 0.448991. Batch_loss: 1.552398 \n",
      "Batch: 2923. Acc: 0.409087. Loss: 1.656254. Batch_acc: 0.446580. Batch_loss: 1.552248 \n",
      "Batch: 2924. Acc: 0.409102. Loss: 1.656225. Batch_acc: 0.453815. Batch_loss: 1.572092 \n",
      "Batch: 2925. Acc: 0.409107. Loss: 1.656212. Batch_acc: 0.423977. Batch_loss: 1.616459 \n",
      "Batch: 2926. Acc: 0.409118. Loss: 1.656179. Batch_acc: 0.440936. Batch_loss: 1.557091 \n",
      "Batch: 2927. Acc: 0.409130. Loss: 1.656150. Batch_acc: 0.445272. Batch_loss: 1.572144 \n",
      "Batch: 2928. Acc: 0.409134. Loss: 1.656146. Batch_acc: 0.421355. Batch_loss: 1.644616 \n",
      "Batch: 2929. Acc: 0.409142. Loss: 1.656111. Batch_acc: 0.431452. Batch_loss: 1.554623 \n",
      "Batch: 2930. Acc: 0.409155. Loss: 1.656085. Batch_acc: 0.446418. Batch_loss: 1.581024 \n",
      "Batch: 2931. Acc: 0.409151. Loss: 1.656100. Batch_acc: 0.396956. Batch_loss: 1.700636 \n",
      "Batch: 2932. Acc: 0.409157. Loss: 1.656081. Batch_acc: 0.428987. Batch_loss: 1.597862 \n",
      "Batch: 2933. Acc: 0.409163. Loss: 1.656056. Batch_acc: 0.425668. Batch_loss: 1.583129 \n",
      "Batch: 2934. Acc: 0.409175. Loss: 1.656034. Batch_acc: 0.444507. Batch_loss: 1.593066 \n",
      "Batch: 2935. Acc: 0.409181. Loss: 1.656009. Batch_acc: 0.427647. Batch_loss: 1.579347 \n",
      "Batch: 2936. Acc: 0.409190. Loss: 1.655980. Batch_acc: 0.434503. Batch_loss: 1.570307 \n",
      "Batch: 2937. Acc: 0.409195. Loss: 1.655965. Batch_acc: 0.424036. Batch_loss: 1.613332 \n",
      "Batch: 2938. Acc: 0.409200. Loss: 1.655948. Batch_acc: 0.425851. Batch_loss: 1.605162 \n",
      "Batch: 2939. Acc: 0.409210. Loss: 1.655926. Batch_acc: 0.439039. Batch_loss: 1.590243 \n",
      "Batch: 2940. Acc: 0.409222. Loss: 1.655905. Batch_acc: 0.441954. Batch_loss: 1.594174 \n",
      "Batch: 2941. Acc: 0.409229. Loss: 1.655882. Batch_acc: 0.430595. Batch_loss: 1.587775 \n",
      "Batch: 2942. Acc: 0.409239. Loss: 1.655863. Batch_acc: 0.438787. Batch_loss: 1.602563 \n",
      "Batch: 2943. Acc: 0.409252. Loss: 1.655842. Batch_acc: 0.447323. Batch_loss: 1.592948 \n",
      "Batch: 2944. Acc: 0.409260. Loss: 1.655816. Batch_acc: 0.433798. Batch_loss: 1.579450 \n",
      "Batch: 2945. Acc: 0.409263. Loss: 1.655812. Batch_acc: 0.417722. Batch_loss: 1.642397 \n",
      "Batch: 2946. Acc: 0.409270. Loss: 1.655799. Batch_acc: 0.430034. Batch_loss: 1.618793 \n",
      "Batch: 2947. Acc: 0.409279. Loss: 1.655767. Batch_acc: 0.434683. Batch_loss: 1.562811 \n",
      "Batch: 2948. Acc: 0.409281. Loss: 1.655761. Batch_acc: 0.416522. Batch_loss: 1.638089 \n",
      "Batch: 2949. Acc: 0.409290. Loss: 1.655727. Batch_acc: 0.435301. Batch_loss: 1.555655 \n",
      "Batch: 2950. Acc: 0.409293. Loss: 1.655719. Batch_acc: 0.418485. Batch_loss: 1.631574 \n",
      "Batch: 2951. Acc: 0.409307. Loss: 1.655683. Batch_acc: 0.448100. Batch_loss: 1.552981 \n",
      "Batch: 2952. Acc: 0.409316. Loss: 1.655655. Batch_acc: 0.435003. Batch_loss: 1.574898 \n",
      "Batch: 2953. Acc: 0.409324. Loss: 1.655633. Batch_acc: 0.432819. Batch_loss: 1.589582 \n",
      "Batch: 2954. Acc: 0.409333. Loss: 1.655612. Batch_acc: 0.436103. Batch_loss: 1.595370 \n",
      "Batch: 2955. Acc: 0.409337. Loss: 1.655598. Batch_acc: 0.422639. Batch_loss: 1.612995 \n",
      "Batch: 2956. Acc: 0.409343. Loss: 1.655576. Batch_acc: 0.426352. Batch_loss: 1.591260 \n",
      "Batch: 2957. Acc: 0.409350. Loss: 1.655562. Batch_acc: 0.430239. Batch_loss: 1.613953 \n",
      "Batch: 2958. Acc: 0.409357. Loss: 1.655533. Batch_acc: 0.429145. Batch_loss: 1.567694 \n",
      "Batch: 2959. Acc: 0.409366. Loss: 1.655514. Batch_acc: 0.435956. Batch_loss: 1.600941 \n",
      "Batch: 2960. Acc: 0.409368. Loss: 1.655504. Batch_acc: 0.415517. Batch_loss: 1.624565 \n",
      "Batch: 2961. Acc: 0.409374. Loss: 1.655481. Batch_acc: 0.428404. Batch_loss: 1.586086 \n",
      "Batch: 2962. Acc: 0.409379. Loss: 1.655466. Batch_acc: 0.423643. Batch_loss: 1.612098 \n",
      "Batch: 2963. Acc: 0.409389. Loss: 1.655441. Batch_acc: 0.440183. Batch_loss: 1.583020 \n",
      "Batch: 2964. Acc: 0.409401. Loss: 1.655417. Batch_acc: 0.442509. Batch_loss: 1.584506 \n",
      "Batch: 2965. Acc: 0.409409. Loss: 1.655388. Batch_acc: 0.435706. Batch_loss: 1.568475 \n",
      "Batch: 2966. Acc: 0.409427. Loss: 1.655348. Batch_acc: 0.460444. Batch_loss: 1.538875 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2967. Acc: 0.409432. Loss: 1.655332. Batch_acc: 0.426143. Batch_loss: 1.606925 \n",
      "Batch: 2968. Acc: 0.409441. Loss: 1.655311. Batch_acc: 0.436490. Batch_loss: 1.592866 \n",
      "Batch: 2969. Acc: 0.409443. Loss: 1.655294. Batch_acc: 0.414261. Batch_loss: 1.604363 \n",
      "Batch: 2970. Acc: 0.409451. Loss: 1.655261. Batch_acc: 0.432508. Batch_loss: 1.560101 \n",
      "Batch: 2971. Acc: 0.409454. Loss: 1.655242. Batch_acc: 0.418403. Batch_loss: 1.599403 \n",
      "Batch: 2972. Acc: 0.409456. Loss: 1.655224. Batch_acc: 0.416241. Batch_loss: 1.601346 \n",
      "Batch: 2973. Acc: 0.409465. Loss: 1.655203. Batch_acc: 0.435638. Batch_loss: 1.594069 \n",
      "Batch: 2974. Acc: 0.409473. Loss: 1.655180. Batch_acc: 0.430955. Batch_loss: 1.587749 \n",
      "Batch: 2975. Acc: 0.409477. Loss: 1.655162. Batch_acc: 0.422925. Batch_loss: 1.601449 \n",
      "Batch: 2976. Acc: 0.409487. Loss: 1.655139. Batch_acc: 0.437712. Batch_loss: 1.588327 \n",
      "Batch: 2977. Acc: 0.409492. Loss: 1.655126. Batch_acc: 0.424452. Batch_loss: 1.614664 \n",
      "Batch: 2978. Acc: 0.409497. Loss: 1.655108. Batch_acc: 0.425569. Batch_loss: 1.602124 \n",
      "Batch: 2979. Acc: 0.409514. Loss: 1.655062. Batch_acc: 0.458500. Batch_loss: 1.519881 \n",
      "Batch: 2980. Acc: 0.409520. Loss: 1.655040. Batch_acc: 0.426954. Batch_loss: 1.588409 \n",
      "Batch: 2981. Acc: 0.409525. Loss: 1.655018. Batch_acc: 0.425594. Batch_loss: 1.589950 \n",
      "Batch: 2982. Acc: 0.409530. Loss: 1.655001. Batch_acc: 0.424799. Batch_loss: 1.604199 \n",
      "Batch: 2983. Acc: 0.409542. Loss: 1.654966. Batch_acc: 0.445146. Batch_loss: 1.549381 \n",
      "Batch: 2984. Acc: 0.409551. Loss: 1.654938. Batch_acc: 0.436030. Batch_loss: 1.574157 \n",
      "Batch: 2985. Acc: 0.409555. Loss: 1.654919. Batch_acc: 0.422680. Batch_loss: 1.596015 \n",
      "Batch: 2986. Acc: 0.409557. Loss: 1.654902. Batch_acc: 0.414564. Batch_loss: 1.604971 \n",
      "Batch: 2987. Acc: 0.409572. Loss: 1.654854. Batch_acc: 0.452661. Batch_loss: 1.514582 \n",
      "Batch: 2988. Acc: 0.409582. Loss: 1.654810. Batch_acc: 0.441431. Batch_loss: 1.524519 \n",
      "Batch: 2989. Acc: 0.409592. Loss: 1.654780. Batch_acc: 0.438636. Batch_loss: 1.566255 \n",
      "Batch: 2990. Acc: 0.409602. Loss: 1.654757. Batch_acc: 0.438183. Batch_loss: 1.585204 \n",
      "Batch: 2991. Acc: 0.409611. Loss: 1.654730. Batch_acc: 0.436207. Batch_loss: 1.574796 \n",
      "Batch: 2992. Acc: 0.409626. Loss: 1.654683. Batch_acc: 0.456261. Batch_loss: 1.515125 \n",
      "Batch: 2993. Acc: 0.409633. Loss: 1.654663. Batch_acc: 0.428489. Batch_loss: 1.592902 \n",
      "Batch: 2994. Acc: 0.409635. Loss: 1.654646. Batch_acc: 0.417241. Batch_loss: 1.603633 \n",
      "Batch: 2995. Acc: 0.409639. Loss: 1.654628. Batch_acc: 0.420899. Batch_loss: 1.600186 \n",
      "Batch: 2996. Acc: 0.409648. Loss: 1.654612. Batch_acc: 0.437174. Batch_loss: 1.607877 \n",
      "Batch: 2997. Acc: 0.409661. Loss: 1.654583. Batch_acc: 0.448755. Batch_loss: 1.567072 \n",
      "Batch: 2998. Acc: 0.409665. Loss: 1.654574. Batch_acc: 0.422018. Batch_loss: 1.628310 \n",
      "Batch: 2999. Acc: 0.409675. Loss: 1.654546. Batch_acc: 0.440159. Batch_loss: 1.570984 \n",
      "Batch: 3000. Acc: 0.409689. Loss: 1.654513. Batch_acc: 0.449971. Batch_loss: 1.553378 \n",
      "Batch: 3001. Acc: 0.409693. Loss: 1.654482. Batch_acc: 0.422838. Batch_loss: 1.565156 \n",
      "Batch: 3002. Acc: 0.409699. Loss: 1.654454. Batch_acc: 0.427101. Batch_loss: 1.569258 \n",
      "Batch: 3003. Acc: 0.409710. Loss: 1.654423. Batch_acc: 0.441848. Batch_loss: 1.564611 \n",
      "Batch: 3004. Acc: 0.409718. Loss: 1.654397. Batch_acc: 0.433908. Batch_loss: 1.576914 \n",
      "Batch: 3005. Acc: 0.409724. Loss: 1.654372. Batch_acc: 0.426928. Batch_loss: 1.579322 \n",
      "Batch: 3006. Acc: 0.409735. Loss: 1.654347. Batch_acc: 0.444380. Batch_loss: 1.579219 \n",
      "Batch: 3007. Acc: 0.409753. Loss: 1.654305. Batch_acc: 0.461756. Batch_loss: 1.527655 \n",
      "Batch: 3008. Acc: 0.409763. Loss: 1.654287. Batch_acc: 0.441142. Batch_loss: 1.601288 \n",
      "Batch: 3009. Acc: 0.409772. Loss: 1.654262. Batch_acc: 0.435811. Batch_loss: 1.579494 \n",
      "Batch: 3010. Acc: 0.409774. Loss: 1.654256. Batch_acc: 0.415403. Batch_loss: 1.637195 \n",
      "Batch: 3011. Acc: 0.409790. Loss: 1.654224. Batch_acc: 0.458042. Batch_loss: 1.555922 \n",
      "Batch: 3012. Acc: 0.409796. Loss: 1.654207. Batch_acc: 0.427503. Batch_loss: 1.603479 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.4097956389328413. Loss per char: 1.654207113334822. Time: 1627212725.0718422\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 23, 26,  1, 77, 70, 84, 84,  1, 85,\n",
      "        73, 66, 79,  1, 14, 18, 19, 23, 15, 22, 23, 19, 25, 25, 25, 23, 18, 19,\n",
      "        32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.409802. Loss: 1.654175. Batch_acc: 0.428735. Batch_loss: 1.559283 \n",
      "Batch: 3014. Acc: 0.409819. Loss: 1.654133. Batch_acc: 0.460790. Batch_loss: 1.527133 \n",
      "Batch: 3015. Acc: 0.409829. Loss: 1.654107. Batch_acc: 0.440698. Batch_loss: 1.574012 \n",
      "Batch: 3016. Acc: 0.409836. Loss: 1.654081. Batch_acc: 0.431779. Batch_loss: 1.576967 \n",
      "Batch: 3017. Acc: 0.409845. Loss: 1.654066. Batch_acc: 0.435455. Batch_loss: 1.604818 \n",
      "Batch: 3018. Acc: 0.409855. Loss: 1.654037. Batch_acc: 0.440658. Batch_loss: 1.567399 \n",
      "Batch: 3019. Acc: 0.409859. Loss: 1.654019. Batch_acc: 0.422454. Batch_loss: 1.598404 \n",
      "Batch: 3020. Acc: 0.409863. Loss: 1.654006. Batch_acc: 0.422029. Batch_loss: 1.614588 \n",
      "Batch: 3021. Acc: 0.409878. Loss: 1.653968. Batch_acc: 0.454392. Batch_loss: 1.541567 \n",
      "Batch: 3022. Acc: 0.409890. Loss: 1.653943. Batch_acc: 0.446388. Batch_loss: 1.579331 \n",
      "Batch: 3023. Acc: 0.409901. Loss: 1.653926. Batch_acc: 0.443075. Batch_loss: 1.602823 \n",
      "Batch: 3024. Acc: 0.409905. Loss: 1.653898. Batch_acc: 0.423631. Batch_loss: 1.568589 \n",
      "Batch: 3025. Acc: 0.409907. Loss: 1.653891. Batch_acc: 0.416042. Batch_loss: 1.632168 \n",
      "Batch: 3026. Acc: 0.409915. Loss: 1.653862. Batch_acc: 0.432984. Batch_loss: 1.564455 \n",
      "Batch: 3027. Acc: 0.409921. Loss: 1.653843. Batch_acc: 0.429625. Batch_loss: 1.596243 \n",
      "Batch: 3028. Acc: 0.409929. Loss: 1.653822. Batch_acc: 0.431845. Batch_loss: 1.591492 \n",
      "Batch: 3029. Acc: 0.409932. Loss: 1.653809. Batch_acc: 0.418966. Batch_loss: 1.613113 \n",
      "Batch: 3030. Acc: 0.409935. Loss: 1.653806. Batch_acc: 0.421384. Batch_loss: 1.645241 \n",
      "Batch: 3031. Acc: 0.409943. Loss: 1.653771. Batch_acc: 0.432243. Batch_loss: 1.544818 \n",
      "Batch: 3032. Acc: 0.409950. Loss: 1.653763. Batch_acc: 0.432169. Batch_loss: 1.630777 \n",
      "Batch: 3033. Acc: 0.409956. Loss: 1.653756. Batch_acc: 0.429738. Batch_loss: 1.632687 \n",
      "Batch: 3034. Acc: 0.409966. Loss: 1.653731. Batch_acc: 0.439675. Batch_loss: 1.576312 \n",
      "Batch: 3035. Acc: 0.409969. Loss: 1.653706. Batch_acc: 0.419537. Batch_loss: 1.579505 \n",
      "Batch: 3036. Acc: 0.409971. Loss: 1.653700. Batch_acc: 0.414894. Batch_loss: 1.634584 \n",
      "Batch: 3037. Acc: 0.409973. Loss: 1.653686. Batch_acc: 0.417051. Batch_loss: 1.611477 \n",
      "Batch: 3038. Acc: 0.409986. Loss: 1.653648. Batch_acc: 0.448550. Batch_loss: 1.538801 \n",
      "Batch: 3039. Acc: 0.409992. Loss: 1.653627. Batch_acc: 0.429150. Batch_loss: 1.589890 \n",
      "Batch: 3040. Acc: 0.409997. Loss: 1.653603. Batch_acc: 0.425059. Batch_loss: 1.579613 \n",
      "Batch: 3041. Acc: 0.410005. Loss: 1.653572. Batch_acc: 0.433877. Batch_loss: 1.560246 \n",
      "Batch: 3042. Acc: 0.410011. Loss: 1.653553. Batch_acc: 0.427503. Batch_loss: 1.597864 \n",
      "Batch: 3043. Acc: 0.410012. Loss: 1.653550. Batch_acc: 0.412892. Batch_loss: 1.643473 \n",
      "Batch: 3044. Acc: 0.410017. Loss: 1.653541. Batch_acc: 0.424382. Batch_loss: 1.625606 \n",
      "Batch: 3045. Acc: 0.410027. Loss: 1.653506. Batch_acc: 0.442252. Batch_loss: 1.545020 \n",
      "Batch: 3046. Acc: 0.410027. Loss: 1.653484. Batch_acc: 0.409874. Batch_loss: 1.589159 \n",
      "Batch: 3047. Acc: 0.410032. Loss: 1.653480. Batch_acc: 0.425656. Batch_loss: 1.640050 \n",
      "Batch: 3048. Acc: 0.410042. Loss: 1.653445. Batch_acc: 0.440873. Batch_loss: 1.547550 \n",
      "Batch: 3049. Acc: 0.410047. Loss: 1.653424. Batch_acc: 0.424829. Batch_loss: 1.587997 \n",
      "Batch: 3050. Acc: 0.410055. Loss: 1.653401. Batch_acc: 0.433031. Batch_loss: 1.585178 \n",
      "Batch: 3051. Acc: 0.410064. Loss: 1.653367. Batch_acc: 0.438804. Batch_loss: 1.552486 \n",
      "Batch: 3052. Acc: 0.410077. Loss: 1.653330. Batch_acc: 0.448113. Batch_loss: 1.536296 \n",
      "Batch: 3053. Acc: 0.410085. Loss: 1.653314. Batch_acc: 0.435809. Batch_loss: 1.604365 \n",
      "Batch: 3054. Acc: 0.410091. Loss: 1.653289. Batch_acc: 0.429638. Batch_loss: 1.578843 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3055. Acc: 0.410100. Loss: 1.653266. Batch_acc: 0.436960. Batch_loss: 1.581348 \n",
      "Batch: 3056. Acc: 0.410109. Loss: 1.653232. Batch_acc: 0.437828. Batch_loss: 1.549031 \n",
      "Batch: 3057. Acc: 0.410113. Loss: 1.653221. Batch_acc: 0.422438. Batch_loss: 1.617926 \n",
      "Batch: 3058. Acc: 0.410135. Loss: 1.653167. Batch_acc: 0.474958. Batch_loss: 1.493885 \n",
      "Batch: 3059. Acc: 0.410137. Loss: 1.653154. Batch_acc: 0.415691. Batch_loss: 1.611590 \n",
      "Batch: 3060. Acc: 0.410139. Loss: 1.653141. Batch_acc: 0.416568. Batch_loss: 1.613429 \n",
      "Batch: 3061. Acc: 0.410151. Loss: 1.653104. Batch_acc: 0.447219. Batch_loss: 1.541309 \n",
      "Batch: 3062. Acc: 0.410159. Loss: 1.653087. Batch_acc: 0.434272. Batch_loss: 1.599949 \n",
      "Batch: 3063. Acc: 0.410162. Loss: 1.653077. Batch_acc: 0.418818. Batch_loss: 1.622231 \n",
      "Batch: 3064. Acc: 0.410169. Loss: 1.653047. Batch_acc: 0.432888. Batch_loss: 1.558904 \n",
      "Batch: 3065. Acc: 0.410176. Loss: 1.653028. Batch_acc: 0.431818. Batch_loss: 1.595166 \n",
      "Batch: 3066. Acc: 0.410189. Loss: 1.652997. Batch_acc: 0.449259. Batch_loss: 1.556807 \n",
      "Batch: 3067. Acc: 0.410195. Loss: 1.652981. Batch_acc: 0.428653. Batch_loss: 1.607102 \n",
      "Batch: 3068. Acc: 0.410201. Loss: 1.652965. Batch_acc: 0.429799. Batch_loss: 1.601234 \n",
      "Batch: 3069. Acc: 0.410210. Loss: 1.652937. Batch_acc: 0.438668. Batch_loss: 1.565621 \n",
      "Batch: 3070. Acc: 0.410215. Loss: 1.652910. Batch_acc: 0.425532. Batch_loss: 1.571116 \n",
      "Batch: 3071. Acc: 0.410222. Loss: 1.652885. Batch_acc: 0.429907. Batch_loss: 1.574885 \n",
      "Batch: 3072. Acc: 0.410235. Loss: 1.652861. Batch_acc: 0.451669. Batch_loss: 1.580283 \n",
      "Batch: 3073. Acc: 0.410242. Loss: 1.652845. Batch_acc: 0.430017. Batch_loss: 1.605462 \n",
      "Batch: 3074. Acc: 0.410243. Loss: 1.652844. Batch_acc: 0.413512. Batch_loss: 1.648458 \n",
      "Batch: 3075. Acc: 0.410250. Loss: 1.652816. Batch_acc: 0.432479. Batch_loss: 1.567898 \n",
      "Batch: 3076. Acc: 0.410258. Loss: 1.652792. Batch_acc: 0.435342. Batch_loss: 1.578042 \n",
      "Batch: 3077. Acc: 0.410277. Loss: 1.652742. Batch_acc: 0.467222. Batch_loss: 1.502649 \n",
      "Batch: 3078. Acc: 0.410281. Loss: 1.652720. Batch_acc: 0.422815. Batch_loss: 1.585788 \n",
      "Batch: 3079. Acc: 0.410288. Loss: 1.652693. Batch_acc: 0.430095. Batch_loss: 1.571371 \n",
      "Batch: 3080. Acc: 0.410296. Loss: 1.652673. Batch_acc: 0.435057. Batch_loss: 1.593277 \n",
      "Batch: 3081. Acc: 0.410310. Loss: 1.652647. Batch_acc: 0.454030. Batch_loss: 1.572169 \n",
      "Batch: 3082. Acc: 0.410316. Loss: 1.652628. Batch_acc: 0.426117. Batch_loss: 1.594190 \n",
      "Batch: 3083. Acc: 0.410332. Loss: 1.652589. Batch_acc: 0.461057. Batch_loss: 1.534808 \n",
      "Batch: 3084. Acc: 0.410341. Loss: 1.652563. Batch_acc: 0.437358. Batch_loss: 1.573812 \n",
      "Batch: 3085. Acc: 0.410346. Loss: 1.652540. Batch_acc: 0.425606. Batch_loss: 1.579572 \n",
      "Batch: 3086. Acc: 0.410353. Loss: 1.652513. Batch_acc: 0.432064. Batch_loss: 1.569574 \n",
      "Batch: 3087. Acc: 0.410356. Loss: 1.652508. Batch_acc: 0.419568. Batch_loss: 1.637808 \n",
      "Batch: 3088. Acc: 0.410370. Loss: 1.652477. Batch_acc: 0.453527. Batch_loss: 1.558176 \n",
      "Batch: 3089. Acc: 0.410376. Loss: 1.652463. Batch_acc: 0.428571. Batch_loss: 1.608883 \n",
      "Batch: 3090. Acc: 0.410382. Loss: 1.652445. Batch_acc: 0.429573. Batch_loss: 1.595772 \n",
      "Batch: 3091. Acc: 0.410392. Loss: 1.652416. Batch_acc: 0.442623. Batch_loss: 1.563566 \n",
      "Batch: 3092. Acc: 0.410404. Loss: 1.652382. Batch_acc: 0.445335. Batch_loss: 1.547944 \n",
      "Batch: 3093. Acc: 0.410406. Loss: 1.652375. Batch_acc: 0.416050. Batch_loss: 1.630065 \n",
      "Batch: 3094. Acc: 0.410407. Loss: 1.652364. Batch_acc: 0.414319. Batch_loss: 1.616749 \n",
      "Batch: 3095. Acc: 0.410422. Loss: 1.652314. Batch_acc: 0.455661. Batch_loss: 1.501286 \n",
      "Batch: 3096. Acc: 0.410428. Loss: 1.652293. Batch_acc: 0.428571. Batch_loss: 1.587570 \n",
      "Batch: 3097. Acc: 0.410435. Loss: 1.652276. Batch_acc: 0.431495. Batch_loss: 1.601466 \n",
      "Batch: 3098. Acc: 0.410449. Loss: 1.652240. Batch_acc: 0.453602. Batch_loss: 1.540581 \n",
      "Batch: 3099. Acc: 0.410459. Loss: 1.652215. Batch_acc: 0.442632. Batch_loss: 1.573898 \n",
      "Batch: 3100. Acc: 0.410461. Loss: 1.652210. Batch_acc: 0.418308. Batch_loss: 1.635326 \n",
      "Batch: 3101. Acc: 0.410468. Loss: 1.652190. Batch_acc: 0.433020. Batch_loss: 1.587978 \n",
      "Batch: 3102. Acc: 0.410475. Loss: 1.652161. Batch_acc: 0.429388. Batch_loss: 1.565198 \n",
      "Batch: 3103. Acc: 0.410478. Loss: 1.652147. Batch_acc: 0.421021. Batch_loss: 1.605873 \n",
      "Batch: 3104. Acc: 0.410482. Loss: 1.652133. Batch_acc: 0.423077. Batch_loss: 1.609980 \n",
      "Batch: 3105. Acc: 0.410491. Loss: 1.652099. Batch_acc: 0.437284. Batch_loss: 1.547617 \n",
      "Batch: 3106. Acc: 0.410493. Loss: 1.652084. Batch_acc: 0.418842. Batch_loss: 1.606099 \n",
      "Batch: 3107. Acc: 0.410497. Loss: 1.652060. Batch_acc: 0.423143. Batch_loss: 1.574937 \n",
      "Batch: 3108. Acc: 0.410503. Loss: 1.652050. Batch_acc: 0.429157. Batch_loss: 1.620383 \n",
      "Batch: 3109. Acc: 0.410513. Loss: 1.652013. Batch_acc: 0.441928. Batch_loss: 1.538107 \n",
      "Batch: 3110. Acc: 0.410523. Loss: 1.651975. Batch_acc: 0.439554. Batch_loss: 1.538044 \n",
      "Batch: 3111. Acc: 0.410535. Loss: 1.651943. Batch_acc: 0.447886. Batch_loss: 1.548331 \n",
      "Batch: 3112. Acc: 0.410541. Loss: 1.651917. Batch_acc: 0.429912. Batch_loss: 1.569718 \n",
      "Batch: 3113. Acc: 0.410549. Loss: 1.651893. Batch_acc: 0.435106. Batch_loss: 1.575324 \n",
      "Batch: 3114. Acc: 0.410553. Loss: 1.651882. Batch_acc: 0.423166. Batch_loss: 1.617361 \n",
      "Batch: 3115. Acc: 0.410556. Loss: 1.651864. Batch_acc: 0.420902. Batch_loss: 1.596010 \n",
      "Batch: 3116. Acc: 0.410557. Loss: 1.651864. Batch_acc: 0.413551. Batch_loss: 1.653963 \n",
      "Batch: 3117. Acc: 0.410571. Loss: 1.651820. Batch_acc: 0.455479. Batch_loss: 1.514291 \n",
      "Batch: 3118. Acc: 0.410586. Loss: 1.651779. Batch_acc: 0.454085. Batch_loss: 1.526615 \n",
      "Batch: 3119. Acc: 0.410591. Loss: 1.651762. Batch_acc: 0.427184. Batch_loss: 1.598355 \n",
      "Batch: 3120. Acc: 0.410599. Loss: 1.651733. Batch_acc: 0.433409. Batch_loss: 1.565359 \n",
      "Batch: 3121. Acc: 0.410603. Loss: 1.651722. Batch_acc: 0.425459. Batch_loss: 1.617840 \n",
      "Batch: 3122. Acc: 0.410612. Loss: 1.651701. Batch_acc: 0.436158. Batch_loss: 1.584680 \n",
      "Batch: 3123. Acc: 0.410617. Loss: 1.651667. Batch_acc: 0.428241. Batch_loss: 1.545877 \n",
      "Batch: 3124. Acc: 0.410634. Loss: 1.651613. Batch_acc: 0.463512. Batch_loss: 1.485976 \n",
      "Batch: 3125. Acc: 0.410639. Loss: 1.651597. Batch_acc: 0.423932. Batch_loss: 1.602115 \n",
      "Batch: 3126. Acc: 0.410644. Loss: 1.651575. Batch_acc: 0.428900. Batch_loss: 1.583048 \n",
      "Batch: 3127. Acc: 0.410650. Loss: 1.651552. Batch_acc: 0.428907. Batch_loss: 1.577345 \n",
      "Batch: 3128. Acc: 0.410656. Loss: 1.651535. Batch_acc: 0.429728. Batch_loss: 1.596603 \n",
      "Batch: 3129. Acc: 0.410669. Loss: 1.651499. Batch_acc: 0.451025. Batch_loss: 1.540011 \n",
      "Batch: 3130. Acc: 0.410680. Loss: 1.651461. Batch_acc: 0.443946. Batch_loss: 1.536174 \n",
      "Batch: 3131. Acc: 0.410695. Loss: 1.651424. Batch_acc: 0.455747. Batch_loss: 1.535660 \n",
      "Batch: 3132. Acc: 0.410702. Loss: 1.651404. Batch_acc: 0.432280. Batch_loss: 1.588493 \n",
      "Batch: 3133. Acc: 0.410710. Loss: 1.651383. Batch_acc: 0.436531. Batch_loss: 1.586821 \n",
      "Batch: 3134. Acc: 0.410714. Loss: 1.651363. Batch_acc: 0.424759. Batch_loss: 1.588491 \n",
      "Batch: 3135. Acc: 0.410720. Loss: 1.651341. Batch_acc: 0.429064. Batch_loss: 1.584911 \n",
      "Batch: 3136. Acc: 0.410720. Loss: 1.651339. Batch_acc: 0.411360. Batch_loss: 1.643994 \n",
      "Batch: 3137. Acc: 0.410720. Loss: 1.651327. Batch_acc: 0.410674. Batch_loss: 1.616078 \n",
      "Batch: 3138. Acc: 0.410728. Loss: 1.651309. Batch_acc: 0.434343. Batch_loss: 1.595247 \n",
      "Batch: 3139. Acc: 0.410739. Loss: 1.651280. Batch_acc: 0.442761. Batch_loss: 1.560963 \n",
      "Batch: 3140. Acc: 0.410739. Loss: 1.651275. Batch_acc: 0.411665. Batch_loss: 1.636666 \n",
      "Batch: 3141. Acc: 0.410742. Loss: 1.651260. Batch_acc: 0.419988. Batch_loss: 1.604316 \n",
      "Batch: 3142. Acc: 0.410744. Loss: 1.651257. Batch_acc: 0.417986. Batch_loss: 1.640661 \n",
      "Batch: 3143. Acc: 0.410752. Loss: 1.651232. Batch_acc: 0.435823. Batch_loss: 1.573665 \n",
      "Batch: 3144. Acc: 0.410760. Loss: 1.651212. Batch_acc: 0.437318. Batch_loss: 1.586736 \n",
      "Batch: 3145. Acc: 0.410764. Loss: 1.651193. Batch_acc: 0.422055. Batch_loss: 1.591521 \n",
      "Batch: 3146. Acc: 0.410772. Loss: 1.651162. Batch_acc: 0.436099. Batch_loss: 1.555968 \n",
      "Batch: 3147. Acc: 0.410781. Loss: 1.651127. Batch_acc: 0.438435. Batch_loss: 1.538961 \n",
      "Batch: 3148. Acc: 0.410794. Loss: 1.651093. Batch_acc: 0.450890. Batch_loss: 1.544989 \n",
      "Batch: 3149. Acc: 0.410793. Loss: 1.651098. Batch_acc: 0.407386. Batch_loss: 1.666439 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3150. Acc: 0.410803. Loss: 1.651067. Batch_acc: 0.443807. Batch_loss: 1.555265 \n",
      "Batch: 3151. Acc: 0.410809. Loss: 1.651046. Batch_acc: 0.428738. Batch_loss: 1.582503 \n",
      "Batch: 3152. Acc: 0.410819. Loss: 1.651021. Batch_acc: 0.442874. Batch_loss: 1.571214 \n",
      "Batch: 3153. Acc: 0.410824. Loss: 1.651005. Batch_acc: 0.426230. Batch_loss: 1.601065 \n",
      "Batch: 3154. Acc: 0.410832. Loss: 1.650982. Batch_acc: 0.436261. Batch_loss: 1.579590 \n",
      "Batch: 3155. Acc: 0.410835. Loss: 1.650965. Batch_acc: 0.420901. Batch_loss: 1.596590 \n",
      "Batch: 3156. Acc: 0.410843. Loss: 1.650934. Batch_acc: 0.437500. Batch_loss: 1.552986 \n",
      "Batch: 3157. Acc: 0.410846. Loss: 1.650924. Batch_acc: 0.420528. Batch_loss: 1.618460 \n",
      "Batch: 3158. Acc: 0.410858. Loss: 1.650893. Batch_acc: 0.449157. Batch_loss: 1.551073 \n",
      "Batch: 3159. Acc: 0.410867. Loss: 1.650878. Batch_acc: 0.438870. Batch_loss: 1.604362 \n",
      "Batch: 3160. Acc: 0.410870. Loss: 1.650864. Batch_acc: 0.419487. Batch_loss: 1.606515 \n",
      "Batch: 3161. Acc: 0.410881. Loss: 1.650839. Batch_acc: 0.444886. Batch_loss: 1.571483 \n",
      "Batch: 3162. Acc: 0.410890. Loss: 1.650812. Batch_acc: 0.440047. Batch_loss: 1.563141 \n",
      "Batch: 3163. Acc: 0.410893. Loss: 1.650794. Batch_acc: 0.420339. Batch_loss: 1.596679 \n",
      "Batch: 3164. Acc: 0.410902. Loss: 1.650765. Batch_acc: 0.439342. Batch_loss: 1.558876 \n",
      "Batch: 3165. Acc: 0.410907. Loss: 1.650758. Batch_acc: 0.426117. Batch_loss: 1.628846 \n",
      "Batch: 3166. Acc: 0.410917. Loss: 1.650727. Batch_acc: 0.441462. Batch_loss: 1.553706 \n",
      "Batch: 3167. Acc: 0.410918. Loss: 1.650714. Batch_acc: 0.414564. Batch_loss: 1.608638 \n",
      "Batch: 3168. Acc: 0.410925. Loss: 1.650684. Batch_acc: 0.433429. Batch_loss: 1.557039 \n",
      "Batch: 3169. Acc: 0.410931. Loss: 1.650663. Batch_acc: 0.430233. Batch_loss: 1.583448 \n",
      "Batch: 3170. Acc: 0.410931. Loss: 1.650661. Batch_acc: 0.410300. Batch_loss: 1.642866 \n",
      "Batch: 3171. Acc: 0.410936. Loss: 1.650636. Batch_acc: 0.426752. Batch_loss: 1.571576 \n",
      "Batch: 3172. Acc: 0.410947. Loss: 1.650607. Batch_acc: 0.446735. Batch_loss: 1.560930 \n",
      "Batch: 3173. Acc: 0.410952. Loss: 1.650593. Batch_acc: 0.426570. Batch_loss: 1.604825 \n",
      "Batch: 3174. Acc: 0.410956. Loss: 1.650578. Batch_acc: 0.423371. Batch_loss: 1.604138 \n",
      "Batch: 3175. Acc: 0.410966. Loss: 1.650545. Batch_acc: 0.443567. Batch_loss: 1.547704 \n",
      "Batch: 3176. Acc: 0.410973. Loss: 1.650519. Batch_acc: 0.432776. Batch_loss: 1.566790 \n",
      "Batch: 3177. Acc: 0.410974. Loss: 1.650504. Batch_acc: 0.413238. Batch_loss: 1.600716 \n",
      "Batch: 3178. Acc: 0.410985. Loss: 1.650468. Batch_acc: 0.445708. Batch_loss: 1.537595 \n",
      "Batch: 3179. Acc: 0.410991. Loss: 1.650438. Batch_acc: 0.431818. Batch_loss: 1.552461 \n",
      "Batch: 3180. Acc: 0.410995. Loss: 1.650430. Batch_acc: 0.421483. Batch_loss: 1.627296 \n",
      "Batch: 3181. Acc: 0.411005. Loss: 1.650399. Batch_acc: 0.445354. Batch_loss: 1.547899 \n",
      "Batch: 3182. Acc: 0.411012. Loss: 1.650386. Batch_acc: 0.432895. Batch_loss: 1.609136 \n",
      "Batch: 3183. Acc: 0.411012. Loss: 1.650387. Batch_acc: 0.409453. Batch_loss: 1.656432 \n",
      "Batch: 3184. Acc: 0.411021. Loss: 1.650359. Batch_acc: 0.439205. Batch_loss: 1.561506 \n",
      "Batch: 3185. Acc: 0.411023. Loss: 1.650348. Batch_acc: 0.419336. Batch_loss: 1.613503 \n",
      "Batch: 3186. Acc: 0.411029. Loss: 1.650332. Batch_acc: 0.428902. Batch_loss: 1.599581 \n",
      "Batch: 3187. Acc: 0.411038. Loss: 1.650306. Batch_acc: 0.441244. Batch_loss: 1.568808 \n",
      "Batch: 3188. Acc: 0.411042. Loss: 1.650293. Batch_acc: 0.424138. Batch_loss: 1.607150 \n",
      "Batch: 3189. Acc: 0.411047. Loss: 1.650279. Batch_acc: 0.424208. Batch_loss: 1.607510 \n",
      "Batch: 3190. Acc: 0.411064. Loss: 1.650244. Batch_acc: 0.464031. Batch_loss: 1.542902 \n",
      "Batch: 3191. Acc: 0.411066. Loss: 1.650227. Batch_acc: 0.416763. Batch_loss: 1.596231 \n",
      "Batch: 3192. Acc: 0.411075. Loss: 1.650199. Batch_acc: 0.439841. Batch_loss: 1.562387 \n",
      "Batch: 3193. Acc: 0.411084. Loss: 1.650169. Batch_acc: 0.440717. Batch_loss: 1.553905 \n",
      "Batch: 3194. Acc: 0.411091. Loss: 1.650138. Batch_acc: 0.433390. Batch_loss: 1.553768 \n",
      "Batch: 3195. Acc: 0.411107. Loss: 1.650102. Batch_acc: 0.459536. Batch_loss: 1.535350 \n",
      "Batch: 3196. Acc: 0.411118. Loss: 1.650065. Batch_acc: 0.446357. Batch_loss: 1.532779 \n",
      "Batch: 3197. Acc: 0.411121. Loss: 1.650056. Batch_acc: 0.421625. Batch_loss: 1.619846 \n",
      "Batch: 3198. Acc: 0.411126. Loss: 1.650031. Batch_acc: 0.426635. Batch_loss: 1.569806 \n",
      "Batch: 3199. Acc: 0.411132. Loss: 1.650016. Batch_acc: 0.429977. Batch_loss: 1.601092 \n",
      "Batch: 3200. Acc: 0.411142. Loss: 1.649992. Batch_acc: 0.443364. Batch_loss: 1.573767 \n",
      "Batch: 3201. Acc: 0.411151. Loss: 1.649962. Batch_acc: 0.442529. Batch_loss: 1.555613 \n",
      "Batch: 3202. Acc: 0.411158. Loss: 1.649940. Batch_acc: 0.431015. Batch_loss: 1.579597 \n",
      "Batch: 3203. Acc: 0.411165. Loss: 1.649917. Batch_acc: 0.434417. Batch_loss: 1.576016 \n",
      "Batch: 3204. Acc: 0.411176. Loss: 1.649887. Batch_acc: 0.444891. Batch_loss: 1.555272 \n",
      "Batch: 3205. Acc: 0.411182. Loss: 1.649864. Batch_acc: 0.432479. Batch_loss: 1.575996 \n",
      "Batch: 3206. Acc: 0.411184. Loss: 1.649847. Batch_acc: 0.415349. Batch_loss: 1.596217 \n",
      "Batch: 3207. Acc: 0.411191. Loss: 1.649831. Batch_acc: 0.436686. Batch_loss: 1.594900 \n",
      "Batch: 3208. Acc: 0.411202. Loss: 1.649796. Batch_acc: 0.445080. Batch_loss: 1.539928 \n",
      "Batch: 3209. Acc: 0.411209. Loss: 1.649772. Batch_acc: 0.434113. Batch_loss: 1.573770 \n",
      "Batch: 3210. Acc: 0.411219. Loss: 1.649740. Batch_acc: 0.441874. Batch_loss: 1.545883 \n",
      "Batch: 3211. Acc: 0.411220. Loss: 1.649732. Batch_acc: 0.415959. Batch_loss: 1.623571 \n",
      "Batch: 3212. Acc: 0.411226. Loss: 1.649719. Batch_acc: 0.429243. Batch_loss: 1.608749 \n",
      "Batch: 3213. Acc: 0.411238. Loss: 1.649692. Batch_acc: 0.450399. Batch_loss: 1.562804 \n",
      "Batch: 3214. Acc: 0.411236. Loss: 1.649688. Batch_acc: 0.404193. Batch_loss: 1.637766 \n",
      "Batch: 3215. Acc: 0.411248. Loss: 1.649659. Batch_acc: 0.449714. Batch_loss: 1.556033 \n",
      "Batch: 3216. Acc: 0.411262. Loss: 1.649628. Batch_acc: 0.454646. Batch_loss: 1.554490 \n",
      "Batch: 3217. Acc: 0.411270. Loss: 1.649612. Batch_acc: 0.438566. Batch_loss: 1.596377 \n",
      "Batch: 3218. Acc: 0.411279. Loss: 1.649585. Batch_acc: 0.439150. Batch_loss: 1.561746 \n",
      "Batch: 3219. Acc: 0.411288. Loss: 1.649559. Batch_acc: 0.438457. Batch_loss: 1.568983 \n",
      "Batch: 3220. Acc: 0.411293. Loss: 1.649534. Batch_acc: 0.427923. Batch_loss: 1.568891 \n",
      "Batch: 3221. Acc: 0.411299. Loss: 1.649509. Batch_acc: 0.430259. Batch_loss: 1.571266 \n",
      "Batch: 3222. Acc: 0.411304. Loss: 1.649485. Batch_acc: 0.428152. Batch_loss: 1.569094 \n",
      "Batch: 3223. Acc: 0.411309. Loss: 1.649471. Batch_acc: 0.426822. Batch_loss: 1.603819 \n",
      "Batch: 3224. Acc: 0.411317. Loss: 1.649451. Batch_acc: 0.437676. Batch_loss: 1.587664 \n",
      "Batch: 3225. Acc: 0.411325. Loss: 1.649424. Batch_acc: 0.437788. Batch_loss: 1.561287 \n",
      "Batch: 3226. Acc: 0.411340. Loss: 1.649391. Batch_acc: 0.460218. Batch_loss: 1.542860 \n",
      "Batch: 3227. Acc: 0.411347. Loss: 1.649372. Batch_acc: 0.433562. Batch_loss: 1.590442 \n",
      "Batch: 3228. Acc: 0.411352. Loss: 1.649355. Batch_acc: 0.426220. Batch_loss: 1.592899 \n",
      "Batch: 3229. Acc: 0.411361. Loss: 1.649335. Batch_acc: 0.442063. Batch_loss: 1.582306 \n",
      "Batch: 3230. Acc: 0.411371. Loss: 1.649305. Batch_acc: 0.442558. Batch_loss: 1.556108 \n",
      "Batch: 3231. Acc: 0.411380. Loss: 1.649276. Batch_acc: 0.439542. Batch_loss: 1.553915 \n",
      "Batch: 3232. Acc: 0.411390. Loss: 1.649236. Batch_acc: 0.444186. Batch_loss: 1.517794 \n",
      "Batch: 3233. Acc: 0.411396. Loss: 1.649228. Batch_acc: 0.429621. Batch_loss: 1.626189 \n",
      "Batch: 3234. Acc: 0.411405. Loss: 1.649196. Batch_acc: 0.440503. Batch_loss: 1.544209 \n",
      "Batch: 3235. Acc: 0.411417. Loss: 1.649166. Batch_acc: 0.452055. Batch_loss: 1.553465 \n",
      "Batch: 3236. Acc: 0.411418. Loss: 1.649162. Batch_acc: 0.412493. Batch_loss: 1.636189 \n",
      "Batch: 3237. Acc: 0.411428. Loss: 1.649133. Batch_acc: 0.445397. Batch_loss: 1.557307 \n",
      "Batch: 3238. Acc: 0.411445. Loss: 1.649089. Batch_acc: 0.464652. Batch_loss: 1.506628 \n",
      "Batch: 3239. Acc: 0.411455. Loss: 1.649064. Batch_acc: 0.444509. Batch_loss: 1.568811 \n",
      "Batch: 3240. Acc: 0.411459. Loss: 1.649058. Batch_acc: 0.425641. Batch_loss: 1.628644 \n",
      "Batch: 3241. Acc: 0.411458. Loss: 1.649057. Batch_acc: 0.406838. Batch_loss: 1.646090 \n",
      "Batch: 3242. Acc: 0.411462. Loss: 1.649042. Batch_acc: 0.425893. Batch_loss: 1.600122 \n",
      "Batch: 3243. Acc: 0.411476. Loss: 1.649003. Batch_acc: 0.455645. Batch_loss: 1.520401 \n",
      "Batch: 3244. Acc: 0.411489. Loss: 1.648972. Batch_acc: 0.455711. Batch_loss: 1.547639 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3245. Acc: 0.411490. Loss: 1.648959. Batch_acc: 0.414194. Batch_loss: 1.605905 \n",
      "Batch: 3246. Acc: 0.411494. Loss: 1.648949. Batch_acc: 0.423210. Batch_loss: 1.615978 \n",
      "Batch: 3247. Acc: 0.411503. Loss: 1.648913. Batch_acc: 0.440873. Batch_loss: 1.532161 \n",
      "Batch: 3248. Acc: 0.411508. Loss: 1.648891. Batch_acc: 0.429136. Batch_loss: 1.581274 \n",
      "Batch: 3249. Acc: 0.411520. Loss: 1.648847. Batch_acc: 0.448354. Batch_loss: 1.507621 \n",
      "Batch: 3250. Acc: 0.411527. Loss: 1.648814. Batch_acc: 0.435621. Batch_loss: 1.540772 \n",
      "Batch: 3251. Acc: 0.411529. Loss: 1.648809. Batch_acc: 0.417867. Batch_loss: 1.633915 \n",
      "Batch: 3252. Acc: 0.411540. Loss: 1.648786. Batch_acc: 0.446110. Batch_loss: 1.573074 \n",
      "Batch: 3253. Acc: 0.411548. Loss: 1.648755. Batch_acc: 0.436975. Batch_loss: 1.552023 \n",
      "Batch: 3254. Acc: 0.411556. Loss: 1.648734. Batch_acc: 0.436385. Batch_loss: 1.580629 \n",
      "Batch: 3255. Acc: 0.411561. Loss: 1.648712. Batch_acc: 0.428824. Batch_loss: 1.575944 \n",
      "Batch: 3256. Acc: 0.411565. Loss: 1.648694. Batch_acc: 0.423932. Batch_loss: 1.589689 \n",
      "Batch: 3257. Acc: 0.411574. Loss: 1.648667. Batch_acc: 0.442748. Batch_loss: 1.557778 \n",
      "Batch: 3258. Acc: 0.411581. Loss: 1.648641. Batch_acc: 0.434366. Batch_loss: 1.567734 \n",
      "Batch: 3259. Acc: 0.411588. Loss: 1.648623. Batch_acc: 0.434983. Batch_loss: 1.586958 \n",
      "Batch: 3260. Acc: 0.411595. Loss: 1.648595. Batch_acc: 0.432120. Batch_loss: 1.558399 \n",
      "Batch: 3261. Acc: 0.411601. Loss: 1.648573. Batch_acc: 0.434104. Batch_loss: 1.576493 \n",
      "Batch: 3262. Acc: 0.411607. Loss: 1.648556. Batch_acc: 0.430365. Batch_loss: 1.593782 \n",
      "Batch: 3263. Acc: 0.411633. Loss: 1.648490. Batch_acc: 0.492537. Batch_loss: 1.441723 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.41163297597605375. Loss per char: 1.6484901741430855. Time: 1627212928.148186\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 26, 18, 19, 26, 26, 24, 19,\n",
      "        20, 17, 23,  1, 81, 77, 86, 84,  1, 14, 17, 15, 25, 23, 20, 24, 32,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.411638. Loss: 1.648472. Batch_acc: 0.426857. Batch_loss: 1.590663 \n",
      "Batch: 3265. Acc: 0.411642. Loss: 1.648453. Batch_acc: 0.426046. Batch_loss: 1.582583 \n",
      "Batch: 3266. Acc: 0.411647. Loss: 1.648429. Batch_acc: 0.429638. Batch_loss: 1.571480 \n",
      "Batch: 3267. Acc: 0.411655. Loss: 1.648412. Batch_acc: 0.436385. Batch_loss: 1.592787 \n",
      "Batch: 3268. Acc: 0.411666. Loss: 1.648384. Batch_acc: 0.448138. Batch_loss: 1.557398 \n",
      "Batch: 3269. Acc: 0.411675. Loss: 1.648361. Batch_acc: 0.438787. Batch_loss: 1.572676 \n",
      "Batch: 3270. Acc: 0.411683. Loss: 1.648343. Batch_acc: 0.440647. Batch_loss: 1.585883 \n",
      "Batch: 3271. Acc: 0.411691. Loss: 1.648321. Batch_acc: 0.437831. Batch_loss: 1.576375 \n",
      "Batch: 3272. Acc: 0.411700. Loss: 1.648296. Batch_acc: 0.443591. Batch_loss: 1.563807 \n",
      "Batch: 3273. Acc: 0.411709. Loss: 1.648264. Batch_acc: 0.440697. Batch_loss: 1.547624 \n",
      "Batch: 3274. Acc: 0.411711. Loss: 1.648258. Batch_acc: 0.416469. Batch_loss: 1.628211 \n",
      "Batch: 3275. Acc: 0.411721. Loss: 1.648233. Batch_acc: 0.445783. Batch_loss: 1.564306 \n",
      "Batch: 3276. Acc: 0.411720. Loss: 1.648222. Batch_acc: 0.409117. Batch_loss: 1.613500 \n",
      "Batch: 3277. Acc: 0.411725. Loss: 1.648210. Batch_acc: 0.426598. Batch_loss: 1.609785 \n",
      "Batch: 3278. Acc: 0.411734. Loss: 1.648178. Batch_acc: 0.442217. Batch_loss: 1.538949 \n",
      "Batch: 3279. Acc: 0.411740. Loss: 1.648164. Batch_acc: 0.429799. Batch_loss: 1.602652 \n",
      "Batch: 3280. Acc: 0.411743. Loss: 1.648150. Batch_acc: 0.421563. Batch_loss: 1.603605 \n",
      "Batch: 3281. Acc: 0.411751. Loss: 1.648117. Batch_acc: 0.438497. Batch_loss: 1.538860 \n",
      "Batch: 3282. Acc: 0.411765. Loss: 1.648073. Batch_acc: 0.457483. Batch_loss: 1.505792 \n",
      "Batch: 3283. Acc: 0.411771. Loss: 1.648056. Batch_acc: 0.430832. Batch_loss: 1.591487 \n",
      "Batch: 3284. Acc: 0.411779. Loss: 1.648041. Batch_acc: 0.438497. Batch_loss: 1.599310 \n",
      "Batch: 3285. Acc: 0.411785. Loss: 1.648016. Batch_acc: 0.430114. Batch_loss: 1.566764 \n",
      "Batch: 3286. Acc: 0.411797. Loss: 1.647986. Batch_acc: 0.453287. Batch_loss: 1.548976 \n",
      "Batch: 3287. Acc: 0.411809. Loss: 1.647958. Batch_acc: 0.449489. Batch_loss: 1.557951 \n",
      "Batch: 3288. Acc: 0.411817. Loss: 1.647935. Batch_acc: 0.439296. Batch_loss: 1.570254 \n",
      "Batch: 3289. Acc: 0.411826. Loss: 1.647902. Batch_acc: 0.440324. Batch_loss: 1.538825 \n",
      "Batch: 3290. Acc: 0.411836. Loss: 1.647876. Batch_acc: 0.447778. Batch_loss: 1.563170 \n",
      "Batch: 3291. Acc: 0.411851. Loss: 1.647839. Batch_acc: 0.458381. Batch_loss: 1.526866 \n",
      "Batch: 3292. Acc: 0.411859. Loss: 1.647812. Batch_acc: 0.438882. Batch_loss: 1.558582 \n",
      "Batch: 3293. Acc: 0.411864. Loss: 1.647793. Batch_acc: 0.429949. Batch_loss: 1.585299 \n",
      "Batch: 3294. Acc: 0.411875. Loss: 1.647757. Batch_acc: 0.447473. Batch_loss: 1.530268 \n",
      "Batch: 3295. Acc: 0.411885. Loss: 1.647738. Batch_acc: 0.443991. Batch_loss: 1.585536 \n",
      "Batch: 3296. Acc: 0.411898. Loss: 1.647700. Batch_acc: 0.456547. Batch_loss: 1.520938 \n",
      "Batch: 3297. Acc: 0.411906. Loss: 1.647680. Batch_acc: 0.437901. Batch_loss: 1.582011 \n",
      "Batch: 3298. Acc: 0.411910. Loss: 1.647663. Batch_acc: 0.425777. Batch_loss: 1.588534 \n",
      "Batch: 3299. Acc: 0.411921. Loss: 1.647636. Batch_acc: 0.446636. Batch_loss: 1.559709 \n",
      "Batch: 3300. Acc: 0.411936. Loss: 1.647606. Batch_acc: 0.460712. Batch_loss: 1.551487 \n",
      "Batch: 3301. Acc: 0.411944. Loss: 1.647585. Batch_acc: 0.439083. Batch_loss: 1.574221 \n",
      "Batch: 3302. Acc: 0.411952. Loss: 1.647553. Batch_acc: 0.437749. Batch_loss: 1.542524 \n",
      "Batch: 3303. Acc: 0.411969. Loss: 1.647511. Batch_acc: 0.468838. Batch_loss: 1.510824 \n",
      "Batch: 3304. Acc: 0.411977. Loss: 1.647494. Batch_acc: 0.438596. Batch_loss: 1.592463 \n",
      "Batch: 3305. Acc: 0.411980. Loss: 1.647478. Batch_acc: 0.422209. Batch_loss: 1.593935 \n",
      "Batch: 3306. Acc: 0.411983. Loss: 1.647479. Batch_acc: 0.422339. Batch_loss: 1.650036 \n",
      "Batch: 3307. Acc: 0.411987. Loss: 1.647470. Batch_acc: 0.424435. Batch_loss: 1.619177 \n",
      "Batch: 3308. Acc: 0.411989. Loss: 1.647463. Batch_acc: 0.417396. Batch_loss: 1.623186 \n",
      "Batch: 3309. Acc: 0.411994. Loss: 1.647438. Batch_acc: 0.430239. Batch_loss: 1.565639 \n",
      "Batch: 3310. Acc: 0.411998. Loss: 1.647424. Batch_acc: 0.425446. Batch_loss: 1.603139 \n",
      "Batch: 3311. Acc: 0.412011. Loss: 1.647400. Batch_acc: 0.452287. Batch_loss: 1.567595 \n",
      "Batch: 3312. Acc: 0.412021. Loss: 1.647374. Batch_acc: 0.443270. Batch_loss: 1.563736 \n",
      "Batch: 3313. Acc: 0.412025. Loss: 1.647362. Batch_acc: 0.428319. Batch_loss: 1.606773 \n",
      "Batch: 3314. Acc: 0.412033. Loss: 1.647345. Batch_acc: 0.436164. Batch_loss: 1.590830 \n",
      "Batch: 3315. Acc: 0.412043. Loss: 1.647315. Batch_acc: 0.447052. Batch_loss: 1.549605 \n",
      "Batch: 3316. Acc: 0.412048. Loss: 1.647301. Batch_acc: 0.428738. Batch_loss: 1.599107 \n",
      "Batch: 3317. Acc: 0.412058. Loss: 1.647279. Batch_acc: 0.445154. Batch_loss: 1.573958 \n",
      "Batch: 3318. Acc: 0.412067. Loss: 1.647259. Batch_acc: 0.441833. Batch_loss: 1.580214 \n",
      "Batch: 3319. Acc: 0.412077. Loss: 1.647236. Batch_acc: 0.444573. Batch_loss: 1.570567 \n",
      "Batch: 3320. Acc: 0.412088. Loss: 1.647208. Batch_acc: 0.448968. Batch_loss: 1.552993 \n",
      "Batch: 3321. Acc: 0.412100. Loss: 1.647170. Batch_acc: 0.452765. Batch_loss: 1.521253 \n",
      "Batch: 3322. Acc: 0.412110. Loss: 1.647138. Batch_acc: 0.445217. Batch_loss: 1.542423 \n",
      "Batch: 3323. Acc: 0.412114. Loss: 1.647125. Batch_acc: 0.426334. Batch_loss: 1.601623 \n",
      "Batch: 3324. Acc: 0.412128. Loss: 1.647091. Batch_acc: 0.457175. Batch_loss: 1.535638 \n",
      "Batch: 3325. Acc: 0.412135. Loss: 1.647066. Batch_acc: 0.435986. Batch_loss: 1.563787 \n",
      "Batch: 3326. Acc: 0.412143. Loss: 1.647049. Batch_acc: 0.438721. Batch_loss: 1.588675 \n",
      "Batch: 3327. Acc: 0.412150. Loss: 1.647022. Batch_acc: 0.434487. Batch_loss: 1.559619 \n",
      "Batch: 3328. Acc: 0.412156. Loss: 1.647007. Batch_acc: 0.433372. Batch_loss: 1.597283 \n",
      "Batch: 3329. Acc: 0.412160. Loss: 1.646989. Batch_acc: 0.424173. Batch_loss: 1.587251 \n",
      "Batch: 3330. Acc: 0.412161. Loss: 1.646981. Batch_acc: 0.417640. Batch_loss: 1.618224 \n",
      "Batch: 3331. Acc: 0.412167. Loss: 1.646975. Batch_acc: 0.430425. Batch_loss: 1.626138 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3332. Acc: 0.412182. Loss: 1.646943. Batch_acc: 0.463128. Batch_loss: 1.544113 \n",
      "Batch: 3333. Acc: 0.412195. Loss: 1.646898. Batch_acc: 0.454026. Batch_loss: 1.499434 \n",
      "Batch: 3334. Acc: 0.412201. Loss: 1.646874. Batch_acc: 0.430876. Batch_loss: 1.566811 \n",
      "Batch: 3335. Acc: 0.412212. Loss: 1.646852. Batch_acc: 0.450289. Batch_loss: 1.570408 \n",
      "Batch: 3336. Acc: 0.412218. Loss: 1.646837. Batch_acc: 0.431134. Batch_loss: 1.597721 \n",
      "Batch: 3337. Acc: 0.412225. Loss: 1.646811. Batch_acc: 0.437168. Batch_loss: 1.559485 \n",
      "Batch: 3338. Acc: 0.412233. Loss: 1.646786. Batch_acc: 0.440367. Batch_loss: 1.561205 \n",
      "Batch: 3339. Acc: 0.412241. Loss: 1.646763. Batch_acc: 0.440118. Batch_loss: 1.568836 \n",
      "Batch: 3340. Acc: 0.412254. Loss: 1.646724. Batch_acc: 0.454392. Batch_loss: 1.519482 \n",
      "Batch: 3341. Acc: 0.412268. Loss: 1.646688. Batch_acc: 0.458024. Batch_loss: 1.528308 \n",
      "Batch: 3342. Acc: 0.412272. Loss: 1.646672. Batch_acc: 0.425556. Batch_loss: 1.592652 \n",
      "Batch: 3343. Acc: 0.412278. Loss: 1.646651. Batch_acc: 0.431044. Batch_loss: 1.574604 \n",
      "Batch: 3344. Acc: 0.412281. Loss: 1.646637. Batch_acc: 0.424971. Batch_loss: 1.599308 \n",
      "Batch: 3345. Acc: 0.412294. Loss: 1.646599. Batch_acc: 0.453169. Batch_loss: 1.523955 \n",
      "Batch: 3346. Acc: 0.412295. Loss: 1.646585. Batch_acc: 0.416327. Batch_loss: 1.597918 \n",
      "Batch: 3347. Acc: 0.412297. Loss: 1.646581. Batch_acc: 0.419537. Batch_loss: 1.634786 \n",
      "Batch: 3348. Acc: 0.412306. Loss: 1.646554. Batch_acc: 0.442717. Batch_loss: 1.556469 \n",
      "Batch: 3349. Acc: 0.412319. Loss: 1.646524. Batch_acc: 0.451971. Batch_loss: 1.549788 \n",
      "Batch: 3350. Acc: 0.412333. Loss: 1.646478. Batch_acc: 0.462117. Batch_loss: 1.489950 \n",
      "Batch: 3351. Acc: 0.412333. Loss: 1.646467. Batch_acc: 0.412107. Batch_loss: 1.608675 \n",
      "Batch: 3352. Acc: 0.412342. Loss: 1.646448. Batch_acc: 0.439368. Batch_loss: 1.584484 \n",
      "Batch: 3353. Acc: 0.412356. Loss: 1.646409. Batch_acc: 0.459459. Batch_loss: 1.520227 \n",
      "Batch: 3354. Acc: 0.412369. Loss: 1.646375. Batch_acc: 0.455322. Batch_loss: 1.532474 \n",
      "Batch: 3355. Acc: 0.412370. Loss: 1.646364. Batch_acc: 0.415704. Batch_loss: 1.609351 \n",
      "Batch: 3356. Acc: 0.412386. Loss: 1.646322. Batch_acc: 0.466327. Batch_loss: 1.508225 \n",
      "Batch: 3357. Acc: 0.412391. Loss: 1.646302. Batch_acc: 0.427850. Batch_loss: 1.578903 \n",
      "Batch: 3358. Acc: 0.412404. Loss: 1.646267. Batch_acc: 0.454807. Batch_loss: 1.529634 \n",
      "Batch: 3359. Acc: 0.412412. Loss: 1.646242. Batch_acc: 0.442467. Batch_loss: 1.559476 \n",
      "Batch: 3360. Acc: 0.412415. Loss: 1.646226. Batch_acc: 0.422698. Batch_loss: 1.591649 \n",
      "Batch: 3361. Acc: 0.412432. Loss: 1.646179. Batch_acc: 0.468000. Batch_loss: 1.491329 \n",
      "Batch: 3362. Acc: 0.412441. Loss: 1.646148. Batch_acc: 0.444254. Batch_loss: 1.540295 \n",
      "Batch: 3363. Acc: 0.412444. Loss: 1.646143. Batch_acc: 0.422494. Batch_loss: 1.630157 \n",
      "Batch: 3364. Acc: 0.412460. Loss: 1.646116. Batch_acc: 0.466014. Batch_loss: 1.553340 \n",
      "Batch: 3365. Acc: 0.412478. Loss: 1.646064. Batch_acc: 0.470787. Batch_loss: 1.476260 \n",
      "Batch: 3366. Acc: 0.412485. Loss: 1.646055. Batch_acc: 0.435597. Batch_loss: 1.615582 \n",
      "Batch: 3367. Acc: 0.412493. Loss: 1.646035. Batch_acc: 0.439342. Batch_loss: 1.578365 \n",
      "Batch: 3368. Acc: 0.412501. Loss: 1.646008. Batch_acc: 0.438215. Batch_loss: 1.555822 \n",
      "Batch: 3369. Acc: 0.412510. Loss: 1.645972. Batch_acc: 0.443429. Batch_loss: 1.525722 \n",
      "Batch: 3370. Acc: 0.412511. Loss: 1.645964. Batch_acc: 0.417088. Batch_loss: 1.620911 \n",
      "Batch: 3371. Acc: 0.412514. Loss: 1.645946. Batch_acc: 0.422639. Batch_loss: 1.585783 \n",
      "Batch: 3372. Acc: 0.412519. Loss: 1.645930. Batch_acc: 0.427658. Batch_loss: 1.591560 \n",
      "Batch: 3373. Acc: 0.412522. Loss: 1.645920. Batch_acc: 0.424650. Batch_loss: 1.610092 \n",
      "Batch: 3374. Acc: 0.412537. Loss: 1.645877. Batch_acc: 0.461182. Batch_loss: 1.501616 \n",
      "Batch: 3375. Acc: 0.412550. Loss: 1.645846. Batch_acc: 0.456862. Batch_loss: 1.539971 \n",
      "Batch: 3376. Acc: 0.412559. Loss: 1.645820. Batch_acc: 0.443493. Batch_loss: 1.559134 \n",
      "Batch: 3377. Acc: 0.412562. Loss: 1.645804. Batch_acc: 0.423077. Batch_loss: 1.592074 \n",
      "Batch: 3378. Acc: 0.412570. Loss: 1.645776. Batch_acc: 0.439611. Batch_loss: 1.551604 \n",
      "Batch: 3379. Acc: 0.412580. Loss: 1.645758. Batch_acc: 0.445790. Batch_loss: 1.582641 \n",
      "Batch: 3380. Acc: 0.412583. Loss: 1.645740. Batch_acc: 0.422698. Batch_loss: 1.584735 \n",
      "Batch: 3381. Acc: 0.412586. Loss: 1.645724. Batch_acc: 0.424435. Batch_loss: 1.591191 \n",
      "Batch: 3382. Acc: 0.412593. Loss: 1.645697. Batch_acc: 0.435970. Batch_loss: 1.556314 \n",
      "Batch: 3383. Acc: 0.412606. Loss: 1.645668. Batch_acc: 0.454545. Batch_loss: 1.546778 \n",
      "Batch: 3384. Acc: 0.412612. Loss: 1.645641. Batch_acc: 0.434174. Batch_loss: 1.556685 \n",
      "Batch: 3385. Acc: 0.412621. Loss: 1.645614. Batch_acc: 0.442832. Batch_loss: 1.552311 \n",
      "Batch: 3386. Acc: 0.412627. Loss: 1.645593. Batch_acc: 0.433295. Batch_loss: 1.576459 \n",
      "Batch: 3387. Acc: 0.412635. Loss: 1.645580. Batch_acc: 0.437675. Batch_loss: 1.603272 \n",
      "Batch: 3388. Acc: 0.412645. Loss: 1.645550. Batch_acc: 0.447066. Batch_loss: 1.544234 \n",
      "Batch: 3389. Acc: 0.412660. Loss: 1.645509. Batch_acc: 0.463152. Batch_loss: 1.508946 \n",
      "Batch: 3390. Acc: 0.412664. Loss: 1.645497. Batch_acc: 0.425947. Batch_loss: 1.603849 \n",
      "Batch: 3391. Acc: 0.412673. Loss: 1.645463. Batch_acc: 0.444379. Batch_loss: 1.526473 \n",
      "Batch: 3392. Acc: 0.412673. Loss: 1.645468. Batch_acc: 0.411079. Batch_loss: 1.664492 \n",
      "Batch: 3393. Acc: 0.412685. Loss: 1.645435. Batch_acc: 0.453295. Batch_loss: 1.533043 \n",
      "Batch: 3394. Acc: 0.412695. Loss: 1.645412. Batch_acc: 0.449133. Batch_loss: 1.566425 \n",
      "Batch: 3395. Acc: 0.412701. Loss: 1.645391. Batch_acc: 0.430690. Batch_loss: 1.575716 \n",
      "Batch: 3396. Acc: 0.412705. Loss: 1.645373. Batch_acc: 0.428238. Batch_loss: 1.581625 \n",
      "Batch: 3397. Acc: 0.412718. Loss: 1.645339. Batch_acc: 0.456534. Batch_loss: 1.535644 \n",
      "Batch: 3398. Acc: 0.412727. Loss: 1.645315. Batch_acc: 0.441725. Batch_loss: 1.559660 \n",
      "Batch: 3399. Acc: 0.412734. Loss: 1.645279. Batch_acc: 0.436395. Batch_loss: 1.525022 \n",
      "Batch: 3400. Acc: 0.412734. Loss: 1.645266. Batch_acc: 0.412644. Batch_loss: 1.600091 \n",
      "Batch: 3401. Acc: 0.412742. Loss: 1.645230. Batch_acc: 0.441954. Batch_loss: 1.524255 \n",
      "Batch: 3402. Acc: 0.412746. Loss: 1.645209. Batch_acc: 0.425281. Batch_loss: 1.575573 \n",
      "Batch: 3403. Acc: 0.412748. Loss: 1.645197. Batch_acc: 0.419172. Batch_loss: 1.604676 \n",
      "Batch: 3404. Acc: 0.412756. Loss: 1.645175. Batch_acc: 0.439411. Batch_loss: 1.571887 \n",
      "Batch: 3405. Acc: 0.412771. Loss: 1.645134. Batch_acc: 0.462323. Batch_loss: 1.508810 \n",
      "Batch: 3406. Acc: 0.412784. Loss: 1.645098. Batch_acc: 0.456559. Batch_loss: 1.522275 \n",
      "Batch: 3407. Acc: 0.412789. Loss: 1.645081. Batch_acc: 0.428819. Batch_loss: 1.588921 \n",
      "Batch: 3408. Acc: 0.412800. Loss: 1.645045. Batch_acc: 0.452884. Batch_loss: 1.520175 \n",
      "Batch: 3409. Acc: 0.412806. Loss: 1.645018. Batch_acc: 0.432913. Batch_loss: 1.555384 \n",
      "Batch: 3410. Acc: 0.412816. Loss: 1.644990. Batch_acc: 0.443282. Batch_loss: 1.554002 \n",
      "Batch: 3411. Acc: 0.412819. Loss: 1.644976. Batch_acc: 0.424365. Batch_loss: 1.595756 \n",
      "Batch: 3412. Acc: 0.412827. Loss: 1.644946. Batch_acc: 0.440688. Batch_loss: 1.543629 \n",
      "Batch: 3413. Acc: 0.412837. Loss: 1.644919. Batch_acc: 0.447262. Batch_loss: 1.553155 \n",
      "Batch: 3414. Acc: 0.412851. Loss: 1.644890. Batch_acc: 0.459306. Batch_loss: 1.545992 \n",
      "Batch: 3415. Acc: 0.412855. Loss: 1.644864. Batch_acc: 0.427566. Batch_loss: 1.553686 \n",
      "Batch: 3416. Acc: 0.412860. Loss: 1.644846. Batch_acc: 0.430052. Batch_loss: 1.582305 \n",
      "Batch: 3417. Acc: 0.412865. Loss: 1.644830. Batch_acc: 0.430805. Batch_loss: 1.591820 \n",
      "Batch: 3418. Acc: 0.412876. Loss: 1.644791. Batch_acc: 0.448841. Batch_loss: 1.514346 \n",
      "Batch: 3419. Acc: 0.412883. Loss: 1.644771. Batch_acc: 0.436833. Batch_loss: 1.576347 \n",
      "Batch: 3420. Acc: 0.412889. Loss: 1.644756. Batch_acc: 0.431939. Batch_loss: 1.591475 \n",
      "Batch: 3421. Acc: 0.412897. Loss: 1.644724. Batch_acc: 0.441595. Batch_loss: 1.538401 \n",
      "Batch: 3422. Acc: 0.412903. Loss: 1.644701. Batch_acc: 0.432785. Batch_loss: 1.564608 \n",
      "Batch: 3423. Acc: 0.412903. Loss: 1.644692. Batch_acc: 0.414058. Batch_loss: 1.613056 \n",
      "Batch: 3424. Acc: 0.412911. Loss: 1.644669. Batch_acc: 0.438215. Batch_loss: 1.566667 \n",
      "Batch: 3425. Acc: 0.412926. Loss: 1.644634. Batch_acc: 0.461709. Batch_loss: 1.528766 \n",
      "Batch: 3426. Acc: 0.412933. Loss: 1.644605. Batch_acc: 0.437982. Batch_loss: 1.544654 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3427. Acc: 0.412943. Loss: 1.644583. Batch_acc: 0.449098. Batch_loss: 1.568936 \n",
      "Batch: 3428. Acc: 0.412956. Loss: 1.644549. Batch_acc: 0.456797. Batch_loss: 1.526816 \n",
      "Batch: 3429. Acc: 0.412959. Loss: 1.644537. Batch_acc: 0.422364. Batch_loss: 1.602425 \n",
      "Batch: 3430. Acc: 0.412969. Loss: 1.644511. Batch_acc: 0.447911. Batch_loss: 1.558806 \n",
      "Batch: 3431. Acc: 0.412980. Loss: 1.644482. Batch_acc: 0.452063. Batch_loss: 1.544423 \n",
      "Batch: 3432. Acc: 0.412983. Loss: 1.644470. Batch_acc: 0.422424. Batch_loss: 1.604445 \n",
      "Batch: 3433. Acc: 0.412981. Loss: 1.644475. Batch_acc: 0.403697. Batch_loss: 1.662293 \n",
      "Batch: 3434. Acc: 0.412985. Loss: 1.644456. Batch_acc: 0.427756. Batch_loss: 1.576402 \n",
      "Batch: 3435. Acc: 0.412992. Loss: 1.644438. Batch_acc: 0.436702. Batch_loss: 1.582029 \n",
      "Batch: 3436. Acc: 0.412994. Loss: 1.644431. Batch_acc: 0.421144. Batch_loss: 1.622838 \n",
      "Batch: 3437. Acc: 0.413000. Loss: 1.644420. Batch_acc: 0.432198. Batch_loss: 1.606767 \n",
      "Batch: 3438. Acc: 0.413005. Loss: 1.644403. Batch_acc: 0.431626. Batch_loss: 1.585496 \n",
      "Batch: 3439. Acc: 0.413008. Loss: 1.644385. Batch_acc: 0.422325. Batch_loss: 1.584053 \n",
      "Batch: 3440. Acc: 0.413023. Loss: 1.644342. Batch_acc: 0.464067. Batch_loss: 1.498432 \n",
      "Batch: 3441. Acc: 0.413029. Loss: 1.644321. Batch_acc: 0.433644. Batch_loss: 1.573160 \n",
      "Batch: 3442. Acc: 0.413032. Loss: 1.644312. Batch_acc: 0.422248. Batch_loss: 1.613557 \n",
      "Batch: 3443. Acc: 0.413037. Loss: 1.644304. Batch_acc: 0.430213. Batch_loss: 1.616606 \n",
      "Batch: 3444. Acc: 0.413049. Loss: 1.644274. Batch_acc: 0.454082. Batch_loss: 1.540884 \n",
      "Batch: 3445. Acc: 0.413056. Loss: 1.644250. Batch_acc: 0.439367. Batch_loss: 1.561640 \n",
      "Batch: 3446. Acc: 0.413063. Loss: 1.644231. Batch_acc: 0.435780. Batch_loss: 1.576875 \n",
      "Batch: 3447. Acc: 0.413068. Loss: 1.644217. Batch_acc: 0.431430. Batch_loss: 1.596094 \n",
      "Batch: 3448. Acc: 0.413080. Loss: 1.644185. Batch_acc: 0.452632. Batch_loss: 1.532932 \n",
      "Batch: 3449. Acc: 0.413088. Loss: 1.644158. Batch_acc: 0.443670. Batch_loss: 1.549330 \n",
      "Batch: 3450. Acc: 0.413103. Loss: 1.644119. Batch_acc: 0.463825. Batch_loss: 1.512695 \n",
      "Batch: 3451. Acc: 0.413111. Loss: 1.644104. Batch_acc: 0.438268. Batch_loss: 1.593013 \n",
      "Batch: 3452. Acc: 0.413114. Loss: 1.644088. Batch_acc: 0.423387. Batch_loss: 1.586251 \n",
      "Batch: 3453. Acc: 0.413124. Loss: 1.644073. Batch_acc: 0.449913. Batch_loss: 1.592193 \n",
      "Batch: 3454. Acc: 0.413126. Loss: 1.644053. Batch_acc: 0.420474. Batch_loss: 1.576531 \n",
      "Batch: 3455. Acc: 0.413130. Loss: 1.644041. Batch_acc: 0.426192. Batch_loss: 1.601956 \n",
      "Batch: 3456. Acc: 0.413139. Loss: 1.644016. Batch_acc: 0.442857. Batch_loss: 1.558487 \n",
      "Batch: 3457. Acc: 0.413150. Loss: 1.643984. Batch_acc: 0.451276. Batch_loss: 1.530561 \n",
      "Batch: 3458. Acc: 0.413158. Loss: 1.643959. Batch_acc: 0.441847. Batch_loss: 1.560629 \n",
      "Batch: 3459. Acc: 0.413164. Loss: 1.643950. Batch_acc: 0.433433. Batch_loss: 1.611748 \n",
      "Batch: 3460. Acc: 0.413169. Loss: 1.643938. Batch_acc: 0.432542. Batch_loss: 1.602238 \n",
      "Batch: 3461. Acc: 0.413175. Loss: 1.643916. Batch_acc: 0.432203. Batch_loss: 1.568821 \n",
      "Batch: 3462. Acc: 0.413176. Loss: 1.643910. Batch_acc: 0.417051. Batch_loss: 1.621682 \n",
      "Batch: 3463. Acc: 0.413180. Loss: 1.643895. Batch_acc: 0.427346. Batch_loss: 1.591214 \n",
      "Batch: 3464. Acc: 0.413192. Loss: 1.643870. Batch_acc: 0.453542. Batch_loss: 1.557065 \n",
      "Batch: 3465. Acc: 0.413204. Loss: 1.643841. Batch_acc: 0.453777. Batch_loss: 1.547697 \n",
      "Batch: 3466. Acc: 0.413215. Loss: 1.643819. Batch_acc: 0.453233. Batch_loss: 1.564561 \n",
      "Batch: 3467. Acc: 0.413223. Loss: 1.643793. Batch_acc: 0.440891. Batch_loss: 1.554334 \n",
      "Batch: 3468. Acc: 0.413229. Loss: 1.643769. Batch_acc: 0.435084. Batch_loss: 1.561237 \n",
      "Batch: 3469. Acc: 0.413231. Loss: 1.643760. Batch_acc: 0.417426. Batch_loss: 1.613282 \n",
      "Batch: 3470. Acc: 0.413236. Loss: 1.643736. Batch_acc: 0.432432. Batch_loss: 1.559691 \n",
      "Batch: 3471. Acc: 0.413241. Loss: 1.643722. Batch_acc: 0.429458. Batch_loss: 1.594968 \n",
      "Batch: 3472. Acc: 0.413250. Loss: 1.643701. Batch_acc: 0.445797. Batch_loss: 1.571005 \n",
      "Batch: 3473. Acc: 0.413267. Loss: 1.643659. Batch_acc: 0.472081. Batch_loss: 1.499982 \n",
      "Batch: 3474. Acc: 0.413281. Loss: 1.643626. Batch_acc: 0.460047. Batch_loss: 1.528558 \n",
      "Batch: 3475. Acc: 0.413285. Loss: 1.643609. Batch_acc: 0.430321. Batch_loss: 1.582951 \n",
      "Batch: 3476. Acc: 0.413293. Loss: 1.643590. Batch_acc: 0.438117. Batch_loss: 1.578253 \n",
      "Batch: 3477. Acc: 0.413302. Loss: 1.643561. Batch_acc: 0.446073. Batch_loss: 1.537945 \n",
      "Batch: 3478. Acc: 0.413306. Loss: 1.643541. Batch_acc: 0.426822. Batch_loss: 1.574098 \n",
      "Batch: 3479. Acc: 0.413309. Loss: 1.643533. Batch_acc: 0.424512. Batch_loss: 1.615160 \n",
      "Batch: 3480. Acc: 0.413313. Loss: 1.643518. Batch_acc: 0.428654. Batch_loss: 1.591139 \n",
      "Batch: 3481. Acc: 0.413324. Loss: 1.643493. Batch_acc: 0.451557. Batch_loss: 1.556349 \n",
      "Batch: 3482. Acc: 0.413327. Loss: 1.643480. Batch_acc: 0.423232. Batch_loss: 1.598997 \n",
      "Batch: 3483. Acc: 0.413337. Loss: 1.643450. Batch_acc: 0.449234. Batch_loss: 1.539309 \n",
      "Batch: 3484. Acc: 0.413344. Loss: 1.643420. Batch_acc: 0.437109. Batch_loss: 1.541618 \n",
      "Batch: 3485. Acc: 0.413353. Loss: 1.643395. Batch_acc: 0.443587. Batch_loss: 1.552552 \n",
      "Batch: 3486. Acc: 0.413356. Loss: 1.643393. Batch_acc: 0.426674. Batch_loss: 1.637801 \n",
      "Batch: 3487. Acc: 0.413364. Loss: 1.643372. Batch_acc: 0.439490. Batch_loss: 1.569631 \n",
      "Batch: 3488. Acc: 0.413373. Loss: 1.643349. Batch_acc: 0.445790. Batch_loss: 1.559576 \n",
      "Batch: 3489. Acc: 0.413383. Loss: 1.643320. Batch_acc: 0.447597. Batch_loss: 1.542994 \n",
      "Batch: 3490. Acc: 0.413392. Loss: 1.643285. Batch_acc: 0.446101. Batch_loss: 1.522582 \n",
      "Batch: 3491. Acc: 0.413403. Loss: 1.643254. Batch_acc: 0.450903. Batch_loss: 1.536744 \n",
      "Batch: 3492. Acc: 0.413407. Loss: 1.643250. Batch_acc: 0.425220. Batch_loss: 1.629078 \n",
      "Batch: 3493. Acc: 0.413418. Loss: 1.643221. Batch_acc: 0.452601. Batch_loss: 1.539399 \n",
      "Batch: 3494. Acc: 0.413430. Loss: 1.643178. Batch_acc: 0.457386. Batch_loss: 1.494737 \n",
      "Batch: 3495. Acc: 0.413436. Loss: 1.643153. Batch_acc: 0.431005. Batch_loss: 1.556960 \n",
      "Batch: 3496. Acc: 0.413447. Loss: 1.643122. Batch_acc: 0.452797. Batch_loss: 1.533089 \n",
      "Batch: 3497. Acc: 0.413456. Loss: 1.643095. Batch_acc: 0.443634. Batch_loss: 1.552874 \n",
      "Batch: 3498. Acc: 0.413462. Loss: 1.643071. Batch_acc: 0.435868. Batch_loss: 1.560803 \n",
      "Batch: 3499. Acc: 0.413475. Loss: 1.643040. Batch_acc: 0.458381. Batch_loss: 1.535134 \n",
      "Batch: 3500. Acc: 0.413486. Loss: 1.643006. Batch_acc: 0.453402. Batch_loss: 1.525622 \n",
      "Batch: 3501. Acc: 0.413489. Loss: 1.642993. Batch_acc: 0.423623. Batch_loss: 1.597710 \n",
      "Batch: 3502. Acc: 0.413496. Loss: 1.642968. Batch_acc: 0.438112. Batch_loss: 1.552839 \n",
      "Batch: 3503. Acc: 0.413500. Loss: 1.642958. Batch_acc: 0.424855. Batch_loss: 1.607978 \n",
      "Batch: 3504. Acc: 0.413507. Loss: 1.642936. Batch_acc: 0.439776. Batch_loss: 1.570206 \n",
      "Batch: 3505. Acc: 0.413515. Loss: 1.642912. Batch_acc: 0.441296. Batch_loss: 1.555820 \n",
      "Batch: 3506. Acc: 0.413518. Loss: 1.642904. Batch_acc: 0.423455. Batch_loss: 1.616035 \n",
      "Batch: 3507. Acc: 0.413539. Loss: 1.642851. Batch_acc: 0.483657. Batch_loss: 1.465382 \n",
      "Batch: 3508. Acc: 0.413549. Loss: 1.642823. Batch_acc: 0.450575. Batch_loss: 1.543958 \n",
      "Batch: 3509. Acc: 0.413555. Loss: 1.642806. Batch_acc: 0.434933. Batch_loss: 1.583044 \n",
      "Batch: 3510. Acc: 0.413569. Loss: 1.642774. Batch_acc: 0.462329. Batch_loss: 1.528545 \n",
      "Batch: 3511. Acc: 0.413577. Loss: 1.642752. Batch_acc: 0.439741. Batch_loss: 1.566321 \n",
      "Batch: 3512. Acc: 0.413580. Loss: 1.642737. Batch_acc: 0.426928. Batch_loss: 1.588466 \n",
      "Batch: 3513. Acc: 0.413592. Loss: 1.642707. Batch_acc: 0.453709. Batch_loss: 1.538242 \n",
      "Batch: 3514. Acc: 0.413599. Loss: 1.642682. Batch_acc: 0.438165. Batch_loss: 1.558121 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.4135990970087269. Loss per char: 1.6426823052452066. Time: 1627213129.6493235\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 18, 19, 22, 22, 23,  1, 12,  1, 19,\n",
      "        20, 20, 18, 25, 25, 15, 19, 19, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.413609. Loss: 1.642654. Batch_acc: 0.449352. Batch_loss: 1.539391 \n",
      "Batch: 3516. Acc: 0.413615. Loss: 1.642636. Batch_acc: 0.432861. Batch_loss: 1.582373 \n",
      "Batch: 3517. Acc: 0.413624. Loss: 1.642605. Batch_acc: 0.448033. Batch_loss: 1.531044 \n",
      "Batch: 3518. Acc: 0.413629. Loss: 1.642581. Batch_acc: 0.431949. Batch_loss: 1.557731 \n",
      "Batch: 3519. Acc: 0.413635. Loss: 1.642563. Batch_acc: 0.431679. Batch_loss: 1.580805 \n",
      "Batch: 3520. Acc: 0.413649. Loss: 1.642527. Batch_acc: 0.463442. Batch_loss: 1.517776 \n",
      "Batch: 3521. Acc: 0.413652. Loss: 1.642521. Batch_acc: 0.423392. Batch_loss: 1.623204 \n",
      "Batch: 3522. Acc: 0.413659. Loss: 1.642497. Batch_acc: 0.437822. Batch_loss: 1.556001 \n",
      "Batch: 3523. Acc: 0.413667. Loss: 1.642471. Batch_acc: 0.443341. Batch_loss: 1.551015 \n",
      "Batch: 3524. Acc: 0.413674. Loss: 1.642457. Batch_acc: 0.438286. Batch_loss: 1.593747 \n",
      "Batch: 3525. Acc: 0.413683. Loss: 1.642426. Batch_acc: 0.443998. Batch_loss: 1.533542 \n",
      "Batch: 3526. Acc: 0.413691. Loss: 1.642401. Batch_acc: 0.442604. Batch_loss: 1.554995 \n",
      "Batch: 3527. Acc: 0.413699. Loss: 1.642376. Batch_acc: 0.442008. Batch_loss: 1.552929 \n",
      "Batch: 3528. Acc: 0.413702. Loss: 1.642357. Batch_acc: 0.424190. Batch_loss: 1.573345 \n",
      "Batch: 3529. Acc: 0.413707. Loss: 1.642342. Batch_acc: 0.431909. Batch_loss: 1.591167 \n",
      "Batch: 3530. Acc: 0.413715. Loss: 1.642317. Batch_acc: 0.439955. Batch_loss: 1.557964 \n",
      "Batch: 3531. Acc: 0.413727. Loss: 1.642279. Batch_acc: 0.455932. Batch_loss: 1.509943 \n",
      "Batch: 3532. Acc: 0.413735. Loss: 1.642259. Batch_acc: 0.443169. Batch_loss: 1.569561 \n",
      "Batch: 3533. Acc: 0.413745. Loss: 1.642236. Batch_acc: 0.447093. Batch_loss: 1.560274 \n",
      "Batch: 3534. Acc: 0.413754. Loss: 1.642215. Batch_acc: 0.449249. Batch_loss: 1.564198 \n",
      "Batch: 3535. Acc: 0.413767. Loss: 1.642181. Batch_acc: 0.459016. Batch_loss: 1.523685 \n",
      "Batch: 3536. Acc: 0.413774. Loss: 1.642165. Batch_acc: 0.438567. Batch_loss: 1.589356 \n",
      "Batch: 3537. Acc: 0.413781. Loss: 1.642140. Batch_acc: 0.438717. Batch_loss: 1.551821 \n",
      "Batch: 3538. Acc: 0.413784. Loss: 1.642125. Batch_acc: 0.422119. Batch_loss: 1.588663 \n",
      "Batch: 3539. Acc: 0.413791. Loss: 1.642106. Batch_acc: 0.437931. Batch_loss: 1.576732 \n",
      "Batch: 3540. Acc: 0.413797. Loss: 1.642095. Batch_acc: 0.435694. Batch_loss: 1.604436 \n",
      "Batch: 3541. Acc: 0.413802. Loss: 1.642074. Batch_acc: 0.433295. Batch_loss: 1.568099 \n",
      "Batch: 3542. Acc: 0.413812. Loss: 1.642048. Batch_acc: 0.448899. Batch_loss: 1.549027 \n",
      "Batch: 3543. Acc: 0.413827. Loss: 1.642016. Batch_acc: 0.464347. Batch_loss: 1.529231 \n",
      "Batch: 3544. Acc: 0.413838. Loss: 1.641982. Batch_acc: 0.451576. Batch_loss: 1.524255 \n",
      "Batch: 3545. Acc: 0.413838. Loss: 1.641973. Batch_acc: 0.415429. Batch_loss: 1.608956 \n",
      "Batch: 3546. Acc: 0.413845. Loss: 1.641960. Batch_acc: 0.437785. Batch_loss: 1.597882 \n",
      "Batch: 3547. Acc: 0.413856. Loss: 1.641936. Batch_acc: 0.454756. Batch_loss: 1.555724 \n",
      "Batch: 3548. Acc: 0.413859. Loss: 1.641923. Batch_acc: 0.425073. Batch_loss: 1.596032 \n",
      "Batch: 3549. Acc: 0.413865. Loss: 1.641910. Batch_acc: 0.432793. Batch_loss: 1.594673 \n",
      "Batch: 3550. Acc: 0.413868. Loss: 1.641899. Batch_acc: 0.427807. Batch_loss: 1.602218 \n",
      "Batch: 3551. Acc: 0.413873. Loss: 1.641878. Batch_acc: 0.431452. Batch_loss: 1.565222 \n",
      "Batch: 3552. Acc: 0.413883. Loss: 1.641854. Batch_acc: 0.450350. Batch_loss: 1.554535 \n",
      "Batch: 3553. Acc: 0.413886. Loss: 1.641839. Batch_acc: 0.424107. Batch_loss: 1.593047 \n",
      "Batch: 3554. Acc: 0.413891. Loss: 1.641829. Batch_acc: 0.431065. Batch_loss: 1.602855 \n",
      "Batch: 3555. Acc: 0.413900. Loss: 1.641814. Batch_acc: 0.445487. Batch_loss: 1.589358 \n",
      "Batch: 3556. Acc: 0.413912. Loss: 1.641786. Batch_acc: 0.456171. Batch_loss: 1.542891 \n",
      "Batch: 3557. Acc: 0.413918. Loss: 1.641761. Batch_acc: 0.437573. Batch_loss: 1.550431 \n",
      "Batch: 3558. Acc: 0.413919. Loss: 1.641754. Batch_acc: 0.414564. Batch_loss: 1.618075 \n",
      "Batch: 3559. Acc: 0.413923. Loss: 1.641742. Batch_acc: 0.431831. Batch_loss: 1.596945 \n",
      "Batch: 3560. Acc: 0.413929. Loss: 1.641717. Batch_acc: 0.434082. Batch_loss: 1.552653 \n",
      "Batch: 3561. Acc: 0.413937. Loss: 1.641694. Batch_acc: 0.442467. Batch_loss: 1.556502 \n",
      "Batch: 3562. Acc: 0.413945. Loss: 1.641670. Batch_acc: 0.444508. Batch_loss: 1.555740 \n",
      "Batch: 3563. Acc: 0.413953. Loss: 1.641652. Batch_acc: 0.440208. Batch_loss: 1.577806 \n",
      "Batch: 3564. Acc: 0.413965. Loss: 1.641618. Batch_acc: 0.454647. Batch_loss: 1.526049 \n",
      "Batch: 3565. Acc: 0.413970. Loss: 1.641591. Batch_acc: 0.434908. Batch_loss: 1.544711 \n",
      "Batch: 3566. Acc: 0.413984. Loss: 1.641565. Batch_acc: 0.460011. Batch_loss: 1.549638 \n",
      "Batch: 3567. Acc: 0.413986. Loss: 1.641550. Batch_acc: 0.424191. Batch_loss: 1.587284 \n",
      "Batch: 3568. Acc: 0.413993. Loss: 1.641535. Batch_acc: 0.435942. Batch_loss: 1.587607 \n",
      "Batch: 3569. Acc: 0.414004. Loss: 1.641506. Batch_acc: 0.454598. Batch_loss: 1.538540 \n",
      "Batch: 3570. Acc: 0.414011. Loss: 1.641470. Batch_acc: 0.439052. Batch_loss: 1.515368 \n",
      "Batch: 3571. Acc: 0.414018. Loss: 1.641449. Batch_acc: 0.440115. Batch_loss: 1.567233 \n",
      "Batch: 3572. Acc: 0.414024. Loss: 1.641426. Batch_acc: 0.434758. Batch_loss: 1.556826 \n",
      "Batch: 3573. Acc: 0.414034. Loss: 1.641399. Batch_acc: 0.449349. Batch_loss: 1.549638 \n",
      "Batch: 3574. Acc: 0.414046. Loss: 1.641357. Batch_acc: 0.454906. Batch_loss: 1.490897 \n",
      "Batch: 3575. Acc: 0.414060. Loss: 1.641320. Batch_acc: 0.464773. Batch_loss: 1.510794 \n",
      "Batch: 3576. Acc: 0.414062. Loss: 1.641314. Batch_acc: 0.421687. Batch_loss: 1.619409 \n",
      "Batch: 3577. Acc: 0.414071. Loss: 1.641292. Batch_acc: 0.444249. Batch_loss: 1.562571 \n",
      "Batch: 3578. Acc: 0.414081. Loss: 1.641266. Batch_acc: 0.452199. Batch_loss: 1.546754 \n",
      "Batch: 3579. Acc: 0.414090. Loss: 1.641252. Batch_acc: 0.447813. Batch_loss: 1.588168 \n",
      "Batch: 3580. Acc: 0.414103. Loss: 1.641222. Batch_acc: 0.459757. Batch_loss: 1.533713 \n",
      "Batch: 3581. Acc: 0.414112. Loss: 1.641199. Batch_acc: 0.445610. Batch_loss: 1.562958 \n",
      "Batch: 3582. Acc: 0.414124. Loss: 1.641166. Batch_acc: 0.457803. Batch_loss: 1.522047 \n",
      "Batch: 3583. Acc: 0.414139. Loss: 1.641129. Batch_acc: 0.468860. Batch_loss: 1.504799 \n",
      "Batch: 3584. Acc: 0.414145. Loss: 1.641112. Batch_acc: 0.434860. Batch_loss: 1.577568 \n",
      "Batch: 3585. Acc: 0.414157. Loss: 1.641083. Batch_acc: 0.457447. Batch_loss: 1.540820 \n",
      "Batch: 3586. Acc: 0.414165. Loss: 1.641056. Batch_acc: 0.444315. Batch_loss: 1.543802 \n",
      "Batch: 3587. Acc: 0.414181. Loss: 1.641010. Batch_acc: 0.466298. Batch_loss: 1.481117 \n",
      "Batch: 3588. Acc: 0.414185. Loss: 1.640993. Batch_acc: 0.431659. Batch_loss: 1.581926 \n",
      "Batch: 3589. Acc: 0.414196. Loss: 1.640969. Batch_acc: 0.452436. Batch_loss: 1.552728 \n",
      "Batch: 3590. Acc: 0.414203. Loss: 1.640953. Batch_acc: 0.441228. Batch_loss: 1.583732 \n",
      "Batch: 3591. Acc: 0.414218. Loss: 1.640919. Batch_acc: 0.463662. Batch_loss: 1.521716 \n",
      "Batch: 3592. Acc: 0.414222. Loss: 1.640905. Batch_acc: 0.431044. Batch_loss: 1.590364 \n",
      "Batch: 3593. Acc: 0.414228. Loss: 1.640885. Batch_acc: 0.434631. Batch_loss: 1.566970 \n",
      "Batch: 3594. Acc: 0.414235. Loss: 1.640866. Batch_acc: 0.440281. Batch_loss: 1.572688 \n",
      "Batch: 3595. Acc: 0.414244. Loss: 1.640837. Batch_acc: 0.447430. Batch_loss: 1.532413 \n",
      "Batch: 3596. Acc: 0.414251. Loss: 1.640817. Batch_acc: 0.438488. Batch_loss: 1.570499 \n",
      "Batch: 3597. Acc: 0.414260. Loss: 1.640792. Batch_acc: 0.447928. Batch_loss: 1.555301 \n",
      "Batch: 3598. Acc: 0.414270. Loss: 1.640768. Batch_acc: 0.449914. Batch_loss: 1.552872 \n",
      "Batch: 3599. Acc: 0.414280. Loss: 1.640745. Batch_acc: 0.447821. Batch_loss: 1.557676 \n",
      "Batch: 3600. Acc: 0.414286. Loss: 1.640731. Batch_acc: 0.435838. Batch_loss: 1.591192 \n",
      "Batch: 3601. Acc: 0.414297. Loss: 1.640703. Batch_acc: 0.455497. Batch_loss: 1.539030 \n",
      "Batch: 3602. Acc: 0.414293. Loss: 1.640698. Batch_acc: 0.399314. Batch_loss: 1.623356 \n",
      "Batch: 3603. Acc: 0.414305. Loss: 1.640670. Batch_acc: 0.457077. Batch_loss: 1.537120 \n",
      "Batch: 3604. Acc: 0.414313. Loss: 1.640648. Batch_acc: 0.443240. Batch_loss: 1.564653 \n",
      "Batch: 3605. Acc: 0.414315. Loss: 1.640640. Batch_acc: 0.423768. Batch_loss: 1.611722 \n",
      "Batch: 3606. Acc: 0.414324. Loss: 1.640626. Batch_acc: 0.444255. Batch_loss: 1.588081 \n",
      "Batch: 3607. Acc: 0.414340. Loss: 1.640593. Batch_acc: 0.473081. Batch_loss: 1.521612 \n",
      "Batch: 3608. Acc: 0.414349. Loss: 1.640556. Batch_acc: 0.448018. Batch_loss: 1.508589 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3609. Acc: 0.414355. Loss: 1.640539. Batch_acc: 0.435273. Batch_loss: 1.578573 \n",
      "Batch: 3610. Acc: 0.414354. Loss: 1.640535. Batch_acc: 0.412069. Batch_loss: 1.624730 \n",
      "Batch: 3611. Acc: 0.414359. Loss: 1.640516. Batch_acc: 0.430259. Batch_loss: 1.575067 \n",
      "Batch: 3612. Acc: 0.414362. Loss: 1.640498. Batch_acc: 0.426800. Batch_loss: 1.571593 \n",
      "Batch: 3613. Acc: 0.414370. Loss: 1.640467. Batch_acc: 0.440904. Batch_loss: 1.528721 \n",
      "Batch: 3614. Acc: 0.414373. Loss: 1.640456. Batch_acc: 0.426379. Batch_loss: 1.600157 \n",
      "Batch: 3615. Acc: 0.414381. Loss: 1.640434. Batch_acc: 0.445556. Batch_loss: 1.559201 \n",
      "Batch: 3616. Acc: 0.414389. Loss: 1.640408. Batch_acc: 0.440891. Batch_loss: 1.546676 \n",
      "Batch: 3617. Acc: 0.414391. Loss: 1.640396. Batch_acc: 0.422438. Batch_loss: 1.600047 \n",
      "Batch: 3618. Acc: 0.414402. Loss: 1.640359. Batch_acc: 0.455378. Batch_loss: 1.504485 \n",
      "Batch: 3619. Acc: 0.414407. Loss: 1.640352. Batch_acc: 0.429814. Batch_loss: 1.616939 \n",
      "Batch: 3620. Acc: 0.414414. Loss: 1.640338. Batch_acc: 0.439630. Batch_loss: 1.586657 \n",
      "Batch: 3621. Acc: 0.414418. Loss: 1.640321. Batch_acc: 0.430994. Batch_loss: 1.580661 \n",
      "Batch: 3622. Acc: 0.414427. Loss: 1.640296. Batch_acc: 0.446328. Batch_loss: 1.551014 \n",
      "Batch: 3623. Acc: 0.414433. Loss: 1.640277. Batch_acc: 0.436595. Batch_loss: 1.570441 \n",
      "Batch: 3624. Acc: 0.414443. Loss: 1.640247. Batch_acc: 0.448711. Batch_loss: 1.530238 \n",
      "Batch: 3625. Acc: 0.414456. Loss: 1.640211. Batch_acc: 0.461407. Batch_loss: 1.513411 \n",
      "Batch: 3626. Acc: 0.414468. Loss: 1.640179. Batch_acc: 0.457892. Batch_loss: 1.528494 \n",
      "Batch: 3627. Acc: 0.414476. Loss: 1.640159. Batch_acc: 0.443149. Batch_loss: 1.564615 \n",
      "Batch: 3628. Acc: 0.414481. Loss: 1.640138. Batch_acc: 0.432604. Batch_loss: 1.565398 \n",
      "Batch: 3629. Acc: 0.414490. Loss: 1.640110. Batch_acc: 0.448100. Batch_loss: 1.537531 \n",
      "Batch: 3630. Acc: 0.414493. Loss: 1.640088. Batch_acc: 0.424365. Batch_loss: 1.560429 \n",
      "Batch: 3631. Acc: 0.414502. Loss: 1.640067. Batch_acc: 0.447121. Batch_loss: 1.561711 \n",
      "Batch: 3632. Acc: 0.414512. Loss: 1.640042. Batch_acc: 0.452032. Batch_loss: 1.551083 \n",
      "Batch: 3633. Acc: 0.414516. Loss: 1.640022. Batch_acc: 0.428992. Batch_loss: 1.564834 \n",
      "Batch: 3634. Acc: 0.414526. Loss: 1.639993. Batch_acc: 0.452589. Batch_loss: 1.537008 \n",
      "Batch: 3635. Acc: 0.414535. Loss: 1.639963. Batch_acc: 0.445682. Batch_loss: 1.532942 \n",
      "Batch: 3636. Acc: 0.414547. Loss: 1.639927. Batch_acc: 0.456916. Batch_loss: 1.511585 \n",
      "Batch: 3637. Acc: 0.414550. Loss: 1.639922. Batch_acc: 0.426606. Batch_loss: 1.621543 \n",
      "Batch: 3638. Acc: 0.414564. Loss: 1.639886. Batch_acc: 0.464635. Batch_loss: 1.509653 \n",
      "Batch: 3639. Acc: 0.414572. Loss: 1.639863. Batch_acc: 0.443402. Batch_loss: 1.552221 \n",
      "Batch: 3640. Acc: 0.414580. Loss: 1.639833. Batch_acc: 0.443358. Batch_loss: 1.532222 \n",
      "Batch: 3641. Acc: 0.414586. Loss: 1.639812. Batch_acc: 0.438002. Batch_loss: 1.562198 \n",
      "Batch: 3642. Acc: 0.414589. Loss: 1.639802. Batch_acc: 0.424986. Batch_loss: 1.602933 \n",
      "Batch: 3643. Acc: 0.414592. Loss: 1.639789. Batch_acc: 0.425294. Batch_loss: 1.593918 \n",
      "Batch: 3644. Acc: 0.414603. Loss: 1.639766. Batch_acc: 0.455614. Batch_loss: 1.553941 \n",
      "Batch: 3645. Acc: 0.414607. Loss: 1.639746. Batch_acc: 0.428490. Batch_loss: 1.567771 \n",
      "Batch: 3646. Acc: 0.414614. Loss: 1.639732. Batch_acc: 0.441038. Batch_loss: 1.584491 \n",
      "Batch: 3647. Acc: 0.414624. Loss: 1.639701. Batch_acc: 0.448775. Batch_loss: 1.532513 \n",
      "Batch: 3648. Acc: 0.414630. Loss: 1.639677. Batch_acc: 0.436353. Batch_loss: 1.550620 \n",
      "Batch: 3649. Acc: 0.414637. Loss: 1.639656. Batch_acc: 0.442585. Batch_loss: 1.563677 \n",
      "Batch: 3650. Acc: 0.414647. Loss: 1.639632. Batch_acc: 0.448956. Batch_loss: 1.550576 \n",
      "Batch: 3651. Acc: 0.414650. Loss: 1.639612. Batch_acc: 0.426019. Batch_loss: 1.569307 \n",
      "Batch: 3652. Acc: 0.414657. Loss: 1.639585. Batch_acc: 0.440697. Batch_loss: 1.544781 \n",
      "Batch: 3653. Acc: 0.414669. Loss: 1.639555. Batch_acc: 0.457569. Batch_loss: 1.529800 \n",
      "Batch: 3654. Acc: 0.414679. Loss: 1.639523. Batch_acc: 0.452596. Batch_loss: 1.523010 \n",
      "Batch: 3655. Acc: 0.414688. Loss: 1.639492. Batch_acc: 0.444828. Batch_loss: 1.525197 \n",
      "Batch: 3656. Acc: 0.414688. Loss: 1.639485. Batch_acc: 0.414243. Batch_loss: 1.613295 \n",
      "Batch: 3657. Acc: 0.414696. Loss: 1.639458. Batch_acc: 0.447292. Batch_loss: 1.542631 \n",
      "Batch: 3658. Acc: 0.414706. Loss: 1.639433. Batch_acc: 0.448944. Batch_loss: 1.544578 \n",
      "Batch: 3659. Acc: 0.414715. Loss: 1.639400. Batch_acc: 0.449774. Batch_loss: 1.519478 \n",
      "Batch: 3660. Acc: 0.414724. Loss: 1.639374. Batch_acc: 0.446759. Batch_loss: 1.545528 \n",
      "Batch: 3661. Acc: 0.414728. Loss: 1.639361. Batch_acc: 0.430894. Batch_loss: 1.589631 \n",
      "Batch: 3662. Acc: 0.414734. Loss: 1.639338. Batch_acc: 0.435791. Batch_loss: 1.554317 \n",
      "Batch: 3663. Acc: 0.414739. Loss: 1.639326. Batch_acc: 0.431726. Batch_loss: 1.594238 \n",
      "Batch: 3664. Acc: 0.414739. Loss: 1.639315. Batch_acc: 0.417386. Batch_loss: 1.597809 \n",
      "Batch: 3665. Acc: 0.414744. Loss: 1.639292. Batch_acc: 0.430986. Batch_loss: 1.556939 \n",
      "Batch: 3666. Acc: 0.414749. Loss: 1.639276. Batch_acc: 0.433798. Batch_loss: 1.582015 \n",
      "Batch: 3667. Acc: 0.414758. Loss: 1.639250. Batch_acc: 0.446905. Batch_loss: 1.544975 \n",
      "Batch: 3668. Acc: 0.414764. Loss: 1.639237. Batch_acc: 0.437390. Batch_loss: 1.588161 \n",
      "Batch: 3669. Acc: 0.414769. Loss: 1.639223. Batch_acc: 0.432641. Batch_loss: 1.586456 \n",
      "Batch: 3670. Acc: 0.414772. Loss: 1.639211. Batch_acc: 0.427832. Batch_loss: 1.596177 \n",
      "Batch: 3671. Acc: 0.414782. Loss: 1.639191. Batch_acc: 0.451276. Batch_loss: 1.565604 \n",
      "Batch: 3672. Acc: 0.414790. Loss: 1.639162. Batch_acc: 0.443872. Batch_loss: 1.532938 \n",
      "Batch: 3673. Acc: 0.414793. Loss: 1.639144. Batch_acc: 0.425788. Batch_loss: 1.572336 \n",
      "Batch: 3674. Acc: 0.414800. Loss: 1.639128. Batch_acc: 0.442431. Batch_loss: 1.580009 \n",
      "Batch: 3675. Acc: 0.414805. Loss: 1.639117. Batch_acc: 0.430885. Batch_loss: 1.597664 \n",
      "Batch: 3676. Acc: 0.414815. Loss: 1.639078. Batch_acc: 0.450720. Batch_loss: 1.500350 \n",
      "Batch: 3677. Acc: 0.414826. Loss: 1.639052. Batch_acc: 0.456734. Batch_loss: 1.546290 \n",
      "Batch: 3678. Acc: 0.414833. Loss: 1.639028. Batch_acc: 0.438426. Batch_loss: 1.549581 \n",
      "Batch: 3679. Acc: 0.414840. Loss: 1.639010. Batch_acc: 0.441956. Batch_loss: 1.573350 \n",
      "Batch: 3680. Acc: 0.414851. Loss: 1.638979. Batch_acc: 0.456140. Batch_loss: 1.521704 \n",
      "Batch: 3681. Acc: 0.414860. Loss: 1.638956. Batch_acc: 0.446163. Batch_loss: 1.554563 \n",
      "Batch: 3682. Acc: 0.414867. Loss: 1.638928. Batch_acc: 0.440409. Batch_loss: 1.536345 \n",
      "Batch: 3683. Acc: 0.414873. Loss: 1.638901. Batch_acc: 0.438657. Batch_loss: 1.540078 \n",
      "Batch: 3684. Acc: 0.414883. Loss: 1.638874. Batch_acc: 0.452244. Batch_loss: 1.540605 \n",
      "Batch: 3685. Acc: 0.414896. Loss: 1.638840. Batch_acc: 0.461758. Batch_loss: 1.513323 \n",
      "Batch: 3686. Acc: 0.414900. Loss: 1.638833. Batch_acc: 0.429398. Batch_loss: 1.613268 \n",
      "Batch: 3687. Acc: 0.414903. Loss: 1.638815. Batch_acc: 0.425029. Batch_loss: 1.570611 \n",
      "Batch: 3688. Acc: 0.414910. Loss: 1.638788. Batch_acc: 0.441176. Batch_loss: 1.542579 \n",
      "Batch: 3689. Acc: 0.414920. Loss: 1.638756. Batch_acc: 0.450425. Batch_loss: 1.523402 \n",
      "Batch: 3690. Acc: 0.414929. Loss: 1.638736. Batch_acc: 0.450575. Batch_loss: 1.564724 \n",
      "Batch: 3691. Acc: 0.414929. Loss: 1.638734. Batch_acc: 0.414094. Batch_loss: 1.631560 \n",
      "Batch: 3692. Acc: 0.414938. Loss: 1.638713. Batch_acc: 0.447664. Batch_loss: 1.557901 \n",
      "Batch: 3693. Acc: 0.414943. Loss: 1.638694. Batch_acc: 0.435597. Batch_loss: 1.565990 \n",
      "Batch: 3694. Acc: 0.414955. Loss: 1.638668. Batch_acc: 0.456797. Batch_loss: 1.542071 \n",
      "Batch: 3695. Acc: 0.414960. Loss: 1.638650. Batch_acc: 0.434113. Batch_loss: 1.572561 \n",
      "Batch: 3696. Acc: 0.414969. Loss: 1.638619. Batch_acc: 0.447977. Batch_loss: 1.524928 \n",
      "Batch: 3697. Acc: 0.414976. Loss: 1.638596. Batch_acc: 0.443149. Batch_loss: 1.551196 \n",
      "Batch: 3698. Acc: 0.414976. Loss: 1.638588. Batch_acc: 0.412726. Batch_loss: 1.607935 \n",
      "Batch: 3699. Acc: 0.414981. Loss: 1.638569. Batch_acc: 0.436043. Batch_loss: 1.570649 \n",
      "Batch: 3700. Acc: 0.414989. Loss: 1.638544. Batch_acc: 0.442623. Batch_loss: 1.542732 \n",
      "Batch: 3701. Acc: 0.414996. Loss: 1.638520. Batch_acc: 0.441296. Batch_loss: 1.549753 \n",
      "Batch: 3702. Acc: 0.414999. Loss: 1.638501. Batch_acc: 0.426387. Batch_loss: 1.570546 \n",
      "Batch: 3703. Acc: 0.415014. Loss: 1.638465. Batch_acc: 0.468333. Batch_loss: 1.509196 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3704. Acc: 0.415023. Loss: 1.638443. Batch_acc: 0.449098. Batch_loss: 1.558098 \n",
      "Batch: 3705. Acc: 0.415034. Loss: 1.638410. Batch_acc: 0.457531. Batch_loss: 1.515725 \n",
      "Batch: 3706. Acc: 0.415041. Loss: 1.638389. Batch_acc: 0.440000. Batch_loss: 1.562332 \n",
      "Batch: 3707. Acc: 0.415046. Loss: 1.638365. Batch_acc: 0.430690. Batch_loss: 1.548707 \n",
      "Batch: 3708. Acc: 0.415046. Loss: 1.638352. Batch_acc: 0.417843. Batch_loss: 1.592527 \n",
      "Batch: 3709. Acc: 0.415058. Loss: 1.638321. Batch_acc: 0.457373. Batch_loss: 1.524182 \n",
      "Batch: 3710. Acc: 0.415062. Loss: 1.638309. Batch_acc: 0.430380. Batch_loss: 1.591995 \n",
      "Batch: 3711. Acc: 0.415065. Loss: 1.638290. Batch_acc: 0.426549. Batch_loss: 1.567370 \n",
      "Batch: 3712. Acc: 0.415075. Loss: 1.638261. Batch_acc: 0.454128. Batch_loss: 1.530845 \n",
      "Batch: 3713. Acc: 0.415079. Loss: 1.638240. Batch_acc: 0.428000. Batch_loss: 1.561341 \n",
      "Batch: 3714. Acc: 0.415085. Loss: 1.638219. Batch_acc: 0.438272. Batch_loss: 1.560815 \n",
      "Batch: 3715. Acc: 0.415095. Loss: 1.638188. Batch_acc: 0.451649. Batch_loss: 1.525685 \n",
      "Batch: 3716. Acc: 0.415099. Loss: 1.638179. Batch_acc: 0.426877. Batch_loss: 1.604147 \n",
      "Batch: 3717. Acc: 0.415103. Loss: 1.638154. Batch_acc: 0.431818. Batch_loss: 1.548375 \n",
      "Batch: 3718. Acc: 0.415106. Loss: 1.638147. Batch_acc: 0.426941. Batch_loss: 1.612884 \n",
      "Batch: 3719. Acc: 0.415115. Loss: 1.638127. Batch_acc: 0.446418. Batch_loss: 1.561791 \n",
      "Batch: 3720. Acc: 0.415122. Loss: 1.638107. Batch_acc: 0.442296. Batch_loss: 1.561987 \n",
      "Batch: 3721. Acc: 0.415127. Loss: 1.638101. Batch_acc: 0.433623. Batch_loss: 1.617156 \n",
      "Batch: 3722. Acc: 0.415138. Loss: 1.638069. Batch_acc: 0.455717. Batch_loss: 1.523648 \n",
      "Batch: 3723. Acc: 0.415149. Loss: 1.638040. Batch_acc: 0.458407. Batch_loss: 1.525365 \n",
      "Batch: 3724. Acc: 0.415154. Loss: 1.638025. Batch_acc: 0.432878. Batch_loss: 1.584118 \n",
      "Batch: 3725. Acc: 0.415156. Loss: 1.638016. Batch_acc: 0.422419. Batch_loss: 1.601374 \n",
      "Batch: 3726. Acc: 0.415162. Loss: 1.638007. Batch_acc: 0.437718. Batch_loss: 1.605449 \n",
      "Batch: 3727. Acc: 0.415166. Loss: 1.637992. Batch_acc: 0.429569. Batch_loss: 1.582623 \n",
      "Batch: 3728. Acc: 0.415176. Loss: 1.637966. Batch_acc: 0.451276. Batch_loss: 1.537133 \n",
      "Batch: 3729. Acc: 0.415176. Loss: 1.637962. Batch_acc: 0.416520. Batch_loss: 1.622450 \n",
      "Batch: 3730. Acc: 0.415186. Loss: 1.637930. Batch_acc: 0.452204. Batch_loss: 1.521378 \n",
      "Batch: 3731. Acc: 0.415191. Loss: 1.637913. Batch_acc: 0.435260. Batch_loss: 1.573218 \n",
      "Batch: 3732. Acc: 0.415196. Loss: 1.637903. Batch_acc: 0.433136. Batch_loss: 1.601382 \n",
      "Batch: 3733. Acc: 0.415203. Loss: 1.637884. Batch_acc: 0.442342. Batch_loss: 1.562542 \n",
      "Batch: 3734. Acc: 0.415211. Loss: 1.637854. Batch_acc: 0.444572. Batch_loss: 1.527554 \n",
      "Batch: 3735. Acc: 0.415216. Loss: 1.637831. Batch_acc: 0.435393. Batch_loss: 1.553967 \n",
      "Batch: 3736. Acc: 0.415225. Loss: 1.637806. Batch_acc: 0.447384. Batch_loss: 1.542832 \n",
      "Batch: 3737. Acc: 0.415235. Loss: 1.637780. Batch_acc: 0.451241. Batch_loss: 1.542965 \n",
      "Batch: 3738. Acc: 0.415244. Loss: 1.637757. Batch_acc: 0.450492. Batch_loss: 1.550009 \n",
      "Batch: 3739. Acc: 0.415253. Loss: 1.637737. Batch_acc: 0.449457. Batch_loss: 1.562510 \n",
      "Batch: 3740. Acc: 0.415256. Loss: 1.637730. Batch_acc: 0.427246. Batch_loss: 1.612345 \n",
      "Batch: 3741. Acc: 0.415264. Loss: 1.637700. Batch_acc: 0.442169. Batch_loss: 1.530586 \n",
      "Batch: 3742. Acc: 0.415275. Loss: 1.637671. Batch_acc: 0.455378. Batch_loss: 1.528875 \n",
      "Batch: 3743. Acc: 0.415281. Loss: 1.637648. Batch_acc: 0.439394. Batch_loss: 1.553381 \n",
      "Batch: 3744. Acc: 0.415283. Loss: 1.637631. Batch_acc: 0.421749. Batch_loss: 1.574650 \n",
      "Batch: 3745. Acc: 0.415290. Loss: 1.637608. Batch_acc: 0.440277. Batch_loss: 1.548987 \n",
      "Batch: 3746. Acc: 0.415297. Loss: 1.637587. Batch_acc: 0.443103. Batch_loss: 1.560064 \n",
      "Batch: 3747. Acc: 0.415303. Loss: 1.637564. Batch_acc: 0.436353. Batch_loss: 1.550475 \n",
      "Batch: 3748. Acc: 0.415311. Loss: 1.637540. Batch_acc: 0.447005. Batch_loss: 1.548870 \n",
      "Batch: 3749. Acc: 0.415320. Loss: 1.637510. Batch_acc: 0.449088. Batch_loss: 1.522303 \n",
      "Batch: 3750. Acc: 0.415320. Loss: 1.637503. Batch_acc: 0.417327. Batch_loss: 1.612937 \n",
      "Batch: 3751. Acc: 0.415334. Loss: 1.637463. Batch_acc: 0.462983. Batch_loss: 1.491930 \n",
      "Batch: 3752. Acc: 0.415347. Loss: 1.637429. Batch_acc: 0.463277. Batch_loss: 1.510834 \n",
      "Batch: 3753. Acc: 0.415353. Loss: 1.637419. Batch_acc: 0.439247. Batch_loss: 1.601123 \n",
      "Batch: 3754. Acc: 0.415360. Loss: 1.637401. Batch_acc: 0.441334. Batch_loss: 1.566578 \n",
      "Batch: 3755. Acc: 0.415370. Loss: 1.637374. Batch_acc: 0.452841. Batch_loss: 1.539497 \n",
      "Batch: 3756. Acc: 0.415374. Loss: 1.637363. Batch_acc: 0.432042. Batch_loss: 1.593556 \n",
      "Batch: 3757. Acc: 0.415377. Loss: 1.637352. Batch_acc: 0.424747. Batch_loss: 1.596290 \n",
      "Batch: 3758. Acc: 0.415383. Loss: 1.637332. Batch_acc: 0.438657. Batch_loss: 1.561755 \n",
      "Batch: 3759. Acc: 0.415391. Loss: 1.637303. Batch_acc: 0.444507. Batch_loss: 1.528169 \n",
      "Batch: 3760. Acc: 0.415395. Loss: 1.637286. Batch_acc: 0.430644. Batch_loss: 1.575416 \n",
      "Batch: 3761. Acc: 0.415400. Loss: 1.637272. Batch_acc: 0.435201. Batch_loss: 1.584398 \n",
      "Batch: 3762. Acc: 0.415415. Loss: 1.637231. Batch_acc: 0.469663. Batch_loss: 1.486326 \n",
      "Batch: 3763. Acc: 0.415423. Loss: 1.637208. Batch_acc: 0.445285. Batch_loss: 1.550718 \n",
      "Batch: 3764. Acc: 0.415425. Loss: 1.637199. Batch_acc: 0.422674. Batch_loss: 1.601417 \n",
      "Batch: 3765. Acc: 0.415432. Loss: 1.637170. Batch_acc: 0.443875. Batch_loss: 1.531365 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.41543224253568645. Loss per char: 1.6371704330969088. Time: 1627213327.4382002\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 84, 85, 66,\n",
      "        79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 18, 18, 15, 21, 25, 23,\n",
      "        25,  1, 66, 79, 69,  1, 21, 22, 17, 25, 17, 15, 23, 20, 18, 32,  3,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.415435. Loss: 1.637155. Batch_acc: 0.425030. Batch_loss: 1.577420 \n",
      "Batch: 3767. Acc: 0.415442. Loss: 1.637130. Batch_acc: 0.444508. Batch_loss: 1.543565 \n",
      "Batch: 3768. Acc: 0.415446. Loss: 1.637111. Batch_acc: 0.429617. Batch_loss: 1.567826 \n",
      "Batch: 3769. Acc: 0.415458. Loss: 1.637080. Batch_acc: 0.458381. Batch_loss: 1.518125 \n",
      "Batch: 3770. Acc: 0.415468. Loss: 1.637047. Batch_acc: 0.453970. Batch_loss: 1.513610 \n",
      "Batch: 3771. Acc: 0.415475. Loss: 1.637016. Batch_acc: 0.443804. Batch_loss: 1.521405 \n",
      "Batch: 3772. Acc: 0.415475. Loss: 1.637017. Batch_acc: 0.412921. Batch_loss: 1.640946 \n",
      "Batch: 3773. Acc: 0.415480. Loss: 1.636993. Batch_acc: 0.433089. Batch_loss: 1.546512 \n",
      "Batch: 3774. Acc: 0.415491. Loss: 1.636965. Batch_acc: 0.456498. Batch_loss: 1.536901 \n",
      "Batch: 3775. Acc: 0.415499. Loss: 1.636939. Batch_acc: 0.445701. Batch_loss: 1.539733 \n",
      "Batch: 3776. Acc: 0.415506. Loss: 1.636917. Batch_acc: 0.440659. Batch_loss: 1.554961 \n",
      "Batch: 3777. Acc: 0.415517. Loss: 1.636892. Batch_acc: 0.457916. Batch_loss: 1.540399 \n",
      "Batch: 3778. Acc: 0.415522. Loss: 1.636871. Batch_acc: 0.436471. Batch_loss: 1.555729 \n",
      "Batch: 3779. Acc: 0.415529. Loss: 1.636841. Batch_acc: 0.441244. Batch_loss: 1.524087 \n",
      "Batch: 3780. Acc: 0.415539. Loss: 1.636813. Batch_acc: 0.453287. Batch_loss: 1.528037 \n",
      "Batch: 3781. Acc: 0.415546. Loss: 1.636791. Batch_acc: 0.441328. Batch_loss: 1.556076 \n",
      "Batch: 3782. Acc: 0.415549. Loss: 1.636771. Batch_acc: 0.429402. Batch_loss: 1.561795 \n",
      "Batch: 3783. Acc: 0.415561. Loss: 1.636741. Batch_acc: 0.458651. Batch_loss: 1.519829 \n",
      "Batch: 3784. Acc: 0.415569. Loss: 1.636717. Batch_acc: 0.446509. Batch_loss: 1.548616 \n",
      "Batch: 3785. Acc: 0.415574. Loss: 1.636696. Batch_acc: 0.436164. Batch_loss: 1.556462 \n",
      "Batch: 3786. Acc: 0.415585. Loss: 1.636670. Batch_acc: 0.457278. Batch_loss: 1.536168 \n",
      "Batch: 3787. Acc: 0.415585. Loss: 1.636661. Batch_acc: 0.414938. Batch_loss: 1.599872 \n",
      "Batch: 3788. Acc: 0.415595. Loss: 1.636619. Batch_acc: 0.453933. Batch_loss: 1.483353 \n",
      "Batch: 3789. Acc: 0.415601. Loss: 1.636594. Batch_acc: 0.438853. Batch_loss: 1.537371 \n",
      "Batch: 3790. Acc: 0.415614. Loss: 1.636567. Batch_acc: 0.462644. Batch_loss: 1.534561 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3791. Acc: 0.415623. Loss: 1.636542. Batch_acc: 0.450201. Batch_loss: 1.540854 \n",
      "Batch: 3792. Acc: 0.415633. Loss: 1.636511. Batch_acc: 0.453656. Batch_loss: 1.519943 \n",
      "Batch: 3793. Acc: 0.415640. Loss: 1.636488. Batch_acc: 0.442442. Batch_loss: 1.547269 \n",
      "Batch: 3794. Acc: 0.415646. Loss: 1.636467. Batch_acc: 0.440161. Batch_loss: 1.559108 \n",
      "Batch: 3795. Acc: 0.415651. Loss: 1.636444. Batch_acc: 0.434808. Batch_loss: 1.546671 \n",
      "Batch: 3796. Acc: 0.415661. Loss: 1.636421. Batch_acc: 0.452668. Batch_loss: 1.548615 \n",
      "Batch: 3797. Acc: 0.415666. Loss: 1.636401. Batch_acc: 0.434355. Batch_loss: 1.563026 \n",
      "Batch: 3798. Acc: 0.415674. Loss: 1.636374. Batch_acc: 0.447159. Batch_loss: 1.535004 \n",
      "Batch: 3799. Acc: 0.415680. Loss: 1.636354. Batch_acc: 0.438031. Batch_loss: 1.560691 \n",
      "Batch: 3800. Acc: 0.415686. Loss: 1.636338. Batch_acc: 0.439296. Batch_loss: 1.572064 \n",
      "Batch: 3801. Acc: 0.415693. Loss: 1.636312. Batch_acc: 0.440669. Batch_loss: 1.540395 \n",
      "Batch: 3802. Acc: 0.415702. Loss: 1.636276. Batch_acc: 0.449915. Batch_loss: 1.504257 \n",
      "Batch: 3803. Acc: 0.415703. Loss: 1.636259. Batch_acc: 0.418864. Batch_loss: 1.569438 \n",
      "Batch: 3804. Acc: 0.415705. Loss: 1.636251. Batch_acc: 0.422235. Batch_loss: 1.607438 \n",
      "Batch: 3805. Acc: 0.415712. Loss: 1.636230. Batch_acc: 0.443463. Batch_loss: 1.552484 \n",
      "Batch: 3806. Acc: 0.415720. Loss: 1.636203. Batch_acc: 0.445578. Batch_loss: 1.536138 \n",
      "Batch: 3807. Acc: 0.415728. Loss: 1.636178. Batch_acc: 0.446918. Batch_loss: 1.541927 \n",
      "Batch: 3808. Acc: 0.415734. Loss: 1.636159. Batch_acc: 0.435694. Batch_loss: 1.562204 \n",
      "Batch: 3809. Acc: 0.415741. Loss: 1.636143. Batch_acc: 0.443998. Batch_loss: 1.576426 \n",
      "Batch: 3810. Acc: 0.415747. Loss: 1.636121. Batch_acc: 0.438293. Batch_loss: 1.551054 \n",
      "Batch: 3811. Acc: 0.415757. Loss: 1.636091. Batch_acc: 0.453125. Batch_loss: 1.522931 \n",
      "Batch: 3812. Acc: 0.415764. Loss: 1.636071. Batch_acc: 0.442529. Batch_loss: 1.560267 \n",
      "Batch: 3813. Acc: 0.415765. Loss: 1.636062. Batch_acc: 0.421023. Batch_loss: 1.600507 \n",
      "Batch: 3814. Acc: 0.415769. Loss: 1.636052. Batch_acc: 0.430387. Batch_loss: 1.597887 \n",
      "Batch: 3815. Acc: 0.415771. Loss: 1.636048. Batch_acc: 0.424523. Batch_loss: 1.623217 \n",
      "Batch: 3816. Acc: 0.415774. Loss: 1.636043. Batch_acc: 0.426163. Batch_loss: 1.614888 \n",
      "Batch: 3817. Acc: 0.415779. Loss: 1.636025. Batch_acc: 0.434050. Batch_loss: 1.566463 \n",
      "Batch: 3818. Acc: 0.415785. Loss: 1.636013. Batch_acc: 0.440786. Batch_loss: 1.588397 \n",
      "Batch: 3819. Acc: 0.415789. Loss: 1.636000. Batch_acc: 0.429647. Batch_loss: 1.587428 \n",
      "Batch: 3820. Acc: 0.415798. Loss: 1.635974. Batch_acc: 0.449464. Batch_loss: 1.537997 \n",
      "Batch: 3821. Acc: 0.415799. Loss: 1.635961. Batch_acc: 0.421659. Batch_loss: 1.587156 \n",
      "Batch: 3822. Acc: 0.415809. Loss: 1.635929. Batch_acc: 0.454183. Batch_loss: 1.515381 \n",
      "Batch: 3823. Acc: 0.415820. Loss: 1.635900. Batch_acc: 0.455312. Batch_loss: 1.528018 \n",
      "Batch: 3824. Acc: 0.415830. Loss: 1.635875. Batch_acc: 0.453125. Batch_loss: 1.538371 \n",
      "Batch: 3825. Acc: 0.415830. Loss: 1.635873. Batch_acc: 0.415899. Batch_loss: 1.629253 \n",
      "Batch: 3826. Acc: 0.415836. Loss: 1.635853. Batch_acc: 0.439403. Batch_loss: 1.559940 \n",
      "Batch: 3827. Acc: 0.415846. Loss: 1.635832. Batch_acc: 0.454284. Batch_loss: 1.554481 \n",
      "Batch: 3828. Acc: 0.415851. Loss: 1.635810. Batch_acc: 0.436531. Batch_loss: 1.552123 \n",
      "Batch: 3829. Acc: 0.415864. Loss: 1.635778. Batch_acc: 0.464692. Batch_loss: 1.511872 \n",
      "Batch: 3830. Acc: 0.415869. Loss: 1.635759. Batch_acc: 0.436073. Batch_loss: 1.567019 \n",
      "Batch: 3831. Acc: 0.415873. Loss: 1.635756. Batch_acc: 0.427742. Batch_loss: 1.622503 \n",
      "Batch: 3832. Acc: 0.415887. Loss: 1.635718. Batch_acc: 0.470855. Batch_loss: 1.490804 \n",
      "Batch: 3833. Acc: 0.415890. Loss: 1.635704. Batch_acc: 0.428830. Batch_loss: 1.580286 \n",
      "Batch: 3834. Acc: 0.415902. Loss: 1.635670. Batch_acc: 0.461047. Batch_loss: 1.506229 \n",
      "Batch: 3835. Acc: 0.415907. Loss: 1.635658. Batch_acc: 0.433790. Batch_loss: 1.587620 \n",
      "Batch: 3836. Acc: 0.415914. Loss: 1.635641. Batch_acc: 0.442329. Batch_loss: 1.572987 \n",
      "Batch: 3837. Acc: 0.415918. Loss: 1.635626. Batch_acc: 0.432232. Batch_loss: 1.577067 \n",
      "Batch: 3838. Acc: 0.415923. Loss: 1.635605. Batch_acc: 0.435301. Batch_loss: 1.553718 \n",
      "Batch: 3839. Acc: 0.415931. Loss: 1.635592. Batch_acc: 0.447597. Batch_loss: 1.587188 \n",
      "Batch: 3840. Acc: 0.415938. Loss: 1.635580. Batch_acc: 0.442342. Batch_loss: 1.586585 \n",
      "Batch: 3841. Acc: 0.415946. Loss: 1.635558. Batch_acc: 0.446512. Batch_loss: 1.549163 \n",
      "Batch: 3842. Acc: 0.415958. Loss: 1.635528. Batch_acc: 0.464367. Batch_loss: 1.521817 \n",
      "Batch: 3843. Acc: 0.415967. Loss: 1.635506. Batch_acc: 0.450286. Batch_loss: 1.551302 \n",
      "Batch: 3844. Acc: 0.415980. Loss: 1.635475. Batch_acc: 0.464182. Batch_loss: 1.516531 \n",
      "Batch: 3845. Acc: 0.415985. Loss: 1.635458. Batch_acc: 0.436540. Batch_loss: 1.568778 \n",
      "Batch: 3846. Acc: 0.415991. Loss: 1.635445. Batch_acc: 0.438117. Batch_loss: 1.585288 \n",
      "Batch: 3847. Acc: 0.415997. Loss: 1.635431. Batch_acc: 0.440571. Batch_loss: 1.582807 \n",
      "Batch: 3848. Acc: 0.416002. Loss: 1.635415. Batch_acc: 0.434708. Batch_loss: 1.572996 \n",
      "Batch: 3849. Acc: 0.416008. Loss: 1.635392. Batch_acc: 0.437935. Batch_loss: 1.548202 \n",
      "Batch: 3850. Acc: 0.416013. Loss: 1.635386. Batch_acc: 0.437318. Batch_loss: 1.610242 \n",
      "Batch: 3851. Acc: 0.416019. Loss: 1.635364. Batch_acc: 0.435883. Batch_loss: 1.552980 \n",
      "Batch: 3852. Acc: 0.416030. Loss: 1.635331. Batch_acc: 0.462581. Batch_loss: 1.503335 \n",
      "Batch: 3853. Acc: 0.416035. Loss: 1.635326. Batch_acc: 0.436016. Batch_loss: 1.615776 \n",
      "Batch: 3854. Acc: 0.416037. Loss: 1.635326. Batch_acc: 0.421053. Batch_loss: 1.634352 \n",
      "Batch: 3855. Acc: 0.416040. Loss: 1.635320. Batch_acc: 0.430409. Batch_loss: 1.611886 \n",
      "Batch: 3856. Acc: 0.416044. Loss: 1.635308. Batch_acc: 0.429405. Batch_loss: 1.590407 \n",
      "Batch: 3857. Acc: 0.416046. Loss: 1.635298. Batch_acc: 0.425160. Batch_loss: 1.597232 \n",
      "Batch: 3858. Acc: 0.416053. Loss: 1.635285. Batch_acc: 0.442744. Batch_loss: 1.584127 \n",
      "Batch: 3859. Acc: 0.416054. Loss: 1.635282. Batch_acc: 0.419803. Batch_loss: 1.625341 \n",
      "Batch: 3860. Acc: 0.416059. Loss: 1.635267. Batch_acc: 0.435897. Batch_loss: 1.575891 \n",
      "Batch: 3861. Acc: 0.416066. Loss: 1.635251. Batch_acc: 0.440639. Batch_loss: 1.572671 \n",
      "Batch: 3862. Acc: 0.416074. Loss: 1.635234. Batch_acc: 0.450853. Batch_loss: 1.567501 \n",
      "Batch: 3863. Acc: 0.416076. Loss: 1.635214. Batch_acc: 0.422900. Batch_loss: 1.558223 \n",
      "Batch: 3864. Acc: 0.416082. Loss: 1.635198. Batch_acc: 0.437822. Batch_loss: 1.573681 \n",
      "Batch: 3865. Acc: 0.416089. Loss: 1.635174. Batch_acc: 0.444896. Batch_loss: 1.542964 \n",
      "Batch: 3866. Acc: 0.416107. Loss: 1.635133. Batch_acc: 0.481481. Batch_loss: 1.478448 \n",
      "Batch: 3867. Acc: 0.416116. Loss: 1.635094. Batch_acc: 0.452863. Batch_loss: 1.486342 \n",
      "Batch: 3868. Acc: 0.416122. Loss: 1.635072. Batch_acc: 0.440000. Batch_loss: 1.548676 \n",
      "Batch: 3869. Acc: 0.416130. Loss: 1.635057. Batch_acc: 0.446978. Batch_loss: 1.577306 \n",
      "Batch: 3870. Acc: 0.416137. Loss: 1.635043. Batch_acc: 0.443162. Batch_loss: 1.577315 \n",
      "Batch: 3871. Acc: 0.416146. Loss: 1.635021. Batch_acc: 0.449317. Batch_loss: 1.551366 \n",
      "Batch: 3872. Acc: 0.416150. Loss: 1.635010. Batch_acc: 0.431805. Batch_loss: 1.592713 \n",
      "Batch: 3873. Acc: 0.416157. Loss: 1.634985. Batch_acc: 0.443548. Batch_loss: 1.537898 \n",
      "Batch: 3874. Acc: 0.416165. Loss: 1.634965. Batch_acc: 0.448837. Batch_loss: 1.558710 \n",
      "Batch: 3875. Acc: 0.416173. Loss: 1.634938. Batch_acc: 0.446983. Batch_loss: 1.525872 \n",
      "Batch: 3876. Acc: 0.416175. Loss: 1.634924. Batch_acc: 0.423958. Batch_loss: 1.578645 \n",
      "Batch: 3877. Acc: 0.416182. Loss: 1.634906. Batch_acc: 0.443402. Batch_loss: 1.566735 \n",
      "Batch: 3878. Acc: 0.416188. Loss: 1.634883. Batch_acc: 0.440745. Batch_loss: 1.547536 \n",
      "Batch: 3879. Acc: 0.416193. Loss: 1.634861. Batch_acc: 0.433721. Batch_loss: 1.545426 \n",
      "Batch: 3880. Acc: 0.416199. Loss: 1.634840. Batch_acc: 0.441228. Batch_loss: 1.553287 \n",
      "Batch: 3881. Acc: 0.416207. Loss: 1.634808. Batch_acc: 0.446870. Batch_loss: 1.510358 \n",
      "Batch: 3882. Acc: 0.416218. Loss: 1.634774. Batch_acc: 0.460997. Batch_loss: 1.500837 \n",
      "Batch: 3883. Acc: 0.416222. Loss: 1.634762. Batch_acc: 0.430409. Batch_loss: 1.590251 \n",
      "Batch: 3884. Acc: 0.416231. Loss: 1.634736. Batch_acc: 0.453179. Batch_loss: 1.530836 \n",
      "Batch: 3885. Acc: 0.416236. Loss: 1.634713. Batch_acc: 0.435912. Batch_loss: 1.545176 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3886. Acc: 0.416245. Loss: 1.634697. Batch_acc: 0.450549. Batch_loss: 1.574163 \n",
      "Batch: 3887. Acc: 0.416250. Loss: 1.634680. Batch_acc: 0.436086. Batch_loss: 1.567478 \n",
      "Batch: 3888. Acc: 0.416259. Loss: 1.634649. Batch_acc: 0.452707. Batch_loss: 1.509380 \n",
      "Batch: 3889. Acc: 0.416264. Loss: 1.634635. Batch_acc: 0.434507. Batch_loss: 1.581070 \n",
      "Batch: 3890. Acc: 0.416277. Loss: 1.634594. Batch_acc: 0.466433. Batch_loss: 1.472550 \n",
      "Batch: 3891. Acc: 0.416280. Loss: 1.634573. Batch_acc: 0.428655. Batch_loss: 1.553093 \n",
      "Batch: 3892. Acc: 0.416288. Loss: 1.634547. Batch_acc: 0.445993. Batch_loss: 1.531194 \n",
      "Batch: 3893. Acc: 0.416296. Loss: 1.634532. Batch_acc: 0.449061. Batch_loss: 1.578004 \n",
      "Batch: 3894. Acc: 0.416303. Loss: 1.634519. Batch_acc: 0.444900. Batch_loss: 1.580810 \n",
      "Batch: 3895. Acc: 0.416315. Loss: 1.634490. Batch_acc: 0.459944. Batch_loss: 1.525870 \n",
      "Batch: 3896. Acc: 0.416321. Loss: 1.634470. Batch_acc: 0.440649. Batch_loss: 1.555141 \n",
      "Batch: 3897. Acc: 0.416326. Loss: 1.634452. Batch_acc: 0.434407. Batch_loss: 1.565897 \n",
      "Batch: 3898. Acc: 0.416336. Loss: 1.634430. Batch_acc: 0.457703. Batch_loss: 1.550238 \n",
      "Batch: 3899. Acc: 0.416350. Loss: 1.634403. Batch_acc: 0.469078. Batch_loss: 1.528396 \n",
      "Batch: 3900. Acc: 0.416362. Loss: 1.634370. Batch_acc: 0.464162. Batch_loss: 1.503234 \n",
      "Batch: 3901. Acc: 0.416371. Loss: 1.634346. Batch_acc: 0.452991. Batch_loss: 1.542681 \n",
      "Batch: 3902. Acc: 0.416385. Loss: 1.634312. Batch_acc: 0.468552. Batch_loss: 1.501926 \n",
      "Batch: 3903. Acc: 0.416392. Loss: 1.634289. Batch_acc: 0.443234. Batch_loss: 1.543826 \n",
      "Batch: 3904. Acc: 0.416396. Loss: 1.634277. Batch_acc: 0.435212. Batch_loss: 1.585068 \n",
      "Batch: 3905. Acc: 0.416403. Loss: 1.634265. Batch_acc: 0.442173. Batch_loss: 1.586583 \n",
      "Batch: 3906. Acc: 0.416408. Loss: 1.634250. Batch_acc: 0.435362. Batch_loss: 1.576854 \n",
      "Batch: 3907. Acc: 0.416410. Loss: 1.634237. Batch_acc: 0.424825. Batch_loss: 1.582466 \n",
      "Batch: 3908. Acc: 0.416413. Loss: 1.634223. Batch_acc: 0.429573. Batch_loss: 1.580991 \n",
      "Batch: 3909. Acc: 0.416417. Loss: 1.634206. Batch_acc: 0.432120. Batch_loss: 1.564883 \n",
      "Batch: 3910. Acc: 0.416427. Loss: 1.634181. Batch_acc: 0.453333. Batch_loss: 1.536262 \n",
      "Batch: 3911. Acc: 0.416437. Loss: 1.634148. Batch_acc: 0.455440. Batch_loss: 1.503311 \n",
      "Batch: 3912. Acc: 0.416443. Loss: 1.634123. Batch_acc: 0.440483. Batch_loss: 1.536129 \n",
      "Batch: 3913. Acc: 0.416453. Loss: 1.634090. Batch_acc: 0.456571. Batch_loss: 1.506450 \n",
      "Batch: 3914. Acc: 0.416465. Loss: 1.634059. Batch_acc: 0.464079. Batch_loss: 1.512949 \n",
      "Batch: 3915. Acc: 0.416471. Loss: 1.634038. Batch_acc: 0.440745. Batch_loss: 1.552007 \n",
      "Batch: 3916. Acc: 0.416477. Loss: 1.634019. Batch_acc: 0.438462. Batch_loss: 1.559876 \n",
      "Batch: 3917. Acc: 0.416483. Loss: 1.633995. Batch_acc: 0.440315. Batch_loss: 1.540109 \n",
      "Batch: 3918. Acc: 0.416492. Loss: 1.633973. Batch_acc: 0.449711. Batch_loss: 1.548339 \n",
      "Batch: 3919. Acc: 0.416500. Loss: 1.633949. Batch_acc: 0.449912. Batch_loss: 1.538877 \n",
      "Batch: 3920. Acc: 0.416509. Loss: 1.633924. Batch_acc: 0.451484. Batch_loss: 1.535961 \n",
      "Batch: 3921. Acc: 0.416516. Loss: 1.633905. Batch_acc: 0.444771. Batch_loss: 1.558163 \n",
      "Batch: 3922. Acc: 0.416525. Loss: 1.633874. Batch_acc: 0.452287. Batch_loss: 1.512701 \n",
      "Batch: 3923. Acc: 0.416533. Loss: 1.633838. Batch_acc: 0.448296. Batch_loss: 1.495010 \n",
      "Batch: 3924. Acc: 0.416540. Loss: 1.633823. Batch_acc: 0.444769. Batch_loss: 1.571153 \n",
      "Batch: 3925. Acc: 0.416544. Loss: 1.633811. Batch_acc: 0.429844. Batch_loss: 1.589952 \n",
      "Batch: 3926. Acc: 0.416552. Loss: 1.633782. Batch_acc: 0.448909. Batch_loss: 1.519401 \n",
      "Batch: 3927. Acc: 0.416558. Loss: 1.633766. Batch_acc: 0.441807. Batch_loss: 1.571005 \n",
      "Batch: 3928. Acc: 0.416567. Loss: 1.633750. Batch_acc: 0.448991. Batch_loss: 1.572654 \n",
      "Batch: 3929. Acc: 0.416574. Loss: 1.633726. Batch_acc: 0.442458. Batch_loss: 1.542453 \n",
      "Batch: 3930. Acc: 0.416582. Loss: 1.633704. Batch_acc: 0.447711. Batch_loss: 1.547912 \n",
      "Batch: 3931. Acc: 0.416585. Loss: 1.633705. Batch_acc: 0.427762. Batch_loss: 1.637007 \n",
      "Batch: 3932. Acc: 0.416587. Loss: 1.633704. Batch_acc: 0.423818. Batch_loss: 1.629388 \n",
      "Batch: 3933. Acc: 0.416593. Loss: 1.633687. Batch_acc: 0.442240. Batch_loss: 1.567334 \n",
      "Batch: 3934. Acc: 0.416595. Loss: 1.633676. Batch_acc: 0.424512. Batch_loss: 1.589172 \n",
      "Batch: 3935. Acc: 0.416608. Loss: 1.633645. Batch_acc: 0.465508. Batch_loss: 1.515459 \n",
      "Batch: 3936. Acc: 0.416616. Loss: 1.633619. Batch_acc: 0.447684. Batch_loss: 1.530370 \n",
      "Batch: 3937. Acc: 0.416627. Loss: 1.633582. Batch_acc: 0.460000. Batch_loss: 1.489361 \n",
      "Batch: 3938. Acc: 0.416627. Loss: 1.633581. Batch_acc: 0.419811. Batch_loss: 1.628907 \n",
      "Batch: 3939. Acc: 0.416641. Loss: 1.633544. Batch_acc: 0.468946. Batch_loss: 1.487724 \n",
      "Batch: 3940. Acc: 0.416649. Loss: 1.633520. Batch_acc: 0.448157. Batch_loss: 1.540114 \n",
      "Batch: 3941. Acc: 0.416658. Loss: 1.633496. Batch_acc: 0.453737. Batch_loss: 1.535706 \n",
      "Batch: 3942. Acc: 0.416664. Loss: 1.633467. Batch_acc: 0.441834. Batch_loss: 1.519176 \n",
      "Batch: 3943. Acc: 0.416670. Loss: 1.633448. Batch_acc: 0.437008. Batch_loss: 1.562955 \n",
      "Batch: 3944. Acc: 0.416679. Loss: 1.633420. Batch_acc: 0.455440. Batch_loss: 1.520263 \n",
      "Batch: 3945. Acc: 0.416693. Loss: 1.633381. Batch_acc: 0.470320. Batch_loss: 1.482503 \n",
      "Batch: 3946. Acc: 0.416693. Loss: 1.633378. Batch_acc: 0.417464. Batch_loss: 1.618572 \n",
      "Batch: 3947. Acc: 0.416701. Loss: 1.633359. Batch_acc: 0.447911. Batch_loss: 1.559309 \n",
      "Batch: 3948. Acc: 0.416705. Loss: 1.633337. Batch_acc: 0.433973. Batch_loss: 1.544494 \n",
      "Batch: 3949. Acc: 0.416713. Loss: 1.633314. Batch_acc: 0.445516. Batch_loss: 1.541201 \n",
      "Batch: 3950. Acc: 0.416716. Loss: 1.633304. Batch_acc: 0.429070. Batch_loss: 1.595828 \n",
      "Batch: 3951. Acc: 0.416724. Loss: 1.633278. Batch_acc: 0.448550. Batch_loss: 1.532370 \n",
      "Batch: 3952. Acc: 0.416730. Loss: 1.633260. Batch_acc: 0.439438. Batch_loss: 1.557492 \n",
      "Batch: 3953. Acc: 0.416738. Loss: 1.633232. Batch_acc: 0.448023. Batch_loss: 1.526022 \n",
      "Batch: 3954. Acc: 0.416748. Loss: 1.633211. Batch_acc: 0.458769. Batch_loss: 1.548022 \n",
      "Batch: 3955. Acc: 0.416755. Loss: 1.633196. Batch_acc: 0.443735. Batch_loss: 1.575632 \n",
      "Batch: 3956. Acc: 0.416763. Loss: 1.633166. Batch_acc: 0.447187. Batch_loss: 1.514090 \n",
      "Batch: 3957. Acc: 0.416770. Loss: 1.633141. Batch_acc: 0.444698. Batch_loss: 1.537068 \n",
      "Batch: 3958. Acc: 0.416776. Loss: 1.633121. Batch_acc: 0.440812. Batch_loss: 1.554580 \n",
      "Batch: 3959. Acc: 0.416783. Loss: 1.633104. Batch_acc: 0.442407. Batch_loss: 1.566035 \n",
      "Batch: 3960. Acc: 0.416789. Loss: 1.633091. Batch_acc: 0.442252. Batch_loss: 1.581829 \n",
      "Batch: 3961. Acc: 0.416787. Loss: 1.633090. Batch_acc: 0.410080. Batch_loss: 1.625782 \n",
      "Batch: 3962. Acc: 0.416791. Loss: 1.633073. Batch_acc: 0.430380. Batch_loss: 1.567919 \n",
      "Batch: 3963. Acc: 0.416794. Loss: 1.633061. Batch_acc: 0.431475. Batch_loss: 1.586161 \n",
      "Batch: 3964. Acc: 0.416799. Loss: 1.633044. Batch_acc: 0.434407. Batch_loss: 1.563311 \n",
      "Batch: 3965. Acc: 0.416810. Loss: 1.633010. Batch_acc: 0.463091. Batch_loss: 1.497858 \n",
      "Batch: 3966. Acc: 0.416821. Loss: 1.632983. Batch_acc: 0.458742. Batch_loss: 1.526734 \n",
      "Batch: 3967. Acc: 0.416829. Loss: 1.632965. Batch_acc: 0.448296. Batch_loss: 1.559792 \n",
      "Batch: 3968. Acc: 0.416838. Loss: 1.632941. Batch_acc: 0.452164. Batch_loss: 1.539349 \n",
      "Batch: 3969. Acc: 0.416838. Loss: 1.632929. Batch_acc: 0.419830. Batch_loss: 1.587125 \n",
      "Batch: 3970. Acc: 0.416847. Loss: 1.632911. Batch_acc: 0.451322. Batch_loss: 1.559843 \n",
      "Batch: 3971. Acc: 0.416855. Loss: 1.632886. Batch_acc: 0.447262. Batch_loss: 1.535776 \n",
      "Batch: 3972. Acc: 0.416864. Loss: 1.632858. Batch_acc: 0.453045. Batch_loss: 1.523228 \n",
      "Batch: 3973. Acc: 0.416874. Loss: 1.632834. Batch_acc: 0.455601. Batch_loss: 1.534809 \n",
      "Batch: 3974. Acc: 0.416878. Loss: 1.632827. Batch_acc: 0.436364. Batch_loss: 1.602691 \n",
      "Batch: 3975. Acc: 0.416880. Loss: 1.632817. Batch_acc: 0.421420. Batch_loss: 1.593463 \n",
      "Batch: 3976. Acc: 0.416890. Loss: 1.632791. Batch_acc: 0.455207. Batch_loss: 1.533373 \n",
      "Batch: 3977. Acc: 0.416894. Loss: 1.632785. Batch_acc: 0.433865. Batch_loss: 1.610145 \n",
      "Batch: 3978. Acc: 0.416902. Loss: 1.632762. Batch_acc: 0.451163. Batch_loss: 1.538028 \n",
      "Batch: 3979. Acc: 0.416907. Loss: 1.632746. Batch_acc: 0.436563. Batch_loss: 1.569786 \n",
      "Batch: 3980. Acc: 0.416914. Loss: 1.632729. Batch_acc: 0.445562. Batch_loss: 1.564585 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3981. Acc: 0.416920. Loss: 1.632715. Batch_acc: 0.439908. Batch_loss: 1.574497 \n",
      "Batch: 3982. Acc: 0.416924. Loss: 1.632692. Batch_acc: 0.434682. Batch_loss: 1.539344 \n",
      "Batch: 3983. Acc: 0.416931. Loss: 1.632675. Batch_acc: 0.442566. Batch_loss: 1.565903 \n",
      "Batch: 3984. Acc: 0.416938. Loss: 1.632650. Batch_acc: 0.446460. Batch_loss: 1.533280 \n",
      "Batch: 3985. Acc: 0.416947. Loss: 1.632628. Batch_acc: 0.449638. Batch_loss: 1.547596 \n",
      "Batch: 3986. Acc: 0.416951. Loss: 1.632622. Batch_acc: 0.433099. Batch_loss: 1.606385 \n",
      "Batch: 3987. Acc: 0.416959. Loss: 1.632601. Batch_acc: 0.451762. Batch_loss: 1.549678 \n",
      "Batch: 3988. Acc: 0.416964. Loss: 1.632585. Batch_acc: 0.437935. Batch_loss: 1.567014 \n",
      "Batch: 3989. Acc: 0.416973. Loss: 1.632555. Batch_acc: 0.450256. Batch_loss: 1.515316 \n",
      "Batch: 3990. Acc: 0.416977. Loss: 1.632546. Batch_acc: 0.432524. Batch_loss: 1.596657 \n",
      "Batch: 3991. Acc: 0.416984. Loss: 1.632523. Batch_acc: 0.444954. Batch_loss: 1.540893 \n",
      "Batch: 3992. Acc: 0.416990. Loss: 1.632505. Batch_acc: 0.439523. Batch_loss: 1.562299 \n",
      "Batch: 3993. Acc: 0.417001. Loss: 1.632468. Batch_acc: 0.459899. Batch_loss: 1.486656 \n",
      "Batch: 3994. Acc: 0.417007. Loss: 1.632444. Batch_acc: 0.442375. Batch_loss: 1.534800 \n",
      "Batch: 3995. Acc: 0.417017. Loss: 1.632411. Batch_acc: 0.455262. Batch_loss: 1.503358 \n",
      "Batch: 3996. Acc: 0.417019. Loss: 1.632407. Batch_acc: 0.426786. Batch_loss: 1.616962 \n",
      "Batch: 3997. Acc: 0.417025. Loss: 1.632386. Batch_acc: 0.439093. Batch_loss: 1.549204 \n",
      "Batch: 3998. Acc: 0.417029. Loss: 1.632368. Batch_acc: 0.436226. Batch_loss: 1.561897 \n",
      "Batch: 3999. Acc: 0.417039. Loss: 1.632345. Batch_acc: 0.455711. Batch_loss: 1.537092 \n",
      "Batch: 4000. Acc: 0.417045. Loss: 1.632325. Batch_acc: 0.439310. Batch_loss: 1.555762 \n",
      "Batch: 4001. Acc: 0.417051. Loss: 1.632309. Batch_acc: 0.442050. Batch_loss: 1.568119 \n",
      "Batch: 4002. Acc: 0.417056. Loss: 1.632294. Batch_acc: 0.435502. Batch_loss: 1.571511 \n",
      "Batch: 4003. Acc: 0.417069. Loss: 1.632260. Batch_acc: 0.469271. Batch_loss: 1.497758 \n",
      "Batch: 4004. Acc: 0.417072. Loss: 1.632244. Batch_acc: 0.432977. Batch_loss: 1.564130 \n",
      "Batch: 4005. Acc: 0.417086. Loss: 1.632207. Batch_acc: 0.473081. Batch_loss: 1.486866 \n",
      "Batch: 4006. Acc: 0.417090. Loss: 1.632191. Batch_acc: 0.430548. Batch_loss: 1.566761 \n",
      "Batch: 4007. Acc: 0.417094. Loss: 1.632183. Batch_acc: 0.433638. Batch_loss: 1.600843 \n",
      "Batch: 4008. Acc: 0.417103. Loss: 1.632158. Batch_acc: 0.453860. Batch_loss: 1.531909 \n",
      "Batch: 4009. Acc: 0.417112. Loss: 1.632127. Batch_acc: 0.453638. Batch_loss: 1.503611 \n",
      "Batch: 4010. Acc: 0.417119. Loss: 1.632108. Batch_acc: 0.444058. Batch_loss: 1.554452 \n",
      "Batch: 4011. Acc: 0.417121. Loss: 1.632099. Batch_acc: 0.425386. Batch_loss: 1.595707 \n",
      "Batch: 4012. Acc: 0.417127. Loss: 1.632078. Batch_acc: 0.443998. Batch_loss: 1.551623 \n",
      "Batch: 4013. Acc: 0.417139. Loss: 1.632043. Batch_acc: 0.462057. Batch_loss: 1.491409 \n",
      "Batch: 4014. Acc: 0.417145. Loss: 1.632017. Batch_acc: 0.442229. Batch_loss: 1.525998 \n",
      "Batch: 4015. Acc: 0.417154. Loss: 1.631997. Batch_acc: 0.454231. Batch_loss: 1.552097 \n",
      "Batch: 4016. Acc: 0.417154. Loss: 1.631991. Batch_acc: 0.417654. Batch_loss: 1.609844 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.41715438187592524. Loss per char: 1.6319914577996935. Time: 1627213524.70046\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 14, 18, 25, 26,  1, 66, 79, 69,  1, 14, 20, 23, 19,\n",
      "        24, 17, 17, 17, 25, 24, 21, 25, 17, 18, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.417159. Loss: 1.631972. Batch_acc: 0.435003. Batch_loss: 1.555116 \n",
      "Batch: 4018. Acc: 0.417164. Loss: 1.631949. Batch_acc: 0.438202. Batch_loss: 1.540261 \n",
      "Batch: 4019. Acc: 0.417171. Loss: 1.631932. Batch_acc: 0.444836. Batch_loss: 1.565523 \n",
      "Batch: 4020. Acc: 0.417175. Loss: 1.631923. Batch_acc: 0.434627. Batch_loss: 1.591179 \n",
      "Batch: 4021. Acc: 0.417181. Loss: 1.631903. Batch_acc: 0.442386. Batch_loss: 1.551264 \n",
      "Batch: 4022. Acc: 0.417188. Loss: 1.631881. Batch_acc: 0.445077. Batch_loss: 1.545702 \n",
      "Batch: 4023. Acc: 0.417199. Loss: 1.631870. Batch_acc: 0.458068. Batch_loss: 1.588500 \n",
      "Batch: 4024. Acc: 0.417205. Loss: 1.631846. Batch_acc: 0.444896. Batch_loss: 1.533599 \n",
      "Batch: 4025. Acc: 0.417211. Loss: 1.631822. Batch_acc: 0.438728. Batch_loss: 1.535456 \n",
      "Batch: 4026. Acc: 0.417216. Loss: 1.631807. Batch_acc: 0.438079. Batch_loss: 1.571530 \n",
      "Batch: 4027. Acc: 0.417222. Loss: 1.631791. Batch_acc: 0.440736. Batch_loss: 1.565293 \n",
      "Batch: 4028. Acc: 0.417225. Loss: 1.631772. Batch_acc: 0.432464. Batch_loss: 1.557035 \n",
      "Batch: 4029. Acc: 0.417233. Loss: 1.631744. Batch_acc: 0.447079. Batch_loss: 1.517147 \n",
      "Batch: 4030. Acc: 0.417239. Loss: 1.631725. Batch_acc: 0.442105. Batch_loss: 1.553954 \n",
      "Batch: 4031. Acc: 0.417245. Loss: 1.631706. Batch_acc: 0.441595. Batch_loss: 1.553364 \n",
      "Batch: 4032. Acc: 0.417246. Loss: 1.631700. Batch_acc: 0.423607. Batch_loss: 1.608848 \n",
      "Batch: 4033. Acc: 0.417257. Loss: 1.631673. Batch_acc: 0.460234. Batch_loss: 1.520523 \n",
      "Batch: 4034. Acc: 0.417266. Loss: 1.631654. Batch_acc: 0.452016. Batch_loss: 1.555095 \n",
      "Batch: 4035. Acc: 0.417272. Loss: 1.631634. Batch_acc: 0.444005. Batch_loss: 1.554522 \n",
      "Batch: 4036. Acc: 0.417274. Loss: 1.631628. Batch_acc: 0.422247. Batch_loss: 1.604895 \n",
      "Batch: 4037. Acc: 0.417276. Loss: 1.631613. Batch_acc: 0.425680. Batch_loss: 1.573632 \n",
      "Batch: 4038. Acc: 0.417281. Loss: 1.631598. Batch_acc: 0.439909. Batch_loss: 1.569022 \n",
      "Batch: 4039. Acc: 0.417288. Loss: 1.631574. Batch_acc: 0.444882. Batch_loss: 1.539436 \n",
      "Batch: 4040. Acc: 0.417300. Loss: 1.631544. Batch_acc: 0.463760. Batch_loss: 1.509779 \n",
      "Batch: 4041. Acc: 0.417310. Loss: 1.631519. Batch_acc: 0.458783. Batch_loss: 1.532418 \n",
      "Batch: 4042. Acc: 0.417314. Loss: 1.631499. Batch_acc: 0.432783. Batch_loss: 1.549476 \n",
      "Batch: 4043. Acc: 0.417319. Loss: 1.631478. Batch_acc: 0.438866. Batch_loss: 1.545378 \n",
      "Batch: 4044. Acc: 0.417328. Loss: 1.631452. Batch_acc: 0.452714. Batch_loss: 1.529740 \n",
      "Batch: 4045. Acc: 0.417339. Loss: 1.631424. Batch_acc: 0.461857. Batch_loss: 1.513881 \n",
      "Batch: 4046. Acc: 0.417350. Loss: 1.631388. Batch_acc: 0.459908. Batch_loss: 1.486817 \n",
      "Batch: 4047. Acc: 0.417354. Loss: 1.631373. Batch_acc: 0.435390. Batch_loss: 1.568992 \n",
      "Batch: 4048. Acc: 0.417360. Loss: 1.631358. Batch_acc: 0.440161. Batch_loss: 1.568633 \n",
      "Batch: 4049. Acc: 0.417367. Loss: 1.631337. Batch_acc: 0.447159. Batch_loss: 1.548157 \n",
      "Batch: 4050. Acc: 0.417376. Loss: 1.631315. Batch_acc: 0.452000. Batch_loss: 1.544985 \n",
      "Batch: 4051. Acc: 0.417381. Loss: 1.631293. Batch_acc: 0.437465. Batch_loss: 1.543798 \n",
      "Batch: 4052. Acc: 0.417392. Loss: 1.631261. Batch_acc: 0.462384. Batch_loss: 1.499407 \n",
      "Batch: 4053. Acc: 0.417400. Loss: 1.631240. Batch_acc: 0.451025. Batch_loss: 1.548694 \n",
      "Batch: 4054. Acc: 0.417401. Loss: 1.631231. Batch_acc: 0.420070. Batch_loss: 1.591488 \n",
      "Batch: 4055. Acc: 0.417413. Loss: 1.631190. Batch_acc: 0.463170. Batch_loss: 1.470564 \n",
      "Batch: 4056. Acc: 0.417420. Loss: 1.631171. Batch_acc: 0.448873. Batch_loss: 1.554832 \n",
      "Batch: 4057. Acc: 0.417424. Loss: 1.631168. Batch_acc: 0.433333. Batch_loss: 1.618341 \n",
      "Batch: 4058. Acc: 0.417435. Loss: 1.631140. Batch_acc: 0.462341. Batch_loss: 1.515236 \n",
      "Batch: 4059. Acc: 0.417447. Loss: 1.631102. Batch_acc: 0.466897. Batch_loss: 1.476599 \n",
      "Batch: 4060. Acc: 0.417451. Loss: 1.631092. Batch_acc: 0.432304. Batch_loss: 1.589661 \n",
      "Batch: 4061. Acc: 0.417459. Loss: 1.631071. Batch_acc: 0.451482. Batch_loss: 1.546677 \n",
      "Batch: 4062. Acc: 0.417468. Loss: 1.631044. Batch_acc: 0.452596. Batch_loss: 1.521628 \n",
      "Batch: 4063. Acc: 0.417478. Loss: 1.631021. Batch_acc: 0.458114. Batch_loss: 1.538799 \n",
      "Batch: 4064. Acc: 0.417479. Loss: 1.631028. Batch_acc: 0.423611. Batch_loss: 1.657590 \n",
      "Batch: 4065. Acc: 0.417489. Loss: 1.631003. Batch_acc: 0.456534. Batch_loss: 1.533159 \n",
      "Batch: 4066. Acc: 0.417492. Loss: 1.630994. Batch_acc: 0.428163. Batch_loss: 1.595213 \n",
      "Batch: 4067. Acc: 0.417496. Loss: 1.630983. Batch_acc: 0.432660. Batch_loss: 1.585351 \n",
      "Batch: 4068. Acc: 0.417502. Loss: 1.630963. Batch_acc: 0.445417. Batch_loss: 1.549532 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4069. Acc: 0.417510. Loss: 1.630944. Batch_acc: 0.448354. Batch_loss: 1.553984 \n",
      "Batch: 4070. Acc: 0.417514. Loss: 1.630930. Batch_acc: 0.434832. Batch_loss: 1.572890 \n",
      "Batch: 4071. Acc: 0.417524. Loss: 1.630905. Batch_acc: 0.458333. Batch_loss: 1.531848 \n",
      "Batch: 4072. Acc: 0.417534. Loss: 1.630888. Batch_acc: 0.456261. Batch_loss: 1.560432 \n",
      "Batch: 4073. Acc: 0.417543. Loss: 1.630849. Batch_acc: 0.455625. Batch_loss: 1.475065 \n",
      "Batch: 4074. Acc: 0.417551. Loss: 1.630831. Batch_acc: 0.448658. Batch_loss: 1.556291 \n",
      "Batch: 4075. Acc: 0.417559. Loss: 1.630806. Batch_acc: 0.450450. Batch_loss: 1.531750 \n",
      "Batch: 4076. Acc: 0.417569. Loss: 1.630788. Batch_acc: 0.456790. Batch_loss: 1.557640 \n",
      "Batch: 4077. Acc: 0.417578. Loss: 1.630763. Batch_acc: 0.456221. Batch_loss: 1.526381 \n",
      "Batch: 4078. Acc: 0.417592. Loss: 1.630729. Batch_acc: 0.475533. Batch_loss: 1.492322 \n",
      "Batch: 4079. Acc: 0.417592. Loss: 1.630724. Batch_acc: 0.417146. Batch_loss: 1.609972 \n",
      "Batch: 4080. Acc: 0.417600. Loss: 1.630702. Batch_acc: 0.451765. Batch_loss: 1.540094 \n",
      "Batch: 4081. Acc: 0.417603. Loss: 1.630694. Batch_acc: 0.430402. Batch_loss: 1.599277 \n",
      "Batch: 4082. Acc: 0.417605. Loss: 1.630688. Batch_acc: 0.425608. Batch_loss: 1.602549 \n",
      "Batch: 4083. Acc: 0.417609. Loss: 1.630679. Batch_acc: 0.431805. Batch_loss: 1.595809 \n",
      "Batch: 4084. Acc: 0.417613. Loss: 1.630671. Batch_acc: 0.433239. Batch_loss: 1.598243 \n",
      "Batch: 4085. Acc: 0.417623. Loss: 1.630653. Batch_acc: 0.461673. Batch_loss: 1.554922 \n",
      "Batch: 4086. Acc: 0.417628. Loss: 1.630636. Batch_acc: 0.437247. Batch_loss: 1.561229 \n",
      "Batch: 4087. Acc: 0.417635. Loss: 1.630623. Batch_acc: 0.447183. Batch_loss: 1.578544 \n",
      "Batch: 4088. Acc: 0.417640. Loss: 1.630608. Batch_acc: 0.437720. Batch_loss: 1.564537 \n",
      "Batch: 4089. Acc: 0.417646. Loss: 1.630588. Batch_acc: 0.442874. Batch_loss: 1.550596 \n",
      "Batch: 4090. Acc: 0.417657. Loss: 1.630554. Batch_acc: 0.462952. Batch_loss: 1.489593 \n",
      "Batch: 4091. Acc: 0.417666. Loss: 1.630522. Batch_acc: 0.453974. Batch_loss: 1.502018 \n",
      "Batch: 4092. Acc: 0.417669. Loss: 1.630505. Batch_acc: 0.428329. Batch_loss: 1.559388 \n",
      "Batch: 4093. Acc: 0.417672. Loss: 1.630492. Batch_acc: 0.429068. Batch_loss: 1.579489 \n",
      "Batch: 4094. Acc: 0.417678. Loss: 1.630469. Batch_acc: 0.443418. Batch_loss: 1.535362 \n",
      "Batch: 4095. Acc: 0.417683. Loss: 1.630456. Batch_acc: 0.437428. Batch_loss: 1.576833 \n",
      "Batch: 4096. Acc: 0.417688. Loss: 1.630434. Batch_acc: 0.441109. Batch_loss: 1.538716 \n",
      "Batch: 4097. Acc: 0.417693. Loss: 1.630413. Batch_acc: 0.435248. Batch_loss: 1.548716 \n",
      "Batch: 4098. Acc: 0.417696. Loss: 1.630397. Batch_acc: 0.432920. Batch_loss: 1.562870 \n",
      "Batch: 4099. Acc: 0.417707. Loss: 1.630374. Batch_acc: 0.461627. Batch_loss: 1.538072 \n",
      "Batch: 4100. Acc: 0.417718. Loss: 1.630348. Batch_acc: 0.462151. Batch_loss: 1.525719 \n",
      "Batch: 4101. Acc: 0.417722. Loss: 1.630336. Batch_acc: 0.432401. Batch_loss: 1.580520 \n",
      "Batch: 4102. Acc: 0.417728. Loss: 1.630315. Batch_acc: 0.444709. Batch_loss: 1.540466 \n",
      "Batch: 4103. Acc: 0.417737. Loss: 1.630293. Batch_acc: 0.455006. Batch_loss: 1.540803 \n",
      "Batch: 4104. Acc: 0.417745. Loss: 1.630274. Batch_acc: 0.447874. Batch_loss: 1.550466 \n",
      "Batch: 4105. Acc: 0.417747. Loss: 1.630264. Batch_acc: 0.429392. Batch_loss: 1.588387 \n",
      "Batch: 4106. Acc: 0.417753. Loss: 1.630248. Batch_acc: 0.439883. Batch_loss: 1.564012 \n",
      "Batch: 4107. Acc: 0.417757. Loss: 1.630230. Batch_acc: 0.433742. Batch_loss: 1.561085 \n",
      "Batch: 4108. Acc: 0.417761. Loss: 1.630210. Batch_acc: 0.433735. Batch_loss: 1.546116 \n",
      "Batch: 4109. Acc: 0.417767. Loss: 1.630191. Batch_acc: 0.443670. Batch_loss: 1.552842 \n",
      "Batch: 4110. Acc: 0.417772. Loss: 1.630177. Batch_acc: 0.440435. Batch_loss: 1.573769 \n",
      "Batch: 4111. Acc: 0.417786. Loss: 1.630146. Batch_acc: 0.471526. Batch_loss: 1.501452 \n",
      "Batch: 4112. Acc: 0.417793. Loss: 1.630122. Batch_acc: 0.445871. Batch_loss: 1.535898 \n",
      "Batch: 4113. Acc: 0.417801. Loss: 1.630098. Batch_acc: 0.451706. Batch_loss: 1.529048 \n",
      "Batch: 4114. Acc: 0.417806. Loss: 1.630077. Batch_acc: 0.440588. Batch_loss: 1.541669 \n",
      "Batch: 4115. Acc: 0.417817. Loss: 1.630058. Batch_acc: 0.461274. Batch_loss: 1.554161 \n",
      "Batch: 4116. Acc: 0.417825. Loss: 1.630036. Batch_acc: 0.453088. Batch_loss: 1.534429 \n",
      "Batch: 4117. Acc: 0.417832. Loss: 1.630012. Batch_acc: 0.447201. Batch_loss: 1.533104 \n",
      "Batch: 4118. Acc: 0.417837. Loss: 1.630001. Batch_acc: 0.438758. Batch_loss: 1.584888 \n",
      "Batch: 4119. Acc: 0.417841. Loss: 1.629989. Batch_acc: 0.434166. Batch_loss: 1.578657 \n",
      "Batch: 4120. Acc: 0.417846. Loss: 1.629973. Batch_acc: 0.435260. Batch_loss: 1.566022 \n",
      "Batch: 4121. Acc: 0.417852. Loss: 1.629957. Batch_acc: 0.445029. Batch_loss: 1.561132 \n",
      "Batch: 4122. Acc: 0.417861. Loss: 1.629941. Batch_acc: 0.455285. Batch_loss: 1.564330 \n",
      "Batch: 4123. Acc: 0.417871. Loss: 1.629908. Batch_acc: 0.458551. Batch_loss: 1.493341 \n",
      "Batch: 4124. Acc: 0.417873. Loss: 1.629897. Batch_acc: 0.425215. Batch_loss: 1.584768 \n",
      "Batch: 4125. Acc: 0.417874. Loss: 1.629882. Batch_acc: 0.421777. Batch_loss: 1.567722 \n",
      "Batch: 4126. Acc: 0.417890. Loss: 1.629840. Batch_acc: 0.482565. Batch_loss: 1.460756 \n",
      "Batch: 4127. Acc: 0.417893. Loss: 1.629826. Batch_acc: 0.429954. Batch_loss: 1.573868 \n",
      "Batch: 4128. Acc: 0.417897. Loss: 1.629809. Batch_acc: 0.437860. Batch_loss: 1.558896 \n",
      "Batch: 4129. Acc: 0.417901. Loss: 1.629795. Batch_acc: 0.433506. Batch_loss: 1.572562 \n",
      "Batch: 4130. Acc: 0.417908. Loss: 1.629774. Batch_acc: 0.447113. Batch_loss: 1.542374 \n",
      "Batch: 4131. Acc: 0.417920. Loss: 1.629744. Batch_acc: 0.468085. Batch_loss: 1.507683 \n",
      "Batch: 4132. Acc: 0.417926. Loss: 1.629728. Batch_acc: 0.441008. Batch_loss: 1.562467 \n",
      "Batch: 4133. Acc: 0.417928. Loss: 1.629716. Batch_acc: 0.424650. Batch_loss: 1.576928 \n",
      "Batch: 4134. Acc: 0.417932. Loss: 1.629703. Batch_acc: 0.435986. Batch_loss: 1.576132 \n",
      "Batch: 4135. Acc: 0.417938. Loss: 1.629678. Batch_acc: 0.444123. Batch_loss: 1.528688 \n",
      "Batch: 4136. Acc: 0.417941. Loss: 1.629660. Batch_acc: 0.427598. Batch_loss: 1.554975 \n",
      "Batch: 4137. Acc: 0.417951. Loss: 1.629634. Batch_acc: 0.460000. Batch_loss: 1.524166 \n",
      "Batch: 4138. Acc: 0.417956. Loss: 1.629616. Batch_acc: 0.439438. Batch_loss: 1.553427 \n",
      "Batch: 4139. Acc: 0.417964. Loss: 1.629598. Batch_acc: 0.448495. Batch_loss: 1.556070 \n",
      "Batch: 4140. Acc: 0.417968. Loss: 1.629586. Batch_acc: 0.436269. Batch_loss: 1.579658 \n",
      "Batch: 4141. Acc: 0.417982. Loss: 1.629555. Batch_acc: 0.473926. Batch_loss: 1.501171 \n",
      "Batch: 4142. Acc: 0.417985. Loss: 1.629547. Batch_acc: 0.432742. Batch_loss: 1.595536 \n",
      "Batch: 4143. Acc: 0.417990. Loss: 1.629532. Batch_acc: 0.438079. Batch_loss: 1.570131 \n",
      "Batch: 4144. Acc: 0.417997. Loss: 1.629506. Batch_acc: 0.446552. Batch_loss: 1.520224 \n",
      "Batch: 4145. Acc: 0.418001. Loss: 1.629498. Batch_acc: 0.434272. Batch_loss: 1.594190 \n",
      "Batch: 4146. Acc: 0.418005. Loss: 1.629482. Batch_acc: 0.436332. Batch_loss: 1.562934 \n",
      "Batch: 4147. Acc: 0.418013. Loss: 1.629457. Batch_acc: 0.451377. Batch_loss: 1.528300 \n",
      "Batch: 4148. Acc: 0.418016. Loss: 1.629447. Batch_acc: 0.428322. Batch_loss: 1.588410 \n",
      "Batch: 4149. Acc: 0.418025. Loss: 1.629421. Batch_acc: 0.458165. Batch_loss: 1.522010 \n",
      "Batch: 4150. Acc: 0.418027. Loss: 1.629408. Batch_acc: 0.423413. Batch_loss: 1.575881 \n",
      "Batch: 4151. Acc: 0.418034. Loss: 1.629390. Batch_acc: 0.446701. Batch_loss: 1.552739 \n",
      "Batch: 4152. Acc: 0.418044. Loss: 1.629360. Batch_acc: 0.461975. Batch_loss: 1.506882 \n",
      "Batch: 4153. Acc: 0.418052. Loss: 1.629337. Batch_acc: 0.448534. Batch_loss: 1.534022 \n",
      "Batch: 4154. Acc: 0.418054. Loss: 1.629324. Batch_acc: 0.426766. Batch_loss: 1.574758 \n",
      "Batch: 4155. Acc: 0.418062. Loss: 1.629296. Batch_acc: 0.449750. Batch_loss: 1.519968 \n",
      "Batch: 4156. Acc: 0.418065. Loss: 1.629282. Batch_acc: 0.430580. Batch_loss: 1.570365 \n",
      "Batch: 4157. Acc: 0.418076. Loss: 1.629247. Batch_acc: 0.464567. Batch_loss: 1.484782 \n",
      "Batch: 4158. Acc: 0.418082. Loss: 1.629229. Batch_acc: 0.442341. Batch_loss: 1.554853 \n",
      "Batch: 4159. Acc: 0.418091. Loss: 1.629204. Batch_acc: 0.455033. Batch_loss: 1.520292 \n",
      "Batch: 4160. Acc: 0.418096. Loss: 1.629187. Batch_acc: 0.439794. Batch_loss: 1.560370 \n",
      "Batch: 4161. Acc: 0.418105. Loss: 1.629157. Batch_acc: 0.455069. Batch_loss: 1.504663 \n",
      "Batch: 4162. Acc: 0.418110. Loss: 1.629147. Batch_acc: 0.441819. Batch_loss: 1.586586 \n",
      "Batch: 4163. Acc: 0.418115. Loss: 1.629129. Batch_acc: 0.438112. Batch_loss: 1.555075 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4164. Acc: 0.418121. Loss: 1.629115. Batch_acc: 0.442775. Batch_loss: 1.568049 \n",
      "Batch: 4165. Acc: 0.418129. Loss: 1.629095. Batch_acc: 0.450857. Batch_loss: 1.545570 \n",
      "Batch: 4166. Acc: 0.418136. Loss: 1.629069. Batch_acc: 0.447727. Batch_loss: 1.524104 \n",
      "Batch: 4167. Acc: 0.418150. Loss: 1.629030. Batch_acc: 0.475645. Batch_loss: 1.466736 \n",
      "Batch: 4168. Acc: 0.418158. Loss: 1.629007. Batch_acc: 0.453036. Batch_loss: 1.534020 \n",
      "Batch: 4169. Acc: 0.418165. Loss: 1.628984. Batch_acc: 0.446377. Batch_loss: 1.529526 \n",
      "Batch: 4170. Acc: 0.418173. Loss: 1.628966. Batch_acc: 0.450562. Batch_loss: 1.553409 \n",
      "Batch: 4171. Acc: 0.418178. Loss: 1.628951. Batch_acc: 0.441005. Batch_loss: 1.567388 \n",
      "Batch: 4172. Acc: 0.418183. Loss: 1.628936. Batch_acc: 0.438845. Batch_loss: 1.566037 \n",
      "Batch: 4173. Acc: 0.418188. Loss: 1.628919. Batch_acc: 0.441109. Batch_loss: 1.557760 \n",
      "Batch: 4174. Acc: 0.418199. Loss: 1.628890. Batch_acc: 0.462259. Batch_loss: 1.512834 \n",
      "Batch: 4175. Acc: 0.418203. Loss: 1.628882. Batch_acc: 0.435407. Batch_loss: 1.594026 \n",
      "Batch: 4176. Acc: 0.418210. Loss: 1.628856. Batch_acc: 0.446309. Batch_loss: 1.524018 \n",
      "Batch: 4177. Acc: 0.418215. Loss: 1.628836. Batch_acc: 0.438325. Batch_loss: 1.545628 \n",
      "Batch: 4178. Acc: 0.418228. Loss: 1.628800. Batch_acc: 0.473837. Batch_loss: 1.474992 \n",
      "Batch: 4179. Acc: 0.418236. Loss: 1.628782. Batch_acc: 0.452174. Batch_loss: 1.552755 \n",
      "Batch: 4180. Acc: 0.418245. Loss: 1.628758. Batch_acc: 0.452601. Batch_loss: 1.529656 \n",
      "Batch: 4181. Acc: 0.418251. Loss: 1.628745. Batch_acc: 0.447619. Batch_loss: 1.572140 \n",
      "Batch: 4182. Acc: 0.418268. Loss: 1.628703. Batch_acc: 0.487709. Batch_loss: 1.459760 \n",
      "Batch: 4183. Acc: 0.418281. Loss: 1.628676. Batch_acc: 0.469600. Batch_loss: 1.511040 \n",
      "Batch: 4184. Acc: 0.418289. Loss: 1.628649. Batch_acc: 0.452491. Batch_loss: 1.518192 \n",
      "Batch: 4185. Acc: 0.418295. Loss: 1.628627. Batch_acc: 0.445276. Batch_loss: 1.535396 \n",
      "Batch: 4186. Acc: 0.418301. Loss: 1.628617. Batch_acc: 0.442744. Batch_loss: 1.588969 \n",
      "Batch: 4187. Acc: 0.418312. Loss: 1.628586. Batch_acc: 0.463483. Batch_loss: 1.501684 \n",
      "Batch: 4188. Acc: 0.418316. Loss: 1.628566. Batch_acc: 0.434279. Batch_loss: 1.544150 \n",
      "Batch: 4189. Acc: 0.418321. Loss: 1.628547. Batch_acc: 0.439745. Batch_loss: 1.546637 \n",
      "Batch: 4190. Acc: 0.418327. Loss: 1.628521. Batch_acc: 0.445146. Batch_loss: 1.521076 \n",
      "Batch: 4191. Acc: 0.418335. Loss: 1.628504. Batch_acc: 0.451338. Batch_loss: 1.558211 \n",
      "Batch: 4192. Acc: 0.418343. Loss: 1.628483. Batch_acc: 0.448374. Batch_loss: 1.539281 \n",
      "Batch: 4193. Acc: 0.418354. Loss: 1.628447. Batch_acc: 0.466705. Batch_loss: 1.478385 \n",
      "Batch: 4194. Acc: 0.418355. Loss: 1.628438. Batch_acc: 0.420436. Batch_loss: 1.589790 \n",
      "Batch: 4195. Acc: 0.418363. Loss: 1.628414. Batch_acc: 0.454284. Batch_loss: 1.529495 \n",
      "Batch: 4196. Acc: 0.418360. Loss: 1.628408. Batch_acc: 0.406159. Batch_loss: 1.604321 \n",
      "Batch: 4197. Acc: 0.418365. Loss: 1.628388. Batch_acc: 0.438898. Batch_loss: 1.543418 \n",
      "Batch: 4198. Acc: 0.418374. Loss: 1.628364. Batch_acc: 0.453590. Batch_loss: 1.527999 \n",
      "Batch: 4199. Acc: 0.418378. Loss: 1.628346. Batch_acc: 0.435824. Batch_loss: 1.551463 \n",
      "Batch: 4200. Acc: 0.418384. Loss: 1.628327. Batch_acc: 0.444072. Batch_loss: 1.551888 \n",
      "Batch: 4201. Acc: 0.418393. Loss: 1.628297. Batch_acc: 0.454545. Batch_loss: 1.505791 \n",
      "Batch: 4202. Acc: 0.418396. Loss: 1.628280. Batch_acc: 0.433025. Batch_loss: 1.555675 \n",
      "Batch: 4203. Acc: 0.418399. Loss: 1.628266. Batch_acc: 0.430120. Batch_loss: 1.572394 \n",
      "Batch: 4204. Acc: 0.418408. Loss: 1.628239. Batch_acc: 0.454227. Batch_loss: 1.511010 \n",
      "Batch: 4205. Acc: 0.418416. Loss: 1.628213. Batch_acc: 0.453974. Batch_loss: 1.520856 \n",
      "Batch: 4206. Acc: 0.418419. Loss: 1.628200. Batch_acc: 0.431514. Batch_loss: 1.573274 \n",
      "Batch: 4207. Acc: 0.418426. Loss: 1.628172. Batch_acc: 0.446101. Batch_loss: 1.513948 \n",
      "Batch: 4208. Acc: 0.418431. Loss: 1.628158. Batch_acc: 0.438787. Batch_loss: 1.567158 \n",
      "Batch: 4209. Acc: 0.418439. Loss: 1.628137. Batch_acc: 0.452103. Batch_loss: 1.538843 \n",
      "Batch: 4210. Acc: 0.418450. Loss: 1.628111. Batch_acc: 0.466553. Batch_loss: 1.519857 \n",
      "Batch: 4211. Acc: 0.418454. Loss: 1.628092. Batch_acc: 0.434679. Batch_loss: 1.547254 \n",
      "Batch: 4212. Acc: 0.418457. Loss: 1.628081. Batch_acc: 0.431134. Batch_loss: 1.580699 \n",
      "Batch: 4213. Acc: 0.418464. Loss: 1.628063. Batch_acc: 0.446934. Batch_loss: 1.551082 \n",
      "Batch: 4214. Acc: 0.418468. Loss: 1.628047. Batch_acc: 0.436842. Batch_loss: 1.558966 \n",
      "Batch: 4215. Acc: 0.418476. Loss: 1.628027. Batch_acc: 0.450969. Batch_loss: 1.541799 \n",
      "Batch: 4216. Acc: 0.418481. Loss: 1.628010. Batch_acc: 0.442446. Batch_loss: 1.556663 \n",
      "Batch: 4217. Acc: 0.418494. Loss: 1.627979. Batch_acc: 0.474299. Batch_loss: 1.492161 \n",
      "Batch: 4218. Acc: 0.418501. Loss: 1.627956. Batch_acc: 0.447205. Batch_loss: 1.534563 \n",
      "Batch: 4219. Acc: 0.418509. Loss: 1.627948. Batch_acc: 0.449774. Batch_loss: 1.595090 \n",
      "Batch: 4220. Acc: 0.418516. Loss: 1.627922. Batch_acc: 0.450262. Batch_loss: 1.516289 \n",
      "Batch: 4221. Acc: 0.418533. Loss: 1.627883. Batch_acc: 0.486203. Batch_loss: 1.469193 \n",
      "Batch: 4222. Acc: 0.418538. Loss: 1.627864. Batch_acc: 0.440388. Batch_loss: 1.550614 \n",
      "Batch: 4223. Acc: 0.418545. Loss: 1.627843. Batch_acc: 0.448624. Batch_loss: 1.541285 \n",
      "Batch: 4224. Acc: 0.418551. Loss: 1.627821. Batch_acc: 0.442575. Batch_loss: 1.532709 \n",
      "Batch: 4225. Acc: 0.418555. Loss: 1.627805. Batch_acc: 0.435088. Batch_loss: 1.558449 \n",
      "Batch: 4226. Acc: 0.418563. Loss: 1.627781. Batch_acc: 0.452241. Batch_loss: 1.526366 \n",
      "Batch: 4227. Acc: 0.418569. Loss: 1.627765. Batch_acc: 0.445671. Batch_loss: 1.557054 \n",
      "Batch: 4228. Acc: 0.418569. Loss: 1.627756. Batch_acc: 0.418266. Batch_loss: 1.590827 \n",
      "Batch: 4229. Acc: 0.418575. Loss: 1.627744. Batch_acc: 0.443797. Batch_loss: 1.575704 \n",
      "Batch: 4230. Acc: 0.418584. Loss: 1.627718. Batch_acc: 0.458705. Batch_loss: 1.514209 \n",
      "Batch: 4231. Acc: 0.418595. Loss: 1.627687. Batch_acc: 0.463140. Batch_loss: 1.497231 \n",
      "Batch: 4232. Acc: 0.418601. Loss: 1.627666. Batch_acc: 0.445264. Batch_loss: 1.543686 \n",
      "Batch: 4233. Acc: 0.418602. Loss: 1.627651. Batch_acc: 0.423681. Batch_loss: 1.565714 \n",
      "Batch: 4234. Acc: 0.418612. Loss: 1.627625. Batch_acc: 0.459285. Batch_loss: 1.511901 \n",
      "Batch: 4235. Acc: 0.418615. Loss: 1.627614. Batch_acc: 0.430984. Batch_loss: 1.582669 \n",
      "Batch: 4236. Acc: 0.418618. Loss: 1.627607. Batch_acc: 0.434483. Batch_loss: 1.598480 \n",
      "Batch: 4237. Acc: 0.418623. Loss: 1.627589. Batch_acc: 0.438421. Batch_loss: 1.546812 \n",
      "Batch: 4238. Acc: 0.418630. Loss: 1.627564. Batch_acc: 0.446378. Batch_loss: 1.526511 \n",
      "Batch: 4239. Acc: 0.418642. Loss: 1.627536. Batch_acc: 0.467525. Batch_loss: 1.510208 \n",
      "Batch: 4240. Acc: 0.418651. Loss: 1.627508. Batch_acc: 0.459207. Batch_loss: 1.510478 \n",
      "Batch: 4241. Acc: 0.418659. Loss: 1.627484. Batch_acc: 0.453143. Batch_loss: 1.524590 \n",
      "Batch: 4242. Acc: 0.418666. Loss: 1.627465. Batch_acc: 0.449258. Batch_loss: 1.543442 \n",
      "Batch: 4243. Acc: 0.418671. Loss: 1.627445. Batch_acc: 0.437683. Batch_loss: 1.540347 \n",
      "Batch: 4244. Acc: 0.418681. Loss: 1.627420. Batch_acc: 0.463668. Batch_loss: 1.524329 \n",
      "Batch: 4245. Acc: 0.418687. Loss: 1.627403. Batch_acc: 0.443124. Batch_loss: 1.552741 \n",
      "Batch: 4246. Acc: 0.418700. Loss: 1.627363. Batch_acc: 0.472113. Batch_loss: 1.461844 \n",
      "Batch: 4247. Acc: 0.418709. Loss: 1.627333. Batch_acc: 0.455418. Batch_loss: 1.503701 \n",
      "Batch: 4248. Acc: 0.418715. Loss: 1.627312. Batch_acc: 0.445020. Batch_loss: 1.536305 \n",
      "Batch: 4249. Acc: 0.418727. Loss: 1.627282. Batch_acc: 0.471512. Batch_loss: 1.497809 \n",
      "Batch: 4250. Acc: 0.418735. Loss: 1.627258. Batch_acc: 0.452863. Batch_loss: 1.525712 \n",
      "Batch: 4251. Acc: 0.418742. Loss: 1.627238. Batch_acc: 0.445907. Batch_loss: 1.544526 \n",
      "Batch: 4252. Acc: 0.418752. Loss: 1.627208. Batch_acc: 0.462635. Batch_loss: 1.498005 \n",
      "Batch: 4253. Acc: 0.418758. Loss: 1.627187. Batch_acc: 0.442907. Batch_loss: 1.538182 \n",
      "Batch: 4254. Acc: 0.418773. Loss: 1.627152. Batch_acc: 0.483191. Batch_loss: 1.481504 \n",
      "Batch: 4255. Acc: 0.418781. Loss: 1.627127. Batch_acc: 0.452299. Batch_loss: 1.518506 \n",
      "Batch: 4256. Acc: 0.418785. Loss: 1.627120. Batch_acc: 0.436480. Batch_loss: 1.597557 \n",
      "Batch: 4257. Acc: 0.418789. Loss: 1.627104. Batch_acc: 0.437183. Batch_loss: 1.561729 \n",
      "Batch: 4258. Acc: 0.418795. Loss: 1.627082. Batch_acc: 0.443732. Batch_loss: 1.530791 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4259. Acc: 0.418801. Loss: 1.627065. Batch_acc: 0.442431. Batch_loss: 1.554527 \n",
      "Batch: 4260. Acc: 0.418807. Loss: 1.627039. Batch_acc: 0.444191. Batch_loss: 1.515507 \n",
      "Batch: 4261. Acc: 0.418812. Loss: 1.627018. Batch_acc: 0.440531. Batch_loss: 1.540592 \n",
      "Batch: 4262. Acc: 0.418818. Loss: 1.627001. Batch_acc: 0.444318. Batch_loss: 1.555327 \n",
      "Batch: 4263. Acc: 0.418823. Loss: 1.626980. Batch_acc: 0.442025. Batch_loss: 1.531637 \n",
      "Batch: 4264. Acc: 0.418826. Loss: 1.626966. Batch_acc: 0.433276. Batch_loss: 1.570100 \n",
      "Batch: 4265. Acc: 0.418838. Loss: 1.626931. Batch_acc: 0.470385. Batch_loss: 1.477286 \n",
      "Batch: 4266. Acc: 0.418844. Loss: 1.626920. Batch_acc: 0.444898. Batch_loss: 1.578748 \n",
      "Batch: 4267. Acc: 0.418857. Loss: 1.626894. Batch_acc: 0.471904. Batch_loss: 1.515378 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.41885692897968846. Loss per char: 1.6268937813213642. Time: 1627213722.1436605\n",
      "Last question is tensor([ 2, 14, 20, 26, 21, 12, 14, 24, 15, 18, 23, 19, 22, 17, 25, 20,  3,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.418864. Loss: 1.626874. Batch_acc: 0.449201. Batch_loss: 1.545173 \n",
      "Batch: 4269. Acc: 0.418872. Loss: 1.626849. Batch_acc: 0.452546. Batch_loss: 1.518886 \n",
      "Batch: 4270. Acc: 0.418877. Loss: 1.626833. Batch_acc: 0.442099. Batch_loss: 1.557749 \n",
      "Batch: 4271. Acc: 0.418883. Loss: 1.626822. Batch_acc: 0.442153. Batch_loss: 1.579505 \n",
      "Batch: 4272. Acc: 0.418890. Loss: 1.626810. Batch_acc: 0.450947. Batch_loss: 1.576270 \n",
      "Batch: 4273. Acc: 0.418899. Loss: 1.626789. Batch_acc: 0.455322. Batch_loss: 1.538210 \n",
      "Batch: 4274. Acc: 0.418908. Loss: 1.626760. Batch_acc: 0.457093. Batch_loss: 1.499276 \n",
      "Batch: 4275. Acc: 0.418911. Loss: 1.626748. Batch_acc: 0.434122. Batch_loss: 1.576146 \n",
      "Batch: 4276. Acc: 0.418915. Loss: 1.626730. Batch_acc: 0.432853. Batch_loss: 1.551604 \n",
      "Batch: 4277. Acc: 0.418920. Loss: 1.626716. Batch_acc: 0.441058. Batch_loss: 1.567598 \n",
      "Batch: 4278. Acc: 0.418922. Loss: 1.626708. Batch_acc: 0.426606. Batch_loss: 1.592870 \n",
      "Batch: 4279. Acc: 0.418929. Loss: 1.626685. Batch_acc: 0.447635. Batch_loss: 1.527009 \n",
      "Batch: 4280. Acc: 0.418936. Loss: 1.626670. Batch_acc: 0.450720. Batch_loss: 1.563236 \n",
      "Batch: 4281. Acc: 0.418935. Loss: 1.626659. Batch_acc: 0.413218. Batch_loss: 1.582298 \n",
      "Batch: 4282. Acc: 0.418941. Loss: 1.626646. Batch_acc: 0.446574. Batch_loss: 1.568707 \n",
      "Batch: 4283. Acc: 0.418946. Loss: 1.626619. Batch_acc: 0.439498. Batch_loss: 1.513150 \n",
      "Batch: 4284. Acc: 0.418952. Loss: 1.626602. Batch_acc: 0.444316. Batch_loss: 1.551375 \n",
      "Batch: 4285. Acc: 0.418958. Loss: 1.626584. Batch_acc: 0.446023. Batch_loss: 1.550290 \n",
      "Batch: 4286. Acc: 0.418958. Loss: 1.626573. Batch_acc: 0.419767. Batch_loss: 1.581249 \n",
      "Batch: 4287. Acc: 0.418970. Loss: 1.626541. Batch_acc: 0.467927. Batch_loss: 1.490925 \n",
      "Batch: 4288. Acc: 0.418974. Loss: 1.626535. Batch_acc: 0.435355. Batch_loss: 1.597299 \n",
      "Batch: 4289. Acc: 0.418978. Loss: 1.626526. Batch_acc: 0.435972. Batch_loss: 1.588598 \n",
      "Batch: 4290. Acc: 0.418986. Loss: 1.626497. Batch_acc: 0.456958. Batch_loss: 1.499605 \n",
      "Batch: 4291. Acc: 0.418995. Loss: 1.626474. Batch_acc: 0.455451. Batch_loss: 1.531271 \n",
      "Batch: 4292. Acc: 0.418996. Loss: 1.626468. Batch_acc: 0.422209. Batch_loss: 1.599527 \n",
      "Batch: 4293. Acc: 0.418999. Loss: 1.626459. Batch_acc: 0.431338. Batch_loss: 1.587308 \n",
      "Batch: 4294. Acc: 0.419009. Loss: 1.626432. Batch_acc: 0.463080. Batch_loss: 1.513830 \n",
      "Batch: 4295. Acc: 0.419021. Loss: 1.626404. Batch_acc: 0.468520. Batch_loss: 1.505522 \n",
      "Batch: 4296. Acc: 0.419036. Loss: 1.626362. Batch_acc: 0.486766. Batch_loss: 1.444937 \n",
      "Batch: 4297. Acc: 0.419047. Loss: 1.626334. Batch_acc: 0.465250. Batch_loss: 1.508961 \n",
      "Batch: 4298. Acc: 0.419057. Loss: 1.626309. Batch_acc: 0.460806. Batch_loss: 1.518408 \n",
      "Batch: 4299. Acc: 0.419064. Loss: 1.626287. Batch_acc: 0.451155. Batch_loss: 1.531432 \n",
      "Batch: 4300. Acc: 0.419073. Loss: 1.626266. Batch_acc: 0.454702. Batch_loss: 1.536047 \n",
      "Batch: 4301. Acc: 0.419078. Loss: 1.626249. Batch_acc: 0.442980. Batch_loss: 1.554237 \n",
      "Batch: 4302. Acc: 0.419089. Loss: 1.626220. Batch_acc: 0.464932. Batch_loss: 1.501907 \n",
      "Batch: 4303. Acc: 0.419093. Loss: 1.626202. Batch_acc: 0.438300. Batch_loss: 1.548598 \n",
      "Batch: 4304. Acc: 0.419096. Loss: 1.626191. Batch_acc: 0.429240. Batch_loss: 1.576595 \n",
      "Batch: 4305. Acc: 0.419100. Loss: 1.626173. Batch_acc: 0.436676. Batch_loss: 1.552059 \n",
      "Batch: 4306. Acc: 0.419107. Loss: 1.626155. Batch_acc: 0.451482. Batch_loss: 1.547114 \n",
      "Batch: 4307. Acc: 0.419110. Loss: 1.626144. Batch_acc: 0.430012. Batch_loss: 1.574082 \n",
      "Batch: 4308. Acc: 0.419117. Loss: 1.626117. Batch_acc: 0.451192. Batch_loss: 1.513758 \n",
      "Batch: 4309. Acc: 0.419129. Loss: 1.626087. Batch_acc: 0.469184. Batch_loss: 1.502760 \n",
      "Batch: 4310. Acc: 0.419131. Loss: 1.626076. Batch_acc: 0.427490. Batch_loss: 1.574649 \n",
      "Batch: 4311. Acc: 0.419139. Loss: 1.626058. Batch_acc: 0.454333. Batch_loss: 1.550098 \n",
      "Batch: 4312. Acc: 0.419147. Loss: 1.626038. Batch_acc: 0.454123. Batch_loss: 1.535602 \n",
      "Batch: 4313. Acc: 0.419153. Loss: 1.626024. Batch_acc: 0.441261. Batch_loss: 1.569445 \n",
      "Batch: 4314. Acc: 0.419160. Loss: 1.626000. Batch_acc: 0.452149. Batch_loss: 1.521698 \n",
      "Batch: 4315. Acc: 0.419166. Loss: 1.625992. Batch_acc: 0.443920. Batch_loss: 1.589271 \n",
      "Batch: 4316. Acc: 0.419174. Loss: 1.625970. Batch_acc: 0.453356. Batch_loss: 1.531623 \n",
      "Batch: 4317. Acc: 0.419177. Loss: 1.625957. Batch_acc: 0.433080. Batch_loss: 1.569061 \n",
      "Batch: 4318. Acc: 0.419181. Loss: 1.625940. Batch_acc: 0.436702. Batch_loss: 1.552891 \n",
      "Batch: 4319. Acc: 0.419189. Loss: 1.625920. Batch_acc: 0.453549. Batch_loss: 1.538113 \n",
      "Batch: 4320. Acc: 0.419200. Loss: 1.625894. Batch_acc: 0.465077. Batch_loss: 1.515238 \n",
      "Batch: 4321. Acc: 0.419206. Loss: 1.625879. Batch_acc: 0.445143. Batch_loss: 1.563477 \n",
      "Batch: 4322. Acc: 0.419216. Loss: 1.625854. Batch_acc: 0.462617. Batch_loss: 1.513918 \n",
      "Batch: 4323. Acc: 0.419218. Loss: 1.625849. Batch_acc: 0.427995. Batch_loss: 1.605706 \n",
      "Batch: 4324. Acc: 0.419225. Loss: 1.625832. Batch_acc: 0.450413. Batch_loss: 1.551181 \n",
      "Batch: 4325. Acc: 0.419238. Loss: 1.625797. Batch_acc: 0.474670. Batch_loss: 1.479657 \n",
      "Batch: 4326. Acc: 0.419240. Loss: 1.625790. Batch_acc: 0.425959. Batch_loss: 1.594940 \n",
      "Batch: 4327. Acc: 0.419248. Loss: 1.625764. Batch_acc: 0.455865. Batch_loss: 1.512644 \n",
      "Batch: 4328. Acc: 0.419249. Loss: 1.625750. Batch_acc: 0.422803. Batch_loss: 1.561042 \n",
      "Batch: 4329. Acc: 0.419258. Loss: 1.625729. Batch_acc: 0.456763. Batch_loss: 1.541203 \n",
      "Batch: 4330. Acc: 0.419269. Loss: 1.625704. Batch_acc: 0.469741. Batch_loss: 1.517183 \n",
      "Batch: 4331. Acc: 0.419273. Loss: 1.625700. Batch_acc: 0.434172. Batch_loss: 1.606761 \n",
      "Batch: 4332. Acc: 0.419282. Loss: 1.625677. Batch_acc: 0.459155. Batch_loss: 1.526942 \n",
      "Batch: 4333. Acc: 0.419292. Loss: 1.625648. Batch_acc: 0.460080. Batch_loss: 1.499185 \n",
      "Batch: 4334. Acc: 0.419291. Loss: 1.625641. Batch_acc: 0.418764. Batch_loss: 1.598759 \n",
      "Batch: 4335. Acc: 0.419299. Loss: 1.625628. Batch_acc: 0.451726. Batch_loss: 1.568179 \n",
      "Batch: 4336. Acc: 0.419307. Loss: 1.625609. Batch_acc: 0.454020. Batch_loss: 1.542496 \n",
      "Batch: 4337. Acc: 0.419317. Loss: 1.625583. Batch_acc: 0.462065. Batch_loss: 1.511474 \n",
      "Batch: 4338. Acc: 0.419320. Loss: 1.625573. Batch_acc: 0.435882. Batch_loss: 1.580458 \n",
      "Batch: 4339. Acc: 0.419325. Loss: 1.625557. Batch_acc: 0.439817. Batch_loss: 1.559916 \n",
      "Batch: 4340. Acc: 0.419334. Loss: 1.625532. Batch_acc: 0.459918. Batch_loss: 1.514570 \n",
      "Batch: 4341. Acc: 0.419340. Loss: 1.625518. Batch_acc: 0.444444. Batch_loss: 1.561938 \n",
      "Batch: 4342. Acc: 0.419339. Loss: 1.625518. Batch_acc: 0.416084. Batch_loss: 1.627779 \n",
      "Batch: 4343. Acc: 0.419353. Loss: 1.625479. Batch_acc: 0.475410. Batch_loss: 1.457868 \n",
      "Batch: 4344. Acc: 0.419360. Loss: 1.625460. Batch_acc: 0.453134. Batch_loss: 1.542574 \n",
      "Batch: 4345. Acc: 0.419366. Loss: 1.625441. Batch_acc: 0.444830. Batch_loss: 1.541707 \n",
      "Batch: 4346. Acc: 0.419372. Loss: 1.625426. Batch_acc: 0.446590. Batch_loss: 1.559430 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4347. Acc: 0.419379. Loss: 1.625404. Batch_acc: 0.449003. Batch_loss: 1.530647 \n",
      "Batch: 4348. Acc: 0.419387. Loss: 1.625379. Batch_acc: 0.452852. Batch_loss: 1.513920 \n",
      "Batch: 4349. Acc: 0.419393. Loss: 1.625354. Batch_acc: 0.448041. Batch_loss: 1.518656 \n",
      "Batch: 4350. Acc: 0.419401. Loss: 1.625333. Batch_acc: 0.453045. Batch_loss: 1.535614 \n",
      "Batch: 4351. Acc: 0.419408. Loss: 1.625308. Batch_acc: 0.450867. Batch_loss: 1.516770 \n",
      "Batch: 4352. Acc: 0.419414. Loss: 1.625288. Batch_acc: 0.441887. Batch_loss: 1.539935 \n",
      "Batch: 4353. Acc: 0.419424. Loss: 1.625263. Batch_acc: 0.462932. Batch_loss: 1.518894 \n",
      "Batch: 4354. Acc: 0.419427. Loss: 1.625256. Batch_acc: 0.433084. Batch_loss: 1.592735 \n",
      "Batch: 4355. Acc: 0.419434. Loss: 1.625238. Batch_acc: 0.448394. Batch_loss: 1.548245 \n",
      "Batch: 4356. Acc: 0.419443. Loss: 1.625214. Batch_acc: 0.460291. Batch_loss: 1.523609 \n",
      "Batch: 4357. Acc: 0.419450. Loss: 1.625199. Batch_acc: 0.449739. Batch_loss: 1.558781 \n",
      "Batch: 4358. Acc: 0.419457. Loss: 1.625178. Batch_acc: 0.451613. Batch_loss: 1.534575 \n",
      "Batch: 4359. Acc: 0.419468. Loss: 1.625154. Batch_acc: 0.463626. Batch_loss: 1.518202 \n",
      "Batch: 4360. Acc: 0.419470. Loss: 1.625147. Batch_acc: 0.430723. Batch_loss: 1.592742 \n",
      "Batch: 4361. Acc: 0.419473. Loss: 1.625134. Batch_acc: 0.434582. Batch_loss: 1.570771 \n",
      "Batch: 4362. Acc: 0.419483. Loss: 1.625100. Batch_acc: 0.462660. Batch_loss: 1.473789 \n",
      "Batch: 4363. Acc: 0.419491. Loss: 1.625076. Batch_acc: 0.456079. Batch_loss: 1.518195 \n",
      "Batch: 4364. Acc: 0.419499. Loss: 1.625059. Batch_acc: 0.453016. Batch_loss: 1.551121 \n",
      "Batch: 4365. Acc: 0.419503. Loss: 1.625039. Batch_acc: 0.438348. Batch_loss: 1.539937 \n",
      "Batch: 4366. Acc: 0.419513. Loss: 1.625012. Batch_acc: 0.458979. Batch_loss: 1.507121 \n",
      "Batch: 4367. Acc: 0.419519. Loss: 1.624992. Batch_acc: 0.445915. Batch_loss: 1.536393 \n",
      "Batch: 4368. Acc: 0.419526. Loss: 1.624969. Batch_acc: 0.448697. Batch_loss: 1.529981 \n",
      "Batch: 4369. Acc: 0.419534. Loss: 1.624949. Batch_acc: 0.456711. Batch_loss: 1.533699 \n",
      "Batch: 4370. Acc: 0.419548. Loss: 1.624912. Batch_acc: 0.480682. Batch_loss: 1.467395 \n",
      "Batch: 4371. Acc: 0.419560. Loss: 1.624883. Batch_acc: 0.472886. Batch_loss: 1.496947 \n",
      "Batch: 4372. Acc: 0.419571. Loss: 1.624862. Batch_acc: 0.468245. Batch_loss: 1.531140 \n",
      "Batch: 4373. Acc: 0.419576. Loss: 1.624850. Batch_acc: 0.439333. Batch_loss: 1.574521 \n",
      "Batch: 4374. Acc: 0.419586. Loss: 1.624824. Batch_acc: 0.466053. Batch_loss: 1.507789 \n",
      "Batch: 4375. Acc: 0.419593. Loss: 1.624801. Batch_acc: 0.446398. Batch_loss: 1.528154 \n",
      "Batch: 4376. Acc: 0.419599. Loss: 1.624779. Batch_acc: 0.447046. Batch_loss: 1.531375 \n",
      "Batch: 4377. Acc: 0.419611. Loss: 1.624758. Batch_acc: 0.471027. Batch_loss: 1.530584 \n",
      "Batch: 4378. Acc: 0.419615. Loss: 1.624744. Batch_acc: 0.436563. Batch_loss: 1.564176 \n",
      "Batch: 4379. Acc: 0.419618. Loss: 1.624724. Batch_acc: 0.436183. Batch_loss: 1.538286 \n",
      "Batch: 4380. Acc: 0.419628. Loss: 1.624695. Batch_acc: 0.462609. Batch_loss: 1.496752 \n",
      "Batch: 4381. Acc: 0.419635. Loss: 1.624677. Batch_acc: 0.451047. Batch_loss: 1.544610 \n",
      "Batch: 4382. Acc: 0.419648. Loss: 1.624643. Batch_acc: 0.472842. Batch_loss: 1.475572 \n",
      "Batch: 4383. Acc: 0.419658. Loss: 1.624616. Batch_acc: 0.465636. Batch_loss: 1.507408 \n",
      "Batch: 4384. Acc: 0.419657. Loss: 1.624617. Batch_acc: 0.416274. Batch_loss: 1.632161 \n",
      "Batch: 4385. Acc: 0.419665. Loss: 1.624596. Batch_acc: 0.451945. Batch_loss: 1.530908 \n",
      "Batch: 4386. Acc: 0.419674. Loss: 1.624568. Batch_acc: 0.456570. Batch_loss: 1.505992 \n",
      "Batch: 4387. Acc: 0.419675. Loss: 1.624553. Batch_acc: 0.426411. Batch_loss: 1.559932 \n",
      "Batch: 4388. Acc: 0.419683. Loss: 1.624535. Batch_acc: 0.453441. Batch_loss: 1.541189 \n",
      "Batch: 4389. Acc: 0.419688. Loss: 1.624518. Batch_acc: 0.444510. Batch_loss: 1.548813 \n",
      "Batch: 4390. Acc: 0.419690. Loss: 1.624510. Batch_acc: 0.426366. Batch_loss: 1.590316 \n",
      "Batch: 4391. Acc: 0.419698. Loss: 1.624481. Batch_acc: 0.457355. Batch_loss: 1.497415 \n",
      "Batch: 4392. Acc: 0.419709. Loss: 1.624451. Batch_acc: 0.466042. Batch_loss: 1.488926 \n",
      "Batch: 4393. Acc: 0.419718. Loss: 1.624425. Batch_acc: 0.463006. Batch_loss: 1.509799 \n",
      "Batch: 4394. Acc: 0.419730. Loss: 1.624400. Batch_acc: 0.473964. Batch_loss: 1.512316 \n",
      "Batch: 4395. Acc: 0.419739. Loss: 1.624375. Batch_acc: 0.457697. Batch_loss: 1.511640 \n",
      "Batch: 4396. Acc: 0.419746. Loss: 1.624352. Batch_acc: 0.450810. Batch_loss: 1.520869 \n",
      "Batch: 4397. Acc: 0.419753. Loss: 1.624335. Batch_acc: 0.449025. Batch_loss: 1.551909 \n",
      "Batch: 4398. Acc: 0.419762. Loss: 1.624312. Batch_acc: 0.461364. Batch_loss: 1.527864 \n",
      "Batch: 4399. Acc: 0.419762. Loss: 1.624316. Batch_acc: 0.418005. Batch_loss: 1.639042 \n",
      "Batch: 4400. Acc: 0.419769. Loss: 1.624295. Batch_acc: 0.449342. Batch_loss: 1.534178 \n",
      "Batch: 4401. Acc: 0.419782. Loss: 1.624264. Batch_acc: 0.477654. Batch_loss: 1.488959 \n",
      "Batch: 4402. Acc: 0.419790. Loss: 1.624228. Batch_acc: 0.453434. Batch_loss: 1.466889 \n",
      "Batch: 4403. Acc: 0.419799. Loss: 1.624204. Batch_acc: 0.458625. Batch_loss: 1.517516 \n",
      "Batch: 4404. Acc: 0.419805. Loss: 1.624192. Batch_acc: 0.448576. Batch_loss: 1.570544 \n",
      "Batch: 4405. Acc: 0.419815. Loss: 1.624165. Batch_acc: 0.464968. Batch_loss: 1.503157 \n",
      "Batch: 4406. Acc: 0.419821. Loss: 1.624149. Batch_acc: 0.445652. Batch_loss: 1.555751 \n",
      "Batch: 4407. Acc: 0.419828. Loss: 1.624137. Batch_acc: 0.449599. Batch_loss: 1.571743 \n",
      "Batch: 4408. Acc: 0.419834. Loss: 1.624114. Batch_acc: 0.447536. Batch_loss: 1.518727 \n",
      "Batch: 4409. Acc: 0.419839. Loss: 1.624098. Batch_acc: 0.443732. Batch_loss: 1.555340 \n",
      "Batch: 4410. Acc: 0.419845. Loss: 1.624081. Batch_acc: 0.443391. Batch_loss: 1.551801 \n",
      "Batch: 4411. Acc: 0.419852. Loss: 1.624060. Batch_acc: 0.450549. Batch_loss: 1.530270 \n",
      "Batch: 4412. Acc: 0.419861. Loss: 1.624041. Batch_acc: 0.459255. Batch_loss: 1.537261 \n",
      "Batch: 4413. Acc: 0.419867. Loss: 1.624022. Batch_acc: 0.446858. Batch_loss: 1.537159 \n",
      "Batch: 4414. Acc: 0.419872. Loss: 1.624009. Batch_acc: 0.441558. Batch_loss: 1.568185 \n",
      "Batch: 4415. Acc: 0.419876. Loss: 1.623996. Batch_acc: 0.440476. Batch_loss: 1.566858 \n",
      "Batch: 4416. Acc: 0.419879. Loss: 1.623981. Batch_acc: 0.433180. Batch_loss: 1.560110 \n",
      "Batch: 4417. Acc: 0.419886. Loss: 1.623964. Batch_acc: 0.450197. Batch_loss: 1.548217 \n",
      "Batch: 4418. Acc: 0.419896. Loss: 1.623936. Batch_acc: 0.463512. Batch_loss: 1.503385 \n",
      "Batch: 4419. Acc: 0.419904. Loss: 1.623914. Batch_acc: 0.452546. Batch_loss: 1.525442 \n",
      "Batch: 4420. Acc: 0.419908. Loss: 1.623906. Batch_acc: 0.436499. Batch_loss: 1.590681 \n",
      "Batch: 4421. Acc: 0.419913. Loss: 1.623889. Batch_acc: 0.445481. Batch_loss: 1.545355 \n",
      "Batch: 4422. Acc: 0.419918. Loss: 1.623873. Batch_acc: 0.439954. Batch_loss: 1.551702 \n",
      "Batch: 4423. Acc: 0.419924. Loss: 1.623856. Batch_acc: 0.449074. Batch_loss: 1.548389 \n",
      "Batch: 4424. Acc: 0.419928. Loss: 1.623844. Batch_acc: 0.438112. Batch_loss: 1.574416 \n",
      "Batch: 4425. Acc: 0.419937. Loss: 1.623815. Batch_acc: 0.456000. Batch_loss: 1.496610 \n",
      "Batch: 4426. Acc: 0.419945. Loss: 1.623798. Batch_acc: 0.458831. Batch_loss: 1.543529 \n",
      "Batch: 4427. Acc: 0.419947. Loss: 1.623782. Batch_acc: 0.430158. Batch_loss: 1.551005 \n",
      "Batch: 4428. Acc: 0.419953. Loss: 1.623763. Batch_acc: 0.443790. Batch_loss: 1.537366 \n",
      "Batch: 4429. Acc: 0.419961. Loss: 1.623739. Batch_acc: 0.457110. Batch_loss: 1.518799 \n",
      "Batch: 4430. Acc: 0.419969. Loss: 1.623714. Batch_acc: 0.455601. Batch_loss: 1.513155 \n",
      "Batch: 4431. Acc: 0.419972. Loss: 1.623699. Batch_acc: 0.431304. Batch_loss: 1.556993 \n",
      "Batch: 4432. Acc: 0.419981. Loss: 1.623675. Batch_acc: 0.460102. Batch_loss: 1.515323 \n",
      "Batch: 4433. Acc: 0.419987. Loss: 1.623658. Batch_acc: 0.448560. Batch_loss: 1.546836 \n",
      "Batch: 4434. Acc: 0.419990. Loss: 1.623648. Batch_acc: 0.435009. Batch_loss: 1.582025 \n",
      "Batch: 4435. Acc: 0.419997. Loss: 1.623631. Batch_acc: 0.447504. Batch_loss: 1.545959 \n",
      "Batch: 4436. Acc: 0.420000. Loss: 1.623620. Batch_acc: 0.433819. Batch_loss: 1.574717 \n",
      "Batch: 4437. Acc: 0.420007. Loss: 1.623600. Batch_acc: 0.453052. Batch_loss: 1.533129 \n",
      "Batch: 4438. Acc: 0.420015. Loss: 1.623578. Batch_acc: 0.454030. Batch_loss: 1.528023 \n",
      "Batch: 4439. Acc: 0.420024. Loss: 1.623557. Batch_acc: 0.459178. Batch_loss: 1.531405 \n",
      "Batch: 4440. Acc: 0.420031. Loss: 1.623537. Batch_acc: 0.451465. Batch_loss: 1.531368 \n",
      "Batch: 4441. Acc: 0.420039. Loss: 1.623518. Batch_acc: 0.457193. Batch_loss: 1.541111 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4442. Acc: 0.420042. Loss: 1.623501. Batch_acc: 0.436234. Batch_loss: 1.545272 \n",
      "Batch: 4443. Acc: 0.420046. Loss: 1.623489. Batch_acc: 0.434858. Batch_loss: 1.568069 \n",
      "Batch: 4444. Acc: 0.420054. Loss: 1.623464. Batch_acc: 0.456755. Batch_loss: 1.512930 \n",
      "Batch: 4445. Acc: 0.420063. Loss: 1.623440. Batch_acc: 0.461985. Batch_loss: 1.518500 \n",
      "Batch: 4446. Acc: 0.420071. Loss: 1.623412. Batch_acc: 0.452649. Batch_loss: 1.503085 \n",
      "Batch: 4447. Acc: 0.420080. Loss: 1.623390. Batch_acc: 0.459534. Batch_loss: 1.528403 \n",
      "Batch: 4448. Acc: 0.420091. Loss: 1.623364. Batch_acc: 0.469680. Batch_loss: 1.505915 \n",
      "Batch: 4449. Acc: 0.420100. Loss: 1.623349. Batch_acc: 0.457011. Batch_loss: 1.555340 \n",
      "Batch: 4450. Acc: 0.420104. Loss: 1.623332. Batch_acc: 0.438430. Batch_loss: 1.545372 \n",
      "Batch: 4451. Acc: 0.420112. Loss: 1.623305. Batch_acc: 0.459570. Batch_loss: 1.504118 \n",
      "Batch: 4452. Acc: 0.420122. Loss: 1.623279. Batch_acc: 0.461582. Batch_loss: 1.508135 \n",
      "Batch: 4453. Acc: 0.420128. Loss: 1.623261. Batch_acc: 0.447881. Batch_loss: 1.547049 \n",
      "Batch: 4454. Acc: 0.420133. Loss: 1.623239. Batch_acc: 0.442726. Batch_loss: 1.524124 \n",
      "Batch: 4455. Acc: 0.420139. Loss: 1.623223. Batch_acc: 0.444123. Batch_loss: 1.551420 \n",
      "Batch: 4456. Acc: 0.420144. Loss: 1.623208. Batch_acc: 0.444379. Batch_loss: 1.554706 \n",
      "Batch: 4457. Acc: 0.420154. Loss: 1.623175. Batch_acc: 0.465714. Batch_loss: 1.475387 \n",
      "Batch: 4458. Acc: 0.420159. Loss: 1.623160. Batch_acc: 0.442857. Batch_loss: 1.555993 \n",
      "Batch: 4459. Acc: 0.420170. Loss: 1.623124. Batch_acc: 0.465998. Batch_loss: 1.469208 \n",
      "Batch: 4460. Acc: 0.420178. Loss: 1.623103. Batch_acc: 0.454703. Batch_loss: 1.528126 \n",
      "Batch: 4461. Acc: 0.420181. Loss: 1.623088. Batch_acc: 0.434050. Batch_loss: 1.558652 \n",
      "Batch: 4462. Acc: 0.420185. Loss: 1.623068. Batch_acc: 0.441043. Batch_loss: 1.535582 \n",
      "Batch: 4463. Acc: 0.420190. Loss: 1.623053. Batch_acc: 0.438997. Batch_loss: 1.553744 \n",
      "Batch: 4464. Acc: 0.420193. Loss: 1.623041. Batch_acc: 0.434127. Batch_loss: 1.567875 \n",
      "Batch: 4465. Acc: 0.420202. Loss: 1.623018. Batch_acc: 0.461405. Batch_loss: 1.519768 \n",
      "Batch: 4466. Acc: 0.420211. Loss: 1.622990. Batch_acc: 0.461891. Batch_loss: 1.498710 \n",
      "Batch: 4467. Acc: 0.420221. Loss: 1.622961. Batch_acc: 0.464474. Batch_loss: 1.491343 \n",
      "Batch: 4468. Acc: 0.420233. Loss: 1.622923. Batch_acc: 0.472767. Batch_loss: 1.463865 \n",
      "Batch: 4469. Acc: 0.420246. Loss: 1.622895. Batch_acc: 0.472697. Batch_loss: 1.501389 \n",
      "Batch: 4470. Acc: 0.420253. Loss: 1.622870. Batch_acc: 0.453441. Batch_loss: 1.510416 \n",
      "Batch: 4471. Acc: 0.420259. Loss: 1.622853. Batch_acc: 0.445481. Batch_loss: 1.546997 \n",
      "Batch: 4472. Acc: 0.420269. Loss: 1.622817. Batch_acc: 0.467901. Batch_loss: 1.462404 \n",
      "Batch: 4473. Acc: 0.420281. Loss: 1.622787. Batch_acc: 0.472534. Batch_loss: 1.488003 \n",
      "Batch: 4474. Acc: 0.420293. Loss: 1.622757. Batch_acc: 0.471923. Batch_loss: 1.492033 \n",
      "Batch: 4475. Acc: 0.420305. Loss: 1.622723. Batch_acc: 0.472737. Batch_loss: 1.472372 \n",
      "Batch: 4476. Acc: 0.420312. Loss: 1.622698. Batch_acc: 0.450226. Batch_loss: 1.513830 \n",
      "Batch: 4477. Acc: 0.420304. Loss: 1.622710. Batch_acc: 0.387079. Batch_loss: 1.676549 \n",
      "Batch: 4478. Acc: 0.420315. Loss: 1.622685. Batch_acc: 0.466251. Batch_loss: 1.510973 \n",
      "Batch: 4479. Acc: 0.420322. Loss: 1.622660. Batch_acc: 0.451934. Batch_loss: 1.515924 \n",
      "Batch: 4480. Acc: 0.420329. Loss: 1.622640. Batch_acc: 0.451409. Batch_loss: 1.534281 \n",
      "Batch: 4481. Acc: 0.420335. Loss: 1.622616. Batch_acc: 0.446233. Batch_loss: 1.514455 \n",
      "Batch: 4482. Acc: 0.420343. Loss: 1.622590. Batch_acc: 0.459160. Batch_loss: 1.501929 \n",
      "Batch: 4483. Acc: 0.420347. Loss: 1.622574. Batch_acc: 0.439812. Batch_loss: 1.553163 \n",
      "Batch: 4484. Acc: 0.420358. Loss: 1.622549. Batch_acc: 0.468897. Batch_loss: 1.506791 \n",
      "Batch: 4485. Acc: 0.420360. Loss: 1.622546. Batch_acc: 0.427499. Batch_loss: 1.606638 \n",
      "Batch: 4486. Acc: 0.420373. Loss: 1.622513. Batch_acc: 0.477916. Batch_loss: 1.479367 \n",
      "Batch: 4487. Acc: 0.420379. Loss: 1.622494. Batch_acc: 0.449599. Batch_loss: 1.536544 \n",
      "Batch: 4488. Acc: 0.420385. Loss: 1.622476. Batch_acc: 0.448296. Batch_loss: 1.540016 \n",
      "Batch: 4489. Acc: 0.420390. Loss: 1.622459. Batch_acc: 0.442874. Batch_loss: 1.546933 \n",
      "Batch: 4490. Acc: 0.420395. Loss: 1.622442. Batch_acc: 0.441125. Batch_loss: 1.541855 \n",
      "Batch: 4491. Acc: 0.420407. Loss: 1.622402. Batch_acc: 0.473088. Batch_loss: 1.446502 \n",
      "Batch: 4492. Acc: 0.420418. Loss: 1.622375. Batch_acc: 0.469446. Batch_loss: 1.500378 \n",
      "Batch: 4493. Acc: 0.420429. Loss: 1.622344. Batch_acc: 0.470655. Batch_loss: 1.485499 \n",
      "Batch: 4494. Acc: 0.420435. Loss: 1.622324. Batch_acc: 0.447262. Batch_loss: 1.533979 \n",
      "Batch: 4495. Acc: 0.420443. Loss: 1.622299. Batch_acc: 0.454751. Batch_loss: 1.508968 \n",
      "Batch: 4496. Acc: 0.420449. Loss: 1.622282. Batch_acc: 0.450581. Batch_loss: 1.544324 \n",
      "Batch: 4497. Acc: 0.420457. Loss: 1.622265. Batch_acc: 0.453515. Batch_loss: 1.547966 \n",
      "Batch: 4498. Acc: 0.420458. Loss: 1.622259. Batch_acc: 0.428237. Batch_loss: 1.596338 \n",
      "Batch: 4499. Acc: 0.420463. Loss: 1.622234. Batch_acc: 0.440782. Batch_loss: 1.514288 \n",
      "Batch: 4500. Acc: 0.420468. Loss: 1.622222. Batch_acc: 0.443872. Batch_loss: 1.565263 \n",
      "Batch: 4501. Acc: 0.420474. Loss: 1.622204. Batch_acc: 0.445042. Batch_loss: 1.537202 \n",
      "Batch: 4502. Acc: 0.420479. Loss: 1.622183. Batch_acc: 0.443889. Batch_loss: 1.534202 \n",
      "Batch: 4503. Acc: 0.420488. Loss: 1.622166. Batch_acc: 0.459988. Batch_loss: 1.544991 \n",
      "Batch: 4504. Acc: 0.420497. Loss: 1.622141. Batch_acc: 0.461408. Batch_loss: 1.512871 \n",
      "Batch: 4505. Acc: 0.420504. Loss: 1.622121. Batch_acc: 0.450549. Batch_loss: 1.531775 \n",
      "Batch: 4506. Acc: 0.420513. Loss: 1.622091. Batch_acc: 0.461231. Batch_loss: 1.484697 \n",
      "Batch: 4507. Acc: 0.420523. Loss: 1.622070. Batch_acc: 0.467647. Batch_loss: 1.527626 \n",
      "Batch: 4508. Acc: 0.420528. Loss: 1.622053. Batch_acc: 0.444886. Batch_loss: 1.545425 \n",
      "Batch: 4509. Acc: 0.420533. Loss: 1.622042. Batch_acc: 0.438914. Batch_loss: 1.573459 \n",
      "Batch: 4510. Acc: 0.420541. Loss: 1.622019. Batch_acc: 0.459230. Batch_loss: 1.520040 \n",
      "Batch: 4511. Acc: 0.420549. Loss: 1.621997. Batch_acc: 0.457043. Batch_loss: 1.522062 \n",
      "Batch: 4512. Acc: 0.420554. Loss: 1.621986. Batch_acc: 0.443931. Batch_loss: 1.571502 \n",
      "Batch: 4513. Acc: 0.420563. Loss: 1.621959. Batch_acc: 0.459293. Batch_loss: 1.500729 \n",
      "Batch: 4514. Acc: 0.420571. Loss: 1.621928. Batch_acc: 0.453994. Batch_loss: 1.489854 \n",
      "Batch: 4515. Acc: 0.420578. Loss: 1.621909. Batch_acc: 0.454123. Batch_loss: 1.535998 \n",
      "Batch: 4516. Acc: 0.420584. Loss: 1.621895. Batch_acc: 0.446110. Batch_loss: 1.555915 \n",
      "Batch: 4517. Acc: 0.420592. Loss: 1.621877. Batch_acc: 0.458120. Batch_loss: 1.542296 \n",
      "Batch: 4518. Acc: 0.420601. Loss: 1.621851. Batch_acc: 0.460687. Batch_loss: 1.502843 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.4206010315523553. Loss per char: 1.6218508088950307. Time: 1627213920.1517272\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 18, 18, 21, 21,\n",
      "        19, 23, 19, 17, 24, 17, 18, 15, 23, 23,  1, 66, 79, 69,  1, 14, 22, 15,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.420610. Loss: 1.621825. Batch_acc: 0.461102. Batch_loss: 1.505772 \n",
      "Batch: 4520. Acc: 0.420613. Loss: 1.621811. Batch_acc: 0.435972. Batch_loss: 1.559635 \n",
      "Batch: 4521. Acc: 0.420624. Loss: 1.621783. Batch_acc: 0.467733. Batch_loss: 1.496948 \n",
      "Batch: 4522. Acc: 0.420628. Loss: 1.621773. Batch_acc: 0.437101. Batch_loss: 1.575853 \n",
      "Batch: 4523. Acc: 0.420632. Loss: 1.621762. Batch_acc: 0.440094. Batch_loss: 1.570575 \n",
      "Batch: 4524. Acc: 0.420639. Loss: 1.621740. Batch_acc: 0.455132. Batch_loss: 1.518356 \n",
      "Batch: 4525. Acc: 0.420648. Loss: 1.621714. Batch_acc: 0.461894. Batch_loss: 1.505946 \n",
      "Batch: 4526. Acc: 0.420650. Loss: 1.621711. Batch_acc: 0.427485. Batch_loss: 1.607711 \n",
      "Batch: 4527. Acc: 0.420658. Loss: 1.621693. Batch_acc: 0.460214. Batch_loss: 1.534410 \n",
      "Batch: 4528. Acc: 0.420662. Loss: 1.621681. Batch_acc: 0.435586. Batch_loss: 1.569888 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4529. Acc: 0.420663. Loss: 1.621677. Batch_acc: 0.426107. Batch_loss: 1.601082 \n",
      "Batch: 4530. Acc: 0.420666. Loss: 1.621666. Batch_acc: 0.433819. Batch_loss: 1.573016 \n",
      "Batch: 4531. Acc: 0.420669. Loss: 1.621662. Batch_acc: 0.434407. Batch_loss: 1.602753 \n",
      "Batch: 4532. Acc: 0.420677. Loss: 1.621637. Batch_acc: 0.459783. Batch_loss: 1.510495 \n",
      "Batch: 4533. Acc: 0.420685. Loss: 1.621615. Batch_acc: 0.455056. Batch_loss: 1.521590 \n",
      "Batch: 4534. Acc: 0.420694. Loss: 1.621592. Batch_acc: 0.463017. Batch_loss: 1.517074 \n",
      "Batch: 4535. Acc: 0.420705. Loss: 1.621564. Batch_acc: 0.470998. Batch_loss: 1.495848 \n",
      "Batch: 4536. Acc: 0.420714. Loss: 1.621536. Batch_acc: 0.458924. Batch_loss: 1.495049 \n",
      "Batch: 4537. Acc: 0.420722. Loss: 1.621521. Batch_acc: 0.458333. Batch_loss: 1.554193 \n",
      "Batch: 4538. Acc: 0.420725. Loss: 1.621514. Batch_acc: 0.431871. Batch_loss: 1.588661 \n",
      "Batch: 4539. Acc: 0.420736. Loss: 1.621479. Batch_acc: 0.471165. Batch_loss: 1.466215 \n",
      "Batch: 4540. Acc: 0.420741. Loss: 1.621462. Batch_acc: 0.444898. Batch_loss: 1.538946 \n",
      "Batch: 4541. Acc: 0.420744. Loss: 1.621446. Batch_acc: 0.432698. Batch_loss: 1.550742 \n",
      "Batch: 4542. Acc: 0.420749. Loss: 1.621430. Batch_acc: 0.442613. Batch_loss: 1.548710 \n",
      "Batch: 4543. Acc: 0.420753. Loss: 1.621418. Batch_acc: 0.442399. Batch_loss: 1.561060 \n",
      "Batch: 4544. Acc: 0.420761. Loss: 1.621399. Batch_acc: 0.457275. Batch_loss: 1.538779 \n",
      "Batch: 4545. Acc: 0.420765. Loss: 1.621384. Batch_acc: 0.438249. Batch_loss: 1.550589 \n",
      "Batch: 4546. Acc: 0.420770. Loss: 1.621365. Batch_acc: 0.441639. Batch_loss: 1.534347 \n",
      "Batch: 4547. Acc: 0.420777. Loss: 1.621346. Batch_acc: 0.454755. Batch_loss: 1.537359 \n",
      "Batch: 4548. Acc: 0.420785. Loss: 1.621323. Batch_acc: 0.455549. Batch_loss: 1.513246 \n",
      "Batch: 4549. Acc: 0.420794. Loss: 1.621297. Batch_acc: 0.463244. Batch_loss: 1.504145 \n",
      "Batch: 4550. Acc: 0.420802. Loss: 1.621274. Batch_acc: 0.459829. Batch_loss: 1.517780 \n",
      "Batch: 4551. Acc: 0.420813. Loss: 1.621243. Batch_acc: 0.466025. Batch_loss: 1.481264 \n",
      "Batch: 4552. Acc: 0.420815. Loss: 1.621234. Batch_acc: 0.433295. Batch_loss: 1.577619 \n",
      "Batch: 4553. Acc: 0.420827. Loss: 1.621193. Batch_acc: 0.473318. Batch_loss: 1.433925 \n",
      "Batch: 4554. Acc: 0.420834. Loss: 1.621168. Batch_acc: 0.452149. Batch_loss: 1.508108 \n",
      "Batch: 4555. Acc: 0.420838. Loss: 1.621151. Batch_acc: 0.439242. Batch_loss: 1.548850 \n",
      "Batch: 4556. Acc: 0.420847. Loss: 1.621131. Batch_acc: 0.461102. Batch_loss: 1.529088 \n",
      "Batch: 4557. Acc: 0.420858. Loss: 1.621096. Batch_acc: 0.473034. Batch_loss: 1.463210 \n",
      "Batch: 4558. Acc: 0.420861. Loss: 1.621084. Batch_acc: 0.432198. Batch_loss: 1.568047 \n",
      "Batch: 4559. Acc: 0.420868. Loss: 1.621061. Batch_acc: 0.451740. Batch_loss: 1.516845 \n",
      "Batch: 4560. Acc: 0.420871. Loss: 1.621048. Batch_acc: 0.435748. Batch_loss: 1.560957 \n",
      "Batch: 4561. Acc: 0.420876. Loss: 1.621028. Batch_acc: 0.443413. Batch_loss: 1.532672 \n",
      "Batch: 4562. Acc: 0.420881. Loss: 1.621010. Batch_acc: 0.444508. Batch_loss: 1.535264 \n",
      "Batch: 4563. Acc: 0.420885. Loss: 1.620999. Batch_acc: 0.436742. Batch_loss: 1.574439 \n",
      "Batch: 4564. Acc: 0.420898. Loss: 1.620966. Batch_acc: 0.483352. Batch_loss: 1.469887 \n",
      "Batch: 4565. Acc: 0.420906. Loss: 1.620942. Batch_acc: 0.453672. Batch_loss: 1.510218 \n",
      "Batch: 4566. Acc: 0.420910. Loss: 1.620925. Batch_acc: 0.441739. Batch_loss: 1.545308 \n",
      "Batch: 4567. Acc: 0.420920. Loss: 1.620899. Batch_acc: 0.464531. Batch_loss: 1.501035 \n",
      "Batch: 4568. Acc: 0.420930. Loss: 1.620874. Batch_acc: 0.470030. Batch_loss: 1.504154 \n",
      "Batch: 4569. Acc: 0.420938. Loss: 1.620854. Batch_acc: 0.456977. Batch_loss: 1.531008 \n",
      "Batch: 4570. Acc: 0.420945. Loss: 1.620830. Batch_acc: 0.454911. Batch_loss: 1.509150 \n",
      "Batch: 4571. Acc: 0.420948. Loss: 1.620814. Batch_acc: 0.433411. Batch_loss: 1.546167 \n",
      "Batch: 4572. Acc: 0.420953. Loss: 1.620797. Batch_acc: 0.441595. Batch_loss: 1.542644 \n",
      "Batch: 4573. Acc: 0.420958. Loss: 1.620777. Batch_acc: 0.447338. Batch_loss: 1.530077 \n",
      "Batch: 4574. Acc: 0.420959. Loss: 1.620772. Batch_acc: 0.423099. Batch_loss: 1.598835 \n",
      "Batch: 4575. Acc: 0.420963. Loss: 1.620755. Batch_acc: 0.440000. Batch_loss: 1.544548 \n",
      "Batch: 4576. Acc: 0.420971. Loss: 1.620737. Batch_acc: 0.459238. Batch_loss: 1.535588 \n",
      "Batch: 4577. Acc: 0.420982. Loss: 1.620701. Batch_acc: 0.468696. Batch_loss: 1.456212 \n",
      "Batch: 4578. Acc: 0.420993. Loss: 1.620676. Batch_acc: 0.470655. Batch_loss: 1.507537 \n",
      "Batch: 4579. Acc: 0.421000. Loss: 1.620656. Batch_acc: 0.452928. Batch_loss: 1.526659 \n",
      "Batch: 4580. Acc: 0.421010. Loss: 1.620630. Batch_acc: 0.470484. Batch_loss: 1.499342 \n",
      "Batch: 4581. Acc: 0.421016. Loss: 1.620606. Batch_acc: 0.449324. Batch_loss: 1.511806 \n",
      "Batch: 4582. Acc: 0.421025. Loss: 1.620581. Batch_acc: 0.457831. Batch_loss: 1.510176 \n",
      "Batch: 4583. Acc: 0.421031. Loss: 1.620551. Batch_acc: 0.450113. Batch_loss: 1.485290 \n",
      "Batch: 4584. Acc: 0.421039. Loss: 1.620528. Batch_acc: 0.458920. Batch_loss: 1.508823 \n",
      "Batch: 4585. Acc: 0.421045. Loss: 1.620510. Batch_acc: 0.447977. Batch_loss: 1.537791 \n",
      "Batch: 4586. Acc: 0.421049. Loss: 1.620499. Batch_acc: 0.439516. Batch_loss: 1.573980 \n",
      "Batch: 4587. Acc: 0.421057. Loss: 1.620478. Batch_acc: 0.459091. Batch_loss: 1.520899 \n",
      "Batch: 4588. Acc: 0.421065. Loss: 1.620458. Batch_acc: 0.453974. Batch_loss: 1.530231 \n",
      "Batch: 4589. Acc: 0.421070. Loss: 1.620436. Batch_acc: 0.447560. Batch_loss: 1.521858 \n",
      "Batch: 4590. Acc: 0.421077. Loss: 1.620417. Batch_acc: 0.451519. Batch_loss: 1.531867 \n",
      "Batch: 4591. Acc: 0.421083. Loss: 1.620397. Batch_acc: 0.450292. Batch_loss: 1.527582 \n",
      "Batch: 4592. Acc: 0.421093. Loss: 1.620378. Batch_acc: 0.465568. Batch_loss: 1.533920 \n",
      "Batch: 4593. Acc: 0.421102. Loss: 1.620354. Batch_acc: 0.465318. Batch_loss: 1.508796 \n",
      "Batch: 4594. Acc: 0.421112. Loss: 1.620324. Batch_acc: 0.464968. Batch_loss: 1.481656 \n",
      "Batch: 4595. Acc: 0.421125. Loss: 1.620294. Batch_acc: 0.482798. Batch_loss: 1.481860 \n",
      "Batch: 4596. Acc: 0.421134. Loss: 1.620270. Batch_acc: 0.463415. Batch_loss: 1.509623 \n",
      "Batch: 4597. Acc: 0.421136. Loss: 1.620256. Batch_acc: 0.427920. Batch_loss: 1.553465 \n",
      "Batch: 4598. Acc: 0.421141. Loss: 1.620244. Batch_acc: 0.443045. Batch_loss: 1.566523 \n",
      "Batch: 4599. Acc: 0.421147. Loss: 1.620224. Batch_acc: 0.451465. Batch_loss: 1.528859 \n",
      "Batch: 4600. Acc: 0.421153. Loss: 1.620209. Batch_acc: 0.447126. Batch_loss: 1.550124 \n",
      "Batch: 4601. Acc: 0.421160. Loss: 1.620194. Batch_acc: 0.452159. Batch_loss: 1.553082 \n",
      "Batch: 4602. Acc: 0.421170. Loss: 1.620157. Batch_acc: 0.467622. Batch_loss: 1.449340 \n",
      "Batch: 4603. Acc: 0.421175. Loss: 1.620135. Batch_acc: 0.447788. Batch_loss: 1.516062 \n",
      "Batch: 4604. Acc: 0.421185. Loss: 1.620106. Batch_acc: 0.464594. Batch_loss: 1.488813 \n",
      "Batch: 4605. Acc: 0.421193. Loss: 1.620093. Batch_acc: 0.459444. Batch_loss: 1.556537 \n",
      "Batch: 4606. Acc: 0.421202. Loss: 1.620066. Batch_acc: 0.461625. Batch_loss: 1.498809 \n",
      "Batch: 4607. Acc: 0.421205. Loss: 1.620059. Batch_acc: 0.433995. Batch_loss: 1.586941 \n",
      "Batch: 4608. Acc: 0.421210. Loss: 1.620042. Batch_acc: 0.446101. Batch_loss: 1.542813 \n",
      "Batch: 4609. Acc: 0.421216. Loss: 1.620025. Batch_acc: 0.448636. Batch_loss: 1.541125 \n",
      "Batch: 4610. Acc: 0.421220. Loss: 1.620009. Batch_acc: 0.438026. Batch_loss: 1.550041 \n",
      "Batch: 4611. Acc: 0.421230. Loss: 1.619979. Batch_acc: 0.467157. Batch_loss: 1.484642 \n",
      "Batch: 4612. Acc: 0.421240. Loss: 1.619951. Batch_acc: 0.467525. Batch_loss: 1.487544 \n",
      "Batch: 4613. Acc: 0.421249. Loss: 1.619929. Batch_acc: 0.464589. Batch_loss: 1.517885 \n",
      "Batch: 4614. Acc: 0.421257. Loss: 1.619907. Batch_acc: 0.456032. Batch_loss: 1.522135 \n",
      "Batch: 4615. Acc: 0.421264. Loss: 1.619883. Batch_acc: 0.450649. Batch_loss: 1.509435 \n",
      "Batch: 4616. Acc: 0.421271. Loss: 1.619857. Batch_acc: 0.457272. Batch_loss: 1.502932 \n",
      "Batch: 4617. Acc: 0.421279. Loss: 1.619831. Batch_acc: 0.453872. Batch_loss: 1.502195 \n",
      "Batch: 4618. Acc: 0.421282. Loss: 1.619816. Batch_acc: 0.436385. Batch_loss: 1.548451 \n",
      "Batch: 4619. Acc: 0.421281. Loss: 1.619811. Batch_acc: 0.418919. Batch_loss: 1.594766 \n",
      "Batch: 4620. Acc: 0.421292. Loss: 1.619782. Batch_acc: 0.472159. Batch_loss: 1.488792 \n",
      "Batch: 4621. Acc: 0.421302. Loss: 1.619755. Batch_acc: 0.463941. Batch_loss: 1.495275 \n",
      "Batch: 4622. Acc: 0.421315. Loss: 1.619722. Batch_acc: 0.482421. Batch_loss: 1.470487 \n",
      "Batch: 4623. Acc: 0.421322. Loss: 1.619703. Batch_acc: 0.454128. Batch_loss: 1.532275 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4624. Acc: 0.421330. Loss: 1.619679. Batch_acc: 0.459397. Batch_loss: 1.504242 \n",
      "Batch: 4625. Acc: 0.421340. Loss: 1.619653. Batch_acc: 0.466860. Batch_loss: 1.499376 \n",
      "Batch: 4626. Acc: 0.421354. Loss: 1.619616. Batch_acc: 0.484123. Batch_loss: 1.455254 \n",
      "Batch: 4627. Acc: 0.421361. Loss: 1.619594. Batch_acc: 0.454902. Batch_loss: 1.521125 \n",
      "Batch: 4628. Acc: 0.421368. Loss: 1.619574. Batch_acc: 0.450029. Batch_loss: 1.526473 \n",
      "Batch: 4629. Acc: 0.421373. Loss: 1.619551. Batch_acc: 0.446833. Batch_loss: 1.511340 \n",
      "Batch: 4630. Acc: 0.421383. Loss: 1.619524. Batch_acc: 0.463712. Batch_loss: 1.500255 \n",
      "Batch: 4631. Acc: 0.421392. Loss: 1.619503. Batch_acc: 0.465698. Batch_loss: 1.520573 \n",
      "Batch: 4632. Acc: 0.421398. Loss: 1.619484. Batch_acc: 0.449167. Batch_loss: 1.530558 \n",
      "Batch: 4633. Acc: 0.421402. Loss: 1.619469. Batch_acc: 0.439954. Batch_loss: 1.552967 \n",
      "Batch: 4634. Acc: 0.421406. Loss: 1.619455. Batch_acc: 0.439108. Batch_loss: 1.553630 \n",
      "Batch: 4635. Acc: 0.421415. Loss: 1.619427. Batch_acc: 0.461276. Batch_loss: 1.489582 \n",
      "Batch: 4636. Acc: 0.421418. Loss: 1.619411. Batch_acc: 0.435928. Batch_loss: 1.542567 \n",
      "Batch: 4637. Acc: 0.421426. Loss: 1.619391. Batch_acc: 0.458651. Batch_loss: 1.526087 \n",
      "Batch: 4638. Acc: 0.421430. Loss: 1.619367. Batch_acc: 0.440726. Batch_loss: 1.512580 \n",
      "Batch: 4639. Acc: 0.421443. Loss: 1.619338. Batch_acc: 0.479818. Batch_loss: 1.485232 \n",
      "Batch: 4640. Acc: 0.421452. Loss: 1.619307. Batch_acc: 0.466131. Batch_loss: 1.475069 \n",
      "Batch: 4641. Acc: 0.421457. Loss: 1.619287. Batch_acc: 0.444767. Batch_loss: 1.526847 \n",
      "Batch: 4642. Acc: 0.421466. Loss: 1.619264. Batch_acc: 0.460824. Batch_loss: 1.507589 \n",
      "Batch: 4643. Acc: 0.421475. Loss: 1.619240. Batch_acc: 0.466082. Batch_loss: 1.509863 \n",
      "Batch: 4644. Acc: 0.421481. Loss: 1.619221. Batch_acc: 0.450430. Batch_loss: 1.531583 \n",
      "Batch: 4645. Acc: 0.421491. Loss: 1.619191. Batch_acc: 0.465692. Batch_loss: 1.482146 \n",
      "Batch: 4646. Acc: 0.421497. Loss: 1.619168. Batch_acc: 0.449944. Batch_loss: 1.513472 \n",
      "Batch: 4647. Acc: 0.421508. Loss: 1.619141. Batch_acc: 0.470554. Batch_loss: 1.494453 \n",
      "Batch: 4648. Acc: 0.421516. Loss: 1.619119. Batch_acc: 0.457907. Batch_loss: 1.514543 \n",
      "Batch: 4649. Acc: 0.421522. Loss: 1.619095. Batch_acc: 0.451631. Batch_loss: 1.510044 \n",
      "Batch: 4650. Acc: 0.421528. Loss: 1.619076. Batch_acc: 0.449718. Batch_loss: 1.533067 \n",
      "Batch: 4651. Acc: 0.421534. Loss: 1.619062. Batch_acc: 0.446301. Batch_loss: 1.553304 \n",
      "Batch: 4652. Acc: 0.421540. Loss: 1.619043. Batch_acc: 0.450575. Batch_loss: 1.528073 \n",
      "Batch: 4653. Acc: 0.421550. Loss: 1.619015. Batch_acc: 0.469296. Batch_loss: 1.489676 \n",
      "Batch: 4654. Acc: 0.421562. Loss: 1.618987. Batch_acc: 0.474928. Batch_loss: 1.492931 \n",
      "Batch: 4655. Acc: 0.421565. Loss: 1.618979. Batch_acc: 0.435164. Batch_loss: 1.579772 \n",
      "Batch: 4656. Acc: 0.421574. Loss: 1.618952. Batch_acc: 0.463818. Batch_loss: 1.491877 \n",
      "Batch: 4657. Acc: 0.421581. Loss: 1.618933. Batch_acc: 0.455241. Batch_loss: 1.529492 \n",
      "Batch: 4658. Acc: 0.421588. Loss: 1.618913. Batch_acc: 0.455594. Batch_loss: 1.525494 \n",
      "Batch: 4659. Acc: 0.421598. Loss: 1.618890. Batch_acc: 0.467789. Batch_loss: 1.512404 \n",
      "Batch: 4660. Acc: 0.421602. Loss: 1.618880. Batch_acc: 0.440071. Batch_loss: 1.569005 \n",
      "Batch: 4661. Acc: 0.421604. Loss: 1.618867. Batch_acc: 0.431085. Batch_loss: 1.557360 \n",
      "Batch: 4662. Acc: 0.421608. Loss: 1.618852. Batch_acc: 0.441226. Batch_loss: 1.552033 \n",
      "Batch: 4663. Acc: 0.421617. Loss: 1.618828. Batch_acc: 0.462781. Batch_loss: 1.504515 \n",
      "Batch: 4664. Acc: 0.421627. Loss: 1.618802. Batch_acc: 0.466363. Batch_loss: 1.499890 \n",
      "Batch: 4665. Acc: 0.421631. Loss: 1.618790. Batch_acc: 0.442890. Batch_loss: 1.562130 \n",
      "Batch: 4666. Acc: 0.421636. Loss: 1.618774. Batch_acc: 0.446552. Batch_loss: 1.545113 \n",
      "Batch: 4667. Acc: 0.421648. Loss: 1.618741. Batch_acc: 0.476684. Batch_loss: 1.464123 \n",
      "Batch: 4668. Acc: 0.421653. Loss: 1.618718. Batch_acc: 0.445397. Batch_loss: 1.510036 \n",
      "Batch: 4669. Acc: 0.421659. Loss: 1.618706. Batch_acc: 0.449626. Batch_loss: 1.563106 \n",
      "Batch: 4670. Acc: 0.421669. Loss: 1.618671. Batch_acc: 0.467724. Batch_loss: 1.459697 \n",
      "Batch: 4671. Acc: 0.421681. Loss: 1.618637. Batch_acc: 0.476349. Batch_loss: 1.466558 \n",
      "Batch: 4672. Acc: 0.421686. Loss: 1.618621. Batch_acc: 0.442907. Batch_loss: 1.541573 \n",
      "Batch: 4673. Acc: 0.421697. Loss: 1.618594. Batch_acc: 0.476079. Batch_loss: 1.490272 \n",
      "Batch: 4674. Acc: 0.421700. Loss: 1.618579. Batch_acc: 0.434507. Batch_loss: 1.547684 \n",
      "Batch: 4675. Acc: 0.421703. Loss: 1.618572. Batch_acc: 0.433117. Batch_loss: 1.586225 \n",
      "Batch: 4676. Acc: 0.421710. Loss: 1.618557. Batch_acc: 0.455185. Batch_loss: 1.544977 \n",
      "Batch: 4677. Acc: 0.421715. Loss: 1.618540. Batch_acc: 0.445087. Batch_loss: 1.540882 \n",
      "Batch: 4678. Acc: 0.421724. Loss: 1.618512. Batch_acc: 0.464185. Batch_loss: 1.490011 \n",
      "Batch: 4679. Acc: 0.421727. Loss: 1.618499. Batch_acc: 0.437067. Batch_loss: 1.558392 \n",
      "Batch: 4680. Acc: 0.421736. Loss: 1.618486. Batch_acc: 0.462731. Batch_loss: 1.552161 \n",
      "Batch: 4681. Acc: 0.421748. Loss: 1.618447. Batch_acc: 0.478555. Batch_loss: 1.442980 \n",
      "Batch: 4682. Acc: 0.421757. Loss: 1.618424. Batch_acc: 0.463610. Batch_loss: 1.512009 \n",
      "Batch: 4683. Acc: 0.421767. Loss: 1.618401. Batch_acc: 0.467090. Batch_loss: 1.510145 \n",
      "Batch: 4684. Acc: 0.421768. Loss: 1.618387. Batch_acc: 0.430293. Batch_loss: 1.552438 \n",
      "Batch: 4685. Acc: 0.421774. Loss: 1.618371. Batch_acc: 0.450386. Batch_loss: 1.541653 \n",
      "Batch: 4686. Acc: 0.421782. Loss: 1.618347. Batch_acc: 0.458286. Batch_loss: 1.505665 \n",
      "Batch: 4687. Acc: 0.421783. Loss: 1.618340. Batch_acc: 0.432280. Batch_loss: 1.549025 \n",
      "[Training]  loss: 1.618339749454085, ppl:  5.044708, accuracy: 42.178 %, elapse: 3809176.152ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.4772283962361983,  ppl:  4.38079, accuracy: 47.724 %, elapse: 36618.403ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1127.7015209197998ms\n",
      "[ Epoch: 3 / 8, Run Batch: 14064 / None]\n",
      "Batch: 0. Acc: 0.466174. Loss: 1.502185. Batch_acc: 0.466174. Batch_loss: 1.502185 \n",
      "Batch: 1. Acc: 0.459747. Loss: 1.501771. Batch_acc: 0.453170. Batch_loss: 1.501348 \n",
      "Batch: 2. Acc: 0.457388. Loss: 1.511825. Batch_acc: 0.452745. Batch_loss: 1.531614 \n",
      "Batch: 3. Acc: 0.454220. Loss: 1.517641. Batch_acc: 0.444637. Batch_loss: 1.535234 \n",
      "Batch: 4. Acc: 0.451476. Loss: 1.513246. Batch_acc: 0.440591. Batch_loss: 1.495808 \n",
      "Batch: 5. Acc: 0.453347. Loss: 1.514148. Batch_acc: 0.462781. Batch_loss: 1.518693 \n",
      "Batch: 6. Acc: 0.456092. Loss: 1.509027. Batch_acc: 0.472428. Batch_loss: 1.478545 \n",
      "Batch: 7. Acc: 0.455477. Loss: 1.512906. Batch_acc: 0.451128. Batch_loss: 1.540346 \n",
      "Batch: 8. Acc: 0.454951. Loss: 1.515783. Batch_acc: 0.450745. Batch_loss: 1.538783 \n",
      "Batch: 9. Acc: 0.453287. Loss: 1.516416. Batch_acc: 0.438557. Batch_loss: 1.522024 \n",
      "Batch: 10. Acc: 0.452934. Loss: 1.518033. Batch_acc: 0.449326. Batch_loss: 1.534591 \n",
      "Batch: 11. Acc: 0.452583. Loss: 1.517734. Batch_acc: 0.448620. Batch_loss: 1.514357 \n",
      "Batch: 12. Acc: 0.453482. Loss: 1.518790. Batch_acc: 0.464646. Batch_loss: 1.531899 \n",
      "Batch: 13. Acc: 0.455040. Loss: 1.514498. Batch_acc: 0.475524. Batch_loss: 1.458047 \n",
      "Batch: 14. Acc: 0.455921. Loss: 1.512371. Batch_acc: 0.468109. Batch_loss: 1.482955 \n",
      "Batch: 15. Acc: 0.455216. Loss: 1.513534. Batch_acc: 0.444761. Batch_loss: 1.530781 \n",
      "Batch: 16. Acc: 0.455160. Loss: 1.513359. Batch_acc: 0.454294. Batch_loss: 1.510660 \n",
      "Batch: 17. Acc: 0.455532. Loss: 1.513790. Batch_acc: 0.461988. Batch_loss: 1.521252 \n",
      "Batch: 18. Acc: 0.455966. Loss: 1.512608. Batch_acc: 0.463621. Batch_loss: 1.491738 \n",
      "Batch: 19. Acc: 0.456599. Loss: 1.512198. Batch_acc: 0.468571. Batch_loss: 1.504428 \n",
      "Batch: 20. Acc: 0.455947. Loss: 1.513643. Batch_acc: 0.442915. Batch_loss: 1.542530 \n",
      "Batch: 21. Acc: 0.456094. Loss: 1.513956. Batch_acc: 0.459166. Batch_loss: 1.520499 \n",
      "Batch: 22. Acc: 0.456174. Loss: 1.514395. Batch_acc: 0.457966. Batch_loss: 1.524285 \n",
      "Batch: 23. Acc: 0.456612. Loss: 1.514094. Batch_acc: 0.466822. Batch_loss: 1.507072 \n",
      "Batch: 24. Acc: 0.456233. Loss: 1.514972. Batch_acc: 0.447368. Batch_loss: 1.535498 \n",
      "Batch: 25. Acc: 0.456254. Loss: 1.515350. Batch_acc: 0.456783. Batch_loss: 1.524790 \n",
      "Batch: 26. Acc: 0.455796. Loss: 1.515316. Batch_acc: 0.444002. Batch_loss: 1.514419 \n",
      "Batch: 27. Acc: 0.456273. Loss: 1.514386. Batch_acc: 0.469293. Batch_loss: 1.489062 \n",
      "Batch: 28. Acc: 0.456213. Loss: 1.513845. Batch_acc: 0.454545. Batch_loss: 1.498950 \n",
      "Batch: 29. Acc: 0.455780. Loss: 1.514917. Batch_acc: 0.443234. Batch_loss: 1.545969 \n",
      "Batch: 30. Acc: 0.456404. Loss: 1.513851. Batch_acc: 0.474972. Batch_loss: 1.482148 \n",
      "Batch: 31. Acc: 0.456802. Loss: 1.512780. Batch_acc: 0.469352. Batch_loss: 1.478976 \n",
      "Batch: 32. Acc: 0.456775. Loss: 1.513456. Batch_acc: 0.455899. Batch_loss: 1.535070 \n",
      "Batch: 33. Acc: 0.456415. Loss: 1.514472. Batch_acc: 0.444444. Batch_loss: 1.548276 \n",
      "Batch: 34. Acc: 0.455897. Loss: 1.515601. Batch_acc: 0.438150. Batch_loss: 1.554237 \n",
      "Batch: 35. Acc: 0.455725. Loss: 1.516251. Batch_acc: 0.449621. Batch_loss: 1.539350 \n",
      "Batch: 36. Acc: 0.455715. Loss: 1.516845. Batch_acc: 0.455378. Batch_loss: 1.538126 \n",
      "Batch: 37. Acc: 0.456304. Loss: 1.515507. Batch_acc: 0.477987. Batch_loss: 1.466243 \n",
      "Batch: 38. Acc: 0.456696. Loss: 1.514632. Batch_acc: 0.471494. Batch_loss: 1.481611 \n",
      "Batch: 39. Acc: 0.456508. Loss: 1.514567. Batch_acc: 0.449324. Batch_loss: 1.512085 \n",
      "Batch: 40. Acc: 0.456504. Loss: 1.514334. Batch_acc: 0.456322. Batch_loss: 1.504998 \n",
      "Batch: 41. Acc: 0.456067. Loss: 1.514728. Batch_acc: 0.438418. Batch_loss: 1.530623 \n",
      "Batch: 42. Acc: 0.455055. Loss: 1.516549. Batch_acc: 0.411523. Batch_loss: 1.594926 \n",
      "Batch: 43. Acc: 0.454843. Loss: 1.516613. Batch_acc: 0.445550. Batch_loss: 1.519408 \n",
      "Batch: 44. Acc: 0.454780. Loss: 1.516603. Batch_acc: 0.452000. Batch_loss: 1.516173 \n",
      "Batch: 45. Acc: 0.454645. Loss: 1.516651. Batch_acc: 0.448667. Batch_loss: 1.518807 \n",
      "Batch: 46. Acc: 0.454133. Loss: 1.518630. Batch_acc: 0.430314. Batch_loss: 1.610720 \n",
      "Batch: 47. Acc: 0.454567. Loss: 1.517028. Batch_acc: 0.474481. Batch_loss: 1.443464 \n",
      "Batch: 48. Acc: 0.454463. Loss: 1.516724. Batch_acc: 0.449483. Batch_loss: 1.502130 \n",
      "Batch: 49. Acc: 0.453825. Loss: 1.518252. Batch_acc: 0.422184. Batch_loss: 1.594009 \n",
      "Batch: 50. Acc: 0.454213. Loss: 1.517996. Batch_acc: 0.473474. Batch_loss: 1.505268 \n",
      "Batch: 51. Acc: 0.454256. Loss: 1.517799. Batch_acc: 0.456410. Batch_loss: 1.507827 \n",
      "Batch: 52. Acc: 0.454152. Loss: 1.518246. Batch_acc: 0.448769. Batch_loss: 1.541454 \n",
      "Batch: 53. Acc: 0.453982. Loss: 1.518776. Batch_acc: 0.444834. Batch_loss: 1.547364 \n",
      "Batch: 54. Acc: 0.453850. Loss: 1.519146. Batch_acc: 0.446833. Batch_loss: 1.538829 \n",
      "Batch: 55. Acc: 0.453627. Loss: 1.519502. Batch_acc: 0.441125. Batch_loss: 1.539467 \n",
      "Batch: 56. Acc: 0.453167. Loss: 1.520370. Batch_acc: 0.427252. Batch_loss: 1.569238 \n",
      "Batch: 57. Acc: 0.452910. Loss: 1.521608. Batch_acc: 0.437796. Batch_loss: 1.594445 \n",
      "Batch: 58. Acc: 0.452945. Loss: 1.521610. Batch_acc: 0.454971. Batch_loss: 1.521734 \n",
      "Batch: 59. Acc: 0.452626. Loss: 1.522740. Batch_acc: 0.433756. Batch_loss: 1.589566 \n",
      "Batch: 60. Acc: 0.452783. Loss: 1.522800. Batch_acc: 0.462199. Batch_loss: 1.526417 \n",
      "Batch: 61. Acc: 0.452651. Loss: 1.523226. Batch_acc: 0.444509. Batch_loss: 1.549506 \n",
      "Batch: 62. Acc: 0.452665. Loss: 1.523038. Batch_acc: 0.453536. Batch_loss: 1.511183 \n",
      "Batch: 63. Acc: 0.452747. Loss: 1.523520. Batch_acc: 0.457971. Batch_loss: 1.554086 \n",
      "Batch: 64. Acc: 0.452775. Loss: 1.523835. Batch_acc: 0.454598. Batch_loss: 1.544116 \n",
      "Batch: 65. Acc: 0.452870. Loss: 1.523659. Batch_acc: 0.459083. Batch_loss: 1.512142 \n",
      "Batch: 66. Acc: 0.453039. Loss: 1.523343. Batch_acc: 0.463964. Batch_loss: 1.502900 \n",
      "Batch: 67. Acc: 0.452959. Loss: 1.523235. Batch_acc: 0.447624. Batch_loss: 1.516074 \n",
      "Batch: 68. Acc: 0.453106. Loss: 1.523113. Batch_acc: 0.463037. Batch_loss: 1.514831 \n",
      "Batch: 69. Acc: 0.453105. Loss: 1.523568. Batch_acc: 0.453071. Batch_loss: 1.555178 \n",
      "Batch: 70. Acc: 0.453023. Loss: 1.523716. Batch_acc: 0.447353. Batch_loss: 1.533987 \n",
      "Batch: 71. Acc: 0.452739. Loss: 1.524371. Batch_acc: 0.432448. Batch_loss: 1.571098 \n",
      "Batch: 72. Acc: 0.452789. Loss: 1.524496. Batch_acc: 0.456446. Batch_loss: 1.533607 \n",
      "Batch: 73. Acc: 0.452711. Loss: 1.524514. Batch_acc: 0.446908. Batch_loss: 1.525790 \n",
      "Batch: 74. Acc: 0.452646. Loss: 1.524891. Batch_acc: 0.447863. Batch_loss: 1.552595 \n",
      "Batch: 75. Acc: 0.453056. Loss: 1.523961. Batch_acc: 0.483127. Batch_loss: 1.455721 \n",
      "Batch: 76. Acc: 0.453072. Loss: 1.523989. Batch_acc: 0.454287. Batch_loss: 1.526088 \n",
      "Batch: 77. Acc: 0.453044. Loss: 1.523851. Batch_acc: 0.450853. Batch_loss: 1.512986 \n",
      "Batch: 78. Acc: 0.452922. Loss: 1.524294. Batch_acc: 0.443498. Batch_loss: 1.558360 \n",
      "Batch: 79. Acc: 0.453028. Loss: 1.524228. Batch_acc: 0.461538. Batch_loss: 1.518955 \n",
      "Batch: 80. Acc: 0.453120. Loss: 1.524188. Batch_acc: 0.460399. Batch_loss: 1.521062 \n",
      "Batch: 81. Acc: 0.453199. Loss: 1.523827. Batch_acc: 0.459663. Batch_loss: 1.494265 \n",
      "Batch: 82. Acc: 0.453483. Loss: 1.523161. Batch_acc: 0.477048. Batch_loss: 1.467987 \n",
      "Batch: 83. Acc: 0.453170. Loss: 1.523912. Batch_acc: 0.426643. Batch_loss: 1.587493 \n",
      "Batch: 84. Acc: 0.453255. Loss: 1.523537. Batch_acc: 0.460390. Batch_loss: 1.492144 \n",
      "Batch: 85. Acc: 0.453203. Loss: 1.523469. Batch_acc: 0.448755. Batch_loss: 1.517664 \n",
      "Batch: 86. Acc: 0.453350. Loss: 1.522914. Batch_acc: 0.465942. Batch_loss: 1.475405 \n",
      "Batch: 87. Acc: 0.453580. Loss: 1.522509. Batch_acc: 0.473179. Batch_loss: 1.487901 \n",
      "Batch: 88. Acc: 0.453730. Loss: 1.522322. Batch_acc: 0.466780. Batch_loss: 1.506075 \n",
      "Batch: 89. Acc: 0.453701. Loss: 1.522605. Batch_acc: 0.451115. Batch_loss: 1.547668 \n",
      "Batch: 90. Acc: 0.453945. Loss: 1.521855. Batch_acc: 0.475391. Batch_loss: 1.456160 \n",
      "Batch: 91. Acc: 0.454285. Loss: 1.521123. Batch_acc: 0.485899. Batch_loss: 1.453055 \n",
      "Batch: 92. Acc: 0.454348. Loss: 1.520982. Batch_acc: 0.460116. Batch_loss: 1.507893 \n",
      "Batch: 93. Acc: 0.454600. Loss: 1.520561. Batch_acc: 0.478111. Batch_loss: 1.481292 \n",
      "Batch: 94. Acc: 0.454799. Loss: 1.520118. Batch_acc: 0.473502. Batch_loss: 1.478401 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.454840. Loss: 1.520180. Batch_acc: 0.458634. Batch_loss: 1.525939 \n",
      "Batch: 96. Acc: 0.454887. Loss: 1.520067. Batch_acc: 0.459507. Batch_loss: 1.508955 \n",
      "Batch: 97. Acc: 0.454845. Loss: 1.519856. Batch_acc: 0.450704. Batch_loss: 1.498904 \n",
      "Batch: 98. Acc: 0.455013. Loss: 1.519405. Batch_acc: 0.471154. Batch_loss: 1.475987 \n",
      "Batch: 99. Acc: 0.455043. Loss: 1.519249. Batch_acc: 0.458065. Batch_loss: 1.503440 \n",
      "Batch: 100. Acc: 0.454936. Loss: 1.519549. Batch_acc: 0.444253. Batch_loss: 1.549588 \n",
      "Batch: 101. Acc: 0.455071. Loss: 1.519193. Batch_acc: 0.468520. Batch_loss: 1.483678 \n",
      "Batch: 102. Acc: 0.454853. Loss: 1.519417. Batch_acc: 0.432401. Batch_loss: 1.542647 \n",
      "Batch: 103. Acc: 0.454998. Loss: 1.518947. Batch_acc: 0.470076. Batch_loss: 1.469925 \n",
      "Batch: 104. Acc: 0.455095. Loss: 1.518865. Batch_acc: 0.465011. Batch_loss: 1.510555 \n",
      "Batch: 105. Acc: 0.455133. Loss: 1.518795. Batch_acc: 0.459101. Batch_loss: 1.511410 \n",
      "Batch: 106. Acc: 0.455139. Loss: 1.518821. Batch_acc: 0.455763. Batch_loss: 1.521597 \n",
      "Batch: 107. Acc: 0.455242. Loss: 1.518540. Batch_acc: 0.466472. Batch_loss: 1.488029 \n",
      "Batch: 108. Acc: 0.455235. Loss: 1.518341. Batch_acc: 0.454441. Batch_loss: 1.496977 \n",
      "Batch: 109. Acc: 0.455511. Loss: 1.517564. Batch_acc: 0.485404. Batch_loss: 1.433254 \n",
      "Batch: 110. Acc: 0.455621. Loss: 1.517463. Batch_acc: 0.467863. Batch_loss: 1.506239 \n",
      "Batch: 111. Acc: 0.455846. Loss: 1.517153. Batch_acc: 0.480594. Batch_loss: 1.483056 \n",
      "Batch: 112. Acc: 0.455826. Loss: 1.517218. Batch_acc: 0.453650. Batch_loss: 1.524476 \n",
      "Batch: 113. Acc: 0.455759. Loss: 1.517377. Batch_acc: 0.447953. Batch_loss: 1.535737 \n",
      "Batch: 114. Acc: 0.455752. Loss: 1.516985. Batch_acc: 0.455020. Batch_loss: 1.471895 \n",
      "Batch: 115. Acc: 0.455696. Loss: 1.517029. Batch_acc: 0.449225. Batch_loss: 1.521973 \n",
      "Batch: 116. Acc: 0.455663. Loss: 1.516935. Batch_acc: 0.451890. Batch_loss: 1.506101 \n",
      "Batch: 117. Acc: 0.455543. Loss: 1.517144. Batch_acc: 0.441279. Batch_loss: 1.541842 \n",
      "Batch: 118. Acc: 0.455518. Loss: 1.517142. Batch_acc: 0.452714. Batch_loss: 1.516941 \n",
      "Batch: 119. Acc: 0.455489. Loss: 1.516922. Batch_acc: 0.452109. Batch_loss: 1.490989 \n",
      "Batch: 120. Acc: 0.455668. Loss: 1.516847. Batch_acc: 0.477207. Batch_loss: 1.507858 \n",
      "Batch: 121. Acc: 0.455878. Loss: 1.516497. Batch_acc: 0.480933. Batch_loss: 1.474525 \n",
      "Batch: 122. Acc: 0.456032. Loss: 1.515935. Batch_acc: 0.474702. Batch_loss: 1.448190 \n",
      "Batch: 123. Acc: 0.455988. Loss: 1.516292. Batch_acc: 0.450704. Batch_loss: 1.559236 \n",
      "Batch: 124. Acc: 0.455996. Loss: 1.516348. Batch_acc: 0.456891. Batch_loss: 1.523481 \n",
      "Batch: 125. Acc: 0.455882. Loss: 1.516513. Batch_acc: 0.441860. Batch_loss: 1.536838 \n",
      "Batch: 126. Acc: 0.455952. Loss: 1.516241. Batch_acc: 0.464692. Batch_loss: 1.482259 \n",
      "Batch: 127. Acc: 0.455803. Loss: 1.516608. Batch_acc: 0.435913. Batch_loss: 1.565693 \n",
      "Batch: 128. Acc: 0.455732. Loss: 1.516762. Batch_acc: 0.446471. Batch_loss: 1.536907 \n",
      "Batch: 129. Acc: 0.455674. Loss: 1.517037. Batch_acc: 0.448178. Batch_loss: 1.552142 \n",
      "Batch: 130. Acc: 0.455767. Loss: 1.516643. Batch_acc: 0.467760. Batch_loss: 1.466298 \n",
      "Batch: 131. Acc: 0.455625. Loss: 1.516923. Batch_acc: 0.437071. Batch_loss: 1.553421 \n",
      "Batch: 132. Acc: 0.455582. Loss: 1.517149. Batch_acc: 0.449942. Batch_loss: 1.546982 \n",
      "Batch: 133. Acc: 0.455606. Loss: 1.516972. Batch_acc: 0.458716. Batch_loss: 1.493465 \n",
      "Batch: 134. Acc: 0.455670. Loss: 1.517202. Batch_acc: 0.464411. Batch_loss: 1.548508 \n",
      "Batch: 135. Acc: 0.455686. Loss: 1.517353. Batch_acc: 0.457895. Batch_loss: 1.538115 \n",
      "Batch: 136. Acc: 0.455466. Loss: 1.517665. Batch_acc: 0.425059. Batch_loss: 1.560910 \n",
      "Batch: 137. Acc: 0.455395. Loss: 1.517742. Batch_acc: 0.445878. Batch_loss: 1.528015 \n",
      "Batch: 138. Acc: 0.455630. Loss: 1.517316. Batch_acc: 0.487735. Batch_loss: 1.458968 \n",
      "Batch: 139. Acc: 0.455695. Loss: 1.517122. Batch_acc: 0.464466. Batch_loss: 1.490851 \n",
      "Batch: 140. Acc: 0.455607. Loss: 1.517441. Batch_acc: 0.443364. Batch_loss: 1.561849 \n",
      "Batch: 141. Acc: 0.455487. Loss: 1.517678. Batch_acc: 0.438746. Batch_loss: 1.550847 \n",
      "Batch: 142. Acc: 0.455520. Loss: 1.517520. Batch_acc: 0.460102. Batch_loss: 1.495463 \n",
      "Batch: 143. Acc: 0.455430. Loss: 1.517582. Batch_acc: 0.443017. Batch_loss: 1.526111 \n",
      "Batch: 144. Acc: 0.455293. Loss: 1.517986. Batch_acc: 0.435558. Batch_loss: 1.576324 \n",
      "Batch: 145. Acc: 0.455325. Loss: 1.518099. Batch_acc: 0.459884. Batch_loss: 1.534582 \n",
      "Batch: 146. Acc: 0.455334. Loss: 1.518058. Batch_acc: 0.456725. Batch_loss: 1.511992 \n",
      "Batch: 147. Acc: 0.455238. Loss: 1.518182. Batch_acc: 0.440885. Batch_loss: 1.536733 \n",
      "Batch: 148. Acc: 0.455257. Loss: 1.518301. Batch_acc: 0.458190. Batch_loss: 1.535861 \n",
      "Batch: 149. Acc: 0.455397. Loss: 1.517884. Batch_acc: 0.475630. Batch_loss: 1.457222 \n",
      "Batch: 150. Acc: 0.455388. Loss: 1.518156. Batch_acc: 0.454026. Batch_loss: 1.558708 \n",
      "Batch: 151. Acc: 0.455243. Loss: 1.518347. Batch_acc: 0.433598. Batch_loss: 1.546807 \n",
      "Batch: 152. Acc: 0.455318. Loss: 1.518207. Batch_acc: 0.466370. Batch_loss: 1.497749 \n",
      "Batch: 153. Acc: 0.455278. Loss: 1.518400. Batch_acc: 0.449123. Batch_loss: 1.548458 \n",
      "Batch: 154. Acc: 0.455375. Loss: 1.518140. Batch_acc: 0.470554. Batch_loss: 1.477499 \n",
      "Batch: 155. Acc: 0.455375. Loss: 1.518037. Batch_acc: 0.455266. Batch_loss: 1.502315 \n",
      "Batch: 156. Acc: 0.455440. Loss: 1.517790. Batch_acc: 0.465596. Batch_loss: 1.479332 \n",
      "Batch: 157. Acc: 0.455279. Loss: 1.518137. Batch_acc: 0.430657. Batch_loss: 1.571308 \n",
      "Batch: 158. Acc: 0.455373. Loss: 1.518008. Batch_acc: 0.470416. Batch_loss: 1.497232 \n",
      "Batch: 159. Acc: 0.455257. Loss: 1.518059. Batch_acc: 0.436742. Batch_loss: 1.526188 \n",
      "Batch: 160. Acc: 0.455360. Loss: 1.517953. Batch_acc: 0.471763. Batch_loss: 1.501070 \n",
      "Batch: 161. Acc: 0.455364. Loss: 1.517853. Batch_acc: 0.456019. Batch_loss: 1.501688 \n",
      "Batch: 162. Acc: 0.455317. Loss: 1.517938. Batch_acc: 0.447804. Batch_loss: 1.531621 \n",
      "Batch: 163. Acc: 0.455325. Loss: 1.517851. Batch_acc: 0.456497. Batch_loss: 1.503522 \n",
      "Batch: 164. Acc: 0.455280. Loss: 1.517912. Batch_acc: 0.447899. Batch_loss: 1.528015 \n",
      "Batch: 165. Acc: 0.455288. Loss: 1.517704. Batch_acc: 0.456621. Batch_loss: 1.483494 \n",
      "Batch: 166. Acc: 0.455231. Loss: 1.517789. Batch_acc: 0.445678. Batch_loss: 1.532137 \n",
      "Batch: 167. Acc: 0.455218. Loss: 1.517745. Batch_acc: 0.452982. Batch_loss: 1.510537 \n",
      "Batch: 168. Acc: 0.455197. Loss: 1.517778. Batch_acc: 0.451613. Batch_loss: 1.523397 \n",
      "Batch: 169. Acc: 0.455177. Loss: 1.517782. Batch_acc: 0.451839. Batch_loss: 1.518427 \n",
      "Batch: 170. Acc: 0.455117. Loss: 1.517933. Batch_acc: 0.444826. Batch_loss: 1.543501 \n",
      "Batch: 171. Acc: 0.455055. Loss: 1.517952. Batch_acc: 0.444571. Batch_loss: 1.521231 \n",
      "Batch: 172. Acc: 0.455067. Loss: 1.517924. Batch_acc: 0.457062. Batch_loss: 1.513134 \n",
      "Batch: 173. Acc: 0.455136. Loss: 1.517764. Batch_acc: 0.467410. Batch_loss: 1.489442 \n",
      "Batch: 174. Acc: 0.455075. Loss: 1.517922. Batch_acc: 0.444508. Batch_loss: 1.545402 \n",
      "Batch: 175. Acc: 0.455119. Loss: 1.517769. Batch_acc: 0.462877. Batch_loss: 1.490761 \n",
      "Batch: 176. Acc: 0.455036. Loss: 1.517938. Batch_acc: 0.440415. Batch_loss: 1.547814 \n",
      "Batch: 177. Acc: 0.455014. Loss: 1.517951. Batch_acc: 0.450980. Batch_loss: 1.520293 \n",
      "Batch: 178. Acc: 0.455033. Loss: 1.517827. Batch_acc: 0.458551. Batch_loss: 1.495436 \n",
      "Batch: 179. Acc: 0.454942. Loss: 1.517935. Batch_acc: 0.438372. Batch_loss: 1.537515 \n",
      "Batch: 180. Acc: 0.454939. Loss: 1.518029. Batch_acc: 0.454441. Batch_loss: 1.535001 \n",
      "Batch: 181. Acc: 0.454901. Loss: 1.518103. Batch_acc: 0.447831. Batch_loss: 1.531693 \n",
      "Batch: 182. Acc: 0.454890. Loss: 1.518217. Batch_acc: 0.452841. Batch_loss: 1.539390 \n",
      "Batch: 183. Acc: 0.454904. Loss: 1.518091. Batch_acc: 0.457627. Batch_loss: 1.494769 \n",
      "Batch: 184. Acc: 0.454986. Loss: 1.517848. Batch_acc: 0.470145. Batch_loss: 1.472763 \n",
      "Batch: 185. Acc: 0.455022. Loss: 1.517675. Batch_acc: 0.461670. Batch_loss: 1.485824 \n",
      "Batch: 186. Acc: 0.455071. Loss: 1.517508. Batch_acc: 0.463929. Batch_loss: 1.487556 \n",
      "Batch: 187. Acc: 0.455108. Loss: 1.517412. Batch_acc: 0.461932. Batch_loss: 1.499531 \n",
      "Batch: 188. Acc: 0.455188. Loss: 1.517149. Batch_acc: 0.470214. Batch_loss: 1.467502 \n",
      "Batch: 189. Acc: 0.455117. Loss: 1.517411. Batch_acc: 0.441753. Batch_loss: 1.567147 \n",
      "Batch: 190. Acc: 0.455186. Loss: 1.517152. Batch_acc: 0.468369. Batch_loss: 1.467365 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.455162. Loss: 1.517214. Batch_acc: 0.450617. Batch_loss: 1.528827 \n",
      "Batch: 192. Acc: 0.455161. Loss: 1.517248. Batch_acc: 0.455076. Batch_loss: 1.523750 \n",
      "Batch: 193. Acc: 0.455241. Loss: 1.516993. Batch_acc: 0.470622. Batch_loss: 1.467842 \n",
      "Batch: 194. Acc: 0.455340. Loss: 1.516825. Batch_acc: 0.474344. Batch_loss: 1.484426 \n",
      "Batch: 195. Acc: 0.455372. Loss: 1.516782. Batch_acc: 0.461625. Batch_loss: 1.508495 \n",
      "Batch: 196. Acc: 0.455464. Loss: 1.516438. Batch_acc: 0.473383. Batch_loss: 1.449408 \n",
      "Batch: 197. Acc: 0.455403. Loss: 1.516440. Batch_acc: 0.443293. Batch_loss: 1.516742 \n",
      "Batch: 198. Acc: 0.455299. Loss: 1.516544. Batch_acc: 0.434758. Batch_loss: 1.537332 \n",
      "Batch: 199. Acc: 0.455237. Loss: 1.516724. Batch_acc: 0.442857. Batch_loss: 1.552317 \n",
      "Batch: 200. Acc: 0.455273. Loss: 1.516699. Batch_acc: 0.462402. Batch_loss: 1.511750 \n",
      "Batch: 201. Acc: 0.455330. Loss: 1.516553. Batch_acc: 0.466333. Batch_loss: 1.488196 \n",
      "Batch: 202. Acc: 0.455318. Loss: 1.516507. Batch_acc: 0.452884. Batch_loss: 1.507189 \n",
      "Batch: 203. Acc: 0.455296. Loss: 1.516457. Batch_acc: 0.450777. Batch_loss: 1.506453 \n",
      "Batch: 204. Acc: 0.455311. Loss: 1.516540. Batch_acc: 0.458576. Batch_loss: 1.533634 \n",
      "Batch: 205. Acc: 0.455330. Loss: 1.516475. Batch_acc: 0.459184. Batch_loss: 1.503299 \n",
      "Batch: 206. Acc: 0.455434. Loss: 1.516151. Batch_acc: 0.476571. Batch_loss: 1.449774 \n",
      "Batch: 207. Acc: 0.455464. Loss: 1.516131. Batch_acc: 0.461668. Batch_loss: 1.512046 \n",
      "Batch: 208. Acc: 0.455435. Loss: 1.516132. Batch_acc: 0.449360. Batch_loss: 1.516472 \n",
      "Batch: 209. Acc: 0.455404. Loss: 1.516258. Batch_acc: 0.448718. Batch_loss: 1.543011 \n",
      "Batch: 210. Acc: 0.455484. Loss: 1.516047. Batch_acc: 0.472286. Batch_loss: 1.471460 \n",
      "Batch: 211. Acc: 0.455560. Loss: 1.515913. Batch_acc: 0.471774. Batch_loss: 1.487584 \n",
      "Batch: 212. Acc: 0.455658. Loss: 1.515740. Batch_acc: 0.476163. Batch_loss: 1.479495 \n",
      "Batch: 213. Acc: 0.455705. Loss: 1.515782. Batch_acc: 0.465636. Batch_loss: 1.524594 \n",
      "Batch: 214. Acc: 0.455783. Loss: 1.515670. Batch_acc: 0.472527. Batch_loss: 1.491698 \n",
      "Batch: 215. Acc: 0.455821. Loss: 1.515685. Batch_acc: 0.464037. Batch_loss: 1.518968 \n",
      "Batch: 216. Acc: 0.455879. Loss: 1.515625. Batch_acc: 0.468535. Batch_loss: 1.502717 \n",
      "Batch: 217. Acc: 0.455881. Loss: 1.515681. Batch_acc: 0.456311. Batch_loss: 1.527606 \n",
      "Batch: 218. Acc: 0.455834. Loss: 1.515799. Batch_acc: 0.445407. Batch_loss: 1.541663 \n",
      "Batch: 219. Acc: 0.455882. Loss: 1.515690. Batch_acc: 0.466513. Batch_loss: 1.491797 \n",
      "Batch: 220. Acc: 0.455905. Loss: 1.515642. Batch_acc: 0.460924. Batch_loss: 1.505245 \n",
      "Batch: 221. Acc: 0.455857. Loss: 1.515709. Batch_acc: 0.445093. Batch_loss: 1.530640 \n",
      "Batch: 222. Acc: 0.455707. Loss: 1.515963. Batch_acc: 0.420926. Batch_loss: 1.575104 \n",
      "Batch: 223. Acc: 0.455746. Loss: 1.515900. Batch_acc: 0.464558. Batch_loss: 1.501471 \n",
      "Batch: 224. Acc: 0.455757. Loss: 1.515836. Batch_acc: 0.458068. Batch_loss: 1.501354 \n",
      "Batch: 225. Acc: 0.455773. Loss: 1.515723. Batch_acc: 0.459490. Batch_loss: 1.490625 \n",
      "Batch: 226. Acc: 0.455853. Loss: 1.515420. Batch_acc: 0.473506. Batch_loss: 1.448295 \n",
      "Batch: 227. Acc: 0.455898. Loss: 1.515289. Batch_acc: 0.466355. Batch_loss: 1.485164 \n",
      "Batch: 228. Acc: 0.455875. Loss: 1.515390. Batch_acc: 0.450440. Batch_loss: 1.538763 \n",
      "Batch: 229. Acc: 0.455855. Loss: 1.515413. Batch_acc: 0.451389. Batch_loss: 1.520770 \n",
      "Batch: 230. Acc: 0.455887. Loss: 1.515183. Batch_acc: 0.463274. Batch_loss: 1.461858 \n",
      "Batch: 231. Acc: 0.455809. Loss: 1.515368. Batch_acc: 0.437390. Batch_loss: 1.559237 \n",
      "Batch: 232. Acc: 0.455792. Loss: 1.515269. Batch_acc: 0.451780. Batch_loss: 1.492324 \n",
      "Batch: 233. Acc: 0.455895. Loss: 1.514924. Batch_acc: 0.479885. Batch_loss: 1.434607 \n",
      "Batch: 234. Acc: 0.455923. Loss: 1.514960. Batch_acc: 0.462464. Batch_loss: 1.523268 \n",
      "Batch: 235. Acc: 0.456006. Loss: 1.514805. Batch_acc: 0.475561. Batch_loss: 1.478374 \n",
      "Batch: 236. Acc: 0.456082. Loss: 1.514539. Batch_acc: 0.474299. Batch_loss: 1.450682 \n",
      "Batch: 237. Acc: 0.456020. Loss: 1.514680. Batch_acc: 0.441328. Batch_loss: 1.548102 \n",
      "Batch: 238. Acc: 0.455955. Loss: 1.514765. Batch_acc: 0.440435. Batch_loss: 1.534925 \n",
      "Batch: 239. Acc: 0.456033. Loss: 1.514509. Batch_acc: 0.474330. Batch_loss: 1.454978 \n",
      "Batch: 240. Acc: 0.456057. Loss: 1.514473. Batch_acc: 0.461810. Batch_loss: 1.505611 \n",
      "Batch: 241. Acc: 0.456077. Loss: 1.514471. Batch_acc: 0.461009. Batch_loss: 1.514056 \n",
      "Batch: 242. Acc: 0.456152. Loss: 1.514261. Batch_acc: 0.474227. Batch_loss: 1.463600 \n",
      "Batch: 243. Acc: 0.456006. Loss: 1.514481. Batch_acc: 0.419825. Batch_loss: 1.568724 \n",
      "Batch: 244. Acc: 0.456037. Loss: 1.514460. Batch_acc: 0.463554. Batch_loss: 1.509429 \n",
      "Batch: 245. Acc: 0.456080. Loss: 1.514375. Batch_acc: 0.466224. Batch_loss: 1.494282 \n",
      "Batch: 246. Acc: 0.456038. Loss: 1.514519. Batch_acc: 0.445853. Batch_loss: 1.549935 \n",
      "Batch: 247. Acc: 0.456082. Loss: 1.514340. Batch_acc: 0.466667. Batch_loss: 1.470548 \n",
      "Batch: 248. Acc: 0.456166. Loss: 1.514235. Batch_acc: 0.476810. Batch_loss: 1.488702 \n",
      "Batch: 249. Acc: 0.456248. Loss: 1.514049. Batch_acc: 0.476083. Batch_loss: 1.468656 \n",
      "Batch: 250. Acc: 0.456183. Loss: 1.514251. Batch_acc: 0.440159. Batch_loss: 1.564219 \n",
      "Batch: 251. Acc: 0.456221. Loss: 1.514085. Batch_acc: 0.465863. Batch_loss: 1.472408 \n",
      "Checkpointing on batch: 251. Accuracy: 0.4562210930586851. Loss per char: 1.5140850041491367. Time: 1627214318.4706633\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 18, 15, 26, 17, 18, 26, 26, 17,\n",
      "        23, 20, 25,  1, 12,  1, 24, 20, 19, 18, 17, 15,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.456203. Loss: 1.514046. Batch_acc: 0.451557. Batch_loss: 1.504295 \n",
      "Batch: 253. Acc: 0.456191. Loss: 1.514068. Batch_acc: 0.453152. Batch_loss: 1.519354 \n",
      "Batch: 254. Acc: 0.456189. Loss: 1.513959. Batch_acc: 0.455782. Batch_loss: 1.486736 \n",
      "Batch: 255. Acc: 0.456183. Loss: 1.513880. Batch_acc: 0.454801. Batch_loss: 1.494337 \n",
      "Batch: 256. Acc: 0.456175. Loss: 1.513904. Batch_acc: 0.454126. Batch_loss: 1.519875 \n",
      "Batch: 257. Acc: 0.456173. Loss: 1.513955. Batch_acc: 0.455485. Batch_loss: 1.527046 \n",
      "Batch: 258. Acc: 0.456162. Loss: 1.513902. Batch_acc: 0.453448. Batch_loss: 1.500217 \n",
      "Batch: 259. Acc: 0.456140. Loss: 1.513944. Batch_acc: 0.450399. Batch_loss: 1.524705 \n",
      "Batch: 260. Acc: 0.456168. Loss: 1.513895. Batch_acc: 0.463615. Batch_loss: 1.500956 \n",
      "Batch: 261. Acc: 0.456154. Loss: 1.513845. Batch_acc: 0.452546. Batch_loss: 1.500674 \n",
      "Batch: 262. Acc: 0.456098. Loss: 1.513947. Batch_acc: 0.441595. Batch_loss: 1.540515 \n",
      "Batch: 263. Acc: 0.456189. Loss: 1.513768. Batch_acc: 0.480278. Batch_loss: 1.466232 \n",
      "Batch: 264. Acc: 0.456203. Loss: 1.513699. Batch_acc: 0.459837. Batch_loss: 1.495234 \n",
      "Batch: 265. Acc: 0.456112. Loss: 1.513893. Batch_acc: 0.432169. Batch_loss: 1.565234 \n",
      "Batch: 266. Acc: 0.456138. Loss: 1.513906. Batch_acc: 0.463048. Batch_loss: 1.517219 \n",
      "Batch: 267. Acc: 0.456161. Loss: 1.513792. Batch_acc: 0.462625. Batch_loss: 1.482710 \n",
      "Batch: 268. Acc: 0.456137. Loss: 1.513787. Batch_acc: 0.449504. Batch_loss: 1.512486 \n",
      "Batch: 269. Acc: 0.456099. Loss: 1.513879. Batch_acc: 0.445614. Batch_loss: 1.538940 \n",
      "Batch: 270. Acc: 0.456093. Loss: 1.513893. Batch_acc: 0.454597. Batch_loss: 1.517682 \n",
      "Batch: 271. Acc: 0.455994. Loss: 1.514107. Batch_acc: 0.428571. Batch_loss: 1.573355 \n",
      "Batch: 272. Acc: 0.456173. Loss: 1.513700. Batch_acc: 0.503964. Batch_loss: 1.404696 \n",
      "Batch: 273. Acc: 0.456211. Loss: 1.513688. Batch_acc: 0.466940. Batch_loss: 1.510427 \n",
      "Batch: 274. Acc: 0.456236. Loss: 1.513595. Batch_acc: 0.463017. Batch_loss: 1.487808 \n",
      "Batch: 275. Acc: 0.456259. Loss: 1.513499. Batch_acc: 0.462577. Batch_loss: 1.487586 \n",
      "Batch: 276. Acc: 0.456247. Loss: 1.513641. Batch_acc: 0.452907. Batch_loss: 1.553298 \n",
      "Batch: 277. Acc: 0.456236. Loss: 1.513718. Batch_acc: 0.453080. Batch_loss: 1.535073 \n",
      "Batch: 278. Acc: 0.456281. Loss: 1.513599. Batch_acc: 0.468875. Batch_loss: 1.480625 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 279. Acc: 0.456339. Loss: 1.513321. Batch_acc: 0.472018. Batch_loss: 1.437157 \n",
      "Batch: 280. Acc: 0.456377. Loss: 1.513142. Batch_acc: 0.467083. Batch_loss: 1.463668 \n",
      "Batch: 281. Acc: 0.456405. Loss: 1.513052. Batch_acc: 0.464286. Batch_loss: 1.487775 \n",
      "Batch: 282. Acc: 0.456387. Loss: 1.513045. Batch_acc: 0.451128. Batch_loss: 1.510891 \n",
      "Batch: 283. Acc: 0.456504. Loss: 1.512705. Batch_acc: 0.489914. Batch_loss: 1.416303 \n",
      "Batch: 284. Acc: 0.456555. Loss: 1.512690. Batch_acc: 0.471171. Batch_loss: 1.508266 \n",
      "Batch: 285. Acc: 0.456598. Loss: 1.512637. Batch_acc: 0.468433. Batch_loss: 1.497900 \n",
      "Batch: 286. Acc: 0.456595. Loss: 1.512576. Batch_acc: 0.455763. Batch_loss: 1.494764 \n",
      "Batch: 287. Acc: 0.456628. Loss: 1.512548. Batch_acc: 0.465986. Batch_loss: 1.504692 \n",
      "Batch: 288. Acc: 0.456523. Loss: 1.512747. Batch_acc: 0.425806. Batch_loss: 1.571219 \n",
      "Batch: 289. Acc: 0.456441. Loss: 1.512905. Batch_acc: 0.432047. Batch_loss: 1.560039 \n",
      "Batch: 290. Acc: 0.456504. Loss: 1.512718. Batch_acc: 0.473889. Batch_loss: 1.460318 \n",
      "Batch: 291. Acc: 0.456530. Loss: 1.512712. Batch_acc: 0.464245. Batch_loss: 1.510959 \n",
      "Batch: 292. Acc: 0.456561. Loss: 1.512734. Batch_acc: 0.465729. Batch_loss: 1.519243 \n",
      "Batch: 293. Acc: 0.456617. Loss: 1.512589. Batch_acc: 0.472614. Batch_loss: 1.470878 \n",
      "Batch: 294. Acc: 0.456604. Loss: 1.512588. Batch_acc: 0.452972. Batch_loss: 1.512345 \n",
      "Batch: 295. Acc: 0.456632. Loss: 1.512650. Batch_acc: 0.464912. Batch_loss: 1.531321 \n",
      "Batch: 296. Acc: 0.456673. Loss: 1.512534. Batch_acc: 0.469136. Batch_loss: 1.477475 \n",
      "Batch: 297. Acc: 0.456625. Loss: 1.512618. Batch_acc: 0.441750. Batch_loss: 1.538259 \n",
      "Batch: 298. Acc: 0.456555. Loss: 1.512697. Batch_acc: 0.435586. Batch_loss: 1.536412 \n",
      "Batch: 299. Acc: 0.456696. Loss: 1.512326. Batch_acc: 0.497499. Batch_loss: 1.404931 \n",
      "Batch: 300. Acc: 0.456750. Loss: 1.512236. Batch_acc: 0.473050. Batch_loss: 1.485487 \n",
      "Batch: 301. Acc: 0.456761. Loss: 1.512203. Batch_acc: 0.460094. Batch_loss: 1.501800 \n",
      "Batch: 302. Acc: 0.456748. Loss: 1.512264. Batch_acc: 0.452917. Batch_loss: 1.530968 \n",
      "Batch: 303. Acc: 0.456672. Loss: 1.512431. Batch_acc: 0.433177. Batch_loss: 1.564026 \n",
      "Batch: 304. Acc: 0.456668. Loss: 1.512577. Batch_acc: 0.455357. Batch_loss: 1.555570 \n",
      "Batch: 305. Acc: 0.456657. Loss: 1.512549. Batch_acc: 0.453271. Batch_loss: 1.503892 \n",
      "Batch: 306. Acc: 0.456718. Loss: 1.512388. Batch_acc: 0.475429. Batch_loss: 1.463553 \n",
      "Batch: 307. Acc: 0.456657. Loss: 1.512579. Batch_acc: 0.437352. Batch_loss: 1.572604 \n",
      "Batch: 308. Acc: 0.456664. Loss: 1.512519. Batch_acc: 0.458804. Batch_loss: 1.494538 \n",
      "Batch: 309. Acc: 0.456646. Loss: 1.512592. Batch_acc: 0.450980. Batch_loss: 1.535057 \n",
      "Batch: 310. Acc: 0.456691. Loss: 1.512487. Batch_acc: 0.470690. Batch_loss: 1.480200 \n",
      "Batch: 311. Acc: 0.456741. Loss: 1.512394. Batch_acc: 0.472464. Batch_loss: 1.483088 \n",
      "Batch: 312. Acc: 0.456756. Loss: 1.512274. Batch_acc: 0.461272. Batch_loss: 1.474526 \n",
      "Batch: 313. Acc: 0.456713. Loss: 1.512333. Batch_acc: 0.443281. Batch_loss: 1.531095 \n",
      "Batch: 314. Acc: 0.456737. Loss: 1.512263. Batch_acc: 0.464041. Batch_loss: 1.490335 \n",
      "Batch: 315. Acc: 0.456812. Loss: 1.512185. Batch_acc: 0.480647. Batch_loss: 1.487527 \n",
      "Batch: 316. Acc: 0.456893. Loss: 1.512002. Batch_acc: 0.482521. Batch_loss: 1.454617 \n",
      "Batch: 317. Acc: 0.456863. Loss: 1.511990. Batch_acc: 0.446947. Batch_loss: 1.507859 \n",
      "Batch: 318. Acc: 0.456887. Loss: 1.512039. Batch_acc: 0.464531. Batch_loss: 1.527598 \n",
      "Batch: 319. Acc: 0.456877. Loss: 1.512029. Batch_acc: 0.453656. Batch_loss: 1.508836 \n",
      "Batch: 320. Acc: 0.456902. Loss: 1.512012. Batch_acc: 0.464912. Batch_loss: 1.506369 \n",
      "Batch: 321. Acc: 0.456928. Loss: 1.512026. Batch_acc: 0.465376. Batch_loss: 1.516752 \n",
      "Batch: 322. Acc: 0.456918. Loss: 1.511994. Batch_acc: 0.453936. Batch_loss: 1.501900 \n",
      "Batch: 323. Acc: 0.456949. Loss: 1.511968. Batch_acc: 0.467014. Batch_loss: 1.503718 \n",
      "Batch: 324. Acc: 0.456915. Loss: 1.511968. Batch_acc: 0.445845. Batch_loss: 1.511918 \n",
      "Batch: 325. Acc: 0.456960. Loss: 1.511855. Batch_acc: 0.471601. Batch_loss: 1.475264 \n",
      "Batch: 326. Acc: 0.456901. Loss: 1.512017. Batch_acc: 0.437572. Batch_loss: 1.564873 \n",
      "Batch: 327. Acc: 0.456884. Loss: 1.511992. Batch_acc: 0.451291. Batch_loss: 1.503604 \n",
      "Batch: 328. Acc: 0.456907. Loss: 1.511930. Batch_acc: 0.464428. Batch_loss: 1.491994 \n",
      "Batch: 329. Acc: 0.456863. Loss: 1.511947. Batch_acc: 0.442208. Batch_loss: 1.517351 \n",
      "Batch: 330. Acc: 0.456883. Loss: 1.511894. Batch_acc: 0.463557. Batch_loss: 1.494178 \n",
      "Batch: 331. Acc: 0.456829. Loss: 1.512060. Batch_acc: 0.438740. Batch_loss: 1.567933 \n",
      "Batch: 332. Acc: 0.456820. Loss: 1.512055. Batch_acc: 0.453970. Batch_loss: 1.510489 \n",
      "Batch: 333. Acc: 0.456776. Loss: 1.512117. Batch_acc: 0.441725. Batch_loss: 1.532956 \n",
      "Batch: 334. Acc: 0.456844. Loss: 1.511936. Batch_acc: 0.479679. Batch_loss: 1.451719 \n",
      "Batch: 335. Acc: 0.456842. Loss: 1.512004. Batch_acc: 0.456009. Batch_loss: 1.534816 \n",
      "Batch: 336. Acc: 0.456818. Loss: 1.512006. Batch_acc: 0.448598. Batch_loss: 1.512744 \n",
      "Batch: 337. Acc: 0.456804. Loss: 1.512039. Batch_acc: 0.452199. Batch_loss: 1.523227 \n",
      "Batch: 338. Acc: 0.456809. Loss: 1.511943. Batch_acc: 0.458453. Batch_loss: 1.479591 \n",
      "Batch: 339. Acc: 0.456776. Loss: 1.512058. Batch_acc: 0.445417. Batch_loss: 1.551678 \n",
      "Batch: 340. Acc: 0.456824. Loss: 1.511990. Batch_acc: 0.473168. Batch_loss: 1.489037 \n",
      "Batch: 341. Acc: 0.456864. Loss: 1.511982. Batch_acc: 0.470317. Batch_loss: 1.509007 \n",
      "Batch: 342. Acc: 0.456890. Loss: 1.512076. Batch_acc: 0.465975. Batch_loss: 1.544349 \n",
      "Batch: 343. Acc: 0.456868. Loss: 1.512099. Batch_acc: 0.449374. Batch_loss: 1.519804 \n",
      "Batch: 344. Acc: 0.456919. Loss: 1.511946. Batch_acc: 0.474352. Batch_loss: 1.459175 \n",
      "Batch: 345. Acc: 0.456928. Loss: 1.511881. Batch_acc: 0.460382. Batch_loss: 1.489586 \n",
      "Batch: 346. Acc: 0.456963. Loss: 1.511788. Batch_acc: 0.468894. Batch_loss: 1.479617 \n",
      "Batch: 347. Acc: 0.457013. Loss: 1.511676. Batch_acc: 0.474440. Batch_loss: 1.472843 \n",
      "Batch: 348. Acc: 0.457052. Loss: 1.511622. Batch_acc: 0.470759. Batch_loss: 1.492629 \n",
      "Batch: 349. Acc: 0.457052. Loss: 1.511607. Batch_acc: 0.457061. Batch_loss: 1.506342 \n",
      "Batch: 350. Acc: 0.457076. Loss: 1.511461. Batch_acc: 0.465116. Batch_loss: 1.461152 \n",
      "Batch: 351. Acc: 0.457167. Loss: 1.511359. Batch_acc: 0.488902. Batch_loss: 1.475693 \n",
      "Batch: 352. Acc: 0.457227. Loss: 1.511252. Batch_acc: 0.477772. Batch_loss: 1.474575 \n",
      "Batch: 353. Acc: 0.457205. Loss: 1.511357. Batch_acc: 0.449541. Batch_loss: 1.548167 \n",
      "Batch: 354. Acc: 0.457191. Loss: 1.511401. Batch_acc: 0.452143. Batch_loss: 1.527404 \n",
      "Batch: 355. Acc: 0.457261. Loss: 1.511304. Batch_acc: 0.481316. Batch_loss: 1.478008 \n",
      "Batch: 356. Acc: 0.457305. Loss: 1.511175. Batch_acc: 0.473256. Batch_loss: 1.464701 \n",
      "Batch: 357. Acc: 0.457298. Loss: 1.511178. Batch_acc: 0.454751. Batch_loss: 1.512146 \n",
      "Batch: 358. Acc: 0.457262. Loss: 1.511225. Batch_acc: 0.444381. Batch_loss: 1.528014 \n",
      "Batch: 359. Acc: 0.457296. Loss: 1.511128. Batch_acc: 0.469411. Batch_loss: 1.476581 \n",
      "Batch: 360. Acc: 0.457328. Loss: 1.511083. Batch_acc: 0.468804. Batch_loss: 1.495033 \n",
      "Batch: 361. Acc: 0.457374. Loss: 1.510958. Batch_acc: 0.473773. Batch_loss: 1.466698 \n",
      "Batch: 362. Acc: 0.457384. Loss: 1.510962. Batch_acc: 0.461261. Batch_loss: 1.512494 \n",
      "Batch: 363. Acc: 0.457450. Loss: 1.510857. Batch_acc: 0.480955. Batch_loss: 1.473107 \n",
      "Batch: 364. Acc: 0.457471. Loss: 1.510791. Batch_acc: 0.465222. Batch_loss: 1.486939 \n",
      "Batch: 365. Acc: 0.457563. Loss: 1.510545. Batch_acc: 0.491299. Batch_loss: 1.419991 \n",
      "Batch: 366. Acc: 0.457582. Loss: 1.510477. Batch_acc: 0.464571. Batch_loss: 1.485566 \n",
      "Batch: 367. Acc: 0.457612. Loss: 1.510528. Batch_acc: 0.468624. Batch_loss: 1.529473 \n",
      "Batch: 368. Acc: 0.457633. Loss: 1.510517. Batch_acc: 0.465487. Batch_loss: 1.506178 \n",
      "Batch: 369. Acc: 0.457581. Loss: 1.510641. Batch_acc: 0.438300. Batch_loss: 1.557038 \n",
      "Batch: 370. Acc: 0.457529. Loss: 1.510700. Batch_acc: 0.438007. Batch_loss: 1.532583 \n",
      "Batch: 371. Acc: 0.457526. Loss: 1.510723. Batch_acc: 0.456395. Batch_loss: 1.519485 \n",
      "Batch: 372. Acc: 0.457545. Loss: 1.510745. Batch_acc: 0.464594. Batch_loss: 1.519071 \n",
      "Batch: 373. Acc: 0.457600. Loss: 1.510565. Batch_acc: 0.477866. Batch_loss: 1.444036 \n",
      "Batch: 374. Acc: 0.457645. Loss: 1.510503. Batch_acc: 0.474566. Batch_loss: 1.487397 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 375. Acc: 0.457709. Loss: 1.510324. Batch_acc: 0.481105. Batch_loss: 1.444501 \n",
      "Batch: 376. Acc: 0.457751. Loss: 1.510166. Batch_acc: 0.473714. Batch_loss: 1.451076 \n",
      "Batch: 377. Acc: 0.457778. Loss: 1.510049. Batch_acc: 0.467724. Batch_loss: 1.466609 \n",
      "Batch: 378. Acc: 0.457824. Loss: 1.509966. Batch_acc: 0.475173. Batch_loss: 1.478494 \n",
      "Batch: 379. Acc: 0.457826. Loss: 1.509955. Batch_acc: 0.458810. Batch_loss: 1.505729 \n",
      "Batch: 380. Acc: 0.457853. Loss: 1.509942. Batch_acc: 0.467482. Batch_loss: 1.505247 \n",
      "Batch: 381. Acc: 0.457843. Loss: 1.509949. Batch_acc: 0.454087. Batch_loss: 1.512744 \n",
      "Batch: 382. Acc: 0.457838. Loss: 1.509981. Batch_acc: 0.456140. Batch_loss: 1.522584 \n",
      "Batch: 383. Acc: 0.457897. Loss: 1.509860. Batch_acc: 0.480045. Batch_loss: 1.464498 \n",
      "Batch: 384. Acc: 0.457916. Loss: 1.509889. Batch_acc: 0.465062. Batch_loss: 1.521310 \n",
      "Batch: 385. Acc: 0.457918. Loss: 1.509879. Batch_acc: 0.458736. Batch_loss: 1.506255 \n",
      "Batch: 386. Acc: 0.457926. Loss: 1.509904. Batch_acc: 0.461092. Batch_loss: 1.519387 \n",
      "Batch: 387. Acc: 0.457981. Loss: 1.509777. Batch_acc: 0.479287. Batch_loss: 1.460789 \n",
      "Batch: 388. Acc: 0.458018. Loss: 1.509700. Batch_acc: 0.472527. Batch_loss: 1.479748 \n",
      "Batch: 389. Acc: 0.458010. Loss: 1.509615. Batch_acc: 0.454963. Batch_loss: 1.476673 \n",
      "Batch: 390. Acc: 0.458038. Loss: 1.509509. Batch_acc: 0.468607. Batch_loss: 1.468170 \n",
      "Batch: 391. Acc: 0.458089. Loss: 1.509451. Batch_acc: 0.478361. Batch_loss: 1.487004 \n",
      "Batch: 392. Acc: 0.458040. Loss: 1.509535. Batch_acc: 0.438235. Batch_loss: 1.543130 \n",
      "Batch: 393. Acc: 0.458052. Loss: 1.509491. Batch_acc: 0.462800. Batch_loss: 1.491973 \n",
      "Batch: 394. Acc: 0.458020. Loss: 1.509505. Batch_acc: 0.445590. Batch_loss: 1.514996 \n",
      "Batch: 395. Acc: 0.457985. Loss: 1.509485. Batch_acc: 0.443662. Batch_loss: 1.501390 \n",
      "Batch: 396. Acc: 0.458022. Loss: 1.509417. Batch_acc: 0.473012. Batch_loss: 1.482134 \n",
      "Batch: 397. Acc: 0.458031. Loss: 1.509412. Batch_acc: 0.461673. Batch_loss: 1.507400 \n",
      "Batch: 398. Acc: 0.457989. Loss: 1.509408. Batch_acc: 0.441142. Batch_loss: 1.507859 \n",
      "Batch: 399. Acc: 0.457990. Loss: 1.509412. Batch_acc: 0.458145. Batch_loss: 1.511006 \n",
      "Batch: 400. Acc: 0.458025. Loss: 1.509342. Batch_acc: 0.472350. Batch_loss: 1.481303 \n",
      "Batch: 401. Acc: 0.458044. Loss: 1.509326. Batch_acc: 0.465369. Batch_loss: 1.502689 \n",
      "Batch: 402. Acc: 0.458073. Loss: 1.509250. Batch_acc: 0.469783. Batch_loss: 1.478897 \n",
      "Batch: 403. Acc: 0.458114. Loss: 1.509157. Batch_acc: 0.474461. Batch_loss: 1.472454 \n",
      "Batch: 404. Acc: 0.458159. Loss: 1.509074. Batch_acc: 0.475975. Batch_loss: 1.475989 \n",
      "Batch: 405. Acc: 0.458139. Loss: 1.509027. Batch_acc: 0.450144. Batch_loss: 1.489963 \n",
      "Batch: 406. Acc: 0.458156. Loss: 1.509025. Batch_acc: 0.464917. Batch_loss: 1.508054 \n",
      "Batch: 407. Acc: 0.458105. Loss: 1.509123. Batch_acc: 0.436921. Batch_loss: 1.549597 \n",
      "Batch: 408. Acc: 0.458079. Loss: 1.509147. Batch_acc: 0.447475. Batch_loss: 1.518981 \n",
      "Batch: 409. Acc: 0.458059. Loss: 1.509280. Batch_acc: 0.449649. Batch_loss: 1.564389 \n",
      "Batch: 410. Acc: 0.458050. Loss: 1.509290. Batch_acc: 0.454493. Batch_loss: 1.513633 \n",
      "Batch: 411. Acc: 0.458070. Loss: 1.509336. Batch_acc: 0.466355. Batch_loss: 1.528679 \n",
      "Batch: 412. Acc: 0.458006. Loss: 1.509383. Batch_acc: 0.431779. Batch_loss: 1.528571 \n",
      "Batch: 413. Acc: 0.457979. Loss: 1.509410. Batch_acc: 0.446460. Batch_loss: 1.520823 \n",
      "Batch: 414. Acc: 0.457975. Loss: 1.509459. Batch_acc: 0.456395. Batch_loss: 1.529961 \n",
      "Batch: 415. Acc: 0.458035. Loss: 1.509314. Batch_acc: 0.483718. Batch_loss: 1.447191 \n",
      "Batch: 416. Acc: 0.458089. Loss: 1.509137. Batch_acc: 0.480226. Batch_loss: 1.436728 \n",
      "Batch: 417. Acc: 0.458068. Loss: 1.509214. Batch_acc: 0.449133. Batch_loss: 1.541852 \n",
      "Batch: 418. Acc: 0.458054. Loss: 1.509202. Batch_acc: 0.452128. Batch_loss: 1.503987 \n",
      "Batch: 419. Acc: 0.458037. Loss: 1.509275. Batch_acc: 0.450639. Batch_loss: 1.540060 \n",
      "Batch: 420. Acc: 0.458042. Loss: 1.509188. Batch_acc: 0.460253. Batch_loss: 1.472683 \n",
      "Batch: 421. Acc: 0.458106. Loss: 1.508989. Batch_acc: 0.485040. Batch_loss: 1.425184 \n",
      "Batch: 422. Acc: 0.458134. Loss: 1.508890. Batch_acc: 0.469989. Batch_loss: 1.467784 \n",
      "Batch: 423. Acc: 0.458136. Loss: 1.508895. Batch_acc: 0.458892. Batch_loss: 1.510986 \n",
      "Batch: 424. Acc: 0.458172. Loss: 1.508836. Batch_acc: 0.473112. Batch_loss: 1.483943 \n",
      "Batch: 425. Acc: 0.458203. Loss: 1.508812. Batch_acc: 0.471568. Batch_loss: 1.498391 \n",
      "Batch: 426. Acc: 0.458215. Loss: 1.508728. Batch_acc: 0.463134. Batch_loss: 1.472977 \n",
      "Batch: 427. Acc: 0.458204. Loss: 1.508742. Batch_acc: 0.453693. Batch_loss: 1.514909 \n",
      "Batch: 428. Acc: 0.458209. Loss: 1.508707. Batch_acc: 0.460411. Batch_loss: 1.493282 \n",
      "Batch: 429. Acc: 0.458270. Loss: 1.508589. Batch_acc: 0.483529. Batch_loss: 1.459651 \n",
      "Batch: 430. Acc: 0.458247. Loss: 1.508602. Batch_acc: 0.448593. Batch_loss: 1.514362 \n",
      "Batch: 431. Acc: 0.458271. Loss: 1.508575. Batch_acc: 0.468463. Batch_loss: 1.496727 \n",
      "Batch: 432. Acc: 0.458239. Loss: 1.508675. Batch_acc: 0.444058. Batch_loss: 1.552302 \n",
      "Batch: 433. Acc: 0.458263. Loss: 1.508625. Batch_acc: 0.468732. Batch_loss: 1.487184 \n",
      "Batch: 434. Acc: 0.458318. Loss: 1.508615. Batch_acc: 0.482578. Batch_loss: 1.503902 \n",
      "Batch: 435. Acc: 0.458371. Loss: 1.508472. Batch_acc: 0.481246. Batch_loss: 1.446081 \n",
      "Batch: 436. Acc: 0.458344. Loss: 1.508528. Batch_acc: 0.446870. Batch_loss: 1.533092 \n",
      "Batch: 437. Acc: 0.458380. Loss: 1.508461. Batch_acc: 0.474329. Batch_loss: 1.478584 \n",
      "Batch: 438. Acc: 0.458388. Loss: 1.508423. Batch_acc: 0.461583. Batch_loss: 1.491900 \n",
      "Batch: 439. Acc: 0.458410. Loss: 1.508294. Batch_acc: 0.468122. Batch_loss: 1.451463 \n",
      "Batch: 440. Acc: 0.458463. Loss: 1.508176. Batch_acc: 0.481777. Batch_loss: 1.456880 \n",
      "Batch: 441. Acc: 0.458466. Loss: 1.508191. Batch_acc: 0.459824. Batch_loss: 1.514902 \n",
      "Batch: 442. Acc: 0.458506. Loss: 1.508089. Batch_acc: 0.475945. Batch_loss: 1.463459 \n",
      "Batch: 443. Acc: 0.458530. Loss: 1.507987. Batch_acc: 0.469143. Batch_loss: 1.463101 \n",
      "Batch: 444. Acc: 0.458574. Loss: 1.507907. Batch_acc: 0.478336. Batch_loss: 1.472014 \n",
      "Batch: 445. Acc: 0.458548. Loss: 1.507940. Batch_acc: 0.446931. Batch_loss: 1.522527 \n",
      "Batch: 446. Acc: 0.458562. Loss: 1.507937. Batch_acc: 0.464553. Batch_loss: 1.506717 \n",
      "Batch: 447. Acc: 0.458521. Loss: 1.507984. Batch_acc: 0.440303. Batch_loss: 1.529090 \n",
      "Batch: 448. Acc: 0.458530. Loss: 1.507953. Batch_acc: 0.462464. Batch_loss: 1.494304 \n",
      "Batch: 449. Acc: 0.458523. Loss: 1.507946. Batch_acc: 0.455474. Batch_loss: 1.504970 \n",
      "Batch: 450. Acc: 0.458552. Loss: 1.507860. Batch_acc: 0.471420. Batch_loss: 1.469691 \n",
      "Batch: 451. Acc: 0.458568. Loss: 1.507837. Batch_acc: 0.465856. Batch_loss: 1.497254 \n",
      "Batch: 452. Acc: 0.458528. Loss: 1.507914. Batch_acc: 0.440047. Batch_loss: 1.543415 \n",
      "Batch: 453. Acc: 0.458461. Loss: 1.507973. Batch_acc: 0.428242. Batch_loss: 1.534356 \n",
      "Batch: 454. Acc: 0.458531. Loss: 1.507848. Batch_acc: 0.489738. Batch_loss: 1.451915 \n",
      "Batch: 455. Acc: 0.458492. Loss: 1.507883. Batch_acc: 0.440958. Batch_loss: 1.523686 \n",
      "Batch: 456. Acc: 0.458493. Loss: 1.507877. Batch_acc: 0.458817. Batch_loss: 1.505226 \n",
      "Batch: 457. Acc: 0.458462. Loss: 1.507934. Batch_acc: 0.444316. Batch_loss: 1.534140 \n",
      "Batch: 458. Acc: 0.458492. Loss: 1.507829. Batch_acc: 0.472445. Batch_loss: 1.459466 \n",
      "Batch: 459. Acc: 0.458515. Loss: 1.507797. Batch_acc: 0.469021. Batch_loss: 1.493286 \n",
      "Batch: 460. Acc: 0.458586. Loss: 1.507674. Batch_acc: 0.490482. Batch_loss: 1.452457 \n",
      "Batch: 461. Acc: 0.458584. Loss: 1.507653. Batch_acc: 0.457750. Batch_loss: 1.498153 \n",
      "Batch: 462. Acc: 0.458604. Loss: 1.507603. Batch_acc: 0.467510. Batch_loss: 1.484787 \n",
      "Batch: 463. Acc: 0.458600. Loss: 1.507595. Batch_acc: 0.456706. Batch_loss: 1.503988 \n",
      "Batch: 464. Acc: 0.458579. Loss: 1.507620. Batch_acc: 0.449015. Batch_loss: 1.519374 \n",
      "Batch: 465. Acc: 0.458614. Loss: 1.507539. Batch_acc: 0.474702. Batch_loss: 1.470266 \n",
      "Batch: 466. Acc: 0.458590. Loss: 1.507597. Batch_acc: 0.447262. Batch_loss: 1.534524 \n",
      "Batch: 467. Acc: 0.458571. Loss: 1.507602. Batch_acc: 0.450000. Batch_loss: 1.509843 \n",
      "Batch: 468. Acc: 0.458591. Loss: 1.507553. Batch_acc: 0.467826. Batch_loss: 1.484346 \n",
      "Batch: 469. Acc: 0.458601. Loss: 1.507547. Batch_acc: 0.463457. Batch_loss: 1.504739 \n",
      "Batch: 470. Acc: 0.458603. Loss: 1.507561. Batch_acc: 0.459645. Batch_loss: 1.514192 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 471. Acc: 0.458592. Loss: 1.507594. Batch_acc: 0.453295. Batch_loss: 1.523135 \n",
      "Batch: 472. Acc: 0.458589. Loss: 1.507565. Batch_acc: 0.457369. Batch_loss: 1.493949 \n",
      "Batch: 473. Acc: 0.458567. Loss: 1.507650. Batch_acc: 0.448041. Batch_loss: 1.547703 \n",
      "Batch: 474. Acc: 0.458612. Loss: 1.507543. Batch_acc: 0.479864. Batch_loss: 1.457537 \n",
      "Batch: 475. Acc: 0.458576. Loss: 1.507589. Batch_acc: 0.441194. Batch_loss: 1.529868 \n",
      "Batch: 476. Acc: 0.458577. Loss: 1.507562. Batch_acc: 0.458625. Batch_loss: 1.494525 \n",
      "Batch: 477. Acc: 0.458579. Loss: 1.507548. Batch_acc: 0.459582. Batch_loss: 1.500806 \n",
      "Batch: 478. Acc: 0.458565. Loss: 1.507597. Batch_acc: 0.451878. Batch_loss: 1.531394 \n",
      "Batch: 479. Acc: 0.458603. Loss: 1.507462. Batch_acc: 0.477435. Batch_loss: 1.440627 \n",
      "Batch: 480. Acc: 0.458626. Loss: 1.507382. Batch_acc: 0.469468. Batch_loss: 1.469901 \n",
      "Batch: 481. Acc: 0.458642. Loss: 1.507377. Batch_acc: 0.466200. Batch_loss: 1.504931 \n",
      "Batch: 482. Acc: 0.458649. Loss: 1.507342. Batch_acc: 0.462018. Batch_loss: 1.490917 \n",
      "Batch: 483. Acc: 0.458654. Loss: 1.507284. Batch_acc: 0.461054. Batch_loss: 1.479607 \n",
      "Batch: 484. Acc: 0.458702. Loss: 1.507219. Batch_acc: 0.482517. Batch_loss: 1.475256 \n",
      "Batch: 485. Acc: 0.458701. Loss: 1.507197. Batch_acc: 0.458015. Batch_loss: 1.496242 \n",
      "Batch: 486. Acc: 0.458725. Loss: 1.507163. Batch_acc: 0.470486. Batch_loss: 1.490330 \n",
      "Batch: 487. Acc: 0.458702. Loss: 1.507250. Batch_acc: 0.447262. Batch_loss: 1.549933 \n",
      "Batch: 488. Acc: 0.458735. Loss: 1.507183. Batch_acc: 0.475173. Batch_loss: 1.474303 \n",
      "Batch: 489. Acc: 0.458721. Loss: 1.507234. Batch_acc: 0.451977. Batch_loss: 1.531699 \n",
      "Batch: 490. Acc: 0.458725. Loss: 1.507247. Batch_acc: 0.460542. Batch_loss: 1.513803 \n",
      "Batch: 491. Acc: 0.458771. Loss: 1.507148. Batch_acc: 0.481956. Batch_loss: 1.458206 \n",
      "Batch: 492. Acc: 0.458833. Loss: 1.506988. Batch_acc: 0.488851. Batch_loss: 1.428552 \n",
      "Batch: 493. Acc: 0.458825. Loss: 1.507014. Batch_acc: 0.455066. Batch_loss: 1.519885 \n",
      "Batch: 494. Acc: 0.458808. Loss: 1.507083. Batch_acc: 0.450029. Batch_loss: 1.541345 \n",
      "Batch: 495. Acc: 0.458807. Loss: 1.507090. Batch_acc: 0.458357. Batch_loss: 1.510523 \n",
      "Batch: 496. Acc: 0.458787. Loss: 1.507123. Batch_acc: 0.448851. Batch_loss: 1.523533 \n",
      "Batch: 497. Acc: 0.458783. Loss: 1.507133. Batch_acc: 0.456995. Batch_loss: 1.512200 \n",
      "Batch: 498. Acc: 0.458769. Loss: 1.507172. Batch_acc: 0.452032. Batch_loss: 1.526111 \n",
      "Batch: 499. Acc: 0.458776. Loss: 1.507133. Batch_acc: 0.462309. Batch_loss: 1.487392 \n",
      "Batch: 500. Acc: 0.458797. Loss: 1.507138. Batch_acc: 0.469244. Batch_loss: 1.509711 \n",
      "Batch: 501. Acc: 0.458782. Loss: 1.507147. Batch_acc: 0.451740. Batch_loss: 1.511628 \n",
      "Batch: 502. Acc: 0.458790. Loss: 1.507210. Batch_acc: 0.462625. Batch_loss: 1.539419 \n",
      "Checkpointing on batch: 502. Accuracy: 0.4587897947839295. Loss per char: 1.5072099353768145. Time: 1627214516.0232437\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 84, 85, 66,\n",
      "        79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 14, 21, 21, 24, 20, 18,\n",
      "        23, 21,  1, 66, 79, 69,  1, 14, 22, 24, 20, 23, 17, 15, 21, 32,  3,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.458803. Loss: 1.507156. Batch_acc: 0.465330. Batch_loss: 1.479883 \n",
      "Batch: 504. Acc: 0.458755. Loss: 1.507307. Batch_acc: 0.434507. Batch_loss: 1.583961 \n",
      "Batch: 505. Acc: 0.458753. Loss: 1.507301. Batch_acc: 0.458072. Batch_loss: 1.504423 \n",
      "Batch: 506. Acc: 0.458755. Loss: 1.507274. Batch_acc: 0.459570. Batch_loss: 1.493135 \n",
      "Batch: 507. Acc: 0.458726. Loss: 1.507341. Batch_acc: 0.444191. Batch_loss: 1.541082 \n",
      "Batch: 508. Acc: 0.458714. Loss: 1.507379. Batch_acc: 0.452589. Batch_loss: 1.526747 \n",
      "Batch: 509. Acc: 0.458717. Loss: 1.507381. Batch_acc: 0.460012. Batch_loss: 1.508595 \n",
      "Batch: 510. Acc: 0.458680. Loss: 1.507383. Batch_acc: 0.439650. Batch_loss: 1.508245 \n",
      "Batch: 511. Acc: 0.458659. Loss: 1.507398. Batch_acc: 0.447664. Batch_loss: 1.515365 \n",
      "Batch: 512. Acc: 0.458687. Loss: 1.507340. Batch_acc: 0.473467. Batch_loss: 1.477214 \n",
      "Batch: 513. Acc: 0.458682. Loss: 1.507330. Batch_acc: 0.456060. Batch_loss: 1.501922 \n",
      "Batch: 514. Acc: 0.458692. Loss: 1.507264. Batch_acc: 0.463845. Batch_loss: 1.472406 \n",
      "Batch: 515. Acc: 0.458720. Loss: 1.507171. Batch_acc: 0.473623. Batch_loss: 1.458534 \n",
      "Batch: 516. Acc: 0.458680. Loss: 1.507226. Batch_acc: 0.437537. Batch_loss: 1.536636 \n",
      "Batch: 517. Acc: 0.458704. Loss: 1.507216. Batch_acc: 0.470490. Batch_loss: 1.502262 \n",
      "Batch: 518. Acc: 0.458697. Loss: 1.507241. Batch_acc: 0.455312. Batch_loss: 1.519605 \n",
      "Batch: 519. Acc: 0.458715. Loss: 1.507191. Batch_acc: 0.467938. Batch_loss: 1.481367 \n",
      "Batch: 520. Acc: 0.458758. Loss: 1.507109. Batch_acc: 0.480998. Batch_loss: 1.465139 \n",
      "Batch: 521. Acc: 0.458714. Loss: 1.507150. Batch_acc: 0.436000. Batch_loss: 1.528358 \n",
      "Batch: 522. Acc: 0.458779. Loss: 1.507027. Batch_acc: 0.492991. Batch_loss: 1.441723 \n",
      "Batch: 523. Acc: 0.458753. Loss: 1.507068. Batch_acc: 0.445634. Batch_loss: 1.528225 \n",
      "Batch: 524. Acc: 0.458736. Loss: 1.507062. Batch_acc: 0.449687. Batch_loss: 1.503831 \n",
      "Batch: 525. Acc: 0.458778. Loss: 1.506969. Batch_acc: 0.480912. Batch_loss: 1.458301 \n",
      "Batch: 526. Acc: 0.458752. Loss: 1.506994. Batch_acc: 0.444766. Batch_loss: 1.520479 \n",
      "Batch: 527. Acc: 0.458715. Loss: 1.507048. Batch_acc: 0.439306. Batch_loss: 1.535860 \n",
      "Batch: 528. Acc: 0.458733. Loss: 1.507003. Batch_acc: 0.468599. Batch_loss: 1.481938 \n",
      "Batch: 529. Acc: 0.458754. Loss: 1.506947. Batch_acc: 0.469767. Batch_loss: 1.477101 \n",
      "Batch: 530. Acc: 0.458733. Loss: 1.507022. Batch_acc: 0.448000. Batch_loss: 1.546530 \n",
      "Batch: 531. Acc: 0.458785. Loss: 1.506911. Batch_acc: 0.485731. Batch_loss: 1.448046 \n",
      "Batch: 532. Acc: 0.458761. Loss: 1.506885. Batch_acc: 0.446267. Batch_loss: 1.493309 \n",
      "Batch: 533. Acc: 0.458737. Loss: 1.506894. Batch_acc: 0.445853. Batch_loss: 1.511602 \n",
      "Batch: 534. Acc: 0.458739. Loss: 1.506930. Batch_acc: 0.460208. Batch_loss: 1.526468 \n",
      "Batch: 535. Acc: 0.458733. Loss: 1.506951. Batch_acc: 0.455434. Batch_loss: 1.518193 \n",
      "Batch: 536. Acc: 0.458738. Loss: 1.506929. Batch_acc: 0.461315. Batch_loss: 1.494845 \n",
      "Batch: 537. Acc: 0.458800. Loss: 1.506760. Batch_acc: 0.492183. Batch_loss: 1.415822 \n",
      "Batch: 538. Acc: 0.458823. Loss: 1.506655. Batch_acc: 0.471654. Batch_loss: 1.449086 \n",
      "Batch: 539. Acc: 0.458855. Loss: 1.506622. Batch_acc: 0.475548. Batch_loss: 1.489250 \n",
      "Batch: 540. Acc: 0.458867. Loss: 1.506544. Batch_acc: 0.465547. Batch_loss: 1.464228 \n",
      "Batch: 541. Acc: 0.458855. Loss: 1.506529. Batch_acc: 0.452340. Batch_loss: 1.498020 \n",
      "Batch: 542. Acc: 0.458871. Loss: 1.506468. Batch_acc: 0.467525. Batch_loss: 1.473096 \n",
      "Batch: 543. Acc: 0.458869. Loss: 1.506434. Batch_acc: 0.458094. Batch_loss: 1.487999 \n",
      "Batch: 544. Acc: 0.458903. Loss: 1.506385. Batch_acc: 0.476705. Batch_loss: 1.479988 \n",
      "Batch: 545. Acc: 0.458912. Loss: 1.506328. Batch_acc: 0.464079. Batch_loss: 1.475118 \n",
      "Batch: 546. Acc: 0.458930. Loss: 1.506256. Batch_acc: 0.468662. Batch_loss: 1.467692 \n",
      "Batch: 547. Acc: 0.458975. Loss: 1.506118. Batch_acc: 0.482720. Batch_loss: 1.432910 \n",
      "Batch: 548. Acc: 0.458955. Loss: 1.506117. Batch_acc: 0.448256. Batch_loss: 1.505745 \n",
      "Batch: 549. Acc: 0.458978. Loss: 1.506029. Batch_acc: 0.471765. Batch_loss: 1.456434 \n",
      "Batch: 550. Acc: 0.459002. Loss: 1.505971. Batch_acc: 0.472110. Batch_loss: 1.473992 \n",
      "Batch: 551. Acc: 0.459039. Loss: 1.505869. Batch_acc: 0.479627. Batch_loss: 1.448974 \n",
      "Batch: 552. Acc: 0.459082. Loss: 1.505827. Batch_acc: 0.482877. Batch_loss: 1.483166 \n",
      "Batch: 553. Acc: 0.459101. Loss: 1.505762. Batch_acc: 0.469399. Batch_loss: 1.470746 \n",
      "Batch: 554. Acc: 0.459096. Loss: 1.505727. Batch_acc: 0.456211. Batch_loss: 1.486119 \n",
      "Batch: 555. Acc: 0.459107. Loss: 1.505714. Batch_acc: 0.465116. Batch_loss: 1.498708 \n",
      "Batch: 556. Acc: 0.459086. Loss: 1.505775. Batch_acc: 0.447368. Batch_loss: 1.539283 \n",
      "Batch: 557. Acc: 0.459111. Loss: 1.505734. Batch_acc: 0.473383. Batch_loss: 1.483110 \n",
      "Batch: 558. Acc: 0.459106. Loss: 1.505751. Batch_acc: 0.456261. Batch_loss: 1.515451 \n",
      "Batch: 559. Acc: 0.459098. Loss: 1.505779. Batch_acc: 0.454120. Batch_loss: 1.521381 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 560. Acc: 0.459151. Loss: 1.505643. Batch_acc: 0.487617. Batch_loss: 1.432631 \n",
      "Batch: 561. Acc: 0.459163. Loss: 1.505604. Batch_acc: 0.466092. Batch_loss: 1.483934 \n",
      "Batch: 562. Acc: 0.459184. Loss: 1.505558. Batch_acc: 0.470788. Batch_loss: 1.479798 \n",
      "Batch: 563. Acc: 0.459172. Loss: 1.505591. Batch_acc: 0.452448. Batch_loss: 1.524257 \n",
      "Batch: 564. Acc: 0.459193. Loss: 1.505520. Batch_acc: 0.471154. Batch_loss: 1.466074 \n",
      "Batch: 565. Acc: 0.459227. Loss: 1.505425. Batch_acc: 0.479031. Batch_loss: 1.450276 \n",
      "Batch: 566. Acc: 0.459197. Loss: 1.505419. Batch_acc: 0.442220. Batch_loss: 1.501940 \n",
      "Batch: 567. Acc: 0.459251. Loss: 1.505283. Batch_acc: 0.489679. Batch_loss: 1.428570 \n",
      "Batch: 568. Acc: 0.459264. Loss: 1.505184. Batch_acc: 0.466590. Batch_loss: 1.448751 \n",
      "Batch: 569. Acc: 0.459290. Loss: 1.505126. Batch_acc: 0.474209. Batch_loss: 1.471267 \n",
      "Batch: 570. Acc: 0.459270. Loss: 1.505170. Batch_acc: 0.447674. Batch_loss: 1.530958 \n",
      "Batch: 571. Acc: 0.459270. Loss: 1.505179. Batch_acc: 0.459207. Batch_loss: 1.510391 \n",
      "Batch: 572. Acc: 0.459299. Loss: 1.505117. Batch_acc: 0.476025. Batch_loss: 1.469544 \n",
      "Batch: 573. Acc: 0.459292. Loss: 1.505195. Batch_acc: 0.455336. Batch_loss: 1.549972 \n",
      "Batch: 574. Acc: 0.459304. Loss: 1.505179. Batch_acc: 0.466511. Batch_loss: 1.495674 \n",
      "Batch: 575. Acc: 0.459306. Loss: 1.505161. Batch_acc: 0.460263. Batch_loss: 1.495098 \n",
      "Batch: 576. Acc: 0.459343. Loss: 1.505036. Batch_acc: 0.480267. Batch_loss: 1.435486 \n",
      "Batch: 577. Acc: 0.459377. Loss: 1.504911. Batch_acc: 0.478090. Batch_loss: 1.434253 \n",
      "Batch: 578. Acc: 0.459352. Loss: 1.504927. Batch_acc: 0.444828. Batch_loss: 1.514497 \n",
      "Batch: 579. Acc: 0.459341. Loss: 1.504969. Batch_acc: 0.453441. Batch_loss: 1.529199 \n",
      "Batch: 580. Acc: 0.459392. Loss: 1.504818. Batch_acc: 0.487915. Batch_loss: 1.419300 \n",
      "Batch: 581. Acc: 0.459410. Loss: 1.504776. Batch_acc: 0.469783. Batch_loss: 1.480872 \n",
      "Batch: 582. Acc: 0.459421. Loss: 1.504747. Batch_acc: 0.465842. Batch_loss: 1.487329 \n",
      "Batch: 583. Acc: 0.459436. Loss: 1.504712. Batch_acc: 0.468406. Batch_loss: 1.484124 \n",
      "Batch: 584. Acc: 0.459487. Loss: 1.504578. Batch_acc: 0.489337. Batch_loss: 1.426211 \n",
      "Batch: 585. Acc: 0.459498. Loss: 1.504601. Batch_acc: 0.466174. Batch_loss: 1.517600 \n",
      "Batch: 586. Acc: 0.459474. Loss: 1.504672. Batch_acc: 0.445198. Batch_loss: 1.545827 \n",
      "Batch: 587. Acc: 0.459483. Loss: 1.504593. Batch_acc: 0.465130. Batch_loss: 1.457962 \n",
      "Batch: 588. Acc: 0.459542. Loss: 1.504434. Batch_acc: 0.492770. Batch_loss: 1.414309 \n",
      "Batch: 589. Acc: 0.459593. Loss: 1.504360. Batch_acc: 0.489051. Batch_loss: 1.461793 \n",
      "Batch: 590. Acc: 0.459620. Loss: 1.504310. Batch_acc: 0.475533. Batch_loss: 1.474703 \n",
      "Batch: 591. Acc: 0.459607. Loss: 1.504331. Batch_acc: 0.451786. Batch_loss: 1.517207 \n",
      "Batch: 592. Acc: 0.459587. Loss: 1.504364. Batch_acc: 0.448018. Batch_loss: 1.523608 \n",
      "Batch: 593. Acc: 0.459590. Loss: 1.504384. Batch_acc: 0.461404. Batch_loss: 1.516310 \n",
      "Batch: 594. Acc: 0.459621. Loss: 1.504323. Batch_acc: 0.477790. Batch_loss: 1.468926 \n",
      "Batch: 595. Acc: 0.459648. Loss: 1.504195. Batch_acc: 0.475169. Batch_loss: 1.429084 \n",
      "Batch: 596. Acc: 0.459675. Loss: 1.504164. Batch_acc: 0.475942. Batch_loss: 1.485925 \n",
      "Batch: 597. Acc: 0.459680. Loss: 1.504138. Batch_acc: 0.463040. Batch_loss: 1.488128 \n",
      "Batch: 598. Acc: 0.459677. Loss: 1.504071. Batch_acc: 0.457686. Batch_loss: 1.464103 \n",
      "Batch: 599. Acc: 0.459655. Loss: 1.504119. Batch_acc: 0.446334. Batch_loss: 1.533358 \n",
      "Batch: 600. Acc: 0.459667. Loss: 1.504134. Batch_acc: 0.466667. Batch_loss: 1.513242 \n",
      "Batch: 601. Acc: 0.459659. Loss: 1.504106. Batch_acc: 0.454960. Batch_loss: 1.487218 \n",
      "Batch: 602. Acc: 0.459604. Loss: 1.504178. Batch_acc: 0.426864. Batch_loss: 1.547190 \n",
      "Batch: 603. Acc: 0.459645. Loss: 1.504132. Batch_acc: 0.485026. Batch_loss: 1.475482 \n",
      "Batch: 604. Acc: 0.459582. Loss: 1.504249. Batch_acc: 0.420213. Batch_loss: 1.577321 \n",
      "Batch: 605. Acc: 0.459570. Loss: 1.504278. Batch_acc: 0.452199. Batch_loss: 1.521766 \n",
      "Batch: 606. Acc: 0.459577. Loss: 1.504271. Batch_acc: 0.464018. Batch_loss: 1.500126 \n",
      "Batch: 607. Acc: 0.459602. Loss: 1.504228. Batch_acc: 0.474395. Batch_loss: 1.478725 \n",
      "Batch: 608. Acc: 0.459587. Loss: 1.504262. Batch_acc: 0.449852. Batch_loss: 1.525514 \n",
      "Batch: 609. Acc: 0.459657. Loss: 1.504125. Batch_acc: 0.502296. Batch_loss: 1.421089 \n",
      "Batch: 610. Acc: 0.459675. Loss: 1.504101. Batch_acc: 0.470522. Batch_loss: 1.489654 \n",
      "Batch: 611. Acc: 0.459702. Loss: 1.504036. Batch_acc: 0.476163. Batch_loss: 1.464508 \n",
      "Batch: 612. Acc: 0.459697. Loss: 1.504069. Batch_acc: 0.456496. Batch_loss: 1.524878 \n",
      "Batch: 613. Acc: 0.459672. Loss: 1.504143. Batch_acc: 0.444444. Batch_loss: 1.550083 \n",
      "Batch: 614. Acc: 0.459695. Loss: 1.504101. Batch_acc: 0.473866. Batch_loss: 1.477926 \n",
      "Batch: 615. Acc: 0.459669. Loss: 1.504121. Batch_acc: 0.443609. Batch_loss: 1.516786 \n",
      "Batch: 616. Acc: 0.459682. Loss: 1.504116. Batch_acc: 0.467503. Batch_loss: 1.501112 \n",
      "Batch: 617. Acc: 0.459689. Loss: 1.504104. Batch_acc: 0.464000. Batch_loss: 1.496672 \n",
      "Batch: 618. Acc: 0.459709. Loss: 1.504042. Batch_acc: 0.471923. Batch_loss: 1.466220 \n",
      "Batch: 619. Acc: 0.459721. Loss: 1.504025. Batch_acc: 0.467295. Batch_loss: 1.492996 \n",
      "Batch: 620. Acc: 0.459679. Loss: 1.504131. Batch_acc: 0.433411. Batch_loss: 1.570890 \n",
      "Batch: 621. Acc: 0.459689. Loss: 1.504094. Batch_acc: 0.465929. Batch_loss: 1.480906 \n",
      "Batch: 622. Acc: 0.459693. Loss: 1.504101. Batch_acc: 0.462220. Batch_loss: 1.508897 \n",
      "Batch: 623. Acc: 0.459723. Loss: 1.504025. Batch_acc: 0.477941. Batch_loss: 1.457416 \n",
      "Batch: 624. Acc: 0.459704. Loss: 1.504081. Batch_acc: 0.447447. Batch_loss: 1.540444 \n",
      "Batch: 625. Acc: 0.459697. Loss: 1.504155. Batch_acc: 0.455124. Batch_loss: 1.550959 \n",
      "Batch: 626. Acc: 0.459689. Loss: 1.504161. Batch_acc: 0.454545. Batch_loss: 1.508048 \n",
      "Batch: 627. Acc: 0.459692. Loss: 1.504141. Batch_acc: 0.461538. Batch_loss: 1.491503 \n",
      "Batch: 628. Acc: 0.459723. Loss: 1.504002. Batch_acc: 0.479813. Batch_loss: 1.414946 \n",
      "Batch: 629. Acc: 0.459712. Loss: 1.504030. Batch_acc: 0.452478. Batch_loss: 1.521942 \n",
      "Batch: 630. Acc: 0.459688. Loss: 1.504048. Batch_acc: 0.444575. Batch_loss: 1.515996 \n",
      "Batch: 631. Acc: 0.459726. Loss: 1.503945. Batch_acc: 0.484136. Batch_loss: 1.437534 \n",
      "Batch: 632. Acc: 0.459717. Loss: 1.503972. Batch_acc: 0.454181. Batch_loss: 1.520535 \n",
      "Batch: 633. Acc: 0.459735. Loss: 1.503950. Batch_acc: 0.470723. Batch_loss: 1.490248 \n",
      "Batch: 634. Acc: 0.459721. Loss: 1.503943. Batch_acc: 0.450980. Batch_loss: 1.499726 \n",
      "Batch: 635. Acc: 0.459746. Loss: 1.503892. Batch_acc: 0.475429. Batch_loss: 1.471431 \n",
      "Batch: 636. Acc: 0.459745. Loss: 1.503889. Batch_acc: 0.459190. Batch_loss: 1.502219 \n",
      "Batch: 637. Acc: 0.459750. Loss: 1.503866. Batch_acc: 0.463429. Batch_loss: 1.489009 \n",
      "Batch: 638. Acc: 0.459736. Loss: 1.503861. Batch_acc: 0.450408. Batch_loss: 1.500552 \n",
      "Batch: 639. Acc: 0.459750. Loss: 1.503816. Batch_acc: 0.468520. Batch_loss: 1.475383 \n",
      "Batch: 640. Acc: 0.459752. Loss: 1.503777. Batch_acc: 0.461272. Batch_loss: 1.478677 \n",
      "Batch: 641. Acc: 0.459773. Loss: 1.503751. Batch_acc: 0.473282. Batch_loss: 1.486610 \n",
      "Batch: 642. Acc: 0.459772. Loss: 1.503776. Batch_acc: 0.458884. Batch_loss: 1.520167 \n",
      "Batch: 643. Acc: 0.459795. Loss: 1.503728. Batch_acc: 0.474204. Batch_loss: 1.474422 \n",
      "Batch: 644. Acc: 0.459803. Loss: 1.503695. Batch_acc: 0.464868. Batch_loss: 1.482784 \n",
      "Batch: 645. Acc: 0.459805. Loss: 1.503720. Batch_acc: 0.460757. Batch_loss: 1.519773 \n",
      "Batch: 646. Acc: 0.459834. Loss: 1.503615. Batch_acc: 0.479021. Batch_loss: 1.434903 \n",
      "Batch: 647. Acc: 0.459837. Loss: 1.503643. Batch_acc: 0.461671. Batch_loss: 1.521501 \n",
      "Batch: 648. Acc: 0.459833. Loss: 1.503699. Batch_acc: 0.457410. Batch_loss: 1.540752 \n",
      "Batch: 649. Acc: 0.459828. Loss: 1.503703. Batch_acc: 0.456797. Batch_loss: 1.506041 \n",
      "Batch: 650. Acc: 0.459849. Loss: 1.503645. Batch_acc: 0.473438. Batch_loss: 1.465657 \n",
      "Batch: 651. Acc: 0.459870. Loss: 1.503604. Batch_acc: 0.473441. Batch_loss: 1.476350 \n",
      "Batch: 652. Acc: 0.459874. Loss: 1.503588. Batch_acc: 0.462558. Batch_loss: 1.493344 \n",
      "Batch: 653. Acc: 0.459852. Loss: 1.503634. Batch_acc: 0.445221. Batch_loss: 1.534358 \n",
      "Batch: 654. Acc: 0.459858. Loss: 1.503609. Batch_acc: 0.464120. Batch_loss: 1.487200 \n",
      "Batch: 655. Acc: 0.459794. Loss: 1.503729. Batch_acc: 0.417481. Batch_loss: 1.582081 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 656. Acc: 0.459800. Loss: 1.503686. Batch_acc: 0.463964. Batch_loss: 1.476156 \n",
      "Batch: 657. Acc: 0.459859. Loss: 1.503579. Batch_acc: 0.497479. Batch_loss: 1.435098 \n",
      "Batch: 658. Acc: 0.459847. Loss: 1.503622. Batch_acc: 0.452285. Batch_loss: 1.532157 \n",
      "Batch: 659. Acc: 0.459871. Loss: 1.503562. Batch_acc: 0.474901. Batch_loss: 1.464430 \n",
      "Batch: 660. Acc: 0.459851. Loss: 1.503600. Batch_acc: 0.446619. Batch_loss: 1.529685 \n",
      "Batch: 661. Acc: 0.459857. Loss: 1.503538. Batch_acc: 0.463744. Batch_loss: 1.463216 \n",
      "Batch: 662. Acc: 0.459876. Loss: 1.503508. Batch_acc: 0.472174. Batch_loss: 1.483904 \n",
      "Batch: 663. Acc: 0.459864. Loss: 1.503503. Batch_acc: 0.451687. Batch_loss: 1.500272 \n",
      "Batch: 664. Acc: 0.459868. Loss: 1.503470. Batch_acc: 0.462766. Batch_loss: 1.480746 \n",
      "Batch: 665. Acc: 0.459878. Loss: 1.503475. Batch_acc: 0.466324. Batch_loss: 1.506741 \n",
      "Batch: 666. Acc: 0.459870. Loss: 1.503498. Batch_acc: 0.454913. Batch_loss: 1.518821 \n",
      "Batch: 667. Acc: 0.459872. Loss: 1.503463. Batch_acc: 0.461143. Batch_loss: 1.480584 \n",
      "Batch: 668. Acc: 0.459860. Loss: 1.503476. Batch_acc: 0.452055. Batch_loss: 1.511923 \n",
      "Batch: 669. Acc: 0.459881. Loss: 1.503417. Batch_acc: 0.474148. Batch_loss: 1.463335 \n",
      "Batch: 670. Acc: 0.459905. Loss: 1.503405. Batch_acc: 0.475533. Batch_loss: 1.495215 \n",
      "Batch: 671. Acc: 0.459920. Loss: 1.503320. Batch_acc: 0.470128. Batch_loss: 1.447937 \n",
      "Batch: 672. Acc: 0.459870. Loss: 1.503405. Batch_acc: 0.426012. Batch_loss: 1.560609 \n",
      "Batch: 673. Acc: 0.459878. Loss: 1.503369. Batch_acc: 0.465197. Batch_loss: 1.479135 \n",
      "Batch: 674. Acc: 0.459880. Loss: 1.503353. Batch_acc: 0.461190. Batch_loss: 1.493173 \n",
      "Batch: 675. Acc: 0.459886. Loss: 1.503353. Batch_acc: 0.464327. Batch_loss: 1.503304 \n",
      "Batch: 676. Acc: 0.459895. Loss: 1.503339. Batch_acc: 0.465817. Batch_loss: 1.493559 \n",
      "Batch: 677. Acc: 0.459899. Loss: 1.503359. Batch_acc: 0.462237. Batch_loss: 1.516570 \n",
      "Batch: 678. Acc: 0.459905. Loss: 1.503341. Batch_acc: 0.464387. Batch_loss: 1.491704 \n",
      "Batch: 679. Acc: 0.459904. Loss: 1.503375. Batch_acc: 0.459178. Batch_loss: 1.526268 \n",
      "Batch: 680. Acc: 0.459875. Loss: 1.503392. Batch_acc: 0.439483. Batch_loss: 1.515569 \n",
      "Batch: 681. Acc: 0.459907. Loss: 1.503328. Batch_acc: 0.481609. Batch_loss: 1.459793 \n",
      "Batch: 682. Acc: 0.459914. Loss: 1.503344. Batch_acc: 0.464957. Batch_loss: 1.514135 \n",
      "Batch: 683. Acc: 0.459921. Loss: 1.503329. Batch_acc: 0.464306. Batch_loss: 1.492498 \n",
      "Batch: 684. Acc: 0.459932. Loss: 1.503277. Batch_acc: 0.468097. Batch_loss: 1.467621 \n",
      "Batch: 685. Acc: 0.459922. Loss: 1.503326. Batch_acc: 0.452797. Batch_loss: 1.537146 \n",
      "Batch: 686. Acc: 0.459915. Loss: 1.503338. Batch_acc: 0.454703. Batch_loss: 1.511701 \n",
      "Batch: 687. Acc: 0.459934. Loss: 1.503304. Batch_acc: 0.473260. Batch_loss: 1.480142 \n",
      "Batch: 688. Acc: 0.459955. Loss: 1.503243. Batch_acc: 0.474352. Batch_loss: 1.460778 \n",
      "Batch: 689. Acc: 0.459964. Loss: 1.503251. Batch_acc: 0.465870. Batch_loss: 1.508923 \n",
      "Batch: 690. Acc: 0.459945. Loss: 1.503297. Batch_acc: 0.447066. Batch_loss: 1.535410 \n",
      "Batch: 691. Acc: 0.459924. Loss: 1.503360. Batch_acc: 0.445281. Batch_loss: 1.546646 \n",
      "Batch: 692. Acc: 0.459934. Loss: 1.503321. Batch_acc: 0.466591. Batch_loss: 1.476795 \n",
      "Batch: 693. Acc: 0.459948. Loss: 1.503305. Batch_acc: 0.469907. Batch_loss: 1.492200 \n",
      "Batch: 694. Acc: 0.459968. Loss: 1.503222. Batch_acc: 0.473568. Batch_loss: 1.448285 \n",
      "Batch: 695. Acc: 0.459943. Loss: 1.503281. Batch_acc: 0.442220. Batch_loss: 1.543860 \n",
      "Batch: 696. Acc: 0.459941. Loss: 1.503293. Batch_acc: 0.458904. Batch_loss: 1.511420 \n",
      "Batch: 697. Acc: 0.459956. Loss: 1.503245. Batch_acc: 0.469989. Batch_loss: 1.470237 \n",
      "Batch: 698. Acc: 0.459950. Loss: 1.503296. Batch_acc: 0.455770. Batch_loss: 1.539403 \n",
      "Batch: 699. Acc: 0.459969. Loss: 1.503287. Batch_acc: 0.473314. Batch_loss: 1.496849 \n",
      "Batch: 700. Acc: 0.459971. Loss: 1.503260. Batch_acc: 0.461449. Batch_loss: 1.484270 \n",
      "Batch: 701. Acc: 0.459994. Loss: 1.503210. Batch_acc: 0.476328. Batch_loss: 1.468527 \n",
      "Batch: 702. Acc: 0.459999. Loss: 1.503182. Batch_acc: 0.463710. Batch_loss: 1.483073 \n",
      "Batch: 703. Acc: 0.459982. Loss: 1.503225. Batch_acc: 0.448000. Batch_loss: 1.533453 \n",
      "Batch: 704. Acc: 0.460000. Loss: 1.503199. Batch_acc: 0.472769. Batch_loss: 1.484964 \n",
      "Batch: 705. Acc: 0.460000. Loss: 1.503225. Batch_acc: 0.459896. Batch_loss: 1.521161 \n",
      "Batch: 706. Acc: 0.460016. Loss: 1.503165. Batch_acc: 0.471588. Batch_loss: 1.460534 \n",
      "Batch: 707. Acc: 0.460043. Loss: 1.503076. Batch_acc: 0.478383. Batch_loss: 1.441717 \n",
      "Batch: 708. Acc: 0.460031. Loss: 1.503091. Batch_acc: 0.451501. Batch_loss: 1.513666 \n",
      "Batch: 709. Acc: 0.460049. Loss: 1.503068. Batch_acc: 0.472645. Batch_loss: 1.486575 \n",
      "Batch: 710. Acc: 0.460032. Loss: 1.503090. Batch_acc: 0.448296. Batch_loss: 1.519200 \n",
      "Batch: 711. Acc: 0.460040. Loss: 1.503082. Batch_acc: 0.465792. Batch_loss: 1.497459 \n",
      "Batch: 712. Acc: 0.460022. Loss: 1.503150. Batch_acc: 0.447031. Batch_loss: 1.552106 \n",
      "Batch: 713. Acc: 0.460050. Loss: 1.503098. Batch_acc: 0.479818. Batch_loss: 1.466507 \n",
      "Batch: 714. Acc: 0.460052. Loss: 1.503093. Batch_acc: 0.460879. Batch_loss: 1.499262 \n",
      "Batch: 715. Acc: 0.460062. Loss: 1.503056. Batch_acc: 0.467124. Batch_loss: 1.477222 \n",
      "Batch: 716. Acc: 0.460055. Loss: 1.503035. Batch_acc: 0.455132. Batch_loss: 1.487754 \n",
      "Batch: 717. Acc: 0.460027. Loss: 1.503066. Batch_acc: 0.439502. Batch_loss: 1.525361 \n",
      "Batch: 718. Acc: 0.460042. Loss: 1.503004. Batch_acc: 0.471070. Batch_loss: 1.457961 \n",
      "Batch: 719. Acc: 0.460022. Loss: 1.503081. Batch_acc: 0.445602. Batch_loss: 1.559097 \n",
      "Batch: 720. Acc: 0.460038. Loss: 1.503033. Batch_acc: 0.471316. Batch_loss: 1.469346 \n",
      "Batch: 721. Acc: 0.460025. Loss: 1.503072. Batch_acc: 0.450696. Batch_loss: 1.531192 \n",
      "Batch: 722. Acc: 0.460045. Loss: 1.503075. Batch_acc: 0.474657. Batch_loss: 1.505551 \n",
      "Batch: 723. Acc: 0.460024. Loss: 1.503089. Batch_acc: 0.445087. Batch_loss: 1.513015 \n",
      "Batch: 724. Acc: 0.460038. Loss: 1.503035. Batch_acc: 0.470175. Batch_loss: 1.462996 \n",
      "Batch: 725. Acc: 0.460049. Loss: 1.502999. Batch_acc: 0.467863. Batch_loss: 1.476942 \n",
      "Batch: 726. Acc: 0.460036. Loss: 1.503026. Batch_acc: 0.450119. Batch_loss: 1.522949 \n",
      "Batch: 727. Acc: 0.460053. Loss: 1.502944. Batch_acc: 0.472676. Batch_loss: 1.444560 \n",
      "Batch: 728. Acc: 0.460064. Loss: 1.502903. Batch_acc: 0.467863. Batch_loss: 1.473447 \n",
      "Batch: 729. Acc: 0.460055. Loss: 1.502894. Batch_acc: 0.453468. Batch_loss: 1.495524 \n",
      "Batch: 730. Acc: 0.460043. Loss: 1.502863. Batch_acc: 0.450913. Batch_loss: 1.480939 \n",
      "Batch: 731. Acc: 0.460060. Loss: 1.502815. Batch_acc: 0.472926. Batch_loss: 1.467411 \n",
      "Batch: 732. Acc: 0.460052. Loss: 1.502894. Batch_acc: 0.454337. Batch_loss: 1.560430 \n",
      "Batch: 733. Acc: 0.460051. Loss: 1.502881. Batch_acc: 0.458864. Batch_loss: 1.493217 \n",
      "Batch: 734. Acc: 0.460068. Loss: 1.502827. Batch_acc: 0.472441. Batch_loss: 1.464798 \n",
      "Batch: 735. Acc: 0.460088. Loss: 1.502753. Batch_acc: 0.475323. Batch_loss: 1.447066 \n",
      "Batch: 736. Acc: 0.460067. Loss: 1.502789. Batch_acc: 0.444573. Batch_loss: 1.529032 \n",
      "Batch: 737. Acc: 0.460056. Loss: 1.502781. Batch_acc: 0.451409. Batch_loss: 1.497334 \n",
      "Batch: 738. Acc: 0.460087. Loss: 1.502722. Batch_acc: 0.482301. Batch_loss: 1.460425 \n",
      "Batch: 739. Acc: 0.460077. Loss: 1.502713. Batch_acc: 0.452797. Batch_loss: 1.496523 \n",
      "Batch: 740. Acc: 0.460080. Loss: 1.502719. Batch_acc: 0.462384. Batch_loss: 1.506926 \n",
      "Batch: 741. Acc: 0.460107. Loss: 1.502688. Batch_acc: 0.479722. Batch_loss: 1.479510 \n",
      "Batch: 742. Acc: 0.460130. Loss: 1.502648. Batch_acc: 0.477954. Batch_loss: 1.472593 \n",
      "Batch: 743. Acc: 0.460127. Loss: 1.502650. Batch_acc: 0.457845. Batch_loss: 1.503657 \n",
      "Batch: 744. Acc: 0.460114. Loss: 1.502651. Batch_acc: 0.450543. Batch_loss: 1.503924 \n",
      "Batch: 745. Acc: 0.460148. Loss: 1.502583. Batch_acc: 0.485320. Batch_loss: 1.451664 \n",
      "Batch: 746. Acc: 0.460120. Loss: 1.502639. Batch_acc: 0.438794. Batch_loss: 1.545482 \n",
      "Batch: 747. Acc: 0.460158. Loss: 1.502538. Batch_acc: 0.488590. Batch_loss: 1.425848 \n",
      "Batch: 748. Acc: 0.460158. Loss: 1.502527. Batch_acc: 0.460234. Batch_loss: 1.494302 \n",
      "Batch: 749. Acc: 0.460201. Loss: 1.502409. Batch_acc: 0.491648. Batch_loss: 1.417018 \n",
      "Batch: 750. Acc: 0.460190. Loss: 1.502479. Batch_acc: 0.451797. Batch_loss: 1.554058 \n",
      "Batch: 751. Acc: 0.460197. Loss: 1.502437. Batch_acc: 0.465800. Batch_loss: 1.471985 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 752. Acc: 0.460186. Loss: 1.502457. Batch_acc: 0.451895. Batch_loss: 1.517338 \n",
      "Batch: 753. Acc: 0.460180. Loss: 1.502501. Batch_acc: 0.455289. Batch_loss: 1.536150 \n",
      "Checkpointing on batch: 753. Accuracy: 0.46018005117275995. Loss per char: 1.5025009253949282. Time: 1627214712.5164356\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 18, 24, 21, 25, 23,  1,\n",
      "        14,  1, 14, 19, 18, 25, 22, 17, 19, 26, 18, 21, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.460181. Loss: 1.502483. Batch_acc: 0.460819. Batch_loss: 1.488443 \n",
      "Batch: 755. Acc: 0.460170. Loss: 1.502477. Batch_acc: 0.451907. Batch_loss: 1.498273 \n",
      "Batch: 756. Acc: 0.460178. Loss: 1.502436. Batch_acc: 0.466251. Batch_loss: 1.472165 \n",
      "Batch: 757. Acc: 0.460208. Loss: 1.502356. Batch_acc: 0.482333. Batch_loss: 1.443231 \n",
      "Batch: 758. Acc: 0.460219. Loss: 1.502313. Batch_acc: 0.468433. Batch_loss: 1.470353 \n",
      "Batch: 759. Acc: 0.460255. Loss: 1.502199. Batch_acc: 0.487327. Batch_loss: 1.415396 \n",
      "Batch: 760. Acc: 0.460231. Loss: 1.502230. Batch_acc: 0.442529. Batch_loss: 1.525568 \n",
      "Batch: 761. Acc: 0.460258. Loss: 1.502150. Batch_acc: 0.479733. Batch_loss: 1.443446 \n",
      "Batch: 762. Acc: 0.460259. Loss: 1.502141. Batch_acc: 0.460870. Batch_loss: 1.495464 \n",
      "Batch: 763. Acc: 0.460279. Loss: 1.502103. Batch_acc: 0.475945. Batch_loss: 1.473244 \n",
      "Batch: 764. Acc: 0.460274. Loss: 1.502092. Batch_acc: 0.456261. Batch_loss: 1.493497 \n",
      "Batch: 765. Acc: 0.460268. Loss: 1.502054. Batch_acc: 0.455638. Batch_loss: 1.473655 \n",
      "Batch: 766. Acc: 0.460252. Loss: 1.502085. Batch_acc: 0.448176. Batch_loss: 1.525841 \n",
      "Batch: 767. Acc: 0.460254. Loss: 1.502098. Batch_acc: 0.461843. Batch_loss: 1.511838 \n",
      "Batch: 768. Acc: 0.460251. Loss: 1.502086. Batch_acc: 0.457734. Batch_loss: 1.492968 \n",
      "Batch: 769. Acc: 0.460250. Loss: 1.502046. Batch_acc: 0.459350. Batch_loss: 1.470893 \n",
      "Batch: 770. Acc: 0.460240. Loss: 1.502081. Batch_acc: 0.452546. Batch_loss: 1.529521 \n",
      "Batch: 771. Acc: 0.460252. Loss: 1.502071. Batch_acc: 0.469446. Batch_loss: 1.493750 \n",
      "Batch: 772. Acc: 0.460282. Loss: 1.501993. Batch_acc: 0.483447. Batch_loss: 1.442543 \n",
      "Batch: 773. Acc: 0.460287. Loss: 1.501991. Batch_acc: 0.464182. Batch_loss: 1.500342 \n",
      "Batch: 774. Acc: 0.460306. Loss: 1.501924. Batch_acc: 0.474528. Batch_loss: 1.450323 \n",
      "Batch: 775. Acc: 0.460298. Loss: 1.501952. Batch_acc: 0.453855. Batch_loss: 1.524412 \n",
      "Batch: 776. Acc: 0.460313. Loss: 1.501916. Batch_acc: 0.472254. Batch_loss: 1.474388 \n",
      "Batch: 777. Acc: 0.460331. Loss: 1.501872. Batch_acc: 0.473744. Batch_loss: 1.468401 \n",
      "Batch: 778. Acc: 0.460366. Loss: 1.501793. Batch_acc: 0.487651. Batch_loss: 1.440290 \n",
      "Batch: 779. Acc: 0.460343. Loss: 1.501880. Batch_acc: 0.442642. Batch_loss: 1.569884 \n",
      "Batch: 780. Acc: 0.460370. Loss: 1.501815. Batch_acc: 0.480780. Batch_loss: 1.451427 \n",
      "Batch: 781. Acc: 0.460371. Loss: 1.501778. Batch_acc: 0.461448. Batch_loss: 1.472156 \n",
      "Batch: 782. Acc: 0.460362. Loss: 1.501775. Batch_acc: 0.453448. Batch_loss: 1.499357 \n",
      "Batch: 783. Acc: 0.460383. Loss: 1.501709. Batch_acc: 0.476110. Batch_loss: 1.450993 \n",
      "Batch: 784. Acc: 0.460365. Loss: 1.501712. Batch_acc: 0.446563. Batch_loss: 1.504319 \n",
      "Batch: 785. Acc: 0.460315. Loss: 1.501808. Batch_acc: 0.420408. Batch_loss: 1.578497 \n",
      "Batch: 786. Acc: 0.460332. Loss: 1.501768. Batch_acc: 0.473926. Batch_loss: 1.469995 \n",
      "Batch: 787. Acc: 0.460324. Loss: 1.501788. Batch_acc: 0.453434. Batch_loss: 1.517912 \n",
      "Batch: 788. Acc: 0.460306. Loss: 1.501811. Batch_acc: 0.446918. Batch_loss: 1.519369 \n",
      "Batch: 789. Acc: 0.460298. Loss: 1.501806. Batch_acc: 0.453515. Batch_loss: 1.498580 \n",
      "Batch: 790. Acc: 0.460317. Loss: 1.501757. Batch_acc: 0.475448. Batch_loss: 1.462650 \n",
      "Batch: 791. Acc: 0.460336. Loss: 1.501719. Batch_acc: 0.475574. Batch_loss: 1.470650 \n",
      "Batch: 792. Acc: 0.460317. Loss: 1.501789. Batch_acc: 0.444908. Batch_loss: 1.559358 \n",
      "Batch: 793. Acc: 0.460311. Loss: 1.501791. Batch_acc: 0.455372. Batch_loss: 1.503059 \n",
      "Batch: 794. Acc: 0.460313. Loss: 1.501812. Batch_acc: 0.462500. Batch_loss: 1.518464 \n",
      "Batch: 795. Acc: 0.460320. Loss: 1.501821. Batch_acc: 0.465250. Batch_loss: 1.509380 \n",
      "Batch: 796. Acc: 0.460323. Loss: 1.501840. Batch_acc: 0.462952. Batch_loss: 1.517324 \n",
      "Batch: 797. Acc: 0.460329. Loss: 1.501811. Batch_acc: 0.465301. Batch_loss: 1.478600 \n",
      "Batch: 798. Acc: 0.460328. Loss: 1.501807. Batch_acc: 0.459045. Batch_loss: 1.499123 \n",
      "Batch: 799. Acc: 0.460357. Loss: 1.501765. Batch_acc: 0.483541. Batch_loss: 1.468052 \n",
      "Batch: 800. Acc: 0.460356. Loss: 1.501762. Batch_acc: 0.459730. Batch_loss: 1.499285 \n",
      "Batch: 801. Acc: 0.460390. Loss: 1.501668. Batch_acc: 0.487035. Batch_loss: 1.428516 \n",
      "Batch: 802. Acc: 0.460380. Loss: 1.501712. Batch_acc: 0.451968. Batch_loss: 1.536545 \n",
      "Batch: 803. Acc: 0.460388. Loss: 1.501695. Batch_acc: 0.467279. Batch_loss: 1.488457 \n",
      "Batch: 804. Acc: 0.460410. Loss: 1.501613. Batch_acc: 0.477891. Batch_loss: 1.436411 \n",
      "Batch: 805. Acc: 0.460423. Loss: 1.501602. Batch_acc: 0.470729. Batch_loss: 1.492584 \n",
      "Batch: 806. Acc: 0.460431. Loss: 1.501596. Batch_acc: 0.466857. Batch_loss: 1.496680 \n",
      "Batch: 807. Acc: 0.460411. Loss: 1.501645. Batch_acc: 0.444764. Batch_loss: 1.541282 \n",
      "Batch: 808. Acc: 0.460389. Loss: 1.501666. Batch_acc: 0.442319. Batch_loss: 1.518753 \n",
      "Batch: 809. Acc: 0.460398. Loss: 1.501634. Batch_acc: 0.467975. Batch_loss: 1.475576 \n",
      "Batch: 810. Acc: 0.460416. Loss: 1.501582. Batch_acc: 0.474576. Batch_loss: 1.459211 \n",
      "Batch: 811. Acc: 0.460387. Loss: 1.501651. Batch_acc: 0.436927. Batch_loss: 1.557487 \n",
      "Batch: 812. Acc: 0.460369. Loss: 1.501672. Batch_acc: 0.445853. Batch_loss: 1.518353 \n",
      "Batch: 813. Acc: 0.460412. Loss: 1.501588. Batch_acc: 0.495123. Batch_loss: 1.433748 \n",
      "Batch: 814. Acc: 0.460429. Loss: 1.501537. Batch_acc: 0.474411. Batch_loss: 1.460001 \n",
      "Batch: 815. Acc: 0.460430. Loss: 1.501529. Batch_acc: 0.461713. Batch_loss: 1.494679 \n",
      "Batch: 816. Acc: 0.460427. Loss: 1.501538. Batch_acc: 0.457694. Batch_loss: 1.509354 \n",
      "Batch: 817. Acc: 0.460430. Loss: 1.501517. Batch_acc: 0.462791. Batch_loss: 1.483665 \n",
      "Batch: 818. Acc: 0.460453. Loss: 1.501462. Batch_acc: 0.479738. Batch_loss: 1.454785 \n",
      "Batch: 819. Acc: 0.460491. Loss: 1.501327. Batch_acc: 0.490879. Batch_loss: 1.395847 \n",
      "Batch: 820. Acc: 0.460483. Loss: 1.501359. Batch_acc: 0.453752. Batch_loss: 1.527306 \n",
      "Batch: 821. Acc: 0.460493. Loss: 1.501336. Batch_acc: 0.468179. Batch_loss: 1.483004 \n",
      "Batch: 822. Acc: 0.460478. Loss: 1.501351. Batch_acc: 0.448454. Batch_loss: 1.514369 \n",
      "Batch: 823. Acc: 0.460500. Loss: 1.501350. Batch_acc: 0.478090. Batch_loss: 1.500410 \n",
      "Batch: 824. Acc: 0.460497. Loss: 1.501362. Batch_acc: 0.458075. Batch_loss: 1.510413 \n",
      "Batch: 825. Acc: 0.460500. Loss: 1.501335. Batch_acc: 0.462558. Batch_loss: 1.479535 \n",
      "Batch: 826. Acc: 0.460484. Loss: 1.501356. Batch_acc: 0.447821. Batch_loss: 1.518539 \n",
      "Batch: 827. Acc: 0.460487. Loss: 1.501336. Batch_acc: 0.463037. Batch_loss: 1.485133 \n",
      "Batch: 828. Acc: 0.460506. Loss: 1.501292. Batch_acc: 0.476273. Batch_loss: 1.464534 \n",
      "Batch: 829. Acc: 0.460508. Loss: 1.501290. Batch_acc: 0.462359. Batch_loss: 1.499355 \n",
      "Batch: 830. Acc: 0.460529. Loss: 1.501230. Batch_acc: 0.478009. Batch_loss: 1.451251 \n",
      "Batch: 831. Acc: 0.460519. Loss: 1.501251. Batch_acc: 0.452039. Batch_loss: 1.518455 \n",
      "Batch: 832. Acc: 0.460508. Loss: 1.501281. Batch_acc: 0.451276. Batch_loss: 1.526477 \n",
      "Batch: 833. Acc: 0.460529. Loss: 1.501229. Batch_acc: 0.477553. Batch_loss: 1.459089 \n",
      "Batch: 834. Acc: 0.460528. Loss: 1.501221. Batch_acc: 0.459255. Batch_loss: 1.494915 \n",
      "Batch: 835. Acc: 0.460523. Loss: 1.501267. Batch_acc: 0.456356. Batch_loss: 1.540076 \n",
      "Batch: 836. Acc: 0.460519. Loss: 1.501314. Batch_acc: 0.457852. Batch_loss: 1.540999 \n",
      "Batch: 837. Acc: 0.460527. Loss: 1.501261. Batch_acc: 0.466705. Batch_loss: 1.456827 \n",
      "Batch: 838. Acc: 0.460524. Loss: 1.501263. Batch_acc: 0.458237. Batch_loss: 1.502343 \n",
      "Batch: 839. Acc: 0.460518. Loss: 1.501269. Batch_acc: 0.455211. Batch_loss: 1.506336 \n",
      "Batch: 840. Acc: 0.460544. Loss: 1.501205. Batch_acc: 0.482143. Batch_loss: 1.448979 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 841. Acc: 0.460533. Loss: 1.501243. Batch_acc: 0.450924. Batch_loss: 1.534094 \n",
      "Batch: 842. Acc: 0.460529. Loss: 1.501209. Batch_acc: 0.457191. Batch_loss: 1.472799 \n",
      "Batch: 843. Acc: 0.460553. Loss: 1.501170. Batch_acc: 0.480638. Batch_loss: 1.469015 \n",
      "Batch: 844. Acc: 0.460538. Loss: 1.501178. Batch_acc: 0.448454. Batch_loss: 1.507863 \n",
      "Batch: 845. Acc: 0.460553. Loss: 1.501139. Batch_acc: 0.472414. Batch_loss: 1.468405 \n",
      "Batch: 846. Acc: 0.460557. Loss: 1.501127. Batch_acc: 0.464056. Batch_loss: 1.490087 \n",
      "Batch: 847. Acc: 0.460547. Loss: 1.501137. Batch_acc: 0.452299. Batch_loss: 1.510258 \n",
      "Batch: 848. Acc: 0.460553. Loss: 1.501140. Batch_acc: 0.466097. Batch_loss: 1.503488 \n",
      "Batch: 849. Acc: 0.460585. Loss: 1.501082. Batch_acc: 0.486670. Batch_loss: 1.452102 \n",
      "Batch: 850. Acc: 0.460576. Loss: 1.501095. Batch_acc: 0.452896. Batch_loss: 1.512917 \n",
      "Batch: 851. Acc: 0.460585. Loss: 1.501110. Batch_acc: 0.468391. Batch_loss: 1.513645 \n",
      "Batch: 852. Acc: 0.460583. Loss: 1.501136. Batch_acc: 0.458528. Batch_loss: 1.523488 \n",
      "Batch: 853. Acc: 0.460595. Loss: 1.501095. Batch_acc: 0.471023. Batch_loss: 1.466953 \n",
      "Batch: 854. Acc: 0.460584. Loss: 1.501115. Batch_acc: 0.451302. Batch_loss: 1.517726 \n",
      "Batch: 855. Acc: 0.460587. Loss: 1.501120. Batch_acc: 0.463777. Batch_loss: 1.505161 \n",
      "Batch: 856. Acc: 0.460578. Loss: 1.501156. Batch_acc: 0.452273. Batch_loss: 1.531655 \n",
      "Batch: 857. Acc: 0.460594. Loss: 1.501143. Batch_acc: 0.474537. Batch_loss: 1.490408 \n",
      "Batch: 858. Acc: 0.460556. Loss: 1.501270. Batch_acc: 0.427033. Batch_loss: 1.614026 \n",
      "Batch: 859. Acc: 0.460568. Loss: 1.501240. Batch_acc: 0.470588. Batch_loss: 1.475563 \n",
      "Batch: 860. Acc: 0.460592. Loss: 1.501194. Batch_acc: 0.481675. Batch_loss: 1.461741 \n",
      "Batch: 861. Acc: 0.460594. Loss: 1.501244. Batch_acc: 0.462151. Batch_loss: 1.543608 \n",
      "Batch: 862. Acc: 0.460603. Loss: 1.501240. Batch_acc: 0.468268. Batch_loss: 1.497678 \n",
      "Batch: 863. Acc: 0.460594. Loss: 1.501270. Batch_acc: 0.453080. Batch_loss: 1.526935 \n",
      "Batch: 864. Acc: 0.460605. Loss: 1.501243. Batch_acc: 0.470149. Batch_loss: 1.478390 \n",
      "Batch: 865. Acc: 0.460629. Loss: 1.501206. Batch_acc: 0.480736. Batch_loss: 1.469588 \n",
      "Batch: 866. Acc: 0.460636. Loss: 1.501149. Batch_acc: 0.467045. Batch_loss: 1.451985 \n",
      "Batch: 867. Acc: 0.460651. Loss: 1.501151. Batch_acc: 0.473777. Batch_loss: 1.502644 \n",
      "Batch: 868. Acc: 0.460663. Loss: 1.501084. Batch_acc: 0.471084. Batch_loss: 1.444513 \n",
      "Batch: 869. Acc: 0.460679. Loss: 1.501068. Batch_acc: 0.474615. Batch_loss: 1.487069 \n",
      "Batch: 870. Acc: 0.460669. Loss: 1.501110. Batch_acc: 0.451141. Batch_loss: 1.538259 \n",
      "Batch: 871. Acc: 0.460670. Loss: 1.501090. Batch_acc: 0.462142. Batch_loss: 1.484757 \n",
      "Batch: 872. Acc: 0.460652. Loss: 1.501119. Batch_acc: 0.444178. Batch_loss: 1.527464 \n",
      "Batch: 873. Acc: 0.460669. Loss: 1.501049. Batch_acc: 0.475476. Batch_loss: 1.439411 \n",
      "Batch: 874. Acc: 0.460696. Loss: 1.500982. Batch_acc: 0.483908. Batch_loss: 1.442600 \n",
      "Batch: 875. Acc: 0.460698. Loss: 1.500963. Batch_acc: 0.462434. Batch_loss: 1.483652 \n",
      "Batch: 876. Acc: 0.460719. Loss: 1.500922. Batch_acc: 0.479813. Batch_loss: 1.464562 \n",
      "Batch: 877. Acc: 0.460710. Loss: 1.500930. Batch_acc: 0.452613. Batch_loss: 1.508283 \n",
      "Batch: 878. Acc: 0.460725. Loss: 1.500918. Batch_acc: 0.473958. Batch_loss: 1.490381 \n",
      "Batch: 879. Acc: 0.460733. Loss: 1.500897. Batch_acc: 0.467391. Batch_loss: 1.482706 \n",
      "Batch: 880. Acc: 0.460746. Loss: 1.500848. Batch_acc: 0.472393. Batch_loss: 1.459009 \n",
      "Batch: 881. Acc: 0.460741. Loss: 1.500847. Batch_acc: 0.456211. Batch_loss: 1.500104 \n",
      "Batch: 882. Acc: 0.460734. Loss: 1.500874. Batch_acc: 0.454493. Batch_loss: 1.524297 \n",
      "Batch: 883. Acc: 0.460756. Loss: 1.500836. Batch_acc: 0.480092. Batch_loss: 1.467109 \n",
      "Batch: 884. Acc: 0.460791. Loss: 1.500753. Batch_acc: 0.491188. Batch_loss: 1.428766 \n",
      "Batch: 885. Acc: 0.460795. Loss: 1.500726. Batch_acc: 0.464699. Batch_loss: 1.476212 \n",
      "Batch: 886. Acc: 0.460768. Loss: 1.500806. Batch_acc: 0.436821. Batch_loss: 1.570961 \n",
      "Batch: 887. Acc: 0.460793. Loss: 1.500769. Batch_acc: 0.483218. Batch_loss: 1.468135 \n",
      "Batch: 888. Acc: 0.460816. Loss: 1.500709. Batch_acc: 0.481460. Batch_loss: 1.446879 \n",
      "Batch: 889. Acc: 0.460829. Loss: 1.500660. Batch_acc: 0.472769. Batch_loss: 1.456680 \n",
      "Batch: 890. Acc: 0.460833. Loss: 1.500635. Batch_acc: 0.463859. Batch_loss: 1.479252 \n",
      "Batch: 891. Acc: 0.460831. Loss: 1.500576. Batch_acc: 0.459137. Batch_loss: 1.448086 \n",
      "Batch: 892. Acc: 0.460837. Loss: 1.500547. Batch_acc: 0.465992. Batch_loss: 1.475240 \n",
      "Batch: 893. Acc: 0.460832. Loss: 1.500573. Batch_acc: 0.456693. Batch_loss: 1.523878 \n",
      "Batch: 894. Acc: 0.460849. Loss: 1.500544. Batch_acc: 0.475942. Batch_loss: 1.474266 \n",
      "Batch: 895. Acc: 0.460831. Loss: 1.500577. Batch_acc: 0.444891. Batch_loss: 1.529967 \n",
      "Batch: 896. Acc: 0.460836. Loss: 1.500569. Batch_acc: 0.465405. Batch_loss: 1.493106 \n",
      "Batch: 897. Acc: 0.460826. Loss: 1.500586. Batch_acc: 0.451249. Batch_loss: 1.516008 \n",
      "Batch: 898. Acc: 0.460860. Loss: 1.500513. Batch_acc: 0.491545. Batch_loss: 1.436996 \n",
      "Batch: 899. Acc: 0.460856. Loss: 1.500509. Batch_acc: 0.456761. Batch_loss: 1.496139 \n",
      "Batch: 900. Acc: 0.460835. Loss: 1.500544. Batch_acc: 0.441351. Batch_loss: 1.533579 \n",
      "Batch: 901. Acc: 0.460839. Loss: 1.500553. Batch_acc: 0.464912. Batch_loss: 1.508695 \n",
      "Batch: 902. Acc: 0.460869. Loss: 1.500490. Batch_acc: 0.486902. Batch_loss: 1.444042 \n",
      "Batch: 903. Acc: 0.460893. Loss: 1.500445. Batch_acc: 0.483497. Batch_loss: 1.459927 \n",
      "Batch: 904. Acc: 0.460917. Loss: 1.500374. Batch_acc: 0.482254. Batch_loss: 1.437552 \n",
      "Batch: 905. Acc: 0.460949. Loss: 1.500285. Batch_acc: 0.489879. Batch_loss: 1.418883 \n",
      "Batch: 906. Acc: 0.460951. Loss: 1.500291. Batch_acc: 0.462190. Batch_loss: 1.506146 \n",
      "Batch: 907. Acc: 0.460937. Loss: 1.500319. Batch_acc: 0.448474. Batch_loss: 1.524942 \n",
      "Batch: 908. Acc: 0.460960. Loss: 1.500269. Batch_acc: 0.481628. Batch_loss: 1.455742 \n",
      "Batch: 909. Acc: 0.460974. Loss: 1.500201. Batch_acc: 0.473804. Batch_loss: 1.439515 \n",
      "Batch: 910. Acc: 0.460993. Loss: 1.500169. Batch_acc: 0.477841. Batch_loss: 1.471389 \n",
      "Batch: 911. Acc: 0.461009. Loss: 1.500096. Batch_acc: 0.474972. Batch_loss: 1.434597 \n",
      "Batch: 912. Acc: 0.461045. Loss: 1.500021. Batch_acc: 0.495026. Batch_loss: 1.429974 \n",
      "Batch: 913. Acc: 0.461052. Loss: 1.500013. Batch_acc: 0.467195. Batch_loss: 1.492784 \n",
      "Batch: 914. Acc: 0.461057. Loss: 1.499964. Batch_acc: 0.465306. Batch_loss: 1.454658 \n",
      "Batch: 915. Acc: 0.461065. Loss: 1.499951. Batch_acc: 0.468531. Batch_loss: 1.488385 \n",
      "Batch: 916. Acc: 0.461041. Loss: 1.499980. Batch_acc: 0.438806. Batch_loss: 1.526690 \n",
      "Batch: 917. Acc: 0.461074. Loss: 1.499896. Batch_acc: 0.490544. Batch_loss: 1.423840 \n",
      "Batch: 918. Acc: 0.461071. Loss: 1.499919. Batch_acc: 0.458576. Batch_loss: 1.521100 \n",
      "Batch: 919. Acc: 0.461090. Loss: 1.499872. Batch_acc: 0.478311. Batch_loss: 1.457268 \n",
      "Batch: 920. Acc: 0.461108. Loss: 1.499811. Batch_acc: 0.477638. Batch_loss: 1.443492 \n",
      "Batch: 921. Acc: 0.461104. Loss: 1.499837. Batch_acc: 0.457307. Batch_loss: 1.523967 \n",
      "Batch: 922. Acc: 0.461093. Loss: 1.499870. Batch_acc: 0.451049. Batch_loss: 1.530369 \n",
      "Batch: 923. Acc: 0.461097. Loss: 1.499845. Batch_acc: 0.464411. Batch_loss: 1.476258 \n",
      "Batch: 924. Acc: 0.461110. Loss: 1.499815. Batch_acc: 0.473300. Batch_loss: 1.473371 \n",
      "Batch: 925. Acc: 0.461110. Loss: 1.499811. Batch_acc: 0.461453. Batch_loss: 1.496127 \n",
      "Batch: 926. Acc: 0.461102. Loss: 1.499825. Batch_acc: 0.452797. Batch_loss: 1.512768 \n",
      "Batch: 927. Acc: 0.461130. Loss: 1.499775. Batch_acc: 0.486976. Batch_loss: 1.454417 \n",
      "Batch: 928. Acc: 0.461145. Loss: 1.499749. Batch_acc: 0.475230. Batch_loss: 1.475757 \n",
      "Batch: 929. Acc: 0.461135. Loss: 1.499787. Batch_acc: 0.451895. Batch_loss: 1.535043 \n",
      "Batch: 930. Acc: 0.461149. Loss: 1.499752. Batch_acc: 0.474227. Batch_loss: 1.467776 \n",
      "Batch: 931. Acc: 0.461151. Loss: 1.499756. Batch_acc: 0.462457. Batch_loss: 1.503287 \n",
      "Batch: 932. Acc: 0.461151. Loss: 1.499772. Batch_acc: 0.461057. Batch_loss: 1.514495 \n",
      "Batch: 933. Acc: 0.461166. Loss: 1.499739. Batch_acc: 0.475610. Batch_loss: 1.468610 \n",
      "Batch: 934. Acc: 0.461179. Loss: 1.499720. Batch_acc: 0.473143. Batch_loss: 1.482073 \n",
      "Batch: 935. Acc: 0.461202. Loss: 1.499668. Batch_acc: 0.484103. Batch_loss: 1.449307 \n",
      "Batch: 936. Acc: 0.461215. Loss: 1.499642. Batch_acc: 0.473099. Batch_loss: 1.474958 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 937. Acc: 0.461224. Loss: 1.499650. Batch_acc: 0.470449. Batch_loss: 1.506880 \n",
      "Batch: 938. Acc: 0.461217. Loss: 1.499657. Batch_acc: 0.454023. Batch_loss: 1.505979 \n",
      "Batch: 939. Acc: 0.461226. Loss: 1.499638. Batch_acc: 0.469741. Batch_loss: 1.482174 \n",
      "Batch: 940. Acc: 0.461218. Loss: 1.499684. Batch_acc: 0.453936. Batch_loss: 1.541644 \n",
      "Batch: 941. Acc: 0.461243. Loss: 1.499648. Batch_acc: 0.484507. Batch_loss: 1.466127 \n",
      "Batch: 942. Acc: 0.461261. Loss: 1.499599. Batch_acc: 0.478113. Batch_loss: 1.454541 \n",
      "Batch: 943. Acc: 0.461274. Loss: 1.499572. Batch_acc: 0.472981. Batch_loss: 1.473529 \n",
      "Batch: 944. Acc: 0.461275. Loss: 1.499546. Batch_acc: 0.462286. Batch_loss: 1.475526 \n",
      "Batch: 945. Acc: 0.461256. Loss: 1.499578. Batch_acc: 0.443468. Batch_loss: 1.529564 \n",
      "Batch: 946. Acc: 0.461273. Loss: 1.499574. Batch_acc: 0.477416. Batch_loss: 1.496590 \n",
      "Batch: 947. Acc: 0.461251. Loss: 1.499632. Batch_acc: 0.440372. Batch_loss: 1.555218 \n",
      "Batch: 948. Acc: 0.461257. Loss: 1.499623. Batch_acc: 0.466743. Batch_loss: 1.491172 \n",
      "Batch: 949. Acc: 0.461284. Loss: 1.499611. Batch_acc: 0.485923. Batch_loss: 1.487919 \n",
      "Batch: 950. Acc: 0.461282. Loss: 1.499620. Batch_acc: 0.459160. Batch_loss: 1.508259 \n",
      "Batch: 951. Acc: 0.461272. Loss: 1.499628. Batch_acc: 0.451852. Batch_loss: 1.507277 \n",
      "Batch: 952. Acc: 0.461265. Loss: 1.499642. Batch_acc: 0.455023. Batch_loss: 1.513165 \n",
      "Batch: 953. Acc: 0.461279. Loss: 1.499608. Batch_acc: 0.474490. Batch_loss: 1.467652 \n",
      "Batch: 954. Acc: 0.461278. Loss: 1.499594. Batch_acc: 0.460069. Batch_loss: 1.486504 \n",
      "Batch: 955. Acc: 0.461271. Loss: 1.499595. Batch_acc: 0.454867. Batch_loss: 1.500775 \n",
      "Batch: 956. Acc: 0.461271. Loss: 1.499597. Batch_acc: 0.461179. Batch_loss: 1.501454 \n",
      "Batch: 957. Acc: 0.461292. Loss: 1.499542. Batch_acc: 0.481481. Batch_loss: 1.445060 \n",
      "Batch: 958. Acc: 0.461320. Loss: 1.499503. Batch_acc: 0.488372. Batch_loss: 1.462237 \n",
      "Batch: 959. Acc: 0.461332. Loss: 1.499463. Batch_acc: 0.472674. Batch_loss: 1.460769 \n",
      "Batch: 960. Acc: 0.461353. Loss: 1.499445. Batch_acc: 0.482360. Batch_loss: 1.481419 \n",
      "Batch: 961. Acc: 0.461361. Loss: 1.499407. Batch_acc: 0.468750. Batch_loss: 1.464403 \n",
      "Batch: 962. Acc: 0.461361. Loss: 1.499397. Batch_acc: 0.461494. Batch_loss: 1.489707 \n",
      "Batch: 963. Acc: 0.461387. Loss: 1.499361. Batch_acc: 0.486534. Batch_loss: 1.463805 \n",
      "Batch: 964. Acc: 0.461396. Loss: 1.499360. Batch_acc: 0.470035. Batch_loss: 1.498530 \n",
      "Batch: 965. Acc: 0.461409. Loss: 1.499333. Batch_acc: 0.474070. Batch_loss: 1.474001 \n",
      "Batch: 966. Acc: 0.461440. Loss: 1.499248. Batch_acc: 0.489899. Batch_loss: 1.418781 \n",
      "Batch: 967. Acc: 0.461461. Loss: 1.499221. Batch_acc: 0.482332. Batch_loss: 1.473072 \n",
      "Batch: 968. Acc: 0.461457. Loss: 1.499237. Batch_acc: 0.458094. Batch_loss: 1.514696 \n",
      "Batch: 969. Acc: 0.461468. Loss: 1.499213. Batch_acc: 0.472078. Batch_loss: 1.475615 \n",
      "Batch: 970. Acc: 0.461445. Loss: 1.499261. Batch_acc: 0.437947. Batch_loss: 1.547784 \n",
      "Batch: 971. Acc: 0.461443. Loss: 1.499272. Batch_acc: 0.459953. Batch_loss: 1.510208 \n",
      "Batch: 972. Acc: 0.461441. Loss: 1.499283. Batch_acc: 0.459112. Batch_loss: 1.510380 \n",
      "Batch: 973. Acc: 0.461454. Loss: 1.499260. Batch_acc: 0.473982. Batch_loss: 1.476998 \n",
      "Batch: 974. Acc: 0.461456. Loss: 1.499287. Batch_acc: 0.463751. Batch_loss: 1.525683 \n",
      "Batch: 975. Acc: 0.461447. Loss: 1.499325. Batch_acc: 0.452668. Batch_loss: 1.536111 \n",
      "Batch: 976. Acc: 0.461472. Loss: 1.499257. Batch_acc: 0.485516. Batch_loss: 1.432810 \n",
      "Batch: 977. Acc: 0.461465. Loss: 1.499280. Batch_acc: 0.454802. Batch_loss: 1.521080 \n",
      "Batch: 978. Acc: 0.461467. Loss: 1.499284. Batch_acc: 0.463995. Batch_loss: 1.502662 \n",
      "Batch: 979. Acc: 0.461462. Loss: 1.499309. Batch_acc: 0.455874. Batch_loss: 1.524335 \n",
      "Batch: 980. Acc: 0.461464. Loss: 1.499290. Batch_acc: 0.464056. Batch_loss: 1.480377 \n",
      "Batch: 981. Acc: 0.461465. Loss: 1.499252. Batch_acc: 0.461766. Batch_loss: 1.460892 \n",
      "Batch: 982. Acc: 0.461480. Loss: 1.499223. Batch_acc: 0.476571. Batch_loss: 1.471012 \n",
      "Batch: 983. Acc: 0.461496. Loss: 1.499198. Batch_acc: 0.477181. Batch_loss: 1.474568 \n",
      "Batch: 984. Acc: 0.461502. Loss: 1.499199. Batch_acc: 0.466935. Batch_loss: 1.500074 \n",
      "Batch: 985. Acc: 0.461530. Loss: 1.499158. Batch_acc: 0.489118. Batch_loss: 1.459454 \n",
      "Batch: 986. Acc: 0.461525. Loss: 1.499159. Batch_acc: 0.457258. Batch_loss: 1.500273 \n",
      "Batch: 987. Acc: 0.461527. Loss: 1.499153. Batch_acc: 0.463626. Batch_loss: 1.492494 \n",
      "Batch: 988. Acc: 0.461545. Loss: 1.499100. Batch_acc: 0.478311. Batch_loss: 1.447192 \n",
      "Batch: 989. Acc: 0.461554. Loss: 1.499062. Batch_acc: 0.470455. Batch_loss: 1.461982 \n",
      "Batch: 990. Acc: 0.461575. Loss: 1.498988. Batch_acc: 0.482759. Batch_loss: 1.427657 \n",
      "Batch: 991. Acc: 0.461584. Loss: 1.498966. Batch_acc: 0.469838. Batch_loss: 1.476696 \n",
      "Batch: 992. Acc: 0.461591. Loss: 1.498937. Batch_acc: 0.468913. Batch_loss: 1.470175 \n",
      "Batch: 993. Acc: 0.461569. Loss: 1.498996. Batch_acc: 0.439516. Batch_loss: 1.556867 \n",
      "Batch: 994. Acc: 0.461573. Loss: 1.498970. Batch_acc: 0.465409. Batch_loss: 1.474191 \n",
      "Batch: 995. Acc: 0.461570. Loss: 1.498960. Batch_acc: 0.458769. Batch_loss: 1.488421 \n",
      "Batch: 996. Acc: 0.461566. Loss: 1.498977. Batch_acc: 0.457310. Batch_loss: 1.515895 \n",
      "Batch: 997. Acc: 0.461566. Loss: 1.498935. Batch_acc: 0.461713. Batch_loss: 1.457830 \n",
      "Batch: 998. Acc: 0.461571. Loss: 1.498880. Batch_acc: 0.466433. Batch_loss: 1.443431 \n",
      "Batch: 999. Acc: 0.461577. Loss: 1.498853. Batch_acc: 0.467863. Batch_loss: 1.471153 \n",
      "Batch: 1000. Acc: 0.461574. Loss: 1.498869. Batch_acc: 0.458038. Batch_loss: 1.516277 \n",
      "Batch: 1001. Acc: 0.461563. Loss: 1.498875. Batch_acc: 0.451199. Batch_loss: 1.504281 \n",
      "Batch: 1002. Acc: 0.461558. Loss: 1.498886. Batch_acc: 0.456797. Batch_loss: 1.509522 \n",
      "Batch: 1003. Acc: 0.461564. Loss: 1.498852. Batch_acc: 0.467011. Batch_loss: 1.465640 \n",
      "Batch: 1004. Acc: 0.461585. Loss: 1.498810. Batch_acc: 0.483382. Batch_loss: 1.455142 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.4615849793068615. Loss per char: 1.498809529677551. Time: 1627214909.5942528\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 18, 19, 24, 21,  1, 12,  1,\n",
      "        14, 18, 19, 21, 20, 25, 22, 22, 25, 23, 19, 26, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.461581. Loss: 1.498820. Batch_acc: 0.457608. Batch_loss: 1.508917 \n",
      "Batch: 1006. Acc: 0.461566. Loss: 1.498824. Batch_acc: 0.446882. Batch_loss: 1.503098 \n",
      "Batch: 1007. Acc: 0.461571. Loss: 1.498832. Batch_acc: 0.465856. Batch_loss: 1.506711 \n",
      "Batch: 1008. Acc: 0.461574. Loss: 1.498802. Batch_acc: 0.464814. Batch_loss: 1.467745 \n",
      "Batch: 1009. Acc: 0.461575. Loss: 1.498802. Batch_acc: 0.462844. Batch_loss: 1.498744 \n",
      "Batch: 1010. Acc: 0.461579. Loss: 1.498775. Batch_acc: 0.465738. Batch_loss: 1.471833 \n",
      "Batch: 1011. Acc: 0.461573. Loss: 1.498782. Batch_acc: 0.455026. Batch_loss: 1.505774 \n",
      "Batch: 1012. Acc: 0.461583. Loss: 1.498781. Batch_acc: 0.472611. Batch_loss: 1.497125 \n",
      "Batch: 1013. Acc: 0.461564. Loss: 1.498823. Batch_acc: 0.441627. Batch_loss: 1.543389 \n",
      "Batch: 1014. Acc: 0.461558. Loss: 1.498851. Batch_acc: 0.455172. Batch_loss: 1.526417 \n",
      "Batch: 1015. Acc: 0.461517. Loss: 1.498958. Batch_acc: 0.418919. Batch_loss: 1.610108 \n",
      "Batch: 1016. Acc: 0.461513. Loss: 1.498978. Batch_acc: 0.457767. Batch_loss: 1.520044 \n",
      "Batch: 1017. Acc: 0.461513. Loss: 1.499002. Batch_acc: 0.460784. Batch_loss: 1.523537 \n",
      "Batch: 1018. Acc: 0.461547. Loss: 1.498934. Batch_acc: 0.495803. Batch_loss: 1.430981 \n",
      "Batch: 1019. Acc: 0.461564. Loss: 1.498883. Batch_acc: 0.477994. Batch_loss: 1.449352 \n",
      "Batch: 1020. Acc: 0.461569. Loss: 1.498885. Batch_acc: 0.466403. Batch_loss: 1.500560 \n",
      "Batch: 1021. Acc: 0.461559. Loss: 1.498897. Batch_acc: 0.451945. Batch_loss: 1.511095 \n",
      "Batch: 1022. Acc: 0.461560. Loss: 1.498869. Batch_acc: 0.462652. Batch_loss: 1.469788 \n",
      "Batch: 1023. Acc: 0.461587. Loss: 1.498835. Batch_acc: 0.487996. Batch_loss: 1.464908 \n",
      "Batch: 1024. Acc: 0.461598. Loss: 1.498815. Batch_acc: 0.473496. Batch_loss: 1.478324 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1025. Acc: 0.461621. Loss: 1.498749. Batch_acc: 0.484986. Batch_loss: 1.431647 \n",
      "Batch: 1026. Acc: 0.461629. Loss: 1.498716. Batch_acc: 0.469610. Batch_loss: 1.465739 \n",
      "Batch: 1027. Acc: 0.461639. Loss: 1.498714. Batch_acc: 0.471879. Batch_loss: 1.495900 \n",
      "Batch: 1028. Acc: 0.461649. Loss: 1.498699. Batch_acc: 0.471611. Batch_loss: 1.483877 \n",
      "Batch: 1029. Acc: 0.461638. Loss: 1.498736. Batch_acc: 0.450201. Batch_loss: 1.536911 \n",
      "Batch: 1030. Acc: 0.461623. Loss: 1.498770. Batch_acc: 0.446512. Batch_loss: 1.533650 \n",
      "Batch: 1031. Acc: 0.461627. Loss: 1.498756. Batch_acc: 0.465856. Batch_loss: 1.483869 \n",
      "Batch: 1032. Acc: 0.461622. Loss: 1.498749. Batch_acc: 0.456484. Batch_loss: 1.492049 \n",
      "Batch: 1033. Acc: 0.461628. Loss: 1.498730. Batch_acc: 0.467517. Batch_loss: 1.478397 \n",
      "Batch: 1034. Acc: 0.461630. Loss: 1.498721. Batch_acc: 0.463277. Batch_loss: 1.489657 \n",
      "Batch: 1035. Acc: 0.461643. Loss: 1.498686. Batch_acc: 0.475305. Batch_loss: 1.462216 \n",
      "Batch: 1036. Acc: 0.461668. Loss: 1.498604. Batch_acc: 0.486740. Batch_loss: 1.417165 \n",
      "Batch: 1037. Acc: 0.461657. Loss: 1.498640. Batch_acc: 0.450745. Batch_loss: 1.535898 \n",
      "Batch: 1038. Acc: 0.461657. Loss: 1.498646. Batch_acc: 0.461234. Batch_loss: 1.504346 \n",
      "Batch: 1039. Acc: 0.461666. Loss: 1.498624. Batch_acc: 0.471093. Batch_loss: 1.476375 \n",
      "Batch: 1040. Acc: 0.461686. Loss: 1.498607. Batch_acc: 0.482839. Batch_loss: 1.480279 \n",
      "Batch: 1041. Acc: 0.461706. Loss: 1.498568. Batch_acc: 0.481948. Batch_loss: 1.458215 \n",
      "Batch: 1042. Acc: 0.461706. Loss: 1.498550. Batch_acc: 0.461889. Batch_loss: 1.480523 \n",
      "Batch: 1043. Acc: 0.461698. Loss: 1.498561. Batch_acc: 0.453190. Batch_loss: 1.509817 \n",
      "Batch: 1044. Acc: 0.461709. Loss: 1.498523. Batch_acc: 0.473502. Batch_loss: 1.459156 \n",
      "Batch: 1045. Acc: 0.461704. Loss: 1.498535. Batch_acc: 0.456232. Batch_loss: 1.510818 \n",
      "Batch: 1046. Acc: 0.461707. Loss: 1.498524. Batch_acc: 0.464877. Batch_loss: 1.487204 \n",
      "Batch: 1047. Acc: 0.461708. Loss: 1.498500. Batch_acc: 0.462857. Batch_loss: 1.473960 \n",
      "Batch: 1048. Acc: 0.461728. Loss: 1.498440. Batch_acc: 0.483140. Batch_loss: 1.434472 \n",
      "Batch: 1049. Acc: 0.461741. Loss: 1.498414. Batch_acc: 0.475161. Batch_loss: 1.471428 \n",
      "Batch: 1050. Acc: 0.461753. Loss: 1.498408. Batch_acc: 0.474381. Batch_loss: 1.491884 \n",
      "Batch: 1051. Acc: 0.461773. Loss: 1.498399. Batch_acc: 0.483017. Batch_loss: 1.489241 \n",
      "Batch: 1052. Acc: 0.461787. Loss: 1.498365. Batch_acc: 0.475673. Batch_loss: 1.462310 \n",
      "Batch: 1053. Acc: 0.461806. Loss: 1.498337. Batch_acc: 0.482400. Batch_loss: 1.468672 \n",
      "Batch: 1054. Acc: 0.461813. Loss: 1.498316. Batch_acc: 0.468750. Batch_loss: 1.476634 \n",
      "Batch: 1055. Acc: 0.461821. Loss: 1.498287. Batch_acc: 0.470221. Batch_loss: 1.467954 \n",
      "Batch: 1056. Acc: 0.461839. Loss: 1.498240. Batch_acc: 0.481190. Batch_loss: 1.449918 \n",
      "Batch: 1057. Acc: 0.461846. Loss: 1.498218. Batch_acc: 0.468535. Batch_loss: 1.474519 \n",
      "Batch: 1058. Acc: 0.461843. Loss: 1.498215. Batch_acc: 0.458358. Batch_loss: 1.495323 \n",
      "Batch: 1059. Acc: 0.461859. Loss: 1.498164. Batch_acc: 0.479718. Batch_loss: 1.443343 \n",
      "Batch: 1060. Acc: 0.461885. Loss: 1.498071. Batch_acc: 0.488864. Batch_loss: 1.399598 \n",
      "Batch: 1061. Acc: 0.461911. Loss: 1.497997. Batch_acc: 0.489290. Batch_loss: 1.421742 \n",
      "Batch: 1062. Acc: 0.461908. Loss: 1.497986. Batch_acc: 0.459026. Batch_loss: 1.486173 \n",
      "Batch: 1063. Acc: 0.461908. Loss: 1.497989. Batch_acc: 0.461891. Batch_loss: 1.501200 \n",
      "Batch: 1064. Acc: 0.461919. Loss: 1.497964. Batch_acc: 0.473837. Batch_loss: 1.470865 \n",
      "Batch: 1065. Acc: 0.461937. Loss: 1.497921. Batch_acc: 0.481116. Batch_loss: 1.452057 \n",
      "Batch: 1066. Acc: 0.461970. Loss: 1.497831. Batch_acc: 0.496350. Batch_loss: 1.403748 \n",
      "Batch: 1067. Acc: 0.462001. Loss: 1.497754. Batch_acc: 0.493318. Batch_loss: 1.418810 \n",
      "Batch: 1068. Acc: 0.462003. Loss: 1.497750. Batch_acc: 0.464474. Batch_loss: 1.492928 \n",
      "Batch: 1069. Acc: 0.462013. Loss: 1.497709. Batch_acc: 0.472410. Batch_loss: 1.454708 \n",
      "Batch: 1070. Acc: 0.462021. Loss: 1.497674. Batch_acc: 0.471304. Batch_loss: 1.460198 \n",
      "Batch: 1071. Acc: 0.462020. Loss: 1.497672. Batch_acc: 0.460473. Batch_loss: 1.495662 \n",
      "Batch: 1072. Acc: 0.462024. Loss: 1.497646. Batch_acc: 0.466063. Batch_loss: 1.470178 \n",
      "Batch: 1073. Acc: 0.462030. Loss: 1.497628. Batch_acc: 0.468332. Batch_loss: 1.478474 \n",
      "Batch: 1074. Acc: 0.462018. Loss: 1.497643. Batch_acc: 0.450086. Batch_loss: 1.513090 \n",
      "Batch: 1075. Acc: 0.462018. Loss: 1.497636. Batch_acc: 0.461315. Batch_loss: 1.489713 \n",
      "Batch: 1076. Acc: 0.462016. Loss: 1.497639. Batch_acc: 0.460198. Batch_loss: 1.501195 \n",
      "Batch: 1077. Acc: 0.462010. Loss: 1.497649. Batch_acc: 0.455451. Batch_loss: 1.508864 \n",
      "Batch: 1078. Acc: 0.462006. Loss: 1.497638. Batch_acc: 0.457873. Batch_loss: 1.485972 \n",
      "Batch: 1079. Acc: 0.462021. Loss: 1.497598. Batch_acc: 0.477487. Batch_loss: 1.455049 \n",
      "Batch: 1080. Acc: 0.462020. Loss: 1.497594. Batch_acc: 0.460623. Batch_loss: 1.493191 \n",
      "Batch: 1081. Acc: 0.462038. Loss: 1.497533. Batch_acc: 0.480955. Batch_loss: 1.433106 \n",
      "Batch: 1082. Acc: 0.462046. Loss: 1.497522. Batch_acc: 0.471304. Batch_loss: 1.485736 \n",
      "Batch: 1083. Acc: 0.462038. Loss: 1.497511. Batch_acc: 0.452928. Batch_loss: 1.485729 \n",
      "Batch: 1084. Acc: 0.462037. Loss: 1.497502. Batch_acc: 0.461451. Batch_loss: 1.487426 \n",
      "Batch: 1085. Acc: 0.462029. Loss: 1.497523. Batch_acc: 0.452899. Batch_loss: 1.521835 \n",
      "Batch: 1086. Acc: 0.462023. Loss: 1.497516. Batch_acc: 0.455732. Batch_loss: 1.489438 \n",
      "Batch: 1087. Acc: 0.462019. Loss: 1.497522. Batch_acc: 0.457324. Batch_loss: 1.503938 \n",
      "Batch: 1088. Acc: 0.461998. Loss: 1.497560. Batch_acc: 0.439095. Batch_loss: 1.539943 \n",
      "Batch: 1089. Acc: 0.461994. Loss: 1.497548. Batch_acc: 0.457608. Batch_loss: 1.484863 \n",
      "Batch: 1090. Acc: 0.462033. Loss: 1.497464. Batch_acc: 0.504343. Batch_loss: 1.404379 \n",
      "Batch: 1091. Acc: 0.462048. Loss: 1.497420. Batch_acc: 0.478359. Batch_loss: 1.450567 \n",
      "Batch: 1092. Acc: 0.462068. Loss: 1.497382. Batch_acc: 0.483798. Batch_loss: 1.457171 \n",
      "Batch: 1093. Acc: 0.462080. Loss: 1.497339. Batch_acc: 0.475581. Batch_loss: 1.449663 \n",
      "Batch: 1094. Acc: 0.462104. Loss: 1.497265. Batch_acc: 0.488014. Batch_loss: 1.416699 \n",
      "Batch: 1095. Acc: 0.462114. Loss: 1.497237. Batch_acc: 0.472379. Batch_loss: 1.467137 \n",
      "Batch: 1096. Acc: 0.462114. Loss: 1.497262. Batch_acc: 0.462485. Batch_loss: 1.525027 \n",
      "Batch: 1097. Acc: 0.462125. Loss: 1.497228. Batch_acc: 0.473947. Batch_loss: 1.461935 \n",
      "Batch: 1098. Acc: 0.462135. Loss: 1.497206. Batch_acc: 0.473193. Batch_loss: 1.472612 \n",
      "Batch: 1099. Acc: 0.462132. Loss: 1.497193. Batch_acc: 0.458238. Batch_loss: 1.483166 \n",
      "Batch: 1100. Acc: 0.462152. Loss: 1.497146. Batch_acc: 0.484659. Batch_loss: 1.445568 \n",
      "Batch: 1101. Acc: 0.462150. Loss: 1.497161. Batch_acc: 0.459395. Batch_loss: 1.514506 \n",
      "Batch: 1102. Acc: 0.462170. Loss: 1.497143. Batch_acc: 0.485114. Batch_loss: 1.477040 \n",
      "Batch: 1103. Acc: 0.462188. Loss: 1.497106. Batch_acc: 0.480556. Batch_loss: 1.457190 \n",
      "Batch: 1104. Acc: 0.462223. Loss: 1.497007. Batch_acc: 0.499721. Batch_loss: 1.391953 \n",
      "Batch: 1105. Acc: 0.462234. Loss: 1.496992. Batch_acc: 0.475588. Batch_loss: 1.478750 \n",
      "Batch: 1106. Acc: 0.462261. Loss: 1.496938. Batch_acc: 0.492468. Batch_loss: 1.437194 \n",
      "Batch: 1107. Acc: 0.462277. Loss: 1.496915. Batch_acc: 0.479348. Batch_loss: 1.471676 \n",
      "Batch: 1108. Acc: 0.462273. Loss: 1.496902. Batch_acc: 0.458716. Batch_loss: 1.482165 \n",
      "Batch: 1109. Acc: 0.462284. Loss: 1.496874. Batch_acc: 0.473864. Batch_loss: 1.466342 \n",
      "Batch: 1110. Acc: 0.462284. Loss: 1.496888. Batch_acc: 0.461808. Batch_loss: 1.512608 \n",
      "Batch: 1111. Acc: 0.462299. Loss: 1.496825. Batch_acc: 0.480329. Batch_loss: 1.425422 \n",
      "Batch: 1112. Acc: 0.462303. Loss: 1.496806. Batch_acc: 0.466588. Batch_loss: 1.474807 \n",
      "Batch: 1113. Acc: 0.462323. Loss: 1.496783. Batch_acc: 0.484472. Batch_loss: 1.471563 \n",
      "Batch: 1114. Acc: 0.462321. Loss: 1.496777. Batch_acc: 0.459617. Batch_loss: 1.490751 \n",
      "Batch: 1115. Acc: 0.462321. Loss: 1.496780. Batch_acc: 0.461845. Batch_loss: 1.499759 \n",
      "Batch: 1116. Acc: 0.462342. Loss: 1.496741. Batch_acc: 0.485377. Batch_loss: 1.454212 \n",
      "Batch: 1117. Acc: 0.462327. Loss: 1.496739. Batch_acc: 0.446398. Batch_loss: 1.493952 \n",
      "Batch: 1118. Acc: 0.462319. Loss: 1.496767. Batch_acc: 0.452423. Batch_loss: 1.528665 \n",
      "Batch: 1119. Acc: 0.462342. Loss: 1.496715. Batch_acc: 0.488603. Batch_loss: 1.437697 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1120. Acc: 0.462344. Loss: 1.496714. Batch_acc: 0.464968. Batch_loss: 1.496021 \n",
      "Batch: 1121. Acc: 0.462366. Loss: 1.496653. Batch_acc: 0.485971. Batch_loss: 1.429295 \n",
      "Batch: 1122. Acc: 0.462353. Loss: 1.496667. Batch_acc: 0.447874. Batch_loss: 1.512939 \n",
      "Batch: 1123. Acc: 0.462395. Loss: 1.496581. Batch_acc: 0.508802. Batch_loss: 1.401645 \n",
      "Batch: 1124. Acc: 0.462395. Loss: 1.496588. Batch_acc: 0.462952. Batch_loss: 1.504036 \n",
      "Batch: 1125. Acc: 0.462406. Loss: 1.496549. Batch_acc: 0.474250. Batch_loss: 1.454255 \n",
      "Batch: 1126. Acc: 0.462419. Loss: 1.496497. Batch_acc: 0.477195. Batch_loss: 1.438135 \n",
      "Batch: 1127. Acc: 0.462429. Loss: 1.496482. Batch_acc: 0.473533. Batch_loss: 1.479498 \n",
      "Batch: 1128. Acc: 0.462400. Loss: 1.496517. Batch_acc: 0.428826. Batch_loss: 1.536841 \n",
      "Batch: 1129. Acc: 0.462394. Loss: 1.496552. Batch_acc: 0.455128. Batch_loss: 1.536825 \n",
      "Batch: 1130. Acc: 0.462413. Loss: 1.496479. Batch_acc: 0.485062. Batch_loss: 1.412883 \n",
      "Batch: 1131. Acc: 0.462400. Loss: 1.496509. Batch_acc: 0.447635. Batch_loss: 1.529299 \n",
      "Batch: 1132. Acc: 0.462389. Loss: 1.496544. Batch_acc: 0.449541. Batch_loss: 1.536202 \n",
      "Batch: 1133. Acc: 0.462399. Loss: 1.496526. Batch_acc: 0.474508. Batch_loss: 1.475274 \n",
      "Batch: 1134. Acc: 0.462393. Loss: 1.496549. Batch_acc: 0.455652. Batch_loss: 1.523554 \n",
      "Batch: 1135. Acc: 0.462425. Loss: 1.496465. Batch_acc: 0.498286. Batch_loss: 1.401530 \n",
      "Batch: 1136. Acc: 0.462432. Loss: 1.496445. Batch_acc: 0.470520. Batch_loss: 1.473501 \n",
      "Batch: 1137. Acc: 0.462442. Loss: 1.496424. Batch_acc: 0.473926. Batch_loss: 1.472947 \n",
      "Batch: 1138. Acc: 0.462437. Loss: 1.496410. Batch_acc: 0.456289. Batch_loss: 1.480648 \n",
      "Batch: 1139. Acc: 0.462460. Loss: 1.496350. Batch_acc: 0.488889. Batch_loss: 1.428875 \n",
      "Batch: 1140. Acc: 0.462474. Loss: 1.496318. Batch_acc: 0.477881. Batch_loss: 1.459218 \n",
      "Batch: 1141. Acc: 0.462493. Loss: 1.496285. Batch_acc: 0.485346. Batch_loss: 1.458218 \n",
      "Batch: 1142. Acc: 0.462511. Loss: 1.496244. Batch_acc: 0.482133. Batch_loss: 1.449994 \n",
      "Batch: 1143. Acc: 0.462504. Loss: 1.496245. Batch_acc: 0.454648. Batch_loss: 1.497069 \n",
      "Batch: 1144. Acc: 0.462511. Loss: 1.496209. Batch_acc: 0.470896. Batch_loss: 1.454815 \n",
      "Batch: 1145. Acc: 0.462498. Loss: 1.496238. Batch_acc: 0.447727. Batch_loss: 1.529476 \n",
      "Batch: 1146. Acc: 0.462476. Loss: 1.496278. Batch_acc: 0.437101. Batch_loss: 1.541698 \n",
      "Batch: 1147. Acc: 0.462487. Loss: 1.496240. Batch_acc: 0.475087. Batch_loss: 1.452865 \n",
      "Batch: 1148. Acc: 0.462486. Loss: 1.496258. Batch_acc: 0.460929. Batch_loss: 1.515842 \n",
      "Batch: 1149. Acc: 0.462503. Loss: 1.496195. Batch_acc: 0.482517. Batch_loss: 1.423910 \n",
      "Batch: 1150. Acc: 0.462484. Loss: 1.496238. Batch_acc: 0.440986. Batch_loss: 1.546412 \n",
      "Batch: 1151. Acc: 0.462486. Loss: 1.496259. Batch_acc: 0.464772. Batch_loss: 1.520943 \n",
      "Batch: 1152. Acc: 0.462496. Loss: 1.496216. Batch_acc: 0.474239. Batch_loss: 1.445902 \n",
      "Batch: 1153. Acc: 0.462505. Loss: 1.496206. Batch_acc: 0.472418. Batch_loss: 1.484784 \n",
      "Batch: 1154. Acc: 0.462492. Loss: 1.496228. Batch_acc: 0.447045. Batch_loss: 1.521102 \n",
      "Batch: 1155. Acc: 0.462500. Loss: 1.496229. Batch_acc: 0.472845. Batch_loss: 1.497450 \n",
      "Batch: 1156. Acc: 0.462485. Loss: 1.496272. Batch_acc: 0.445205. Batch_loss: 1.546245 \n",
      "Batch: 1157. Acc: 0.462507. Loss: 1.496205. Batch_acc: 0.487522. Batch_loss: 1.417383 \n",
      "Batch: 1158. Acc: 0.462516. Loss: 1.496177. Batch_acc: 0.473326. Batch_loss: 1.464222 \n",
      "Batch: 1159. Acc: 0.462505. Loss: 1.496222. Batch_acc: 0.449801. Batch_loss: 1.548182 \n",
      "Batch: 1160. Acc: 0.462525. Loss: 1.496147. Batch_acc: 0.485944. Batch_loss: 1.409754 \n",
      "Batch: 1161. Acc: 0.462541. Loss: 1.496103. Batch_acc: 0.480204. Batch_loss: 1.445652 \n",
      "Batch: 1162. Acc: 0.462540. Loss: 1.496114. Batch_acc: 0.461447. Batch_loss: 1.509068 \n",
      "Batch: 1163. Acc: 0.462557. Loss: 1.496056. Batch_acc: 0.481731. Batch_loss: 1.430525 \n",
      "Batch: 1164. Acc: 0.462561. Loss: 1.496034. Batch_acc: 0.467295. Batch_loss: 1.468902 \n",
      "Batch: 1165. Acc: 0.462584. Loss: 1.495976. Batch_acc: 0.489278. Batch_loss: 1.429993 \n",
      "Batch: 1166. Acc: 0.462586. Loss: 1.495992. Batch_acc: 0.464368. Batch_loss: 1.514764 \n",
      "Batch: 1167. Acc: 0.462583. Loss: 1.495984. Batch_acc: 0.459382. Batch_loss: 1.486908 \n",
      "Batch: 1168. Acc: 0.462570. Loss: 1.496002. Batch_acc: 0.447460. Batch_loss: 1.517347 \n",
      "Batch: 1169. Acc: 0.462557. Loss: 1.496015. Batch_acc: 0.447863. Batch_loss: 1.510345 \n",
      "Batch: 1170. Acc: 0.462579. Loss: 1.495985. Batch_acc: 0.487654. Batch_loss: 1.461863 \n",
      "Batch: 1171. Acc: 0.462608. Loss: 1.495912. Batch_acc: 0.495702. Batch_loss: 1.410815 \n",
      "Batch: 1172. Acc: 0.462624. Loss: 1.495894. Batch_acc: 0.482353. Batch_loss: 1.474795 \n",
      "Batch: 1173. Acc: 0.462641. Loss: 1.495855. Batch_acc: 0.482031. Batch_loss: 1.450493 \n",
      "Batch: 1174. Acc: 0.462648. Loss: 1.495841. Batch_acc: 0.471478. Batch_loss: 1.479363 \n",
      "Batch: 1175. Acc: 0.462619. Loss: 1.495920. Batch_acc: 0.428896. Batch_loss: 1.587054 \n",
      "Batch: 1176. Acc: 0.462623. Loss: 1.495895. Batch_acc: 0.467124. Batch_loss: 1.467457 \n",
      "Batch: 1177. Acc: 0.462621. Loss: 1.495884. Batch_acc: 0.459896. Batch_loss: 1.482394 \n",
      "Batch: 1178. Acc: 0.462617. Loss: 1.495906. Batch_acc: 0.458382. Batch_loss: 1.522001 \n",
      "Batch: 1179. Acc: 0.462632. Loss: 1.495892. Batch_acc: 0.479815. Batch_loss: 1.479050 \n",
      "Batch: 1180. Acc: 0.462634. Loss: 1.495891. Batch_acc: 0.465011. Batch_loss: 1.494582 \n",
      "Batch: 1181. Acc: 0.462658. Loss: 1.495811. Batch_acc: 0.491555. Batch_loss: 1.400671 \n",
      "Batch: 1182. Acc: 0.462649. Loss: 1.495845. Batch_acc: 0.452450. Batch_loss: 1.535437 \n",
      "Batch: 1183. Acc: 0.462646. Loss: 1.495828. Batch_acc: 0.459259. Batch_loss: 1.476277 \n",
      "Batch: 1184. Acc: 0.462649. Loss: 1.495804. Batch_acc: 0.465738. Batch_loss: 1.466695 \n",
      "Batch: 1185. Acc: 0.462672. Loss: 1.495756. Batch_acc: 0.489026. Batch_loss: 1.440349 \n",
      "Batch: 1186. Acc: 0.462679. Loss: 1.495715. Batch_acc: 0.471023. Batch_loss: 1.447802 \n",
      "Batch: 1187. Acc: 0.462698. Loss: 1.495676. Batch_acc: 0.484814. Batch_loss: 1.450104 \n",
      "Batch: 1188. Acc: 0.462691. Loss: 1.495686. Batch_acc: 0.454754. Batch_loss: 1.507512 \n",
      "Batch: 1189. Acc: 0.462702. Loss: 1.495689. Batch_acc: 0.475344. Batch_loss: 1.498827 \n",
      "Batch: 1190. Acc: 0.462706. Loss: 1.495672. Batch_acc: 0.467911. Batch_loss: 1.475710 \n",
      "Batch: 1191. Acc: 0.462717. Loss: 1.495653. Batch_acc: 0.475429. Batch_loss: 1.472503 \n",
      "Batch: 1192. Acc: 0.462732. Loss: 1.495618. Batch_acc: 0.480437. Batch_loss: 1.454206 \n",
      "Batch: 1193. Acc: 0.462746. Loss: 1.495565. Batch_acc: 0.479908. Batch_loss: 1.432533 \n",
      "Batch: 1194. Acc: 0.462755. Loss: 1.495538. Batch_acc: 0.473714. Batch_loss: 1.463706 \n",
      "Batch: 1195. Acc: 0.462757. Loss: 1.495506. Batch_acc: 0.465409. Batch_loss: 1.456914 \n",
      "Batch: 1196. Acc: 0.462775. Loss: 1.495491. Batch_acc: 0.483152. Batch_loss: 1.477548 \n",
      "Batch: 1197. Acc: 0.462794. Loss: 1.495459. Batch_acc: 0.485536. Batch_loss: 1.458079 \n",
      "Batch: 1198. Acc: 0.462802. Loss: 1.495413. Batch_acc: 0.472450. Batch_loss: 1.439486 \n",
      "Batch: 1199. Acc: 0.462831. Loss: 1.495371. Batch_acc: 0.497433. Batch_loss: 1.444821 \n",
      "Batch: 1200. Acc: 0.462836. Loss: 1.495348. Batch_acc: 0.469213. Batch_loss: 1.468246 \n",
      "Batch: 1201. Acc: 0.462840. Loss: 1.495353. Batch_acc: 0.467656. Batch_loss: 1.501791 \n",
      "Batch: 1202. Acc: 0.462856. Loss: 1.495308. Batch_acc: 0.481697. Batch_loss: 1.441023 \n",
      "Batch: 1203. Acc: 0.462852. Loss: 1.495289. Batch_acc: 0.459053. Batch_loss: 1.472668 \n",
      "Batch: 1204. Acc: 0.462845. Loss: 1.495307. Batch_acc: 0.454390. Batch_loss: 1.517204 \n",
      "Batch: 1205. Acc: 0.462863. Loss: 1.495266. Batch_acc: 0.484655. Batch_loss: 1.445284 \n",
      "Batch: 1206. Acc: 0.462846. Loss: 1.495303. Batch_acc: 0.441452. Batch_loss: 1.541113 \n",
      "Batch: 1207. Acc: 0.462836. Loss: 1.495329. Batch_acc: 0.451084. Batch_loss: 1.527003 \n",
      "Batch: 1208. Acc: 0.462840. Loss: 1.495331. Batch_acc: 0.467360. Batch_loss: 1.497382 \n",
      "Batch: 1209. Acc: 0.462840. Loss: 1.495313. Batch_acc: 0.462389. Batch_loss: 1.474581 \n",
      "Batch: 1210. Acc: 0.462849. Loss: 1.495299. Batch_acc: 0.473508. Batch_loss: 1.478709 \n",
      "Batch: 1211. Acc: 0.462851. Loss: 1.495288. Batch_acc: 0.465238. Batch_loss: 1.481683 \n",
      "Batch: 1212. Acc: 0.462842. Loss: 1.495313. Batch_acc: 0.451951. Batch_loss: 1.526086 \n",
      "Batch: 1213. Acc: 0.462840. Loss: 1.495319. Batch_acc: 0.460549. Batch_loss: 1.503498 \n",
      "Batch: 1214. Acc: 0.462862. Loss: 1.495269. Batch_acc: 0.489518. Batch_loss: 1.435203 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1215. Acc: 0.462864. Loss: 1.495277. Batch_acc: 0.465009. Batch_loss: 1.505510 \n",
      "Batch: 1216. Acc: 0.462855. Loss: 1.495282. Batch_acc: 0.451594. Batch_loss: 1.500956 \n",
      "Batch: 1217. Acc: 0.462855. Loss: 1.495240. Batch_acc: 0.463401. Batch_loss: 1.444727 \n",
      "Batch: 1218. Acc: 0.462858. Loss: 1.495241. Batch_acc: 0.466205. Batch_loss: 1.496882 \n",
      "Batch: 1219. Acc: 0.462862. Loss: 1.495231. Batch_acc: 0.467874. Batch_loss: 1.482906 \n",
      "Batch: 1220. Acc: 0.462873. Loss: 1.495190. Batch_acc: 0.476630. Batch_loss: 1.445460 \n",
      "Batch: 1221. Acc: 0.462883. Loss: 1.495177. Batch_acc: 0.474783. Batch_loss: 1.478723 \n",
      "Batch: 1222. Acc: 0.462881. Loss: 1.495211. Batch_acc: 0.460802. Batch_loss: 1.538787 \n",
      "Batch: 1223. Acc: 0.462899. Loss: 1.495186. Batch_acc: 0.484778. Batch_loss: 1.463900 \n",
      "Batch: 1224. Acc: 0.462911. Loss: 1.495162. Batch_acc: 0.478136. Batch_loss: 1.465811 \n",
      "Batch: 1225. Acc: 0.462923. Loss: 1.495131. Batch_acc: 0.477233. Batch_loss: 1.456451 \n",
      "Batch: 1226. Acc: 0.462949. Loss: 1.495066. Batch_acc: 0.493543. Batch_loss: 1.417563 \n",
      "Batch: 1227. Acc: 0.462955. Loss: 1.495030. Batch_acc: 0.470554. Batch_loss: 1.451334 \n",
      "Batch: 1228. Acc: 0.462947. Loss: 1.495029. Batch_acc: 0.453966. Batch_loss: 1.493396 \n",
      "Batch: 1229. Acc: 0.462953. Loss: 1.495020. Batch_acc: 0.470012. Batch_loss: 1.484525 \n",
      "Batch: 1230. Acc: 0.462963. Loss: 1.494990. Batch_acc: 0.474783. Batch_loss: 1.457233 \n",
      "Batch: 1231. Acc: 0.462964. Loss: 1.494972. Batch_acc: 0.464450. Batch_loss: 1.473433 \n",
      "Batch: 1232. Acc: 0.462962. Loss: 1.494970. Batch_acc: 0.460896. Batch_loss: 1.492460 \n",
      "Batch: 1233. Acc: 0.462967. Loss: 1.494968. Batch_acc: 0.468427. Batch_loss: 1.491442 \n",
      "Batch: 1234. Acc: 0.462972. Loss: 1.494949. Batch_acc: 0.470006. Batch_loss: 1.472160 \n",
      "Batch: 1235. Acc: 0.462975. Loss: 1.494941. Batch_acc: 0.466590. Batch_loss: 1.484198 \n",
      "Batch: 1236. Acc: 0.462976. Loss: 1.494948. Batch_acc: 0.463658. Batch_loss: 1.504571 \n",
      "Batch: 1237. Acc: 0.462970. Loss: 1.494951. Batch_acc: 0.455451. Batch_loss: 1.497854 \n",
      "Batch: 1238. Acc: 0.462978. Loss: 1.494910. Batch_acc: 0.473469. Batch_loss: 1.443395 \n",
      "Batch: 1239. Acc: 0.462970. Loss: 1.494929. Batch_acc: 0.452103. Batch_loss: 1.519808 \n",
      "Batch: 1240. Acc: 0.462973. Loss: 1.494908. Batch_acc: 0.466592. Batch_loss: 1.469080 \n",
      "Batch: 1241. Acc: 0.462981. Loss: 1.494909. Batch_acc: 0.472943. Batch_loss: 1.496022 \n",
      "Batch: 1242. Acc: 0.462970. Loss: 1.494943. Batch_acc: 0.449309. Batch_loss: 1.537633 \n",
      "Batch: 1243. Acc: 0.462959. Loss: 1.494954. Batch_acc: 0.450142. Batch_loss: 1.507665 \n",
      "Batch: 1244. Acc: 0.462944. Loss: 1.494998. Batch_acc: 0.444121. Batch_loss: 1.550283 \n",
      "Batch: 1245. Acc: 0.462936. Loss: 1.495000. Batch_acc: 0.451744. Batch_loss: 1.498710 \n",
      "Batch: 1246. Acc: 0.462941. Loss: 1.494998. Batch_acc: 0.469435. Batch_loss: 1.491564 \n",
      "Batch: 1247. Acc: 0.462935. Loss: 1.495003. Batch_acc: 0.456005. Batch_loss: 1.502013 \n",
      "Batch: 1248. Acc: 0.462924. Loss: 1.495020. Batch_acc: 0.449374. Batch_loss: 1.516094 \n",
      "Batch: 1249. Acc: 0.462937. Loss: 1.495023. Batch_acc: 0.478681. Batch_loss: 1.498730 \n",
      "Batch: 1250. Acc: 0.462955. Loss: 1.495003. Batch_acc: 0.484952. Batch_loss: 1.469655 \n",
      "Batch: 1251. Acc: 0.462949. Loss: 1.495010. Batch_acc: 0.454920. Batch_loss: 1.504408 \n",
      "Batch: 1252. Acc: 0.462968. Loss: 1.494974. Batch_acc: 0.487536. Batch_loss: 1.449083 \n",
      "Batch: 1253. Acc: 0.462998. Loss: 1.494924. Batch_acc: 0.500000. Batch_loss: 1.433916 \n",
      "Batch: 1254. Acc: 0.462992. Loss: 1.494919. Batch_acc: 0.455594. Batch_loss: 1.488677 \n",
      "Batch: 1255. Acc: 0.463006. Loss: 1.494866. Batch_acc: 0.480023. Batch_loss: 1.428451 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.4630059503898958. Loss per char: 1.4948659415102112. Time: 1627215107.372121\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 17, 15, 21,  1, 12,  1, 19,\n",
      "        18, 19, 22, 21, 18, 20, 17, 15, 17, 22, 19, 25, 22, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.463008. Loss: 1.494854. Batch_acc: 0.465975. Batch_loss: 1.479840 \n",
      "Batch: 1257. Acc: 0.463022. Loss: 1.494842. Batch_acc: 0.479792. Batch_loss: 1.479579 \n",
      "Batch: 1258. Acc: 0.463021. Loss: 1.494836. Batch_acc: 0.461938. Batch_loss: 1.486974 \n",
      "Batch: 1259. Acc: 0.463023. Loss: 1.494833. Batch_acc: 0.466174. Batch_loss: 1.491236 \n",
      "Batch: 1260. Acc: 0.463040. Loss: 1.494778. Batch_acc: 0.483926. Batch_loss: 1.426520 \n",
      "Batch: 1261. Acc: 0.463054. Loss: 1.494730. Batch_acc: 0.480278. Batch_loss: 1.434009 \n",
      "Batch: 1262. Acc: 0.463056. Loss: 1.494737. Batch_acc: 0.465809. Batch_loss: 1.503999 \n",
      "Batch: 1263. Acc: 0.463056. Loss: 1.494740. Batch_acc: 0.463206. Batch_loss: 1.499002 \n",
      "Batch: 1264. Acc: 0.463065. Loss: 1.494698. Batch_acc: 0.474143. Batch_loss: 1.440928 \n",
      "Batch: 1265. Acc: 0.463066. Loss: 1.494722. Batch_acc: 0.465047. Batch_loss: 1.525501 \n",
      "Batch: 1266. Acc: 0.463050. Loss: 1.494728. Batch_acc: 0.442087. Batch_loss: 1.502783 \n",
      "Batch: 1267. Acc: 0.463064. Loss: 1.494705. Batch_acc: 0.481611. Batch_loss: 1.465415 \n",
      "Batch: 1268. Acc: 0.463092. Loss: 1.494648. Batch_acc: 0.497231. Batch_loss: 1.424898 \n",
      "Batch: 1269. Acc: 0.463090. Loss: 1.494660. Batch_acc: 0.460011. Batch_loss: 1.509613 \n",
      "Batch: 1270. Acc: 0.463088. Loss: 1.494689. Batch_acc: 0.460767. Batch_loss: 1.532112 \n",
      "Batch: 1271. Acc: 0.463098. Loss: 1.494659. Batch_acc: 0.475354. Batch_loss: 1.456585 \n",
      "Batch: 1272. Acc: 0.463111. Loss: 1.494626. Batch_acc: 0.479795. Batch_loss: 1.453948 \n",
      "Batch: 1273. Acc: 0.463109. Loss: 1.494654. Batch_acc: 0.460253. Batch_loss: 1.529924 \n",
      "Batch: 1274. Acc: 0.463121. Loss: 1.494616. Batch_acc: 0.478921. Batch_loss: 1.447319 \n",
      "Batch: 1275. Acc: 0.463129. Loss: 1.494602. Batch_acc: 0.472428. Batch_loss: 1.477736 \n",
      "Batch: 1276. Acc: 0.463133. Loss: 1.494597. Batch_acc: 0.468785. Batch_loss: 1.487891 \n",
      "Batch: 1277. Acc: 0.463135. Loss: 1.494614. Batch_acc: 0.466014. Batch_loss: 1.516102 \n",
      "Batch: 1278. Acc: 0.463136. Loss: 1.494593. Batch_acc: 0.464060. Batch_loss: 1.467344 \n",
      "Batch: 1279. Acc: 0.463127. Loss: 1.494627. Batch_acc: 0.451613. Batch_loss: 1.537588 \n",
      "Batch: 1280. Acc: 0.463123. Loss: 1.494623. Batch_acc: 0.458215. Batch_loss: 1.489565 \n",
      "Batch: 1281. Acc: 0.463135. Loss: 1.494605. Batch_acc: 0.477984. Batch_loss: 1.472263 \n",
      "Batch: 1282. Acc: 0.463158. Loss: 1.494538. Batch_acc: 0.493039. Batch_loss: 1.407130 \n",
      "Batch: 1283. Acc: 0.463159. Loss: 1.494536. Batch_acc: 0.464646. Batch_loss: 1.491994 \n",
      "Batch: 1284. Acc: 0.463157. Loss: 1.494546. Batch_acc: 0.461124. Batch_loss: 1.507866 \n",
      "Batch: 1285. Acc: 0.463177. Loss: 1.494497. Batch_acc: 0.489298. Batch_loss: 1.429441 \n",
      "Batch: 1286. Acc: 0.463174. Loss: 1.494500. Batch_acc: 0.459091. Batch_loss: 1.498303 \n",
      "Batch: 1287. Acc: 0.463171. Loss: 1.494512. Batch_acc: 0.459659. Batch_loss: 1.509322 \n",
      "Batch: 1288. Acc: 0.463175. Loss: 1.494495. Batch_acc: 0.468362. Batch_loss: 1.473262 \n",
      "Batch: 1289. Acc: 0.463183. Loss: 1.494483. Batch_acc: 0.473985. Batch_loss: 1.479001 \n",
      "Batch: 1290. Acc: 0.463194. Loss: 1.494451. Batch_acc: 0.476940. Batch_loss: 1.453335 \n",
      "Batch: 1291. Acc: 0.463213. Loss: 1.494410. Batch_acc: 0.486746. Batch_loss: 1.443092 \n",
      "Batch: 1292. Acc: 0.463223. Loss: 1.494373. Batch_acc: 0.476415. Batch_loss: 1.444669 \n",
      "Batch: 1293. Acc: 0.463227. Loss: 1.494358. Batch_acc: 0.468875. Batch_loss: 1.476033 \n",
      "Batch: 1294. Acc: 0.463226. Loss: 1.494358. Batch_acc: 0.461808. Batch_loss: 1.493318 \n",
      "Batch: 1295. Acc: 0.463245. Loss: 1.494284. Batch_acc: 0.487165. Batch_loss: 1.399961 \n",
      "Batch: 1296. Acc: 0.463228. Loss: 1.494328. Batch_acc: 0.441420. Batch_loss: 1.552847 \n",
      "Batch: 1297. Acc: 0.463240. Loss: 1.494280. Batch_acc: 0.478559. Batch_loss: 1.432060 \n",
      "Batch: 1298. Acc: 0.463240. Loss: 1.494282. Batch_acc: 0.462209. Batch_loss: 1.497736 \n",
      "Batch: 1299. Acc: 0.463234. Loss: 1.494272. Batch_acc: 0.456706. Batch_loss: 1.481246 \n",
      "Batch: 1300. Acc: 0.463253. Loss: 1.494217. Batch_acc: 0.487917. Batch_loss: 1.422668 \n",
      "Batch: 1301. Acc: 0.463281. Loss: 1.494146. Batch_acc: 0.498561. Batch_loss: 1.401726 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1302. Acc: 0.463283. Loss: 1.494114. Batch_acc: 0.466628. Batch_loss: 1.452002 \n",
      "Batch: 1303. Acc: 0.463302. Loss: 1.494048. Batch_acc: 0.487252. Batch_loss: 1.408591 \n",
      "Batch: 1304. Acc: 0.463315. Loss: 1.493997. Batch_acc: 0.479730. Batch_loss: 1.428990 \n",
      "Batch: 1305. Acc: 0.463331. Loss: 1.493946. Batch_acc: 0.484321. Batch_loss: 1.426545 \n",
      "Batch: 1306. Acc: 0.463325. Loss: 1.493948. Batch_acc: 0.455446. Batch_loss: 1.497811 \n",
      "Batch: 1307. Acc: 0.463339. Loss: 1.493920. Batch_acc: 0.482759. Batch_loss: 1.456727 \n",
      "Batch: 1308. Acc: 0.463328. Loss: 1.493962. Batch_acc: 0.447337. Batch_loss: 1.551339 \n",
      "Batch: 1309. Acc: 0.463354. Loss: 1.493894. Batch_acc: 0.497976. Batch_loss: 1.404034 \n",
      "Batch: 1310. Acc: 0.463358. Loss: 1.493870. Batch_acc: 0.468981. Batch_loss: 1.462960 \n",
      "Batch: 1311. Acc: 0.463370. Loss: 1.493837. Batch_acc: 0.478778. Batch_loss: 1.450723 \n",
      "Batch: 1312. Acc: 0.463371. Loss: 1.493832. Batch_acc: 0.464887. Batch_loss: 1.488350 \n",
      "Batch: 1313. Acc: 0.463366. Loss: 1.493841. Batch_acc: 0.456200. Batch_loss: 1.505558 \n",
      "Batch: 1314. Acc: 0.463368. Loss: 1.493839. Batch_acc: 0.466782. Batch_loss: 1.490785 \n",
      "Batch: 1315. Acc: 0.463376. Loss: 1.493818. Batch_acc: 0.473807. Batch_loss: 1.465530 \n",
      "Batch: 1316. Acc: 0.463381. Loss: 1.493800. Batch_acc: 0.469052. Batch_loss: 1.470789 \n",
      "Batch: 1317. Acc: 0.463381. Loss: 1.493799. Batch_acc: 0.464118. Batch_loss: 1.491642 \n",
      "Batch: 1318. Acc: 0.463392. Loss: 1.493761. Batch_acc: 0.477861. Batch_loss: 1.443869 \n",
      "Batch: 1319. Acc: 0.463388. Loss: 1.493789. Batch_acc: 0.457944. Batch_loss: 1.531875 \n",
      "Batch: 1320. Acc: 0.463404. Loss: 1.493756. Batch_acc: 0.483781. Batch_loss: 1.451795 \n",
      "Batch: 1321. Acc: 0.463404. Loss: 1.493741. Batch_acc: 0.462963. Batch_loss: 1.473174 \n",
      "Batch: 1322. Acc: 0.463409. Loss: 1.493728. Batch_acc: 0.470385. Batch_loss: 1.476050 \n",
      "Batch: 1323. Acc: 0.463420. Loss: 1.493695. Batch_acc: 0.478338. Batch_loss: 1.449478 \n",
      "Batch: 1324. Acc: 0.463444. Loss: 1.493600. Batch_acc: 0.494702. Batch_loss: 1.372064 \n",
      "Batch: 1325. Acc: 0.463442. Loss: 1.493597. Batch_acc: 0.460779. Batch_loss: 1.489506 \n",
      "Batch: 1326. Acc: 0.463449. Loss: 1.493568. Batch_acc: 0.472303. Batch_loss: 1.453919 \n",
      "Batch: 1327. Acc: 0.463428. Loss: 1.493563. Batch_acc: 0.435868. Batch_loss: 1.486837 \n",
      "Batch: 1328. Acc: 0.463419. Loss: 1.493586. Batch_acc: 0.450935. Batch_loss: 1.524513 \n",
      "Batch: 1329. Acc: 0.463428. Loss: 1.493573. Batch_acc: 0.475072. Batch_loss: 1.476472 \n",
      "Batch: 1330. Acc: 0.463440. Loss: 1.493550. Batch_acc: 0.479954. Batch_loss: 1.463218 \n",
      "Batch: 1331. Acc: 0.463433. Loss: 1.493556. Batch_acc: 0.453190. Batch_loss: 1.502007 \n",
      "Batch: 1332. Acc: 0.463435. Loss: 1.493557. Batch_acc: 0.466247. Batch_loss: 1.494573 \n",
      "Batch: 1333. Acc: 0.463446. Loss: 1.493525. Batch_acc: 0.478767. Batch_loss: 1.450274 \n",
      "Batch: 1334. Acc: 0.463455. Loss: 1.493477. Batch_acc: 0.474860. Batch_loss: 1.431752 \n",
      "Batch: 1335. Acc: 0.463481. Loss: 1.493385. Batch_acc: 0.497719. Batch_loss: 1.371951 \n",
      "Batch: 1336. Acc: 0.463491. Loss: 1.493357. Batch_acc: 0.477326. Batch_loss: 1.454793 \n",
      "Batch: 1337. Acc: 0.463505. Loss: 1.493334. Batch_acc: 0.481865. Batch_loss: 1.463476 \n",
      "Batch: 1338. Acc: 0.463507. Loss: 1.493320. Batch_acc: 0.466315. Batch_loss: 1.474402 \n",
      "Batch: 1339. Acc: 0.463531. Loss: 1.493237. Batch_acc: 0.495112. Batch_loss: 1.381676 \n",
      "Batch: 1340. Acc: 0.463541. Loss: 1.493218. Batch_acc: 0.477401. Batch_loss: 1.468567 \n",
      "Batch: 1341. Acc: 0.463542. Loss: 1.493207. Batch_acc: 0.464997. Batch_loss: 1.477959 \n",
      "Batch: 1342. Acc: 0.463562. Loss: 1.493180. Batch_acc: 0.489902. Batch_loss: 1.456846 \n",
      "Batch: 1343. Acc: 0.463549. Loss: 1.493207. Batch_acc: 0.445797. Batch_loss: 1.530430 \n",
      "Batch: 1344. Acc: 0.463547. Loss: 1.493202. Batch_acc: 0.461538. Batch_loss: 1.486777 \n",
      "Batch: 1345. Acc: 0.463540. Loss: 1.493223. Batch_acc: 0.453747. Batch_loss: 1.521942 \n",
      "Batch: 1346. Acc: 0.463549. Loss: 1.493189. Batch_acc: 0.475485. Batch_loss: 1.447647 \n",
      "Batch: 1347. Acc: 0.463568. Loss: 1.493158. Batch_acc: 0.488839. Batch_loss: 1.451837 \n",
      "Batch: 1348. Acc: 0.463584. Loss: 1.493116. Batch_acc: 0.484055. Batch_loss: 1.437806 \n",
      "Batch: 1349. Acc: 0.463594. Loss: 1.493099. Batch_acc: 0.478134. Batch_loss: 1.470118 \n",
      "Batch: 1350. Acc: 0.463607. Loss: 1.493061. Batch_acc: 0.479977. Batch_loss: 1.441581 \n",
      "Batch: 1351. Acc: 0.463621. Loss: 1.493030. Batch_acc: 0.483796. Batch_loss: 1.451498 \n",
      "Batch: 1352. Acc: 0.463630. Loss: 1.493005. Batch_acc: 0.474800. Batch_loss: 1.458993 \n",
      "Batch: 1353. Acc: 0.463637. Loss: 1.493000. Batch_acc: 0.473958. Batch_loss: 1.485579 \n",
      "Batch: 1354. Acc: 0.463646. Loss: 1.492951. Batch_acc: 0.475305. Batch_loss: 1.426637 \n",
      "Batch: 1355. Acc: 0.463647. Loss: 1.492953. Batch_acc: 0.464589. Batch_loss: 1.495019 \n",
      "Batch: 1356. Acc: 0.463657. Loss: 1.492927. Batch_acc: 0.477352. Batch_loss: 1.457785 \n",
      "Batch: 1357. Acc: 0.463650. Loss: 1.492947. Batch_acc: 0.454286. Batch_loss: 1.520087 \n",
      "Batch: 1358. Acc: 0.463667. Loss: 1.492906. Batch_acc: 0.487400. Batch_loss: 1.437309 \n",
      "Batch: 1359. Acc: 0.463684. Loss: 1.492893. Batch_acc: 0.487047. Batch_loss: 1.475016 \n",
      "Batch: 1360. Acc: 0.463698. Loss: 1.492878. Batch_acc: 0.482143. Batch_loss: 1.473885 \n",
      "Batch: 1361. Acc: 0.463717. Loss: 1.492856. Batch_acc: 0.488927. Batch_loss: 1.462298 \n",
      "Batch: 1362. Acc: 0.463723. Loss: 1.492811. Batch_acc: 0.472254. Batch_loss: 1.433578 \n",
      "Batch: 1363. Acc: 0.463734. Loss: 1.492774. Batch_acc: 0.478436. Batch_loss: 1.441550 \n",
      "Batch: 1364. Acc: 0.463743. Loss: 1.492738. Batch_acc: 0.475834. Batch_loss: 1.443735 \n",
      "Batch: 1365. Acc: 0.463764. Loss: 1.492703. Batch_acc: 0.492754. Batch_loss: 1.444580 \n",
      "Batch: 1366. Acc: 0.463781. Loss: 1.492660. Batch_acc: 0.487136. Batch_loss: 1.434963 \n",
      "Batch: 1367. Acc: 0.463784. Loss: 1.492646. Batch_acc: 0.467166. Batch_loss: 1.472427 \n",
      "Batch: 1368. Acc: 0.463790. Loss: 1.492606. Batch_acc: 0.471667. Batch_loss: 1.440658 \n",
      "Batch: 1369. Acc: 0.463802. Loss: 1.492592. Batch_acc: 0.480248. Batch_loss: 1.472870 \n",
      "Batch: 1370. Acc: 0.463807. Loss: 1.492558. Batch_acc: 0.470920. Batch_loss: 1.447769 \n",
      "Batch: 1371. Acc: 0.463804. Loss: 1.492573. Batch_acc: 0.458683. Batch_loss: 1.513156 \n",
      "Batch: 1372. Acc: 0.463812. Loss: 1.492567. Batch_acc: 0.474586. Batch_loss: 1.484249 \n",
      "Batch: 1373. Acc: 0.463820. Loss: 1.492545. Batch_acc: 0.475589. Batch_loss: 1.463182 \n",
      "Batch: 1374. Acc: 0.463811. Loss: 1.492538. Batch_acc: 0.451261. Batch_loss: 1.483099 \n",
      "Batch: 1375. Acc: 0.463828. Loss: 1.492497. Batch_acc: 0.486049. Batch_loss: 1.437740 \n",
      "Batch: 1376. Acc: 0.463847. Loss: 1.492432. Batch_acc: 0.490341. Batch_loss: 1.404361 \n",
      "Batch: 1377. Acc: 0.463858. Loss: 1.492406. Batch_acc: 0.478134. Batch_loss: 1.455423 \n",
      "Batch: 1378. Acc: 0.463866. Loss: 1.492396. Batch_acc: 0.476246. Batch_loss: 1.478631 \n",
      "Batch: 1379. Acc: 0.463873. Loss: 1.492381. Batch_acc: 0.472503. Batch_loss: 1.472191 \n",
      "Batch: 1380. Acc: 0.463893. Loss: 1.492325. Batch_acc: 0.491766. Batch_loss: 1.415802 \n",
      "Batch: 1381. Acc: 0.463899. Loss: 1.492314. Batch_acc: 0.472028. Batch_loss: 1.477214 \n",
      "Batch: 1382. Acc: 0.463928. Loss: 1.492265. Batch_acc: 0.505009. Batch_loss: 1.423335 \n",
      "Batch: 1383. Acc: 0.463939. Loss: 1.492264. Batch_acc: 0.479627. Batch_loss: 1.490939 \n",
      "Batch: 1384. Acc: 0.463928. Loss: 1.492284. Batch_acc: 0.448316. Batch_loss: 1.520001 \n",
      "Batch: 1385. Acc: 0.463948. Loss: 1.492261. Batch_acc: 0.490609. Batch_loss: 1.460615 \n",
      "Batch: 1386. Acc: 0.463953. Loss: 1.492215. Batch_acc: 0.471503. Batch_loss: 1.428246 \n",
      "Batch: 1387. Acc: 0.463957. Loss: 1.492200. Batch_acc: 0.468913. Batch_loss: 1.471915 \n",
      "Batch: 1388. Acc: 0.463950. Loss: 1.492222. Batch_acc: 0.454231. Batch_loss: 1.521694 \n",
      "Batch: 1389. Acc: 0.463936. Loss: 1.492240. Batch_acc: 0.443783. Batch_loss: 1.518143 \n",
      "Batch: 1390. Acc: 0.463936. Loss: 1.492200. Batch_acc: 0.464245. Batch_loss: 1.437747 \n",
      "Batch: 1391. Acc: 0.463933. Loss: 1.492203. Batch_acc: 0.460047. Batch_loss: 1.496046 \n",
      "Batch: 1392. Acc: 0.463942. Loss: 1.492191. Batch_acc: 0.476273. Batch_loss: 1.475892 \n",
      "Batch: 1393. Acc: 0.463943. Loss: 1.492180. Batch_acc: 0.465981. Batch_loss: 1.477034 \n",
      "Batch: 1394. Acc: 0.463955. Loss: 1.492151. Batch_acc: 0.480611. Batch_loss: 1.451439 \n",
      "Batch: 1395. Acc: 0.463960. Loss: 1.492122. Batch_acc: 0.471323. Batch_loss: 1.452114 \n",
      "Batch: 1396. Acc: 0.463955. Loss: 1.492129. Batch_acc: 0.456109. Batch_loss: 1.502189 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1397. Acc: 0.463962. Loss: 1.492118. Batch_acc: 0.474221. Batch_loss: 1.476881 \n",
      "Batch: 1398. Acc: 0.463967. Loss: 1.492106. Batch_acc: 0.470622. Batch_loss: 1.475136 \n",
      "Batch: 1399. Acc: 0.463964. Loss: 1.492112. Batch_acc: 0.459871. Batch_loss: 1.500303 \n",
      "Batch: 1400. Acc: 0.463982. Loss: 1.492061. Batch_acc: 0.488229. Batch_loss: 1.422276 \n",
      "Batch: 1401. Acc: 0.463995. Loss: 1.492032. Batch_acc: 0.482060. Batch_loss: 1.452418 \n",
      "Batch: 1402. Acc: 0.463988. Loss: 1.492032. Batch_acc: 0.453772. Batch_loss: 1.491273 \n",
      "Batch: 1403. Acc: 0.463994. Loss: 1.492029. Batch_acc: 0.472509. Batch_loss: 1.487865 \n",
      "Batch: 1404. Acc: 0.463987. Loss: 1.492067. Batch_acc: 0.453963. Batch_loss: 1.545880 \n",
      "Batch: 1405. Acc: 0.463981. Loss: 1.492057. Batch_acc: 0.456356. Batch_loss: 1.478128 \n",
      "Batch: 1406. Acc: 0.463980. Loss: 1.492077. Batch_acc: 0.462309. Batch_loss: 1.520183 \n",
      "Batch: 1407. Acc: 0.463982. Loss: 1.492070. Batch_acc: 0.466591. Batch_loss: 1.482478 \n",
      "Batch: 1408. Acc: 0.463985. Loss: 1.492065. Batch_acc: 0.468195. Batch_loss: 1.485188 \n",
      "Batch: 1409. Acc: 0.463974. Loss: 1.492119. Batch_acc: 0.448056. Batch_loss: 1.569865 \n",
      "Batch: 1410. Acc: 0.463977. Loss: 1.492120. Batch_acc: 0.467986. Batch_loss: 1.493303 \n",
      "Batch: 1411. Acc: 0.463974. Loss: 1.492128. Batch_acc: 0.460630. Batch_loss: 1.502634 \n",
      "Batch: 1412. Acc: 0.463970. Loss: 1.492133. Batch_acc: 0.457637. Batch_loss: 1.499972 \n",
      "Batch: 1413. Acc: 0.463969. Loss: 1.492140. Batch_acc: 0.463529. Batch_loss: 1.501705 \n",
      "Batch: 1414. Acc: 0.463978. Loss: 1.492105. Batch_acc: 0.476540. Batch_loss: 1.443234 \n",
      "Batch: 1415. Acc: 0.463987. Loss: 1.492106. Batch_acc: 0.476136. Batch_loss: 1.494238 \n",
      "Batch: 1416. Acc: 0.463984. Loss: 1.492108. Batch_acc: 0.459119. Batch_loss: 1.494338 \n",
      "Batch: 1417. Acc: 0.463989. Loss: 1.492068. Batch_acc: 0.471677. Batch_loss: 1.437053 \n",
      "Batch: 1418. Acc: 0.463986. Loss: 1.492077. Batch_acc: 0.459195. Batch_loss: 1.504184 \n",
      "Batch: 1419. Acc: 0.463988. Loss: 1.492082. Batch_acc: 0.466511. Batch_loss: 1.499017 \n",
      "Batch: 1420. Acc: 0.464000. Loss: 1.492059. Batch_acc: 0.481948. Batch_loss: 1.459616 \n",
      "Batch: 1421. Acc: 0.464010. Loss: 1.492044. Batch_acc: 0.477207. Batch_loss: 1.471721 \n",
      "Batch: 1422. Acc: 0.463998. Loss: 1.492095. Batch_acc: 0.447813. Batch_loss: 1.565278 \n",
      "Batch: 1423. Acc: 0.464014. Loss: 1.492074. Batch_acc: 0.487047. Batch_loss: 1.462006 \n",
      "Batch: 1424. Acc: 0.464013. Loss: 1.492083. Batch_acc: 0.461985. Batch_loss: 1.505402 \n",
      "Batch: 1425. Acc: 0.464020. Loss: 1.492073. Batch_acc: 0.474044. Batch_loss: 1.478186 \n",
      "Batch: 1426. Acc: 0.464026. Loss: 1.492083. Batch_acc: 0.472591. Batch_loss: 1.505887 \n",
      "Batch: 1427. Acc: 0.464024. Loss: 1.492136. Batch_acc: 0.460534. Batch_loss: 1.570691 \n",
      "Batch: 1428. Acc: 0.464034. Loss: 1.492112. Batch_acc: 0.478236. Batch_loss: 1.456411 \n",
      "Batch: 1429. Acc: 0.464030. Loss: 1.492112. Batch_acc: 0.459123. Batch_loss: 1.492751 \n",
      "Batch: 1430. Acc: 0.464039. Loss: 1.492104. Batch_acc: 0.475998. Batch_loss: 1.479935 \n",
      "Batch: 1431. Acc: 0.464030. Loss: 1.492113. Batch_acc: 0.452109. Batch_loss: 1.505288 \n",
      "Batch: 1432. Acc: 0.464044. Loss: 1.492091. Batch_acc: 0.483362. Batch_loss: 1.461088 \n",
      "Batch: 1433. Acc: 0.464043. Loss: 1.492106. Batch_acc: 0.463158. Batch_loss: 1.514350 \n",
      "Batch: 1434. Acc: 0.464051. Loss: 1.492089. Batch_acc: 0.474615. Batch_loss: 1.467200 \n",
      "Batch: 1435. Acc: 0.464060. Loss: 1.492072. Batch_acc: 0.477390. Batch_loss: 1.468612 \n",
      "Batch: 1436. Acc: 0.464072. Loss: 1.492043. Batch_acc: 0.481871. Batch_loss: 1.448843 \n",
      "Batch: 1437. Acc: 0.464063. Loss: 1.492056. Batch_acc: 0.449971. Batch_loss: 1.510821 \n",
      "Batch: 1438. Acc: 0.464059. Loss: 1.492057. Batch_acc: 0.459054. Batch_loss: 1.493497 \n",
      "Batch: 1439. Acc: 0.464060. Loss: 1.492067. Batch_acc: 0.464862. Batch_loss: 1.507370 \n",
      "Batch: 1440. Acc: 0.464074. Loss: 1.492029. Batch_acc: 0.484313. Batch_loss: 1.437023 \n",
      "Batch: 1441. Acc: 0.464088. Loss: 1.491998. Batch_acc: 0.483541. Batch_loss: 1.448790 \n",
      "Batch: 1442. Acc: 0.464117. Loss: 1.491911. Batch_acc: 0.506721. Batch_loss: 1.363483 \n",
      "Batch: 1443. Acc: 0.464106. Loss: 1.491933. Batch_acc: 0.449464. Batch_loss: 1.523942 \n",
      "Batch: 1444. Acc: 0.464101. Loss: 1.491953. Batch_acc: 0.457110. Batch_loss: 1.520153 \n",
      "Batch: 1445. Acc: 0.464107. Loss: 1.491942. Batch_acc: 0.472014. Batch_loss: 1.476036 \n",
      "Batch: 1446. Acc: 0.464099. Loss: 1.491959. Batch_acc: 0.452087. Batch_loss: 1.518000 \n",
      "Batch: 1447. Acc: 0.464115. Loss: 1.491895. Batch_acc: 0.487721. Batch_loss: 1.399812 \n",
      "Batch: 1448. Acc: 0.464120. Loss: 1.491883. Batch_acc: 0.471291. Batch_loss: 1.474280 \n",
      "Batch: 1449. Acc: 0.464104. Loss: 1.491919. Batch_acc: 0.439953. Batch_loss: 1.544627 \n",
      "Batch: 1450. Acc: 0.464076. Loss: 1.491991. Batch_acc: 0.423699. Batch_loss: 1.597872 \n",
      "Batch: 1451. Acc: 0.464079. Loss: 1.492002. Batch_acc: 0.468535. Batch_loss: 1.506814 \n",
      "Batch: 1452. Acc: 0.464068. Loss: 1.492020. Batch_acc: 0.447592. Batch_loss: 1.518802 \n",
      "Batch: 1453. Acc: 0.464061. Loss: 1.492036. Batch_acc: 0.455008. Batch_loss: 1.514061 \n",
      "Batch: 1454. Acc: 0.464067. Loss: 1.492048. Batch_acc: 0.472302. Batch_loss: 1.509617 \n",
      "Batch: 1455. Acc: 0.464076. Loss: 1.492030. Batch_acc: 0.477663. Batch_loss: 1.466587 \n",
      "Batch: 1456. Acc: 0.464097. Loss: 1.491988. Batch_acc: 0.493700. Batch_loss: 1.430168 \n",
      "Batch: 1457. Acc: 0.464098. Loss: 1.491981. Batch_acc: 0.465467. Batch_loss: 1.481872 \n",
      "Batch: 1458. Acc: 0.464111. Loss: 1.491961. Batch_acc: 0.483761. Batch_loss: 1.462855 \n",
      "Batch: 1459. Acc: 0.464116. Loss: 1.491952. Batch_acc: 0.470120. Batch_loss: 1.479699 \n",
      "Batch: 1460. Acc: 0.464127. Loss: 1.491917. Batch_acc: 0.480157. Batch_loss: 1.442557 \n",
      "Batch: 1461. Acc: 0.464119. Loss: 1.491924. Batch_acc: 0.452297. Batch_loss: 1.501231 \n",
      "Batch: 1462. Acc: 0.464117. Loss: 1.491903. Batch_acc: 0.461494. Batch_loss: 1.461460 \n",
      "Batch: 1463. Acc: 0.464135. Loss: 1.491847. Batch_acc: 0.489173. Batch_loss: 1.413094 \n",
      "Batch: 1464. Acc: 0.464136. Loss: 1.491842. Batch_acc: 0.466247. Batch_loss: 1.484749 \n",
      "Batch: 1465. Acc: 0.464131. Loss: 1.491840. Batch_acc: 0.455916. Batch_loss: 1.489061 \n",
      "Batch: 1466. Acc: 0.464131. Loss: 1.491856. Batch_acc: 0.464286. Batch_loss: 1.514496 \n",
      "Batch: 1467. Acc: 0.464122. Loss: 1.491867. Batch_acc: 0.450234. Batch_loss: 1.508365 \n",
      "Batch: 1468. Acc: 0.464130. Loss: 1.491846. Batch_acc: 0.477232. Batch_loss: 1.459618 \n",
      "Batch: 1469. Acc: 0.464097. Loss: 1.491921. Batch_acc: 0.415429. Batch_loss: 1.602154 \n",
      "Batch: 1470. Acc: 0.464101. Loss: 1.491921. Batch_acc: 0.470065. Batch_loss: 1.491673 \n",
      "Batch: 1471. Acc: 0.464103. Loss: 1.491906. Batch_acc: 0.467779. Batch_loss: 1.469382 \n",
      "Batch: 1472. Acc: 0.464122. Loss: 1.491872. Batch_acc: 0.492694. Batch_loss: 1.441696 \n",
      "Batch: 1473. Acc: 0.464127. Loss: 1.491862. Batch_acc: 0.470344. Batch_loss: 1.476240 \n",
      "Batch: 1474. Acc: 0.464127. Loss: 1.491861. Batch_acc: 0.465103. Batch_loss: 1.490617 \n",
      "Batch: 1475. Acc: 0.464132. Loss: 1.491830. Batch_acc: 0.471568. Batch_loss: 1.445273 \n",
      "Batch: 1476. Acc: 0.464122. Loss: 1.491858. Batch_acc: 0.448555. Batch_loss: 1.534283 \n",
      "Batch: 1477. Acc: 0.464122. Loss: 1.491855. Batch_acc: 0.464245. Batch_loss: 1.487769 \n",
      "Batch: 1478. Acc: 0.464123. Loss: 1.491845. Batch_acc: 0.466363. Batch_loss: 1.477291 \n",
      "Batch: 1479. Acc: 0.464141. Loss: 1.491815. Batch_acc: 0.489738. Batch_loss: 1.447108 \n",
      "Batch: 1480. Acc: 0.464150. Loss: 1.491776. Batch_acc: 0.477663. Batch_loss: 1.434817 \n",
      "Batch: 1481. Acc: 0.464152. Loss: 1.491747. Batch_acc: 0.466968. Batch_loss: 1.449230 \n",
      "Batch: 1482. Acc: 0.464161. Loss: 1.491724. Batch_acc: 0.477933. Batch_loss: 1.457742 \n",
      "Batch: 1483. Acc: 0.464156. Loss: 1.491738. Batch_acc: 0.456674. Batch_loss: 1.512089 \n",
      "Batch: 1484. Acc: 0.464142. Loss: 1.491775. Batch_acc: 0.441707. Batch_loss: 1.549030 \n",
      "Batch: 1485. Acc: 0.464142. Loss: 1.491784. Batch_acc: 0.463810. Batch_loss: 1.506407 \n",
      "Batch: 1486. Acc: 0.464131. Loss: 1.491794. Batch_acc: 0.449109. Batch_loss: 1.506033 \n",
      "Batch: 1487. Acc: 0.464135. Loss: 1.491773. Batch_acc: 0.469942. Batch_loss: 1.459629 \n",
      "Batch: 1488. Acc: 0.464142. Loss: 1.491738. Batch_acc: 0.474374. Batch_loss: 1.440332 \n",
      "Batch: 1489. Acc: 0.464145. Loss: 1.491717. Batch_acc: 0.468624. Batch_loss: 1.460382 \n",
      "Batch: 1490. Acc: 0.464144. Loss: 1.491690. Batch_acc: 0.462384. Batch_loss: 1.451254 \n",
      "Batch: 1491. Acc: 0.464148. Loss: 1.491668. Batch_acc: 0.470149. Batch_loss: 1.459960 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1492. Acc: 0.464158. Loss: 1.491633. Batch_acc: 0.479143. Batch_loss: 1.439494 \n",
      "Batch: 1493. Acc: 0.464183. Loss: 1.491575. Batch_acc: 0.500563. Batch_loss: 1.408115 \n",
      "Batch: 1494. Acc: 0.464177. Loss: 1.491588. Batch_acc: 0.454545. Batch_loss: 1.511283 \n",
      "Batch: 1495. Acc: 0.464183. Loss: 1.491572. Batch_acc: 0.473444. Batch_loss: 1.467683 \n",
      "Batch: 1496. Acc: 0.464197. Loss: 1.491551. Batch_acc: 0.484127. Batch_loss: 1.460151 \n",
      "Batch: 1497. Acc: 0.464202. Loss: 1.491545. Batch_acc: 0.472142. Batch_loss: 1.482084 \n",
      "Batch: 1498. Acc: 0.464227. Loss: 1.491499. Batch_acc: 0.500560. Batch_loss: 1.424278 \n",
      "Batch: 1499. Acc: 0.464251. Loss: 1.491470. Batch_acc: 0.500868. Batch_loss: 1.448512 \n",
      "Batch: 1500. Acc: 0.464253. Loss: 1.491451. Batch_acc: 0.466933. Batch_loss: 1.463037 \n",
      "Batch: 1501. Acc: 0.464260. Loss: 1.491446. Batch_acc: 0.474197. Batch_loss: 1.484272 \n",
      "Batch: 1502. Acc: 0.464260. Loss: 1.491448. Batch_acc: 0.465129. Batch_loss: 1.493991 \n",
      "Batch: 1503. Acc: 0.464257. Loss: 1.491438. Batch_acc: 0.459428. Batch_loss: 1.476852 \n",
      "Batch: 1504. Acc: 0.464263. Loss: 1.491422. Batch_acc: 0.473623. Batch_loss: 1.466436 \n",
      "Batch: 1505. Acc: 0.464283. Loss: 1.491397. Batch_acc: 0.495316. Batch_loss: 1.453636 \n",
      "Batch: 1506. Acc: 0.464283. Loss: 1.491410. Batch_acc: 0.462887. Batch_loss: 1.510892 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.46428256370755455. Loss per char: 1.4914101290561248. Time: 1627215305.0154548\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 26, 18, 22,  1, 78, 74, 79, 86,\n",
      "        84,  1, 14, 20, 26, 19, 19, 21, 21, 17, 21, 19, 24, 32,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.464286. Loss: 1.491409. Batch_acc: 0.468910. Batch_loss: 1.489982 \n",
      "Batch: 1508. Acc: 0.464293. Loss: 1.491395. Batch_acc: 0.475866. Batch_loss: 1.470993 \n",
      "Batch: 1509. Acc: 0.464287. Loss: 1.491397. Batch_acc: 0.454274. Batch_loss: 1.494073 \n",
      "Batch: 1510. Acc: 0.464281. Loss: 1.491405. Batch_acc: 0.455652. Batch_loss: 1.503395 \n",
      "Batch: 1511. Acc: 0.464291. Loss: 1.491377. Batch_acc: 0.477991. Batch_loss: 1.450245 \n",
      "Batch: 1512. Acc: 0.464295. Loss: 1.491378. Batch_acc: 0.470927. Batch_loss: 1.492527 \n",
      "Batch: 1513. Acc: 0.464294. Loss: 1.491389. Batch_acc: 0.462451. Batch_loss: 1.507678 \n",
      "Batch: 1514. Acc: 0.464280. Loss: 1.491399. Batch_acc: 0.443618. Batch_loss: 1.506399 \n",
      "Batch: 1515. Acc: 0.464286. Loss: 1.491377. Batch_acc: 0.473900. Batch_loss: 1.457601 \n",
      "Batch: 1516. Acc: 0.464298. Loss: 1.491341. Batch_acc: 0.481630. Batch_loss: 1.436187 \n",
      "Batch: 1517. Acc: 0.464304. Loss: 1.491345. Batch_acc: 0.472965. Batch_loss: 1.498135 \n",
      "Batch: 1518. Acc: 0.464321. Loss: 1.491297. Batch_acc: 0.490130. Batch_loss: 1.419194 \n",
      "Batch: 1519. Acc: 0.464327. Loss: 1.491303. Batch_acc: 0.473654. Batch_loss: 1.500364 \n",
      "Batch: 1520. Acc: 0.464334. Loss: 1.491291. Batch_acc: 0.474857. Batch_loss: 1.473536 \n",
      "Batch: 1521. Acc: 0.464329. Loss: 1.491314. Batch_acc: 0.457143. Batch_loss: 1.525817 \n",
      "Batch: 1522. Acc: 0.464342. Loss: 1.491318. Batch_acc: 0.483616. Batch_loss: 1.497905 \n",
      "Batch: 1523. Acc: 0.464363. Loss: 1.491274. Batch_acc: 0.495418. Batch_loss: 1.424313 \n",
      "Batch: 1524. Acc: 0.464376. Loss: 1.491262. Batch_acc: 0.484483. Batch_loss: 1.473077 \n",
      "Batch: 1525. Acc: 0.464380. Loss: 1.491253. Batch_acc: 0.471371. Batch_loss: 1.477469 \n",
      "Batch: 1526. Acc: 0.464387. Loss: 1.491238. Batch_acc: 0.473866. Batch_loss: 1.468382 \n",
      "Batch: 1527. Acc: 0.464390. Loss: 1.491239. Batch_acc: 0.469093. Batch_loss: 1.493143 \n",
      "Batch: 1528. Acc: 0.464413. Loss: 1.491185. Batch_acc: 0.500289. Batch_loss: 1.407773 \n",
      "Batch: 1529. Acc: 0.464435. Loss: 1.491118. Batch_acc: 0.497973. Batch_loss: 1.388493 \n",
      "Batch: 1530. Acc: 0.464440. Loss: 1.491116. Batch_acc: 0.472654. Batch_loss: 1.488430 \n",
      "Batch: 1531. Acc: 0.464445. Loss: 1.491105. Batch_acc: 0.471454. Batch_loss: 1.472842 \n",
      "Batch: 1532. Acc: 0.464453. Loss: 1.491076. Batch_acc: 0.477595. Batch_loss: 1.447400 \n",
      "Batch: 1533. Acc: 0.464450. Loss: 1.491089. Batch_acc: 0.459302. Batch_loss: 1.511427 \n",
      "Batch: 1534. Acc: 0.464464. Loss: 1.491055. Batch_acc: 0.485360. Batch_loss: 1.440927 \n",
      "Batch: 1535. Acc: 0.464454. Loss: 1.491054. Batch_acc: 0.448909. Batch_loss: 1.489218 \n",
      "Batch: 1536. Acc: 0.464447. Loss: 1.491075. Batch_acc: 0.454751. Batch_loss: 1.522498 \n",
      "Batch: 1537. Acc: 0.464454. Loss: 1.491065. Batch_acc: 0.474899. Batch_loss: 1.474888 \n",
      "Batch: 1538. Acc: 0.464453. Loss: 1.491053. Batch_acc: 0.461995. Batch_loss: 1.472394 \n",
      "Batch: 1539. Acc: 0.464445. Loss: 1.491059. Batch_acc: 0.452852. Batch_loss: 1.500233 \n",
      "Batch: 1540. Acc: 0.464454. Loss: 1.491027. Batch_acc: 0.477696. Batch_loss: 1.443204 \n",
      "Batch: 1541. Acc: 0.464466. Loss: 1.490995. Batch_acc: 0.482561. Batch_loss: 1.442600 \n",
      "Batch: 1542. Acc: 0.464481. Loss: 1.490957. Batch_acc: 0.488683. Batch_loss: 1.431080 \n",
      "Batch: 1543. Acc: 0.464486. Loss: 1.490949. Batch_acc: 0.472042. Batch_loss: 1.478312 \n",
      "Batch: 1544. Acc: 0.464489. Loss: 1.490945. Batch_acc: 0.469550. Batch_loss: 1.485231 \n",
      "Batch: 1545. Acc: 0.464505. Loss: 1.490931. Batch_acc: 0.488966. Batch_loss: 1.468436 \n",
      "Batch: 1546. Acc: 0.464515. Loss: 1.490893. Batch_acc: 0.480482. Batch_loss: 1.432072 \n",
      "Batch: 1547. Acc: 0.464507. Loss: 1.490904. Batch_acc: 0.451327. Batch_loss: 1.509619 \n",
      "Batch: 1548. Acc: 0.464518. Loss: 1.490888. Batch_acc: 0.481739. Batch_loss: 1.464900 \n",
      "Batch: 1549. Acc: 0.464532. Loss: 1.490836. Batch_acc: 0.486135. Batch_loss: 1.411339 \n",
      "Batch: 1550. Acc: 0.464548. Loss: 1.490786. Batch_acc: 0.487696. Batch_loss: 1.416012 \n",
      "Batch: 1551. Acc: 0.464563. Loss: 1.490724. Batch_acc: 0.487805. Batch_loss: 1.396465 \n",
      "Batch: 1552. Acc: 0.464573. Loss: 1.490700. Batch_acc: 0.480638. Batch_loss: 1.453313 \n",
      "Batch: 1553. Acc: 0.464576. Loss: 1.490678. Batch_acc: 0.468458. Batch_loss: 1.456558 \n",
      "Batch: 1554. Acc: 0.464599. Loss: 1.490620. Batch_acc: 0.500571. Batch_loss: 1.400356 \n",
      "Batch: 1555. Acc: 0.464605. Loss: 1.490588. Batch_acc: 0.473715. Batch_loss: 1.440749 \n",
      "Batch: 1556. Acc: 0.464623. Loss: 1.490530. Batch_acc: 0.491963. Batch_loss: 1.400502 \n",
      "Batch: 1557. Acc: 0.464627. Loss: 1.490511. Batch_acc: 0.471884. Batch_loss: 1.460747 \n",
      "Batch: 1558. Acc: 0.464643. Loss: 1.490473. Batch_acc: 0.489619. Batch_loss: 1.430287 \n",
      "Batch: 1559. Acc: 0.464660. Loss: 1.490426. Batch_acc: 0.489994. Batch_loss: 1.418293 \n",
      "Batch: 1560. Acc: 0.464671. Loss: 1.490371. Batch_acc: 0.482286. Batch_loss: 1.405032 \n",
      "Batch: 1561. Acc: 0.464677. Loss: 1.490380. Batch_acc: 0.474078. Batch_loss: 1.504355 \n",
      "Batch: 1562. Acc: 0.464668. Loss: 1.490411. Batch_acc: 0.451141. Batch_loss: 1.539090 \n",
      "Batch: 1563. Acc: 0.464674. Loss: 1.490391. Batch_acc: 0.473593. Batch_loss: 1.458806 \n",
      "Batch: 1564. Acc: 0.464681. Loss: 1.490364. Batch_acc: 0.475858. Batch_loss: 1.448355 \n",
      "Batch: 1565. Acc: 0.464691. Loss: 1.490329. Batch_acc: 0.479954. Batch_loss: 1.435392 \n",
      "Batch: 1566. Acc: 0.464707. Loss: 1.490300. Batch_acc: 0.489026. Batch_loss: 1.445064 \n",
      "Batch: 1567. Acc: 0.464720. Loss: 1.490255. Batch_acc: 0.485649. Batch_loss: 1.419848 \n",
      "Batch: 1568. Acc: 0.464721. Loss: 1.490233. Batch_acc: 0.466247. Batch_loss: 1.457218 \n",
      "Batch: 1569. Acc: 0.464738. Loss: 1.490173. Batch_acc: 0.490940. Batch_loss: 1.396049 \n",
      "Batch: 1570. Acc: 0.464744. Loss: 1.490155. Batch_acc: 0.473684. Batch_loss: 1.462160 \n",
      "Batch: 1571. Acc: 0.464748. Loss: 1.490136. Batch_acc: 0.471379. Batch_loss: 1.459195 \n",
      "Batch: 1572. Acc: 0.464763. Loss: 1.490077. Batch_acc: 0.488889. Batch_loss: 1.398098 \n",
      "Batch: 1573. Acc: 0.464769. Loss: 1.490040. Batch_acc: 0.474469. Batch_loss: 1.432387 \n",
      "Batch: 1574. Acc: 0.464783. Loss: 1.490006. Batch_acc: 0.485294. Batch_loss: 1.437524 \n",
      "Batch: 1575. Acc: 0.464782. Loss: 1.489989. Batch_acc: 0.463912. Batch_loss: 1.462911 \n",
      "Batch: 1576. Acc: 0.464775. Loss: 1.490006. Batch_acc: 0.453423. Batch_loss: 1.516173 \n",
      "Batch: 1577. Acc: 0.464779. Loss: 1.490010. Batch_acc: 0.471478. Batch_loss: 1.496702 \n",
      "Batch: 1578. Acc: 0.464777. Loss: 1.490009. Batch_acc: 0.461896. Batch_loss: 1.488802 \n",
      "Batch: 1579. Acc: 0.464774. Loss: 1.490017. Batch_acc: 0.460094. Batch_loss: 1.502990 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1580. Acc: 0.464764. Loss: 1.490041. Batch_acc: 0.447400. Batch_loss: 1.528887 \n",
      "Batch: 1581. Acc: 0.464753. Loss: 1.490039. Batch_acc: 0.448235. Batch_loss: 1.486280 \n",
      "Batch: 1582. Acc: 0.464763. Loss: 1.490029. Batch_acc: 0.480000. Batch_loss: 1.474225 \n",
      "Batch: 1583. Acc: 0.464761. Loss: 1.490032. Batch_acc: 0.462108. Batch_loss: 1.493879 \n",
      "Batch: 1584. Acc: 0.464766. Loss: 1.490021. Batch_acc: 0.472190. Batch_loss: 1.473052 \n",
      "Batch: 1585. Acc: 0.464771. Loss: 1.490005. Batch_acc: 0.472400. Batch_loss: 1.464599 \n",
      "Batch: 1586. Acc: 0.464777. Loss: 1.489998. Batch_acc: 0.474857. Batch_loss: 1.478434 \n",
      "Batch: 1587. Acc: 0.464781. Loss: 1.489978. Batch_acc: 0.470421. Batch_loss: 1.459229 \n",
      "Batch: 1588. Acc: 0.464790. Loss: 1.489949. Batch_acc: 0.479954. Batch_loss: 1.442945 \n",
      "Batch: 1589. Acc: 0.464794. Loss: 1.489946. Batch_acc: 0.471930. Batch_loss: 1.485460 \n",
      "Batch: 1590. Acc: 0.464798. Loss: 1.489946. Batch_acc: 0.470175. Batch_loss: 1.489839 \n",
      "Batch: 1591. Acc: 0.464808. Loss: 1.489923. Batch_acc: 0.480319. Batch_loss: 1.452941 \n",
      "Batch: 1592. Acc: 0.464810. Loss: 1.489899. Batch_acc: 0.468012. Batch_loss: 1.452302 \n",
      "Batch: 1593. Acc: 0.464830. Loss: 1.489873. Batch_acc: 0.496334. Batch_loss: 1.449485 \n",
      "Batch: 1594. Acc: 0.464836. Loss: 1.489850. Batch_acc: 0.474448. Batch_loss: 1.452661 \n",
      "Batch: 1595. Acc: 0.464833. Loss: 1.489867. Batch_acc: 0.460382. Batch_loss: 1.516927 \n",
      "Batch: 1596. Acc: 0.464825. Loss: 1.489901. Batch_acc: 0.452571. Batch_loss: 1.543848 \n",
      "Batch: 1597. Acc: 0.464816. Loss: 1.489914. Batch_acc: 0.450060. Batch_loss: 1.511069 \n",
      "Batch: 1598. Acc: 0.464820. Loss: 1.489898. Batch_acc: 0.470986. Batch_loss: 1.465283 \n",
      "Batch: 1599. Acc: 0.464833. Loss: 1.489862. Batch_acc: 0.485131. Batch_loss: 1.431376 \n",
      "Batch: 1600. Acc: 0.464829. Loss: 1.489875. Batch_acc: 0.457998. Batch_loss: 1.511596 \n",
      "Batch: 1601. Acc: 0.464828. Loss: 1.489871. Batch_acc: 0.464041. Batch_loss: 1.483550 \n",
      "Batch: 1602. Acc: 0.464849. Loss: 1.489825. Batch_acc: 0.498017. Batch_loss: 1.416259 \n",
      "Batch: 1603. Acc: 0.464845. Loss: 1.489859. Batch_acc: 0.458989. Batch_loss: 1.542929 \n",
      "Batch: 1604. Acc: 0.464836. Loss: 1.489878. Batch_acc: 0.449137. Batch_loss: 1.521531 \n",
      "Batch: 1605. Acc: 0.464837. Loss: 1.489855. Batch_acc: 0.466019. Batch_loss: 1.454315 \n",
      "Batch: 1606. Acc: 0.464834. Loss: 1.489858. Batch_acc: 0.460700. Batch_loss: 1.493528 \n",
      "Batch: 1607. Acc: 0.464842. Loss: 1.489849. Batch_acc: 0.477441. Batch_loss: 1.476620 \n",
      "Batch: 1608. Acc: 0.464846. Loss: 1.489826. Batch_acc: 0.471065. Batch_loss: 1.452012 \n",
      "Batch: 1609. Acc: 0.464834. Loss: 1.489830. Batch_acc: 0.444575. Batch_loss: 1.495629 \n",
      "Batch: 1610. Acc: 0.464846. Loss: 1.489794. Batch_acc: 0.484223. Batch_loss: 1.433014 \n",
      "Batch: 1611. Acc: 0.464856. Loss: 1.489761. Batch_acc: 0.482090. Batch_loss: 1.434554 \n",
      "Batch: 1612. Acc: 0.464880. Loss: 1.489696. Batch_acc: 0.502260. Batch_loss: 1.387632 \n",
      "Batch: 1613. Acc: 0.464889. Loss: 1.489668. Batch_acc: 0.479815. Batch_loss: 1.443824 \n",
      "Batch: 1614. Acc: 0.464912. Loss: 1.489595. Batch_acc: 0.503214. Batch_loss: 1.370226 \n",
      "Batch: 1615. Acc: 0.464919. Loss: 1.489578. Batch_acc: 0.475145. Batch_loss: 1.462674 \n",
      "Batch: 1616. Acc: 0.464919. Loss: 1.489576. Batch_acc: 0.466058. Batch_loss: 1.485251 \n",
      "Batch: 1617. Acc: 0.464920. Loss: 1.489569. Batch_acc: 0.465817. Batch_loss: 1.478246 \n",
      "Batch: 1618. Acc: 0.464925. Loss: 1.489553. Batch_acc: 0.472591. Batch_loss: 1.464906 \n",
      "Batch: 1619. Acc: 0.464913. Loss: 1.489580. Batch_acc: 0.445608. Batch_loss: 1.533286 \n",
      "Batch: 1620. Acc: 0.464894. Loss: 1.489606. Batch_acc: 0.434040. Batch_loss: 1.532652 \n",
      "Batch: 1621. Acc: 0.464908. Loss: 1.489569. Batch_acc: 0.487917. Batch_loss: 1.428730 \n",
      "Batch: 1622. Acc: 0.464910. Loss: 1.489547. Batch_acc: 0.467927. Batch_loss: 1.455168 \n",
      "Batch: 1623. Acc: 0.464924. Loss: 1.489488. Batch_acc: 0.486336. Batch_loss: 1.396154 \n",
      "Batch: 1624. Acc: 0.464927. Loss: 1.489484. Batch_acc: 0.469783. Batch_loss: 1.483682 \n",
      "Batch: 1625. Acc: 0.464929. Loss: 1.489470. Batch_acc: 0.467585. Batch_loss: 1.466777 \n",
      "Batch: 1626. Acc: 0.464924. Loss: 1.489469. Batch_acc: 0.456961. Batch_loss: 1.487644 \n",
      "Batch: 1627. Acc: 0.464927. Loss: 1.489462. Batch_acc: 0.470289. Batch_loss: 1.478592 \n",
      "Batch: 1628. Acc: 0.464927. Loss: 1.489466. Batch_acc: 0.465689. Batch_loss: 1.495021 \n",
      "Batch: 1629. Acc: 0.464932. Loss: 1.489453. Batch_acc: 0.472643. Batch_loss: 1.468600 \n",
      "Batch: 1630. Acc: 0.464924. Loss: 1.489476. Batch_acc: 0.452313. Batch_loss: 1.527262 \n",
      "Batch: 1631. Acc: 0.464917. Loss: 1.489480. Batch_acc: 0.453542. Batch_loss: 1.495016 \n",
      "Batch: 1632. Acc: 0.464919. Loss: 1.489461. Batch_acc: 0.466854. Batch_loss: 1.459278 \n",
      "Batch: 1633. Acc: 0.464924. Loss: 1.489439. Batch_acc: 0.473260. Batch_loss: 1.454146 \n",
      "Batch: 1634. Acc: 0.464947. Loss: 1.489384. Batch_acc: 0.502815. Batch_loss: 1.401209 \n",
      "Batch: 1635. Acc: 0.464940. Loss: 1.489401. Batch_acc: 0.452255. Batch_loss: 1.517268 \n",
      "Batch: 1636. Acc: 0.464943. Loss: 1.489410. Batch_acc: 0.470522. Batch_loss: 1.503937 \n",
      "Batch: 1637. Acc: 0.464945. Loss: 1.489393. Batch_acc: 0.467890. Batch_loss: 1.462011 \n",
      "Batch: 1638. Acc: 0.464960. Loss: 1.489351. Batch_acc: 0.490401. Batch_loss: 1.420475 \n",
      "Batch: 1639. Acc: 0.464973. Loss: 1.489331. Batch_acc: 0.484866. Batch_loss: 1.456470 \n",
      "Batch: 1640. Acc: 0.464974. Loss: 1.489305. Batch_acc: 0.467585. Batch_loss: 1.446953 \n",
      "Batch: 1641. Acc: 0.464974. Loss: 1.489304. Batch_acc: 0.464594. Batch_loss: 1.486380 \n",
      "Batch: 1642. Acc: 0.464975. Loss: 1.489293. Batch_acc: 0.465856. Batch_loss: 1.471975 \n",
      "Batch: 1643. Acc: 0.464976. Loss: 1.489284. Batch_acc: 0.467742. Batch_loss: 1.473341 \n",
      "Batch: 1644. Acc: 0.464974. Loss: 1.489289. Batch_acc: 0.461627. Batch_loss: 1.497175 \n",
      "Batch: 1645. Acc: 0.464971. Loss: 1.489307. Batch_acc: 0.459570. Batch_loss: 1.519395 \n",
      "Batch: 1646. Acc: 0.464956. Loss: 1.489319. Batch_acc: 0.440609. Batch_loss: 1.510223 \n",
      "Batch: 1647. Acc: 0.464963. Loss: 1.489309. Batch_acc: 0.475924. Batch_loss: 1.472463 \n",
      "Batch: 1648. Acc: 0.464960. Loss: 1.489323. Batch_acc: 0.459663. Batch_loss: 1.513702 \n",
      "Batch: 1649. Acc: 0.464963. Loss: 1.489314. Batch_acc: 0.469364. Batch_loss: 1.474241 \n",
      "Batch: 1650. Acc: 0.464980. Loss: 1.489276. Batch_acc: 0.493962. Batch_loss: 1.426963 \n",
      "Batch: 1651. Acc: 0.464981. Loss: 1.489282. Batch_acc: 0.466200. Batch_loss: 1.498164 \n",
      "Batch: 1652. Acc: 0.464988. Loss: 1.489250. Batch_acc: 0.476879. Batch_loss: 1.436350 \n",
      "Batch: 1653. Acc: 0.464983. Loss: 1.489258. Batch_acc: 0.456942. Batch_loss: 1.502620 \n",
      "Batch: 1654. Acc: 0.464982. Loss: 1.489267. Batch_acc: 0.462464. Batch_loss: 1.505009 \n",
      "Batch: 1655. Acc: 0.464977. Loss: 1.489280. Batch_acc: 0.457478. Batch_loss: 1.510375 \n",
      "Batch: 1656. Acc: 0.464995. Loss: 1.489253. Batch_acc: 0.493174. Batch_loss: 1.445392 \n",
      "Batch: 1657. Acc: 0.464990. Loss: 1.489240. Batch_acc: 0.457369. Batch_loss: 1.468855 \n",
      "Batch: 1658. Acc: 0.465002. Loss: 1.489189. Batch_acc: 0.484507. Batch_loss: 1.405424 \n",
      "Batch: 1659. Acc: 0.465006. Loss: 1.489169. Batch_acc: 0.472365. Batch_loss: 1.456824 \n",
      "Batch: 1660. Acc: 0.465021. Loss: 1.489127. Batch_acc: 0.489362. Batch_loss: 1.419438 \n",
      "Batch: 1661. Acc: 0.465022. Loss: 1.489124. Batch_acc: 0.466401. Batch_loss: 1.483228 \n",
      "Batch: 1662. Acc: 0.465038. Loss: 1.489086. Batch_acc: 0.492694. Batch_loss: 1.425720 \n",
      "Batch: 1663. Acc: 0.465052. Loss: 1.489055. Batch_acc: 0.487585. Batch_loss: 1.439060 \n",
      "Batch: 1664. Acc: 0.465054. Loss: 1.489052. Batch_acc: 0.468171. Batch_loss: 1.483253 \n",
      "Batch: 1665. Acc: 0.465079. Loss: 1.488999. Batch_acc: 0.505022. Batch_loss: 1.403539 \n",
      "Batch: 1666. Acc: 0.465082. Loss: 1.488990. Batch_acc: 0.470994. Batch_loss: 1.473768 \n",
      "Batch: 1667. Acc: 0.465091. Loss: 1.488953. Batch_acc: 0.479334. Batch_loss: 1.428321 \n",
      "Batch: 1668. Acc: 0.465082. Loss: 1.488960. Batch_acc: 0.450229. Batch_loss: 1.500532 \n",
      "Batch: 1669. Acc: 0.465089. Loss: 1.488943. Batch_acc: 0.477752. Batch_loss: 1.458937 \n",
      "Batch: 1670. Acc: 0.465076. Loss: 1.488973. Batch_acc: 0.442775. Batch_loss: 1.540622 \n",
      "Batch: 1671. Acc: 0.465091. Loss: 1.488921. Batch_acc: 0.489423. Batch_loss: 1.401446 \n",
      "Batch: 1672. Acc: 0.465097. Loss: 1.488896. Batch_acc: 0.474615. Batch_loss: 1.447609 \n",
      "Batch: 1673. Acc: 0.465103. Loss: 1.488880. Batch_acc: 0.475202. Batch_loss: 1.462814 \n",
      "Batch: 1674. Acc: 0.465095. Loss: 1.488876. Batch_acc: 0.453071. Batch_loss: 1.481512 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1675. Acc: 0.465098. Loss: 1.488867. Batch_acc: 0.469164. Batch_loss: 1.473087 \n",
      "Batch: 1676. Acc: 0.465113. Loss: 1.488845. Batch_acc: 0.490308. Batch_loss: 1.453425 \n",
      "Batch: 1677. Acc: 0.465116. Loss: 1.488828. Batch_acc: 0.470035. Batch_loss: 1.459736 \n",
      "Batch: 1678. Acc: 0.465133. Loss: 1.488810. Batch_acc: 0.492934. Batch_loss: 1.458891 \n",
      "Batch: 1679. Acc: 0.465149. Loss: 1.488752. Batch_acc: 0.491758. Batch_loss: 1.395682 \n",
      "Batch: 1680. Acc: 0.465150. Loss: 1.488740. Batch_acc: 0.465956. Batch_loss: 1.468238 \n",
      "Batch: 1681. Acc: 0.465156. Loss: 1.488737. Batch_acc: 0.475015. Batch_loss: 1.483016 \n",
      "Batch: 1682. Acc: 0.465175. Loss: 1.488690. Batch_acc: 0.497427. Batch_loss: 1.411274 \n",
      "Batch: 1683. Acc: 0.465173. Loss: 1.488691. Batch_acc: 0.461538. Batch_loss: 1.489647 \n",
      "Batch: 1684. Acc: 0.465180. Loss: 1.488648. Batch_acc: 0.478035. Batch_loss: 1.416703 \n",
      "Batch: 1685. Acc: 0.465201. Loss: 1.488607. Batch_acc: 0.499717. Batch_loss: 1.419217 \n",
      "Batch: 1686. Acc: 0.465215. Loss: 1.488576. Batch_acc: 0.489030. Batch_loss: 1.437329 \n",
      "Batch: 1687. Acc: 0.465212. Loss: 1.488562. Batch_acc: 0.459696. Batch_loss: 1.464188 \n",
      "Batch: 1688. Acc: 0.465228. Loss: 1.488525. Batch_acc: 0.491131. Batch_loss: 1.428516 \n",
      "Batch: 1689. Acc: 0.465256. Loss: 1.488455. Batch_acc: 0.509890. Batch_loss: 1.375803 \n",
      "Batch: 1690. Acc: 0.465261. Loss: 1.488449. Batch_acc: 0.475132. Batch_loss: 1.478106 \n",
      "Batch: 1691. Acc: 0.465272. Loss: 1.488430. Batch_acc: 0.484634. Batch_loss: 1.454467 \n",
      "Batch: 1692. Acc: 0.465260. Loss: 1.488454. Batch_acc: 0.443875. Batch_loss: 1.529494 \n",
      "Batch: 1693. Acc: 0.465274. Loss: 1.488401. Batch_acc: 0.489326. Batch_loss: 1.399750 \n",
      "Batch: 1694. Acc: 0.465276. Loss: 1.488379. Batch_acc: 0.467687. Batch_loss: 1.452007 \n",
      "Batch: 1695. Acc: 0.465275. Loss: 1.488377. Batch_acc: 0.463401. Batch_loss: 1.485158 \n",
      "Batch: 1696. Acc: 0.465276. Loss: 1.488369. Batch_acc: 0.468147. Batch_loss: 1.474676 \n",
      "Batch: 1697. Acc: 0.465273. Loss: 1.488383. Batch_acc: 0.459521. Batch_loss: 1.512706 \n",
      "Batch: 1698. Acc: 0.465276. Loss: 1.488372. Batch_acc: 0.471396. Batch_loss: 1.468859 \n",
      "Batch: 1699. Acc: 0.465286. Loss: 1.488345. Batch_acc: 0.480616. Batch_loss: 1.443040 \n",
      "Batch: 1700. Acc: 0.465289. Loss: 1.488324. Batch_acc: 0.471807. Batch_loss: 1.453427 \n",
      "Batch: 1701. Acc: 0.465302. Loss: 1.488276. Batch_acc: 0.486345. Batch_loss: 1.405659 \n",
      "Batch: 1702. Acc: 0.465307. Loss: 1.488259. Batch_acc: 0.474508. Batch_loss: 1.459112 \n",
      "Batch: 1703. Acc: 0.465306. Loss: 1.488255. Batch_acc: 0.462729. Batch_loss: 1.481513 \n",
      "Batch: 1704. Acc: 0.465311. Loss: 1.488231. Batch_acc: 0.474706. Batch_loss: 1.445493 \n",
      "Batch: 1705. Acc: 0.465306. Loss: 1.488235. Batch_acc: 0.457675. Batch_loss: 1.495699 \n",
      "Batch: 1706. Acc: 0.465321. Loss: 1.488192. Batch_acc: 0.490555. Batch_loss: 1.413389 \n",
      "Batch: 1707. Acc: 0.465330. Loss: 1.488177. Batch_acc: 0.480415. Batch_loss: 1.461802 \n",
      "Batch: 1708. Acc: 0.465335. Loss: 1.488182. Batch_acc: 0.474173. Batch_loss: 1.496602 \n",
      "Batch: 1709. Acc: 0.465343. Loss: 1.488175. Batch_acc: 0.479977. Batch_loss: 1.475515 \n",
      "Batch: 1710. Acc: 0.465337. Loss: 1.488177. Batch_acc: 0.455176. Batch_loss: 1.491638 \n",
      "Batch: 1711. Acc: 0.465337. Loss: 1.488176. Batch_acc: 0.465341. Batch_loss: 1.487637 \n",
      "Batch: 1712. Acc: 0.465341. Loss: 1.488170. Batch_acc: 0.471477. Batch_loss: 1.477260 \n",
      "Batch: 1713. Acc: 0.465346. Loss: 1.488153. Batch_acc: 0.474526. Batch_loss: 1.459062 \n",
      "Batch: 1714. Acc: 0.465352. Loss: 1.488116. Batch_acc: 0.475756. Batch_loss: 1.425080 \n",
      "Batch: 1715. Acc: 0.465356. Loss: 1.488122. Batch_acc: 0.472318. Batch_loss: 1.498822 \n",
      "Batch: 1716. Acc: 0.465372. Loss: 1.488091. Batch_acc: 0.492555. Batch_loss: 1.432759 \n",
      "Batch: 1717. Acc: 0.465380. Loss: 1.488079. Batch_acc: 0.478754. Batch_loss: 1.467805 \n",
      "Batch: 1718. Acc: 0.465387. Loss: 1.488052. Batch_acc: 0.478060. Batch_loss: 1.441681 \n",
      "Batch: 1719. Acc: 0.465396. Loss: 1.488028. Batch_acc: 0.481675. Batch_loss: 1.445852 \n",
      "Batch: 1720. Acc: 0.465413. Loss: 1.487973. Batch_acc: 0.494786. Batch_loss: 1.392553 \n",
      "Batch: 1721. Acc: 0.465433. Loss: 1.487923. Batch_acc: 0.498035. Batch_loss: 1.404158 \n",
      "Batch: 1722. Acc: 0.465435. Loss: 1.487915. Batch_acc: 0.469732. Batch_loss: 1.474692 \n",
      "Batch: 1723. Acc: 0.465444. Loss: 1.487897. Batch_acc: 0.481013. Batch_loss: 1.455547 \n",
      "Batch: 1724. Acc: 0.465478. Loss: 1.487832. Batch_acc: 0.522599. Batch_loss: 1.379141 \n",
      "Batch: 1725. Acc: 0.465493. Loss: 1.487793. Batch_acc: 0.490385. Batch_loss: 1.421794 \n",
      "Batch: 1726. Acc: 0.465499. Loss: 1.487764. Batch_acc: 0.476657. Batch_loss: 1.437653 \n",
      "Batch: 1727. Acc: 0.465509. Loss: 1.487728. Batch_acc: 0.482153. Batch_loss: 1.425619 \n",
      "Batch: 1728. Acc: 0.465508. Loss: 1.487735. Batch_acc: 0.463876. Batch_loss: 1.499382 \n",
      "Batch: 1729. Acc: 0.465508. Loss: 1.487733. Batch_acc: 0.465313. Batch_loss: 1.483958 \n",
      "Batch: 1730. Acc: 0.465523. Loss: 1.487698. Batch_acc: 0.490981. Batch_loss: 1.428977 \n",
      "Batch: 1731. Acc: 0.465545. Loss: 1.487647. Batch_acc: 0.504389. Batch_loss: 1.398290 \n",
      "Batch: 1732. Acc: 0.465559. Loss: 1.487616. Batch_acc: 0.490040. Batch_loss: 1.433841 \n",
      "Batch: 1733. Acc: 0.465573. Loss: 1.487581. Batch_acc: 0.488532. Batch_loss: 1.427446 \n",
      "Batch: 1734. Acc: 0.465574. Loss: 1.487573. Batch_acc: 0.467354. Batch_loss: 1.474571 \n",
      "Batch: 1735. Acc: 0.465580. Loss: 1.487559. Batch_acc: 0.477169. Batch_loss: 1.463646 \n",
      "Batch: 1736. Acc: 0.465589. Loss: 1.487536. Batch_acc: 0.479444. Batch_loss: 1.447871 \n",
      "Batch: 1737. Acc: 0.465602. Loss: 1.487499. Batch_acc: 0.487307. Batch_loss: 1.426491 \n",
      "Batch: 1738. Acc: 0.465599. Loss: 1.487485. Batch_acc: 0.461261. Batch_loss: 1.462140 \n",
      "Batch: 1739. Acc: 0.465599. Loss: 1.487480. Batch_acc: 0.465889. Batch_loss: 1.478138 \n",
      "Batch: 1740. Acc: 0.465609. Loss: 1.487451. Batch_acc: 0.483021. Batch_loss: 1.436839 \n",
      "Batch: 1741. Acc: 0.465611. Loss: 1.487464. Batch_acc: 0.468025. Batch_loss: 1.509028 \n",
      "Batch: 1742. Acc: 0.465622. Loss: 1.487434. Batch_acc: 0.485795. Batch_loss: 1.436774 \n",
      "Batch: 1743. Acc: 0.465630. Loss: 1.487404. Batch_acc: 0.479250. Batch_loss: 1.434864 \n",
      "Batch: 1744. Acc: 0.465628. Loss: 1.487421. Batch_acc: 0.462514. Batch_loss: 1.517121 \n",
      "Batch: 1745. Acc: 0.465643. Loss: 1.487399. Batch_acc: 0.490501. Batch_loss: 1.449198 \n",
      "Batch: 1746. Acc: 0.465646. Loss: 1.487379. Batch_acc: 0.471559. Batch_loss: 1.452824 \n",
      "Batch: 1747. Acc: 0.465632. Loss: 1.487406. Batch_acc: 0.441023. Batch_loss: 1.535516 \n",
      "Batch: 1748. Acc: 0.465659. Loss: 1.487355. Batch_acc: 0.510949. Batch_loss: 1.400002 \n",
      "Batch: 1749. Acc: 0.465654. Loss: 1.487361. Batch_acc: 0.457509. Batch_loss: 1.498299 \n",
      "Batch: 1750. Acc: 0.465649. Loss: 1.487383. Batch_acc: 0.456634. Batch_loss: 1.526129 \n",
      "Batch: 1751. Acc: 0.465652. Loss: 1.487369. Batch_acc: 0.471601. Batch_loss: 1.461782 \n",
      "Batch: 1752. Acc: 0.465651. Loss: 1.487382. Batch_acc: 0.463345. Batch_loss: 1.511158 \n",
      "Batch: 1753. Acc: 0.465658. Loss: 1.487363. Batch_acc: 0.478336. Batch_loss: 1.452756 \n",
      "Batch: 1754. Acc: 0.465665. Loss: 1.487344. Batch_acc: 0.477638. Batch_loss: 1.455480 \n",
      "Batch: 1755. Acc: 0.465665. Loss: 1.487329. Batch_acc: 0.464797. Batch_loss: 1.460264 \n",
      "Batch: 1756. Acc: 0.465665. Loss: 1.487334. Batch_acc: 0.466472. Batch_loss: 1.496467 \n",
      "Batch: 1757. Acc: 0.465673. Loss: 1.487308. Batch_acc: 0.478480. Batch_loss: 1.442184 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.46567255732533175. Loss per char: 1.4873076873710083. Time: 1627215502.685739\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 25, 20, 23, 19, 20, 19, 20, 15, 25,\n",
      "        21, 23, 23, 18, 22, 26,  1, 85, 66, 76, 70,  1, 66, 88, 66, 90,  1, 14,\n",
      "        17, 15, 22, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.465686. Loss: 1.487289. Batch_acc: 0.490242. Batch_loss: 1.454037 \n",
      "Batch: 1759. Acc: 0.465701. Loss: 1.487242. Batch_acc: 0.491329. Batch_loss: 1.403800 \n",
      "Batch: 1760. Acc: 0.465702. Loss: 1.487241. Batch_acc: 0.468677. Batch_loss: 1.485899 \n",
      "Batch: 1761. Acc: 0.465707. Loss: 1.487197. Batch_acc: 0.473862. Batch_loss: 1.411265 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1762. Acc: 0.465719. Loss: 1.487174. Batch_acc: 0.486857. Batch_loss: 1.446999 \n",
      "Batch: 1763. Acc: 0.465728. Loss: 1.487156. Batch_acc: 0.480638. Batch_loss: 1.455420 \n",
      "Batch: 1764. Acc: 0.465735. Loss: 1.487133. Batch_acc: 0.478778. Batch_loss: 1.447743 \n",
      "Batch: 1765. Acc: 0.465740. Loss: 1.487127. Batch_acc: 0.474596. Batch_loss: 1.476827 \n",
      "Batch: 1766. Acc: 0.465732. Loss: 1.487141. Batch_acc: 0.451517. Batch_loss: 1.511719 \n",
      "Batch: 1767. Acc: 0.465748. Loss: 1.487102. Batch_acc: 0.493395. Batch_loss: 1.418437 \n",
      "Batch: 1768. Acc: 0.465758. Loss: 1.487083. Batch_acc: 0.483816. Batch_loss: 1.453041 \n",
      "Batch: 1769. Acc: 0.465762. Loss: 1.487077. Batch_acc: 0.472696. Batch_loss: 1.478005 \n",
      "Batch: 1770. Acc: 0.465766. Loss: 1.487053. Batch_acc: 0.472696. Batch_loss: 1.443640 \n",
      "Batch: 1771. Acc: 0.465778. Loss: 1.487024. Batch_acc: 0.486348. Batch_loss: 1.437654 \n",
      "Batch: 1772. Acc: 0.465802. Loss: 1.486958. Batch_acc: 0.507155. Batch_loss: 1.369684 \n",
      "Batch: 1773. Acc: 0.465827. Loss: 1.486886. Batch_acc: 0.510808. Batch_loss: 1.360242 \n",
      "Batch: 1774. Acc: 0.465831. Loss: 1.486880. Batch_acc: 0.472864. Batch_loss: 1.476789 \n",
      "Batch: 1775. Acc: 0.465847. Loss: 1.486837. Batch_acc: 0.493387. Batch_loss: 1.410596 \n",
      "Batch: 1776. Acc: 0.465856. Loss: 1.486809. Batch_acc: 0.482581. Batch_loss: 1.437922 \n",
      "Batch: 1777. Acc: 0.465865. Loss: 1.486799. Batch_acc: 0.480769. Batch_loss: 1.469025 \n",
      "Batch: 1778. Acc: 0.465870. Loss: 1.486773. Batch_acc: 0.474845. Batch_loss: 1.441168 \n",
      "Batch: 1779. Acc: 0.465889. Loss: 1.486719. Batch_acc: 0.499429. Batch_loss: 1.392057 \n",
      "Batch: 1780. Acc: 0.465886. Loss: 1.486725. Batch_acc: 0.460727. Batch_loss: 1.497641 \n",
      "Batch: 1781. Acc: 0.465881. Loss: 1.486746. Batch_acc: 0.455968. Batch_loss: 1.524300 \n",
      "Batch: 1782. Acc: 0.465891. Loss: 1.486725. Batch_acc: 0.485397. Batch_loss: 1.448402 \n",
      "Batch: 1783. Acc: 0.465892. Loss: 1.486734. Batch_acc: 0.467204. Batch_loss: 1.502418 \n",
      "Batch: 1784. Acc: 0.465891. Loss: 1.486722. Batch_acc: 0.464813. Batch_loss: 1.466114 \n",
      "Batch: 1785. Acc: 0.465903. Loss: 1.486698. Batch_acc: 0.487877. Batch_loss: 1.443075 \n",
      "Batch: 1786. Acc: 0.465891. Loss: 1.486706. Batch_acc: 0.443662. Batch_loss: 1.500325 \n",
      "Batch: 1787. Acc: 0.465891. Loss: 1.486709. Batch_acc: 0.464646. Batch_loss: 1.491921 \n",
      "Batch: 1788. Acc: 0.465897. Loss: 1.486689. Batch_acc: 0.477620. Batch_loss: 1.451464 \n",
      "Batch: 1789. Acc: 0.465901. Loss: 1.486679. Batch_acc: 0.473386. Batch_loss: 1.469983 \n",
      "Batch: 1790. Acc: 0.465899. Loss: 1.486672. Batch_acc: 0.460784. Batch_loss: 1.473119 \n",
      "Batch: 1791. Acc: 0.465896. Loss: 1.486677. Batch_acc: 0.460875. Batch_loss: 1.496891 \n",
      "Batch: 1792. Acc: 0.465918. Loss: 1.486617. Batch_acc: 0.505807. Batch_loss: 1.377167 \n",
      "Batch: 1793. Acc: 0.465922. Loss: 1.486597. Batch_acc: 0.474168. Batch_loss: 1.451481 \n",
      "Batch: 1794. Acc: 0.465948. Loss: 1.486528. Batch_acc: 0.511261. Batch_loss: 1.365750 \n",
      "Batch: 1795. Acc: 0.465965. Loss: 1.486489. Batch_acc: 0.495506. Batch_loss: 1.416994 \n",
      "Batch: 1796. Acc: 0.465970. Loss: 1.486466. Batch_acc: 0.474478. Batch_loss: 1.444805 \n",
      "Batch: 1797. Acc: 0.465973. Loss: 1.486452. Batch_acc: 0.472222. Batch_loss: 1.461571 \n",
      "Batch: 1798. Acc: 0.465978. Loss: 1.486436. Batch_acc: 0.474828. Batch_loss: 1.457240 \n",
      "Batch: 1799. Acc: 0.465972. Loss: 1.486447. Batch_acc: 0.455020. Batch_loss: 1.506844 \n",
      "Batch: 1800. Acc: 0.465974. Loss: 1.486423. Batch_acc: 0.469575. Batch_loss: 1.443962 \n",
      "Batch: 1801. Acc: 0.465975. Loss: 1.486412. Batch_acc: 0.467473. Batch_loss: 1.466819 \n",
      "Batch: 1802. Acc: 0.465996. Loss: 1.486374. Batch_acc: 0.504323. Batch_loss: 1.417170 \n",
      "Batch: 1803. Acc: 0.466003. Loss: 1.486348. Batch_acc: 0.477759. Batch_loss: 1.439524 \n",
      "Batch: 1804. Acc: 0.466018. Loss: 1.486312. Batch_acc: 0.493111. Batch_loss: 1.421433 \n",
      "Batch: 1805. Acc: 0.466012. Loss: 1.486309. Batch_acc: 0.455652. Batch_loss: 1.481423 \n",
      "Batch: 1806. Acc: 0.466022. Loss: 1.486277. Batch_acc: 0.484638. Batch_loss: 1.428421 \n",
      "Batch: 1807. Acc: 0.466019. Loss: 1.486273. Batch_acc: 0.460402. Batch_loss: 1.478110 \n",
      "Batch: 1808. Acc: 0.466028. Loss: 1.486266. Batch_acc: 0.480868. Batch_loss: 1.473259 \n",
      "Batch: 1809. Acc: 0.466035. Loss: 1.486250. Batch_acc: 0.479339. Batch_loss: 1.456585 \n",
      "Batch: 1810. Acc: 0.466042. Loss: 1.486215. Batch_acc: 0.479011. Batch_loss: 1.423364 \n",
      "Batch: 1811. Acc: 0.466049. Loss: 1.486197. Batch_acc: 0.478833. Batch_loss: 1.454414 \n",
      "Batch: 1812. Acc: 0.466063. Loss: 1.486181. Batch_acc: 0.491506. Batch_loss: 1.455472 \n",
      "Batch: 1813. Acc: 0.466070. Loss: 1.486169. Batch_acc: 0.479025. Batch_loss: 1.465858 \n",
      "Batch: 1814. Acc: 0.466085. Loss: 1.486129. Batch_acc: 0.493506. Batch_loss: 1.414904 \n",
      "Batch: 1815. Acc: 0.466075. Loss: 1.486142. Batch_acc: 0.447368. Batch_loss: 1.508620 \n",
      "Batch: 1816. Acc: 0.466089. Loss: 1.486106. Batch_acc: 0.491633. Batch_loss: 1.420770 \n",
      "Batch: 1817. Acc: 0.466103. Loss: 1.486082. Batch_acc: 0.491691. Batch_loss: 1.441938 \n",
      "Batch: 1818. Acc: 0.466109. Loss: 1.486054. Batch_acc: 0.477207. Batch_loss: 1.435653 \n",
      "Batch: 1819. Acc: 0.466116. Loss: 1.486057. Batch_acc: 0.478637. Batch_loss: 1.492221 \n",
      "Batch: 1820. Acc: 0.466120. Loss: 1.486046. Batch_acc: 0.473287. Batch_loss: 1.466047 \n",
      "Batch: 1821. Acc: 0.466134. Loss: 1.486028. Batch_acc: 0.490694. Batch_loss: 1.452496 \n",
      "Batch: 1822. Acc: 0.466135. Loss: 1.485997. Batch_acc: 0.467642. Batch_loss: 1.430887 \n",
      "Batch: 1823. Acc: 0.466133. Loss: 1.486010. Batch_acc: 0.462550. Batch_loss: 1.510810 \n",
      "Batch: 1824. Acc: 0.466136. Loss: 1.485995. Batch_acc: 0.471578. Batch_loss: 1.457097 \n",
      "Batch: 1825. Acc: 0.466152. Loss: 1.485946. Batch_acc: 0.496059. Batch_loss: 1.398934 \n",
      "Batch: 1826. Acc: 0.466152. Loss: 1.485931. Batch_acc: 0.464490. Batch_loss: 1.459142 \n",
      "Batch: 1827. Acc: 0.466154. Loss: 1.485914. Batch_acc: 0.470722. Batch_loss: 1.453900 \n",
      "Batch: 1828. Acc: 0.466160. Loss: 1.485893. Batch_acc: 0.477128. Batch_loss: 1.448049 \n",
      "Batch: 1829. Acc: 0.466171. Loss: 1.485870. Batch_acc: 0.486772. Batch_loss: 1.442157 \n",
      "Batch: 1830. Acc: 0.466177. Loss: 1.485885. Batch_acc: 0.476829. Batch_loss: 1.512877 \n",
      "Batch: 1831. Acc: 0.466188. Loss: 1.485843. Batch_acc: 0.485731. Batch_loss: 1.408870 \n",
      "Batch: 1832. Acc: 0.466186. Loss: 1.485831. Batch_acc: 0.464000. Batch_loss: 1.464255 \n",
      "Batch: 1833. Acc: 0.466192. Loss: 1.485820. Batch_acc: 0.475834. Batch_loss: 1.464993 \n",
      "Batch: 1834. Acc: 0.466197. Loss: 1.485813. Batch_acc: 0.476108. Batch_loss: 1.472512 \n",
      "Batch: 1835. Acc: 0.466201. Loss: 1.485800. Batch_acc: 0.473349. Batch_loss: 1.461699 \n",
      "Batch: 1836. Acc: 0.466196. Loss: 1.485809. Batch_acc: 0.457637. Batch_loss: 1.502466 \n",
      "Batch: 1837. Acc: 0.466205. Loss: 1.485773. Batch_acc: 0.481990. Batch_loss: 1.420162 \n",
      "Batch: 1838. Acc: 0.466199. Loss: 1.485771. Batch_acc: 0.455237. Batch_loss: 1.482229 \n",
      "Batch: 1839. Acc: 0.466208. Loss: 1.485748. Batch_acc: 0.483152. Batch_loss: 1.443718 \n",
      "Batch: 1840. Acc: 0.466221. Loss: 1.485726. Batch_acc: 0.489583. Batch_loss: 1.445682 \n",
      "Batch: 1841. Acc: 0.466212. Loss: 1.485749. Batch_acc: 0.448884. Batch_loss: 1.527848 \n",
      "Batch: 1842. Acc: 0.466225. Loss: 1.485724. Batch_acc: 0.490424. Batch_loss: 1.439314 \n",
      "Batch: 1843. Acc: 0.466239. Loss: 1.485687. Batch_acc: 0.492580. Batch_loss: 1.417876 \n",
      "Batch: 1844. Acc: 0.466237. Loss: 1.485692. Batch_acc: 0.462522. Batch_loss: 1.494933 \n",
      "Batch: 1845. Acc: 0.466238. Loss: 1.485680. Batch_acc: 0.468048. Batch_loss: 1.464305 \n",
      "Batch: 1846. Acc: 0.466242. Loss: 1.485670. Batch_acc: 0.473596. Batch_loss: 1.467738 \n",
      "Batch: 1847. Acc: 0.466228. Loss: 1.485694. Batch_acc: 0.439858. Batch_loss: 1.531007 \n",
      "Batch: 1848. Acc: 0.466226. Loss: 1.485681. Batch_acc: 0.462791. Batch_loss: 1.460991 \n",
      "Batch: 1849. Acc: 0.466221. Loss: 1.485679. Batch_acc: 0.455271. Batch_loss: 1.482378 \n",
      "Batch: 1850. Acc: 0.466224. Loss: 1.485676. Batch_acc: 0.473204. Batch_loss: 1.480550 \n",
      "Batch: 1851. Acc: 0.466231. Loss: 1.485652. Batch_acc: 0.479468. Batch_loss: 1.441266 \n",
      "Batch: 1852. Acc: 0.466245. Loss: 1.485610. Batch_acc: 0.490736. Batch_loss: 1.408325 \n",
      "Batch: 1853. Acc: 0.466250. Loss: 1.485593. Batch_acc: 0.475967. Batch_loss: 1.454729 \n",
      "Batch: 1854. Acc: 0.466250. Loss: 1.485585. Batch_acc: 0.465578. Batch_loss: 1.469469 \n",
      "Batch: 1855. Acc: 0.466257. Loss: 1.485571. Batch_acc: 0.479452. Batch_loss: 1.459925 \n",
      "Batch: 1856. Acc: 0.466254. Loss: 1.485574. Batch_acc: 0.461883. Batch_loss: 1.490194 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1857. Acc: 0.466282. Loss: 1.485518. Batch_acc: 0.517519. Batch_loss: 1.381427 \n",
      "Batch: 1858. Acc: 0.466284. Loss: 1.485498. Batch_acc: 0.470657. Batch_loss: 1.449264 \n",
      "Batch: 1859. Acc: 0.466290. Loss: 1.485473. Batch_acc: 0.476724. Batch_loss: 1.437865 \n",
      "Batch: 1860. Acc: 0.466284. Loss: 1.485490. Batch_acc: 0.455185. Batch_loss: 1.517251 \n",
      "Batch: 1861. Acc: 0.466293. Loss: 1.485471. Batch_acc: 0.483967. Batch_loss: 1.448673 \n",
      "Batch: 1862. Acc: 0.466298. Loss: 1.485474. Batch_acc: 0.476246. Batch_loss: 1.490937 \n",
      "Batch: 1863. Acc: 0.466302. Loss: 1.485461. Batch_acc: 0.474052. Batch_loss: 1.461261 \n",
      "Batch: 1864. Acc: 0.466311. Loss: 1.485439. Batch_acc: 0.482278. Batch_loss: 1.443684 \n",
      "Batch: 1865. Acc: 0.466296. Loss: 1.485458. Batch_acc: 0.438418. Batch_loss: 1.519837 \n",
      "Batch: 1866. Acc: 0.466283. Loss: 1.485482. Batch_acc: 0.442353. Batch_loss: 1.532112 \n",
      "Batch: 1867. Acc: 0.466300. Loss: 1.485441. Batch_acc: 0.498554. Batch_loss: 1.408776 \n",
      "Batch: 1868. Acc: 0.466314. Loss: 1.485408. Batch_acc: 0.491652. Batch_loss: 1.422705 \n",
      "Batch: 1869. Acc: 0.466320. Loss: 1.485408. Batch_acc: 0.478413. Batch_loss: 1.485513 \n",
      "Batch: 1870. Acc: 0.466329. Loss: 1.485387. Batch_acc: 0.482010. Batch_loss: 1.446947 \n",
      "Batch: 1871. Acc: 0.466324. Loss: 1.485389. Batch_acc: 0.457410. Batch_loss: 1.490152 \n",
      "Batch: 1872. Acc: 0.466331. Loss: 1.485353. Batch_acc: 0.479703. Batch_loss: 1.416724 \n",
      "Batch: 1873. Acc: 0.466334. Loss: 1.485341. Batch_acc: 0.471437. Batch_loss: 1.463520 \n",
      "Batch: 1874. Acc: 0.466352. Loss: 1.485295. Batch_acc: 0.500283. Batch_loss: 1.400630 \n",
      "Batch: 1875. Acc: 0.466355. Loss: 1.485288. Batch_acc: 0.472042. Batch_loss: 1.472480 \n",
      "Batch: 1876. Acc: 0.466357. Loss: 1.485276. Batch_acc: 0.470588. Batch_loss: 1.462780 \n",
      "Batch: 1877. Acc: 0.466364. Loss: 1.485263. Batch_acc: 0.478480. Batch_loss: 1.460636 \n",
      "Batch: 1878. Acc: 0.466375. Loss: 1.485235. Batch_acc: 0.486564. Batch_loss: 1.433682 \n",
      "Batch: 1879. Acc: 0.466387. Loss: 1.485197. Batch_acc: 0.488902. Batch_loss: 1.411539 \n",
      "Batch: 1880. Acc: 0.466395. Loss: 1.485159. Batch_acc: 0.481718. Batch_loss: 1.414217 \n",
      "Batch: 1881. Acc: 0.466402. Loss: 1.485155. Batch_acc: 0.480092. Batch_loss: 1.476869 \n",
      "Batch: 1882. Acc: 0.466401. Loss: 1.485157. Batch_acc: 0.463859. Batch_loss: 1.488431 \n",
      "Batch: 1883. Acc: 0.466405. Loss: 1.485143. Batch_acc: 0.474747. Batch_loss: 1.459620 \n",
      "Batch: 1884. Acc: 0.466418. Loss: 1.485101. Batch_acc: 0.490555. Batch_loss: 1.406523 \n",
      "Batch: 1885. Acc: 0.466414. Loss: 1.485102. Batch_acc: 0.458742. Batch_loss: 1.488390 \n",
      "Batch: 1886. Acc: 0.466433. Loss: 1.485051. Batch_acc: 0.500843. Batch_loss: 1.389432 \n",
      "Batch: 1887. Acc: 0.466426. Loss: 1.485074. Batch_acc: 0.453405. Batch_loss: 1.531383 \n",
      "Batch: 1888. Acc: 0.466423. Loss: 1.485081. Batch_acc: 0.460489. Batch_loss: 1.497476 \n",
      "Batch: 1889. Acc: 0.466426. Loss: 1.485084. Batch_acc: 0.471949. Batch_loss: 1.491201 \n",
      "Batch: 1890. Acc: 0.466419. Loss: 1.485102. Batch_acc: 0.453650. Batch_loss: 1.520017 \n",
      "Batch: 1891. Acc: 0.466441. Loss: 1.485054. Batch_acc: 0.507585. Batch_loss: 1.392940 \n",
      "Batch: 1892. Acc: 0.466444. Loss: 1.485046. Batch_acc: 0.472286. Batch_loss: 1.468466 \n",
      "Batch: 1893. Acc: 0.466450. Loss: 1.485036. Batch_acc: 0.478681. Batch_loss: 1.467388 \n",
      "Batch: 1894. Acc: 0.466452. Loss: 1.485037. Batch_acc: 0.469654. Batch_loss: 1.485662 \n",
      "Batch: 1895. Acc: 0.466456. Loss: 1.485016. Batch_acc: 0.474985. Batch_loss: 1.445227 \n",
      "Batch: 1896. Acc: 0.466463. Loss: 1.484994. Batch_acc: 0.478363. Batch_loss: 1.443301 \n",
      "Batch: 1897. Acc: 0.466460. Loss: 1.484989. Batch_acc: 0.462464. Batch_loss: 1.474025 \n",
      "Batch: 1898. Acc: 0.466464. Loss: 1.484962. Batch_acc: 0.473684. Batch_loss: 1.435179 \n",
      "Batch: 1899. Acc: 0.466459. Loss: 1.484977. Batch_acc: 0.456130. Batch_loss: 1.513984 \n",
      "Batch: 1900. Acc: 0.466457. Loss: 1.484971. Batch_acc: 0.463542. Batch_loss: 1.472817 \n",
      "Batch: 1901. Acc: 0.466456. Loss: 1.484976. Batch_acc: 0.464056. Batch_loss: 1.495570 \n",
      "Batch: 1902. Acc: 0.466464. Loss: 1.484960. Batch_acc: 0.480858. Batch_loss: 1.453684 \n",
      "Batch: 1903. Acc: 0.466470. Loss: 1.484962. Batch_acc: 0.477733. Batch_loss: 1.489268 \n",
      "Batch: 1904. Acc: 0.466470. Loss: 1.484958. Batch_acc: 0.466551. Batch_loss: 1.476635 \n",
      "Batch: 1905. Acc: 0.466481. Loss: 1.484937. Batch_acc: 0.487298. Batch_loss: 1.446145 \n",
      "Batch: 1906. Acc: 0.466494. Loss: 1.484899. Batch_acc: 0.492281. Batch_loss: 1.411548 \n",
      "Batch: 1907. Acc: 0.466506. Loss: 1.484861. Batch_acc: 0.488426. Batch_loss: 1.412255 \n",
      "Batch: 1908. Acc: 0.466517. Loss: 1.484817. Batch_acc: 0.487251. Batch_loss: 1.404378 \n",
      "Batch: 1909. Acc: 0.466531. Loss: 1.484781. Batch_acc: 0.493151. Batch_loss: 1.416952 \n",
      "Batch: 1910. Acc: 0.466542. Loss: 1.484756. Batch_acc: 0.487734. Batch_loss: 1.435027 \n",
      "Batch: 1911. Acc: 0.466553. Loss: 1.484728. Batch_acc: 0.487654. Batch_loss: 1.433265 \n",
      "Batch: 1912. Acc: 0.466549. Loss: 1.484744. Batch_acc: 0.458432. Batch_loss: 1.516847 \n",
      "Batch: 1913. Acc: 0.466549. Loss: 1.484734. Batch_acc: 0.466667. Batch_loss: 1.464923 \n",
      "Batch: 1914. Acc: 0.466560. Loss: 1.484716. Batch_acc: 0.487647. Batch_loss: 1.449190 \n",
      "Batch: 1915. Acc: 0.466549. Loss: 1.484723. Batch_acc: 0.445900. Batch_loss: 1.497929 \n",
      "Batch: 1916. Acc: 0.466551. Loss: 1.484724. Batch_acc: 0.469626. Batch_loss: 1.486300 \n",
      "Batch: 1917. Acc: 0.466546. Loss: 1.484748. Batch_acc: 0.458382. Batch_loss: 1.530779 \n",
      "Batch: 1918. Acc: 0.466547. Loss: 1.484747. Batch_acc: 0.468511. Batch_loss: 1.483328 \n",
      "Batch: 1919. Acc: 0.466548. Loss: 1.484753. Batch_acc: 0.467540. Batch_loss: 1.495974 \n",
      "Batch: 1920. Acc: 0.466543. Loss: 1.484773. Batch_acc: 0.457289. Batch_loss: 1.523799 \n",
      "Batch: 1921. Acc: 0.466542. Loss: 1.484767. Batch_acc: 0.464912. Batch_loss: 1.473227 \n",
      "Batch: 1922. Acc: 0.466567. Loss: 1.484722. Batch_acc: 0.512792. Batch_loss: 1.399398 \n",
      "Batch: 1923. Acc: 0.466569. Loss: 1.484700. Batch_acc: 0.470554. Batch_loss: 1.443940 \n",
      "Batch: 1924. Acc: 0.466576. Loss: 1.484686. Batch_acc: 0.480138. Batch_loss: 1.457086 \n",
      "Batch: 1925. Acc: 0.466589. Loss: 1.484646. Batch_acc: 0.491497. Batch_loss: 1.409313 \n",
      "Batch: 1926. Acc: 0.466606. Loss: 1.484604. Batch_acc: 0.498006. Batch_loss: 1.403562 \n",
      "Batch: 1927. Acc: 0.466605. Loss: 1.484605. Batch_acc: 0.465649. Batch_loss: 1.487907 \n",
      "Batch: 1928. Acc: 0.466606. Loss: 1.484608. Batch_acc: 0.468212. Batch_loss: 1.489672 \n",
      "Batch: 1929. Acc: 0.466611. Loss: 1.484582. Batch_acc: 0.476562. Batch_loss: 1.436229 \n",
      "Batch: 1930. Acc: 0.466623. Loss: 1.484554. Batch_acc: 0.488266. Batch_loss: 1.430064 \n",
      "Batch: 1931. Acc: 0.466617. Loss: 1.484567. Batch_acc: 0.456522. Batch_loss: 1.509176 \n",
      "Batch: 1932. Acc: 0.466617. Loss: 1.484579. Batch_acc: 0.465557. Batch_loss: 1.508458 \n",
      "Batch: 1933. Acc: 0.466631. Loss: 1.484550. Batch_acc: 0.494085. Batch_loss: 1.429785 \n",
      "Batch: 1934. Acc: 0.466638. Loss: 1.484520. Batch_acc: 0.479492. Batch_loss: 1.426690 \n",
      "Batch: 1935. Acc: 0.466655. Loss: 1.484481. Batch_acc: 0.498026. Batch_loss: 1.409566 \n",
      "Batch: 1936. Acc: 0.466666. Loss: 1.484447. Batch_acc: 0.489118. Batch_loss: 1.418958 \n",
      "Batch: 1937. Acc: 0.466671. Loss: 1.484429. Batch_acc: 0.475185. Batch_loss: 1.450221 \n",
      "Batch: 1938. Acc: 0.466686. Loss: 1.484387. Batch_acc: 0.497130. Batch_loss: 1.402811 \n",
      "Batch: 1939. Acc: 0.466691. Loss: 1.484370. Batch_acc: 0.474886. Batch_loss: 1.451686 \n",
      "Batch: 1940. Acc: 0.466690. Loss: 1.484369. Batch_acc: 0.464641. Batch_loss: 1.481879 \n",
      "Batch: 1941. Acc: 0.466689. Loss: 1.484350. Batch_acc: 0.466037. Batch_loss: 1.446668 \n",
      "Batch: 1942. Acc: 0.466705. Loss: 1.484310. Batch_acc: 0.496575. Batch_loss: 1.407800 \n",
      "Batch: 1943. Acc: 0.466706. Loss: 1.484312. Batch_acc: 0.469757. Batch_loss: 1.488019 \n",
      "Batch: 1944. Acc: 0.466716. Loss: 1.484309. Batch_acc: 0.486239. Batch_loss: 1.479650 \n",
      "Batch: 1945. Acc: 0.466724. Loss: 1.484286. Batch_acc: 0.481948. Batch_loss: 1.439786 \n",
      "Batch: 1946. Acc: 0.466723. Loss: 1.484290. Batch_acc: 0.464435. Batch_loss: 1.491314 \n",
      "Batch: 1947. Acc: 0.466722. Loss: 1.484290. Batch_acc: 0.465116. Batch_loss: 1.484221 \n",
      "Batch: 1948. Acc: 0.466719. Loss: 1.484302. Batch_acc: 0.459336. Batch_loss: 1.508525 \n",
      "Batch: 1949. Acc: 0.466709. Loss: 1.484321. Batch_acc: 0.447368. Batch_loss: 1.521674 \n",
      "Batch: 1950. Acc: 0.466713. Loss: 1.484312. Batch_acc: 0.475476. Batch_loss: 1.465919 \n",
      "Batch: 1951. Acc: 0.466712. Loss: 1.484324. Batch_acc: 0.464060. Batch_loss: 1.507795 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1952. Acc: 0.466723. Loss: 1.484301. Batch_acc: 0.488902. Batch_loss: 1.439394 \n",
      "Batch: 1953. Acc: 0.466721. Loss: 1.484308. Batch_acc: 0.463060. Batch_loss: 1.498425 \n",
      "Batch: 1954. Acc: 0.466728. Loss: 1.484280. Batch_acc: 0.478905. Batch_loss: 1.428731 \n",
      "Batch: 1955. Acc: 0.466739. Loss: 1.484245. Batch_acc: 0.489068. Batch_loss: 1.417100 \n",
      "Batch: 1956. Acc: 0.466746. Loss: 1.484239. Batch_acc: 0.481034. Batch_loss: 1.472525 \n",
      "Batch: 1957. Acc: 0.466756. Loss: 1.484224. Batch_acc: 0.485857. Batch_loss: 1.455277 \n",
      "Batch: 1958. Acc: 0.466761. Loss: 1.484244. Batch_acc: 0.474828. Batch_loss: 1.523551 \n",
      "Batch: 1959. Acc: 0.466759. Loss: 1.484259. Batch_acc: 0.464539. Batch_loss: 1.513423 \n",
      "Batch: 1960. Acc: 0.466761. Loss: 1.484272. Batch_acc: 0.469617. Batch_loss: 1.511295 \n",
      "Batch: 1961. Acc: 0.466763. Loss: 1.484267. Batch_acc: 0.471591. Batch_loss: 1.473741 \n",
      "Batch: 1962. Acc: 0.466763. Loss: 1.484260. Batch_acc: 0.465692. Batch_loss: 1.470838 \n",
      "Batch: 1963. Acc: 0.466772. Loss: 1.484234. Batch_acc: 0.484501. Batch_loss: 1.433792 \n",
      "Batch: 1964. Acc: 0.466783. Loss: 1.484191. Batch_acc: 0.487613. Batch_loss: 1.401137 \n",
      "Batch: 1965. Acc: 0.466784. Loss: 1.484187. Batch_acc: 0.468804. Batch_loss: 1.477269 \n",
      "Batch: 1966. Acc: 0.466788. Loss: 1.484161. Batch_acc: 0.475998. Batch_loss: 1.432814 \n",
      "Batch: 1967. Acc: 0.466802. Loss: 1.484136. Batch_acc: 0.492795. Batch_loss: 1.433886 \n",
      "Batch: 1968. Acc: 0.466821. Loss: 1.484085. Batch_acc: 0.505125. Batch_loss: 1.385629 \n",
      "Batch: 1969. Acc: 0.466826. Loss: 1.484079. Batch_acc: 0.475728. Batch_loss: 1.472440 \n",
      "Batch: 1970. Acc: 0.466835. Loss: 1.484035. Batch_acc: 0.485252. Batch_loss: 1.396102 \n",
      "Batch: 1971. Acc: 0.466852. Loss: 1.483996. Batch_acc: 0.499713. Batch_loss: 1.408977 \n",
      "Batch: 1972. Acc: 0.466850. Loss: 1.483986. Batch_acc: 0.463231. Batch_loss: 1.462988 \n",
      "Batch: 1973. Acc: 0.466858. Loss: 1.483963. Batch_acc: 0.483852. Batch_loss: 1.436189 \n",
      "Batch: 1974. Acc: 0.466865. Loss: 1.483949. Batch_acc: 0.481138. Batch_loss: 1.456372 \n",
      "Batch: 1975. Acc: 0.466863. Loss: 1.483942. Batch_acc: 0.461584. Batch_loss: 1.469400 \n",
      "Batch: 1976. Acc: 0.466874. Loss: 1.483905. Batch_acc: 0.489068. Batch_loss: 1.412351 \n",
      "Batch: 1977. Acc: 0.466863. Loss: 1.483913. Batch_acc: 0.443600. Batch_loss: 1.499527 \n",
      "Batch: 1978. Acc: 0.466861. Loss: 1.483935. Batch_acc: 0.464245. Batch_loss: 1.526477 \n",
      "Batch: 1979. Acc: 0.466864. Loss: 1.483923. Batch_acc: 0.471923. Batch_loss: 1.462294 \n",
      "Batch: 1980. Acc: 0.466867. Loss: 1.483913. Batch_acc: 0.472477. Batch_loss: 1.462834 \n",
      "Batch: 1981. Acc: 0.466872. Loss: 1.483893. Batch_acc: 0.478009. Batch_loss: 1.445165 \n",
      "Batch: 1982. Acc: 0.466877. Loss: 1.483877. Batch_acc: 0.476110. Batch_loss: 1.452404 \n",
      "Batch: 1983. Acc: 0.466881. Loss: 1.483866. Batch_acc: 0.474245. Batch_loss: 1.460428 \n",
      "Batch: 1984. Acc: 0.466896. Loss: 1.483836. Batch_acc: 0.497453. Batch_loss: 1.425303 \n",
      "Batch: 1985. Acc: 0.466901. Loss: 1.483825. Batch_acc: 0.475745. Batch_loss: 1.462556 \n",
      "Batch: 1986. Acc: 0.466910. Loss: 1.483814. Batch_acc: 0.484901. Batch_loss: 1.462318 \n",
      "Batch: 1987. Acc: 0.466923. Loss: 1.483777. Batch_acc: 0.492420. Batch_loss: 1.410751 \n",
      "Batch: 1988. Acc: 0.466922. Loss: 1.483781. Batch_acc: 0.466008. Batch_loss: 1.492366 \n",
      "Batch: 1989. Acc: 0.466922. Loss: 1.483773. Batch_acc: 0.467208. Batch_loss: 1.468077 \n",
      "Batch: 1990. Acc: 0.466925. Loss: 1.483759. Batch_acc: 0.471774. Batch_loss: 1.455089 \n",
      "Batch: 1991. Acc: 0.466927. Loss: 1.483740. Batch_acc: 0.470723. Batch_loss: 1.446100 \n",
      "Batch: 1992. Acc: 0.466919. Loss: 1.483747. Batch_acc: 0.452489. Batch_loss: 1.498579 \n",
      "Batch: 1993. Acc: 0.466938. Loss: 1.483685. Batch_acc: 0.503937. Batch_loss: 1.363015 \n",
      "Batch: 1994. Acc: 0.466934. Loss: 1.483698. Batch_acc: 0.457657. Batch_loss: 1.508504 \n",
      "Batch: 1995. Acc: 0.466950. Loss: 1.483670. Batch_acc: 0.499712. Batch_loss: 1.428593 \n",
      "Batch: 1996. Acc: 0.466952. Loss: 1.483680. Batch_acc: 0.470175. Batch_loss: 1.503612 \n",
      "Batch: 1997. Acc: 0.466964. Loss: 1.483643. Batch_acc: 0.490074. Batch_loss: 1.411211 \n",
      "Batch: 1998. Acc: 0.466976. Loss: 1.483613. Batch_acc: 0.490662. Batch_loss: 1.423517 \n",
      "Batch: 1999. Acc: 0.466988. Loss: 1.483586. Batch_acc: 0.491486. Batch_loss: 1.429522 \n",
      "Batch: 2000. Acc: 0.466989. Loss: 1.483589. Batch_acc: 0.468696. Batch_loss: 1.488886 \n",
      "Batch: 2001. Acc: 0.466985. Loss: 1.483591. Batch_acc: 0.459757. Batch_loss: 1.488911 \n",
      "Batch: 2002. Acc: 0.466991. Loss: 1.483574. Batch_acc: 0.479930. Batch_loss: 1.448377 \n",
      "Batch: 2003. Acc: 0.466992. Loss: 1.483581. Batch_acc: 0.469016. Batch_loss: 1.498189 \n",
      "Batch: 2004. Acc: 0.466998. Loss: 1.483562. Batch_acc: 0.477681. Batch_loss: 1.445153 \n",
      "Batch: 2005. Acc: 0.467009. Loss: 1.483524. Batch_acc: 0.490741. Batch_loss: 1.405717 \n",
      "Batch: 2006. Acc: 0.467021. Loss: 1.483486. Batch_acc: 0.490762. Batch_loss: 1.408542 \n",
      "Batch: 2007. Acc: 0.467033. Loss: 1.483453. Batch_acc: 0.490379. Batch_loss: 1.416267 \n",
      "Batch: 2008. Acc: 0.467042. Loss: 1.483420. Batch_acc: 0.486564. Batch_loss: 1.417488 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.4670424626765411. Loss per char: 1.4834203679084434. Time: 1627215700.4277277\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 14, 17, 15, 21,  1, 14,  1, 14,\n",
      "        25, 22, 18, 22, 26, 22, 18, 18, 15, 18, 22, 22, 17, 19, 24, 15,  3,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.467048. Loss: 1.483417. Batch_acc: 0.479056. Batch_loss: 1.476205 \n",
      "Batch: 2010. Acc: 0.467041. Loss: 1.483436. Batch_acc: 0.452521. Batch_loss: 1.523158 \n",
      "Batch: 2011. Acc: 0.467044. Loss: 1.483424. Batch_acc: 0.472238. Batch_loss: 1.458639 \n",
      "Batch: 2012. Acc: 0.467057. Loss: 1.483388. Batch_acc: 0.492697. Batch_loss: 1.412516 \n",
      "Batch: 2013. Acc: 0.467077. Loss: 1.483341. Batch_acc: 0.507172. Batch_loss: 1.389209 \n",
      "Batch: 2014. Acc: 0.467075. Loss: 1.483350. Batch_acc: 0.462507. Batch_loss: 1.500676 \n",
      "Batch: 2015. Acc: 0.467092. Loss: 1.483298. Batch_acc: 0.501135. Batch_loss: 1.381343 \n",
      "Batch: 2016. Acc: 0.467105. Loss: 1.483271. Batch_acc: 0.492918. Batch_loss: 1.429274 \n",
      "Batch: 2017. Acc: 0.467112. Loss: 1.483252. Batch_acc: 0.481760. Batch_loss: 1.444302 \n",
      "Batch: 2018. Acc: 0.467119. Loss: 1.483234. Batch_acc: 0.480647. Batch_loss: 1.446385 \n",
      "Batch: 2019. Acc: 0.467121. Loss: 1.483231. Batch_acc: 0.472174. Batch_loss: 1.477048 \n",
      "Batch: 2020. Acc: 0.467123. Loss: 1.483234. Batch_acc: 0.471645. Batch_loss: 1.490876 \n",
      "Batch: 2021. Acc: 0.467128. Loss: 1.483199. Batch_acc: 0.475319. Batch_loss: 1.414016 \n",
      "Batch: 2022. Acc: 0.467136. Loss: 1.483176. Batch_acc: 0.482817. Batch_loss: 1.438324 \n",
      "Batch: 2023. Acc: 0.467153. Loss: 1.483144. Batch_acc: 0.502857. Batch_loss: 1.418895 \n",
      "Batch: 2024. Acc: 0.467154. Loss: 1.483154. Batch_acc: 0.468732. Batch_loss: 1.503279 \n",
      "Batch: 2025. Acc: 0.467167. Loss: 1.483122. Batch_acc: 0.494973. Batch_loss: 1.416593 \n",
      "Batch: 2026. Acc: 0.467173. Loss: 1.483101. Batch_acc: 0.478760. Batch_loss: 1.440755 \n",
      "Batch: 2027. Acc: 0.467160. Loss: 1.483124. Batch_acc: 0.440383. Batch_loss: 1.530660 \n",
      "Batch: 2028. Acc: 0.467165. Loss: 1.483112. Batch_acc: 0.477312. Batch_loss: 1.458564 \n",
      "Batch: 2029. Acc: 0.467168. Loss: 1.483104. Batch_acc: 0.472864. Batch_loss: 1.467064 \n",
      "Batch: 2030. Acc: 0.467153. Loss: 1.483127. Batch_acc: 0.436970. Batch_loss: 1.528429 \n",
      "Batch: 2031. Acc: 0.467158. Loss: 1.483103. Batch_acc: 0.477431. Batch_loss: 1.435156 \n",
      "Batch: 2032. Acc: 0.467154. Loss: 1.483119. Batch_acc: 0.459475. Batch_loss: 1.516095 \n",
      "Batch: 2033. Acc: 0.467160. Loss: 1.483114. Batch_acc: 0.478336. Batch_loss: 1.473112 \n",
      "Batch: 2034. Acc: 0.467171. Loss: 1.483090. Batch_acc: 0.489960. Batch_loss: 1.434206 \n",
      "Batch: 2035. Acc: 0.467175. Loss: 1.483068. Batch_acc: 0.474041. Batch_loss: 1.438777 \n",
      "Batch: 2036. Acc: 0.467185. Loss: 1.483036. Batch_acc: 0.489060. Batch_loss: 1.415500 \n",
      "Batch: 2037. Acc: 0.467199. Loss: 1.483006. Batch_acc: 0.494690. Batch_loss: 1.425056 \n",
      "Batch: 2038. Acc: 0.467211. Loss: 1.482976. Batch_acc: 0.490374. Batch_loss: 1.422412 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2039. Acc: 0.467220. Loss: 1.482954. Batch_acc: 0.485666. Batch_loss: 1.438519 \n",
      "Batch: 2040. Acc: 0.467225. Loss: 1.482932. Batch_acc: 0.478136. Batch_loss: 1.438610 \n",
      "Batch: 2041. Acc: 0.467234. Loss: 1.482913. Batch_acc: 0.484348. Batch_loss: 1.445059 \n",
      "Batch: 2042. Acc: 0.467253. Loss: 1.482857. Batch_acc: 0.507745. Batch_loss: 1.367472 \n",
      "Batch: 2043. Acc: 0.467246. Loss: 1.482870. Batch_acc: 0.451234. Batch_loss: 1.510579 \n",
      "Batch: 2044. Acc: 0.467249. Loss: 1.482852. Batch_acc: 0.473349. Batch_loss: 1.445727 \n",
      "Batch: 2045. Acc: 0.467258. Loss: 1.482818. Batch_acc: 0.487062. Batch_loss: 1.413614 \n",
      "Batch: 2046. Acc: 0.467277. Loss: 1.482763. Batch_acc: 0.503679. Batch_loss: 1.371423 \n",
      "Batch: 2047. Acc: 0.467279. Loss: 1.482740. Batch_acc: 0.471904. Batch_loss: 1.437303 \n",
      "Batch: 2048. Acc: 0.467275. Loss: 1.482749. Batch_acc: 0.458430. Batch_loss: 1.499581 \n",
      "Batch: 2049. Acc: 0.467275. Loss: 1.482734. Batch_acc: 0.467770. Batch_loss: 1.452887 \n",
      "Batch: 2050. Acc: 0.467287. Loss: 1.482695. Batch_acc: 0.491208. Batch_loss: 1.403748 \n",
      "Batch: 2051. Acc: 0.467294. Loss: 1.482674. Batch_acc: 0.481546. Batch_loss: 1.439092 \n",
      "Batch: 2052. Acc: 0.467297. Loss: 1.482674. Batch_acc: 0.474771. Batch_loss: 1.482463 \n",
      "Batch: 2053. Acc: 0.467304. Loss: 1.482651. Batch_acc: 0.481928. Batch_loss: 1.436105 \n",
      "Batch: 2054. Acc: 0.467304. Loss: 1.482646. Batch_acc: 0.466037. Batch_loss: 1.471845 \n",
      "Batch: 2055. Acc: 0.467312. Loss: 1.482608. Batch_acc: 0.484795. Batch_loss: 1.403864 \n",
      "Batch: 2056. Acc: 0.467321. Loss: 1.482594. Batch_acc: 0.486364. Batch_loss: 1.453556 \n",
      "Batch: 2057. Acc: 0.467329. Loss: 1.482565. Batch_acc: 0.482163. Batch_loss: 1.423402 \n",
      "Batch: 2058. Acc: 0.467337. Loss: 1.482533. Batch_acc: 0.484763. Batch_loss: 1.417800 \n",
      "Batch: 2059. Acc: 0.467343. Loss: 1.482527. Batch_acc: 0.478816. Batch_loss: 1.469969 \n",
      "Batch: 2060. Acc: 0.467348. Loss: 1.482523. Batch_acc: 0.478760. Batch_loss: 1.474549 \n",
      "Batch: 2061. Acc: 0.467342. Loss: 1.482531. Batch_acc: 0.454911. Batch_loss: 1.498848 \n",
      "Batch: 2062. Acc: 0.467348. Loss: 1.482521. Batch_acc: 0.478338. Batch_loss: 1.462078 \n",
      "Batch: 2063. Acc: 0.467356. Loss: 1.482491. Batch_acc: 0.485006. Batch_loss: 1.420323 \n",
      "Batch: 2064. Acc: 0.467364. Loss: 1.482452. Batch_acc: 0.484375. Batch_loss: 1.400141 \n",
      "Batch: 2065. Acc: 0.467376. Loss: 1.482427. Batch_acc: 0.490899. Batch_loss: 1.432539 \n",
      "Batch: 2066. Acc: 0.467374. Loss: 1.482424. Batch_acc: 0.463401. Batch_loss: 1.475932 \n",
      "Batch: 2067. Acc: 0.467379. Loss: 1.482422. Batch_acc: 0.478987. Batch_loss: 1.479279 \n",
      "Batch: 2068. Acc: 0.467402. Loss: 1.482369. Batch_acc: 0.512557. Batch_loss: 1.371843 \n",
      "Batch: 2069. Acc: 0.467412. Loss: 1.482352. Batch_acc: 0.488837. Batch_loss: 1.448490 \n",
      "Batch: 2070. Acc: 0.467428. Loss: 1.482309. Batch_acc: 0.501446. Batch_loss: 1.390875 \n",
      "Batch: 2071. Acc: 0.467425. Loss: 1.482327. Batch_acc: 0.462117. Batch_loss: 1.520152 \n",
      "Batch: 2072. Acc: 0.467426. Loss: 1.482321. Batch_acc: 0.468605. Batch_loss: 1.469857 \n",
      "Batch: 2073. Acc: 0.467437. Loss: 1.482285. Batch_acc: 0.491197. Batch_loss: 1.407608 \n",
      "Batch: 2074. Acc: 0.467451. Loss: 1.482249. Batch_acc: 0.495775. Batch_loss: 1.408986 \n",
      "Batch: 2075. Acc: 0.467454. Loss: 1.482244. Batch_acc: 0.472823. Batch_loss: 1.470394 \n",
      "Batch: 2076. Acc: 0.467453. Loss: 1.482256. Batch_acc: 0.465929. Batch_loss: 1.508108 \n",
      "Batch: 2077. Acc: 0.467455. Loss: 1.482240. Batch_acc: 0.471526. Batch_loss: 1.449942 \n",
      "Batch: 2078. Acc: 0.467461. Loss: 1.482222. Batch_acc: 0.479287. Batch_loss: 1.443364 \n",
      "Batch: 2079. Acc: 0.467469. Loss: 1.482198. Batch_acc: 0.485387. Batch_loss: 1.433670 \n",
      "Batch: 2080. Acc: 0.467477. Loss: 1.482169. Batch_acc: 0.484634. Batch_loss: 1.420298 \n",
      "Batch: 2081. Acc: 0.467482. Loss: 1.482160. Batch_acc: 0.476109. Batch_loss: 1.464139 \n",
      "Batch: 2082. Acc: 0.467480. Loss: 1.482166. Batch_acc: 0.463372. Batch_loss: 1.493195 \n",
      "Batch: 2083. Acc: 0.467467. Loss: 1.482185. Batch_acc: 0.442008. Batch_loss: 1.521975 \n",
      "Batch: 2084. Acc: 0.467479. Loss: 1.482160. Batch_acc: 0.492991. Batch_loss: 1.429273 \n",
      "Batch: 2085. Acc: 0.467480. Loss: 1.482147. Batch_acc: 0.468862. Batch_loss: 1.454357 \n",
      "Batch: 2086. Acc: 0.467485. Loss: 1.482121. Batch_acc: 0.477544. Batch_loss: 1.429176 \n",
      "Batch: 2087. Acc: 0.467496. Loss: 1.482105. Batch_acc: 0.489855. Batch_loss: 1.447125 \n",
      "Batch: 2088. Acc: 0.467512. Loss: 1.482067. Batch_acc: 0.502001. Batch_loss: 1.403311 \n",
      "Batch: 2089. Acc: 0.467524. Loss: 1.482031. Batch_acc: 0.491438. Batch_loss: 1.407488 \n",
      "Batch: 2090. Acc: 0.467524. Loss: 1.482018. Batch_acc: 0.467532. Batch_loss: 1.455590 \n",
      "Batch: 2091. Acc: 0.467520. Loss: 1.482018. Batch_acc: 0.459522. Batch_loss: 1.481570 \n",
      "Batch: 2092. Acc: 0.467521. Loss: 1.482007. Batch_acc: 0.469410. Batch_loss: 1.461516 \n",
      "Batch: 2093. Acc: 0.467532. Loss: 1.481965. Batch_acc: 0.490847. Batch_loss: 1.393702 \n",
      "Batch: 2094. Acc: 0.467539. Loss: 1.481949. Batch_acc: 0.481203. Batch_loss: 1.447923 \n",
      "Batch: 2095. Acc: 0.467541. Loss: 1.481939. Batch_acc: 0.472832. Batch_loss: 1.461631 \n",
      "Batch: 2096. Acc: 0.467551. Loss: 1.481903. Batch_acc: 0.488748. Batch_loss: 1.406786 \n",
      "Batch: 2097. Acc: 0.467552. Loss: 1.481899. Batch_acc: 0.468427. Batch_loss: 1.473352 \n",
      "Batch: 2098. Acc: 0.467562. Loss: 1.481869. Batch_acc: 0.488902. Batch_loss: 1.419184 \n",
      "Batch: 2099. Acc: 0.467573. Loss: 1.481842. Batch_acc: 0.491545. Batch_loss: 1.423764 \n",
      "Batch: 2100. Acc: 0.467579. Loss: 1.481837. Batch_acc: 0.480549. Batch_loss: 1.471064 \n",
      "Batch: 2101. Acc: 0.467576. Loss: 1.481837. Batch_acc: 0.460187. Batch_loss: 1.482403 \n",
      "Batch: 2102. Acc: 0.467582. Loss: 1.481833. Batch_acc: 0.480380. Batch_loss: 1.472955 \n",
      "Batch: 2103. Acc: 0.467583. Loss: 1.481817. Batch_acc: 0.470757. Batch_loss: 1.449596 \n",
      "Batch: 2104. Acc: 0.467584. Loss: 1.481798. Batch_acc: 0.468448. Batch_loss: 1.441008 \n",
      "Batch: 2105. Acc: 0.467594. Loss: 1.481784. Batch_acc: 0.489250. Batch_loss: 1.452176 \n",
      "Batch: 2106. Acc: 0.467598. Loss: 1.481779. Batch_acc: 0.476380. Batch_loss: 1.470566 \n",
      "Batch: 2107. Acc: 0.467594. Loss: 1.481775. Batch_acc: 0.458072. Batch_loss: 1.474108 \n",
      "Batch: 2108. Acc: 0.467592. Loss: 1.481763. Batch_acc: 0.464286. Batch_loss: 1.456890 \n",
      "Batch: 2109. Acc: 0.467593. Loss: 1.481762. Batch_acc: 0.470145. Batch_loss: 1.480512 \n",
      "Batch: 2110. Acc: 0.467595. Loss: 1.481751. Batch_acc: 0.471103. Batch_loss: 1.456651 \n",
      "Batch: 2111. Acc: 0.467597. Loss: 1.481742. Batch_acc: 0.473118. Batch_loss: 1.462820 \n",
      "Batch: 2112. Acc: 0.467602. Loss: 1.481719. Batch_acc: 0.477663. Batch_loss: 1.432225 \n",
      "Batch: 2113. Acc: 0.467595. Loss: 1.481741. Batch_acc: 0.452103. Batch_loss: 1.530807 \n",
      "Batch: 2114. Acc: 0.467589. Loss: 1.481749. Batch_acc: 0.455220. Batch_loss: 1.497854 \n",
      "Batch: 2115. Acc: 0.467599. Loss: 1.481725. Batch_acc: 0.488995. Batch_loss: 1.429477 \n",
      "Batch: 2116. Acc: 0.467605. Loss: 1.481713. Batch_acc: 0.481417. Batch_loss: 1.454771 \n",
      "Batch: 2117. Acc: 0.467621. Loss: 1.481684. Batch_acc: 0.500293. Batch_loss: 1.420925 \n",
      "Batch: 2118. Acc: 0.467622. Loss: 1.481664. Batch_acc: 0.471461. Batch_loss: 1.438734 \n",
      "Batch: 2119. Acc: 0.467630. Loss: 1.481626. Batch_acc: 0.483555. Batch_loss: 1.400586 \n",
      "Batch: 2120. Acc: 0.467628. Loss: 1.481626. Batch_acc: 0.463726. Batch_loss: 1.481186 \n",
      "Batch: 2121. Acc: 0.467624. Loss: 1.481637. Batch_acc: 0.459686. Batch_loss: 1.504364 \n",
      "Batch: 2122. Acc: 0.467636. Loss: 1.481612. Batch_acc: 0.492804. Batch_loss: 1.429874 \n",
      "Batch: 2123. Acc: 0.467654. Loss: 1.481577. Batch_acc: 0.504789. Batch_loss: 1.408538 \n",
      "Batch: 2124. Acc: 0.467664. Loss: 1.481552. Batch_acc: 0.489300. Batch_loss: 1.427676 \n",
      "Batch: 2125. Acc: 0.467677. Loss: 1.481513. Batch_acc: 0.494581. Batch_loss: 1.400016 \n",
      "Batch: 2126. Acc: 0.467684. Loss: 1.481494. Batch_acc: 0.483429. Batch_loss: 1.440626 \n",
      "Batch: 2127. Acc: 0.467692. Loss: 1.481471. Batch_acc: 0.483362. Batch_loss: 1.433022 \n",
      "Batch: 2128. Acc: 0.467698. Loss: 1.481458. Batch_acc: 0.479730. Batch_loss: 1.454911 \n",
      "Batch: 2129. Acc: 0.467704. Loss: 1.481437. Batch_acc: 0.482174. Batch_loss: 1.435761 \n",
      "Batch: 2130. Acc: 0.467713. Loss: 1.481411. Batch_acc: 0.486797. Batch_loss: 1.426860 \n",
      "Batch: 2131. Acc: 0.467725. Loss: 1.481391. Batch_acc: 0.492625. Batch_loss: 1.437957 \n",
      "Batch: 2132. Acc: 0.467737. Loss: 1.481369. Batch_acc: 0.494512. Batch_loss: 1.433537 \n",
      "Batch: 2133. Acc: 0.467733. Loss: 1.481369. Batch_acc: 0.459582. Batch_loss: 1.481955 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2134. Acc: 0.467739. Loss: 1.481344. Batch_acc: 0.479011. Batch_loss: 1.427699 \n",
      "Batch: 2135. Acc: 0.467744. Loss: 1.481337. Batch_acc: 0.480213. Batch_loss: 1.465802 \n",
      "Batch: 2136. Acc: 0.467748. Loss: 1.481327. Batch_acc: 0.475042. Batch_loss: 1.460069 \n",
      "Batch: 2137. Acc: 0.467753. Loss: 1.481310. Batch_acc: 0.479094. Batch_loss: 1.446330 \n",
      "Batch: 2138. Acc: 0.467762. Loss: 1.481281. Batch_acc: 0.487571. Batch_loss: 1.419211 \n",
      "Batch: 2139. Acc: 0.467771. Loss: 1.481254. Batch_acc: 0.485814. Batch_loss: 1.423732 \n",
      "Batch: 2140. Acc: 0.467789. Loss: 1.481213. Batch_acc: 0.507188. Batch_loss: 1.392176 \n",
      "Batch: 2141. Acc: 0.467794. Loss: 1.481186. Batch_acc: 0.478809. Batch_loss: 1.425772 \n",
      "Batch: 2142. Acc: 0.467803. Loss: 1.481168. Batch_acc: 0.487047. Batch_loss: 1.440541 \n",
      "Batch: 2143. Acc: 0.467818. Loss: 1.481130. Batch_acc: 0.499425. Batch_loss: 1.401866 \n",
      "Batch: 2144. Acc: 0.467813. Loss: 1.481138. Batch_acc: 0.457241. Batch_loss: 1.496267 \n",
      "Batch: 2145. Acc: 0.467807. Loss: 1.481142. Batch_acc: 0.455372. Batch_loss: 1.489957 \n",
      "Batch: 2146. Acc: 0.467810. Loss: 1.481111. Batch_acc: 0.473684. Batch_loss: 1.416736 \n",
      "Batch: 2147. Acc: 0.467826. Loss: 1.481062. Batch_acc: 0.501138. Batch_loss: 1.376054 \n",
      "Batch: 2148. Acc: 0.467841. Loss: 1.481027. Batch_acc: 0.500291. Batch_loss: 1.405738 \n",
      "Batch: 2149. Acc: 0.467850. Loss: 1.480985. Batch_acc: 0.487777. Batch_loss: 1.391535 \n",
      "Batch: 2150. Acc: 0.467860. Loss: 1.480964. Batch_acc: 0.488914. Batch_loss: 1.435657 \n",
      "Batch: 2151. Acc: 0.467861. Loss: 1.480970. Batch_acc: 0.470824. Batch_loss: 1.493516 \n",
      "Batch: 2152. Acc: 0.467868. Loss: 1.480938. Batch_acc: 0.481781. Batch_loss: 1.412512 \n",
      "Batch: 2153. Acc: 0.467875. Loss: 1.480926. Batch_acc: 0.482298. Batch_loss: 1.455077 \n",
      "Batch: 2154. Acc: 0.467873. Loss: 1.480920. Batch_acc: 0.465157. Batch_loss: 1.468904 \n",
      "Batch: 2155. Acc: 0.467882. Loss: 1.480896. Batch_acc: 0.485879. Batch_loss: 1.428789 \n",
      "Batch: 2156. Acc: 0.467879. Loss: 1.480904. Batch_acc: 0.462085. Batch_loss: 1.498295 \n",
      "Batch: 2157. Acc: 0.467879. Loss: 1.480901. Batch_acc: 0.468804. Batch_loss: 1.473204 \n",
      "Batch: 2158. Acc: 0.467886. Loss: 1.480894. Batch_acc: 0.481651. Batch_loss: 1.466205 \n",
      "Batch: 2159. Acc: 0.467896. Loss: 1.480851. Batch_acc: 0.490424. Batch_loss: 1.388706 \n",
      "Batch: 2160. Acc: 0.467902. Loss: 1.480828. Batch_acc: 0.479437. Batch_loss: 1.431383 \n",
      "Batch: 2161. Acc: 0.467912. Loss: 1.480795. Batch_acc: 0.489631. Batch_loss: 1.410318 \n",
      "Batch: 2162. Acc: 0.467924. Loss: 1.480766. Batch_acc: 0.494357. Batch_loss: 1.418656 \n",
      "Batch: 2163. Acc: 0.467925. Loss: 1.480758. Batch_acc: 0.470826. Batch_loss: 1.462246 \n",
      "Batch: 2164. Acc: 0.467937. Loss: 1.480731. Batch_acc: 0.493560. Batch_loss: 1.421378 \n",
      "Batch: 2165. Acc: 0.467945. Loss: 1.480708. Batch_acc: 0.485087. Batch_loss: 1.433223 \n",
      "Batch: 2166. Acc: 0.467950. Loss: 1.480708. Batch_acc: 0.479143. Batch_loss: 1.479860 \n",
      "Batch: 2167. Acc: 0.467956. Loss: 1.480681. Batch_acc: 0.479131. Batch_loss: 1.422965 \n",
      "Batch: 2168. Acc: 0.467970. Loss: 1.480635. Batch_acc: 0.500297. Batch_loss: 1.377670 \n",
      "Batch: 2169. Acc: 0.467989. Loss: 1.480595. Batch_acc: 0.508703. Batch_loss: 1.395280 \n",
      "Batch: 2170. Acc: 0.467994. Loss: 1.480581. Batch_acc: 0.478363. Batch_loss: 1.449468 \n",
      "Batch: 2171. Acc: 0.468014. Loss: 1.480531. Batch_acc: 0.510181. Batch_loss: 1.373612 \n",
      "Batch: 2172. Acc: 0.468025. Loss: 1.480491. Batch_acc: 0.491954. Batch_loss: 1.395177 \n",
      "Batch: 2173. Acc: 0.468046. Loss: 1.480435. Batch_acc: 0.513360. Batch_loss: 1.359545 \n",
      "Batch: 2174. Acc: 0.468051. Loss: 1.480422. Batch_acc: 0.480319. Batch_loss: 1.451975 \n",
      "Batch: 2175. Acc: 0.468068. Loss: 1.480383. Batch_acc: 0.504939. Batch_loss: 1.396454 \n",
      "Batch: 2176. Acc: 0.468068. Loss: 1.480375. Batch_acc: 0.467622. Batch_loss: 1.463012 \n",
      "Batch: 2177. Acc: 0.468066. Loss: 1.480390. Batch_acc: 0.464037. Batch_loss: 1.512659 \n",
      "Batch: 2178. Acc: 0.468076. Loss: 1.480361. Batch_acc: 0.488623. Batch_loss: 1.417278 \n",
      "Batch: 2179. Acc: 0.468078. Loss: 1.480347. Batch_acc: 0.472139. Batch_loss: 1.448176 \n",
      "Batch: 2180. Acc: 0.468074. Loss: 1.480342. Batch_acc: 0.461362. Batch_loss: 1.471210 \n",
      "Batch: 2181. Acc: 0.468077. Loss: 1.480329. Batch_acc: 0.472873. Batch_loss: 1.451608 \n",
      "Batch: 2182. Acc: 0.468084. Loss: 1.480311. Batch_acc: 0.483541. Batch_loss: 1.441512 \n",
      "Batch: 2183. Acc: 0.468087. Loss: 1.480290. Batch_acc: 0.475734. Batch_loss: 1.435673 \n",
      "Batch: 2184. Acc: 0.468101. Loss: 1.480254. Batch_acc: 0.496587. Batch_loss: 1.400729 \n",
      "Batch: 2185. Acc: 0.468104. Loss: 1.480236. Batch_acc: 0.475917. Batch_loss: 1.441754 \n",
      "Batch: 2186. Acc: 0.468109. Loss: 1.480201. Batch_acc: 0.479250. Batch_loss: 1.404603 \n",
      "Batch: 2187. Acc: 0.468106. Loss: 1.480201. Batch_acc: 0.459918. Batch_loss: 1.481584 \n",
      "Batch: 2188. Acc: 0.468114. Loss: 1.480176. Batch_acc: 0.486320. Batch_loss: 1.425111 \n",
      "Batch: 2189. Acc: 0.468123. Loss: 1.480149. Batch_acc: 0.488116. Batch_loss: 1.421750 \n",
      "Batch: 2190. Acc: 0.468134. Loss: 1.480112. Batch_acc: 0.490950. Batch_loss: 1.399868 \n",
      "Batch: 2191. Acc: 0.468145. Loss: 1.480076. Batch_acc: 0.492459. Batch_loss: 1.400536 \n",
      "Batch: 2192. Acc: 0.468152. Loss: 1.480049. Batch_acc: 0.483510. Batch_loss: 1.419785 \n",
      "Batch: 2193. Acc: 0.468175. Loss: 1.480000. Batch_acc: 0.517949. Batch_loss: 1.372890 \n",
      "Batch: 2194. Acc: 0.468180. Loss: 1.479984. Batch_acc: 0.480236. Batch_loss: 1.445743 \n",
      "Batch: 2195. Acc: 0.468184. Loss: 1.479982. Batch_acc: 0.476027. Batch_loss: 1.475185 \n",
      "Batch: 2196. Acc: 0.468182. Loss: 1.479981. Batch_acc: 0.464865. Batch_loss: 1.478269 \n",
      "Batch: 2197. Acc: 0.468189. Loss: 1.479962. Batch_acc: 0.483761. Batch_loss: 1.437807 \n",
      "Batch: 2198. Acc: 0.468188. Loss: 1.479974. Batch_acc: 0.465467. Batch_loss: 1.507655 \n",
      "Batch: 2199. Acc: 0.468201. Loss: 1.479946. Batch_acc: 0.495717. Batch_loss: 1.417953 \n",
      "Batch: 2200. Acc: 0.468209. Loss: 1.479925. Batch_acc: 0.486423. Batch_loss: 1.432313 \n",
      "Batch: 2201. Acc: 0.468219. Loss: 1.479897. Batch_acc: 0.489205. Batch_loss: 1.418226 \n",
      "Batch: 2202. Acc: 0.468220. Loss: 1.479892. Batch_acc: 0.471159. Batch_loss: 1.469904 \n",
      "Batch: 2203. Acc: 0.468228. Loss: 1.479878. Batch_acc: 0.485092. Batch_loss: 1.449576 \n",
      "Batch: 2204. Acc: 0.468244. Loss: 1.479842. Batch_acc: 0.504832. Batch_loss: 1.401949 \n",
      "Batch: 2205. Acc: 0.468251. Loss: 1.479819. Batch_acc: 0.482143. Batch_loss: 1.427840 \n",
      "Batch: 2206. Acc: 0.468263. Loss: 1.479788. Batch_acc: 0.496789. Batch_loss: 1.411407 \n",
      "Batch: 2207. Acc: 0.468262. Loss: 1.479788. Batch_acc: 0.465009. Batch_loss: 1.478512 \n",
      "Batch: 2208. Acc: 0.468264. Loss: 1.479772. Batch_acc: 0.473533. Batch_loss: 1.444171 \n",
      "Batch: 2209. Acc: 0.468273. Loss: 1.479741. Batch_acc: 0.487209. Batch_loss: 1.413775 \n",
      "Batch: 2210. Acc: 0.468282. Loss: 1.479729. Batch_acc: 0.487763. Batch_loss: 1.451624 \n",
      "Batch: 2211. Acc: 0.468288. Loss: 1.479709. Batch_acc: 0.481417. Batch_loss: 1.435563 \n",
      "Batch: 2212. Acc: 0.468291. Loss: 1.479695. Batch_acc: 0.475305. Batch_loss: 1.448273 \n",
      "Batch: 2213. Acc: 0.468302. Loss: 1.479681. Batch_acc: 0.493258. Batch_loss: 1.450941 \n",
      "Batch: 2214. Acc: 0.468316. Loss: 1.479651. Batch_acc: 0.497725. Batch_loss: 1.413384 \n",
      "Batch: 2215. Acc: 0.468319. Loss: 1.479639. Batch_acc: 0.474854. Batch_loss: 1.452100 \n",
      "Batch: 2216. Acc: 0.468328. Loss: 1.479606. Batch_acc: 0.488675. Batch_loss: 1.408916 \n",
      "Batch: 2217. Acc: 0.468342. Loss: 1.479563. Batch_acc: 0.497512. Batch_loss: 1.387793 \n",
      "Batch: 2218. Acc: 0.468350. Loss: 1.479532. Batch_acc: 0.486095. Batch_loss: 1.410323 \n",
      "Batch: 2219. Acc: 0.468351. Loss: 1.479515. Batch_acc: 0.471891. Batch_loss: 1.440596 \n",
      "Batch: 2220. Acc: 0.468348. Loss: 1.479501. Batch_acc: 0.460419. Batch_loss: 1.450070 \n",
      "Batch: 2221. Acc: 0.468351. Loss: 1.479499. Batch_acc: 0.475496. Batch_loss: 1.474172 \n",
      "Batch: 2222. Acc: 0.468363. Loss: 1.479460. Batch_acc: 0.494104. Batch_loss: 1.394075 \n",
      "Batch: 2223. Acc: 0.468367. Loss: 1.479442. Batch_acc: 0.477032. Batch_loss: 1.438146 \n",
      "Batch: 2224. Acc: 0.468369. Loss: 1.479431. Batch_acc: 0.472996. Batch_loss: 1.456548 \n",
      "Batch: 2225. Acc: 0.468371. Loss: 1.479417. Batch_acc: 0.472614. Batch_loss: 1.449328 \n",
      "Batch: 2226. Acc: 0.468372. Loss: 1.479417. Batch_acc: 0.471859. Batch_loss: 1.478500 \n",
      "Batch: 2227. Acc: 0.468379. Loss: 1.479408. Batch_acc: 0.483070. Batch_loss: 1.459500 \n",
      "Batch: 2228. Acc: 0.468381. Loss: 1.479415. Batch_acc: 0.472989. Batch_loss: 1.495073 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2229. Acc: 0.468384. Loss: 1.479405. Batch_acc: 0.474665. Batch_loss: 1.458197 \n",
      "Batch: 2230. Acc: 0.468383. Loss: 1.479403. Batch_acc: 0.467179. Batch_loss: 1.473397 \n",
      "Batch: 2231. Acc: 0.468390. Loss: 1.479379. Batch_acc: 0.482022. Batch_loss: 1.428394 \n",
      "Batch: 2232. Acc: 0.468403. Loss: 1.479337. Batch_acc: 0.497430. Batch_loss: 1.385151 \n",
      "Batch: 2233. Acc: 0.468408. Loss: 1.479313. Batch_acc: 0.480890. Batch_loss: 1.426186 \n",
      "Batch: 2234. Acc: 0.468415. Loss: 1.479285. Batch_acc: 0.482072. Batch_loss: 1.417736 \n",
      "Batch: 2235. Acc: 0.468416. Loss: 1.479279. Batch_acc: 0.471056. Batch_loss: 1.466407 \n",
      "Batch: 2236. Acc: 0.468408. Loss: 1.479283. Batch_acc: 0.451541. Batch_loss: 1.487147 \n",
      "Batch: 2237. Acc: 0.468421. Loss: 1.479249. Batch_acc: 0.496823. Batch_loss: 1.403798 \n",
      "Batch: 2238. Acc: 0.468427. Loss: 1.479230. Batch_acc: 0.484002. Batch_loss: 1.436936 \n",
      "Batch: 2239. Acc: 0.468427. Loss: 1.479230. Batch_acc: 0.468326. Batch_loss: 1.478647 \n",
      "Batch: 2240. Acc: 0.468434. Loss: 1.479223. Batch_acc: 0.482063. Batch_loss: 1.462950 \n",
      "Batch: 2241. Acc: 0.468447. Loss: 1.479185. Batch_acc: 0.498297. Batch_loss: 1.396233 \n",
      "Batch: 2242. Acc: 0.468462. Loss: 1.479165. Batch_acc: 0.499175. Batch_loss: 1.437207 \n",
      "Batch: 2243. Acc: 0.468469. Loss: 1.479150. Batch_acc: 0.484429. Batch_loss: 1.443496 \n",
      "Batch: 2244. Acc: 0.468481. Loss: 1.479109. Batch_acc: 0.496072. Batch_loss: 1.390753 \n",
      "Batch: 2245. Acc: 0.468496. Loss: 1.479072. Batch_acc: 0.500860. Batch_loss: 1.395841 \n",
      "Batch: 2246. Acc: 0.468506. Loss: 1.479032. Batch_acc: 0.491289. Batch_loss: 1.387798 \n",
      "Batch: 2247. Acc: 0.468510. Loss: 1.479019. Batch_acc: 0.477069. Batch_loss: 1.450727 \n",
      "Batch: 2248. Acc: 0.468513. Loss: 1.479017. Batch_acc: 0.475014. Batch_loss: 1.475412 \n",
      "Batch: 2249. Acc: 0.468521. Loss: 1.478994. Batch_acc: 0.486592. Batch_loss: 1.427518 \n",
      "Batch: 2250. Acc: 0.468521. Loss: 1.478981. Batch_acc: 0.467779. Batch_loss: 1.451791 \n",
      "Batch: 2251. Acc: 0.468524. Loss: 1.478978. Batch_acc: 0.475630. Batch_loss: 1.471010 \n",
      "Batch: 2252. Acc: 0.468534. Loss: 1.478959. Batch_acc: 0.490808. Batch_loss: 1.437769 \n",
      "Batch: 2253. Acc: 0.468556. Loss: 1.478906. Batch_acc: 0.518129. Batch_loss: 1.356584 \n",
      "Batch: 2254. Acc: 0.468552. Loss: 1.478919. Batch_acc: 0.461088. Batch_loss: 1.509490 \n",
      "Batch: 2255. Acc: 0.468550. Loss: 1.478944. Batch_acc: 0.463218. Batch_loss: 1.536304 \n",
      "Batch: 2256. Acc: 0.468554. Loss: 1.478943. Batch_acc: 0.477022. Batch_loss: 1.474821 \n",
      "Batch: 2257. Acc: 0.468561. Loss: 1.478919. Batch_acc: 0.484113. Batch_loss: 1.425675 \n",
      "Batch: 2258. Acc: 0.468563. Loss: 1.478915. Batch_acc: 0.474173. Batch_loss: 1.470566 \n",
      "Batch: 2259. Acc: 0.468583. Loss: 1.478860. Batch_acc: 0.512514. Batch_loss: 1.355646 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.468582734360619. Loss per char: 1.4788601963419776. Time: 1627215898.1545794\n",
      "Last question is tensor([ 2, 53, 80, 85, 66, 77,  1, 80, 71,  1, 22, 26, 15, 22, 19,  1, 66, 79,\n",
      "        69,  1, 14, 18, 17, 21, 24, 26, 22, 20, 23, 23, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.468577. Loss: 1.478872. Batch_acc: 0.455574. Batch_loss: 1.506155 \n",
      "Batch: 2261. Acc: 0.468577. Loss: 1.478887. Batch_acc: 0.469645. Batch_loss: 1.511826 \n",
      "Batch: 2262. Acc: 0.468575. Loss: 1.478886. Batch_acc: 0.464245. Batch_loss: 1.477229 \n",
      "Batch: 2263. Acc: 0.468578. Loss: 1.478891. Batch_acc: 0.474702. Batch_loss: 1.488186 \n",
      "Batch: 2264. Acc: 0.468592. Loss: 1.478851. Batch_acc: 0.498311. Batch_loss: 1.392332 \n",
      "Batch: 2265. Acc: 0.468592. Loss: 1.478833. Batch_acc: 0.469157. Batch_loss: 1.438244 \n",
      "Batch: 2266. Acc: 0.468604. Loss: 1.478804. Batch_acc: 0.495972. Batch_loss: 1.412791 \n",
      "Batch: 2267. Acc: 0.468605. Loss: 1.478789. Batch_acc: 0.470070. Batch_loss: 1.443624 \n",
      "Batch: 2268. Acc: 0.468606. Loss: 1.478778. Batch_acc: 0.472738. Batch_loss: 1.453727 \n",
      "Batch: 2269. Acc: 0.468612. Loss: 1.478779. Batch_acc: 0.482599. Batch_loss: 1.480012 \n",
      "Batch: 2270. Acc: 0.468612. Loss: 1.478770. Batch_acc: 0.466901. Batch_loss: 1.459079 \n",
      "Batch: 2271. Acc: 0.468616. Loss: 1.478764. Batch_acc: 0.479263. Batch_loss: 1.465444 \n",
      "Batch: 2272. Acc: 0.468617. Loss: 1.478776. Batch_acc: 0.469400. Batch_loss: 1.505159 \n",
      "Batch: 2273. Acc: 0.468622. Loss: 1.478767. Batch_acc: 0.481116. Batch_loss: 1.458222 \n",
      "Batch: 2274. Acc: 0.468624. Loss: 1.478771. Batch_acc: 0.472222. Batch_loss: 1.487240 \n",
      "Batch: 2275. Acc: 0.468623. Loss: 1.478777. Batch_acc: 0.466667. Batch_loss: 1.493078 \n",
      "Batch: 2276. Acc: 0.468622. Loss: 1.478780. Batch_acc: 0.466092. Batch_loss: 1.486351 \n",
      "Batch: 2277. Acc: 0.468636. Loss: 1.478752. Batch_acc: 0.501130. Batch_loss: 1.414848 \n",
      "Batch: 2278. Acc: 0.468629. Loss: 1.478780. Batch_acc: 0.451631. Batch_loss: 1.541773 \n",
      "Batch: 2279. Acc: 0.468638. Loss: 1.478747. Batch_acc: 0.490323. Batch_loss: 1.403177 \n",
      "Batch: 2280. Acc: 0.468645. Loss: 1.478748. Batch_acc: 0.483668. Batch_loss: 1.479476 \n",
      "Batch: 2281. Acc: 0.468637. Loss: 1.478777. Batch_acc: 0.451385. Batch_loss: 1.547046 \n",
      "Batch: 2282. Acc: 0.468640. Loss: 1.478770. Batch_acc: 0.473931. Batch_loss: 1.461969 \n",
      "Batch: 2283. Acc: 0.468645. Loss: 1.478753. Batch_acc: 0.481672. Batch_loss: 1.440784 \n",
      "Batch: 2284. Acc: 0.468646. Loss: 1.478743. Batch_acc: 0.469365. Batch_loss: 1.455906 \n",
      "Batch: 2285. Acc: 0.468645. Loss: 1.478741. Batch_acc: 0.466667. Batch_loss: 1.476103 \n",
      "Batch: 2286. Acc: 0.468646. Loss: 1.478733. Batch_acc: 0.470452. Batch_loss: 1.460257 \n",
      "Batch: 2287. Acc: 0.468638. Loss: 1.478753. Batch_acc: 0.451595. Batch_loss: 1.521927 \n",
      "Batch: 2288. Acc: 0.468647. Loss: 1.478739. Batch_acc: 0.488000. Batch_loss: 1.447153 \n",
      "Batch: 2289. Acc: 0.468652. Loss: 1.478733. Batch_acc: 0.481335. Batch_loss: 1.465366 \n",
      "Batch: 2290. Acc: 0.468652. Loss: 1.478753. Batch_acc: 0.467059. Batch_loss: 1.527454 \n",
      "Batch: 2291. Acc: 0.468651. Loss: 1.478752. Batch_acc: 0.468376. Batch_loss: 1.474904 \n",
      "Batch: 2292. Acc: 0.468655. Loss: 1.478748. Batch_acc: 0.476985. Batch_loss: 1.470719 \n",
      "Batch: 2293. Acc: 0.468662. Loss: 1.478747. Batch_acc: 0.485981. Batch_loss: 1.476127 \n",
      "Batch: 2294. Acc: 0.468672. Loss: 1.478730. Batch_acc: 0.490952. Batch_loss: 1.438532 \n",
      "Batch: 2295. Acc: 0.468689. Loss: 1.478701. Batch_acc: 0.506523. Batch_loss: 1.412479 \n",
      "Batch: 2296. Acc: 0.468696. Loss: 1.478687. Batch_acc: 0.485286. Batch_loss: 1.447991 \n",
      "Batch: 2297. Acc: 0.468707. Loss: 1.478651. Batch_acc: 0.492966. Batch_loss: 1.399145 \n",
      "Batch: 2298. Acc: 0.468707. Loss: 1.478641. Batch_acc: 0.467853. Batch_loss: 1.454243 \n",
      "Batch: 2299. Acc: 0.468715. Loss: 1.478639. Batch_acc: 0.488493. Batch_loss: 1.473663 \n",
      "Batch: 2300. Acc: 0.468727. Loss: 1.478613. Batch_acc: 0.496454. Batch_loss: 1.417974 \n",
      "Batch: 2301. Acc: 0.468729. Loss: 1.478608. Batch_acc: 0.473988. Batch_loss: 1.466124 \n",
      "Batch: 2302. Acc: 0.468730. Loss: 1.478615. Batch_acc: 0.469620. Batch_loss: 1.496463 \n",
      "Batch: 2303. Acc: 0.468732. Loss: 1.478614. Batch_acc: 0.473745. Batch_loss: 1.475858 \n",
      "Batch: 2304. Acc: 0.468743. Loss: 1.478588. Batch_acc: 0.494869. Batch_loss: 1.417897 \n",
      "Batch: 2305. Acc: 0.468739. Loss: 1.478591. Batch_acc: 0.458383. Batch_loss: 1.486205 \n",
      "Batch: 2306. Acc: 0.468738. Loss: 1.478591. Batch_acc: 0.466298. Batch_loss: 1.479828 \n",
      "Batch: 2307. Acc: 0.468735. Loss: 1.478598. Batch_acc: 0.461630. Batch_loss: 1.493478 \n",
      "Batch: 2308. Acc: 0.468741. Loss: 1.478572. Batch_acc: 0.483240. Batch_loss: 1.420767 \n",
      "Batch: 2309. Acc: 0.468741. Loss: 1.478571. Batch_acc: 0.469021. Batch_loss: 1.476973 \n",
      "Batch: 2310. Acc: 0.468735. Loss: 1.478583. Batch_acc: 0.453495. Batch_loss: 1.506555 \n",
      "Batch: 2311. Acc: 0.468736. Loss: 1.478561. Batch_acc: 0.471148. Batch_loss: 1.428760 \n",
      "Batch: 2312. Acc: 0.468738. Loss: 1.478563. Batch_acc: 0.473345. Batch_loss: 1.482256 \n",
      "Batch: 2313. Acc: 0.468750. Loss: 1.478520. Batch_acc: 0.495687. Batch_loss: 1.380907 \n",
      "Batch: 2314. Acc: 0.468760. Loss: 1.478507. Batch_acc: 0.491111. Batch_loss: 1.448722 \n",
      "Batch: 2315. Acc: 0.468768. Loss: 1.478471. Batch_acc: 0.487165. Batch_loss: 1.395546 \n",
      "Batch: 2316. Acc: 0.468768. Loss: 1.478483. Batch_acc: 0.470342. Batch_loss: 1.508406 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2317. Acc: 0.468767. Loss: 1.478489. Batch_acc: 0.465323. Batch_loss: 1.492596 \n",
      "Batch: 2318. Acc: 0.468766. Loss: 1.478495. Batch_acc: 0.466048. Batch_loss: 1.491510 \n",
      "Batch: 2319. Acc: 0.468776. Loss: 1.478459. Batch_acc: 0.493856. Batch_loss: 1.394328 \n",
      "Batch: 2320. Acc: 0.468781. Loss: 1.478441. Batch_acc: 0.479348. Batch_loss: 1.436410 \n",
      "Batch: 2321. Acc: 0.468778. Loss: 1.478443. Batch_acc: 0.461313. Batch_loss: 1.482424 \n",
      "Batch: 2322. Acc: 0.468789. Loss: 1.478410. Batch_acc: 0.494170. Batch_loss: 1.404512 \n",
      "Batch: 2323. Acc: 0.468793. Loss: 1.478404. Batch_acc: 0.478736. Batch_loss: 1.463840 \n",
      "Batch: 2324. Acc: 0.468801. Loss: 1.478385. Batch_acc: 0.488304. Batch_loss: 1.434063 \n",
      "Batch: 2325. Acc: 0.468803. Loss: 1.478375. Batch_acc: 0.473209. Batch_loss: 1.453317 \n",
      "Batch: 2326. Acc: 0.468812. Loss: 1.478342. Batch_acc: 0.488643. Batch_loss: 1.401990 \n",
      "Batch: 2327. Acc: 0.468812. Loss: 1.478336. Batch_acc: 0.468641. Batch_loss: 1.464707 \n",
      "Batch: 2328. Acc: 0.468827. Loss: 1.478291. Batch_acc: 0.504343. Batch_loss: 1.371265 \n",
      "Batch: 2329. Acc: 0.468831. Loss: 1.478284. Batch_acc: 0.479107. Batch_loss: 1.463060 \n",
      "Batch: 2330. Acc: 0.468837. Loss: 1.478262. Batch_acc: 0.481418. Batch_loss: 1.426257 \n",
      "Batch: 2331. Acc: 0.468853. Loss: 1.478211. Batch_acc: 0.506530. Batch_loss: 1.361138 \n",
      "Batch: 2332. Acc: 0.468863. Loss: 1.478179. Batch_acc: 0.491389. Batch_loss: 1.404385 \n",
      "Batch: 2333. Acc: 0.468874. Loss: 1.478137. Batch_acc: 0.494512. Batch_loss: 1.379702 \n",
      "Batch: 2334. Acc: 0.468874. Loss: 1.478134. Batch_acc: 0.470210. Batch_loss: 1.471497 \n",
      "Batch: 2335. Acc: 0.468886. Loss: 1.478103. Batch_acc: 0.495930. Batch_loss: 1.403807 \n",
      "Batch: 2336. Acc: 0.468902. Loss: 1.478056. Batch_acc: 0.507692. Batch_loss: 1.370154 \n",
      "Batch: 2337. Acc: 0.468904. Loss: 1.478051. Batch_acc: 0.471613. Batch_loss: 1.466493 \n",
      "Batch: 2338. Acc: 0.468910. Loss: 1.478040. Batch_acc: 0.482680. Batch_loss: 1.451827 \n",
      "Batch: 2339. Acc: 0.468920. Loss: 1.478010. Batch_acc: 0.491740. Batch_loss: 1.411822 \n",
      "Batch: 2340. Acc: 0.468924. Loss: 1.478004. Batch_acc: 0.479072. Batch_loss: 1.464549 \n",
      "Batch: 2341. Acc: 0.468938. Loss: 1.477965. Batch_acc: 0.502652. Batch_loss: 1.383713 \n",
      "Batch: 2342. Acc: 0.468947. Loss: 1.477946. Batch_acc: 0.490093. Batch_loss: 1.432463 \n",
      "Batch: 2343. Acc: 0.468958. Loss: 1.477909. Batch_acc: 0.493417. Batch_loss: 1.393404 \n",
      "Batch: 2344. Acc: 0.468966. Loss: 1.477884. Batch_acc: 0.487298. Batch_loss: 1.417220 \n",
      "Batch: 2345. Acc: 0.468975. Loss: 1.477853. Batch_acc: 0.491269. Batch_loss: 1.404635 \n",
      "Batch: 2346. Acc: 0.468976. Loss: 1.477842. Batch_acc: 0.471470. Batch_loss: 1.451685 \n",
      "Batch: 2347. Acc: 0.468975. Loss: 1.477833. Batch_acc: 0.465769. Batch_loss: 1.456713 \n",
      "Batch: 2348. Acc: 0.468973. Loss: 1.477839. Batch_acc: 0.464245. Batch_loss: 1.493086 \n",
      "Batch: 2349. Acc: 0.468980. Loss: 1.477813. Batch_acc: 0.485846. Batch_loss: 1.414718 \n",
      "Batch: 2350. Acc: 0.468987. Loss: 1.477792. Batch_acc: 0.485632. Batch_loss: 1.429351 \n",
      "Batch: 2351. Acc: 0.468996. Loss: 1.477767. Batch_acc: 0.490534. Batch_loss: 1.418815 \n",
      "Batch: 2352. Acc: 0.469000. Loss: 1.477744. Batch_acc: 0.478826. Batch_loss: 1.425830 \n",
      "Batch: 2353. Acc: 0.469009. Loss: 1.477724. Batch_acc: 0.488493. Batch_loss: 1.429618 \n",
      "Batch: 2354. Acc: 0.469006. Loss: 1.477723. Batch_acc: 0.462073. Batch_loss: 1.474683 \n",
      "Batch: 2355. Acc: 0.469010. Loss: 1.477696. Batch_acc: 0.479420. Batch_loss: 1.415020 \n",
      "Batch: 2356. Acc: 0.469007. Loss: 1.477704. Batch_acc: 0.462073. Batch_loss: 1.495402 \n",
      "Batch: 2357. Acc: 0.469006. Loss: 1.477698. Batch_acc: 0.465387. Batch_loss: 1.463482 \n",
      "Batch: 2358. Acc: 0.469016. Loss: 1.477667. Batch_acc: 0.493536. Batch_loss: 1.406804 \n",
      "Batch: 2359. Acc: 0.469028. Loss: 1.477639. Batch_acc: 0.497677. Batch_loss: 1.410590 \n",
      "Batch: 2360. Acc: 0.469023. Loss: 1.477661. Batch_acc: 0.456160. Batch_loss: 1.529348 \n",
      "Batch: 2361. Acc: 0.469022. Loss: 1.477663. Batch_acc: 0.467429. Batch_loss: 1.483966 \n",
      "Batch: 2362. Acc: 0.469021. Loss: 1.477659. Batch_acc: 0.466510. Batch_loss: 1.467681 \n",
      "Batch: 2363. Acc: 0.469029. Loss: 1.477624. Batch_acc: 0.486517. Batch_loss: 1.395358 \n",
      "Batch: 2364. Acc: 0.469043. Loss: 1.477595. Batch_acc: 0.501994. Batch_loss: 1.410537 \n",
      "Batch: 2365. Acc: 0.469042. Loss: 1.477598. Batch_acc: 0.468048. Batch_loss: 1.484426 \n",
      "Batch: 2366. Acc: 0.469046. Loss: 1.477579. Batch_acc: 0.476959. Batch_loss: 1.433214 \n",
      "Batch: 2367. Acc: 0.469053. Loss: 1.477557. Batch_acc: 0.486317. Batch_loss: 1.425534 \n",
      "Batch: 2368. Acc: 0.469069. Loss: 1.477519. Batch_acc: 0.506780. Batch_loss: 1.388829 \n",
      "Batch: 2369. Acc: 0.469060. Loss: 1.477527. Batch_acc: 0.447821. Batch_loss: 1.496503 \n",
      "Batch: 2370. Acc: 0.469071. Loss: 1.477495. Batch_acc: 0.494292. Batch_loss: 1.403399 \n",
      "Batch: 2371. Acc: 0.469083. Loss: 1.477490. Batch_acc: 0.498195. Batch_loss: 1.464500 \n",
      "Batch: 2372. Acc: 0.469097. Loss: 1.477452. Batch_acc: 0.503452. Batch_loss: 1.386763 \n",
      "Batch: 2373. Acc: 0.469107. Loss: 1.477432. Batch_acc: 0.491138. Batch_loss: 1.429832 \n",
      "Batch: 2374. Acc: 0.469117. Loss: 1.477399. Batch_acc: 0.492910. Batch_loss: 1.400719 \n",
      "Batch: 2375. Acc: 0.469125. Loss: 1.477374. Batch_acc: 0.488385. Batch_loss: 1.418775 \n",
      "Batch: 2376. Acc: 0.469133. Loss: 1.477348. Batch_acc: 0.487327. Batch_loss: 1.416744 \n",
      "Batch: 2377. Acc: 0.469147. Loss: 1.477317. Batch_acc: 0.502555. Batch_loss: 1.404126 \n",
      "Batch: 2378. Acc: 0.469149. Loss: 1.477302. Batch_acc: 0.475574. Batch_loss: 1.441493 \n",
      "Batch: 2379. Acc: 0.469139. Loss: 1.477321. Batch_acc: 0.443988. Batch_loss: 1.522860 \n",
      "Batch: 2380. Acc: 0.469147. Loss: 1.477307. Batch_acc: 0.487327. Batch_loss: 1.442673 \n",
      "Batch: 2381. Acc: 0.469146. Loss: 1.477311. Batch_acc: 0.467622. Batch_loss: 1.488266 \n",
      "Batch: 2382. Acc: 0.469152. Loss: 1.477284. Batch_acc: 0.483616. Batch_loss: 1.413187 \n",
      "Batch: 2383. Acc: 0.469149. Loss: 1.477274. Batch_acc: 0.461234. Batch_loss: 1.455215 \n",
      "Batch: 2384. Acc: 0.469149. Loss: 1.477268. Batch_acc: 0.469757. Batch_loss: 1.461952 \n",
      "Batch: 2385. Acc: 0.469159. Loss: 1.477243. Batch_acc: 0.492837. Batch_loss: 1.417758 \n",
      "Batch: 2386. Acc: 0.469171. Loss: 1.477203. Batch_acc: 0.496887. Batch_loss: 1.383643 \n",
      "Batch: 2387. Acc: 0.469183. Loss: 1.477170. Batch_acc: 0.497149. Batch_loss: 1.398338 \n",
      "Batch: 2388. Acc: 0.469196. Loss: 1.477137. Batch_acc: 0.500583. Batch_loss: 1.398906 \n",
      "Batch: 2389. Acc: 0.469210. Loss: 1.477107. Batch_acc: 0.504051. Batch_loss: 1.404549 \n",
      "Batch: 2390. Acc: 0.469216. Loss: 1.477094. Batch_acc: 0.482875. Batch_loss: 1.445774 \n",
      "Batch: 2391. Acc: 0.469219. Loss: 1.477087. Batch_acc: 0.477169. Batch_loss: 1.461949 \n",
      "Batch: 2392. Acc: 0.469229. Loss: 1.477058. Batch_acc: 0.490950. Batch_loss: 1.408405 \n",
      "Batch: 2393. Acc: 0.469231. Loss: 1.477041. Batch_acc: 0.474070. Batch_loss: 1.437766 \n",
      "Batch: 2394. Acc: 0.469235. Loss: 1.477034. Batch_acc: 0.478717. Batch_loss: 1.458187 \n",
      "Batch: 2395. Acc: 0.469248. Loss: 1.476998. Batch_acc: 0.502336. Batch_loss: 1.391529 \n",
      "Batch: 2396. Acc: 0.469249. Loss: 1.476988. Batch_acc: 0.470554. Batch_loss: 1.450197 \n",
      "Batch: 2397. Acc: 0.469242. Loss: 1.476996. Batch_acc: 0.454082. Batch_loss: 1.496890 \n",
      "Batch: 2398. Acc: 0.469245. Loss: 1.476971. Batch_acc: 0.476744. Batch_loss: 1.417508 \n",
      "Batch: 2399. Acc: 0.469257. Loss: 1.476941. Batch_acc: 0.496005. Batch_loss: 1.403907 \n",
      "Batch: 2400. Acc: 0.469269. Loss: 1.476908. Batch_acc: 0.497727. Batch_loss: 1.398602 \n",
      "Batch: 2401. Acc: 0.469272. Loss: 1.476892. Batch_acc: 0.478113. Batch_loss: 1.439814 \n",
      "Batch: 2402. Acc: 0.469279. Loss: 1.476875. Batch_acc: 0.485714. Batch_loss: 1.435995 \n",
      "Batch: 2403. Acc: 0.469277. Loss: 1.476884. Batch_acc: 0.464716. Batch_loss: 1.497080 \n",
      "Batch: 2404. Acc: 0.469283. Loss: 1.476878. Batch_acc: 0.481921. Batch_loss: 1.462894 \n",
      "Batch: 2405. Acc: 0.469288. Loss: 1.476866. Batch_acc: 0.481439. Batch_loss: 1.449135 \n",
      "Batch: 2406. Acc: 0.469299. Loss: 1.476860. Batch_acc: 0.494966. Batch_loss: 1.462111 \n",
      "Batch: 2407. Acc: 0.469311. Loss: 1.476827. Batch_acc: 0.498539. Batch_loss: 1.396749 \n",
      "Batch: 2408. Acc: 0.469316. Loss: 1.476800. Batch_acc: 0.481013. Batch_loss: 1.411037 \n",
      "Batch: 2409. Acc: 0.469317. Loss: 1.476799. Batch_acc: 0.472400. Batch_loss: 1.475246 \n",
      "Batch: 2410. Acc: 0.469323. Loss: 1.476779. Batch_acc: 0.483276. Batch_loss: 1.428843 \n",
      "Batch: 2411. Acc: 0.469334. Loss: 1.476763. Batch_acc: 0.496587. Batch_loss: 1.437559 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2412. Acc: 0.469340. Loss: 1.476758. Batch_acc: 0.483763. Batch_loss: 1.464624 \n",
      "Batch: 2413. Acc: 0.469342. Loss: 1.476741. Batch_acc: 0.474901. Batch_loss: 1.436823 \n",
      "Batch: 2414. Acc: 0.469350. Loss: 1.476726. Batch_acc: 0.488466. Batch_loss: 1.440126 \n",
      "Batch: 2415. Acc: 0.469360. Loss: 1.476691. Batch_acc: 0.491021. Batch_loss: 1.395811 \n",
      "Batch: 2416. Acc: 0.469356. Loss: 1.476698. Batch_acc: 0.459884. Batch_loss: 1.491660 \n",
      "Batch: 2417. Acc: 0.469352. Loss: 1.476695. Batch_acc: 0.461494. Batch_loss: 1.470922 \n",
      "Batch: 2418. Acc: 0.469365. Loss: 1.476677. Batch_acc: 0.498870. Batch_loss: 1.434625 \n",
      "Batch: 2419. Acc: 0.469364. Loss: 1.476689. Batch_acc: 0.467017. Batch_loss: 1.505868 \n",
      "Batch: 2420. Acc: 0.469369. Loss: 1.476670. Batch_acc: 0.480947. Batch_loss: 1.429679 \n",
      "Batch: 2421. Acc: 0.469363. Loss: 1.476677. Batch_acc: 0.454493. Batch_loss: 1.494449 \n",
      "Batch: 2422. Acc: 0.469360. Loss: 1.476682. Batch_acc: 0.463206. Batch_loss: 1.488668 \n",
      "Batch: 2423. Acc: 0.469357. Loss: 1.476686. Batch_acc: 0.461808. Batch_loss: 1.485264 \n",
      "Batch: 2424. Acc: 0.469372. Loss: 1.476653. Batch_acc: 0.506644. Batch_loss: 1.397956 \n",
      "Batch: 2425. Acc: 0.469368. Loss: 1.476673. Batch_acc: 0.459988. Batch_loss: 1.523904 \n",
      "Batch: 2426. Acc: 0.469364. Loss: 1.476678. Batch_acc: 0.457770. Batch_loss: 1.489128 \n",
      "Batch: 2427. Acc: 0.469361. Loss: 1.476674. Batch_acc: 0.464060. Batch_loss: 1.466728 \n",
      "Batch: 2428. Acc: 0.469357. Loss: 1.476684. Batch_acc: 0.459691. Batch_loss: 1.500521 \n",
      "Batch: 2429. Acc: 0.469364. Loss: 1.476668. Batch_acc: 0.485649. Batch_loss: 1.438593 \n",
      "Batch: 2430. Acc: 0.469367. Loss: 1.476645. Batch_acc: 0.477048. Batch_loss: 1.418800 \n",
      "Batch: 2431. Acc: 0.469368. Loss: 1.476647. Batch_acc: 0.472127. Batch_loss: 1.482730 \n",
      "Batch: 2432. Acc: 0.469368. Loss: 1.476633. Batch_acc: 0.467409. Batch_loss: 1.443245 \n",
      "Batch: 2433. Acc: 0.469368. Loss: 1.476633. Batch_acc: 0.471278. Batch_loss: 1.475689 \n",
      "Batch: 2434. Acc: 0.469371. Loss: 1.476611. Batch_acc: 0.477075. Batch_loss: 1.422495 \n",
      "Batch: 2435. Acc: 0.469385. Loss: 1.476563. Batch_acc: 0.501697. Batch_loss: 1.361671 \n",
      "Batch: 2436. Acc: 0.469388. Loss: 1.476559. Batch_acc: 0.477560. Batch_loss: 1.468114 \n",
      "Batch: 2437. Acc: 0.469391. Loss: 1.476550. Batch_acc: 0.475344. Batch_loss: 1.453598 \n",
      "Batch: 2438. Acc: 0.469396. Loss: 1.476533. Batch_acc: 0.481566. Batch_loss: 1.437062 \n",
      "Batch: 2439. Acc: 0.469401. Loss: 1.476527. Batch_acc: 0.482392. Batch_loss: 1.461799 \n",
      "Batch: 2440. Acc: 0.469407. Loss: 1.476506. Batch_acc: 0.482778. Batch_loss: 1.427128 \n",
      "Batch: 2441. Acc: 0.469408. Loss: 1.476496. Batch_acc: 0.473143. Batch_loss: 1.452219 \n",
      "Batch: 2442. Acc: 0.469417. Loss: 1.476489. Batch_acc: 0.491021. Batch_loss: 1.458214 \n",
      "Batch: 2443. Acc: 0.469428. Loss: 1.476465. Batch_acc: 0.496789. Batch_loss: 1.418249 \n",
      "Batch: 2444. Acc: 0.469436. Loss: 1.476455. Batch_acc: 0.487962. Batch_loss: 1.449954 \n",
      "Batch: 2445. Acc: 0.469447. Loss: 1.476428. Batch_acc: 0.497166. Batch_loss: 1.413239 \n",
      "Batch: 2446. Acc: 0.469453. Loss: 1.476402. Batch_acc: 0.483724. Batch_loss: 1.413189 \n",
      "Batch: 2447. Acc: 0.469465. Loss: 1.476381. Batch_acc: 0.497732. Batch_loss: 1.425660 \n",
      "Batch: 2448. Acc: 0.469477. Loss: 1.476339. Batch_acc: 0.500000. Batch_loss: 1.371146 \n",
      "Batch: 2449. Acc: 0.469478. Loss: 1.476341. Batch_acc: 0.471165. Batch_loss: 1.482099 \n",
      "Batch: 2450. Acc: 0.469497. Loss: 1.476300. Batch_acc: 0.515429. Batch_loss: 1.377377 \n",
      "Batch: 2451. Acc: 0.469511. Loss: 1.476260. Batch_acc: 0.503174. Batch_loss: 1.377982 \n",
      "Batch: 2452. Acc: 0.469512. Loss: 1.476248. Batch_acc: 0.473900. Batch_loss: 1.446178 \n",
      "Batch: 2453. Acc: 0.469521. Loss: 1.476217. Batch_acc: 0.491349. Batch_loss: 1.399197 \n",
      "Batch: 2454. Acc: 0.469529. Loss: 1.476189. Batch_acc: 0.488812. Batch_loss: 1.407839 \n",
      "Batch: 2455. Acc: 0.469531. Loss: 1.476166. Batch_acc: 0.474586. Batch_loss: 1.420674 \n",
      "Batch: 2456. Acc: 0.469541. Loss: 1.476128. Batch_acc: 0.493064. Batch_loss: 1.382373 \n",
      "Batch: 2457. Acc: 0.469544. Loss: 1.476104. Batch_acc: 0.477313. Batch_loss: 1.415294 \n",
      "Batch: 2458. Acc: 0.469537. Loss: 1.476118. Batch_acc: 0.452424. Batch_loss: 1.512579 \n",
      "Batch: 2459. Acc: 0.469544. Loss: 1.476110. Batch_acc: 0.487121. Batch_loss: 1.455911 \n",
      "Batch: 2460. Acc: 0.469557. Loss: 1.476066. Batch_acc: 0.500872. Batch_loss: 1.366429 \n",
      "Batch: 2461. Acc: 0.469558. Loss: 1.476077. Batch_acc: 0.471445. Batch_loss: 1.503292 \n",
      "Batch: 2462. Acc: 0.469561. Loss: 1.476062. Batch_acc: 0.476852. Batch_loss: 1.438888 \n",
      "Batch: 2463. Acc: 0.469554. Loss: 1.476081. Batch_acc: 0.453561. Batch_loss: 1.521807 \n",
      "Batch: 2464. Acc: 0.469567. Loss: 1.476048. Batch_acc: 0.501140. Batch_loss: 1.396144 \n",
      "Batch: 2465. Acc: 0.469564. Loss: 1.476048. Batch_acc: 0.462421. Batch_loss: 1.476639 \n",
      "Batch: 2466. Acc: 0.469568. Loss: 1.476040. Batch_acc: 0.479420. Batch_loss: 1.455970 \n",
      "Batch: 2467. Acc: 0.469577. Loss: 1.476016. Batch_acc: 0.490119. Batch_loss: 1.417617 \n",
      "Batch: 2468. Acc: 0.469593. Loss: 1.475970. Batch_acc: 0.510086. Batch_loss: 1.362385 \n",
      "Batch: 2469. Acc: 0.469602. Loss: 1.475947. Batch_acc: 0.490751. Batch_loss: 1.419386 \n",
      "Batch: 2470. Acc: 0.469607. Loss: 1.475941. Batch_acc: 0.483172. Batch_loss: 1.459779 \n",
      "Batch: 2471. Acc: 0.469616. Loss: 1.475917. Batch_acc: 0.491468. Batch_loss: 1.418913 \n",
      "Batch: 2472. Acc: 0.469624. Loss: 1.475901. Batch_acc: 0.489100. Batch_loss: 1.436969 \n",
      "Batch: 2473. Acc: 0.469622. Loss: 1.475901. Batch_acc: 0.465301. Batch_loss: 1.474682 \n",
      "Batch: 2474. Acc: 0.469629. Loss: 1.475892. Batch_acc: 0.487283. Batch_loss: 1.453568 \n",
      "Batch: 2475. Acc: 0.469643. Loss: 1.475860. Batch_acc: 0.502864. Batch_loss: 1.398823 \n",
      "Batch: 2476. Acc: 0.469653. Loss: 1.475839. Batch_acc: 0.493274. Batch_loss: 1.423652 \n",
      "Batch: 2477. Acc: 0.469655. Loss: 1.475844. Batch_acc: 0.475866. Batch_loss: 1.488657 \n",
      "Batch: 2478. Acc: 0.469653. Loss: 1.475845. Batch_acc: 0.463527. Batch_loss: 1.478516 \n",
      "Batch: 2479. Acc: 0.469659. Loss: 1.475837. Batch_acc: 0.484287. Batch_loss: 1.456902 \n",
      "Batch: 2480. Acc: 0.469658. Loss: 1.475829. Batch_acc: 0.466394. Batch_loss: 1.456127 \n",
      "Batch: 2481. Acc: 0.469669. Loss: 1.475801. Batch_acc: 0.498848. Batch_loss: 1.405680 \n",
      "Batch: 2482. Acc: 0.469676. Loss: 1.475782. Batch_acc: 0.486701. Batch_loss: 1.428797 \n",
      "Batch: 2483. Acc: 0.469674. Loss: 1.475779. Batch_acc: 0.462731. Batch_loss: 1.468524 \n",
      "Batch: 2484. Acc: 0.469683. Loss: 1.475752. Batch_acc: 0.491954. Batch_loss: 1.409816 \n",
      "Batch: 2485. Acc: 0.469689. Loss: 1.475746. Batch_acc: 0.484866. Batch_loss: 1.458705 \n",
      "Batch: 2486. Acc: 0.469688. Loss: 1.475727. Batch_acc: 0.467901. Batch_loss: 1.428486 \n",
      "Batch: 2487. Acc: 0.469682. Loss: 1.475740. Batch_acc: 0.454545. Batch_loss: 1.509194 \n",
      "Batch: 2488. Acc: 0.469688. Loss: 1.475722. Batch_acc: 0.486393. Batch_loss: 1.431024 \n",
      "Batch: 2489. Acc: 0.469684. Loss: 1.475721. Batch_acc: 0.459522. Batch_loss: 1.471060 \n",
      "Batch: 2490. Acc: 0.469684. Loss: 1.475726. Batch_acc: 0.467656. Batch_loss: 1.488708 \n",
      "Batch: 2491. Acc: 0.469696. Loss: 1.475693. Batch_acc: 0.499157. Batch_loss: 1.395318 \n",
      "Batch: 2492. Acc: 0.469702. Loss: 1.475679. Batch_acc: 0.485037. Batch_loss: 1.443358 \n",
      "Batch: 2493. Acc: 0.469707. Loss: 1.475664. Batch_acc: 0.481027. Batch_loss: 1.435482 \n",
      "Batch: 2494. Acc: 0.469706. Loss: 1.475656. Batch_acc: 0.468622. Batch_loss: 1.457369 \n",
      "Batch: 2495. Acc: 0.469710. Loss: 1.475648. Batch_acc: 0.478542. Batch_loss: 1.453352 \n",
      "Batch: 2496. Acc: 0.469712. Loss: 1.475636. Batch_acc: 0.475141. Batch_loss: 1.446121 \n",
      "Batch: 2497. Acc: 0.469722. Loss: 1.475611. Batch_acc: 0.494944. Batch_loss: 1.416398 \n",
      "Batch: 2498. Acc: 0.469737. Loss: 1.475571. Batch_acc: 0.507172. Batch_loss: 1.374704 \n",
      "Batch: 2499. Acc: 0.469738. Loss: 1.475574. Batch_acc: 0.471477. Batch_loss: 1.482346 \n",
      "Batch: 2500. Acc: 0.469736. Loss: 1.475580. Batch_acc: 0.465210. Batch_loss: 1.492122 \n",
      "Batch: 2501. Acc: 0.469749. Loss: 1.475553. Batch_acc: 0.502618. Batch_loss: 1.405752 \n",
      "Batch: 2502. Acc: 0.469753. Loss: 1.475544. Batch_acc: 0.481176. Batch_loss: 1.452668 \n",
      "Batch: 2503. Acc: 0.469752. Loss: 1.475553. Batch_acc: 0.466174. Batch_loss: 1.497856 \n",
      "Batch: 2504. Acc: 0.469757. Loss: 1.475543. Batch_acc: 0.480769. Batch_loss: 1.452251 \n",
      "Batch: 2505. Acc: 0.469768. Loss: 1.475532. Batch_acc: 0.496681. Batch_loss: 1.447852 \n",
      "Batch: 2506. Acc: 0.469771. Loss: 1.475529. Batch_acc: 0.479094. Batch_loss: 1.469747 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2507. Acc: 0.469775. Loss: 1.475515. Batch_acc: 0.477663. Batch_loss: 1.438667 \n",
      "Batch: 2508. Acc: 0.469777. Loss: 1.475507. Batch_acc: 0.476027. Batch_loss: 1.456445 \n",
      "Batch: 2509. Acc: 0.469788. Loss: 1.475463. Batch_acc: 0.497701. Batch_loss: 1.365570 \n",
      "Batch: 2510. Acc: 0.469798. Loss: 1.475452. Batch_acc: 0.495887. Batch_loss: 1.448149 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.46979836556211096. Loss per char: 1.4754524728739304. Time: 1627216095.8774354\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 19, 21, 22, 15, 26, 17,\n",
      "        18, 25,  1, 12,  1, 17, 15, 17, 22, 22, 17, 21, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.469807. Loss: 1.475419. Batch_acc: 0.492081. Batch_loss: 1.392917 \n",
      "Batch: 2512. Acc: 0.469806. Loss: 1.475409. Batch_acc: 0.466152. Batch_loss: 1.448199 \n",
      "Batch: 2513. Acc: 0.469810. Loss: 1.475384. Batch_acc: 0.479908. Batch_loss: 1.412647 \n",
      "Batch: 2514. Acc: 0.469809. Loss: 1.475395. Batch_acc: 0.466282. Batch_loss: 1.503425 \n",
      "Batch: 2515. Acc: 0.469813. Loss: 1.475380. Batch_acc: 0.481439. Batch_loss: 1.438302 \n",
      "Batch: 2516. Acc: 0.469811. Loss: 1.475388. Batch_acc: 0.464584. Batch_loss: 1.494153 \n",
      "Batch: 2517. Acc: 0.469813. Loss: 1.475374. Batch_acc: 0.474411. Batch_loss: 1.442155 \n",
      "Batch: 2518. Acc: 0.469811. Loss: 1.475382. Batch_acc: 0.463572. Batch_loss: 1.494223 \n",
      "Batch: 2519. Acc: 0.469809. Loss: 1.475393. Batch_acc: 0.465817. Batch_loss: 1.502984 \n",
      "Batch: 2520. Acc: 0.469815. Loss: 1.475377. Batch_acc: 0.484763. Batch_loss: 1.437015 \n",
      "Batch: 2521. Acc: 0.469820. Loss: 1.475347. Batch_acc: 0.481418. Batch_loss: 1.399401 \n",
      "Batch: 2522. Acc: 0.469817. Loss: 1.475341. Batch_acc: 0.463977. Batch_loss: 1.460978 \n",
      "Batch: 2523. Acc: 0.469828. Loss: 1.475316. Batch_acc: 0.496491. Batch_loss: 1.411178 \n",
      "Batch: 2524. Acc: 0.469834. Loss: 1.475290. Batch_acc: 0.487135. Batch_loss: 1.408946 \n",
      "Batch: 2525. Acc: 0.469846. Loss: 1.475263. Batch_acc: 0.497473. Batch_loss: 1.409553 \n",
      "Batch: 2526. Acc: 0.469845. Loss: 1.475259. Batch_acc: 0.467963. Batch_loss: 1.465153 \n",
      "Batch: 2527. Acc: 0.469844. Loss: 1.475263. Batch_acc: 0.466513. Batch_loss: 1.483067 \n",
      "Batch: 2528. Acc: 0.469851. Loss: 1.475239. Batch_acc: 0.487429. Batch_loss: 1.415141 \n",
      "Batch: 2529. Acc: 0.469853. Loss: 1.475236. Batch_acc: 0.475660. Batch_loss: 1.469463 \n",
      "Batch: 2530. Acc: 0.469865. Loss: 1.475207. Batch_acc: 0.499433. Batch_loss: 1.401256 \n",
      "Batch: 2531. Acc: 0.469871. Loss: 1.475186. Batch_acc: 0.485630. Batch_loss: 1.422795 \n",
      "Batch: 2532. Acc: 0.469882. Loss: 1.475157. Batch_acc: 0.497153. Batch_loss: 1.400855 \n",
      "Batch: 2533. Acc: 0.469888. Loss: 1.475137. Batch_acc: 0.485960. Batch_loss: 1.425883 \n",
      "Batch: 2534. Acc: 0.469888. Loss: 1.475132. Batch_acc: 0.468585. Batch_loss: 1.462454 \n",
      "Batch: 2535. Acc: 0.469890. Loss: 1.475116. Batch_acc: 0.476879. Batch_loss: 1.433089 \n",
      "Batch: 2536. Acc: 0.469900. Loss: 1.475091. Batch_acc: 0.495863. Batch_loss: 1.411026 \n",
      "Batch: 2537. Acc: 0.469908. Loss: 1.475055. Batch_acc: 0.489554. Batch_loss: 1.385825 \n",
      "Batch: 2538. Acc: 0.469910. Loss: 1.475036. Batch_acc: 0.474197. Batch_loss: 1.424737 \n",
      "Batch: 2539. Acc: 0.469931. Loss: 1.474993. Batch_acc: 0.523183. Batch_loss: 1.368588 \n",
      "Batch: 2540. Acc: 0.469930. Loss: 1.474992. Batch_acc: 0.466818. Batch_loss: 1.471351 \n",
      "Batch: 2541. Acc: 0.469937. Loss: 1.474962. Batch_acc: 0.489831. Batch_loss: 1.399196 \n",
      "Batch: 2542. Acc: 0.469945. Loss: 1.474937. Batch_acc: 0.488176. Batch_loss: 1.412320 \n",
      "Batch: 2543. Acc: 0.469954. Loss: 1.474921. Batch_acc: 0.493213. Batch_loss: 1.433396 \n",
      "Batch: 2544. Acc: 0.469958. Loss: 1.474911. Batch_acc: 0.480638. Batch_loss: 1.451733 \n",
      "Batch: 2545. Acc: 0.469963. Loss: 1.474901. Batch_acc: 0.481990. Batch_loss: 1.448527 \n",
      "Batch: 2546. Acc: 0.469965. Loss: 1.474874. Batch_acc: 0.475253. Batch_loss: 1.407813 \n",
      "Batch: 2547. Acc: 0.469974. Loss: 1.474851. Batch_acc: 0.492933. Batch_loss: 1.414249 \n",
      "Batch: 2548. Acc: 0.469968. Loss: 1.474865. Batch_acc: 0.454016. Batch_loss: 1.511674 \n",
      "Batch: 2549. Acc: 0.469964. Loss: 1.474890. Batch_acc: 0.461095. Batch_loss: 1.538960 \n",
      "Batch: 2550. Acc: 0.469970. Loss: 1.474872. Batch_acc: 0.484140. Batch_loss: 1.430633 \n",
      "Batch: 2551. Acc: 0.469971. Loss: 1.474860. Batch_acc: 0.471165. Batch_loss: 1.444163 \n",
      "Batch: 2552. Acc: 0.469985. Loss: 1.474831. Batch_acc: 0.506977. Batch_loss: 1.399666 \n",
      "Batch: 2553. Acc: 0.469993. Loss: 1.474794. Batch_acc: 0.489948. Batch_loss: 1.378970 \n",
      "Batch: 2554. Acc: 0.469991. Loss: 1.474792. Batch_acc: 0.466396. Batch_loss: 1.471749 \n",
      "Batch: 2555. Acc: 0.469991. Loss: 1.474782. Batch_acc: 0.470153. Batch_loss: 1.447933 \n",
      "Batch: 2556. Acc: 0.469994. Loss: 1.474783. Batch_acc: 0.476825. Batch_loss: 1.477384 \n",
      "Batch: 2557. Acc: 0.470003. Loss: 1.474751. Batch_acc: 0.493135. Batch_loss: 1.394908 \n",
      "Batch: 2558. Acc: 0.470007. Loss: 1.474731. Batch_acc: 0.480877. Batch_loss: 1.424011 \n",
      "Batch: 2559. Acc: 0.470015. Loss: 1.474714. Batch_acc: 0.488479. Batch_loss: 1.432274 \n",
      "Batch: 2560. Acc: 0.470029. Loss: 1.474678. Batch_acc: 0.505125. Batch_loss: 1.381779 \n",
      "Batch: 2561. Acc: 0.470032. Loss: 1.474663. Batch_acc: 0.479707. Batch_loss: 1.436551 \n",
      "Batch: 2562. Acc: 0.470039. Loss: 1.474651. Batch_acc: 0.486766. Batch_loss: 1.445246 \n",
      "Batch: 2563. Acc: 0.470042. Loss: 1.474649. Batch_acc: 0.476791. Batch_loss: 1.468472 \n",
      "Batch: 2564. Acc: 0.470049. Loss: 1.474630. Batch_acc: 0.488074. Batch_loss: 1.426122 \n",
      "Batch: 2565. Acc: 0.470062. Loss: 1.474598. Batch_acc: 0.503363. Batch_loss: 1.395352 \n",
      "Batch: 2566. Acc: 0.470061. Loss: 1.474581. Batch_acc: 0.468657. Batch_loss: 1.429304 \n",
      "Batch: 2567. Acc: 0.470069. Loss: 1.474552. Batch_acc: 0.490352. Batch_loss: 1.399309 \n",
      "Batch: 2568. Acc: 0.470063. Loss: 1.474566. Batch_acc: 0.452632. Batch_loss: 1.513031 \n",
      "Batch: 2569. Acc: 0.470059. Loss: 1.474567. Batch_acc: 0.459696. Batch_loss: 1.476115 \n",
      "Batch: 2570. Acc: 0.470062. Loss: 1.474544. Batch_acc: 0.477477. Batch_loss: 1.415822 \n",
      "Batch: 2571. Acc: 0.470061. Loss: 1.474529. Batch_acc: 0.468035. Batch_loss: 1.437126 \n",
      "Batch: 2572. Acc: 0.470059. Loss: 1.474527. Batch_acc: 0.465387. Batch_loss: 1.469833 \n",
      "Batch: 2573. Acc: 0.470064. Loss: 1.474520. Batch_acc: 0.481628. Batch_loss: 1.454728 \n",
      "Batch: 2574. Acc: 0.470084. Loss: 1.474469. Batch_acc: 0.522533. Batch_loss: 1.345863 \n",
      "Batch: 2575. Acc: 0.470076. Loss: 1.474494. Batch_acc: 0.447831. Batch_loss: 1.538416 \n",
      "Batch: 2576. Acc: 0.470077. Loss: 1.474476. Batch_acc: 0.472552. Batch_loss: 1.428633 \n",
      "Batch: 2577. Acc: 0.470080. Loss: 1.474456. Batch_acc: 0.478898. Batch_loss: 1.422048 \n",
      "Batch: 2578. Acc: 0.470089. Loss: 1.474425. Batch_acc: 0.492009. Batch_loss: 1.396145 \n",
      "Batch: 2579. Acc: 0.470097. Loss: 1.474409. Batch_acc: 0.491277. Batch_loss: 1.435211 \n",
      "Batch: 2580. Acc: 0.470103. Loss: 1.474381. Batch_acc: 0.485828. Batch_loss: 1.401740 \n",
      "Batch: 2581. Acc: 0.470100. Loss: 1.474378. Batch_acc: 0.462887. Batch_loss: 1.466496 \n",
      "Batch: 2582. Acc: 0.470101. Loss: 1.474384. Batch_acc: 0.471753. Batch_loss: 1.491028 \n",
      "Batch: 2583. Acc: 0.470107. Loss: 1.474369. Batch_acc: 0.484584. Batch_loss: 1.434709 \n",
      "Batch: 2584. Acc: 0.470121. Loss: 1.474335. Batch_acc: 0.506381. Batch_loss: 1.384464 \n",
      "Batch: 2585. Acc: 0.470132. Loss: 1.474318. Batch_acc: 0.498311. Batch_loss: 1.432669 \n",
      "Batch: 2586. Acc: 0.470132. Loss: 1.474309. Batch_acc: 0.470790. Batch_loss: 1.451240 \n",
      "Batch: 2587. Acc: 0.470144. Loss: 1.474283. Batch_acc: 0.501413. Batch_loss: 1.407167 \n",
      "Batch: 2588. Acc: 0.470142. Loss: 1.474289. Batch_acc: 0.465184. Batch_loss: 1.492074 \n",
      "Batch: 2589. Acc: 0.470146. Loss: 1.474280. Batch_acc: 0.479484. Batch_loss: 1.450133 \n",
      "Batch: 2590. Acc: 0.470149. Loss: 1.474264. Batch_acc: 0.478579. Batch_loss: 1.433319 \n",
      "Batch: 2591. Acc: 0.470163. Loss: 1.474235. Batch_acc: 0.505556. Batch_loss: 1.401247 \n",
      "Batch: 2592. Acc: 0.470166. Loss: 1.474225. Batch_acc: 0.476246. Batch_loss: 1.448997 \n",
      "Batch: 2593. Acc: 0.470175. Loss: 1.474210. Batch_acc: 0.494828. Batch_loss: 1.434749 \n",
      "Batch: 2594. Acc: 0.470184. Loss: 1.474181. Batch_acc: 0.492144. Batch_loss: 1.400409 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2595. Acc: 0.470188. Loss: 1.474167. Batch_acc: 0.480824. Batch_loss: 1.437480 \n",
      "Batch: 2596. Acc: 0.470189. Loss: 1.474155. Batch_acc: 0.473356. Batch_loss: 1.443674 \n",
      "Batch: 2597. Acc: 0.470196. Loss: 1.474143. Batch_acc: 0.487594. Batch_loss: 1.443730 \n",
      "Batch: 2598. Acc: 0.470204. Loss: 1.474132. Batch_acc: 0.490566. Batch_loss: 1.445316 \n",
      "Batch: 2599. Acc: 0.470209. Loss: 1.474120. Batch_acc: 0.484168. Batch_loss: 1.441518 \n",
      "Batch: 2600. Acc: 0.470218. Loss: 1.474109. Batch_acc: 0.494375. Batch_loss: 1.446389 \n",
      "Batch: 2601. Acc: 0.470235. Loss: 1.474074. Batch_acc: 0.512168. Batch_loss: 1.384855 \n",
      "Batch: 2602. Acc: 0.470235. Loss: 1.474063. Batch_acc: 0.472571. Batch_loss: 1.444171 \n",
      "Batch: 2603. Acc: 0.470243. Loss: 1.474035. Batch_acc: 0.489175. Batch_loss: 1.401498 \n",
      "Batch: 2604. Acc: 0.470259. Loss: 1.474002. Batch_acc: 0.511312. Batch_loss: 1.389300 \n",
      "Batch: 2605. Acc: 0.470261. Loss: 1.473999. Batch_acc: 0.477707. Batch_loss: 1.464910 \n",
      "Batch: 2606. Acc: 0.470267. Loss: 1.473990. Batch_acc: 0.484411. Batch_loss: 1.451477 \n",
      "Batch: 2607. Acc: 0.470278. Loss: 1.473951. Batch_acc: 0.499421. Batch_loss: 1.370556 \n",
      "Batch: 2608. Acc: 0.470283. Loss: 1.473939. Batch_acc: 0.483759. Batch_loss: 1.442167 \n",
      "Batch: 2609. Acc: 0.470293. Loss: 1.473904. Batch_acc: 0.496503. Batch_loss: 1.381106 \n",
      "Batch: 2610. Acc: 0.470303. Loss: 1.473879. Batch_acc: 0.496210. Batch_loss: 1.407941 \n",
      "Batch: 2611. Acc: 0.470298. Loss: 1.473892. Batch_acc: 0.457824. Batch_loss: 1.510099 \n",
      "Batch: 2612. Acc: 0.470302. Loss: 1.473876. Batch_acc: 0.481418. Batch_loss: 1.431504 \n",
      "Batch: 2613. Acc: 0.470301. Loss: 1.473874. Batch_acc: 0.467300. Batch_loss: 1.468125 \n",
      "Batch: 2614. Acc: 0.470307. Loss: 1.473869. Batch_acc: 0.484830. Batch_loss: 1.460438 \n",
      "Batch: 2615. Acc: 0.470310. Loss: 1.473856. Batch_acc: 0.478929. Batch_loss: 1.441636 \n",
      "Batch: 2616. Acc: 0.470318. Loss: 1.473847. Batch_acc: 0.492669. Batch_loss: 1.448859 \n",
      "Batch: 2617. Acc: 0.470326. Loss: 1.473821. Batch_acc: 0.491458. Batch_loss: 1.405473 \n",
      "Batch: 2618. Acc: 0.470340. Loss: 1.473779. Batch_acc: 0.506329. Batch_loss: 1.363243 \n",
      "Batch: 2619. Acc: 0.470346. Loss: 1.473760. Batch_acc: 0.485177. Batch_loss: 1.425155 \n",
      "Batch: 2620. Acc: 0.470352. Loss: 1.473743. Batch_acc: 0.487209. Batch_loss: 1.429303 \n",
      "Batch: 2621. Acc: 0.470352. Loss: 1.473740. Batch_acc: 0.468680. Batch_loss: 1.465256 \n",
      "Batch: 2622. Acc: 0.470358. Loss: 1.473717. Batch_acc: 0.487707. Batch_loss: 1.415410 \n",
      "Batch: 2623. Acc: 0.470364. Loss: 1.473697. Batch_acc: 0.486119. Batch_loss: 1.419161 \n",
      "Batch: 2624. Acc: 0.470362. Loss: 1.473696. Batch_acc: 0.463674. Batch_loss: 1.472089 \n",
      "Batch: 2625. Acc: 0.470371. Loss: 1.473684. Batch_acc: 0.495038. Batch_loss: 1.439207 \n",
      "Batch: 2626. Acc: 0.470388. Loss: 1.473637. Batch_acc: 0.515753. Batch_loss: 1.349432 \n",
      "Batch: 2627. Acc: 0.470396. Loss: 1.473609. Batch_acc: 0.492135. Batch_loss: 1.402289 \n",
      "Batch: 2628. Acc: 0.470407. Loss: 1.473580. Batch_acc: 0.498282. Batch_loss: 1.396832 \n",
      "Batch: 2629. Acc: 0.470412. Loss: 1.473554. Batch_acc: 0.483759. Batch_loss: 1.404125 \n",
      "Batch: 2630. Acc: 0.470415. Loss: 1.473539. Batch_acc: 0.477427. Batch_loss: 1.436317 \n",
      "Batch: 2631. Acc: 0.470413. Loss: 1.473534. Batch_acc: 0.464531. Batch_loss: 1.460896 \n",
      "Batch: 2632. Acc: 0.470415. Loss: 1.473519. Batch_acc: 0.476744. Batch_loss: 1.433746 \n",
      "Batch: 2633. Acc: 0.470424. Loss: 1.473499. Batch_acc: 0.493274. Batch_loss: 1.422259 \n",
      "Batch: 2634. Acc: 0.470431. Loss: 1.473478. Batch_acc: 0.489088. Batch_loss: 1.420694 \n",
      "Batch: 2635. Acc: 0.470433. Loss: 1.473470. Batch_acc: 0.474250. Batch_loss: 1.451852 \n",
      "Batch: 2636. Acc: 0.470436. Loss: 1.473457. Batch_acc: 0.479444. Batch_loss: 1.439183 \n",
      "Batch: 2637. Acc: 0.470445. Loss: 1.473440. Batch_acc: 0.492861. Batch_loss: 1.429603 \n",
      "Batch: 2638. Acc: 0.470454. Loss: 1.473406. Batch_acc: 0.495954. Batch_loss: 1.384279 \n",
      "Batch: 2639. Acc: 0.470456. Loss: 1.473388. Batch_acc: 0.475617. Batch_loss: 1.426253 \n",
      "Batch: 2640. Acc: 0.470466. Loss: 1.473358. Batch_acc: 0.497140. Batch_loss: 1.393569 \n",
      "Batch: 2641. Acc: 0.470475. Loss: 1.473319. Batch_acc: 0.493671. Batch_loss: 1.369609 \n",
      "Batch: 2642. Acc: 0.470487. Loss: 1.473289. Batch_acc: 0.502278. Batch_loss: 1.394449 \n",
      "Batch: 2643. Acc: 0.470494. Loss: 1.473272. Batch_acc: 0.486547. Batch_loss: 1.430251 \n",
      "Batch: 2644. Acc: 0.470502. Loss: 1.473256. Batch_acc: 0.492415. Batch_loss: 1.430793 \n",
      "Batch: 2645. Acc: 0.470510. Loss: 1.473244. Batch_acc: 0.490981. Batch_loss: 1.442536 \n",
      "Batch: 2646. Acc: 0.470508. Loss: 1.473238. Batch_acc: 0.466087. Batch_loss: 1.455444 \n",
      "Batch: 2647. Acc: 0.470516. Loss: 1.473220. Batch_acc: 0.491991. Batch_loss: 1.425669 \n",
      "Batch: 2648. Acc: 0.470516. Loss: 1.473220. Batch_acc: 0.469021. Batch_loss: 1.474153 \n",
      "Batch: 2649. Acc: 0.470526. Loss: 1.473178. Batch_acc: 0.496891. Batch_loss: 1.364286 \n",
      "Batch: 2650. Acc: 0.470534. Loss: 1.473155. Batch_acc: 0.492537. Batch_loss: 1.412594 \n",
      "Batch: 2651. Acc: 0.470533. Loss: 1.473153. Batch_acc: 0.467761. Batch_loss: 1.468585 \n",
      "Batch: 2652. Acc: 0.470538. Loss: 1.473136. Batch_acc: 0.483597. Batch_loss: 1.428729 \n",
      "Batch: 2653. Acc: 0.470550. Loss: 1.473097. Batch_acc: 0.503817. Batch_loss: 1.367248 \n",
      "Batch: 2654. Acc: 0.470566. Loss: 1.473055. Batch_acc: 0.512251. Batch_loss: 1.361471 \n",
      "Batch: 2655. Acc: 0.470565. Loss: 1.473046. Batch_acc: 0.467622. Batch_loss: 1.449881 \n",
      "Batch: 2656. Acc: 0.470574. Loss: 1.473018. Batch_acc: 0.494518. Batch_loss: 1.399284 \n",
      "Batch: 2657. Acc: 0.470578. Loss: 1.473012. Batch_acc: 0.480594. Batch_loss: 1.456653 \n",
      "Batch: 2658. Acc: 0.470584. Loss: 1.472991. Batch_acc: 0.488482. Batch_loss: 1.414407 \n",
      "Batch: 2659. Acc: 0.470591. Loss: 1.472974. Batch_acc: 0.488005. Batch_loss: 1.428152 \n",
      "Batch: 2660. Acc: 0.470590. Loss: 1.472976. Batch_acc: 0.469244. Batch_loss: 1.478325 \n",
      "Batch: 2661. Acc: 0.470593. Loss: 1.472969. Batch_acc: 0.477048. Batch_loss: 1.452756 \n",
      "Batch: 2662. Acc: 0.470612. Loss: 1.472929. Batch_acc: 0.523588. Batch_loss: 1.366631 \n",
      "Batch: 2663. Acc: 0.470619. Loss: 1.472919. Batch_acc: 0.487735. Batch_loss: 1.444497 \n",
      "Batch: 2664. Acc: 0.470624. Loss: 1.472897. Batch_acc: 0.483759. Batch_loss: 1.415706 \n",
      "Batch: 2665. Acc: 0.470628. Loss: 1.472883. Batch_acc: 0.482997. Batch_loss: 1.434522 \n",
      "Batch: 2666. Acc: 0.470637. Loss: 1.472860. Batch_acc: 0.492246. Batch_loss: 1.412190 \n",
      "Batch: 2667. Acc: 0.470641. Loss: 1.472840. Batch_acc: 0.481823. Batch_loss: 1.419322 \n",
      "Batch: 2668. Acc: 0.470646. Loss: 1.472811. Batch_acc: 0.484095. Batch_loss: 1.395225 \n",
      "Batch: 2669. Acc: 0.470654. Loss: 1.472778. Batch_acc: 0.493425. Batch_loss: 1.385948 \n",
      "Batch: 2670. Acc: 0.470661. Loss: 1.472754. Batch_acc: 0.487874. Batch_loss: 1.409742 \n",
      "Batch: 2671. Acc: 0.470672. Loss: 1.472723. Batch_acc: 0.501148. Batch_loss: 1.390103 \n",
      "Batch: 2672. Acc: 0.470670. Loss: 1.472726. Batch_acc: 0.465250. Batch_loss: 1.478827 \n",
      "Batch: 2673. Acc: 0.470677. Loss: 1.472711. Batch_acc: 0.488143. Batch_loss: 1.432798 \n",
      "Batch: 2674. Acc: 0.470672. Loss: 1.472730. Batch_acc: 0.458406. Batch_loss: 1.523559 \n",
      "Batch: 2675. Acc: 0.470673. Loss: 1.472720. Batch_acc: 0.473808. Batch_loss: 1.445961 \n",
      "Batch: 2676. Acc: 0.470683. Loss: 1.472700. Batch_acc: 0.495168. Batch_loss: 1.419773 \n",
      "Batch: 2677. Acc: 0.470691. Loss: 1.472676. Batch_acc: 0.491982. Batch_loss: 1.408375 \n",
      "Batch: 2678. Acc: 0.470695. Loss: 1.472673. Batch_acc: 0.481998. Batch_loss: 1.466727 \n",
      "Batch: 2679. Acc: 0.470701. Loss: 1.472644. Batch_acc: 0.488318. Batch_loss: 1.392646 \n",
      "Batch: 2680. Acc: 0.470706. Loss: 1.472640. Batch_acc: 0.482421. Batch_loss: 1.462458 \n",
      "Batch: 2681. Acc: 0.470722. Loss: 1.472609. Batch_acc: 0.514121. Batch_loss: 1.387537 \n",
      "Batch: 2682. Acc: 0.470732. Loss: 1.472588. Batch_acc: 0.497126. Batch_loss: 1.416767 \n",
      "Batch: 2683. Acc: 0.470741. Loss: 1.472561. Batch_acc: 0.496338. Batch_loss: 1.401920 \n",
      "Batch: 2684. Acc: 0.470750. Loss: 1.472529. Batch_acc: 0.493671. Batch_loss: 1.386059 \n",
      "Batch: 2685. Acc: 0.470758. Loss: 1.472501. Batch_acc: 0.493349. Batch_loss: 1.397249 \n",
      "Batch: 2686. Acc: 0.470765. Loss: 1.472487. Batch_acc: 0.488143. Batch_loss: 1.435762 \n",
      "Batch: 2687. Acc: 0.470777. Loss: 1.472475. Batch_acc: 0.504882. Batch_loss: 1.440686 \n",
      "Batch: 2688. Acc: 0.470782. Loss: 1.472466. Batch_acc: 0.484266. Batch_loss: 1.447241 \n",
      "Batch: 2689. Acc: 0.470795. Loss: 1.472431. Batch_acc: 0.504303. Batch_loss: 1.379330 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2690. Acc: 0.470802. Loss: 1.472418. Batch_acc: 0.490116. Batch_loss: 1.435076 \n",
      "Batch: 2691. Acc: 0.470816. Loss: 1.472376. Batch_acc: 0.507901. Batch_loss: 1.362659 \n",
      "Batch: 2692. Acc: 0.470831. Loss: 1.472352. Batch_acc: 0.510465. Batch_loss: 1.407450 \n",
      "Batch: 2693. Acc: 0.470841. Loss: 1.472335. Batch_acc: 0.497727. Batch_loss: 1.425842 \n",
      "Batch: 2694. Acc: 0.470842. Loss: 1.472320. Batch_acc: 0.474857. Batch_loss: 1.432711 \n",
      "Batch: 2695. Acc: 0.470846. Loss: 1.472298. Batch_acc: 0.482436. Batch_loss: 1.413314 \n",
      "Batch: 2696. Acc: 0.470849. Loss: 1.472305. Batch_acc: 0.476603. Batch_loss: 1.489399 \n",
      "Batch: 2697. Acc: 0.470850. Loss: 1.472297. Batch_acc: 0.474282. Batch_loss: 1.450012 \n",
      "Batch: 2698. Acc: 0.470858. Loss: 1.472280. Batch_acc: 0.491700. Batch_loss: 1.427003 \n",
      "Batch: 2699. Acc: 0.470869. Loss: 1.472244. Batch_acc: 0.503534. Batch_loss: 1.371797 \n",
      "Batch: 2700. Acc: 0.470878. Loss: 1.472223. Batch_acc: 0.493582. Batch_loss: 1.414715 \n",
      "Batch: 2701. Acc: 0.470888. Loss: 1.472194. Batch_acc: 0.499711. Batch_loss: 1.394770 \n",
      "Batch: 2702. Acc: 0.470899. Loss: 1.472158. Batch_acc: 0.501163. Batch_loss: 1.372993 \n",
      "Batch: 2703. Acc: 0.470907. Loss: 1.472129. Batch_acc: 0.492334. Batch_loss: 1.395690 \n",
      "Batch: 2704. Acc: 0.470908. Loss: 1.472119. Batch_acc: 0.472981. Batch_loss: 1.445017 \n",
      "Batch: 2705. Acc: 0.470917. Loss: 1.472093. Batch_acc: 0.494618. Batch_loss: 1.402518 \n",
      "Batch: 2706. Acc: 0.470924. Loss: 1.472080. Batch_acc: 0.490962. Batch_loss: 1.436846 \n",
      "Batch: 2707. Acc: 0.470931. Loss: 1.472061. Batch_acc: 0.488122. Batch_loss: 1.420239 \n",
      "Batch: 2708. Acc: 0.470944. Loss: 1.472014. Batch_acc: 0.505587. Batch_loss: 1.350137 \n",
      "Batch: 2709. Acc: 0.470940. Loss: 1.472025. Batch_acc: 0.458742. Batch_loss: 1.499996 \n",
      "Batch: 2710. Acc: 0.470951. Loss: 1.471989. Batch_acc: 0.501722. Batch_loss: 1.375712 \n",
      "Batch: 2711. Acc: 0.470954. Loss: 1.471981. Batch_acc: 0.480724. Batch_loss: 1.449831 \n",
      "Batch: 2712. Acc: 0.470966. Loss: 1.471950. Batch_acc: 0.502630. Batch_loss: 1.385903 \n",
      "Batch: 2713. Acc: 0.470975. Loss: 1.471920. Batch_acc: 0.494636. Batch_loss: 1.392243 \n",
      "Batch: 2714. Acc: 0.470975. Loss: 1.471913. Batch_acc: 0.470521. Batch_loss: 1.452502 \n",
      "Batch: 2715. Acc: 0.470979. Loss: 1.471898. Batch_acc: 0.481948. Batch_loss: 1.430963 \n",
      "Batch: 2716. Acc: 0.470980. Loss: 1.471894. Batch_acc: 0.473593. Batch_loss: 1.461333 \n",
      "Batch: 2717. Acc: 0.470994. Loss: 1.471858. Batch_acc: 0.510216. Batch_loss: 1.375445 \n",
      "Batch: 2718. Acc: 0.471002. Loss: 1.471835. Batch_acc: 0.492000. Batch_loss: 1.409759 \n",
      "Batch: 2719. Acc: 0.471009. Loss: 1.471810. Batch_acc: 0.489326. Batch_loss: 1.406172 \n",
      "Batch: 2720. Acc: 0.471024. Loss: 1.471770. Batch_acc: 0.509041. Batch_loss: 1.367405 \n",
      "Batch: 2721. Acc: 0.471024. Loss: 1.471769. Batch_acc: 0.471143. Batch_loss: 1.470657 \n",
      "Batch: 2722. Acc: 0.471030. Loss: 1.471753. Batch_acc: 0.489017. Batch_loss: 1.426285 \n",
      "Batch: 2723. Acc: 0.471024. Loss: 1.471764. Batch_acc: 0.454383. Batch_loss: 1.503040 \n",
      "Batch: 2724. Acc: 0.471033. Loss: 1.471738. Batch_acc: 0.494486. Batch_loss: 1.401814 \n",
      "Batch: 2725. Acc: 0.471038. Loss: 1.471717. Batch_acc: 0.484357. Batch_loss: 1.414361 \n",
      "Batch: 2726. Acc: 0.471040. Loss: 1.471700. Batch_acc: 0.478085. Batch_loss: 1.424091 \n",
      "Batch: 2727. Acc: 0.471043. Loss: 1.471697. Batch_acc: 0.479813. Batch_loss: 1.462592 \n",
      "Batch: 2728. Acc: 0.471039. Loss: 1.471700. Batch_acc: 0.458664. Batch_loss: 1.481680 \n",
      "Batch: 2729. Acc: 0.471045. Loss: 1.471691. Batch_acc: 0.488095. Batch_loss: 1.445332 \n",
      "Batch: 2730. Acc: 0.471044. Loss: 1.471695. Batch_acc: 0.468442. Batch_loss: 1.483301 \n",
      "Batch: 2731. Acc: 0.471049. Loss: 1.471685. Batch_acc: 0.484954. Batch_loss: 1.444352 \n",
      "Batch: 2732. Acc: 0.471056. Loss: 1.471680. Batch_acc: 0.488372. Batch_loss: 1.457742 \n",
      "Batch: 2733. Acc: 0.471051. Loss: 1.471688. Batch_acc: 0.458072. Batch_loss: 1.494095 \n",
      "Batch: 2734. Acc: 0.471054. Loss: 1.471672. Batch_acc: 0.479726. Batch_loss: 1.427645 \n",
      "Batch: 2735. Acc: 0.471059. Loss: 1.471663. Batch_acc: 0.484105. Batch_loss: 1.448731 \n",
      "Batch: 2736. Acc: 0.471058. Loss: 1.471662. Batch_acc: 0.467874. Batch_loss: 1.467749 \n",
      "Batch: 2737. Acc: 0.471055. Loss: 1.471670. Batch_acc: 0.464098. Batch_loss: 1.494457 \n",
      "Batch: 2738. Acc: 0.471057. Loss: 1.471656. Batch_acc: 0.474857. Batch_loss: 1.434402 \n",
      "Batch: 2739. Acc: 0.471068. Loss: 1.471627. Batch_acc: 0.501703. Batch_loss: 1.392314 \n",
      "Batch: 2740. Acc: 0.471075. Loss: 1.471602. Batch_acc: 0.488966. Batch_loss: 1.402676 \n",
      "Batch: 2741. Acc: 0.471081. Loss: 1.471591. Batch_acc: 0.488061. Batch_loss: 1.441462 \n",
      "Batch: 2742. Acc: 0.471087. Loss: 1.471567. Batch_acc: 0.488319. Batch_loss: 1.404978 \n",
      "Batch: 2743. Acc: 0.471095. Loss: 1.471544. Batch_acc: 0.491594. Batch_loss: 1.409861 \n",
      "Batch: 2744. Acc: 0.471094. Loss: 1.471541. Batch_acc: 0.470167. Batch_loss: 1.462346 \n",
      "Batch: 2745. Acc: 0.471094. Loss: 1.471528. Batch_acc: 0.471056. Batch_loss: 1.436723 \n",
      "Batch: 2746. Acc: 0.471103. Loss: 1.471507. Batch_acc: 0.494834. Batch_loss: 1.412528 \n",
      "Batch: 2747. Acc: 0.471107. Loss: 1.471493. Batch_acc: 0.483372. Batch_loss: 1.434014 \n",
      "Batch: 2748. Acc: 0.471114. Loss: 1.471484. Batch_acc: 0.491187. Batch_loss: 1.445764 \n",
      "Batch: 2749. Acc: 0.471124. Loss: 1.471456. Batch_acc: 0.497666. Batch_loss: 1.392751 \n",
      "Batch: 2750. Acc: 0.471133. Loss: 1.471429. Batch_acc: 0.495702. Batch_loss: 1.399013 \n",
      "Batch: 2751. Acc: 0.471138. Loss: 1.471415. Batch_acc: 0.484518. Batch_loss: 1.432698 \n",
      "Batch: 2752. Acc: 0.471148. Loss: 1.471374. Batch_acc: 0.496960. Batch_loss: 1.363374 \n",
      "Batch: 2753. Acc: 0.471155. Loss: 1.471331. Batch_acc: 0.490708. Batch_loss: 1.350205 \n",
      "Batch: 2754. Acc: 0.471152. Loss: 1.471328. Batch_acc: 0.463443. Batch_loss: 1.465383 \n",
      "Batch: 2755. Acc: 0.471157. Loss: 1.471302. Batch_acc: 0.484797. Batch_loss: 1.401268 \n",
      "Batch: 2756. Acc: 0.471154. Loss: 1.471309. Batch_acc: 0.461905. Batch_loss: 1.490096 \n",
      "Batch: 2757. Acc: 0.471158. Loss: 1.471294. Batch_acc: 0.484043. Batch_loss: 1.428657 \n",
      "Batch: 2758. Acc: 0.471167. Loss: 1.471269. Batch_acc: 0.494363. Batch_loss: 1.404567 \n",
      "Batch: 2759. Acc: 0.471172. Loss: 1.471247. Batch_acc: 0.485499. Batch_loss: 1.407727 \n",
      "Batch: 2760. Acc: 0.471183. Loss: 1.471222. Batch_acc: 0.501730. Batch_loss: 1.403100 \n",
      "Batch: 2761. Acc: 0.471180. Loss: 1.471222. Batch_acc: 0.462077. Batch_loss: 1.472905 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.4711797233621688. Loss per char: 1.4712224850707512. Time: 1627216293.5853148\n",
      "Last question is tensor([ 2, 18, 26, 26, 23, 20, 23, 18, 12, 18, 17, 19, 17, 19, 22,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.471181. Loss: 1.471207. Batch_acc: 0.475504. Batch_loss: 1.429505 \n",
      "Batch: 2763. Acc: 0.471185. Loss: 1.471206. Batch_acc: 0.482265. Batch_loss: 1.466219 \n",
      "Batch: 2764. Acc: 0.471196. Loss: 1.471180. Batch_acc: 0.499432. Batch_loss: 1.402656 \n",
      "Batch: 2765. Acc: 0.471202. Loss: 1.471169. Batch_acc: 0.488171. Batch_loss: 1.438934 \n",
      "Batch: 2766. Acc: 0.471210. Loss: 1.471148. Batch_acc: 0.493590. Batch_loss: 1.411855 \n",
      "Batch: 2767. Acc: 0.471210. Loss: 1.471142. Batch_acc: 0.472061. Batch_loss: 1.456289 \n",
      "Batch: 2768. Acc: 0.471210. Loss: 1.471140. Batch_acc: 0.470622. Batch_loss: 1.465798 \n",
      "Batch: 2769. Acc: 0.471216. Loss: 1.471123. Batch_acc: 0.488345. Batch_loss: 1.421077 \n",
      "Batch: 2770. Acc: 0.471220. Loss: 1.471110. Batch_acc: 0.482974. Batch_loss: 1.436621 \n",
      "Batch: 2771. Acc: 0.471234. Loss: 1.471071. Batch_acc: 0.506667. Batch_loss: 1.367074 \n",
      "Batch: 2772. Acc: 0.471249. Loss: 1.471031. Batch_acc: 0.515099. Batch_loss: 1.359343 \n",
      "Batch: 2773. Acc: 0.471253. Loss: 1.471012. Batch_acc: 0.480482. Batch_loss: 1.416933 \n",
      "Batch: 2774. Acc: 0.471261. Loss: 1.470972. Batch_acc: 0.495712. Batch_loss: 1.362684 \n",
      "Batch: 2775. Acc: 0.471272. Loss: 1.470937. Batch_acc: 0.500565. Batch_loss: 1.374157 \n",
      "Batch: 2776. Acc: 0.471275. Loss: 1.470929. Batch_acc: 0.479839. Batch_loss: 1.449644 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2777. Acc: 0.471279. Loss: 1.470928. Batch_acc: 0.483075. Batch_loss: 1.466428 \n",
      "Batch: 2778. Acc: 0.471273. Loss: 1.470939. Batch_acc: 0.453860. Batch_loss: 1.502813 \n",
      "Batch: 2779. Acc: 0.471275. Loss: 1.470930. Batch_acc: 0.477075. Batch_loss: 1.444662 \n",
      "Batch: 2780. Acc: 0.471285. Loss: 1.470904. Batch_acc: 0.498303. Batch_loss: 1.401528 \n",
      "Batch: 2781. Acc: 0.471290. Loss: 1.470888. Batch_acc: 0.485143. Batch_loss: 1.425812 \n",
      "Batch: 2782. Acc: 0.471293. Loss: 1.470887. Batch_acc: 0.478996. Batch_loss: 1.467320 \n",
      "Batch: 2783. Acc: 0.471309. Loss: 1.470831. Batch_acc: 0.516477. Batch_loss: 1.317544 \n",
      "Batch: 2784. Acc: 0.471310. Loss: 1.470820. Batch_acc: 0.472957. Batch_loss: 1.439955 \n",
      "Batch: 2785. Acc: 0.471317. Loss: 1.470805. Batch_acc: 0.491706. Batch_loss: 1.427164 \n",
      "Batch: 2786. Acc: 0.471322. Loss: 1.470785. Batch_acc: 0.485566. Batch_loss: 1.414903 \n",
      "Batch: 2787. Acc: 0.471320. Loss: 1.470784. Batch_acc: 0.465262. Batch_loss: 1.470265 \n",
      "Batch: 2788. Acc: 0.471331. Loss: 1.470755. Batch_acc: 0.503497. Batch_loss: 1.387860 \n",
      "Batch: 2789. Acc: 0.471340. Loss: 1.470725. Batch_acc: 0.494064. Batch_loss: 1.388646 \n",
      "Batch: 2790. Acc: 0.471346. Loss: 1.470701. Batch_acc: 0.490196. Batch_loss: 1.404479 \n",
      "Batch: 2791. Acc: 0.471340. Loss: 1.470724. Batch_acc: 0.451957. Batch_loss: 1.536767 \n",
      "Batch: 2792. Acc: 0.471348. Loss: 1.470688. Batch_acc: 0.495692. Batch_loss: 1.367972 \n",
      "Batch: 2793. Acc: 0.471359. Loss: 1.470659. Batch_acc: 0.501712. Batch_loss: 1.390576 \n",
      "Batch: 2794. Acc: 0.471373. Loss: 1.470627. Batch_acc: 0.510145. Batch_loss: 1.381862 \n",
      "Batch: 2795. Acc: 0.471368. Loss: 1.470627. Batch_acc: 0.456534. Batch_loss: 1.471307 \n",
      "Batch: 2796. Acc: 0.471378. Loss: 1.470594. Batch_acc: 0.498564. Batch_loss: 1.377316 \n",
      "Batch: 2797. Acc: 0.471381. Loss: 1.470578. Batch_acc: 0.480229. Batch_loss: 1.426838 \n",
      "Batch: 2798. Acc: 0.471385. Loss: 1.470566. Batch_acc: 0.484393. Batch_loss: 1.435793 \n",
      "Batch: 2799. Acc: 0.471394. Loss: 1.470548. Batch_acc: 0.494581. Batch_loss: 1.421692 \n",
      "Batch: 2800. Acc: 0.471400. Loss: 1.470521. Batch_acc: 0.489136. Batch_loss: 1.397856 \n",
      "Batch: 2801. Acc: 0.471411. Loss: 1.470492. Batch_acc: 0.501416. Batch_loss: 1.389941 \n",
      "Batch: 2802. Acc: 0.471415. Loss: 1.470472. Batch_acc: 0.480933. Batch_loss: 1.413414 \n",
      "Batch: 2803. Acc: 0.471416. Loss: 1.470471. Batch_acc: 0.476025. Batch_loss: 1.468222 \n",
      "Batch: 2804. Acc: 0.471419. Loss: 1.470458. Batch_acc: 0.479131. Batch_loss: 1.434671 \n",
      "Batch: 2805. Acc: 0.471420. Loss: 1.470459. Batch_acc: 0.474256. Batch_loss: 1.473422 \n",
      "Batch: 2806. Acc: 0.471423. Loss: 1.470449. Batch_acc: 0.480702. Batch_loss: 1.441275 \n",
      "Batch: 2807. Acc: 0.471426. Loss: 1.470436. Batch_acc: 0.479694. Batch_loss: 1.434411 \n",
      "Batch: 2808. Acc: 0.471432. Loss: 1.470430. Batch_acc: 0.488184. Batch_loss: 1.452131 \n",
      "Batch: 2809. Acc: 0.471434. Loss: 1.470418. Batch_acc: 0.477326. Batch_loss: 1.435525 \n",
      "Batch: 2810. Acc: 0.471451. Loss: 1.470381. Batch_acc: 0.517202. Batch_loss: 1.369095 \n",
      "Batch: 2811. Acc: 0.471449. Loss: 1.470378. Batch_acc: 0.467128. Batch_loss: 1.460816 \n",
      "Batch: 2812. Acc: 0.471445. Loss: 1.470372. Batch_acc: 0.459677. Batch_loss: 1.453516 \n",
      "Batch: 2813. Acc: 0.471442. Loss: 1.470377. Batch_acc: 0.462428. Batch_loss: 1.483878 \n",
      "Batch: 2814. Acc: 0.471447. Loss: 1.470359. Batch_acc: 0.485825. Batch_loss: 1.423281 \n",
      "Batch: 2815. Acc: 0.471451. Loss: 1.470347. Batch_acc: 0.481781. Batch_loss: 1.436180 \n",
      "Batch: 2816. Acc: 0.471457. Loss: 1.470331. Batch_acc: 0.489051. Batch_loss: 1.424850 \n",
      "Batch: 2817. Acc: 0.471459. Loss: 1.470323. Batch_acc: 0.478236. Batch_loss: 1.448167 \n",
      "Batch: 2818. Acc: 0.471468. Loss: 1.470295. Batch_acc: 0.496350. Batch_loss: 1.393888 \n",
      "Batch: 2819. Acc: 0.471478. Loss: 1.470270. Batch_acc: 0.498254. Batch_loss: 1.399758 \n",
      "Batch: 2820. Acc: 0.471487. Loss: 1.470240. Batch_acc: 0.498571. Batch_loss: 1.386550 \n",
      "Batch: 2821. Acc: 0.471488. Loss: 1.470236. Batch_acc: 0.472238. Batch_loss: 1.456585 \n",
      "Batch: 2822. Acc: 0.471495. Loss: 1.470212. Batch_acc: 0.492571. Batch_loss: 1.405163 \n",
      "Batch: 2823. Acc: 0.471494. Loss: 1.470204. Batch_acc: 0.467473. Batch_loss: 1.446342 \n",
      "Batch: 2824. Acc: 0.471497. Loss: 1.470202. Batch_acc: 0.480070. Batch_loss: 1.464105 \n",
      "Batch: 2825. Acc: 0.471500. Loss: 1.470196. Batch_acc: 0.481308. Batch_loss: 1.452928 \n",
      "Batch: 2826. Acc: 0.471504. Loss: 1.470187. Batch_acc: 0.481914. Batch_loss: 1.443577 \n",
      "Batch: 2827. Acc: 0.471504. Loss: 1.470187. Batch_acc: 0.470755. Batch_loss: 1.471707 \n",
      "Batch: 2828. Acc: 0.471507. Loss: 1.470170. Batch_acc: 0.481907. Batch_loss: 1.420788 \n",
      "Batch: 2829. Acc: 0.471515. Loss: 1.470157. Batch_acc: 0.493236. Batch_loss: 1.434761 \n",
      "Batch: 2830. Acc: 0.471514. Loss: 1.470148. Batch_acc: 0.469636. Batch_loss: 1.444378 \n",
      "Batch: 2831. Acc: 0.471520. Loss: 1.470131. Batch_acc: 0.487613. Batch_loss: 1.424427 \n",
      "Batch: 2832. Acc: 0.471524. Loss: 1.470122. Batch_acc: 0.483256. Batch_loss: 1.443761 \n",
      "Batch: 2833. Acc: 0.471534. Loss: 1.470088. Batch_acc: 0.499124. Batch_loss: 1.371184 \n",
      "Batch: 2834. Acc: 0.471534. Loss: 1.470095. Batch_acc: 0.470421. Batch_loss: 1.489810 \n",
      "Batch: 2835. Acc: 0.471534. Loss: 1.470079. Batch_acc: 0.472801. Batch_loss: 1.426737 \n",
      "Batch: 2836. Acc: 0.471542. Loss: 1.470067. Batch_acc: 0.493455. Batch_loss: 1.436416 \n",
      "Batch: 2837. Acc: 0.471551. Loss: 1.470038. Batch_acc: 0.499118. Batch_loss: 1.386043 \n",
      "Batch: 2838. Acc: 0.471569. Loss: 1.469992. Batch_acc: 0.523015. Batch_loss: 1.338340 \n",
      "Batch: 2839. Acc: 0.471572. Loss: 1.469986. Batch_acc: 0.478597. Batch_loss: 1.453327 \n",
      "Batch: 2840. Acc: 0.471579. Loss: 1.469973. Batch_acc: 0.491128. Batch_loss: 1.432162 \n",
      "Batch: 2841. Acc: 0.471587. Loss: 1.469945. Batch_acc: 0.496249. Batch_loss: 1.390822 \n",
      "Batch: 2842. Acc: 0.471590. Loss: 1.469943. Batch_acc: 0.479882. Batch_loss: 1.462301 \n",
      "Batch: 2843. Acc: 0.471594. Loss: 1.469948. Batch_acc: 0.481308. Batch_loss: 1.486726 \n",
      "Batch: 2844. Acc: 0.471599. Loss: 1.469931. Batch_acc: 0.487721. Batch_loss: 1.419593 \n",
      "Batch: 2845. Acc: 0.471603. Loss: 1.469925. Batch_acc: 0.481290. Batch_loss: 1.452864 \n",
      "Batch: 2846. Acc: 0.471612. Loss: 1.469894. Batch_acc: 0.496313. Batch_loss: 1.385094 \n",
      "Batch: 2847. Acc: 0.471622. Loss: 1.469867. Batch_acc: 0.501153. Batch_loss: 1.391201 \n",
      "Batch: 2848. Acc: 0.471626. Loss: 1.469870. Batch_acc: 0.483286. Batch_loss: 1.479566 \n",
      "Batch: 2849. Acc: 0.471632. Loss: 1.469854. Batch_acc: 0.489667. Batch_loss: 1.423041 \n",
      "Batch: 2850. Acc: 0.471640. Loss: 1.469833. Batch_acc: 0.493064. Batch_loss: 1.409916 \n",
      "Batch: 2851. Acc: 0.471647. Loss: 1.469809. Batch_acc: 0.492705. Batch_loss: 1.404532 \n",
      "Batch: 2852. Acc: 0.471653. Loss: 1.469794. Batch_acc: 0.487091. Batch_loss: 1.424847 \n",
      "Batch: 2853. Acc: 0.471657. Loss: 1.469775. Batch_acc: 0.482918. Batch_loss: 1.415278 \n",
      "Batch: 2854. Acc: 0.471667. Loss: 1.469754. Batch_acc: 0.501480. Batch_loss: 1.407876 \n",
      "Batch: 2855. Acc: 0.471672. Loss: 1.469741. Batch_acc: 0.486440. Batch_loss: 1.433000 \n",
      "Batch: 2856. Acc: 0.471689. Loss: 1.469702. Batch_acc: 0.518414. Batch_loss: 1.359206 \n",
      "Batch: 2857. Acc: 0.471700. Loss: 1.469676. Batch_acc: 0.504635. Batch_loss: 1.396845 \n",
      "Batch: 2858. Acc: 0.471699. Loss: 1.469680. Batch_acc: 0.468281. Batch_loss: 1.480058 \n",
      "Batch: 2859. Acc: 0.471705. Loss: 1.469663. Batch_acc: 0.488851. Batch_loss: 1.421626 \n",
      "Batch: 2860. Acc: 0.471704. Loss: 1.469650. Batch_acc: 0.470095. Batch_loss: 1.434583 \n",
      "Batch: 2861. Acc: 0.471705. Loss: 1.469654. Batch_acc: 0.473011. Batch_loss: 1.479593 \n",
      "Batch: 2862. Acc: 0.471708. Loss: 1.469639. Batch_acc: 0.479769. Batch_loss: 1.427176 \n",
      "Batch: 2863. Acc: 0.471710. Loss: 1.469633. Batch_acc: 0.479083. Batch_loss: 1.452325 \n",
      "Batch: 2864. Acc: 0.471719. Loss: 1.469609. Batch_acc: 0.496884. Batch_loss: 1.400542 \n",
      "Batch: 2865. Acc: 0.471722. Loss: 1.469593. Batch_acc: 0.479651. Batch_loss: 1.423221 \n",
      "Batch: 2866. Acc: 0.471728. Loss: 1.469585. Batch_acc: 0.487861. Batch_loss: 1.448896 \n",
      "Batch: 2867. Acc: 0.471732. Loss: 1.469573. Batch_acc: 0.484095. Batch_loss: 1.433609 \n",
      "Batch: 2868. Acc: 0.471745. Loss: 1.469550. Batch_acc: 0.508361. Batch_loss: 1.405263 \n",
      "Batch: 2869. Acc: 0.471750. Loss: 1.469537. Batch_acc: 0.484901. Batch_loss: 1.432397 \n",
      "Batch: 2870. Acc: 0.471756. Loss: 1.469517. Batch_acc: 0.488914. Batch_loss: 1.412590 \n",
      "Batch: 2871. Acc: 0.471754. Loss: 1.469526. Batch_acc: 0.467204. Batch_loss: 1.496022 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2872. Acc: 0.471750. Loss: 1.469524. Batch_acc: 0.461229. Batch_loss: 1.464229 \n",
      "Batch: 2873. Acc: 0.471762. Loss: 1.469494. Batch_acc: 0.506403. Batch_loss: 1.380136 \n",
      "Batch: 2874. Acc: 0.471763. Loss: 1.469494. Batch_acc: 0.473131. Batch_loss: 1.472284 \n",
      "Batch: 2875. Acc: 0.471769. Loss: 1.469477. Batch_acc: 0.490128. Batch_loss: 1.417776 \n",
      "Batch: 2876. Acc: 0.471777. Loss: 1.469452. Batch_acc: 0.494581. Batch_loss: 1.398641 \n",
      "Batch: 2877. Acc: 0.471778. Loss: 1.469453. Batch_acc: 0.474644. Batch_loss: 1.473173 \n",
      "Batch: 2878. Acc: 0.471777. Loss: 1.469447. Batch_acc: 0.469723. Batch_loss: 1.450959 \n",
      "Batch: 2879. Acc: 0.471775. Loss: 1.469446. Batch_acc: 0.465241. Batch_loss: 1.467902 \n",
      "Batch: 2880. Acc: 0.471777. Loss: 1.469438. Batch_acc: 0.476581. Batch_loss: 1.446653 \n",
      "Batch: 2881. Acc: 0.471789. Loss: 1.469405. Batch_acc: 0.506443. Batch_loss: 1.374793 \n",
      "Batch: 2882. Acc: 0.471794. Loss: 1.469401. Batch_acc: 0.484348. Batch_loss: 1.460471 \n",
      "Batch: 2883. Acc: 0.471794. Loss: 1.469397. Batch_acc: 0.473441. Batch_loss: 1.456806 \n",
      "Batch: 2884. Acc: 0.471808. Loss: 1.469362. Batch_acc: 0.511061. Batch_loss: 1.369351 \n",
      "Batch: 2885. Acc: 0.471811. Loss: 1.469361. Batch_acc: 0.479372. Batch_loss: 1.465537 \n",
      "Batch: 2886. Acc: 0.471813. Loss: 1.469351. Batch_acc: 0.479314. Batch_loss: 1.441759 \n",
      "Batch: 2887. Acc: 0.471813. Loss: 1.469346. Batch_acc: 0.473088. Batch_loss: 1.454935 \n",
      "Batch: 2888. Acc: 0.471816. Loss: 1.469330. Batch_acc: 0.479977. Batch_loss: 1.424018 \n",
      "Batch: 2889. Acc: 0.471823. Loss: 1.469308. Batch_acc: 0.489937. Batch_loss: 1.404737 \n",
      "Batch: 2890. Acc: 0.471832. Loss: 1.469276. Batch_acc: 0.497966. Batch_loss: 1.376195 \n",
      "Batch: 2891. Acc: 0.471842. Loss: 1.469255. Batch_acc: 0.503525. Batch_loss: 1.406978 \n",
      "Batch: 2892. Acc: 0.471850. Loss: 1.469237. Batch_acc: 0.495343. Batch_loss: 1.414955 \n",
      "Batch: 2893. Acc: 0.471855. Loss: 1.469218. Batch_acc: 0.487240. Batch_loss: 1.413508 \n",
      "Batch: 2894. Acc: 0.471860. Loss: 1.469214. Batch_acc: 0.485915. Batch_loss: 1.456312 \n",
      "Batch: 2895. Acc: 0.471866. Loss: 1.469199. Batch_acc: 0.488558. Batch_loss: 1.427852 \n",
      "Batch: 2896. Acc: 0.471868. Loss: 1.469192. Batch_acc: 0.476603. Batch_loss: 1.449187 \n",
      "Batch: 2897. Acc: 0.471869. Loss: 1.469191. Batch_acc: 0.475219. Batch_loss: 1.464636 \n",
      "Batch: 2898. Acc: 0.471876. Loss: 1.469156. Batch_acc: 0.492697. Batch_loss: 1.370747 \n",
      "Batch: 2899. Acc: 0.471882. Loss: 1.469143. Batch_acc: 0.488810. Batch_loss: 1.431038 \n",
      "Batch: 2900. Acc: 0.471885. Loss: 1.469134. Batch_acc: 0.480278. Batch_loss: 1.442929 \n",
      "Batch: 2901. Acc: 0.471887. Loss: 1.469138. Batch_acc: 0.477286. Batch_loss: 1.480056 \n",
      "Batch: 2902. Acc: 0.471885. Loss: 1.469139. Batch_acc: 0.467963. Batch_loss: 1.473595 \n",
      "Batch: 2903. Acc: 0.471891. Loss: 1.469112. Batch_acc: 0.488082. Batch_loss: 1.391214 \n",
      "Batch: 2904. Acc: 0.471901. Loss: 1.469095. Batch_acc: 0.500575. Batch_loss: 1.418862 \n",
      "Batch: 2905. Acc: 0.471914. Loss: 1.469058. Batch_acc: 0.510006. Batch_loss: 1.363051 \n",
      "Batch: 2906. Acc: 0.471920. Loss: 1.469036. Batch_acc: 0.489447. Batch_loss: 1.404643 \n",
      "Batch: 2907. Acc: 0.471927. Loss: 1.469021. Batch_acc: 0.490641. Batch_loss: 1.425597 \n",
      "Batch: 2908. Acc: 0.471934. Loss: 1.468999. Batch_acc: 0.494253. Batch_loss: 1.404769 \n",
      "Batch: 2909. Acc: 0.471947. Loss: 1.468973. Batch_acc: 0.510725. Batch_loss: 1.392428 \n",
      "Batch: 2910. Acc: 0.471955. Loss: 1.468943. Batch_acc: 0.494828. Batch_loss: 1.383788 \n",
      "Batch: 2911. Acc: 0.471969. Loss: 1.468898. Batch_acc: 0.512321. Batch_loss: 1.336939 \n",
      "Batch: 2912. Acc: 0.471971. Loss: 1.468890. Batch_acc: 0.478137. Batch_loss: 1.446061 \n",
      "Batch: 2913. Acc: 0.471972. Loss: 1.468878. Batch_acc: 0.475087. Batch_loss: 1.434091 \n",
      "Batch: 2914. Acc: 0.471977. Loss: 1.468856. Batch_acc: 0.483653. Batch_loss: 1.405695 \n",
      "Batch: 2915. Acc: 0.471978. Loss: 1.468854. Batch_acc: 0.477364. Batch_loss: 1.464916 \n",
      "Batch: 2916. Acc: 0.471974. Loss: 1.468862. Batch_acc: 0.457177. Batch_loss: 1.491522 \n",
      "Batch: 2917. Acc: 0.471975. Loss: 1.468858. Batch_acc: 0.474971. Batch_loss: 1.456905 \n",
      "Batch: 2918. Acc: 0.471976. Loss: 1.468849. Batch_acc: 0.475391. Batch_loss: 1.444283 \n",
      "Batch: 2919. Acc: 0.471987. Loss: 1.468811. Batch_acc: 0.504225. Batch_loss: 1.359308 \n",
      "Batch: 2920. Acc: 0.471995. Loss: 1.468791. Batch_acc: 0.494376. Batch_loss: 1.410562 \n",
      "Batch: 2921. Acc: 0.472001. Loss: 1.468776. Batch_acc: 0.489694. Batch_loss: 1.427750 \n",
      "Batch: 2922. Acc: 0.472009. Loss: 1.468758. Batch_acc: 0.494804. Batch_loss: 1.416593 \n",
      "Batch: 2923. Acc: 0.472015. Loss: 1.468741. Batch_acc: 0.489130. Batch_loss: 1.417242 \n",
      "Batch: 2924. Acc: 0.472028. Loss: 1.468714. Batch_acc: 0.510369. Batch_loss: 1.389384 \n",
      "Batch: 2925. Acc: 0.472031. Loss: 1.468717. Batch_acc: 0.480473. Batch_loss: 1.479574 \n",
      "Batch: 2926. Acc: 0.472037. Loss: 1.468699. Batch_acc: 0.491168. Batch_loss: 1.416003 \n",
      "Batch: 2927. Acc: 0.472046. Loss: 1.468677. Batch_acc: 0.499415. Batch_loss: 1.403121 \n",
      "Batch: 2928. Acc: 0.472062. Loss: 1.468636. Batch_acc: 0.516590. Batch_loss: 1.348192 \n",
      "Batch: 2929. Acc: 0.472063. Loss: 1.468639. Batch_acc: 0.474800. Batch_loss: 1.477633 \n",
      "Batch: 2930. Acc: 0.472062. Loss: 1.468643. Batch_acc: 0.470930. Batch_loss: 1.482062 \n",
      "Batch: 2931. Acc: 0.472071. Loss: 1.468622. Batch_acc: 0.499119. Batch_loss: 1.405762 \n",
      "Batch: 2932. Acc: 0.472076. Loss: 1.468620. Batch_acc: 0.485235. Batch_loss: 1.461854 \n",
      "Batch: 2933. Acc: 0.472085. Loss: 1.468590. Batch_acc: 0.499134. Batch_loss: 1.381303 \n",
      "Batch: 2934. Acc: 0.472085. Loss: 1.468587. Batch_acc: 0.472141. Batch_loss: 1.459966 \n",
      "Batch: 2935. Acc: 0.472086. Loss: 1.468580. Batch_acc: 0.474008. Batch_loss: 1.446809 \n",
      "Batch: 2936. Acc: 0.472091. Loss: 1.468563. Batch_acc: 0.487047. Batch_loss: 1.418443 \n",
      "Batch: 2937. Acc: 0.472102. Loss: 1.468538. Batch_acc: 0.506682. Batch_loss: 1.395577 \n",
      "Batch: 2938. Acc: 0.472106. Loss: 1.468530. Batch_acc: 0.481503. Batch_loss: 1.445501 \n",
      "Batch: 2939. Acc: 0.472110. Loss: 1.468516. Batch_acc: 0.485109. Batch_loss: 1.427876 \n",
      "Batch: 2940. Acc: 0.472113. Loss: 1.468504. Batch_acc: 0.480283. Batch_loss: 1.430796 \n",
      "Batch: 2941. Acc: 0.472124. Loss: 1.468474. Batch_acc: 0.504582. Batch_loss: 1.381890 \n",
      "Batch: 2942. Acc: 0.472131. Loss: 1.468453. Batch_acc: 0.491248. Batch_loss: 1.405961 \n",
      "Batch: 2943. Acc: 0.472140. Loss: 1.468441. Batch_acc: 0.499714. Batch_loss: 1.433252 \n",
      "Batch: 2944. Acc: 0.472139. Loss: 1.468445. Batch_acc: 0.468990. Batch_loss: 1.481927 \n",
      "Batch: 2945. Acc: 0.472148. Loss: 1.468426. Batch_acc: 0.498556. Batch_loss: 1.410659 \n",
      "Batch: 2946. Acc: 0.472153. Loss: 1.468408. Batch_acc: 0.488545. Batch_loss: 1.417735 \n",
      "Batch: 2947. Acc: 0.472163. Loss: 1.468380. Batch_acc: 0.500000. Batch_loss: 1.388490 \n",
      "Batch: 2948. Acc: 0.472167. Loss: 1.468384. Batch_acc: 0.481977. Batch_loss: 1.479864 \n",
      "Batch: 2949. Acc: 0.472170. Loss: 1.468369. Batch_acc: 0.483382. Batch_loss: 1.422476 \n",
      "Batch: 2950. Acc: 0.472182. Loss: 1.468346. Batch_acc: 0.507585. Batch_loss: 1.398894 \n",
      "Batch: 2951. Acc: 0.472185. Loss: 1.468337. Batch_acc: 0.480163. Batch_loss: 1.443845 \n",
      "Batch: 2952. Acc: 0.472194. Loss: 1.468312. Batch_acc: 0.499148. Batch_loss: 1.395319 \n",
      "Batch: 2953. Acc: 0.472189. Loss: 1.468322. Batch_acc: 0.456546. Batch_loss: 1.497697 \n",
      "Batch: 2954. Acc: 0.472192. Loss: 1.468321. Batch_acc: 0.482295. Batch_loss: 1.464814 \n",
      "Batch: 2955. Acc: 0.472203. Loss: 1.468306. Batch_acc: 0.506031. Batch_loss: 1.421831 \n",
      "Batch: 2956. Acc: 0.472211. Loss: 1.468280. Batch_acc: 0.496536. Batch_loss: 1.391814 \n",
      "Batch: 2957. Acc: 0.472217. Loss: 1.468270. Batch_acc: 0.487948. Batch_loss: 1.437625 \n",
      "Batch: 2958. Acc: 0.472224. Loss: 1.468243. Batch_acc: 0.493664. Batch_loss: 1.387972 \n",
      "Batch: 2959. Acc: 0.472227. Loss: 1.468229. Batch_acc: 0.482985. Batch_loss: 1.428064 \n",
      "Batch: 2960. Acc: 0.472226. Loss: 1.468237. Batch_acc: 0.468479. Batch_loss: 1.490004 \n",
      "Batch: 2961. Acc: 0.472228. Loss: 1.468230. Batch_acc: 0.479118. Batch_loss: 1.447460 \n",
      "Batch: 2962. Acc: 0.472241. Loss: 1.468201. Batch_acc: 0.508160. Batch_loss: 1.383227 \n",
      "Batch: 2963. Acc: 0.472252. Loss: 1.468179. Batch_acc: 0.505974. Batch_loss: 1.400631 \n",
      "Batch: 2964. Acc: 0.472253. Loss: 1.468172. Batch_acc: 0.476048. Batch_loss: 1.449177 \n",
      "Batch: 2965. Acc: 0.472254. Loss: 1.468163. Batch_acc: 0.475766. Batch_loss: 1.439839 \n",
      "Batch: 2966. Acc: 0.472260. Loss: 1.468143. Batch_acc: 0.487915. Batch_loss: 1.410496 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2967. Acc: 0.472259. Loss: 1.468140. Batch_acc: 0.470252. Batch_loss: 1.461320 \n",
      "Batch: 2968. Acc: 0.472260. Loss: 1.468134. Batch_acc: 0.475533. Batch_loss: 1.448680 \n",
      "Batch: 2969. Acc: 0.472263. Loss: 1.468110. Batch_acc: 0.481630. Batch_loss: 1.396504 \n",
      "Batch: 2970. Acc: 0.472272. Loss: 1.468083. Batch_acc: 0.496830. Batch_loss: 1.389251 \n",
      "Batch: 2971. Acc: 0.472281. Loss: 1.468061. Batch_acc: 0.500292. Batch_loss: 1.400587 \n",
      "Batch: 2972. Acc: 0.472281. Loss: 1.468048. Batch_acc: 0.471478. Batch_loss: 1.430870 \n",
      "Batch: 2973. Acc: 0.472286. Loss: 1.468032. Batch_acc: 0.486961. Batch_loss: 1.418675 \n",
      "Batch: 2974. Acc: 0.472292. Loss: 1.468009. Batch_acc: 0.490773. Batch_loss: 1.400987 \n",
      "Batch: 2975. Acc: 0.472291. Loss: 1.468009. Batch_acc: 0.470757. Batch_loss: 1.466724 \n",
      "Batch: 2976. Acc: 0.472305. Loss: 1.467977. Batch_acc: 0.511472. Batch_loss: 1.375606 \n",
      "Batch: 2977. Acc: 0.472303. Loss: 1.467979. Batch_acc: 0.466244. Batch_loss: 1.473580 \n",
      "Batch: 2978. Acc: 0.472311. Loss: 1.467953. Batch_acc: 0.498270. Batch_loss: 1.392813 \n",
      "Batch: 2979. Acc: 0.472316. Loss: 1.467940. Batch_acc: 0.485431. Batch_loss: 1.427636 \n",
      "Batch: 2980. Acc: 0.472329. Loss: 1.467906. Batch_acc: 0.513279. Batch_loss: 1.365089 \n",
      "Batch: 2981. Acc: 0.472340. Loss: 1.467878. Batch_acc: 0.503174. Batch_loss: 1.384218 \n",
      "Batch: 2982. Acc: 0.472345. Loss: 1.467859. Batch_acc: 0.488027. Batch_loss: 1.411850 \n",
      "Batch: 2983. Acc: 0.472356. Loss: 1.467834. Batch_acc: 0.502515. Batch_loss: 1.397476 \n",
      "Batch: 2984. Acc: 0.472357. Loss: 1.467824. Batch_acc: 0.477169. Batch_loss: 1.437318 \n",
      "Batch: 2985. Acc: 0.472355. Loss: 1.467832. Batch_acc: 0.466212. Batch_loss: 1.489855 \n",
      "Batch: 2986. Acc: 0.472362. Loss: 1.467814. Batch_acc: 0.492343. Batch_loss: 1.414794 \n",
      "Batch: 2987. Acc: 0.472379. Loss: 1.467770. Batch_acc: 0.522507. Batch_loss: 1.337848 \n",
      "Batch: 2988. Acc: 0.472395. Loss: 1.467736. Batch_acc: 0.518916. Batch_loss: 1.368578 \n",
      "Batch: 2989. Acc: 0.472399. Loss: 1.467727. Batch_acc: 0.486548. Batch_loss: 1.441266 \n",
      "Batch: 2990. Acc: 0.472400. Loss: 1.467726. Batch_acc: 0.473743. Batch_loss: 1.464361 \n",
      "Batch: 2991. Acc: 0.472415. Loss: 1.467690. Batch_acc: 0.516841. Batch_loss: 1.359857 \n",
      "Batch: 2992. Acc: 0.472420. Loss: 1.467672. Batch_acc: 0.487507. Batch_loss: 1.411615 \n",
      "Batch: 2993. Acc: 0.472421. Loss: 1.467679. Batch_acc: 0.475312. Batch_loss: 1.492095 \n",
      "Batch: 2994. Acc: 0.472414. Loss: 1.467698. Batch_acc: 0.454648. Batch_loss: 1.520926 \n",
      "Batch: 2995. Acc: 0.472419. Loss: 1.467682. Batch_acc: 0.485923. Batch_loss: 1.422989 \n",
      "Batch: 2996. Acc: 0.472420. Loss: 1.467688. Batch_acc: 0.474897. Batch_loss: 1.486053 \n",
      "Batch: 2997. Acc: 0.472433. Loss: 1.467652. Batch_acc: 0.512938. Batch_loss: 1.359778 \n",
      "Batch: 2998. Acc: 0.472437. Loss: 1.467644. Batch_acc: 0.483555. Batch_loss: 1.443261 \n",
      "Batch: 2999. Acc: 0.472436. Loss: 1.467643. Batch_acc: 0.469314. Batch_loss: 1.463873 \n",
      "Batch: 3000. Acc: 0.472441. Loss: 1.467627. Batch_acc: 0.486228. Batch_loss: 1.420434 \n",
      "Batch: 3001. Acc: 0.472444. Loss: 1.467616. Batch_acc: 0.482981. Batch_loss: 1.433552 \n",
      "Batch: 3002. Acc: 0.472447. Loss: 1.467620. Batch_acc: 0.481243. Batch_loss: 1.481132 \n",
      "Batch: 3003. Acc: 0.472453. Loss: 1.467601. Batch_acc: 0.489005. Batch_loss: 1.408670 \n",
      "Batch: 3004. Acc: 0.472462. Loss: 1.467597. Batch_acc: 0.501431. Batch_loss: 1.456741 \n",
      "Batch: 3005. Acc: 0.472473. Loss: 1.467564. Batch_acc: 0.505501. Batch_loss: 1.367631 \n",
      "Batch: 3006. Acc: 0.472483. Loss: 1.467539. Batch_acc: 0.501127. Batch_loss: 1.394451 \n",
      "Batch: 3007. Acc: 0.472493. Loss: 1.467517. Batch_acc: 0.503356. Batch_loss: 1.403863 \n",
      "Batch: 3008. Acc: 0.472503. Loss: 1.467497. Batch_acc: 0.500869. Batch_loss: 1.404985 \n",
      "Batch: 3009. Acc: 0.472501. Loss: 1.467492. Batch_acc: 0.468273. Batch_loss: 1.453072 \n",
      "Batch: 3010. Acc: 0.472510. Loss: 1.467473. Batch_acc: 0.498866. Batch_loss: 1.410110 \n",
      "Batch: 3011. Acc: 0.472514. Loss: 1.467457. Batch_acc: 0.485207. Batch_loss: 1.419486 \n",
      "Batch: 3012. Acc: 0.472520. Loss: 1.467446. Batch_acc: 0.487571. Batch_loss: 1.433860 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.47251954774782756. Loss per char: 1.4674459129705795. Time: 1627216491.6047692\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 20, 24, 18, 23,\n",
      "        21,  1, 66, 79, 69,  1, 14, 23, 23, 17, 19, 26, 21, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.472512. Loss: 1.467465. Batch_acc: 0.449887. Batch_loss: 1.524396 \n",
      "Batch: 3014. Acc: 0.472520. Loss: 1.467444. Batch_acc: 0.495418. Batch_loss: 1.402942 \n",
      "Batch: 3015. Acc: 0.472519. Loss: 1.467449. Batch_acc: 0.471976. Batch_loss: 1.484610 \n",
      "Batch: 3016. Acc: 0.472515. Loss: 1.467451. Batch_acc: 0.458309. Batch_loss: 1.473027 \n",
      "Batch: 3017. Acc: 0.472514. Loss: 1.467444. Batch_acc: 0.472061. Batch_loss: 1.445825 \n",
      "Batch: 3018. Acc: 0.472515. Loss: 1.467443. Batch_acc: 0.474695. Batch_loss: 1.464263 \n",
      "Batch: 3019. Acc: 0.472523. Loss: 1.467411. Batch_acc: 0.496050. Batch_loss: 1.372263 \n",
      "Batch: 3020. Acc: 0.472529. Loss: 1.467395. Batch_acc: 0.490523. Batch_loss: 1.420416 \n",
      "Batch: 3021. Acc: 0.472535. Loss: 1.467376. Batch_acc: 0.491545. Batch_loss: 1.407769 \n",
      "Batch: 3022. Acc: 0.472534. Loss: 1.467375. Batch_acc: 0.468000. Batch_loss: 1.464688 \n",
      "Batch: 3023. Acc: 0.472546. Loss: 1.467352. Batch_acc: 0.511450. Batch_loss: 1.395361 \n",
      "Batch: 3024. Acc: 0.472536. Loss: 1.467380. Batch_acc: 0.441750. Batch_loss: 1.555778 \n",
      "Batch: 3025. Acc: 0.472540. Loss: 1.467374. Batch_acc: 0.483440. Batch_loss: 1.449172 \n",
      "Batch: 3026. Acc: 0.472548. Loss: 1.467356. Batch_acc: 0.496183. Batch_loss: 1.411008 \n",
      "Batch: 3027. Acc: 0.472558. Loss: 1.467329. Batch_acc: 0.502304. Batch_loss: 1.385357 \n",
      "Batch: 3028. Acc: 0.472557. Loss: 1.467324. Batch_acc: 0.471319. Batch_loss: 1.452852 \n",
      "Batch: 3029. Acc: 0.472562. Loss: 1.467315. Batch_acc: 0.487917. Batch_loss: 1.440476 \n",
      "Batch: 3030. Acc: 0.472570. Loss: 1.467290. Batch_acc: 0.494678. Batch_loss: 1.393618 \n",
      "Batch: 3031. Acc: 0.472577. Loss: 1.467278. Batch_acc: 0.493402. Batch_loss: 1.430756 \n",
      "Batch: 3032. Acc: 0.472586. Loss: 1.467244. Batch_acc: 0.502020. Batch_loss: 1.364249 \n",
      "Batch: 3033. Acc: 0.472599. Loss: 1.467213. Batch_acc: 0.510590. Batch_loss: 1.371546 \n",
      "Batch: 3034. Acc: 0.472600. Loss: 1.467198. Batch_acc: 0.476941. Batch_loss: 1.421397 \n",
      "Batch: 3035. Acc: 0.472610. Loss: 1.467176. Batch_acc: 0.501720. Batch_loss: 1.401209 \n",
      "Batch: 3036. Acc: 0.472621. Loss: 1.467141. Batch_acc: 0.506696. Batch_loss: 1.362935 \n",
      "Batch: 3037. Acc: 0.472627. Loss: 1.467121. Batch_acc: 0.490107. Batch_loss: 1.408154 \n",
      "Batch: 3038. Acc: 0.472639. Loss: 1.467093. Batch_acc: 0.506530. Batch_loss: 1.384057 \n",
      "Batch: 3039. Acc: 0.472646. Loss: 1.467064. Batch_acc: 0.496254. Batch_loss: 1.377588 \n",
      "Batch: 3040. Acc: 0.472656. Loss: 1.467046. Batch_acc: 0.500843. Batch_loss: 1.413715 \n",
      "Batch: 3041. Acc: 0.472654. Loss: 1.467040. Batch_acc: 0.467685. Batch_loss: 1.449483 \n",
      "Batch: 3042. Acc: 0.472655. Loss: 1.467036. Batch_acc: 0.475073. Batch_loss: 1.453712 \n",
      "Batch: 3043. Acc: 0.472661. Loss: 1.467020. Batch_acc: 0.491803. Batch_loss: 1.419360 \n",
      "Batch: 3044. Acc: 0.472669. Loss: 1.466991. Batch_acc: 0.495190. Batch_loss: 1.380932 \n",
      "Batch: 3045. Acc: 0.472684. Loss: 1.466957. Batch_acc: 0.518018. Batch_loss: 1.365243 \n",
      "Batch: 3046. Acc: 0.472694. Loss: 1.466933. Batch_acc: 0.500853. Batch_loss: 1.395754 \n",
      "Batch: 3047. Acc: 0.472698. Loss: 1.466924. Batch_acc: 0.485075. Batch_loss: 1.438549 \n",
      "Batch: 3048. Acc: 0.472703. Loss: 1.466905. Batch_acc: 0.489495. Batch_loss: 1.408400 \n",
      "Batch: 3049. Acc: 0.472703. Loss: 1.466907. Batch_acc: 0.472432. Batch_loss: 1.475139 \n",
      "Batch: 3050. Acc: 0.472708. Loss: 1.466883. Batch_acc: 0.486239. Batch_loss: 1.391631 \n",
      "Batch: 3051. Acc: 0.472700. Loss: 1.466895. Batch_acc: 0.449525. Batch_loss: 1.506726 \n",
      "Batch: 3052. Acc: 0.472696. Loss: 1.466906. Batch_acc: 0.458333. Batch_loss: 1.500572 \n",
      "Batch: 3053. Acc: 0.472700. Loss: 1.466883. Batch_acc: 0.487135. Batch_loss: 1.396539 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3054. Acc: 0.472711. Loss: 1.466861. Batch_acc: 0.505585. Batch_loss: 1.396912 \n",
      "Batch: 3055. Acc: 0.472721. Loss: 1.466826. Batch_acc: 0.503409. Batch_loss: 1.360896 \n",
      "Batch: 3056. Acc: 0.472724. Loss: 1.466820. Batch_acc: 0.481739. Batch_loss: 1.449035 \n",
      "Batch: 3057. Acc: 0.472727. Loss: 1.466810. Batch_acc: 0.483948. Batch_loss: 1.435268 \n",
      "Batch: 3058. Acc: 0.472739. Loss: 1.466788. Batch_acc: 0.507255. Batch_loss: 1.399001 \n",
      "Batch: 3059. Acc: 0.472741. Loss: 1.466782. Batch_acc: 0.479081. Batch_loss: 1.446479 \n",
      "Batch: 3060. Acc: 0.472746. Loss: 1.466760. Batch_acc: 0.488761. Batch_loss: 1.399308 \n",
      "Batch: 3061. Acc: 0.472756. Loss: 1.466728. Batch_acc: 0.505275. Batch_loss: 1.367381 \n",
      "Batch: 3062. Acc: 0.472759. Loss: 1.466724. Batch_acc: 0.480916. Batch_loss: 1.456405 \n",
      "Batch: 3063. Acc: 0.472768. Loss: 1.466699. Batch_acc: 0.501748. Batch_loss: 1.386888 \n",
      "Batch: 3064. Acc: 0.472769. Loss: 1.466694. Batch_acc: 0.474926. Batch_loss: 1.450562 \n",
      "Batch: 3065. Acc: 0.472771. Loss: 1.466689. Batch_acc: 0.478210. Batch_loss: 1.451953 \n",
      "Batch: 3066. Acc: 0.472777. Loss: 1.466676. Batch_acc: 0.493205. Batch_loss: 1.429476 \n",
      "Batch: 3067. Acc: 0.472788. Loss: 1.466652. Batch_acc: 0.505708. Batch_loss: 1.392098 \n",
      "Batch: 3068. Acc: 0.472792. Loss: 1.466647. Batch_acc: 0.484779. Batch_loss: 1.450267 \n",
      "Batch: 3069. Acc: 0.472804. Loss: 1.466617. Batch_acc: 0.508552. Batch_loss: 1.377861 \n",
      "Batch: 3070. Acc: 0.472815. Loss: 1.466595. Batch_acc: 0.504805. Batch_loss: 1.399336 \n",
      "Batch: 3071. Acc: 0.472824. Loss: 1.466571. Batch_acc: 0.502003. Batch_loss: 1.394214 \n",
      "Batch: 3072. Acc: 0.472828. Loss: 1.466561. Batch_acc: 0.484447. Batch_loss: 1.434973 \n",
      "Batch: 3073. Acc: 0.472834. Loss: 1.466549. Batch_acc: 0.490643. Batch_loss: 1.428156 \n",
      "Batch: 3074. Acc: 0.472839. Loss: 1.466539. Batch_acc: 0.487846. Batch_loss: 1.437570 \n",
      "Batch: 3075. Acc: 0.472840. Loss: 1.466534. Batch_acc: 0.477612. Batch_loss: 1.448830 \n",
      "Batch: 3076. Acc: 0.472847. Loss: 1.466519. Batch_acc: 0.493247. Batch_loss: 1.420026 \n",
      "Batch: 3077. Acc: 0.472850. Loss: 1.466511. Batch_acc: 0.482639. Batch_loss: 1.441969 \n",
      "Batch: 3078. Acc: 0.472858. Loss: 1.466490. Batch_acc: 0.498870. Batch_loss: 1.404783 \n",
      "Batch: 3079. Acc: 0.472866. Loss: 1.466463. Batch_acc: 0.495944. Batch_loss: 1.381307 \n",
      "Batch: 3080. Acc: 0.472892. Loss: 1.466396. Batch_acc: 0.551043. Batch_loss: 1.263192 \n",
      "Batch: 3081. Acc: 0.472895. Loss: 1.466385. Batch_acc: 0.484174. Batch_loss: 1.432086 \n",
      "Batch: 3082. Acc: 0.472891. Loss: 1.466392. Batch_acc: 0.459816. Batch_loss: 1.488571 \n",
      "Batch: 3083. Acc: 0.472900. Loss: 1.466369. Batch_acc: 0.501143. Batch_loss: 1.397177 \n",
      "Batch: 3084. Acc: 0.472907. Loss: 1.466342. Batch_acc: 0.494037. Batch_loss: 1.382123 \n",
      "Batch: 3085. Acc: 0.472912. Loss: 1.466321. Batch_acc: 0.486701. Batch_loss: 1.402085 \n",
      "Batch: 3086. Acc: 0.472924. Loss: 1.466292. Batch_acc: 0.509884. Batch_loss: 1.378819 \n",
      "Batch: 3087. Acc: 0.472930. Loss: 1.466269. Batch_acc: 0.493158. Batch_loss: 1.395449 \n",
      "Batch: 3088. Acc: 0.472940. Loss: 1.466245. Batch_acc: 0.504968. Batch_loss: 1.391535 \n",
      "Batch: 3089. Acc: 0.472943. Loss: 1.466238. Batch_acc: 0.481739. Batch_loss: 1.442659 \n",
      "Batch: 3090. Acc: 0.472945. Loss: 1.466227. Batch_acc: 0.479420. Batch_loss: 1.432094 \n",
      "Batch: 3091. Acc: 0.472947. Loss: 1.466227. Batch_acc: 0.477525. Batch_loss: 1.465895 \n",
      "Batch: 3092. Acc: 0.472946. Loss: 1.466222. Batch_acc: 0.471225. Batch_loss: 1.450949 \n",
      "Batch: 3093. Acc: 0.472954. Loss: 1.466198. Batch_acc: 0.495972. Batch_loss: 1.392098 \n",
      "Batch: 3094. Acc: 0.472956. Loss: 1.466189. Batch_acc: 0.481460. Batch_loss: 1.438234 \n",
      "Batch: 3095. Acc: 0.472957. Loss: 1.466180. Batch_acc: 0.475561. Batch_loss: 1.438150 \n",
      "Batch: 3096. Acc: 0.472964. Loss: 1.466169. Batch_acc: 0.494505. Batch_loss: 1.431345 \n",
      "Batch: 3097. Acc: 0.472972. Loss: 1.466149. Batch_acc: 0.496793. Batch_loss: 1.406124 \n",
      "Batch: 3098. Acc: 0.472980. Loss: 1.466128. Batch_acc: 0.499427. Batch_loss: 1.398692 \n",
      "Batch: 3099. Acc: 0.472987. Loss: 1.466097. Batch_acc: 0.493550. Batch_loss: 1.375026 \n",
      "Batch: 3100. Acc: 0.472995. Loss: 1.466073. Batch_acc: 0.497655. Batch_loss: 1.388627 \n",
      "Batch: 3101. Acc: 0.472999. Loss: 1.466064. Batch_acc: 0.485582. Batch_loss: 1.438401 \n",
      "Batch: 3102. Acc: 0.472999. Loss: 1.466065. Batch_acc: 0.473474. Batch_loss: 1.468222 \n",
      "Batch: 3103. Acc: 0.473005. Loss: 1.466048. Batch_acc: 0.491468. Batch_loss: 1.415312 \n",
      "Batch: 3104. Acc: 0.473018. Loss: 1.466021. Batch_acc: 0.511964. Batch_loss: 1.383881 \n",
      "Batch: 3105. Acc: 0.473029. Loss: 1.465992. Batch_acc: 0.505734. Batch_loss: 1.377993 \n",
      "Batch: 3106. Acc: 0.473025. Loss: 1.465990. Batch_acc: 0.462585. Batch_loss: 1.459159 \n",
      "Batch: 3107. Acc: 0.473030. Loss: 1.465972. Batch_acc: 0.489614. Batch_loss: 1.407971 \n",
      "Batch: 3108. Acc: 0.473037. Loss: 1.465959. Batch_acc: 0.494266. Batch_loss: 1.426923 \n",
      "Batch: 3109. Acc: 0.473045. Loss: 1.465937. Batch_acc: 0.496045. Batch_loss: 1.396854 \n",
      "Batch: 3110. Acc: 0.473055. Loss: 1.465910. Batch_acc: 0.503937. Batch_loss: 1.383559 \n",
      "Batch: 3111. Acc: 0.473060. Loss: 1.465894. Batch_acc: 0.487637. Batch_loss: 1.416190 \n",
      "Batch: 3112. Acc: 0.473080. Loss: 1.465842. Batch_acc: 0.534415. Batch_loss: 1.309766 \n",
      "Batch: 3113. Acc: 0.473087. Loss: 1.465823. Batch_acc: 0.495741. Batch_loss: 1.407013 \n",
      "Batch: 3114. Acc: 0.473090. Loss: 1.465815. Batch_acc: 0.482861. Batch_loss: 1.439282 \n",
      "Batch: 3115. Acc: 0.473092. Loss: 1.465803. Batch_acc: 0.478711. Batch_loss: 1.428996 \n",
      "Batch: 3116. Acc: 0.473098. Loss: 1.465784. Batch_acc: 0.491238. Batch_loss: 1.409157 \n",
      "Batch: 3117. Acc: 0.473113. Loss: 1.465754. Batch_acc: 0.518177. Batch_loss: 1.370424 \n",
      "Batch: 3118. Acc: 0.473116. Loss: 1.465736. Batch_acc: 0.483372. Batch_loss: 1.408596 \n",
      "Batch: 3119. Acc: 0.473120. Loss: 1.465734. Batch_acc: 0.485616. Batch_loss: 1.460755 \n",
      "Batch: 3120. Acc: 0.473119. Loss: 1.465732. Batch_acc: 0.469636. Batch_loss: 1.460783 \n",
      "Batch: 3121. Acc: 0.473126. Loss: 1.465713. Batch_acc: 0.494562. Batch_loss: 1.406039 \n",
      "Batch: 3122. Acc: 0.473134. Loss: 1.465690. Batch_acc: 0.497213. Batch_loss: 1.396522 \n",
      "Batch: 3123. Acc: 0.473139. Loss: 1.465676. Batch_acc: 0.490185. Batch_loss: 1.419574 \n",
      "Batch: 3124. Acc: 0.473143. Loss: 1.465667. Batch_acc: 0.486166. Batch_loss: 1.439841 \n",
      "Batch: 3125. Acc: 0.473154. Loss: 1.465634. Batch_acc: 0.506229. Batch_loss: 1.363319 \n",
      "Batch: 3126. Acc: 0.473160. Loss: 1.465621. Batch_acc: 0.491545. Batch_loss: 1.426690 \n",
      "Batch: 3127. Acc: 0.473163. Loss: 1.465610. Batch_acc: 0.483946. Batch_loss: 1.428736 \n",
      "Batch: 3128. Acc: 0.473168. Loss: 1.465587. Batch_acc: 0.486056. Batch_loss: 1.394987 \n",
      "Batch: 3129. Acc: 0.473178. Loss: 1.465566. Batch_acc: 0.505469. Batch_loss: 1.401399 \n",
      "Batch: 3130. Acc: 0.473179. Loss: 1.465575. Batch_acc: 0.476474. Batch_loss: 1.494967 \n",
      "Batch: 3131. Acc: 0.473182. Loss: 1.465563. Batch_acc: 0.483324. Batch_loss: 1.425136 \n",
      "Batch: 3132. Acc: 0.473188. Loss: 1.465536. Batch_acc: 0.491035. Batch_loss: 1.382741 \n",
      "Batch: 3133. Acc: 0.473189. Loss: 1.465518. Batch_acc: 0.477233. Batch_loss: 1.406943 \n",
      "Batch: 3134. Acc: 0.473188. Loss: 1.465518. Batch_acc: 0.469715. Batch_loss: 1.465696 \n",
      "Batch: 3135. Acc: 0.473192. Loss: 1.465506. Batch_acc: 0.486842. Batch_loss: 1.429283 \n",
      "Batch: 3136. Acc: 0.473194. Loss: 1.465499. Batch_acc: 0.477075. Batch_loss: 1.442887 \n",
      "Batch: 3137. Acc: 0.473199. Loss: 1.465482. Batch_acc: 0.488751. Batch_loss: 1.412555 \n",
      "Batch: 3138. Acc: 0.473209. Loss: 1.465448. Batch_acc: 0.505073. Batch_loss: 1.362916 \n",
      "Batch: 3139. Acc: 0.473212. Loss: 1.465427. Batch_acc: 0.483890. Batch_loss: 1.398514 \n",
      "Batch: 3140. Acc: 0.473214. Loss: 1.465429. Batch_acc: 0.478723. Batch_loss: 1.472695 \n",
      "Batch: 3141. Acc: 0.473217. Loss: 1.465421. Batch_acc: 0.481760. Batch_loss: 1.440121 \n",
      "Batch: 3142. Acc: 0.473222. Loss: 1.465411. Batch_acc: 0.490523. Batch_loss: 1.433036 \n",
      "Batch: 3143. Acc: 0.473223. Loss: 1.465414. Batch_acc: 0.474250. Batch_loss: 1.473994 \n",
      "Batch: 3144. Acc: 0.473225. Loss: 1.465409. Batch_acc: 0.481311. Batch_loss: 1.449250 \n",
      "Batch: 3145. Acc: 0.473230. Loss: 1.465398. Batch_acc: 0.488584. Batch_loss: 1.431714 \n",
      "Batch: 3146. Acc: 0.473237. Loss: 1.465379. Batch_acc: 0.496005. Batch_loss: 1.407479 \n",
      "Batch: 3147. Acc: 0.473246. Loss: 1.465349. Batch_acc: 0.498584. Batch_loss: 1.371982 \n",
      "Batch: 3148. Acc: 0.473247. Loss: 1.465344. Batch_acc: 0.476985. Batch_loss: 1.448713 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3149. Acc: 0.473245. Loss: 1.465340. Batch_acc: 0.467571. Batch_loss: 1.453725 \n",
      "Batch: 3150. Acc: 0.473260. Loss: 1.465303. Batch_acc: 0.519711. Batch_loss: 1.351564 \n",
      "Batch: 3151. Acc: 0.473263. Loss: 1.465290. Batch_acc: 0.481633. Batch_loss: 1.423975 \n",
      "Batch: 3152. Acc: 0.473268. Loss: 1.465278. Batch_acc: 0.490708. Batch_loss: 1.427961 \n",
      "Batch: 3153. Acc: 0.473276. Loss: 1.465256. Batch_acc: 0.496880. Batch_loss: 1.395752 \n",
      "Batch: 3154. Acc: 0.473279. Loss: 1.465243. Batch_acc: 0.483206. Batch_loss: 1.422740 \n",
      "Batch: 3155. Acc: 0.473291. Loss: 1.465213. Batch_acc: 0.509359. Batch_loss: 1.372219 \n",
      "Batch: 3156. Acc: 0.473301. Loss: 1.465186. Batch_acc: 0.506293. Batch_loss: 1.380159 \n",
      "Batch: 3157. Acc: 0.473310. Loss: 1.465150. Batch_acc: 0.500280. Batch_loss: 1.355730 \n",
      "Batch: 3158. Acc: 0.473310. Loss: 1.465148. Batch_acc: 0.474048. Batch_loss: 1.457553 \n",
      "Batch: 3159. Acc: 0.473310. Loss: 1.465146. Batch_acc: 0.472142. Batch_loss: 1.460355 \n",
      "Batch: 3160. Acc: 0.473308. Loss: 1.465147. Batch_acc: 0.467170. Batch_loss: 1.467149 \n",
      "Batch: 3161. Acc: 0.473314. Loss: 1.465131. Batch_acc: 0.491188. Batch_loss: 1.416746 \n",
      "Batch: 3162. Acc: 0.473317. Loss: 1.465121. Batch_acc: 0.482623. Batch_loss: 1.431687 \n",
      "Batch: 3163. Acc: 0.473314. Loss: 1.465123. Batch_acc: 0.464531. Batch_loss: 1.472347 \n",
      "Batch: 3164. Acc: 0.473319. Loss: 1.465117. Batch_acc: 0.489188. Batch_loss: 1.446525 \n",
      "Batch: 3165. Acc: 0.473324. Loss: 1.465109. Batch_acc: 0.489118. Batch_loss: 1.440836 \n",
      "Batch: 3166. Acc: 0.473327. Loss: 1.465093. Batch_acc: 0.482353. Batch_loss: 1.411125 \n",
      "Batch: 3167. Acc: 0.473344. Loss: 1.465053. Batch_acc: 0.529002. Batch_loss: 1.339629 \n",
      "Batch: 3168. Acc: 0.473346. Loss: 1.465054. Batch_acc: 0.477987. Batch_loss: 1.467813 \n",
      "Batch: 3169. Acc: 0.473349. Loss: 1.465048. Batch_acc: 0.485682. Batch_loss: 1.445560 \n",
      "Batch: 3170. Acc: 0.473355. Loss: 1.465041. Batch_acc: 0.489671. Batch_loss: 1.443615 \n",
      "Batch: 3171. Acc: 0.473363. Loss: 1.465018. Batch_acc: 0.498551. Batch_loss: 1.391222 \n",
      "Batch: 3172. Acc: 0.473368. Loss: 1.465005. Batch_acc: 0.491945. Batch_loss: 1.422098 \n",
      "Batch: 3173. Acc: 0.473374. Loss: 1.464985. Batch_acc: 0.489667. Batch_loss: 1.403327 \n",
      "Batch: 3174. Acc: 0.473377. Loss: 1.464971. Batch_acc: 0.482659. Batch_loss: 1.419977 \n",
      "Batch: 3175. Acc: 0.473383. Loss: 1.464963. Batch_acc: 0.494991. Batch_loss: 1.438849 \n",
      "Batch: 3176. Acc: 0.473383. Loss: 1.464962. Batch_acc: 0.472000. Batch_loss: 1.462864 \n",
      "Batch: 3177. Acc: 0.473383. Loss: 1.464952. Batch_acc: 0.473623. Batch_loss: 1.432329 \n",
      "Batch: 3178. Acc: 0.473388. Loss: 1.464938. Batch_acc: 0.488439. Batch_loss: 1.420812 \n",
      "Batch: 3179. Acc: 0.473387. Loss: 1.464927. Batch_acc: 0.472385. Batch_loss: 1.429594 \n",
      "Batch: 3180. Acc: 0.473401. Loss: 1.464895. Batch_acc: 0.516074. Batch_loss: 1.365109 \n",
      "Batch: 3181. Acc: 0.473407. Loss: 1.464870. Batch_acc: 0.493750. Batch_loss: 1.385448 \n",
      "Batch: 3182. Acc: 0.473407. Loss: 1.464863. Batch_acc: 0.473504. Batch_loss: 1.441904 \n",
      "Batch: 3183. Acc: 0.473410. Loss: 1.464843. Batch_acc: 0.482619. Batch_loss: 1.399890 \n",
      "Batch: 3184. Acc: 0.473415. Loss: 1.464825. Batch_acc: 0.488493. Batch_loss: 1.409540 \n",
      "Batch: 3185. Acc: 0.473419. Loss: 1.464815. Batch_acc: 0.487776. Batch_loss: 1.431452 \n",
      "Batch: 3186. Acc: 0.473426. Loss: 1.464802. Batch_acc: 0.493425. Batch_loss: 1.424252 \n",
      "Batch: 3187. Acc: 0.473428. Loss: 1.464784. Batch_acc: 0.481460. Batch_loss: 1.407194 \n",
      "Batch: 3188. Acc: 0.473431. Loss: 1.464778. Batch_acc: 0.480769. Batch_loss: 1.446655 \n",
      "Batch: 3189. Acc: 0.473432. Loss: 1.464769. Batch_acc: 0.477568. Batch_loss: 1.433587 \n",
      "Batch: 3190. Acc: 0.473437. Loss: 1.464748. Batch_acc: 0.489136. Batch_loss: 1.399986 \n",
      "Batch: 3191. Acc: 0.473441. Loss: 1.464735. Batch_acc: 0.485420. Batch_loss: 1.423554 \n",
      "Batch: 3192. Acc: 0.473446. Loss: 1.464722. Batch_acc: 0.491269. Batch_loss: 1.424128 \n",
      "Batch: 3193. Acc: 0.473450. Loss: 1.464711. Batch_acc: 0.484450. Batch_loss: 1.426693 \n",
      "Batch: 3194. Acc: 0.473451. Loss: 1.464707. Batch_acc: 0.476949. Batch_loss: 1.452322 \n",
      "Batch: 3195. Acc: 0.473460. Loss: 1.464681. Batch_acc: 0.503145. Batch_loss: 1.384060 \n",
      "Batch: 3196. Acc: 0.473460. Loss: 1.464677. Batch_acc: 0.474203. Batch_loss: 1.450370 \n",
      "Batch: 3197. Acc: 0.473466. Loss: 1.464662. Batch_acc: 0.493231. Batch_loss: 1.413899 \n",
      "Batch: 3198. Acc: 0.473471. Loss: 1.464656. Batch_acc: 0.490373. Batch_loss: 1.447435 \n",
      "Batch: 3199. Acc: 0.473476. Loss: 1.464634. Batch_acc: 0.488590. Batch_loss: 1.390873 \n",
      "Batch: 3200. Acc: 0.473474. Loss: 1.464641. Batch_acc: 0.467385. Batch_loss: 1.488927 \n",
      "Batch: 3201. Acc: 0.473479. Loss: 1.464635. Batch_acc: 0.488263. Batch_loss: 1.443919 \n",
      "Batch: 3202. Acc: 0.473483. Loss: 1.464621. Batch_acc: 0.486827. Batch_loss: 1.418300 \n",
      "Batch: 3203. Acc: 0.473491. Loss: 1.464604. Batch_acc: 0.498559. Batch_loss: 1.410730 \n",
      "Batch: 3204. Acc: 0.473501. Loss: 1.464579. Batch_acc: 0.505997. Batch_loss: 1.385394 \n",
      "Batch: 3205. Acc: 0.473505. Loss: 1.464577. Batch_acc: 0.486348. Batch_loss: 1.457961 \n",
      "Batch: 3206. Acc: 0.473508. Loss: 1.464569. Batch_acc: 0.483592. Batch_loss: 1.440083 \n",
      "Batch: 3207. Acc: 0.473513. Loss: 1.464550. Batch_acc: 0.489937. Batch_loss: 1.403490 \n",
      "Batch: 3208. Acc: 0.473519. Loss: 1.464534. Batch_acc: 0.492537. Batch_loss: 1.413775 \n",
      "Batch: 3209. Acc: 0.473522. Loss: 1.464528. Batch_acc: 0.481566. Batch_loss: 1.444131 \n",
      "Batch: 3210. Acc: 0.473524. Loss: 1.464525. Batch_acc: 0.481588. Batch_loss: 1.455637 \n",
      "Batch: 3211. Acc: 0.473532. Loss: 1.464513. Batch_acc: 0.499711. Batch_loss: 1.427455 \n",
      "Batch: 3212. Acc: 0.473540. Loss: 1.464506. Batch_acc: 0.498297. Batch_loss: 1.439962 \n",
      "Batch: 3213. Acc: 0.473542. Loss: 1.464499. Batch_acc: 0.480660. Batch_loss: 1.441537 \n",
      "Batch: 3214. Acc: 0.473555. Loss: 1.464470. Batch_acc: 0.513605. Batch_loss: 1.374596 \n",
      "Batch: 3215. Acc: 0.473567. Loss: 1.464441. Batch_acc: 0.512209. Batch_loss: 1.368502 \n",
      "Batch: 3216. Acc: 0.473570. Loss: 1.464426. Batch_acc: 0.483191. Batch_loss: 1.418460 \n",
      "Batch: 3217. Acc: 0.473574. Loss: 1.464414. Batch_acc: 0.486902. Batch_loss: 1.424867 \n",
      "Batch: 3218. Acc: 0.473579. Loss: 1.464401. Batch_acc: 0.490070. Batch_loss: 1.422079 \n",
      "Batch: 3219. Acc: 0.473584. Loss: 1.464384. Batch_acc: 0.488398. Batch_loss: 1.411318 \n",
      "Batch: 3220. Acc: 0.473591. Loss: 1.464364. Batch_acc: 0.498280. Batch_loss: 1.399710 \n",
      "Batch: 3221. Acc: 0.473595. Loss: 1.464348. Batch_acc: 0.484204. Batch_loss: 1.412366 \n",
      "Batch: 3222. Acc: 0.473600. Loss: 1.464334. Batch_acc: 0.489577. Batch_loss: 1.419669 \n",
      "Batch: 3223. Acc: 0.473611. Loss: 1.464311. Batch_acc: 0.509926. Batch_loss: 1.392137 \n",
      "Batch: 3224. Acc: 0.473612. Loss: 1.464298. Batch_acc: 0.475700. Batch_loss: 1.422623 \n",
      "Batch: 3225. Acc: 0.473624. Loss: 1.464267. Batch_acc: 0.512195. Batch_loss: 1.363720 \n",
      "Batch: 3226. Acc: 0.473625. Loss: 1.464262. Batch_acc: 0.476247. Batch_loss: 1.446941 \n",
      "Batch: 3227. Acc: 0.473629. Loss: 1.464246. Batch_acc: 0.488812. Batch_loss: 1.414818 \n",
      "Batch: 3228. Acc: 0.473632. Loss: 1.464242. Batch_acc: 0.483159. Batch_loss: 1.450180 \n",
      "Batch: 3229. Acc: 0.473635. Loss: 1.464228. Batch_acc: 0.482799. Batch_loss: 1.417246 \n",
      "Batch: 3230. Acc: 0.473632. Loss: 1.464220. Batch_acc: 0.462910. Batch_loss: 1.438786 \n",
      "Batch: 3231. Acc: 0.473640. Loss: 1.464196. Batch_acc: 0.499711. Batch_loss: 1.386681 \n",
      "Batch: 3232. Acc: 0.473639. Loss: 1.464200. Batch_acc: 0.472333. Batch_loss: 1.475558 \n",
      "Batch: 3233. Acc: 0.473641. Loss: 1.464190. Batch_acc: 0.479604. Batch_loss: 1.432109 \n",
      "Batch: 3234. Acc: 0.473648. Loss: 1.464170. Batch_acc: 0.495697. Batch_loss: 1.400949 \n",
      "Batch: 3235. Acc: 0.473647. Loss: 1.464175. Batch_acc: 0.469376. Batch_loss: 1.480660 \n",
      "Batch: 3236. Acc: 0.473654. Loss: 1.464156. Batch_acc: 0.496712. Batch_loss: 1.401197 \n",
      "Batch: 3237. Acc: 0.473657. Loss: 1.464144. Batch_acc: 0.483324. Batch_loss: 1.424990 \n",
      "Batch: 3238. Acc: 0.473663. Loss: 1.464124. Batch_acc: 0.493197. Batch_loss: 1.400067 \n",
      "Batch: 3239. Acc: 0.473663. Loss: 1.464132. Batch_acc: 0.473144. Batch_loss: 1.489764 \n",
      "Batch: 3240. Acc: 0.473671. Loss: 1.464114. Batch_acc: 0.501441. Batch_loss: 1.408650 \n",
      "Batch: 3241. Acc: 0.473682. Loss: 1.464092. Batch_acc: 0.509565. Batch_loss: 1.390741 \n",
      "Batch: 3242. Acc: 0.473691. Loss: 1.464072. Batch_acc: 0.502043. Batch_loss: 1.399535 \n",
      "Batch: 3243. Acc: 0.473685. Loss: 1.464073. Batch_acc: 0.455280. Batch_loss: 1.467293 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3244. Acc: 0.473685. Loss: 1.464069. Batch_acc: 0.474457. Batch_loss: 1.448303 \n",
      "Batch: 3245. Acc: 0.473690. Loss: 1.464052. Batch_acc: 0.489712. Batch_loss: 1.407578 \n",
      "Batch: 3246. Acc: 0.473701. Loss: 1.464024. Batch_acc: 0.508741. Batch_loss: 1.372928 \n",
      "Batch: 3247. Acc: 0.473698. Loss: 1.464027. Batch_acc: 0.465290. Batch_loss: 1.475479 \n",
      "Batch: 3248. Acc: 0.473713. Loss: 1.463995. Batch_acc: 0.520091. Batch_loss: 1.361724 \n",
      "Batch: 3249. Acc: 0.473713. Loss: 1.463990. Batch_acc: 0.476002. Batch_loss: 1.446051 \n",
      "Batch: 3250. Acc: 0.473720. Loss: 1.463975. Batch_acc: 0.496245. Batch_loss: 1.416942 \n",
      "Batch: 3251. Acc: 0.473724. Loss: 1.463955. Batch_acc: 0.483907. Batch_loss: 1.398228 \n",
      "Batch: 3252. Acc: 0.473724. Loss: 1.463946. Batch_acc: 0.476603. Batch_loss: 1.434065 \n",
      "Batch: 3253. Acc: 0.473727. Loss: 1.463925. Batch_acc: 0.483592. Batch_loss: 1.397787 \n",
      "Batch: 3254. Acc: 0.473729. Loss: 1.463914. Batch_acc: 0.480519. Batch_loss: 1.425131 \n",
      "Batch: 3255. Acc: 0.473737. Loss: 1.463896. Batch_acc: 0.496587. Batch_loss: 1.408444 \n",
      "Batch: 3256. Acc: 0.473737. Loss: 1.463897. Batch_acc: 0.476218. Batch_loss: 1.466409 \n",
      "Batch: 3257. Acc: 0.473739. Loss: 1.463887. Batch_acc: 0.480602. Batch_loss: 1.431069 \n",
      "Batch: 3258. Acc: 0.473746. Loss: 1.463871. Batch_acc: 0.493969. Batch_loss: 1.410435 \n",
      "Batch: 3259. Acc: 0.473743. Loss: 1.463874. Batch_acc: 0.466589. Batch_loss: 1.475146 \n",
      "Batch: 3260. Acc: 0.473748. Loss: 1.463856. Batch_acc: 0.488603. Batch_loss: 1.403754 \n",
      "Batch: 3261. Acc: 0.473757. Loss: 1.463837. Batch_acc: 0.502024. Batch_loss: 1.402454 \n",
      "Batch: 3262. Acc: 0.473761. Loss: 1.463828. Batch_acc: 0.489229. Batch_loss: 1.434021 \n",
      "Batch: 3263. Acc: 0.473769. Loss: 1.463815. Batch_acc: 0.499714. Batch_loss: 1.421991 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.47376938079286646. Loss per char: 1.4638151208716945. Time: 1627216689.5196798\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 18, 25, 15, 19, 20,  1, 66, 79, 69,  1, 14, 18, 20,\n",
      "        20, 19, 19, 24, 15, 17, 19, 25, 26, 22, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.473767. Loss: 1.463820. Batch_acc: 0.466629. Batch_loss: 1.481081 \n",
      "Batch: 3265. Acc: 0.473770. Loss: 1.463818. Batch_acc: 0.482048. Batch_loss: 1.457037 \n",
      "Batch: 3266. Acc: 0.473773. Loss: 1.463809. Batch_acc: 0.486004. Batch_loss: 1.430353 \n",
      "Batch: 3267. Acc: 0.473778. Loss: 1.463799. Batch_acc: 0.489627. Batch_loss: 1.432808 \n",
      "Batch: 3268. Acc: 0.473781. Loss: 1.463795. Batch_acc: 0.482875. Batch_loss: 1.449204 \n",
      "Batch: 3269. Acc: 0.473782. Loss: 1.463780. Batch_acc: 0.476678. Batch_loss: 1.416750 \n",
      "Batch: 3270. Acc: 0.473789. Loss: 1.463758. Batch_acc: 0.498021. Batch_loss: 1.393154 \n",
      "Batch: 3271. Acc: 0.473787. Loss: 1.463763. Batch_acc: 0.464641. Batch_loss: 1.479609 \n",
      "Batch: 3272. Acc: 0.473788. Loss: 1.463752. Batch_acc: 0.477207. Batch_loss: 1.427503 \n",
      "Batch: 3273. Acc: 0.473798. Loss: 1.463727. Batch_acc: 0.508701. Batch_loss: 1.379837 \n",
      "Batch: 3274. Acc: 0.473803. Loss: 1.463712. Batch_acc: 0.491107. Batch_loss: 1.417475 \n",
      "Batch: 3275. Acc: 0.473808. Loss: 1.463703. Batch_acc: 0.487945. Batch_loss: 1.431622 \n",
      "Batch: 3276. Acc: 0.473818. Loss: 1.463674. Batch_acc: 0.507437. Batch_loss: 1.371775 \n",
      "Batch: 3277. Acc: 0.473820. Loss: 1.463667. Batch_acc: 0.481268. Batch_loss: 1.439551 \n",
      "Batch: 3278. Acc: 0.473824. Loss: 1.463653. Batch_acc: 0.485470. Batch_loss: 1.418278 \n",
      "Batch: 3279. Acc: 0.473828. Loss: 1.463637. Batch_acc: 0.486812. Batch_loss: 1.412906 \n",
      "Batch: 3280. Acc: 0.473835. Loss: 1.463627. Batch_acc: 0.495817. Batch_loss: 1.430807 \n",
      "Batch: 3281. Acc: 0.473840. Loss: 1.463611. Batch_acc: 0.489313. Batch_loss: 1.410686 \n",
      "Batch: 3282. Acc: 0.473840. Loss: 1.463601. Batch_acc: 0.475694. Batch_loss: 1.428909 \n",
      "Batch: 3283. Acc: 0.473844. Loss: 1.463590. Batch_acc: 0.486471. Batch_loss: 1.430099 \n",
      "Batch: 3284. Acc: 0.473853. Loss: 1.463577. Batch_acc: 0.502910. Batch_loss: 1.420435 \n",
      "Batch: 3285. Acc: 0.473860. Loss: 1.463553. Batch_acc: 0.496873. Batch_loss: 1.385904 \n",
      "Batch: 3286. Acc: 0.473864. Loss: 1.463548. Batch_acc: 0.489060. Batch_loss: 1.446000 \n",
      "Batch: 3287. Acc: 0.473881. Loss: 1.463505. Batch_acc: 0.526870. Batch_loss: 1.326196 \n",
      "Batch: 3288. Acc: 0.473882. Loss: 1.463502. Batch_acc: 0.477378. Batch_loss: 1.452733 \n",
      "Batch: 3289. Acc: 0.473895. Loss: 1.463469. Batch_acc: 0.515341. Batch_loss: 1.356179 \n",
      "Batch: 3290. Acc: 0.473898. Loss: 1.463473. Batch_acc: 0.484518. Batch_loss: 1.479194 \n",
      "Batch: 3291. Acc: 0.473905. Loss: 1.463459. Batch_acc: 0.498828. Batch_loss: 1.415983 \n",
      "Batch: 3292. Acc: 0.473916. Loss: 1.463435. Batch_acc: 0.506849. Batch_loss: 1.385317 \n",
      "Batch: 3293. Acc: 0.473921. Loss: 1.463419. Batch_acc: 0.492974. Batch_loss: 1.406935 \n",
      "Batch: 3294. Acc: 0.473924. Loss: 1.463414. Batch_acc: 0.483343. Batch_loss: 1.449840 \n",
      "Batch: 3295. Acc: 0.473930. Loss: 1.463400. Batch_acc: 0.492820. Batch_loss: 1.416603 \n",
      "Batch: 3296. Acc: 0.473942. Loss: 1.463376. Batch_acc: 0.514960. Batch_loss: 1.383230 \n",
      "Batch: 3297. Acc: 0.473943. Loss: 1.463372. Batch_acc: 0.474783. Batch_loss: 1.451123 \n",
      "Batch: 3298. Acc: 0.473951. Loss: 1.463341. Batch_acc: 0.500843. Batch_loss: 1.361313 \n",
      "Batch: 3299. Acc: 0.473956. Loss: 1.463322. Batch_acc: 0.489655. Batch_loss: 1.400705 \n",
      "Batch: 3300. Acc: 0.473965. Loss: 1.463295. Batch_acc: 0.505643. Batch_loss: 1.377867 \n",
      "Batch: 3301. Acc: 0.473974. Loss: 1.463274. Batch_acc: 0.504032. Batch_loss: 1.393627 \n",
      "Batch: 3302. Acc: 0.473977. Loss: 1.463275. Batch_acc: 0.481942. Batch_loss: 1.467565 \n",
      "Batch: 3303. Acc: 0.473990. Loss: 1.463238. Batch_acc: 0.514477. Batch_loss: 1.344007 \n",
      "Batch: 3304. Acc: 0.473999. Loss: 1.463214. Batch_acc: 0.503712. Batch_loss: 1.383455 \n",
      "Batch: 3305. Acc: 0.474005. Loss: 1.463181. Batch_acc: 0.495995. Batch_loss: 1.356081 \n",
      "Batch: 3306. Acc: 0.474010. Loss: 1.463175. Batch_acc: 0.490368. Batch_loss: 1.443318 \n",
      "Batch: 3307. Acc: 0.474011. Loss: 1.463172. Batch_acc: 0.477987. Batch_loss: 1.452139 \n",
      "Batch: 3308. Acc: 0.474023. Loss: 1.463145. Batch_acc: 0.513841. Batch_loss: 1.375472 \n",
      "Batch: 3309. Acc: 0.474032. Loss: 1.463121. Batch_acc: 0.503375. Batch_loss: 1.385649 \n",
      "Batch: 3310. Acc: 0.474034. Loss: 1.463107. Batch_acc: 0.478111. Batch_loss: 1.415772 \n",
      "Batch: 3311. Acc: 0.474036. Loss: 1.463112. Batch_acc: 0.483267. Batch_loss: 1.479301 \n",
      "Batch: 3312. Acc: 0.474034. Loss: 1.463118. Batch_acc: 0.464327. Batch_loss: 1.482943 \n",
      "Batch: 3313. Acc: 0.474037. Loss: 1.463104. Batch_acc: 0.484302. Batch_loss: 1.414593 \n",
      "Batch: 3314. Acc: 0.474043. Loss: 1.463079. Batch_acc: 0.494767. Batch_loss: 1.380799 \n",
      "Batch: 3315. Acc: 0.474048. Loss: 1.463062. Batch_acc: 0.490468. Batch_loss: 1.404912 \n",
      "Batch: 3316. Acc: 0.474053. Loss: 1.463055. Batch_acc: 0.493064. Batch_loss: 1.441997 \n",
      "Batch: 3317. Acc: 0.474059. Loss: 1.463033. Batch_acc: 0.491747. Batch_loss: 1.389887 \n",
      "Batch: 3318. Acc: 0.474061. Loss: 1.463024. Batch_acc: 0.482060. Batch_loss: 1.431897 \n",
      "Batch: 3319. Acc: 0.474066. Loss: 1.463022. Batch_acc: 0.490288. Batch_loss: 1.455902 \n",
      "Batch: 3320. Acc: 0.474072. Loss: 1.463005. Batch_acc: 0.494804. Batch_loss: 1.408969 \n",
      "Batch: 3321. Acc: 0.474073. Loss: 1.462992. Batch_acc: 0.477493. Batch_loss: 1.418028 \n",
      "Batch: 3322. Acc: 0.474077. Loss: 1.462979. Batch_acc: 0.485764. Batch_loss: 1.420967 \n",
      "Batch: 3323. Acc: 0.474083. Loss: 1.462952. Batch_acc: 0.496032. Batch_loss: 1.374814 \n",
      "Batch: 3324. Acc: 0.474092. Loss: 1.462928. Batch_acc: 0.502326. Batch_loss: 1.380605 \n",
      "Batch: 3325. Acc: 0.474100. Loss: 1.462909. Batch_acc: 0.501706. Batch_loss: 1.400068 \n",
      "Batch: 3326. Acc: 0.474101. Loss: 1.462896. Batch_acc: 0.478132. Batch_loss: 1.419414 \n",
      "Batch: 3327. Acc: 0.474118. Loss: 1.462861. Batch_acc: 0.528367. Batch_loss: 1.347225 \n",
      "Batch: 3328. Acc: 0.474124. Loss: 1.462839. Batch_acc: 0.496023. Batch_loss: 1.390351 \n",
      "Batch: 3329. Acc: 0.474130. Loss: 1.462824. Batch_acc: 0.493031. Batch_loss: 1.414088 \n",
      "Batch: 3330. Acc: 0.474137. Loss: 1.462817. Batch_acc: 0.497669. Batch_loss: 1.438257 \n",
      "Batch: 3331. Acc: 0.474135. Loss: 1.462820. Batch_acc: 0.468012. Batch_loss: 1.471766 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3332. Acc: 0.474146. Loss: 1.462790. Batch_acc: 0.509206. Batch_loss: 1.362057 \n",
      "Batch: 3333. Acc: 0.474152. Loss: 1.462766. Batch_acc: 0.494550. Batch_loss: 1.384482 \n",
      "Batch: 3334. Acc: 0.474149. Loss: 1.462770. Batch_acc: 0.464118. Batch_loss: 1.475875 \n",
      "Batch: 3335. Acc: 0.474164. Loss: 1.462735. Batch_acc: 0.522910. Batch_loss: 1.345151 \n",
      "Batch: 3336. Acc: 0.474175. Loss: 1.462716. Batch_acc: 0.510286. Batch_loss: 1.401753 \n",
      "Batch: 3337. Acc: 0.474178. Loss: 1.462705. Batch_acc: 0.485252. Batch_loss: 1.425113 \n",
      "Batch: 3338. Acc: 0.474180. Loss: 1.462697. Batch_acc: 0.481545. Batch_loss: 1.436300 \n",
      "Batch: 3339. Acc: 0.474180. Loss: 1.462694. Batch_acc: 0.472490. Batch_loss: 1.452473 \n",
      "Batch: 3340. Acc: 0.474186. Loss: 1.462672. Batch_acc: 0.496054. Batch_loss: 1.390361 \n",
      "Batch: 3341. Acc: 0.474189. Loss: 1.462654. Batch_acc: 0.484295. Batch_loss: 1.403690 \n",
      "Batch: 3342. Acc: 0.474193. Loss: 1.462642. Batch_acc: 0.486761. Batch_loss: 1.423344 \n",
      "Batch: 3343. Acc: 0.474205. Loss: 1.462606. Batch_acc: 0.513652. Batch_loss: 1.343966 \n",
      "Batch: 3344. Acc: 0.474210. Loss: 1.462590. Batch_acc: 0.489118. Batch_loss: 1.407702 \n",
      "Batch: 3345. Acc: 0.474216. Loss: 1.462569. Batch_acc: 0.495697. Batch_loss: 1.395457 \n",
      "Batch: 3346. Acc: 0.474221. Loss: 1.462562. Batch_acc: 0.491399. Batch_loss: 1.438327 \n",
      "Batch: 3347. Acc: 0.474222. Loss: 1.462557. Batch_acc: 0.478411. Batch_loss: 1.443771 \n",
      "Batch: 3348. Acc: 0.474233. Loss: 1.462525. Batch_acc: 0.509292. Batch_loss: 1.355609 \n",
      "Batch: 3349. Acc: 0.474241. Loss: 1.462508. Batch_acc: 0.500567. Batch_loss: 1.405754 \n",
      "Batch: 3350. Acc: 0.474244. Loss: 1.462484. Batch_acc: 0.484814. Batch_loss: 1.384790 \n",
      "Batch: 3351. Acc: 0.474251. Loss: 1.462459. Batch_acc: 0.498535. Batch_loss: 1.374983 \n",
      "Batch: 3352. Acc: 0.474251. Loss: 1.462460. Batch_acc: 0.473322. Batch_loss: 1.466637 \n",
      "Batch: 3353. Acc: 0.474247. Loss: 1.462469. Batch_acc: 0.461765. Batch_loss: 1.492873 \n",
      "Batch: 3354. Acc: 0.474243. Loss: 1.462476. Batch_acc: 0.461852. Batch_loss: 1.485419 \n",
      "Batch: 3355. Acc: 0.474252. Loss: 1.462453. Batch_acc: 0.503695. Batch_loss: 1.387047 \n",
      "Batch: 3356. Acc: 0.474257. Loss: 1.462444. Batch_acc: 0.490263. Batch_loss: 1.433189 \n",
      "Batch: 3357. Acc: 0.474259. Loss: 1.462427. Batch_acc: 0.482332. Batch_loss: 1.404405 \n",
      "Batch: 3358. Acc: 0.474264. Loss: 1.462423. Batch_acc: 0.488074. Batch_loss: 1.448501 \n",
      "Batch: 3359. Acc: 0.474271. Loss: 1.462404. Batch_acc: 0.498546. Batch_loss: 1.398336 \n",
      "Batch: 3360. Acc: 0.474281. Loss: 1.462376. Batch_acc: 0.508782. Batch_loss: 1.369475 \n",
      "Batch: 3361. Acc: 0.474289. Loss: 1.462354. Batch_acc: 0.501410. Batch_loss: 1.388505 \n",
      "Batch: 3362. Acc: 0.474297. Loss: 1.462333. Batch_acc: 0.498566. Batch_loss: 1.391442 \n",
      "Batch: 3363. Acc: 0.474304. Loss: 1.462307. Batch_acc: 0.500286. Batch_loss: 1.376177 \n",
      "Batch: 3364. Acc: 0.474315. Loss: 1.462278. Batch_acc: 0.510614. Batch_loss: 1.365962 \n",
      "Batch: 3365. Acc: 0.474323. Loss: 1.462256. Batch_acc: 0.500000. Batch_loss: 1.388242 \n",
      "Batch: 3366. Acc: 0.474329. Loss: 1.462236. Batch_acc: 0.495501. Batch_loss: 1.394964 \n",
      "Batch: 3367. Acc: 0.474336. Loss: 1.462212. Batch_acc: 0.495455. Batch_loss: 1.381948 \n",
      "Batch: 3368. Acc: 0.474344. Loss: 1.462186. Batch_acc: 0.504037. Batch_loss: 1.375376 \n",
      "Batch: 3369. Acc: 0.474350. Loss: 1.462172. Batch_acc: 0.495090. Batch_loss: 1.416416 \n",
      "Batch: 3370. Acc: 0.474353. Loss: 1.462162. Batch_acc: 0.482060. Batch_loss: 1.428072 \n",
      "Batch: 3371. Acc: 0.474362. Loss: 1.462139. Batch_acc: 0.506166. Batch_loss: 1.381162 \n",
      "Batch: 3372. Acc: 0.474376. Loss: 1.462112. Batch_acc: 0.522559. Batch_loss: 1.372511 \n",
      "Batch: 3373. Acc: 0.474381. Loss: 1.462098. Batch_acc: 0.491389. Batch_loss: 1.415465 \n",
      "Batch: 3374. Acc: 0.474384. Loss: 1.462087. Batch_acc: 0.484393. Batch_loss: 1.424369 \n",
      "Batch: 3375. Acc: 0.474387. Loss: 1.462077. Batch_acc: 0.484726. Batch_loss: 1.428332 \n",
      "Batch: 3376. Acc: 0.474389. Loss: 1.462069. Batch_acc: 0.480947. Batch_loss: 1.434633 \n",
      "Batch: 3377. Acc: 0.474395. Loss: 1.462052. Batch_acc: 0.493111. Batch_loss: 1.404246 \n",
      "Batch: 3378. Acc: 0.474403. Loss: 1.462031. Batch_acc: 0.501149. Batch_loss: 1.389873 \n",
      "Batch: 3379. Acc: 0.474413. Loss: 1.462011. Batch_acc: 0.509259. Batch_loss: 1.396784 \n",
      "Batch: 3380. Acc: 0.474416. Loss: 1.462002. Batch_acc: 0.483440. Batch_loss: 1.430479 \n",
      "Batch: 3381. Acc: 0.474413. Loss: 1.462003. Batch_acc: 0.465608. Batch_loss: 1.466693 \n",
      "Batch: 3382. Acc: 0.474416. Loss: 1.461992. Batch_acc: 0.483740. Batch_loss: 1.421508 \n",
      "Batch: 3383. Acc: 0.474420. Loss: 1.461981. Batch_acc: 0.487165. Batch_loss: 1.427216 \n",
      "Batch: 3384. Acc: 0.474420. Loss: 1.461984. Batch_acc: 0.476897. Batch_loss: 1.471943 \n",
      "Batch: 3385. Acc: 0.474433. Loss: 1.461947. Batch_acc: 0.516276. Batch_loss: 1.337080 \n",
      "Batch: 3386. Acc: 0.474444. Loss: 1.461917. Batch_acc: 0.512938. Batch_loss: 1.359532 \n",
      "Batch: 3387. Acc: 0.474449. Loss: 1.461907. Batch_acc: 0.491917. Batch_loss: 1.427668 \n",
      "Batch: 3388. Acc: 0.474460. Loss: 1.461877. Batch_acc: 0.511036. Batch_loss: 1.361502 \n",
      "Batch: 3389. Acc: 0.474461. Loss: 1.461879. Batch_acc: 0.476553. Batch_loss: 1.471913 \n",
      "Batch: 3390. Acc: 0.474467. Loss: 1.461860. Batch_acc: 0.496245. Batch_loss: 1.395436 \n",
      "Batch: 3391. Acc: 0.474469. Loss: 1.461854. Batch_acc: 0.479143. Batch_loss: 1.441419 \n",
      "Batch: 3392. Acc: 0.474482. Loss: 1.461820. Batch_acc: 0.520846. Batch_loss: 1.344792 \n",
      "Batch: 3393. Acc: 0.474487. Loss: 1.461795. Batch_acc: 0.490435. Batch_loss: 1.376279 \n",
      "Batch: 3394. Acc: 0.474494. Loss: 1.461774. Batch_acc: 0.500588. Batch_loss: 1.388061 \n",
      "Batch: 3395. Acc: 0.474500. Loss: 1.461749. Batch_acc: 0.491803. Batch_loss: 1.380483 \n",
      "Batch: 3396. Acc: 0.474502. Loss: 1.461738. Batch_acc: 0.483908. Batch_loss: 1.423653 \n",
      "Batch: 3397. Acc: 0.474505. Loss: 1.461729. Batch_acc: 0.482798. Batch_loss: 1.430823 \n",
      "Batch: 3398. Acc: 0.474506. Loss: 1.461723. Batch_acc: 0.479492. Batch_loss: 1.440238 \n",
      "Batch: 3399. Acc: 0.474515. Loss: 1.461698. Batch_acc: 0.505482. Batch_loss: 1.375847 \n",
      "Batch: 3400. Acc: 0.474522. Loss: 1.461686. Batch_acc: 0.497166. Batch_loss: 1.421875 \n",
      "Batch: 3401. Acc: 0.474534. Loss: 1.461653. Batch_acc: 0.514896. Batch_loss: 1.352509 \n",
      "Batch: 3402. Acc: 0.474542. Loss: 1.461629. Batch_acc: 0.501152. Batch_loss: 1.381442 \n",
      "Batch: 3403. Acc: 0.474547. Loss: 1.461613. Batch_acc: 0.492494. Batch_loss: 1.407543 \n",
      "Batch: 3404. Acc: 0.474557. Loss: 1.461597. Batch_acc: 0.506045. Batch_loss: 1.406043 \n",
      "Batch: 3405. Acc: 0.474571. Loss: 1.461572. Batch_acc: 0.523086. Batch_loss: 1.378248 \n",
      "Batch: 3406. Acc: 0.474578. Loss: 1.461551. Batch_acc: 0.499711. Batch_loss: 1.390965 \n",
      "Batch: 3407. Acc: 0.474587. Loss: 1.461516. Batch_acc: 0.504827. Batch_loss: 1.343038 \n",
      "Batch: 3408. Acc: 0.474592. Loss: 1.461503. Batch_acc: 0.491399. Batch_loss: 1.415693 \n",
      "Batch: 3409. Acc: 0.474597. Loss: 1.461485. Batch_acc: 0.490357. Batch_loss: 1.401262 \n",
      "Batch: 3410. Acc: 0.474606. Loss: 1.461460. Batch_acc: 0.506865. Batch_loss: 1.375503 \n",
      "Batch: 3411. Acc: 0.474616. Loss: 1.461442. Batch_acc: 0.505328. Batch_loss: 1.400330 \n",
      "Batch: 3412. Acc: 0.474617. Loss: 1.461445. Batch_acc: 0.478584. Batch_loss: 1.473375 \n",
      "Batch: 3413. Acc: 0.474621. Loss: 1.461427. Batch_acc: 0.487969. Batch_loss: 1.400265 \n",
      "Batch: 3414. Acc: 0.474617. Loss: 1.461431. Batch_acc: 0.462033. Batch_loss: 1.476923 \n",
      "Batch: 3415. Acc: 0.474621. Loss: 1.461422. Batch_acc: 0.488215. Batch_loss: 1.432090 \n",
      "Batch: 3416. Acc: 0.474624. Loss: 1.461410. Batch_acc: 0.482461. Batch_loss: 1.418231 \n",
      "Batch: 3417. Acc: 0.474631. Loss: 1.461396. Batch_acc: 0.499712. Batch_loss: 1.413125 \n",
      "Batch: 3418. Acc: 0.474633. Loss: 1.461383. Batch_acc: 0.482596. Batch_loss: 1.415657 \n",
      "Batch: 3419. Acc: 0.474634. Loss: 1.461379. Batch_acc: 0.475457. Batch_loss: 1.448655 \n",
      "Batch: 3420. Acc: 0.474642. Loss: 1.461369. Batch_acc: 0.502273. Batch_loss: 1.428286 \n",
      "Batch: 3421. Acc: 0.474642. Loss: 1.461363. Batch_acc: 0.475954. Batch_loss: 1.442268 \n",
      "Batch: 3422. Acc: 0.474646. Loss: 1.461355. Batch_acc: 0.486150. Batch_loss: 1.431945 \n",
      "Batch: 3423. Acc: 0.474647. Loss: 1.461345. Batch_acc: 0.481333. Batch_loss: 1.429997 \n",
      "Batch: 3424. Acc: 0.474659. Loss: 1.461325. Batch_acc: 0.513028. Batch_loss: 1.391673 \n",
      "Batch: 3425. Acc: 0.474657. Loss: 1.461330. Batch_acc: 0.470554. Batch_loss: 1.479987 \n",
      "Batch: 3426. Acc: 0.474658. Loss: 1.461328. Batch_acc: 0.475354. Batch_loss: 1.454197 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3427. Acc: 0.474661. Loss: 1.461315. Batch_acc: 0.486812. Batch_loss: 1.416272 \n",
      "Batch: 3428. Acc: 0.474664. Loss: 1.461305. Batch_acc: 0.484884. Batch_loss: 1.427482 \n",
      "Batch: 3429. Acc: 0.474666. Loss: 1.461294. Batch_acc: 0.481839. Batch_loss: 1.423210 \n",
      "Batch: 3430. Acc: 0.474669. Loss: 1.461287. Batch_acc: 0.485580. Batch_loss: 1.436094 \n",
      "Batch: 3431. Acc: 0.474672. Loss: 1.461278. Batch_acc: 0.484043. Batch_loss: 1.431428 \n",
      "Batch: 3432. Acc: 0.474681. Loss: 1.461259. Batch_acc: 0.505682. Batch_loss: 1.393798 \n",
      "Batch: 3433. Acc: 0.474688. Loss: 1.461243. Batch_acc: 0.498316. Batch_loss: 1.407652 \n",
      "Batch: 3434. Acc: 0.474693. Loss: 1.461224. Batch_acc: 0.492991. Batch_loss: 1.397781 \n",
      "Batch: 3435. Acc: 0.474700. Loss: 1.461202. Batch_acc: 0.498822. Batch_loss: 1.382724 \n",
      "Batch: 3436. Acc: 0.474703. Loss: 1.461191. Batch_acc: 0.484866. Batch_loss: 1.423258 \n",
      "Batch: 3437. Acc: 0.474709. Loss: 1.461177. Batch_acc: 0.494091. Batch_loss: 1.413119 \n",
      "Batch: 3438. Acc: 0.474716. Loss: 1.461152. Batch_acc: 0.498237. Batch_loss: 1.373344 \n",
      "Batch: 3439. Acc: 0.474722. Loss: 1.461144. Batch_acc: 0.495044. Batch_loss: 1.433728 \n",
      "Batch: 3440. Acc: 0.474729. Loss: 1.461126. Batch_acc: 0.498855. Batch_loss: 1.400245 \n",
      "Batch: 3441. Acc: 0.474736. Loss: 1.461110. Batch_acc: 0.498572. Batch_loss: 1.407935 \n",
      "Batch: 3442. Acc: 0.474737. Loss: 1.461102. Batch_acc: 0.479049. Batch_loss: 1.433997 \n",
      "Batch: 3443. Acc: 0.474745. Loss: 1.461073. Batch_acc: 0.500834. Batch_loss: 1.363565 \n",
      "Batch: 3444. Acc: 0.474743. Loss: 1.461071. Batch_acc: 0.469150. Batch_loss: 1.455053 \n",
      "Batch: 3445. Acc: 0.474756. Loss: 1.461043. Batch_acc: 0.517143. Batch_loss: 1.364388 \n",
      "Batch: 3446. Acc: 0.474764. Loss: 1.461017. Batch_acc: 0.501967. Batch_loss: 1.373940 \n",
      "Batch: 3447. Acc: 0.474768. Loss: 1.461007. Batch_acc: 0.489983. Batch_loss: 1.426814 \n",
      "Batch: 3448. Acc: 0.474769. Loss: 1.461002. Batch_acc: 0.479742. Batch_loss: 1.443574 \n",
      "Batch: 3449. Acc: 0.474780. Loss: 1.460978. Batch_acc: 0.510626. Batch_loss: 1.376383 \n",
      "Batch: 3450. Acc: 0.474787. Loss: 1.460958. Batch_acc: 0.499131. Batch_loss: 1.390783 \n",
      "Batch: 3451. Acc: 0.474786. Loss: 1.460962. Batch_acc: 0.472093. Batch_loss: 1.476718 \n",
      "Batch: 3452. Acc: 0.474794. Loss: 1.460949. Batch_acc: 0.503421. Batch_loss: 1.416499 \n",
      "Batch: 3453. Acc: 0.474808. Loss: 1.460904. Batch_acc: 0.521469. Batch_loss: 1.307916 \n",
      "Batch: 3454. Acc: 0.474811. Loss: 1.460896. Batch_acc: 0.485665. Batch_loss: 1.432455 \n",
      "Batch: 3455. Acc: 0.474806. Loss: 1.460909. Batch_acc: 0.454545. Batch_loss: 1.508485 \n",
      "Batch: 3456. Acc: 0.474807. Loss: 1.460904. Batch_acc: 0.480364. Batch_loss: 1.443254 \n",
      "Batch: 3457. Acc: 0.474818. Loss: 1.460878. Batch_acc: 0.513756. Batch_loss: 1.368586 \n",
      "Batch: 3458. Acc: 0.474824. Loss: 1.460867. Batch_acc: 0.495084. Batch_loss: 1.420073 \n",
      "Batch: 3459. Acc: 0.474834. Loss: 1.460841. Batch_acc: 0.508651. Batch_loss: 1.370177 \n",
      "Batch: 3460. Acc: 0.474842. Loss: 1.460825. Batch_acc: 0.504018. Batch_loss: 1.407556 \n",
      "Batch: 3461. Acc: 0.474846. Loss: 1.460799. Batch_acc: 0.488212. Batch_loss: 1.371193 \n",
      "Batch: 3462. Acc: 0.474849. Loss: 1.460786. Batch_acc: 0.485812. Batch_loss: 1.414392 \n",
      "Batch: 3463. Acc: 0.474852. Loss: 1.460777. Batch_acc: 0.483889. Batch_loss: 1.432000 \n",
      "Batch: 3464. Acc: 0.474859. Loss: 1.460754. Batch_acc: 0.500875. Batch_loss: 1.378766 \n",
      "Batch: 3465. Acc: 0.474856. Loss: 1.460749. Batch_acc: 0.462973. Batch_loss: 1.444867 \n",
      "Batch: 3466. Acc: 0.474858. Loss: 1.460742. Batch_acc: 0.481675. Batch_loss: 1.435216 \n",
      "Batch: 3467. Acc: 0.474860. Loss: 1.460737. Batch_acc: 0.484036. Batch_loss: 1.445270 \n",
      "Batch: 3468. Acc: 0.474865. Loss: 1.460725. Batch_acc: 0.489374. Batch_loss: 1.418043 \n",
      "Batch: 3469. Acc: 0.474871. Loss: 1.460709. Batch_acc: 0.496560. Batch_loss: 1.404552 \n",
      "Batch: 3470. Acc: 0.474872. Loss: 1.460706. Batch_acc: 0.478236. Batch_loss: 1.452294 \n",
      "Batch: 3471. Acc: 0.474873. Loss: 1.460701. Batch_acc: 0.479598. Batch_loss: 1.442182 \n",
      "Batch: 3472. Acc: 0.474876. Loss: 1.460687. Batch_acc: 0.485109. Batch_loss: 1.413338 \n",
      "Batch: 3473. Acc: 0.474882. Loss: 1.460675. Batch_acc: 0.493417. Batch_loss: 1.416742 \n",
      "Batch: 3474. Acc: 0.474884. Loss: 1.460652. Batch_acc: 0.483459. Batch_loss: 1.382072 \n",
      "Batch: 3475. Acc: 0.474893. Loss: 1.460631. Batch_acc: 0.503911. Batch_loss: 1.389730 \n",
      "Batch: 3476. Acc: 0.474896. Loss: 1.460614. Batch_acc: 0.485431. Batch_loss: 1.398679 \n",
      "Batch: 3477. Acc: 0.474901. Loss: 1.460595. Batch_acc: 0.492630. Batch_loss: 1.397016 \n",
      "Batch: 3478. Acc: 0.474905. Loss: 1.460586. Batch_acc: 0.489589. Batch_loss: 1.428814 \n",
      "Batch: 3479. Acc: 0.474912. Loss: 1.460575. Batch_acc: 0.497992. Batch_loss: 1.424526 \n",
      "Batch: 3480. Acc: 0.474917. Loss: 1.460571. Batch_acc: 0.493197. Batch_loss: 1.445128 \n",
      "Batch: 3481. Acc: 0.474922. Loss: 1.460564. Batch_acc: 0.492179. Batch_loss: 1.437513 \n",
      "Batch: 3482. Acc: 0.474919. Loss: 1.460570. Batch_acc: 0.462738. Batch_loss: 1.483111 \n",
      "Batch: 3483. Acc: 0.474920. Loss: 1.460550. Batch_acc: 0.480046. Batch_loss: 1.388607 \n",
      "Batch: 3484. Acc: 0.474919. Loss: 1.460555. Batch_acc: 0.471521. Batch_loss: 1.480335 \n",
      "Batch: 3485. Acc: 0.474918. Loss: 1.460552. Batch_acc: 0.471056. Batch_loss: 1.449767 \n",
      "Batch: 3486. Acc: 0.474922. Loss: 1.460543. Batch_acc: 0.488649. Batch_loss: 1.430692 \n",
      "Batch: 3487. Acc: 0.474926. Loss: 1.460530. Batch_acc: 0.489540. Batch_loss: 1.413011 \n",
      "Batch: 3488. Acc: 0.474927. Loss: 1.460529. Batch_acc: 0.477312. Batch_loss: 1.457343 \n",
      "Batch: 3489. Acc: 0.474934. Loss: 1.460511. Batch_acc: 0.500000. Batch_loss: 1.396897 \n",
      "Batch: 3490. Acc: 0.474931. Loss: 1.460517. Batch_acc: 0.463429. Batch_loss: 1.480907 \n",
      "Batch: 3491. Acc: 0.474932. Loss: 1.460504. Batch_acc: 0.478137. Batch_loss: 1.416677 \n",
      "Batch: 3492. Acc: 0.474942. Loss: 1.460481. Batch_acc: 0.509434. Batch_loss: 1.381256 \n",
      "Batch: 3493. Acc: 0.474940. Loss: 1.460493. Batch_acc: 0.470180. Batch_loss: 1.501349 \n",
      "Batch: 3494. Acc: 0.474955. Loss: 1.460453. Batch_acc: 0.525750. Batch_loss: 1.324081 \n",
      "Batch: 3495. Acc: 0.474956. Loss: 1.460448. Batch_acc: 0.478364. Batch_loss: 1.444064 \n",
      "Batch: 3496. Acc: 0.474960. Loss: 1.460432. Batch_acc: 0.488952. Batch_loss: 1.402853 \n",
      "Batch: 3497. Acc: 0.474972. Loss: 1.460406. Batch_acc: 0.517162. Batch_loss: 1.372201 \n",
      "Batch: 3498. Acc: 0.474980. Loss: 1.460384. Batch_acc: 0.503116. Batch_loss: 1.383941 \n",
      "Batch: 3499. Acc: 0.474987. Loss: 1.460356. Batch_acc: 0.498845. Batch_loss: 1.361427 \n",
      "Batch: 3500. Acc: 0.474999. Loss: 1.460330. Batch_acc: 0.516464. Batch_loss: 1.367694 \n",
      "Batch: 3501. Acc: 0.475005. Loss: 1.460309. Batch_acc: 0.495168. Batch_loss: 1.389962 \n",
      "Batch: 3502. Acc: 0.474999. Loss: 1.460315. Batch_acc: 0.455176. Batch_loss: 1.480155 \n",
      "Batch: 3503. Acc: 0.475010. Loss: 1.460291. Batch_acc: 0.511926. Batch_loss: 1.375180 \n",
      "Batch: 3504. Acc: 0.475020. Loss: 1.460259. Batch_acc: 0.511912. Batch_loss: 1.347947 \n",
      "Batch: 3505. Acc: 0.475024. Loss: 1.460250. Batch_acc: 0.487136. Batch_loss: 1.429512 \n",
      "Batch: 3506. Acc: 0.475028. Loss: 1.460236. Batch_acc: 0.491604. Batch_loss: 1.409353 \n",
      "Batch: 3507. Acc: 0.475042. Loss: 1.460202. Batch_acc: 0.521863. Batch_loss: 1.341170 \n",
      "Batch: 3508. Acc: 0.475049. Loss: 1.460180. Batch_acc: 0.501699. Batch_loss: 1.386753 \n",
      "Batch: 3509. Acc: 0.475051. Loss: 1.460163. Batch_acc: 0.479858. Batch_loss: 1.399183 \n",
      "Batch: 3510. Acc: 0.475054. Loss: 1.460146. Batch_acc: 0.487338. Batch_loss: 1.399137 \n",
      "Batch: 3511. Acc: 0.475062. Loss: 1.460128. Batch_acc: 0.502034. Batch_loss: 1.395949 \n",
      "Batch: 3512. Acc: 0.475065. Loss: 1.460120. Batch_acc: 0.484673. Batch_loss: 1.433137 \n",
      "Batch: 3513. Acc: 0.475075. Loss: 1.460091. Batch_acc: 0.510638. Batch_loss: 1.358962 \n",
      "Batch: 3514. Acc: 0.475074. Loss: 1.460089. Batch_acc: 0.472093. Batch_loss: 1.451426 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.4750739813711945. Loss per char: 1.4600886243891382. Time: 1627216890.288572\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 17, 15, 17, 26,\n",
      "        17, 22, 23, 26, 17, 26,  1, 66, 79, 69,  1, 24, 18, 26, 24, 17, 26, 25,\n",
      "        23, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.475080. Loss: 1.460072. Batch_acc: 0.494157. Batch_loss: 1.403219 \n",
      "Batch: 3516. Acc: 0.475080. Loss: 1.460074. Batch_acc: 0.478163. Batch_loss: 1.467453 \n",
      "Batch: 3517. Acc: 0.475084. Loss: 1.460061. Batch_acc: 0.488252. Batch_loss: 1.413030 \n",
      "Batch: 3518. Acc: 0.475076. Loss: 1.460077. Batch_acc: 0.445602. Batch_loss: 1.518697 \n",
      "Batch: 3519. Acc: 0.475082. Loss: 1.460062. Batch_acc: 0.495963. Batch_loss: 1.406801 \n",
      "Batch: 3520. Acc: 0.475091. Loss: 1.460036. Batch_acc: 0.507074. Batch_loss: 1.369375 \n",
      "Batch: 3521. Acc: 0.475098. Loss: 1.460016. Batch_acc: 0.500292. Batch_loss: 1.390403 \n",
      "Batch: 3522. Acc: 0.475105. Loss: 1.460000. Batch_acc: 0.499136. Batch_loss: 1.400407 \n",
      "Batch: 3523. Acc: 0.475112. Loss: 1.459981. Batch_acc: 0.499162. Batch_loss: 1.395022 \n",
      "Batch: 3524. Acc: 0.475123. Loss: 1.459939. Batch_acc: 0.513403. Batch_loss: 1.311378 \n",
      "Batch: 3525. Acc: 0.475130. Loss: 1.459915. Batch_acc: 0.500853. Batch_loss: 1.376503 \n",
      "Batch: 3526. Acc: 0.475134. Loss: 1.459905. Batch_acc: 0.489857. Batch_loss: 1.422131 \n",
      "Batch: 3527. Acc: 0.475144. Loss: 1.459876. Batch_acc: 0.507804. Batch_loss: 1.362799 \n",
      "Batch: 3528. Acc: 0.475144. Loss: 1.459880. Batch_acc: 0.476247. Batch_loss: 1.474105 \n",
      "Batch: 3529. Acc: 0.475154. Loss: 1.459862. Batch_acc: 0.510321. Batch_loss: 1.394619 \n",
      "Batch: 3530. Acc: 0.475153. Loss: 1.459855. Batch_acc: 0.471676. Batch_loss: 1.436541 \n",
      "Batch: 3531. Acc: 0.475154. Loss: 1.459851. Batch_acc: 0.478038. Batch_loss: 1.444081 \n",
      "Batch: 3532. Acc: 0.475165. Loss: 1.459831. Batch_acc: 0.514956. Batch_loss: 1.387764 \n",
      "Batch: 3533. Acc: 0.475166. Loss: 1.459834. Batch_acc: 0.477752. Batch_loss: 1.470559 \n",
      "Batch: 3534. Acc: 0.475175. Loss: 1.459815. Batch_acc: 0.510121. Batch_loss: 1.395325 \n",
      "Batch: 3535. Acc: 0.475182. Loss: 1.459792. Batch_acc: 0.497680. Batch_loss: 1.376111 \n",
      "Batch: 3536. Acc: 0.475185. Loss: 1.459783. Batch_acc: 0.487313. Batch_loss: 1.427187 \n",
      "Batch: 3537. Acc: 0.475188. Loss: 1.459776. Batch_acc: 0.485252. Batch_loss: 1.435163 \n",
      "Batch: 3538. Acc: 0.475195. Loss: 1.459752. Batch_acc: 0.500854. Batch_loss: 1.375654 \n",
      "Batch: 3539. Acc: 0.475195. Loss: 1.459763. Batch_acc: 0.473529. Batch_loss: 1.499909 \n",
      "Batch: 3540. Acc: 0.475199. Loss: 1.459747. Batch_acc: 0.489589. Batch_loss: 1.405795 \n",
      "Batch: 3541. Acc: 0.475211. Loss: 1.459727. Batch_acc: 0.516093. Batch_loss: 1.387780 \n",
      "Batch: 3542. Acc: 0.475225. Loss: 1.459685. Batch_acc: 0.524874. Batch_loss: 1.315700 \n",
      "Batch: 3543. Acc: 0.475226. Loss: 1.459685. Batch_acc: 0.479694. Batch_loss: 1.459209 \n",
      "Batch: 3544. Acc: 0.475242. Loss: 1.459651. Batch_acc: 0.531142. Batch_loss: 1.342072 \n",
      "Batch: 3545. Acc: 0.475253. Loss: 1.459628. Batch_acc: 0.514137. Batch_loss: 1.376728 \n",
      "Batch: 3546. Acc: 0.475258. Loss: 1.459612. Batch_acc: 0.492343. Batch_loss: 1.403482 \n",
      "Batch: 3547. Acc: 0.475262. Loss: 1.459595. Batch_acc: 0.490460. Batch_loss: 1.398670 \n",
      "Batch: 3548. Acc: 0.475269. Loss: 1.459571. Batch_acc: 0.500000. Batch_loss: 1.373881 \n",
      "Batch: 3549. Acc: 0.475275. Loss: 1.459550. Batch_acc: 0.494761. Batch_loss: 1.385086 \n",
      "Batch: 3550. Acc: 0.475281. Loss: 1.459534. Batch_acc: 0.497448. Batch_loss: 1.402998 \n",
      "Batch: 3551. Acc: 0.475284. Loss: 1.459526. Batch_acc: 0.486425. Batch_loss: 1.431755 \n",
      "Batch: 3552. Acc: 0.475277. Loss: 1.459536. Batch_acc: 0.449471. Batch_loss: 1.497640 \n",
      "Batch: 3553. Acc: 0.475275. Loss: 1.459543. Batch_acc: 0.469484. Batch_loss: 1.483319 \n",
      "Batch: 3554. Acc: 0.475290. Loss: 1.459510. Batch_acc: 0.525779. Batch_loss: 1.345289 \n",
      "Batch: 3555. Acc: 0.475300. Loss: 1.459480. Batch_acc: 0.512363. Batch_loss: 1.351652 \n",
      "Batch: 3556. Acc: 0.475306. Loss: 1.459465. Batch_acc: 0.495611. Batch_loss: 1.405473 \n",
      "Batch: 3557. Acc: 0.475301. Loss: 1.459470. Batch_acc: 0.458599. Batch_loss: 1.475663 \n",
      "Batch: 3558. Acc: 0.475306. Loss: 1.459454. Batch_acc: 0.492934. Batch_loss: 1.405700 \n",
      "Batch: 3559. Acc: 0.475321. Loss: 1.459412. Batch_acc: 0.528696. Batch_loss: 1.309595 \n",
      "Batch: 3560. Acc: 0.475323. Loss: 1.459401. Batch_acc: 0.479841. Batch_loss: 1.418228 \n",
      "Batch: 3561. Acc: 0.475325. Loss: 1.459389. Batch_acc: 0.483056. Batch_loss: 1.416698 \n",
      "Batch: 3562. Acc: 0.475332. Loss: 1.459369. Batch_acc: 0.503214. Batch_loss: 1.388532 \n",
      "Batch: 3563. Acc: 0.475343. Loss: 1.459335. Batch_acc: 0.511551. Batch_loss: 1.343244 \n",
      "Batch: 3564. Acc: 0.475349. Loss: 1.459320. Batch_acc: 0.496292. Batch_loss: 1.406892 \n",
      "Batch: 3565. Acc: 0.475351. Loss: 1.459315. Batch_acc: 0.482466. Batch_loss: 1.440804 \n",
      "Batch: 3566. Acc: 0.475351. Loss: 1.459310. Batch_acc: 0.476273. Batch_loss: 1.443229 \n",
      "Batch: 3567. Acc: 0.475355. Loss: 1.459299. Batch_acc: 0.488952. Batch_loss: 1.419893 \n",
      "Batch: 3568. Acc: 0.475363. Loss: 1.459277. Batch_acc: 0.504905. Batch_loss: 1.381196 \n",
      "Batch: 3569. Acc: 0.475372. Loss: 1.459254. Batch_acc: 0.504794. Batch_loss: 1.376649 \n",
      "Batch: 3570. Acc: 0.475379. Loss: 1.459229. Batch_acc: 0.498895. Batch_loss: 1.373409 \n",
      "Batch: 3571. Acc: 0.475388. Loss: 1.459203. Batch_acc: 0.508732. Batch_loss: 1.370449 \n",
      "Batch: 3572. Acc: 0.475397. Loss: 1.459183. Batch_acc: 0.507772. Batch_loss: 1.385099 \n",
      "Batch: 3573. Acc: 0.475403. Loss: 1.459172. Batch_acc: 0.494312. Batch_loss: 1.420160 \n",
      "Batch: 3574. Acc: 0.475408. Loss: 1.459162. Batch_acc: 0.494213. Batch_loss: 1.423552 \n",
      "Batch: 3575. Acc: 0.475408. Loss: 1.459156. Batch_acc: 0.475103. Batch_loss: 1.438192 \n",
      "Batch: 3576. Acc: 0.475407. Loss: 1.459166. Batch_acc: 0.473349. Batch_loss: 1.494953 \n",
      "Batch: 3577. Acc: 0.475413. Loss: 1.459151. Batch_acc: 0.498807. Batch_loss: 1.404209 \n",
      "Batch: 3578. Acc: 0.475419. Loss: 1.459139. Batch_acc: 0.494467. Batch_loss: 1.415960 \n",
      "Batch: 3579. Acc: 0.475427. Loss: 1.459121. Batch_acc: 0.503725. Batch_loss: 1.394630 \n",
      "Batch: 3580. Acc: 0.475428. Loss: 1.459114. Batch_acc: 0.479358. Batch_loss: 1.432440 \n",
      "Batch: 3581. Acc: 0.475435. Loss: 1.459096. Batch_acc: 0.500858. Batch_loss: 1.394875 \n",
      "Batch: 3582. Acc: 0.475445. Loss: 1.459065. Batch_acc: 0.510216. Batch_loss: 1.351078 \n",
      "Batch: 3583. Acc: 0.475446. Loss: 1.459047. Batch_acc: 0.481714. Batch_loss: 1.395344 \n",
      "Batch: 3584. Acc: 0.475451. Loss: 1.459037. Batch_acc: 0.492728. Batch_loss: 1.422120 \n",
      "Batch: 3585. Acc: 0.475454. Loss: 1.459033. Batch_acc: 0.485846. Batch_loss: 1.444213 \n",
      "Batch: 3586. Acc: 0.475463. Loss: 1.459010. Batch_acc: 0.507034. Batch_loss: 1.377430 \n",
      "Batch: 3587. Acc: 0.475472. Loss: 1.458981. Batch_acc: 0.506920. Batch_loss: 1.351994 \n",
      "Batch: 3588. Acc: 0.475476. Loss: 1.458966. Batch_acc: 0.493223. Batch_loss: 1.405213 \n",
      "Batch: 3589. Acc: 0.475487. Loss: 1.458937. Batch_acc: 0.515239. Batch_loss: 1.353158 \n",
      "Batch: 3590. Acc: 0.475492. Loss: 1.458931. Batch_acc: 0.493432. Batch_loss: 1.439538 \n",
      "Batch: 3591. Acc: 0.475493. Loss: 1.458927. Batch_acc: 0.478890. Batch_loss: 1.444442 \n",
      "Batch: 3592. Acc: 0.475498. Loss: 1.458912. Batch_acc: 0.490523. Batch_loss: 1.406138 \n",
      "Batch: 3593. Acc: 0.475502. Loss: 1.458900. Batch_acc: 0.490093. Batch_loss: 1.411908 \n",
      "Batch: 3594. Acc: 0.475505. Loss: 1.458890. Batch_acc: 0.486111. Batch_loss: 1.423058 \n",
      "Batch: 3595. Acc: 0.475507. Loss: 1.458878. Batch_acc: 0.484848. Batch_loss: 1.416825 \n",
      "Batch: 3596. Acc: 0.475509. Loss: 1.458871. Batch_acc: 0.482678. Batch_loss: 1.432379 \n",
      "Batch: 3597. Acc: 0.475515. Loss: 1.458857. Batch_acc: 0.498017. Batch_loss: 1.408705 \n",
      "Batch: 3598. Acc: 0.475523. Loss: 1.458837. Batch_acc: 0.501712. Batch_loss: 1.387490 \n",
      "Batch: 3599. Acc: 0.475525. Loss: 1.458830. Batch_acc: 0.482132. Batch_loss: 1.433756 \n",
      "Batch: 3600. Acc: 0.475531. Loss: 1.458810. Batch_acc: 0.497691. Batch_loss: 1.385752 \n",
      "Batch: 3601. Acc: 0.475535. Loss: 1.458800. Batch_acc: 0.490855. Batch_loss: 1.423597 \n",
      "Batch: 3602. Acc: 0.475536. Loss: 1.458790. Batch_acc: 0.480047. Batch_loss: 1.421772 \n",
      "Batch: 3603. Acc: 0.475541. Loss: 1.458776. Batch_acc: 0.493536. Batch_loss: 1.409957 \n",
      "Batch: 3604. Acc: 0.475545. Loss: 1.458764. Batch_acc: 0.488523. Batch_loss: 1.414106 \n",
      "Batch: 3605. Acc: 0.475552. Loss: 1.458738. Batch_acc: 0.500887. Batch_loss: 1.363008 \n",
      "Batch: 3606. Acc: 0.475556. Loss: 1.458728. Batch_acc: 0.490952. Batch_loss: 1.421989 \n",
      "Batch: 3607. Acc: 0.475561. Loss: 1.458714. Batch_acc: 0.495968. Batch_loss: 1.406890 \n",
      "Batch: 3608. Acc: 0.475565. Loss: 1.458692. Batch_acc: 0.490096. Batch_loss: 1.381569 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3609. Acc: 0.475568. Loss: 1.458684. Batch_acc: 0.484706. Batch_loss: 1.430264 \n",
      "Batch: 3610. Acc: 0.475579. Loss: 1.458658. Batch_acc: 0.513360. Batch_loss: 1.364507 \n",
      "Batch: 3611. Acc: 0.475584. Loss: 1.458648. Batch_acc: 0.495662. Batch_loss: 1.423005 \n",
      "Batch: 3612. Acc: 0.475587. Loss: 1.458635. Batch_acc: 0.485536. Batch_loss: 1.410397 \n",
      "Batch: 3613. Acc: 0.475591. Loss: 1.458628. Batch_acc: 0.492424. Batch_loss: 1.432557 \n",
      "Batch: 3614. Acc: 0.475589. Loss: 1.458631. Batch_acc: 0.464706. Batch_loss: 1.469619 \n",
      "Batch: 3615. Acc: 0.475591. Loss: 1.458621. Batch_acc: 0.483432. Batch_loss: 1.421900 \n",
      "Batch: 3616. Acc: 0.475593. Loss: 1.458611. Batch_acc: 0.483699. Batch_loss: 1.424170 \n",
      "Batch: 3617. Acc: 0.475598. Loss: 1.458602. Batch_acc: 0.492861. Batch_loss: 1.425789 \n",
      "Batch: 3618. Acc: 0.475595. Loss: 1.458604. Batch_acc: 0.466589. Batch_loss: 1.465722 \n",
      "Batch: 3619. Acc: 0.475597. Loss: 1.458596. Batch_acc: 0.481172. Batch_loss: 1.426855 \n",
      "Batch: 3620. Acc: 0.475603. Loss: 1.458576. Batch_acc: 0.498003. Batch_loss: 1.386514 \n",
      "Batch: 3621. Acc: 0.475606. Loss: 1.458566. Batch_acc: 0.487108. Batch_loss: 1.424192 \n",
      "Batch: 3622. Acc: 0.475611. Loss: 1.458541. Batch_acc: 0.492272. Batch_loss: 1.367708 \n",
      "Batch: 3623. Acc: 0.475611. Loss: 1.458529. Batch_acc: 0.477535. Batch_loss: 1.414328 \n",
      "Batch: 3624. Acc: 0.475610. Loss: 1.458524. Batch_acc: 0.472385. Batch_loss: 1.442086 \n",
      "Batch: 3625. Acc: 0.475620. Loss: 1.458505. Batch_acc: 0.509576. Batch_loss: 1.388437 \n",
      "Batch: 3626. Acc: 0.475621. Loss: 1.458499. Batch_acc: 0.479977. Batch_loss: 1.438471 \n",
      "Batch: 3627. Acc: 0.475625. Loss: 1.458491. Batch_acc: 0.491046. Batch_loss: 1.426549 \n",
      "Batch: 3628. Acc: 0.475635. Loss: 1.458468. Batch_acc: 0.512806. Batch_loss: 1.373790 \n",
      "Batch: 3629. Acc: 0.475641. Loss: 1.458444. Batch_acc: 0.495940. Batch_loss: 1.373751 \n",
      "Batch: 3630. Acc: 0.475645. Loss: 1.458424. Batch_acc: 0.489784. Batch_loss: 1.386201 \n",
      "Batch: 3631. Acc: 0.475649. Loss: 1.458411. Batch_acc: 0.492403. Batch_loss: 1.412570 \n",
      "Batch: 3632. Acc: 0.475652. Loss: 1.458394. Batch_acc: 0.483705. Batch_loss: 1.395295 \n",
      "Batch: 3633. Acc: 0.475651. Loss: 1.458390. Batch_acc: 0.473832. Batch_loss: 1.446057 \n",
      "Batch: 3634. Acc: 0.475656. Loss: 1.458376. Batch_acc: 0.493425. Batch_loss: 1.404356 \n",
      "Batch: 3635. Acc: 0.475661. Loss: 1.458357. Batch_acc: 0.492599. Batch_loss: 1.389863 \n",
      "Batch: 3636. Acc: 0.475665. Loss: 1.458351. Batch_acc: 0.491061. Batch_loss: 1.435905 \n",
      "Batch: 3637. Acc: 0.475671. Loss: 1.458335. Batch_acc: 0.498853. Batch_loss: 1.399496 \n",
      "Batch: 3638. Acc: 0.475683. Loss: 1.458301. Batch_acc: 0.518023. Batch_loss: 1.333047 \n",
      "Batch: 3639. Acc: 0.475689. Loss: 1.458286. Batch_acc: 0.499154. Batch_loss: 1.404762 \n",
      "Batch: 3640. Acc: 0.475700. Loss: 1.458255. Batch_acc: 0.513158. Batch_loss: 1.349293 \n",
      "Batch: 3641. Acc: 0.475709. Loss: 1.458232. Batch_acc: 0.508595. Batch_loss: 1.371434 \n",
      "Batch: 3642. Acc: 0.475710. Loss: 1.458225. Batch_acc: 0.482245. Batch_loss: 1.430219 \n",
      "Batch: 3643. Acc: 0.475721. Loss: 1.458201. Batch_acc: 0.514673. Batch_loss: 1.374494 \n",
      "Batch: 3644. Acc: 0.475724. Loss: 1.458192. Batch_acc: 0.485062. Batch_loss: 1.424569 \n",
      "Batch: 3645. Acc: 0.475732. Loss: 1.458172. Batch_acc: 0.506636. Batch_loss: 1.383172 \n",
      "Batch: 3646. Acc: 0.475740. Loss: 1.458159. Batch_acc: 0.503968. Batch_loss: 1.411384 \n",
      "Batch: 3647. Acc: 0.475746. Loss: 1.458154. Batch_acc: 0.498574. Batch_loss: 1.440337 \n",
      "Batch: 3648. Acc: 0.475759. Loss: 1.458123. Batch_acc: 0.520989. Batch_loss: 1.348097 \n",
      "Batch: 3649. Acc: 0.475763. Loss: 1.458110. Batch_acc: 0.489290. Batch_loss: 1.410182 \n",
      "Batch: 3650. Acc: 0.475768. Loss: 1.458102. Batch_acc: 0.495511. Batch_loss: 1.428311 \n",
      "Batch: 3651. Acc: 0.475766. Loss: 1.458098. Batch_acc: 0.469087. Batch_loss: 1.443319 \n",
      "Batch: 3652. Acc: 0.475775. Loss: 1.458068. Batch_acc: 0.508883. Batch_loss: 1.350185 \n",
      "Batch: 3653. Acc: 0.475778. Loss: 1.458056. Batch_acc: 0.486286. Batch_loss: 1.414004 \n",
      "Batch: 3654. Acc: 0.475783. Loss: 1.458040. Batch_acc: 0.494568. Batch_loss: 1.401045 \n",
      "Batch: 3655. Acc: 0.475790. Loss: 1.458018. Batch_acc: 0.498024. Batch_loss: 1.378665 \n",
      "Batch: 3656. Acc: 0.475782. Loss: 1.458038. Batch_acc: 0.447066. Batch_loss: 1.532574 \n",
      "Batch: 3657. Acc: 0.475787. Loss: 1.458026. Batch_acc: 0.494259. Batch_loss: 1.414405 \n",
      "Batch: 3658. Acc: 0.475803. Loss: 1.457990. Batch_acc: 0.533141. Batch_loss: 1.323765 \n",
      "Batch: 3659. Acc: 0.475812. Loss: 1.457961. Batch_acc: 0.511481. Batch_loss: 1.354080 \n",
      "Batch: 3660. Acc: 0.475819. Loss: 1.457940. Batch_acc: 0.499714. Batch_loss: 1.380679 \n",
      "Batch: 3661. Acc: 0.475824. Loss: 1.457924. Batch_acc: 0.494259. Batch_loss: 1.399383 \n",
      "Batch: 3662. Acc: 0.475832. Loss: 1.457903. Batch_acc: 0.503704. Batch_loss: 1.381463 \n",
      "Batch: 3663. Acc: 0.475836. Loss: 1.457891. Batch_acc: 0.491066. Batch_loss: 1.415155 \n",
      "Batch: 3664. Acc: 0.475836. Loss: 1.457883. Batch_acc: 0.476163. Batch_loss: 1.428298 \n",
      "Batch: 3665. Acc: 0.475839. Loss: 1.457871. Batch_acc: 0.487651. Batch_loss: 1.413109 \n",
      "Batch: 3666. Acc: 0.475844. Loss: 1.457871. Batch_acc: 0.495078. Batch_loss: 1.456038 \n",
      "Batch: 3667. Acc: 0.475851. Loss: 1.457858. Batch_acc: 0.498855. Batch_loss: 1.411289 \n",
      "Batch: 3668. Acc: 0.475856. Loss: 1.457843. Batch_acc: 0.495095. Batch_loss: 1.403884 \n",
      "Batch: 3669. Acc: 0.475865. Loss: 1.457821. Batch_acc: 0.509477. Batch_loss: 1.376725 \n",
      "Batch: 3670. Acc: 0.475871. Loss: 1.457805. Batch_acc: 0.498231. Batch_loss: 1.396891 \n",
      "Batch: 3671. Acc: 0.475881. Loss: 1.457790. Batch_acc: 0.512004. Batch_loss: 1.405538 \n",
      "Batch: 3672. Acc: 0.475884. Loss: 1.457789. Batch_acc: 0.485277. Batch_loss: 1.452151 \n",
      "Batch: 3673. Acc: 0.475878. Loss: 1.457797. Batch_acc: 0.454968. Batch_loss: 1.487327 \n",
      "Batch: 3674. Acc: 0.475887. Loss: 1.457764. Batch_acc: 0.507279. Batch_loss: 1.341806 \n",
      "Batch: 3675. Acc: 0.475889. Loss: 1.457763. Batch_acc: 0.485431. Batch_loss: 1.452177 \n",
      "Batch: 3676. Acc: 0.475899. Loss: 1.457743. Batch_acc: 0.510700. Batch_loss: 1.386394 \n",
      "Batch: 3677. Acc: 0.475902. Loss: 1.457746. Batch_acc: 0.486659. Batch_loss: 1.466484 \n",
      "Batch: 3678. Acc: 0.475909. Loss: 1.457727. Batch_acc: 0.502914. Batch_loss: 1.388019 \n",
      "Batch: 3679. Acc: 0.475919. Loss: 1.457707. Batch_acc: 0.514891. Batch_loss: 1.383777 \n",
      "Batch: 3680. Acc: 0.475922. Loss: 1.457698. Batch_acc: 0.487365. Batch_loss: 1.422988 \n",
      "Batch: 3681. Acc: 0.475931. Loss: 1.457677. Batch_acc: 0.505922. Batch_loss: 1.382898 \n",
      "Batch: 3682. Acc: 0.475938. Loss: 1.457658. Batch_acc: 0.503964. Batch_loss: 1.387153 \n",
      "Batch: 3683. Acc: 0.475940. Loss: 1.457656. Batch_acc: 0.480689. Batch_loss: 1.449408 \n",
      "Batch: 3684. Acc: 0.475948. Loss: 1.457639. Batch_acc: 0.505495. Batch_loss: 1.397634 \n",
      "Batch: 3685. Acc: 0.475952. Loss: 1.457632. Batch_acc: 0.490424. Batch_loss: 1.429819 \n",
      "Batch: 3686. Acc: 0.475958. Loss: 1.457606. Batch_acc: 0.499713. Batch_loss: 1.361031 \n",
      "Batch: 3687. Acc: 0.475965. Loss: 1.457591. Batch_acc: 0.500000. Batch_loss: 1.403496 \n",
      "Batch: 3688. Acc: 0.475972. Loss: 1.457573. Batch_acc: 0.502222. Batch_loss: 1.395505 \n",
      "Batch: 3689. Acc: 0.475976. Loss: 1.457563. Batch_acc: 0.492398. Batch_loss: 1.417755 \n",
      "Batch: 3690. Acc: 0.475980. Loss: 1.457558. Batch_acc: 0.489374. Batch_loss: 1.438437 \n",
      "Batch: 3691. Acc: 0.475988. Loss: 1.457543. Batch_acc: 0.505364. Batch_loss: 1.404597 \n",
      "Batch: 3692. Acc: 0.475993. Loss: 1.457528. Batch_acc: 0.493372. Batch_loss: 1.400779 \n",
      "Batch: 3693. Acc: 0.475996. Loss: 1.457517. Batch_acc: 0.487032. Batch_loss: 1.417055 \n",
      "Batch: 3694. Acc: 0.475997. Loss: 1.457512. Batch_acc: 0.479954. Batch_loss: 1.438196 \n",
      "Batch: 3695. Acc: 0.475994. Loss: 1.457516. Batch_acc: 0.465786. Batch_loss: 1.473498 \n",
      "Batch: 3696. Acc: 0.476001. Loss: 1.457501. Batch_acc: 0.500863. Batch_loss: 1.404589 \n",
      "Batch: 3697. Acc: 0.476008. Loss: 1.457477. Batch_acc: 0.501421. Batch_loss: 1.368983 \n",
      "Batch: 3698. Acc: 0.476009. Loss: 1.457467. Batch_acc: 0.481693. Batch_loss: 1.421577 \n",
      "Batch: 3699. Acc: 0.476011. Loss: 1.457464. Batch_acc: 0.481570. Batch_loss: 1.442874 \n",
      "Batch: 3700. Acc: 0.476012. Loss: 1.457455. Batch_acc: 0.481808. Batch_loss: 1.425654 \n",
      "Batch: 3701. Acc: 0.476018. Loss: 1.457444. Batch_acc: 0.495687. Batch_loss: 1.414431 \n",
      "Batch: 3702. Acc: 0.476030. Loss: 1.457413. Batch_acc: 0.519384. Batch_loss: 1.345607 \n",
      "Batch: 3703. Acc: 0.476036. Loss: 1.457396. Batch_acc: 0.498860. Batch_loss: 1.394570 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3704. Acc: 0.476043. Loss: 1.457379. Batch_acc: 0.501142. Batch_loss: 1.395025 \n",
      "Batch: 3705. Acc: 0.476048. Loss: 1.457358. Batch_acc: 0.494562. Batch_loss: 1.379653 \n",
      "Batch: 3706. Acc: 0.476054. Loss: 1.457333. Batch_acc: 0.499711. Batch_loss: 1.366347 \n",
      "Batch: 3707. Acc: 0.476056. Loss: 1.457331. Batch_acc: 0.484778. Batch_loss: 1.449452 \n",
      "Batch: 3708. Acc: 0.476062. Loss: 1.457319. Batch_acc: 0.497412. Batch_loss: 1.411195 \n",
      "Batch: 3709. Acc: 0.476071. Loss: 1.457290. Batch_acc: 0.510553. Batch_loss: 1.351807 \n",
      "Batch: 3710. Acc: 0.476073. Loss: 1.457290. Batch_acc: 0.482225. Batch_loss: 1.456481 \n",
      "Batch: 3711. Acc: 0.476079. Loss: 1.457274. Batch_acc: 0.497677. Batch_loss: 1.397245 \n",
      "Batch: 3712. Acc: 0.476080. Loss: 1.457269. Batch_acc: 0.480248. Batch_loss: 1.440241 \n",
      "Batch: 3713. Acc: 0.476087. Loss: 1.457245. Batch_acc: 0.502874. Batch_loss: 1.368571 \n",
      "Batch: 3714. Acc: 0.476096. Loss: 1.457216. Batch_acc: 0.507471. Batch_loss: 1.348576 \n",
      "Batch: 3715. Acc: 0.476104. Loss: 1.457192. Batch_acc: 0.506066. Batch_loss: 1.368744 \n",
      "Batch: 3716. Acc: 0.476108. Loss: 1.457178. Batch_acc: 0.491719. Batch_loss: 1.404824 \n",
      "Batch: 3717. Acc: 0.476116. Loss: 1.457158. Batch_acc: 0.504303. Batch_loss: 1.382727 \n",
      "Batch: 3718. Acc: 0.476125. Loss: 1.457132. Batch_acc: 0.510029. Batch_loss: 1.361083 \n",
      "Batch: 3719. Acc: 0.476125. Loss: 1.457124. Batch_acc: 0.479059. Batch_loss: 1.425875 \n",
      "Batch: 3720. Acc: 0.476132. Loss: 1.457108. Batch_acc: 0.498852. Batch_loss: 1.397480 \n",
      "Batch: 3721. Acc: 0.476139. Loss: 1.457095. Batch_acc: 0.501999. Batch_loss: 1.409395 \n",
      "Batch: 3722. Acc: 0.476144. Loss: 1.457079. Batch_acc: 0.495897. Batch_loss: 1.397356 \n",
      "Batch: 3723. Acc: 0.476148. Loss: 1.457066. Batch_acc: 0.490093. Batch_loss: 1.408027 \n",
      "Batch: 3724. Acc: 0.476150. Loss: 1.457054. Batch_acc: 0.486408. Batch_loss: 1.412266 \n",
      "Batch: 3725. Acc: 0.476165. Loss: 1.457019. Batch_acc: 0.530079. Batch_loss: 1.328013 \n",
      "Batch: 3726. Acc: 0.476170. Loss: 1.457003. Batch_acc: 0.493990. Batch_loss: 1.398767 \n",
      "Batch: 3727. Acc: 0.476174. Loss: 1.456993. Batch_acc: 0.490401. Batch_loss: 1.417179 \n",
      "Batch: 3728. Acc: 0.476174. Loss: 1.456986. Batch_acc: 0.476302. Batch_loss: 1.431556 \n",
      "Batch: 3729. Acc: 0.476177. Loss: 1.456971. Batch_acc: 0.489055. Batch_loss: 1.401455 \n",
      "Batch: 3730. Acc: 0.476183. Loss: 1.456947. Batch_acc: 0.497156. Batch_loss: 1.369713 \n",
      "Batch: 3731. Acc: 0.476189. Loss: 1.456929. Batch_acc: 0.500285. Batch_loss: 1.388461 \n",
      "Batch: 3732. Acc: 0.476197. Loss: 1.456908. Batch_acc: 0.503662. Batch_loss: 1.379326 \n",
      "Batch: 3733. Acc: 0.476198. Loss: 1.456901. Batch_acc: 0.480278. Batch_loss: 1.429873 \n",
      "Batch: 3734. Acc: 0.476204. Loss: 1.456881. Batch_acc: 0.500292. Batch_loss: 1.383261 \n",
      "Batch: 3735. Acc: 0.476208. Loss: 1.456876. Batch_acc: 0.491870. Batch_loss: 1.438208 \n",
      "Batch: 3736. Acc: 0.476213. Loss: 1.456859. Batch_acc: 0.495123. Batch_loss: 1.394385 \n",
      "Batch: 3737. Acc: 0.476219. Loss: 1.456849. Batch_acc: 0.495930. Batch_loss: 1.415935 \n",
      "Batch: 3738. Acc: 0.476228. Loss: 1.456825. Batch_acc: 0.512571. Batch_loss: 1.369102 \n",
      "Batch: 3739. Acc: 0.476238. Loss: 1.456797. Batch_acc: 0.513452. Batch_loss: 1.352671 \n",
      "Batch: 3740. Acc: 0.476243. Loss: 1.456783. Batch_acc: 0.493410. Batch_loss: 1.406211 \n",
      "Batch: 3741. Acc: 0.476249. Loss: 1.456759. Batch_acc: 0.497719. Batch_loss: 1.368145 \n",
      "Batch: 3742. Acc: 0.476250. Loss: 1.456757. Batch_acc: 0.480916. Batch_loss: 1.446200 \n",
      "Batch: 3743. Acc: 0.476252. Loss: 1.456748. Batch_acc: 0.483568. Batch_loss: 1.424086 \n",
      "Batch: 3744. Acc: 0.476259. Loss: 1.456727. Batch_acc: 0.502361. Batch_loss: 1.376455 \n",
      "Batch: 3745. Acc: 0.476262. Loss: 1.456709. Batch_acc: 0.487209. Batch_loss: 1.388903 \n",
      "Batch: 3746. Acc: 0.476277. Loss: 1.456677. Batch_acc: 0.532658. Batch_loss: 1.337270 \n",
      "Batch: 3747. Acc: 0.476290. Loss: 1.456644. Batch_acc: 0.523945. Batch_loss: 1.334497 \n",
      "Batch: 3748. Acc: 0.476299. Loss: 1.456614. Batch_acc: 0.510725. Batch_loss: 1.344329 \n",
      "Batch: 3749. Acc: 0.476314. Loss: 1.456580. Batch_acc: 0.530430. Batch_loss: 1.331387 \n",
      "Batch: 3750. Acc: 0.476312. Loss: 1.456576. Batch_acc: 0.467617. Batch_loss: 1.443246 \n",
      "Batch: 3751. Acc: 0.476320. Loss: 1.456556. Batch_acc: 0.507188. Batch_loss: 1.380824 \n",
      "Batch: 3752. Acc: 0.476323. Loss: 1.456549. Batch_acc: 0.488439. Batch_loss: 1.431655 \n",
      "Batch: 3753. Acc: 0.476331. Loss: 1.456529. Batch_acc: 0.506366. Batch_loss: 1.378912 \n",
      "Batch: 3754. Acc: 0.476335. Loss: 1.456514. Batch_acc: 0.491516. Batch_loss: 1.399166 \n",
      "Batch: 3755. Acc: 0.476337. Loss: 1.456506. Batch_acc: 0.485698. Batch_loss: 1.427807 \n",
      "Batch: 3756. Acc: 0.476343. Loss: 1.456487. Batch_acc: 0.499404. Batch_loss: 1.381241 \n",
      "Batch: 3757. Acc: 0.476344. Loss: 1.456482. Batch_acc: 0.478109. Batch_loss: 1.437938 \n",
      "Batch: 3758. Acc: 0.476353. Loss: 1.456461. Batch_acc: 0.511732. Batch_loss: 1.378446 \n",
      "Batch: 3759. Acc: 0.476361. Loss: 1.456442. Batch_acc: 0.505275. Batch_loss: 1.383684 \n",
      "Batch: 3760. Acc: 0.476369. Loss: 1.456421. Batch_acc: 0.505334. Batch_loss: 1.381155 \n",
      "Batch: 3761. Acc: 0.476371. Loss: 1.456411. Batch_acc: 0.484571. Batch_loss: 1.416667 \n",
      "Batch: 3762. Acc: 0.476366. Loss: 1.456418. Batch_acc: 0.455504. Batch_loss: 1.483266 \n",
      "Batch: 3763. Acc: 0.476373. Loss: 1.456390. Batch_acc: 0.501979. Batch_loss: 1.354854 \n",
      "Batch: 3764. Acc: 0.476381. Loss: 1.456364. Batch_acc: 0.508903. Batch_loss: 1.356019 \n",
      "Batch: 3765. Acc: 0.476385. Loss: 1.456358. Batch_acc: 0.491486. Batch_loss: 1.436631 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.4763851847144636. Loss per char: 1.4563583736929078. Time: 1627217096.1729047\n",
      "Last question is tensor([ 2, 53, 80, 85, 66, 77,  1, 80, 71,  1, 17, 15, 17, 25,  1, 66, 79, 69,\n",
      "         1, 17, 15, 18, 26, 23, 24, 21, 24, 25, 24, 26, 18, 21, 23, 25, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.476383. Loss: 1.456354. Batch_acc: 0.468304. Batch_loss: 1.441500 \n",
      "Batch: 3767. Acc: 0.476388. Loss: 1.456331. Batch_acc: 0.495444. Batch_loss: 1.367332 \n",
      "Batch: 3768. Acc: 0.476390. Loss: 1.456321. Batch_acc: 0.484113. Batch_loss: 1.420326 \n",
      "Batch: 3769. Acc: 0.476387. Loss: 1.456321. Batch_acc: 0.464101. Batch_loss: 1.456921 \n",
      "Batch: 3770. Acc: 0.476389. Loss: 1.456308. Batch_acc: 0.483833. Batch_loss: 1.404101 \n",
      "Batch: 3771. Acc: 0.476385. Loss: 1.456316. Batch_acc: 0.460648. Batch_loss: 1.487513 \n",
      "Batch: 3772. Acc: 0.476392. Loss: 1.456290. Batch_acc: 0.505425. Batch_loss: 1.360165 \n",
      "Batch: 3773. Acc: 0.476395. Loss: 1.456276. Batch_acc: 0.485448. Batch_loss: 1.402350 \n",
      "Batch: 3774. Acc: 0.476396. Loss: 1.456269. Batch_acc: 0.479320. Batch_loss: 1.428232 \n",
      "Batch: 3775. Acc: 0.476400. Loss: 1.456252. Batch_acc: 0.491784. Batch_loss: 1.392436 \n",
      "Batch: 3776. Acc: 0.476407. Loss: 1.456229. Batch_acc: 0.504005. Batch_loss: 1.371676 \n",
      "Batch: 3777. Acc: 0.476415. Loss: 1.456208. Batch_acc: 0.508416. Batch_loss: 1.376230 \n",
      "Batch: 3778. Acc: 0.476424. Loss: 1.456185. Batch_acc: 0.507991. Batch_loss: 1.367993 \n",
      "Batch: 3779. Acc: 0.476426. Loss: 1.456172. Batch_acc: 0.484776. Batch_loss: 1.406006 \n",
      "Batch: 3780. Acc: 0.476426. Loss: 1.456166. Batch_acc: 0.475830. Batch_loss: 1.433644 \n",
      "Batch: 3781. Acc: 0.476424. Loss: 1.456164. Batch_acc: 0.470857. Batch_loss: 1.448287 \n",
      "Batch: 3782. Acc: 0.476428. Loss: 1.456151. Batch_acc: 0.490468. Batch_loss: 1.407264 \n",
      "Batch: 3783. Acc: 0.476437. Loss: 1.456127. Batch_acc: 0.508965. Batch_loss: 1.363445 \n",
      "Batch: 3784. Acc: 0.476447. Loss: 1.456095. Batch_acc: 0.516351. Batch_loss: 1.336872 \n",
      "Batch: 3785. Acc: 0.476446. Loss: 1.456093. Batch_acc: 0.472695. Batch_loss: 1.446667 \n",
      "Batch: 3786. Acc: 0.476450. Loss: 1.456082. Batch_acc: 0.491269. Batch_loss: 1.416321 \n",
      "Batch: 3787. Acc: 0.476447. Loss: 1.456095. Batch_acc: 0.466476. Batch_loss: 1.501951 \n",
      "Batch: 3788. Acc: 0.476441. Loss: 1.456102. Batch_acc: 0.451465. Batch_loss: 1.482746 \n",
      "Batch: 3789. Acc: 0.476448. Loss: 1.456078. Batch_acc: 0.504630. Batch_loss: 1.366985 \n",
      "Batch: 3790. Acc: 0.476451. Loss: 1.456076. Batch_acc: 0.487920. Batch_loss: 1.448172 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3791. Acc: 0.476453. Loss: 1.456072. Batch_acc: 0.485404. Batch_loss: 1.438733 \n",
      "Batch: 3792. Acc: 0.476460. Loss: 1.456048. Batch_acc: 0.500000. Batch_loss: 1.366479 \n",
      "Batch: 3793. Acc: 0.476463. Loss: 1.456023. Batch_acc: 0.490719. Batch_loss: 1.363196 \n",
      "Batch: 3794. Acc: 0.476464. Loss: 1.456007. Batch_acc: 0.478996. Batch_loss: 1.394424 \n",
      "Batch: 3795. Acc: 0.476460. Loss: 1.456007. Batch_acc: 0.460733. Batch_loss: 1.453806 \n",
      "Batch: 3796. Acc: 0.476466. Loss: 1.455987. Batch_acc: 0.497453. Batch_loss: 1.381936 \n",
      "Batch: 3797. Acc: 0.476465. Loss: 1.455980. Batch_acc: 0.473891. Batch_loss: 1.429004 \n",
      "Batch: 3798. Acc: 0.476471. Loss: 1.455958. Batch_acc: 0.500288. Batch_loss: 1.371797 \n",
      "Batch: 3799. Acc: 0.476479. Loss: 1.455937. Batch_acc: 0.504614. Batch_loss: 1.378863 \n",
      "Batch: 3800. Acc: 0.476483. Loss: 1.455923. Batch_acc: 0.493834. Batch_loss: 1.404489 \n",
      "Batch: 3801. Acc: 0.476498. Loss: 1.455884. Batch_acc: 0.532558. Batch_loss: 1.304348 \n",
      "Batch: 3802. Acc: 0.476500. Loss: 1.455876. Batch_acc: 0.484136. Batch_loss: 1.425819 \n",
      "Batch: 3803. Acc: 0.476502. Loss: 1.455867. Batch_acc: 0.485143. Batch_loss: 1.419262 \n",
      "Batch: 3804. Acc: 0.476508. Loss: 1.455857. Batch_acc: 0.498324. Batch_loss: 1.422292 \n",
      "Batch: 3805. Acc: 0.476509. Loss: 1.455856. Batch_acc: 0.480527. Batch_loss: 1.451625 \n",
      "Batch: 3806. Acc: 0.476511. Loss: 1.455847. Batch_acc: 0.481731. Batch_loss: 1.421006 \n",
      "Batch: 3807. Acc: 0.476513. Loss: 1.455833. Batch_acc: 0.485599. Batch_loss: 1.404272 \n",
      "Batch: 3808. Acc: 0.476517. Loss: 1.455817. Batch_acc: 0.491128. Batch_loss: 1.394384 \n",
      "Batch: 3809. Acc: 0.476520. Loss: 1.455803. Batch_acc: 0.488239. Batch_loss: 1.400782 \n",
      "Batch: 3810. Acc: 0.476525. Loss: 1.455784. Batch_acc: 0.494983. Batch_loss: 1.386863 \n",
      "Batch: 3811. Acc: 0.476532. Loss: 1.455767. Batch_acc: 0.501985. Batch_loss: 1.392511 \n",
      "Batch: 3812. Acc: 0.476531. Loss: 1.455768. Batch_acc: 0.475236. Batch_loss: 1.457531 \n",
      "Batch: 3813. Acc: 0.476537. Loss: 1.455749. Batch_acc: 0.500289. Batch_loss: 1.385196 \n",
      "Batch: 3814. Acc: 0.476544. Loss: 1.455738. Batch_acc: 0.499712. Batch_loss: 1.412397 \n",
      "Batch: 3815. Acc: 0.476542. Loss: 1.455732. Batch_acc: 0.469423. Batch_loss: 1.433141 \n",
      "Batch: 3816. Acc: 0.476549. Loss: 1.455714. Batch_acc: 0.505552. Batch_loss: 1.384103 \n",
      "Batch: 3817. Acc: 0.476554. Loss: 1.455694. Batch_acc: 0.496475. Batch_loss: 1.380088 \n",
      "Batch: 3818. Acc: 0.476558. Loss: 1.455684. Batch_acc: 0.489374. Batch_loss: 1.416615 \n",
      "Batch: 3819. Acc: 0.476565. Loss: 1.455661. Batch_acc: 0.503977. Batch_loss: 1.367315 \n",
      "Batch: 3820. Acc: 0.476568. Loss: 1.455656. Batch_acc: 0.486395. Batch_loss: 1.437861 \n",
      "Batch: 3821. Acc: 0.476576. Loss: 1.455638. Batch_acc: 0.509357. Batch_loss: 1.385926 \n",
      "Batch: 3822. Acc: 0.476584. Loss: 1.455615. Batch_acc: 0.505482. Batch_loss: 1.368594 \n",
      "Batch: 3823. Acc: 0.476585. Loss: 1.455609. Batch_acc: 0.482100. Batch_loss: 1.431238 \n",
      "Batch: 3824. Acc: 0.476588. Loss: 1.455602. Batch_acc: 0.486674. Batch_loss: 1.429603 \n",
      "Batch: 3825. Acc: 0.476595. Loss: 1.455590. Batch_acc: 0.504587. Batch_loss: 1.407391 \n",
      "Batch: 3826. Acc: 0.476607. Loss: 1.455558. Batch_acc: 0.521079. Batch_loss: 1.337503 \n",
      "Batch: 3827. Acc: 0.476617. Loss: 1.455528. Batch_acc: 0.515634. Batch_loss: 1.341769 \n",
      "Batch: 3828. Acc: 0.476625. Loss: 1.455500. Batch_acc: 0.507763. Batch_loss: 1.349452 \n",
      "Batch: 3829. Acc: 0.476634. Loss: 1.455476. Batch_acc: 0.508367. Batch_loss: 1.361571 \n",
      "Batch: 3830. Acc: 0.476632. Loss: 1.455478. Batch_acc: 0.471437. Batch_loss: 1.464213 \n",
      "Batch: 3831. Acc: 0.476638. Loss: 1.455464. Batch_acc: 0.499426. Batch_loss: 1.400733 \n",
      "Batch: 3832. Acc: 0.476641. Loss: 1.455458. Batch_acc: 0.486690. Batch_loss: 1.434383 \n",
      "Batch: 3833. Acc: 0.476649. Loss: 1.455445. Batch_acc: 0.507114. Batch_loss: 1.403247 \n",
      "Batch: 3834. Acc: 0.476655. Loss: 1.455422. Batch_acc: 0.500562. Batch_loss: 1.370381 \n",
      "Batch: 3835. Acc: 0.476663. Loss: 1.455398. Batch_acc: 0.506450. Batch_loss: 1.365603 \n",
      "Batch: 3836. Acc: 0.476668. Loss: 1.455390. Batch_acc: 0.496536. Batch_loss: 1.425631 \n",
      "Batch: 3837. Acc: 0.476678. Loss: 1.455361. Batch_acc: 0.512251. Batch_loss: 1.345508 \n",
      "Batch: 3838. Acc: 0.476674. Loss: 1.455364. Batch_acc: 0.463327. Batch_loss: 1.465193 \n",
      "Batch: 3839. Acc: 0.476678. Loss: 1.455353. Batch_acc: 0.492394. Batch_loss: 1.414220 \n",
      "Batch: 3840. Acc: 0.476689. Loss: 1.455322. Batch_acc: 0.515033. Batch_loss: 1.341487 \n",
      "Batch: 3841. Acc: 0.476695. Loss: 1.455309. Batch_acc: 0.500286. Batch_loss: 1.403490 \n",
      "Batch: 3842. Acc: 0.476706. Loss: 1.455273. Batch_acc: 0.518705. Batch_loss: 1.323275 \n",
      "Batch: 3843. Acc: 0.476712. Loss: 1.455260. Batch_acc: 0.497966. Batch_loss: 1.406006 \n",
      "Batch: 3844. Acc: 0.476713. Loss: 1.455257. Batch_acc: 0.482153. Batch_loss: 1.442036 \n",
      "Batch: 3845. Acc: 0.476722. Loss: 1.455234. Batch_acc: 0.510216. Batch_loss: 1.364135 \n",
      "Batch: 3846. Acc: 0.476730. Loss: 1.455202. Batch_acc: 0.508782. Batch_loss: 1.336183 \n",
      "Batch: 3847. Acc: 0.476738. Loss: 1.455187. Batch_acc: 0.506381. Batch_loss: 1.396655 \n",
      "Batch: 3848. Acc: 0.476745. Loss: 1.455167. Batch_acc: 0.504060. Batch_loss: 1.375888 \n",
      "Batch: 3849. Acc: 0.476747. Loss: 1.455160. Batch_acc: 0.486408. Batch_loss: 1.428305 \n",
      "Batch: 3850. Acc: 0.476757. Loss: 1.455131. Batch_acc: 0.513687. Batch_loss: 1.341178 \n",
      "Batch: 3851. Acc: 0.476759. Loss: 1.455120. Batch_acc: 0.486941. Batch_loss: 1.413323 \n",
      "Batch: 3852. Acc: 0.476765. Loss: 1.455106. Batch_acc: 0.499698. Batch_loss: 1.400348 \n",
      "Batch: 3853. Acc: 0.476771. Loss: 1.455104. Batch_acc: 0.498564. Batch_loss: 1.444472 \n",
      "Batch: 3854. Acc: 0.476777. Loss: 1.455088. Batch_acc: 0.500000. Batch_loss: 1.394712 \n",
      "Batch: 3855. Acc: 0.476779. Loss: 1.455071. Batch_acc: 0.483597. Batch_loss: 1.391482 \n",
      "Batch: 3856. Acc: 0.476779. Loss: 1.455074. Batch_acc: 0.479444. Batch_loss: 1.466237 \n",
      "Batch: 3857. Acc: 0.476788. Loss: 1.455048. Batch_acc: 0.510006. Batch_loss: 1.355987 \n",
      "Batch: 3858. Acc: 0.476796. Loss: 1.455032. Batch_acc: 0.506215. Batch_loss: 1.395334 \n",
      "Batch: 3859. Acc: 0.476801. Loss: 1.455017. Batch_acc: 0.496544. Batch_loss: 1.394898 \n",
      "Batch: 3860. Acc: 0.476801. Loss: 1.455020. Batch_acc: 0.478261. Batch_loss: 1.467710 \n",
      "Batch: 3861. Acc: 0.476802. Loss: 1.455014. Batch_acc: 0.479492. Batch_loss: 1.431497 \n",
      "Batch: 3862. Acc: 0.476805. Loss: 1.455009. Batch_acc: 0.487434. Batch_loss: 1.436740 \n",
      "Batch: 3863. Acc: 0.476814. Loss: 1.454991. Batch_acc: 0.510998. Batch_loss: 1.386208 \n",
      "Batch: 3864. Acc: 0.476814. Loss: 1.454985. Batch_acc: 0.478261. Batch_loss: 1.429786 \n",
      "Batch: 3865. Acc: 0.476816. Loss: 1.454976. Batch_acc: 0.485599. Batch_loss: 1.420378 \n",
      "Batch: 3866. Acc: 0.476819. Loss: 1.454966. Batch_acc: 0.488385. Batch_loss: 1.418988 \n",
      "Batch: 3867. Acc: 0.476827. Loss: 1.454941. Batch_acc: 0.505800. Batch_loss: 1.358179 \n",
      "Batch: 3868. Acc: 0.476835. Loss: 1.454919. Batch_acc: 0.508824. Batch_loss: 1.365454 \n",
      "Batch: 3869. Acc: 0.476841. Loss: 1.454911. Batch_acc: 0.502339. Batch_loss: 1.423513 \n",
      "Batch: 3870. Acc: 0.476847. Loss: 1.454893. Batch_acc: 0.498857. Batch_loss: 1.385104 \n",
      "Batch: 3871. Acc: 0.476852. Loss: 1.454878. Batch_acc: 0.496877. Batch_loss: 1.398253 \n",
      "Batch: 3872. Acc: 0.476863. Loss: 1.454858. Batch_acc: 0.517499. Batch_loss: 1.379845 \n",
      "Batch: 3873. Acc: 0.476866. Loss: 1.454851. Batch_acc: 0.488584. Batch_loss: 1.426576 \n",
      "Batch: 3874. Acc: 0.476871. Loss: 1.454835. Batch_acc: 0.498239. Batch_loss: 1.392709 \n",
      "Batch: 3875. Acc: 0.476879. Loss: 1.454816. Batch_acc: 0.507213. Batch_loss: 1.381367 \n",
      "Batch: 3876. Acc: 0.476885. Loss: 1.454804. Batch_acc: 0.498861. Batch_loss: 1.408904 \n",
      "Batch: 3877. Acc: 0.476888. Loss: 1.454791. Batch_acc: 0.488603. Batch_loss: 1.403804 \n",
      "Batch: 3878. Acc: 0.476897. Loss: 1.454775. Batch_acc: 0.512658. Batch_loss: 1.391768 \n",
      "Batch: 3879. Acc: 0.476901. Loss: 1.454764. Batch_acc: 0.490468. Batch_loss: 1.410779 \n",
      "Batch: 3880. Acc: 0.476901. Loss: 1.454759. Batch_acc: 0.477140. Batch_loss: 1.433717 \n",
      "Batch: 3881. Acc: 0.476907. Loss: 1.454734. Batch_acc: 0.502609. Batch_loss: 1.360370 \n",
      "Batch: 3882. Acc: 0.476913. Loss: 1.454728. Batch_acc: 0.498282. Batch_loss: 1.430135 \n",
      "Batch: 3883. Acc: 0.476917. Loss: 1.454724. Batch_acc: 0.495627. Batch_loss: 1.437074 \n",
      "Batch: 3884. Acc: 0.476917. Loss: 1.454708. Batch_acc: 0.474197. Batch_loss: 1.392356 \n",
      "Batch: 3885. Acc: 0.476919. Loss: 1.454701. Batch_acc: 0.487676. Batch_loss: 1.428028 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3886. Acc: 0.476923. Loss: 1.454684. Batch_acc: 0.490971. Batch_loss: 1.392202 \n",
      "Batch: 3887. Acc: 0.476928. Loss: 1.454671. Batch_acc: 0.495434. Batch_loss: 1.403327 \n",
      "Batch: 3888. Acc: 0.476929. Loss: 1.454668. Batch_acc: 0.482584. Batch_loss: 1.443655 \n",
      "Batch: 3889. Acc: 0.476935. Loss: 1.454652. Batch_acc: 0.498878. Batch_loss: 1.392608 \n",
      "Batch: 3890. Acc: 0.476939. Loss: 1.454633. Batch_acc: 0.492486. Batch_loss: 1.382392 \n",
      "Batch: 3891. Acc: 0.476940. Loss: 1.454634. Batch_acc: 0.480903. Batch_loss: 1.455644 \n",
      "Batch: 3892. Acc: 0.476952. Loss: 1.454599. Batch_acc: 0.523140. Batch_loss: 1.317803 \n",
      "Batch: 3893. Acc: 0.476954. Loss: 1.454587. Batch_acc: 0.486655. Batch_loss: 1.409040 \n",
      "Batch: 3894. Acc: 0.476961. Loss: 1.454573. Batch_acc: 0.500862. Batch_loss: 1.399436 \n",
      "Batch: 3895. Acc: 0.476967. Loss: 1.454548. Batch_acc: 0.500000. Batch_loss: 1.361069 \n",
      "Batch: 3896. Acc: 0.476974. Loss: 1.454538. Batch_acc: 0.505643. Batch_loss: 1.415699 \n",
      "Batch: 3897. Acc: 0.476980. Loss: 1.454522. Batch_acc: 0.498537. Batch_loss: 1.391839 \n",
      "Batch: 3898. Acc: 0.476979. Loss: 1.454518. Batch_acc: 0.476326. Batch_loss: 1.438671 \n",
      "Batch: 3899. Acc: 0.476976. Loss: 1.454528. Batch_acc: 0.464245. Batch_loss: 1.492542 \n",
      "Batch: 3900. Acc: 0.476983. Loss: 1.454507. Batch_acc: 0.502561. Batch_loss: 1.372930 \n",
      "Batch: 3901. Acc: 0.476989. Loss: 1.454491. Batch_acc: 0.502870. Batch_loss: 1.394380 \n",
      "Batch: 3902. Acc: 0.476992. Loss: 1.454479. Batch_acc: 0.487874. Batch_loss: 1.408539 \n",
      "Batch: 3903. Acc: 0.476995. Loss: 1.454466. Batch_acc: 0.486233. Batch_loss: 1.402462 \n",
      "Batch: 3904. Acc: 0.477001. Loss: 1.454447. Batch_acc: 0.504018. Batch_loss: 1.378272 \n",
      "Batch: 3905. Acc: 0.477005. Loss: 1.454435. Batch_acc: 0.489571. Batch_loss: 1.408936 \n",
      "Batch: 3906. Acc: 0.477007. Loss: 1.454425. Batch_acc: 0.487059. Batch_loss: 1.413123 \n",
      "Batch: 3907. Acc: 0.477012. Loss: 1.454414. Batch_acc: 0.497251. Batch_loss: 1.408390 \n",
      "Batch: 3908. Acc: 0.477015. Loss: 1.454406. Batch_acc: 0.487076. Batch_loss: 1.425175 \n",
      "Batch: 3909. Acc: 0.477021. Loss: 1.454394. Batch_acc: 0.501689. Batch_loss: 1.408524 \n",
      "Batch: 3910. Acc: 0.477020. Loss: 1.454394. Batch_acc: 0.473225. Batch_loss: 1.452373 \n",
      "Batch: 3911. Acc: 0.477023. Loss: 1.454385. Batch_acc: 0.489808. Batch_loss: 1.420733 \n",
      "Batch: 3912. Acc: 0.477033. Loss: 1.454370. Batch_acc: 0.514061. Batch_loss: 1.397110 \n",
      "Batch: 3913. Acc: 0.477034. Loss: 1.454376. Batch_acc: 0.480392. Batch_loss: 1.476339 \n",
      "Batch: 3914. Acc: 0.477039. Loss: 1.454364. Batch_acc: 0.496027. Batch_loss: 1.410013 \n",
      "Batch: 3915. Acc: 0.477048. Loss: 1.454339. Batch_acc: 0.512605. Batch_loss: 1.356214 \n",
      "Batch: 3916. Acc: 0.477053. Loss: 1.454329. Batch_acc: 0.496855. Batch_loss: 1.416262 \n",
      "Batch: 3917. Acc: 0.477057. Loss: 1.454317. Batch_acc: 0.493470. Batch_loss: 1.408852 \n",
      "Batch: 3918. Acc: 0.477060. Loss: 1.454309. Batch_acc: 0.486440. Batch_loss: 1.420953 \n",
      "Batch: 3919. Acc: 0.477069. Loss: 1.454277. Batch_acc: 0.514105. Batch_loss: 1.329196 \n",
      "Batch: 3920. Acc: 0.477071. Loss: 1.454278. Batch_acc: 0.482659. Batch_loss: 1.457835 \n",
      "Batch: 3921. Acc: 0.477073. Loss: 1.454273. Batch_acc: 0.484691. Batch_loss: 1.437178 \n",
      "Batch: 3922. Acc: 0.477074. Loss: 1.454266. Batch_acc: 0.482069. Batch_loss: 1.424414 \n",
      "Batch: 3923. Acc: 0.477081. Loss: 1.454246. Batch_acc: 0.504358. Batch_loss: 1.376690 \n",
      "Batch: 3924. Acc: 0.477080. Loss: 1.454236. Batch_acc: 0.475631. Batch_loss: 1.411449 \n",
      "Batch: 3925. Acc: 0.477088. Loss: 1.454210. Batch_acc: 0.505631. Batch_loss: 1.356955 \n",
      "Batch: 3926. Acc: 0.477090. Loss: 1.454202. Batch_acc: 0.486972. Batch_loss: 1.420353 \n",
      "Batch: 3927. Acc: 0.477098. Loss: 1.454182. Batch_acc: 0.506516. Batch_loss: 1.377630 \n",
      "Batch: 3928. Acc: 0.477102. Loss: 1.454171. Batch_acc: 0.493934. Batch_loss: 1.409090 \n",
      "Batch: 3929. Acc: 0.477108. Loss: 1.454146. Batch_acc: 0.498858. Batch_loss: 1.357177 \n",
      "Batch: 3930. Acc: 0.477110. Loss: 1.454137. Batch_acc: 0.486502. Batch_loss: 1.419826 \n",
      "Batch: 3931. Acc: 0.477114. Loss: 1.454132. Batch_acc: 0.492192. Batch_loss: 1.433849 \n",
      "Batch: 3932. Acc: 0.477116. Loss: 1.454116. Batch_acc: 0.486063. Batch_loss: 1.393373 \n",
      "Batch: 3933. Acc: 0.477121. Loss: 1.454110. Batch_acc: 0.493521. Batch_loss: 1.429562 \n",
      "Batch: 3934. Acc: 0.477125. Loss: 1.454103. Batch_acc: 0.493750. Batch_loss: 1.424830 \n",
      "Batch: 3935. Acc: 0.477132. Loss: 1.454079. Batch_acc: 0.503311. Batch_loss: 1.363546 \n",
      "Batch: 3936. Acc: 0.477135. Loss: 1.454063. Batch_acc: 0.492017. Batch_loss: 1.390528 \n",
      "Batch: 3937. Acc: 0.477140. Loss: 1.454050. Batch_acc: 0.493432. Batch_loss: 1.404614 \n",
      "Batch: 3938. Acc: 0.477140. Loss: 1.454046. Batch_acc: 0.477022. Batch_loss: 1.435694 \n",
      "Batch: 3939. Acc: 0.477144. Loss: 1.454031. Batch_acc: 0.495157. Batch_loss: 1.398541 \n",
      "Batch: 3940. Acc: 0.477151. Loss: 1.454013. Batch_acc: 0.502013. Batch_loss: 1.379701 \n",
      "Batch: 3941. Acc: 0.477161. Loss: 1.453979. Batch_acc: 0.515695. Batch_loss: 1.325888 \n",
      "Batch: 3942. Acc: 0.477162. Loss: 1.453973. Batch_acc: 0.482386. Batch_loss: 1.431029 \n",
      "Batch: 3943. Acc: 0.477163. Loss: 1.453967. Batch_acc: 0.481138. Batch_loss: 1.430857 \n",
      "Batch: 3944. Acc: 0.477167. Loss: 1.453965. Batch_acc: 0.492554. Batch_loss: 1.442678 \n",
      "Batch: 3945. Acc: 0.477169. Loss: 1.453950. Batch_acc: 0.486239. Batch_loss: 1.397588 \n",
      "Batch: 3946. Acc: 0.477176. Loss: 1.453937. Batch_acc: 0.502867. Batch_loss: 1.400097 \n",
      "Batch: 3947. Acc: 0.477177. Loss: 1.453928. Batch_acc: 0.484313. Batch_loss: 1.420234 \n",
      "Batch: 3948. Acc: 0.477185. Loss: 1.453910. Batch_acc: 0.505814. Batch_loss: 1.382001 \n",
      "Batch: 3949. Acc: 0.477187. Loss: 1.453896. Batch_acc: 0.487457. Batch_loss: 1.400677 \n",
      "Batch: 3950. Acc: 0.477188. Loss: 1.453894. Batch_acc: 0.480634. Batch_loss: 1.444382 \n",
      "Batch: 3951. Acc: 0.477194. Loss: 1.453875. Batch_acc: 0.500000. Batch_loss: 1.378284 \n",
      "Batch: 3952. Acc: 0.477193. Loss: 1.453870. Batch_acc: 0.473413. Batch_loss: 1.436402 \n",
      "Batch: 3953. Acc: 0.477201. Loss: 1.453852. Batch_acc: 0.509965. Batch_loss: 1.380310 \n",
      "Batch: 3954. Acc: 0.477203. Loss: 1.453841. Batch_acc: 0.485465. Batch_loss: 1.409798 \n",
      "Batch: 3955. Acc: 0.477209. Loss: 1.453819. Batch_acc: 0.498888. Batch_loss: 1.371741 \n",
      "Batch: 3956. Acc: 0.477212. Loss: 1.453801. Batch_acc: 0.490556. Batch_loss: 1.383272 \n",
      "Batch: 3957. Acc: 0.477211. Loss: 1.453795. Batch_acc: 0.470453. Batch_loss: 1.430857 \n",
      "Batch: 3958. Acc: 0.477209. Loss: 1.453798. Batch_acc: 0.470655. Batch_loss: 1.465875 \n",
      "Batch: 3959. Acc: 0.477220. Loss: 1.453763. Batch_acc: 0.520951. Batch_loss: 1.318184 \n",
      "Batch: 3960. Acc: 0.477228. Loss: 1.453737. Batch_acc: 0.509445. Batch_loss: 1.350652 \n",
      "Batch: 3961. Acc: 0.477242. Loss: 1.453707. Batch_acc: 0.530720. Batch_loss: 1.333449 \n",
      "Batch: 3962. Acc: 0.477248. Loss: 1.453699. Batch_acc: 0.502288. Batch_loss: 1.422168 \n",
      "Batch: 3963. Acc: 0.477253. Loss: 1.453683. Batch_acc: 0.499125. Batch_loss: 1.385651 \n",
      "Batch: 3964. Acc: 0.477259. Loss: 1.453662. Batch_acc: 0.498260. Batch_loss: 1.371272 \n",
      "Batch: 3965. Acc: 0.477260. Loss: 1.453656. Batch_acc: 0.481850. Batch_loss: 1.428519 \n",
      "Batch: 3966. Acc: 0.477264. Loss: 1.453635. Batch_acc: 0.493425. Batch_loss: 1.372953 \n",
      "Batch: 3967. Acc: 0.477267. Loss: 1.453622. Batch_acc: 0.491208. Batch_loss: 1.399907 \n",
      "Batch: 3968. Acc: 0.477280. Loss: 1.453593. Batch_acc: 0.525000. Batch_loss: 1.339457 \n",
      "Batch: 3969. Acc: 0.477286. Loss: 1.453577. Batch_acc: 0.501754. Batch_loss: 1.391272 \n",
      "Batch: 3970. Acc: 0.477289. Loss: 1.453570. Batch_acc: 0.489619. Batch_loss: 1.425602 \n",
      "Batch: 3971. Acc: 0.477288. Loss: 1.453568. Batch_acc: 0.474644. Batch_loss: 1.442737 \n",
      "Batch: 3972. Acc: 0.477296. Loss: 1.453553. Batch_acc: 0.509456. Batch_loss: 1.394900 \n",
      "Batch: 3973. Acc: 0.477297. Loss: 1.453541. Batch_acc: 0.482319. Batch_loss: 1.407035 \n",
      "Batch: 3974. Acc: 0.477304. Loss: 1.453522. Batch_acc: 0.505251. Batch_loss: 1.374794 \n",
      "Batch: 3975. Acc: 0.477309. Loss: 1.453512. Batch_acc: 0.497625. Batch_loss: 1.412226 \n",
      "Batch: 3976. Acc: 0.477305. Loss: 1.453520. Batch_acc: 0.462069. Batch_loss: 1.488070 \n",
      "Batch: 3977. Acc: 0.477315. Loss: 1.453483. Batch_acc: 0.516186. Batch_loss: 1.300057 \n",
      "Batch: 3978. Acc: 0.477322. Loss: 1.453468. Batch_acc: 0.504888. Batch_loss: 1.396843 \n",
      "Batch: 3979. Acc: 0.477323. Loss: 1.453463. Batch_acc: 0.481928. Batch_loss: 1.431366 \n",
      "Batch: 3980. Acc: 0.477326. Loss: 1.453455. Batch_acc: 0.487875. Batch_loss: 1.421914 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3981. Acc: 0.477336. Loss: 1.453425. Batch_acc: 0.517339. Batch_loss: 1.334642 \n",
      "Batch: 3982. Acc: 0.477334. Loss: 1.453422. Batch_acc: 0.471420. Batch_loss: 1.441517 \n",
      "Batch: 3983. Acc: 0.477341. Loss: 1.453398. Batch_acc: 0.504075. Batch_loss: 1.356310 \n",
      "Batch: 3984. Acc: 0.477349. Loss: 1.453378. Batch_acc: 0.509132. Batch_loss: 1.377668 \n",
      "Batch: 3985. Acc: 0.477350. Loss: 1.453374. Batch_acc: 0.479539. Batch_loss: 1.433617 \n",
      "Batch: 3986. Acc: 0.477362. Loss: 1.453331. Batch_acc: 0.526556. Batch_loss: 1.286560 \n",
      "Batch: 3987. Acc: 0.477370. Loss: 1.453309. Batch_acc: 0.511163. Batch_loss: 1.360348 \n",
      "Batch: 3988. Acc: 0.477375. Loss: 1.453289. Batch_acc: 0.494575. Batch_loss: 1.377273 \n",
      "Batch: 3989. Acc: 0.477378. Loss: 1.453271. Batch_acc: 0.492147. Batch_loss: 1.381010 \n",
      "Batch: 3990. Acc: 0.477385. Loss: 1.453257. Batch_acc: 0.501418. Batch_loss: 1.395088 \n",
      "Batch: 3991. Acc: 0.477386. Loss: 1.453251. Batch_acc: 0.481654. Batch_loss: 1.431054 \n",
      "Batch: 3992. Acc: 0.477388. Loss: 1.453238. Batch_acc: 0.487395. Batch_loss: 1.401301 \n",
      "Batch: 3993. Acc: 0.477389. Loss: 1.453231. Batch_acc: 0.481609. Batch_loss: 1.425819 \n",
      "Batch: 3994. Acc: 0.477399. Loss: 1.453204. Batch_acc: 0.517826. Batch_loss: 1.345412 \n",
      "Batch: 3995. Acc: 0.477409. Loss: 1.453186. Batch_acc: 0.517661. Batch_loss: 1.377591 \n",
      "Batch: 3996. Acc: 0.477415. Loss: 1.453174. Batch_acc: 0.500835. Batch_loss: 1.408986 \n",
      "Batch: 3997. Acc: 0.477424. Loss: 1.453152. Batch_acc: 0.513249. Batch_loss: 1.363935 \n",
      "Batch: 3998. Acc: 0.477428. Loss: 1.453145. Batch_acc: 0.492380. Batch_loss: 1.425168 \n",
      "Batch: 3999. Acc: 0.477437. Loss: 1.453116. Batch_acc: 0.512464. Batch_loss: 1.335574 \n",
      "Batch: 4000. Acc: 0.477445. Loss: 1.453095. Batch_acc: 0.512571. Batch_loss: 1.368836 \n",
      "Batch: 4001. Acc: 0.477448. Loss: 1.453083. Batch_acc: 0.489398. Batch_loss: 1.407900 \n",
      "Batch: 4002. Acc: 0.477449. Loss: 1.453078. Batch_acc: 0.480849. Batch_loss: 1.431267 \n",
      "Batch: 4003. Acc: 0.477453. Loss: 1.453065. Batch_acc: 0.493499. Batch_loss: 1.400230 \n",
      "Batch: 4004. Acc: 0.477460. Loss: 1.453046. Batch_acc: 0.506605. Batch_loss: 1.375196 \n",
      "Batch: 4005. Acc: 0.477463. Loss: 1.453031. Batch_acc: 0.488852. Batch_loss: 1.398077 \n",
      "Batch: 4006. Acc: 0.477471. Loss: 1.453012. Batch_acc: 0.507378. Batch_loss: 1.376896 \n",
      "Batch: 4007. Acc: 0.477481. Loss: 1.452993. Batch_acc: 0.518775. Batch_loss: 1.376174 \n",
      "Batch: 4008. Acc: 0.477490. Loss: 1.452966. Batch_acc: 0.513104. Batch_loss: 1.341950 \n",
      "Batch: 4009. Acc: 0.477491. Loss: 1.452968. Batch_acc: 0.480161. Batch_loss: 1.460129 \n",
      "Batch: 4010. Acc: 0.477499. Loss: 1.452949. Batch_acc: 0.511274. Batch_loss: 1.380411 \n",
      "Batch: 4011. Acc: 0.477505. Loss: 1.452934. Batch_acc: 0.499143. Batch_loss: 1.393763 \n",
      "Batch: 4012. Acc: 0.477511. Loss: 1.452916. Batch_acc: 0.501985. Batch_loss: 1.381072 \n",
      "Batch: 4013. Acc: 0.477517. Loss: 1.452897. Batch_acc: 0.501471. Batch_loss: 1.374208 \n",
      "Batch: 4014. Acc: 0.477529. Loss: 1.452867. Batch_acc: 0.524157. Batch_loss: 1.335364 \n",
      "Batch: 4015. Acc: 0.477534. Loss: 1.452843. Batch_acc: 0.499146. Batch_loss: 1.356516 \n",
      "Batch: 4016. Acc: 0.477532. Loss: 1.452839. Batch_acc: 0.471103. Batch_loss: 1.439662 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.4775324530438186. Loss per char: 1.4528394169211405. Time: 1627217300.9224164\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 14, 20, 24, 15, 24, 18, 23, 25,\n",
      "        17, 26, 19, 18, 18,  1, 14,  1, 14, 18, 15, 26, 19, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.477540. Loss: 1.452822. Batch_acc: 0.507549. Batch_loss: 1.383548 \n",
      "Batch: 4018. Acc: 0.477543. Loss: 1.452813. Batch_acc: 0.489068. Batch_loss: 1.416703 \n",
      "Batch: 4019. Acc: 0.477546. Loss: 1.452800. Batch_acc: 0.489300. Batch_loss: 1.396869 \n",
      "Batch: 4020. Acc: 0.477554. Loss: 1.452778. Batch_acc: 0.511959. Batch_loss: 1.368265 \n",
      "Batch: 4021. Acc: 0.477557. Loss: 1.452766. Batch_acc: 0.489736. Batch_loss: 1.401566 \n",
      "Batch: 4022. Acc: 0.477560. Loss: 1.452751. Batch_acc: 0.489278. Batch_loss: 1.392858 \n",
      "Batch: 4023. Acc: 0.477567. Loss: 1.452731. Batch_acc: 0.505155. Batch_loss: 1.375611 \n",
      "Batch: 4024. Acc: 0.477575. Loss: 1.452713. Batch_acc: 0.509275. Batch_loss: 1.380705 \n",
      "Batch: 4025. Acc: 0.477583. Loss: 1.452693. Batch_acc: 0.508065. Batch_loss: 1.373387 \n",
      "Batch: 4026. Acc: 0.477592. Loss: 1.452671. Batch_acc: 0.512676. Batch_loss: 1.363493 \n",
      "Batch: 4027. Acc: 0.477597. Loss: 1.452652. Batch_acc: 0.500886. Batch_loss: 1.375903 \n",
      "Batch: 4028. Acc: 0.477597. Loss: 1.452648. Batch_acc: 0.476833. Batch_loss: 1.434471 \n",
      "Batch: 4029. Acc: 0.477603. Loss: 1.452628. Batch_acc: 0.502585. Batch_loss: 1.373237 \n",
      "Batch: 4030. Acc: 0.477611. Loss: 1.452598. Batch_acc: 0.508872. Batch_loss: 1.330581 \n",
      "Batch: 4031. Acc: 0.477623. Loss: 1.452571. Batch_acc: 0.523810. Batch_loss: 1.346733 \n",
      "Batch: 4032. Acc: 0.477622. Loss: 1.452565. Batch_acc: 0.476651. Batch_loss: 1.430074 \n",
      "Batch: 4033. Acc: 0.477628. Loss: 1.452550. Batch_acc: 0.498544. Batch_loss: 1.390033 \n",
      "Batch: 4034. Acc: 0.477627. Loss: 1.452546. Batch_acc: 0.475574. Batch_loss: 1.435834 \n",
      "Batch: 4035. Acc: 0.477625. Loss: 1.452549. Batch_acc: 0.467251. Batch_loss: 1.464543 \n",
      "Batch: 4036. Acc: 0.477627. Loss: 1.452543. Batch_acc: 0.486827. Batch_loss: 1.427902 \n",
      "Batch: 4037. Acc: 0.477632. Loss: 1.452529. Batch_acc: 0.497666. Batch_loss: 1.396397 \n",
      "Batch: 4038. Acc: 0.477639. Loss: 1.452504. Batch_acc: 0.505949. Batch_loss: 1.353930 \n",
      "Batch: 4039. Acc: 0.477638. Loss: 1.452510. Batch_acc: 0.475072. Batch_loss: 1.474258 \n",
      "Batch: 4040. Acc: 0.477639. Loss: 1.452506. Batch_acc: 0.482132. Batch_loss: 1.438753 \n",
      "Batch: 4041. Acc: 0.477643. Loss: 1.452495. Batch_acc: 0.494967. Batch_loss: 1.407214 \n",
      "Batch: 4042. Acc: 0.477651. Loss: 1.452468. Batch_acc: 0.506104. Batch_loss: 1.347466 \n",
      "Batch: 4043. Acc: 0.477656. Loss: 1.452451. Batch_acc: 0.499432. Batch_loss: 1.382125 \n",
      "Batch: 4044. Acc: 0.477661. Loss: 1.452432. Batch_acc: 0.495954. Batch_loss: 1.374427 \n",
      "Batch: 4045. Acc: 0.477668. Loss: 1.452413. Batch_acc: 0.507323. Batch_loss: 1.377347 \n",
      "Batch: 4046. Acc: 0.477670. Loss: 1.452405. Batch_acc: 0.484659. Batch_loss: 1.419327 \n",
      "Batch: 4047. Acc: 0.477676. Loss: 1.452380. Batch_acc: 0.502825. Batch_loss: 1.351556 \n",
      "Batch: 4048. Acc: 0.477687. Loss: 1.452355. Batch_acc: 0.523509. Batch_loss: 1.353280 \n",
      "Batch: 4049. Acc: 0.477694. Loss: 1.452342. Batch_acc: 0.504816. Batch_loss: 1.398590 \n",
      "Batch: 4050. Acc: 0.477702. Loss: 1.452322. Batch_acc: 0.511291. Batch_loss: 1.370515 \n",
      "Batch: 4051. Acc: 0.477702. Loss: 1.452322. Batch_acc: 0.476825. Batch_loss: 1.453996 \n",
      "Batch: 4052. Acc: 0.477703. Loss: 1.452323. Batch_acc: 0.480496. Batch_loss: 1.454462 \n",
      "Batch: 4053. Acc: 0.477709. Loss: 1.452306. Batch_acc: 0.502874. Batch_loss: 1.386624 \n",
      "Batch: 4054. Acc: 0.477718. Loss: 1.452282. Batch_acc: 0.514697. Batch_loss: 1.351117 \n",
      "Batch: 4055. Acc: 0.477722. Loss: 1.452265. Batch_acc: 0.494152. Batch_loss: 1.379121 \n",
      "Batch: 4056. Acc: 0.477724. Loss: 1.452249. Batch_acc: 0.485698. Batch_loss: 1.389485 \n",
      "Batch: 4057. Acc: 0.477731. Loss: 1.452222. Batch_acc: 0.507684. Batch_loss: 1.341712 \n",
      "Batch: 4058. Acc: 0.477733. Loss: 1.452207. Batch_acc: 0.485647. Batch_loss: 1.391257 \n",
      "Batch: 4059. Acc: 0.477736. Loss: 1.452196. Batch_acc: 0.489100. Batch_loss: 1.408873 \n",
      "Batch: 4060. Acc: 0.477742. Loss: 1.452183. Batch_acc: 0.503155. Batch_loss: 1.398115 \n",
      "Batch: 4061. Acc: 0.477751. Loss: 1.452162. Batch_acc: 0.514072. Batch_loss: 1.370907 \n",
      "Batch: 4062. Acc: 0.477761. Loss: 1.452134. Batch_acc: 0.517544. Batch_loss: 1.333340 \n",
      "Batch: 4063. Acc: 0.477760. Loss: 1.452134. Batch_acc: 0.473775. Batch_loss: 1.454993 \n",
      "Batch: 4064. Acc: 0.477762. Loss: 1.452133. Batch_acc: 0.485616. Batch_loss: 1.444704 \n",
      "Batch: 4065. Acc: 0.477768. Loss: 1.452118. Batch_acc: 0.502415. Batch_loss: 1.388376 \n",
      "Batch: 4066. Acc: 0.477770. Loss: 1.452109. Batch_acc: 0.487136. Batch_loss: 1.416999 \n",
      "Batch: 4067. Acc: 0.477776. Loss: 1.452096. Batch_acc: 0.501181. Batch_loss: 1.398001 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4068. Acc: 0.477783. Loss: 1.452073. Batch_acc: 0.506329. Batch_loss: 1.359232 \n",
      "Batch: 4069. Acc: 0.477793. Loss: 1.452051. Batch_acc: 0.519220. Batch_loss: 1.363969 \n",
      "Batch: 4070. Acc: 0.477804. Loss: 1.452025. Batch_acc: 0.523782. Batch_loss: 1.343072 \n",
      "Batch: 4071. Acc: 0.477808. Loss: 1.452009. Batch_acc: 0.493484. Batch_loss: 1.390384 \n",
      "Batch: 4072. Acc: 0.477815. Loss: 1.451986. Batch_acc: 0.505166. Batch_loss: 1.357665 \n",
      "Batch: 4073. Acc: 0.477822. Loss: 1.451962. Batch_acc: 0.506344. Batch_loss: 1.352978 \n",
      "Batch: 4074. Acc: 0.477825. Loss: 1.451951. Batch_acc: 0.491056. Batch_loss: 1.408365 \n",
      "Batch: 4075. Acc: 0.477832. Loss: 1.451938. Batch_acc: 0.507366. Batch_loss: 1.398842 \n",
      "Batch: 4076. Acc: 0.477836. Loss: 1.451928. Batch_acc: 0.491747. Batch_loss: 1.410726 \n",
      "Batch: 4077. Acc: 0.477834. Loss: 1.451926. Batch_acc: 0.471311. Batch_loss: 1.441801 \n",
      "Batch: 4078. Acc: 0.477839. Loss: 1.451907. Batch_acc: 0.497962. Batch_loss: 1.373466 \n",
      "Batch: 4079. Acc: 0.477847. Loss: 1.451877. Batch_acc: 0.510882. Batch_loss: 1.331380 \n",
      "Batch: 4080. Acc: 0.477854. Loss: 1.451855. Batch_acc: 0.504283. Batch_loss: 1.364545 \n",
      "Batch: 4081. Acc: 0.477854. Loss: 1.451852. Batch_acc: 0.478461. Batch_loss: 1.436178 \n",
      "Batch: 4082. Acc: 0.477861. Loss: 1.451827. Batch_acc: 0.509292. Batch_loss: 1.351345 \n",
      "Batch: 4083. Acc: 0.477864. Loss: 1.451814. Batch_acc: 0.490468. Batch_loss: 1.396471 \n",
      "Batch: 4084. Acc: 0.477871. Loss: 1.451796. Batch_acc: 0.504288. Batch_loss: 1.378424 \n",
      "Batch: 4085. Acc: 0.477873. Loss: 1.451793. Batch_acc: 0.484988. Batch_loss: 1.442555 \n",
      "Batch: 4086. Acc: 0.477877. Loss: 1.451781. Batch_acc: 0.496732. Batch_loss: 1.398755 \n",
      "Batch: 4087. Acc: 0.477885. Loss: 1.451759. Batch_acc: 0.509793. Batch_loss: 1.364014 \n",
      "Batch: 4088. Acc: 0.477888. Loss: 1.451756. Batch_acc: 0.489507. Batch_loss: 1.439444 \n",
      "Batch: 4089. Acc: 0.477891. Loss: 1.451750. Batch_acc: 0.490006. Batch_loss: 1.425365 \n",
      "Batch: 4090. Acc: 0.477901. Loss: 1.451727. Batch_acc: 0.522222. Batch_loss: 1.355463 \n",
      "Batch: 4091. Acc: 0.477911. Loss: 1.451703. Batch_acc: 0.518692. Batch_loss: 1.352783 \n",
      "Batch: 4092. Acc: 0.477914. Loss: 1.451697. Batch_acc: 0.491166. Batch_loss: 1.428535 \n",
      "Batch: 4093. Acc: 0.477917. Loss: 1.451691. Batch_acc: 0.490801. Batch_loss: 1.425981 \n",
      "Batch: 4094. Acc: 0.477924. Loss: 1.451678. Batch_acc: 0.504800. Batch_loss: 1.397134 \n",
      "Batch: 4095. Acc: 0.477929. Loss: 1.451660. Batch_acc: 0.498030. Batch_loss: 1.380671 \n",
      "Batch: 4096. Acc: 0.477933. Loss: 1.451644. Batch_acc: 0.493326. Batch_loss: 1.385479 \n",
      "Batch: 4097. Acc: 0.477938. Loss: 1.451625. Batch_acc: 0.498572. Batch_loss: 1.372948 \n",
      "Batch: 4098. Acc: 0.477943. Loss: 1.451608. Batch_acc: 0.498830. Batch_loss: 1.382231 \n",
      "Batch: 4099. Acc: 0.477948. Loss: 1.451598. Batch_acc: 0.500283. Batch_loss: 1.410432 \n",
      "Batch: 4100. Acc: 0.477958. Loss: 1.451574. Batch_acc: 0.518561. Batch_loss: 1.353949 \n",
      "Batch: 4101. Acc: 0.477966. Loss: 1.451561. Batch_acc: 0.507272. Batch_loss: 1.398195 \n",
      "Batch: 4102. Acc: 0.477970. Loss: 1.451552. Batch_acc: 0.495687. Batch_loss: 1.415003 \n",
      "Batch: 4103. Acc: 0.477968. Loss: 1.451560. Batch_acc: 0.469929. Batch_loss: 1.486840 \n",
      "Batch: 4104. Acc: 0.477976. Loss: 1.451542. Batch_acc: 0.511986. Batch_loss: 1.376163 \n",
      "Batch: 4105. Acc: 0.477979. Loss: 1.451533. Batch_acc: 0.488927. Batch_loss: 1.415505 \n",
      "Batch: 4106. Acc: 0.477986. Loss: 1.451509. Batch_acc: 0.506598. Batch_loss: 1.351413 \n",
      "Batch: 4107. Acc: 0.477992. Loss: 1.451497. Batch_acc: 0.504056. Batch_loss: 1.405532 \n",
      "Batch: 4108. Acc: 0.478003. Loss: 1.451471. Batch_acc: 0.520182. Batch_loss: 1.342525 \n",
      "Batch: 4109. Acc: 0.478014. Loss: 1.451443. Batch_acc: 0.522843. Batch_loss: 1.340614 \n",
      "Batch: 4110. Acc: 0.478019. Loss: 1.451426. Batch_acc: 0.497962. Batch_loss: 1.380580 \n",
      "Batch: 4111. Acc: 0.478023. Loss: 1.451418. Batch_acc: 0.495637. Batch_loss: 1.417105 \n",
      "Batch: 4112. Acc: 0.478030. Loss: 1.451390. Batch_acc: 0.507745. Batch_loss: 1.335633 \n",
      "Batch: 4113. Acc: 0.478036. Loss: 1.451375. Batch_acc: 0.501404. Batch_loss: 1.392936 \n",
      "Batch: 4114. Acc: 0.478039. Loss: 1.451366. Batch_acc: 0.491279. Batch_loss: 1.413866 \n",
      "Batch: 4115. Acc: 0.478048. Loss: 1.451345. Batch_acc: 0.516763. Batch_loss: 1.364127 \n",
      "Batch: 4116. Acc: 0.478051. Loss: 1.451342. Batch_acc: 0.489869. Batch_loss: 1.440716 \n",
      "Batch: 4117. Acc: 0.478056. Loss: 1.451327. Batch_acc: 0.498884. Batch_loss: 1.390272 \n",
      "Batch: 4118. Acc: 0.478060. Loss: 1.451321. Batch_acc: 0.491051. Batch_loss: 1.424918 \n",
      "Batch: 4119. Acc: 0.478063. Loss: 1.451319. Batch_acc: 0.491696. Batch_loss: 1.442805 \n",
      "Batch: 4120. Acc: 0.478071. Loss: 1.451298. Batch_acc: 0.513039. Batch_loss: 1.367948 \n",
      "Batch: 4121. Acc: 0.478077. Loss: 1.451287. Batch_acc: 0.499435. Batch_loss: 1.408059 \n",
      "Batch: 4122. Acc: 0.478085. Loss: 1.451263. Batch_acc: 0.511536. Batch_loss: 1.353328 \n",
      "Batch: 4123. Acc: 0.478093. Loss: 1.451249. Batch_acc: 0.511497. Batch_loss: 1.396490 \n",
      "Batch: 4124. Acc: 0.478098. Loss: 1.451242. Batch_acc: 0.495944. Batch_loss: 1.420275 \n",
      "Batch: 4125. Acc: 0.478102. Loss: 1.451230. Batch_acc: 0.495151. Batch_loss: 1.402414 \n",
      "Batch: 4126. Acc: 0.478109. Loss: 1.451209. Batch_acc: 0.508802. Batch_loss: 1.366799 \n",
      "Batch: 4127. Acc: 0.478111. Loss: 1.451198. Batch_acc: 0.485781. Batch_loss: 1.404120 \n",
      "Batch: 4128. Acc: 0.478118. Loss: 1.451180. Batch_acc: 0.504871. Batch_loss: 1.376835 \n",
      "Batch: 4129. Acc: 0.478118. Loss: 1.451181. Batch_acc: 0.480961. Batch_loss: 1.454215 \n",
      "Batch: 4130. Acc: 0.478132. Loss: 1.451148. Batch_acc: 0.531674. Batch_loss: 1.316965 \n",
      "Batch: 4131. Acc: 0.478134. Loss: 1.451144. Batch_acc: 0.488290. Batch_loss: 1.434631 \n",
      "Batch: 4132. Acc: 0.478132. Loss: 1.451142. Batch_acc: 0.469192. Batch_loss: 1.445639 \n",
      "Batch: 4133. Acc: 0.478132. Loss: 1.451142. Batch_acc: 0.478286. Batch_loss: 1.452087 \n",
      "Batch: 4134. Acc: 0.478141. Loss: 1.451117. Batch_acc: 0.516771. Batch_loss: 1.346130 \n",
      "Batch: 4135. Acc: 0.478150. Loss: 1.451097. Batch_acc: 0.516451. Batch_loss: 1.369249 \n",
      "Batch: 4136. Acc: 0.478159. Loss: 1.451071. Batch_acc: 0.512690. Batch_loss: 1.342626 \n",
      "Batch: 4137. Acc: 0.478165. Loss: 1.451039. Batch_acc: 0.502273. Batch_loss: 1.321637 \n",
      "Batch: 4138. Acc: 0.478168. Loss: 1.451027. Batch_acc: 0.491269. Batch_loss: 1.402582 \n",
      "Batch: 4139. Acc: 0.478170. Loss: 1.451019. Batch_acc: 0.488279. Batch_loss: 1.415756 \n",
      "Batch: 4140. Acc: 0.478178. Loss: 1.450994. Batch_acc: 0.508832. Batch_loss: 1.347946 \n",
      "Batch: 4141. Acc: 0.478174. Loss: 1.450998. Batch_acc: 0.460745. Batch_loss: 1.467483 \n",
      "Batch: 4142. Acc: 0.478185. Loss: 1.450968. Batch_acc: 0.526559. Batch_loss: 1.325507 \n",
      "Batch: 4143. Acc: 0.478188. Loss: 1.450946. Batch_acc: 0.490888. Batch_loss: 1.364429 \n",
      "Batch: 4144. Acc: 0.478198. Loss: 1.450924. Batch_acc: 0.518836. Batch_loss: 1.358397 \n",
      "Batch: 4145. Acc: 0.478196. Loss: 1.450919. Batch_acc: 0.469662. Batch_loss: 1.428865 \n",
      "Batch: 4146. Acc: 0.478202. Loss: 1.450897. Batch_acc: 0.501752. Batch_loss: 1.358444 \n",
      "Batch: 4147. Acc: 0.478210. Loss: 1.450873. Batch_acc: 0.511884. Batch_loss: 1.352448 \n",
      "Batch: 4148. Acc: 0.478220. Loss: 1.450840. Batch_acc: 0.520676. Batch_loss: 1.313019 \n",
      "Batch: 4149. Acc: 0.478218. Loss: 1.450842. Batch_acc: 0.469411. Batch_loss: 1.459670 \n",
      "Batch: 4150. Acc: 0.478223. Loss: 1.450825. Batch_acc: 0.501151. Batch_loss: 1.379961 \n",
      "Batch: 4151. Acc: 0.478234. Loss: 1.450806. Batch_acc: 0.521612. Batch_loss: 1.368429 \n",
      "Batch: 4152. Acc: 0.478240. Loss: 1.450790. Batch_acc: 0.506644. Batch_loss: 1.385846 \n",
      "Batch: 4153. Acc: 0.478243. Loss: 1.450776. Batch_acc: 0.488915. Batch_loss: 1.390081 \n",
      "Batch: 4154. Acc: 0.478243. Loss: 1.450773. Batch_acc: 0.480023. Batch_loss: 1.438407 \n",
      "Batch: 4155. Acc: 0.478245. Loss: 1.450769. Batch_acc: 0.483814. Batch_loss: 1.433025 \n",
      "Batch: 4156. Acc: 0.478254. Loss: 1.450740. Batch_acc: 0.516359. Batch_loss: 1.325375 \n",
      "Batch: 4157. Acc: 0.478260. Loss: 1.450716. Batch_acc: 0.504303. Batch_loss: 1.353802 \n",
      "Batch: 4158. Acc: 0.478259. Loss: 1.450719. Batch_acc: 0.473465. Batch_loss: 1.462582 \n",
      "Batch: 4159. Acc: 0.478258. Loss: 1.450716. Batch_acc: 0.473870. Batch_loss: 1.439859 \n",
      "Batch: 4160. Acc: 0.478266. Loss: 1.450699. Batch_acc: 0.512209. Batch_loss: 1.377611 \n",
      "Batch: 4161. Acc: 0.478271. Loss: 1.450685. Batch_acc: 0.500866. Batch_loss: 1.395119 \n",
      "Batch: 4162. Acc: 0.478277. Loss: 1.450671. Batch_acc: 0.500582. Batch_loss: 1.391301 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4163. Acc: 0.478283. Loss: 1.450648. Batch_acc: 0.504249. Batch_loss: 1.353642 \n",
      "Batch: 4164. Acc: 0.478289. Loss: 1.450627. Batch_acc: 0.503249. Batch_loss: 1.364078 \n",
      "Batch: 4165. Acc: 0.478295. Loss: 1.450616. Batch_acc: 0.504888. Batch_loss: 1.404357 \n",
      "Batch: 4166. Acc: 0.478300. Loss: 1.450596. Batch_acc: 0.499714. Batch_loss: 1.367073 \n",
      "Batch: 4167. Acc: 0.478307. Loss: 1.450582. Batch_acc: 0.507238. Batch_loss: 1.393700 \n",
      "Batch: 4168. Acc: 0.478313. Loss: 1.450560. Batch_acc: 0.501126. Batch_loss: 1.359935 \n",
      "Batch: 4169. Acc: 0.478315. Loss: 1.450551. Batch_acc: 0.487805. Batch_loss: 1.413087 \n",
      "Batch: 4170. Acc: 0.478319. Loss: 1.450545. Batch_acc: 0.492580. Batch_loss: 1.425664 \n",
      "Batch: 4171. Acc: 0.478328. Loss: 1.450522. Batch_acc: 0.514747. Batch_loss: 1.355914 \n",
      "Batch: 4172. Acc: 0.478333. Loss: 1.450507. Batch_acc: 0.500286. Batch_loss: 1.389291 \n",
      "Batch: 4173. Acc: 0.478335. Loss: 1.450493. Batch_acc: 0.485944. Batch_loss: 1.390730 \n",
      "Batch: 4174. Acc: 0.478339. Loss: 1.450486. Batch_acc: 0.494718. Batch_loss: 1.422164 \n",
      "Batch: 4175. Acc: 0.478337. Loss: 1.450488. Batch_acc: 0.470994. Batch_loss: 1.457421 \n",
      "Batch: 4176. Acc: 0.478343. Loss: 1.450466. Batch_acc: 0.501974. Batch_loss: 1.362315 \n",
      "Batch: 4177. Acc: 0.478347. Loss: 1.450460. Batch_acc: 0.496870. Batch_loss: 1.424638 \n",
      "Batch: 4178. Acc: 0.478358. Loss: 1.450427. Batch_acc: 0.523702. Batch_loss: 1.316225 \n",
      "Batch: 4179. Acc: 0.478364. Loss: 1.450405. Batch_acc: 0.500277. Batch_loss: 1.359926 \n",
      "Batch: 4180. Acc: 0.478366. Loss: 1.450392. Batch_acc: 0.487165. Batch_loss: 1.396886 \n",
      "Batch: 4181. Acc: 0.478364. Loss: 1.450390. Batch_acc: 0.471404. Batch_loss: 1.441149 \n",
      "Batch: 4182. Acc: 0.478372. Loss: 1.450369. Batch_acc: 0.511547. Batch_loss: 1.365262 \n",
      "Batch: 4183. Acc: 0.478376. Loss: 1.450353. Batch_acc: 0.495687. Batch_loss: 1.380508 \n",
      "Batch: 4184. Acc: 0.478380. Loss: 1.450346. Batch_acc: 0.495617. Batch_loss: 1.421117 \n",
      "Batch: 4185. Acc: 0.478378. Loss: 1.450350. Batch_acc: 0.467223. Batch_loss: 1.467398 \n",
      "Batch: 4186. Acc: 0.478383. Loss: 1.450334. Batch_acc: 0.499720. Batch_loss: 1.387094 \n",
      "Batch: 4187. Acc: 0.478391. Loss: 1.450311. Batch_acc: 0.515044. Batch_loss: 1.349017 \n",
      "Batch: 4188. Acc: 0.478392. Loss: 1.450305. Batch_acc: 0.481333. Batch_loss: 1.427420 \n",
      "Batch: 4189. Acc: 0.478397. Loss: 1.450288. Batch_acc: 0.497110. Batch_loss: 1.376568 \n",
      "Batch: 4190. Acc: 0.478392. Loss: 1.450299. Batch_acc: 0.460603. Batch_loss: 1.497083 \n",
      "Batch: 4191. Acc: 0.478397. Loss: 1.450287. Batch_acc: 0.495506. Batch_loss: 1.400472 \n",
      "Batch: 4192. Acc: 0.478397. Loss: 1.450279. Batch_acc: 0.478905. Batch_loss: 1.417972 \n",
      "Batch: 4193. Acc: 0.478405. Loss: 1.450266. Batch_acc: 0.515589. Batch_loss: 1.394937 \n",
      "Batch: 4194. Acc: 0.478409. Loss: 1.450261. Batch_acc: 0.492703. Batch_loss: 1.429432 \n",
      "Batch: 4195. Acc: 0.478413. Loss: 1.450243. Batch_acc: 0.496018. Batch_loss: 1.376257 \n",
      "Batch: 4196. Acc: 0.478414. Loss: 1.450241. Batch_acc: 0.482039. Batch_loss: 1.443708 \n",
      "Batch: 4197. Acc: 0.478417. Loss: 1.450231. Batch_acc: 0.491870. Batch_loss: 1.407525 \n",
      "Batch: 4198. Acc: 0.478424. Loss: 1.450218. Batch_acc: 0.507306. Batch_loss: 1.392810 \n",
      "Batch: 4199. Acc: 0.478427. Loss: 1.450209. Batch_acc: 0.489691. Batch_loss: 1.415178 \n",
      "Batch: 4200. Acc: 0.478425. Loss: 1.450211. Batch_acc: 0.469948. Batch_loss: 1.456065 \n",
      "Batch: 4201. Acc: 0.478431. Loss: 1.450187. Batch_acc: 0.505245. Batch_loss: 1.348460 \n",
      "Batch: 4202. Acc: 0.478434. Loss: 1.450178. Batch_acc: 0.493440. Batch_loss: 1.411407 \n",
      "Batch: 4203. Acc: 0.478439. Loss: 1.450160. Batch_acc: 0.498571. Batch_loss: 1.378193 \n",
      "Batch: 4204. Acc: 0.478443. Loss: 1.450142. Batch_acc: 0.493693. Batch_loss: 1.372395 \n",
      "Batch: 4205. Acc: 0.478450. Loss: 1.450122. Batch_acc: 0.509907. Batch_loss: 1.364079 \n",
      "Batch: 4206. Acc: 0.478455. Loss: 1.450110. Batch_acc: 0.499441. Batch_loss: 1.404231 \n",
      "Batch: 4207. Acc: 0.478459. Loss: 1.450095. Batch_acc: 0.495255. Batch_loss: 1.381692 \n",
      "Batch: 4208. Acc: 0.478465. Loss: 1.450081. Batch_acc: 0.501701. Batch_loss: 1.394277 \n",
      "Batch: 4209. Acc: 0.478468. Loss: 1.450072. Batch_acc: 0.493575. Batch_loss: 1.410004 \n",
      "Batch: 4210. Acc: 0.478472. Loss: 1.450055. Batch_acc: 0.493007. Batch_loss: 1.380125 \n",
      "Batch: 4211. Acc: 0.478478. Loss: 1.450048. Batch_acc: 0.503977. Batch_loss: 1.417287 \n",
      "Batch: 4212. Acc: 0.478485. Loss: 1.450020. Batch_acc: 0.506897. Batch_loss: 1.334743 \n",
      "Batch: 4213. Acc: 0.478485. Loss: 1.450019. Batch_acc: 0.477570. Batch_loss: 1.446474 \n",
      "Batch: 4214. Acc: 0.478492. Loss: 1.449996. Batch_acc: 0.508782. Batch_loss: 1.356890 \n",
      "Batch: 4215. Acc: 0.478497. Loss: 1.449976. Batch_acc: 0.500281. Batch_loss: 1.368587 \n",
      "Batch: 4216. Acc: 0.478503. Loss: 1.449964. Batch_acc: 0.502347. Batch_loss: 1.395643 \n",
      "Batch: 4217. Acc: 0.478504. Loss: 1.449957. Batch_acc: 0.482601. Batch_loss: 1.421672 \n",
      "Batch: 4218. Acc: 0.478512. Loss: 1.449945. Batch_acc: 0.511602. Batch_loss: 1.399263 \n",
      "Batch: 4219. Acc: 0.478518. Loss: 1.449923. Batch_acc: 0.505208. Batch_loss: 1.356697 \n",
      "Batch: 4220. Acc: 0.478526. Loss: 1.449906. Batch_acc: 0.509759. Batch_loss: 1.380446 \n",
      "Batch: 4221. Acc: 0.478526. Loss: 1.449901. Batch_acc: 0.481990. Batch_loss: 1.428456 \n",
      "Batch: 4222. Acc: 0.478529. Loss: 1.449895. Batch_acc: 0.491813. Batch_loss: 1.425154 \n",
      "Batch: 4223. Acc: 0.478535. Loss: 1.449879. Batch_acc: 0.501990. Batch_loss: 1.379860 \n",
      "Batch: 4224. Acc: 0.478546. Loss: 1.449848. Batch_acc: 0.526100. Batch_loss: 1.315650 \n",
      "Batch: 4225. Acc: 0.478556. Loss: 1.449823. Batch_acc: 0.522063. Batch_loss: 1.345433 \n",
      "Batch: 4226. Acc: 0.478556. Loss: 1.449822. Batch_acc: 0.476897. Batch_loss: 1.448008 \n",
      "Batch: 4227. Acc: 0.478562. Loss: 1.449796. Batch_acc: 0.503817. Batch_loss: 1.336940 \n",
      "Batch: 4228. Acc: 0.478580. Loss: 1.449751. Batch_acc: 0.552602. Batch_loss: 1.260940 \n",
      "Batch: 4229. Acc: 0.478584. Loss: 1.449732. Batch_acc: 0.498498. Batch_loss: 1.366387 \n",
      "Batch: 4230. Acc: 0.478589. Loss: 1.449717. Batch_acc: 0.498303. Batch_loss: 1.386879 \n",
      "Batch: 4231. Acc: 0.478602. Loss: 1.449684. Batch_acc: 0.532490. Batch_loss: 1.309166 \n",
      "Batch: 4232. Acc: 0.478605. Loss: 1.449675. Batch_acc: 0.493294. Batch_loss: 1.414963 \n",
      "Batch: 4233. Acc: 0.478602. Loss: 1.449671. Batch_acc: 0.465009. Batch_loss: 1.428966 \n",
      "Batch: 4234. Acc: 0.478611. Loss: 1.449647. Batch_acc: 0.514431. Batch_loss: 1.351609 \n",
      "Batch: 4235. Acc: 0.478620. Loss: 1.449625. Batch_acc: 0.516329. Batch_loss: 1.357754 \n",
      "Batch: 4236. Acc: 0.478620. Loss: 1.449628. Batch_acc: 0.480444. Batch_loss: 1.464245 \n",
      "Batch: 4237. Acc: 0.478626. Loss: 1.449609. Batch_acc: 0.503174. Batch_loss: 1.368573 \n",
      "Batch: 4238. Acc: 0.478633. Loss: 1.449585. Batch_acc: 0.507808. Batch_loss: 1.347400 \n",
      "Batch: 4239. Acc: 0.478635. Loss: 1.449576. Batch_acc: 0.487536. Batch_loss: 1.410583 \n",
      "Batch: 4240. Acc: 0.478643. Loss: 1.449551. Batch_acc: 0.515100. Batch_loss: 1.344672 \n",
      "Batch: 4241. Acc: 0.478645. Loss: 1.449549. Batch_acc: 0.487165. Batch_loss: 1.439238 \n",
      "Batch: 4242. Acc: 0.478655. Loss: 1.449524. Batch_acc: 0.517755. Batch_loss: 1.345583 \n",
      "Batch: 4243. Acc: 0.478657. Loss: 1.449517. Batch_acc: 0.486502. Batch_loss: 1.417506 \n",
      "Batch: 4244. Acc: 0.478660. Loss: 1.449506. Batch_acc: 0.494369. Batch_loss: 1.405150 \n",
      "Batch: 4245. Acc: 0.478664. Loss: 1.449492. Batch_acc: 0.494932. Batch_loss: 1.392487 \n",
      "Batch: 4246. Acc: 0.478669. Loss: 1.449481. Batch_acc: 0.497680. Batch_loss: 1.401973 \n",
      "Batch: 4247. Acc: 0.478678. Loss: 1.449458. Batch_acc: 0.519816. Batch_loss: 1.350820 \n",
      "Batch: 4248. Acc: 0.478687. Loss: 1.449432. Batch_acc: 0.515419. Batch_loss: 1.344122 \n",
      "Batch: 4249. Acc: 0.478690. Loss: 1.449427. Batch_acc: 0.491614. Batch_loss: 1.429008 \n",
      "Batch: 4250. Acc: 0.478696. Loss: 1.449414. Batch_acc: 0.503432. Batch_loss: 1.392145 \n",
      "Batch: 4251. Acc: 0.478698. Loss: 1.449408. Batch_acc: 0.487429. Batch_loss: 1.424694 \n",
      "Batch: 4252. Acc: 0.478704. Loss: 1.449386. Batch_acc: 0.500841. Batch_loss: 1.361132 \n",
      "Batch: 4253. Acc: 0.478713. Loss: 1.449368. Batch_acc: 0.518895. Batch_loss: 1.371495 \n",
      "Batch: 4254. Acc: 0.478716. Loss: 1.449358. Batch_acc: 0.489760. Batch_loss: 1.408026 \n",
      "Batch: 4255. Acc: 0.478716. Loss: 1.449362. Batch_acc: 0.477431. Batch_loss: 1.465252 \n",
      "Batch: 4256. Acc: 0.478719. Loss: 1.449354. Batch_acc: 0.492703. Batch_loss: 1.413167 \n",
      "Batch: 4257. Acc: 0.478725. Loss: 1.449335. Batch_acc: 0.502851. Batch_loss: 1.370971 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4258. Acc: 0.478730. Loss: 1.449323. Batch_acc: 0.503432. Batch_loss: 1.400567 \n",
      "Batch: 4259. Acc: 0.478732. Loss: 1.449308. Batch_acc: 0.485410. Batch_loss: 1.386050 \n",
      "Batch: 4260. Acc: 0.478731. Loss: 1.449310. Batch_acc: 0.473438. Batch_loss: 1.456198 \n",
      "Batch: 4261. Acc: 0.478737. Loss: 1.449290. Batch_acc: 0.504933. Batch_loss: 1.364117 \n",
      "Batch: 4262. Acc: 0.478738. Loss: 1.449277. Batch_acc: 0.483248. Batch_loss: 1.394821 \n",
      "Batch: 4263. Acc: 0.478744. Loss: 1.449259. Batch_acc: 0.504916. Batch_loss: 1.370080 \n",
      "Batch: 4264. Acc: 0.478744. Loss: 1.449257. Batch_acc: 0.476491. Batch_loss: 1.442880 \n",
      "Batch: 4265. Acc: 0.478753. Loss: 1.449243. Batch_acc: 0.518793. Batch_loss: 1.388911 \n",
      "Batch: 4266. Acc: 0.478755. Loss: 1.449232. Batch_acc: 0.488584. Batch_loss: 1.402806 \n",
      "Batch: 4267. Acc: 0.478762. Loss: 1.449212. Batch_acc: 0.509206. Batch_loss: 1.366652 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.47876245637824527. Loss per char: 1.4492124518090392. Time: 1627217507.6312082\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 24, 22, 26, 18, 21, 20,  1, 77,\n",
      "        70, 84, 84,  1, 85, 73, 66, 79,  1, 22, 21, 22, 22, 17, 20, 21, 21, 32,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.478765. Loss: 1.449203. Batch_acc: 0.488346. Batch_loss: 1.410588 \n",
      "Batch: 4269. Acc: 0.478766. Loss: 1.449198. Batch_acc: 0.485899. Batch_loss: 1.426044 \n",
      "Batch: 4270. Acc: 0.478775. Loss: 1.449180. Batch_acc: 0.516809. Batch_loss: 1.372602 \n",
      "Batch: 4271. Acc: 0.478781. Loss: 1.449170. Batch_acc: 0.504577. Batch_loss: 1.406414 \n",
      "Batch: 4272. Acc: 0.478787. Loss: 1.449158. Batch_acc: 0.502877. Batch_loss: 1.397714 \n",
      "Batch: 4273. Acc: 0.478798. Loss: 1.449125. Batch_acc: 0.524030. Batch_loss: 1.308343 \n",
      "Batch: 4274. Acc: 0.478807. Loss: 1.449097. Batch_acc: 0.518805. Batch_loss: 1.333768 \n",
      "Batch: 4275. Acc: 0.478811. Loss: 1.449087. Batch_acc: 0.493707. Batch_loss: 1.408441 \n",
      "Batch: 4276. Acc: 0.478819. Loss: 1.449068. Batch_acc: 0.513514. Batch_loss: 1.365770 \n",
      "Batch: 4277. Acc: 0.478823. Loss: 1.449054. Batch_acc: 0.498258. Batch_loss: 1.389942 \n",
      "Batch: 4278. Acc: 0.478824. Loss: 1.449049. Batch_acc: 0.483140. Batch_loss: 1.424527 \n",
      "Batch: 4279. Acc: 0.478828. Loss: 1.449038. Batch_acc: 0.492949. Batch_loss: 1.403761 \n",
      "Batch: 4280. Acc: 0.478834. Loss: 1.449018. Batch_acc: 0.506501. Batch_loss: 1.365645 \n",
      "Batch: 4281. Acc: 0.478841. Loss: 1.449003. Batch_acc: 0.510192. Batch_loss: 1.382722 \n",
      "Batch: 4282. Acc: 0.478846. Loss: 1.448995. Batch_acc: 0.499713. Batch_loss: 1.414424 \n",
      "Batch: 4283. Acc: 0.478854. Loss: 1.448973. Batch_acc: 0.512251. Batch_loss: 1.356871 \n",
      "Batch: 4284. Acc: 0.478865. Loss: 1.448957. Batch_acc: 0.526195. Batch_loss: 1.377324 \n",
      "Batch: 4285. Acc: 0.478867. Loss: 1.448958. Batch_acc: 0.487478. Batch_loss: 1.453453 \n",
      "Batch: 4286. Acc: 0.478873. Loss: 1.448942. Batch_acc: 0.504293. Batch_loss: 1.384336 \n",
      "Batch: 4287. Acc: 0.478879. Loss: 1.448926. Batch_acc: 0.501740. Batch_loss: 1.375851 \n",
      "Batch: 4288. Acc: 0.478884. Loss: 1.448910. Batch_acc: 0.502606. Batch_loss: 1.381697 \n",
      "Batch: 4289. Acc: 0.478886. Loss: 1.448901. Batch_acc: 0.485477. Batch_loss: 1.408563 \n",
      "Batch: 4290. Acc: 0.478885. Loss: 1.448897. Batch_acc: 0.477902. Batch_loss: 1.433458 \n",
      "Batch: 4291. Acc: 0.478889. Loss: 1.448883. Batch_acc: 0.493785. Batch_loss: 1.390342 \n",
      "Batch: 4292. Acc: 0.478892. Loss: 1.448877. Batch_acc: 0.490836. Batch_loss: 1.423263 \n",
      "Batch: 4293. Acc: 0.478894. Loss: 1.448871. Batch_acc: 0.486976. Batch_loss: 1.419580 \n",
      "Batch: 4294. Acc: 0.478894. Loss: 1.448865. Batch_acc: 0.480370. Batch_loss: 1.423912 \n",
      "Batch: 4295. Acc: 0.478903. Loss: 1.448842. Batch_acc: 0.518269. Batch_loss: 1.352039 \n",
      "Batch: 4296. Acc: 0.478905. Loss: 1.448837. Batch_acc: 0.488603. Batch_loss: 1.427459 \n",
      "Batch: 4297. Acc: 0.478905. Loss: 1.448837. Batch_acc: 0.477299. Batch_loss: 1.451960 \n",
      "Batch: 4298. Acc: 0.478912. Loss: 1.448820. Batch_acc: 0.505922. Batch_loss: 1.374785 \n",
      "Batch: 4299. Acc: 0.478922. Loss: 1.448792. Batch_acc: 0.523702. Batch_loss: 1.329914 \n",
      "Batch: 4300. Acc: 0.478924. Loss: 1.448782. Batch_acc: 0.486471. Batch_loss: 1.408575 \n",
      "Batch: 4301. Acc: 0.478931. Loss: 1.448766. Batch_acc: 0.509848. Batch_loss: 1.382528 \n",
      "Batch: 4302. Acc: 0.478932. Loss: 1.448764. Batch_acc: 0.482421. Batch_loss: 1.436511 \n",
      "Batch: 4303. Acc: 0.478937. Loss: 1.448761. Batch_acc: 0.497735. Batch_loss: 1.439510 \n",
      "Batch: 4304. Acc: 0.478943. Loss: 1.448746. Batch_acc: 0.506575. Batch_loss: 1.381279 \n",
      "Batch: 4305. Acc: 0.478947. Loss: 1.448729. Batch_acc: 0.497992. Batch_loss: 1.376001 \n",
      "Batch: 4306. Acc: 0.478953. Loss: 1.448711. Batch_acc: 0.501136. Batch_loss: 1.373413 \n",
      "Batch: 4307. Acc: 0.478954. Loss: 1.448708. Batch_acc: 0.485437. Batch_loss: 1.437641 \n",
      "Batch: 4308. Acc: 0.478956. Loss: 1.448699. Batch_acc: 0.488726. Batch_loss: 1.407247 \n",
      "Batch: 4309. Acc: 0.478965. Loss: 1.448674. Batch_acc: 0.514269. Batch_loss: 1.344009 \n",
      "Batch: 4310. Acc: 0.478971. Loss: 1.448656. Batch_acc: 0.507844. Batch_loss: 1.367929 \n",
      "Batch: 4311. Acc: 0.478971. Loss: 1.448658. Batch_acc: 0.477205. Batch_loss: 1.458183 \n",
      "Batch: 4312. Acc: 0.478973. Loss: 1.448652. Batch_acc: 0.485665. Batch_loss: 1.423618 \n",
      "Batch: 4313. Acc: 0.478980. Loss: 1.448631. Batch_acc: 0.510591. Batch_loss: 1.359315 \n",
      "Batch: 4314. Acc: 0.478990. Loss: 1.448604. Batch_acc: 0.521589. Batch_loss: 1.334338 \n",
      "Batch: 4315. Acc: 0.478998. Loss: 1.448585. Batch_acc: 0.513818. Batch_loss: 1.368210 \n",
      "Batch: 4316. Acc: 0.479005. Loss: 1.448570. Batch_acc: 0.510075. Batch_loss: 1.382352 \n",
      "Batch: 4317. Acc: 0.479016. Loss: 1.448545. Batch_acc: 0.522662. Batch_loss: 1.340318 \n",
      "Batch: 4318. Acc: 0.479018. Loss: 1.448543. Batch_acc: 0.491249. Batch_loss: 1.440273 \n",
      "Batch: 4319. Acc: 0.479028. Loss: 1.448522. Batch_acc: 0.523256. Batch_loss: 1.356078 \n",
      "Batch: 4320. Acc: 0.479037. Loss: 1.448507. Batch_acc: 0.516782. Batch_loss: 1.384878 \n",
      "Batch: 4321. Acc: 0.479040. Loss: 1.448498. Batch_acc: 0.490305. Batch_loss: 1.409957 \n",
      "Batch: 4322. Acc: 0.479045. Loss: 1.448481. Batch_acc: 0.500000. Batch_loss: 1.375340 \n",
      "Batch: 4323. Acc: 0.479048. Loss: 1.448478. Batch_acc: 0.492299. Batch_loss: 1.439250 \n",
      "Batch: 4324. Acc: 0.479051. Loss: 1.448471. Batch_acc: 0.491516. Batch_loss: 1.416708 \n",
      "Batch: 4325. Acc: 0.479054. Loss: 1.448456. Batch_acc: 0.493462. Batch_loss: 1.384592 \n",
      "Batch: 4326. Acc: 0.479059. Loss: 1.448442. Batch_acc: 0.499120. Batch_loss: 1.387693 \n",
      "Batch: 4327. Acc: 0.479064. Loss: 1.448427. Batch_acc: 0.504667. Batch_loss: 1.378739 \n",
      "Batch: 4328. Acc: 0.479066. Loss: 1.448421. Batch_acc: 0.488000. Batch_loss: 1.425091 \n",
      "Batch: 4329. Acc: 0.479072. Loss: 1.448405. Batch_acc: 0.501159. Batch_loss: 1.376130 \n",
      "Batch: 4330. Acc: 0.479077. Loss: 1.448384. Batch_acc: 0.501990. Batch_loss: 1.359316 \n",
      "Batch: 4331. Acc: 0.479087. Loss: 1.448353. Batch_acc: 0.523516. Batch_loss: 1.320317 \n",
      "Batch: 4332. Acc: 0.479092. Loss: 1.448335. Batch_acc: 0.500860. Batch_loss: 1.369007 \n",
      "Batch: 4333. Acc: 0.479090. Loss: 1.448332. Batch_acc: 0.468463. Batch_loss: 1.437084 \n",
      "Batch: 4334. Acc: 0.479091. Loss: 1.448332. Batch_acc: 0.483286. Batch_loss: 1.445836 \n",
      "Batch: 4335. Acc: 0.479098. Loss: 1.448310. Batch_acc: 0.507799. Batch_loss: 1.354317 \n",
      "Batch: 4336. Acc: 0.479099. Loss: 1.448295. Batch_acc: 0.485797. Batch_loss: 1.382762 \n",
      "Batch: 4337. Acc: 0.479108. Loss: 1.448279. Batch_acc: 0.518182. Batch_loss: 1.376598 \n",
      "Batch: 4338. Acc: 0.479112. Loss: 1.448265. Batch_acc: 0.495101. Batch_loss: 1.390428 \n",
      "Batch: 4339. Acc: 0.479114. Loss: 1.448258. Batch_acc: 0.486579. Batch_loss: 1.416606 \n",
      "Batch: 4340. Acc: 0.479117. Loss: 1.448246. Batch_acc: 0.494273. Batch_loss: 1.397704 \n",
      "Batch: 4341. Acc: 0.479124. Loss: 1.448232. Batch_acc: 0.508435. Batch_loss: 1.386974 \n",
      "Batch: 4342. Acc: 0.479132. Loss: 1.448210. Batch_acc: 0.513210. Batch_loss: 1.352907 \n",
      "Batch: 4343. Acc: 0.479141. Loss: 1.448185. Batch_acc: 0.516571. Batch_loss: 1.342647 \n",
      "Batch: 4344. Acc: 0.479150. Loss: 1.448162. Batch_acc: 0.521421. Batch_loss: 1.349497 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4345. Acc: 0.479157. Loss: 1.448144. Batch_acc: 0.508406. Batch_loss: 1.369651 \n",
      "Batch: 4346. Acc: 0.479165. Loss: 1.448122. Batch_acc: 0.514140. Batch_loss: 1.351215 \n",
      "Batch: 4347. Acc: 0.479172. Loss: 1.448096. Batch_acc: 0.507918. Batch_loss: 1.336164 \n",
      "Batch: 4348. Acc: 0.479179. Loss: 1.448069. Batch_acc: 0.511008. Batch_loss: 1.329871 \n",
      "Batch: 4349. Acc: 0.479181. Loss: 1.448063. Batch_acc: 0.485682. Batch_loss: 1.419022 \n",
      "Batch: 4350. Acc: 0.479180. Loss: 1.448067. Batch_acc: 0.476105. Batch_loss: 1.467707 \n",
      "Batch: 4351. Acc: 0.479181. Loss: 1.448065. Batch_acc: 0.484814. Batch_loss: 1.440667 \n",
      "Batch: 4352. Acc: 0.479187. Loss: 1.448051. Batch_acc: 0.502857. Batch_loss: 1.387385 \n",
      "Batch: 4353. Acc: 0.479195. Loss: 1.448020. Batch_acc: 0.517202. Batch_loss: 1.313197 \n",
      "Batch: 4354. Acc: 0.479200. Loss: 1.448006. Batch_acc: 0.497406. Batch_loss: 1.387875 \n",
      "Batch: 4355. Acc: 0.479209. Loss: 1.447985. Batch_acc: 0.520349. Batch_loss: 1.353136 \n",
      "Batch: 4356. Acc: 0.479219. Loss: 1.447963. Batch_acc: 0.521539. Batch_loss: 1.351485 \n",
      "Batch: 4357. Acc: 0.479232. Loss: 1.447937. Batch_acc: 0.535921. Batch_loss: 1.334958 \n",
      "Batch: 4358. Acc: 0.479238. Loss: 1.447920. Batch_acc: 0.508130. Batch_loss: 1.375394 \n",
      "Batch: 4359. Acc: 0.479241. Loss: 1.447911. Batch_acc: 0.490139. Batch_loss: 1.408379 \n",
      "Batch: 4360. Acc: 0.479240. Loss: 1.447904. Batch_acc: 0.477338. Batch_loss: 1.417413 \n",
      "Batch: 4361. Acc: 0.479243. Loss: 1.447897. Batch_acc: 0.491822. Batch_loss: 1.414030 \n",
      "Batch: 4362. Acc: 0.479250. Loss: 1.447878. Batch_acc: 0.508581. Batch_loss: 1.364638 \n",
      "Batch: 4363. Acc: 0.479256. Loss: 1.447864. Batch_acc: 0.504854. Batch_loss: 1.390531 \n",
      "Batch: 4364. Acc: 0.479258. Loss: 1.447852. Batch_acc: 0.488623. Batch_loss: 1.396098 \n",
      "Batch: 4365. Acc: 0.479265. Loss: 1.447834. Batch_acc: 0.509296. Batch_loss: 1.371369 \n",
      "Batch: 4366. Acc: 0.479272. Loss: 1.447821. Batch_acc: 0.508641. Batch_loss: 1.389403 \n",
      "Batch: 4367. Acc: 0.479279. Loss: 1.447804. Batch_acc: 0.509994. Batch_loss: 1.372210 \n",
      "Batch: 4368. Acc: 0.479282. Loss: 1.447792. Batch_acc: 0.493072. Batch_loss: 1.394854 \n",
      "Batch: 4369. Acc: 0.479284. Loss: 1.447792. Batch_acc: 0.486628. Batch_loss: 1.448741 \n",
      "Batch: 4370. Acc: 0.479282. Loss: 1.447796. Batch_acc: 0.473287. Batch_loss: 1.466801 \n",
      "Batch: 4371. Acc: 0.479286. Loss: 1.447778. Batch_acc: 0.497400. Batch_loss: 1.369630 \n",
      "Batch: 4372. Acc: 0.479284. Loss: 1.447774. Batch_acc: 0.468950. Batch_loss: 1.429314 \n",
      "Batch: 4373. Acc: 0.479287. Loss: 1.447760. Batch_acc: 0.490566. Batch_loss: 1.385975 \n",
      "Batch: 4374. Acc: 0.479299. Loss: 1.447727. Batch_acc: 0.530261. Batch_loss: 1.310369 \n",
      "Batch: 4375. Acc: 0.479299. Loss: 1.447729. Batch_acc: 0.482311. Batch_loss: 1.454558 \n",
      "Batch: 4376. Acc: 0.479302. Loss: 1.447719. Batch_acc: 0.489200. Batch_loss: 1.403178 \n",
      "Batch: 4377. Acc: 0.479309. Loss: 1.447700. Batch_acc: 0.512528. Batch_loss: 1.367948 \n",
      "Batch: 4378. Acc: 0.479316. Loss: 1.447685. Batch_acc: 0.510663. Batch_loss: 1.378622 \n",
      "Batch: 4379. Acc: 0.479324. Loss: 1.447664. Batch_acc: 0.513059. Batch_loss: 1.354563 \n",
      "Batch: 4380. Acc: 0.479326. Loss: 1.447652. Batch_acc: 0.488014. Batch_loss: 1.397950 \n",
      "Batch: 4381. Acc: 0.479328. Loss: 1.447637. Batch_acc: 0.488630. Batch_loss: 1.378964 \n",
      "Batch: 4382. Acc: 0.479338. Loss: 1.447611. Batch_acc: 0.522956. Batch_loss: 1.337133 \n",
      "Batch: 4383. Acc: 0.479344. Loss: 1.447602. Batch_acc: 0.503095. Batch_loss: 1.409132 \n",
      "Batch: 4384. Acc: 0.479347. Loss: 1.447591. Batch_acc: 0.495848. Batch_loss: 1.399284 \n",
      "Batch: 4385. Acc: 0.479354. Loss: 1.447577. Batch_acc: 0.505976. Batch_loss: 1.387764 \n",
      "Batch: 4386. Acc: 0.479356. Loss: 1.447569. Batch_acc: 0.487819. Batch_loss: 1.412140 \n",
      "Batch: 4387. Acc: 0.479352. Loss: 1.447573. Batch_acc: 0.465658. Batch_loss: 1.467053 \n",
      "Batch: 4388. Acc: 0.479355. Loss: 1.447561. Batch_acc: 0.488636. Batch_loss: 1.394595 \n",
      "Batch: 4389. Acc: 0.479351. Loss: 1.447567. Batch_acc: 0.461899. Batch_loss: 1.472811 \n",
      "Batch: 4390. Acc: 0.479352. Loss: 1.447565. Batch_acc: 0.483963. Batch_loss: 1.438985 \n",
      "Batch: 4391. Acc: 0.479359. Loss: 1.447546. Batch_acc: 0.509292. Batch_loss: 1.361503 \n",
      "Batch: 4392. Acc: 0.479358. Loss: 1.447545. Batch_acc: 0.476791. Batch_loss: 1.446802 \n",
      "Batch: 4393. Acc: 0.479362. Loss: 1.447536. Batch_acc: 0.496054. Batch_loss: 1.406227 \n",
      "Batch: 4394. Acc: 0.479366. Loss: 1.447519. Batch_acc: 0.495963. Batch_loss: 1.371791 \n",
      "Batch: 4395. Acc: 0.479373. Loss: 1.447503. Batch_acc: 0.511932. Batch_loss: 1.378775 \n",
      "Batch: 4396. Acc: 0.479379. Loss: 1.447491. Batch_acc: 0.506834. Batch_loss: 1.395909 \n",
      "Batch: 4397. Acc: 0.479387. Loss: 1.447471. Batch_acc: 0.511252. Batch_loss: 1.357643 \n",
      "Batch: 4398. Acc: 0.479393. Loss: 1.447454. Batch_acc: 0.508290. Batch_loss: 1.375843 \n",
      "Batch: 4399. Acc: 0.479406. Loss: 1.447422. Batch_acc: 0.535915. Batch_loss: 1.307340 \n",
      "Batch: 4400. Acc: 0.479413. Loss: 1.447408. Batch_acc: 0.509102. Batch_loss: 1.385778 \n",
      "Batch: 4401. Acc: 0.479418. Loss: 1.447400. Batch_acc: 0.501142. Batch_loss: 1.415340 \n",
      "Batch: 4402. Acc: 0.479423. Loss: 1.447388. Batch_acc: 0.502270. Batch_loss: 1.395013 \n",
      "Batch: 4403. Acc: 0.479429. Loss: 1.447375. Batch_acc: 0.503170. Batch_loss: 1.387556 \n",
      "Batch: 4404. Acc: 0.479437. Loss: 1.447352. Batch_acc: 0.515014. Batch_loss: 1.348690 \n",
      "Batch: 4405. Acc: 0.479440. Loss: 1.447335. Batch_acc: 0.492910. Batch_loss: 1.374419 \n",
      "Batch: 4406. Acc: 0.479449. Loss: 1.447308. Batch_acc: 0.518093. Batch_loss: 1.325196 \n",
      "Batch: 4407. Acc: 0.479454. Loss: 1.447297. Batch_acc: 0.502001. Batch_loss: 1.403113 \n",
      "Batch: 4408. Acc: 0.479452. Loss: 1.447298. Batch_acc: 0.471182. Batch_loss: 1.450701 \n",
      "Batch: 4409. Acc: 0.479452. Loss: 1.447296. Batch_acc: 0.479955. Batch_loss: 1.436634 \n",
      "Batch: 4410. Acc: 0.479462. Loss: 1.447268. Batch_acc: 0.524927. Batch_loss: 1.321504 \n",
      "Batch: 4411. Acc: 0.479465. Loss: 1.447256. Batch_acc: 0.493151. Batch_loss: 1.394030 \n",
      "Batch: 4412. Acc: 0.479470. Loss: 1.447237. Batch_acc: 0.501143. Batch_loss: 1.365157 \n",
      "Batch: 4413. Acc: 0.479472. Loss: 1.447238. Batch_acc: 0.485536. Batch_loss: 1.450400 \n",
      "Batch: 4414. Acc: 0.479472. Loss: 1.447227. Batch_acc: 0.479339. Batch_loss: 1.398182 \n",
      "Batch: 4415. Acc: 0.479478. Loss: 1.447208. Batch_acc: 0.509655. Batch_loss: 1.360735 \n",
      "Batch: 4416. Acc: 0.479484. Loss: 1.447196. Batch_acc: 0.506448. Batch_loss: 1.397256 \n",
      "Batch: 4417. Acc: 0.479486. Loss: 1.447193. Batch_acc: 0.485795. Batch_loss: 1.430865 \n",
      "Batch: 4418. Acc: 0.479492. Loss: 1.447177. Batch_acc: 0.508357. Batch_loss: 1.378208 \n",
      "Batch: 4419. Acc: 0.479495. Loss: 1.447172. Batch_acc: 0.492147. Batch_loss: 1.423524 \n",
      "Batch: 4420. Acc: 0.479504. Loss: 1.447153. Batch_acc: 0.515982. Batch_loss: 1.365237 \n",
      "Batch: 4421. Acc: 0.479504. Loss: 1.447150. Batch_acc: 0.479909. Batch_loss: 1.435118 \n",
      "Batch: 4422. Acc: 0.479507. Loss: 1.447139. Batch_acc: 0.494286. Batch_loss: 1.396728 \n",
      "Batch: 4423. Acc: 0.479513. Loss: 1.447121. Batch_acc: 0.506038. Batch_loss: 1.369670 \n",
      "Batch: 4424. Acc: 0.479515. Loss: 1.447112. Batch_acc: 0.489819. Batch_loss: 1.406605 \n",
      "Batch: 4425. Acc: 0.479520. Loss: 1.447094. Batch_acc: 0.498866. Batch_loss: 1.367971 \n",
      "Batch: 4426. Acc: 0.479523. Loss: 1.447085. Batch_acc: 0.494531. Batch_loss: 1.405584 \n",
      "Batch: 4427. Acc: 0.479531. Loss: 1.447068. Batch_acc: 0.515571. Batch_loss: 1.373633 \n",
      "Batch: 4428. Acc: 0.479542. Loss: 1.447039. Batch_acc: 0.526227. Batch_loss: 1.321035 \n",
      "Batch: 4429. Acc: 0.479545. Loss: 1.447032. Batch_acc: 0.492290. Batch_loss: 1.417193 \n",
      "Batch: 4430. Acc: 0.479550. Loss: 1.447022. Batch_acc: 0.503148. Batch_loss: 1.401502 \n",
      "Batch: 4431. Acc: 0.479551. Loss: 1.447014. Batch_acc: 0.482699. Batch_loss: 1.411877 \n",
      "Batch: 4432. Acc: 0.479552. Loss: 1.447009. Batch_acc: 0.483352. Batch_loss: 1.425163 \n",
      "Batch: 4433. Acc: 0.479556. Loss: 1.446993. Batch_acc: 0.496793. Batch_loss: 1.376019 \n",
      "Batch: 4434. Acc: 0.479556. Loss: 1.446987. Batch_acc: 0.481928. Batch_loss: 1.420520 \n",
      "Batch: 4435. Acc: 0.479558. Loss: 1.446987. Batch_acc: 0.485948. Batch_loss: 1.445889 \n",
      "Batch: 4436. Acc: 0.479562. Loss: 1.446975. Batch_acc: 0.498559. Batch_loss: 1.392495 \n",
      "Batch: 4437. Acc: 0.479568. Loss: 1.446956. Batch_acc: 0.503982. Batch_loss: 1.365412 \n",
      "Batch: 4438. Acc: 0.479580. Loss: 1.446923. Batch_acc: 0.534191. Batch_loss: 1.298598 \n",
      "Batch: 4439. Acc: 0.479583. Loss: 1.446906. Batch_acc: 0.495112. Batch_loss: 1.368873 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4440. Acc: 0.479582. Loss: 1.446905. Batch_acc: 0.474457. Batch_loss: 1.445511 \n",
      "Batch: 4441. Acc: 0.479584. Loss: 1.446898. Batch_acc: 0.487928. Batch_loss: 1.415922 \n",
      "Batch: 4442. Acc: 0.479587. Loss: 1.446886. Batch_acc: 0.491466. Batch_loss: 1.389617 \n",
      "Batch: 4443. Acc: 0.479588. Loss: 1.446877. Batch_acc: 0.487945. Batch_loss: 1.409806 \n",
      "Batch: 4444. Acc: 0.479595. Loss: 1.446857. Batch_acc: 0.507541. Batch_loss: 1.356020 \n",
      "Batch: 4445. Acc: 0.479598. Loss: 1.446849. Batch_acc: 0.493649. Batch_loss: 1.410835 \n",
      "Batch: 4446. Acc: 0.479598. Loss: 1.446848. Batch_acc: 0.478495. Batch_loss: 1.444342 \n",
      "Batch: 4447. Acc: 0.479600. Loss: 1.446842. Batch_acc: 0.489137. Batch_loss: 1.418855 \n",
      "Batch: 4448. Acc: 0.479609. Loss: 1.446813. Batch_acc: 0.517986. Batch_loss: 1.320169 \n",
      "Batch: 4449. Acc: 0.479611. Loss: 1.446802. Batch_acc: 0.490173. Batch_loss: 1.398456 \n",
      "Batch: 4450. Acc: 0.479612. Loss: 1.446797. Batch_acc: 0.484302. Batch_loss: 1.423822 \n",
      "Batch: 4451. Acc: 0.479615. Loss: 1.446787. Batch_acc: 0.490620. Batch_loss: 1.404468 \n",
      "Batch: 4452. Acc: 0.479619. Loss: 1.446775. Batch_acc: 0.501732. Batch_loss: 1.395009 \n",
      "Batch: 4453. Acc: 0.479620. Loss: 1.446769. Batch_acc: 0.481246. Batch_loss: 1.416460 \n",
      "Batch: 4454. Acc: 0.479625. Loss: 1.446755. Batch_acc: 0.501684. Batch_loss: 1.385714 \n",
      "Batch: 4455. Acc: 0.479626. Loss: 1.446739. Batch_acc: 0.484095. Batch_loss: 1.375708 \n",
      "Batch: 4456. Acc: 0.479637. Loss: 1.446710. Batch_acc: 0.526770. Batch_loss: 1.316286 \n",
      "Batch: 4457. Acc: 0.479638. Loss: 1.446701. Batch_acc: 0.484638. Batch_loss: 1.409148 \n",
      "Batch: 4458. Acc: 0.479639. Loss: 1.446691. Batch_acc: 0.486301. Batch_loss: 1.401935 \n",
      "Batch: 4459. Acc: 0.479641. Loss: 1.446689. Batch_acc: 0.489595. Batch_loss: 1.435478 \n",
      "Batch: 4460. Acc: 0.479653. Loss: 1.446653. Batch_acc: 0.533567. Batch_loss: 1.283589 \n",
      "Batch: 4461. Acc: 0.479658. Loss: 1.446637. Batch_acc: 0.502591. Batch_loss: 1.376629 \n",
      "Batch: 4462. Acc: 0.479658. Loss: 1.446636. Batch_acc: 0.475850. Batch_loss: 1.442896 \n",
      "Batch: 4463. Acc: 0.479662. Loss: 1.446625. Batch_acc: 0.498008. Batch_loss: 1.397238 \n",
      "Batch: 4464. Acc: 0.479663. Loss: 1.446621. Batch_acc: 0.485976. Batch_loss: 1.430218 \n",
      "Batch: 4465. Acc: 0.479670. Loss: 1.446598. Batch_acc: 0.511485. Batch_loss: 1.347231 \n",
      "Batch: 4466. Acc: 0.479677. Loss: 1.446580. Batch_acc: 0.506881. Batch_loss: 1.362957 \n",
      "Batch: 4467. Acc: 0.479684. Loss: 1.446558. Batch_acc: 0.514513. Batch_loss: 1.350424 \n",
      "Batch: 4468. Acc: 0.479694. Loss: 1.446534. Batch_acc: 0.523864. Batch_loss: 1.341252 \n",
      "Batch: 4469. Acc: 0.479703. Loss: 1.446513. Batch_acc: 0.518414. Batch_loss: 1.355048 \n",
      "Batch: 4470. Acc: 0.479711. Loss: 1.446491. Batch_acc: 0.512349. Batch_loss: 1.347412 \n",
      "Batch: 4471. Acc: 0.479714. Loss: 1.446479. Batch_acc: 0.495538. Batch_loss: 1.391200 \n",
      "Batch: 4472. Acc: 0.479716. Loss: 1.446470. Batch_acc: 0.488242. Batch_loss: 1.409243 \n",
      "Batch: 4473. Acc: 0.479717. Loss: 1.446463. Batch_acc: 0.484118. Batch_loss: 1.413123 \n",
      "Batch: 4474. Acc: 0.479719. Loss: 1.446455. Batch_acc: 0.487165. Batch_loss: 1.410105 \n",
      "Batch: 4475. Acc: 0.479726. Loss: 1.446433. Batch_acc: 0.512586. Batch_loss: 1.348536 \n",
      "Batch: 4476. Acc: 0.479726. Loss: 1.446428. Batch_acc: 0.477810. Batch_loss: 1.421726 \n",
      "Batch: 4477. Acc: 0.479733. Loss: 1.446405. Batch_acc: 0.513746. Batch_loss: 1.344333 \n",
      "Batch: 4478. Acc: 0.479737. Loss: 1.446392. Batch_acc: 0.495707. Batch_loss: 1.390903 \n",
      "Batch: 4479. Acc: 0.479741. Loss: 1.446379. Batch_acc: 0.500562. Batch_loss: 1.387599 \n",
      "Batch: 4480. Acc: 0.479745. Loss: 1.446372. Batch_acc: 0.496602. Batch_loss: 1.415256 \n",
      "Batch: 4481. Acc: 0.479748. Loss: 1.446360. Batch_acc: 0.490196. Batch_loss: 1.392017 \n",
      "Batch: 4482. Acc: 0.479750. Loss: 1.446351. Batch_acc: 0.490544. Batch_loss: 1.407668 \n",
      "Batch: 4483. Acc: 0.479756. Loss: 1.446334. Batch_acc: 0.508611. Batch_loss: 1.367727 \n",
      "Batch: 4484. Acc: 0.479762. Loss: 1.446320. Batch_acc: 0.505572. Batch_loss: 1.384346 \n",
      "Batch: 4485. Acc: 0.479764. Loss: 1.446314. Batch_acc: 0.487062. Batch_loss: 1.420245 \n",
      "Batch: 4486. Acc: 0.479760. Loss: 1.446318. Batch_acc: 0.462514. Batch_loss: 1.460750 \n",
      "Batch: 4487. Acc: 0.479766. Loss: 1.446300. Batch_acc: 0.507471. Batch_loss: 1.365933 \n",
      "Batch: 4488. Acc: 0.479770. Loss: 1.446280. Batch_acc: 0.497412. Batch_loss: 1.359409 \n",
      "Batch: 4489. Acc: 0.479777. Loss: 1.446260. Batch_acc: 0.512153. Batch_loss: 1.355862 \n",
      "Batch: 4490. Acc: 0.479779. Loss: 1.446248. Batch_acc: 0.487062. Batch_loss: 1.391932 \n",
      "Batch: 4491. Acc: 0.479781. Loss: 1.446238. Batch_acc: 0.489971. Batch_loss: 1.398850 \n",
      "Batch: 4492. Acc: 0.479787. Loss: 1.446224. Batch_acc: 0.505774. Batch_loss: 1.386836 \n",
      "Batch: 4493. Acc: 0.479787. Loss: 1.446223. Batch_acc: 0.479522. Batch_loss: 1.441079 \n",
      "Batch: 4494. Acc: 0.479789. Loss: 1.446217. Batch_acc: 0.487875. Batch_loss: 1.418666 \n",
      "Batch: 4495. Acc: 0.479796. Loss: 1.446197. Batch_acc: 0.513649. Batch_loss: 1.357208 \n",
      "Batch: 4496. Acc: 0.479802. Loss: 1.446178. Batch_acc: 0.504425. Batch_loss: 1.361571 \n",
      "Batch: 4497. Acc: 0.479809. Loss: 1.446152. Batch_acc: 0.514994. Batch_loss: 1.329011 \n",
      "Batch: 4498. Acc: 0.479812. Loss: 1.446147. Batch_acc: 0.493039. Batch_loss: 1.423345 \n",
      "Batch: 4499. Acc: 0.479818. Loss: 1.446126. Batch_acc: 0.506651. Batch_loss: 1.348538 \n",
      "Batch: 4500. Acc: 0.479818. Loss: 1.446121. Batch_acc: 0.478681. Batch_loss: 1.423123 \n",
      "Batch: 4501. Acc: 0.479823. Loss: 1.446104. Batch_acc: 0.504005. Batch_loss: 1.373305 \n",
      "Batch: 4502. Acc: 0.479832. Loss: 1.446082. Batch_acc: 0.519144. Batch_loss: 1.348641 \n",
      "Batch: 4503. Acc: 0.479836. Loss: 1.446069. Batch_acc: 0.497952. Batch_loss: 1.383741 \n",
      "Batch: 4504. Acc: 0.479840. Loss: 1.446063. Batch_acc: 0.498834. Batch_loss: 1.419378 \n",
      "Batch: 4505. Acc: 0.479846. Loss: 1.446053. Batch_acc: 0.504122. Batch_loss: 1.399829 \n",
      "Batch: 4506. Acc: 0.479845. Loss: 1.446045. Batch_acc: 0.478032. Batch_loss: 1.408875 \n",
      "Batch: 4507. Acc: 0.479851. Loss: 1.446027. Batch_acc: 0.506222. Batch_loss: 1.366901 \n",
      "Batch: 4508. Acc: 0.479852. Loss: 1.446023. Batch_acc: 0.484179. Batch_loss: 1.427269 \n",
      "Batch: 4509. Acc: 0.479856. Loss: 1.446016. Batch_acc: 0.498557. Batch_loss: 1.413603 \n",
      "Batch: 4510. Acc: 0.479861. Loss: 1.446000. Batch_acc: 0.501175. Batch_loss: 1.373213 \n",
      "Batch: 4511. Acc: 0.479865. Loss: 1.445985. Batch_acc: 0.497086. Batch_loss: 1.376443 \n",
      "Batch: 4512. Acc: 0.479872. Loss: 1.445967. Batch_acc: 0.510771. Batch_loss: 1.369583 \n",
      "Batch: 4513. Acc: 0.479883. Loss: 1.445944. Batch_acc: 0.527192. Batch_loss: 1.344984 \n",
      "Batch: 4514. Acc: 0.479884. Loss: 1.445933. Batch_acc: 0.485981. Batch_loss: 1.394022 \n",
      "Batch: 4515. Acc: 0.479886. Loss: 1.445916. Batch_acc: 0.490847. Batch_loss: 1.368518 \n",
      "Batch: 4516. Acc: 0.479897. Loss: 1.445886. Batch_acc: 0.527293. Batch_loss: 1.313152 \n",
      "Batch: 4517. Acc: 0.479902. Loss: 1.445873. Batch_acc: 0.503163. Batch_loss: 1.390005 \n",
      "Batch: 4518. Acc: 0.479908. Loss: 1.445859. Batch_acc: 0.507799. Batch_loss: 1.381923 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.47990838626909166. Loss per char: 1.4458591214969834. Time: 1627217712.4856887\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 20, 17, 23, 26, 20, 21, 20,\n",
      "        22, 17, 26, 22,  1, 12,  1, 14, 17, 15, 22, 15,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.479913. Loss: 1.445845. Batch_acc: 0.501730. Batch_loss: 1.380422 \n",
      "Batch: 4520. Acc: 0.479920. Loss: 1.445824. Batch_acc: 0.512406. Batch_loss: 1.349802 \n",
      "Batch: 4521. Acc: 0.479922. Loss: 1.445823. Batch_acc: 0.488014. Batch_loss: 1.443522 \n",
      "Batch: 4522. Acc: 0.479928. Loss: 1.445805. Batch_acc: 0.507471. Batch_loss: 1.366668 \n",
      "Batch: 4523. Acc: 0.479935. Loss: 1.445785. Batch_acc: 0.508018. Batch_loss: 1.353006 \n",
      "Batch: 4524. Acc: 0.479936. Loss: 1.445776. Batch_acc: 0.488109. Batch_loss: 1.407429 \n",
      "Batch: 4525. Acc: 0.479945. Loss: 1.445758. Batch_acc: 0.521562. Batch_loss: 1.364004 \n",
      "Batch: 4526. Acc: 0.479950. Loss: 1.445744. Batch_acc: 0.498839. Batch_loss: 1.378847 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4527. Acc: 0.479947. Loss: 1.445750. Batch_acc: 0.469783. Batch_loss: 1.474753 \n",
      "Batch: 4528. Acc: 0.479954. Loss: 1.445730. Batch_acc: 0.509370. Batch_loss: 1.356639 \n",
      "Batch: 4529. Acc: 0.479956. Loss: 1.445726. Batch_acc: 0.490730. Batch_loss: 1.424330 \n",
      "Batch: 4530. Acc: 0.479964. Loss: 1.445708. Batch_acc: 0.513953. Batch_loss: 1.364218 \n",
      "Batch: 4531. Acc: 0.479967. Loss: 1.445696. Batch_acc: 0.496540. Batch_loss: 1.392179 \n",
      "Batch: 4532. Acc: 0.479978. Loss: 1.445670. Batch_acc: 0.527858. Batch_loss: 1.328122 \n",
      "Batch: 4533. Acc: 0.479984. Loss: 1.445654. Batch_acc: 0.509510. Batch_loss: 1.373049 \n",
      "Batch: 4534. Acc: 0.479988. Loss: 1.445650. Batch_acc: 0.496262. Batch_loss: 1.429307 \n",
      "Batch: 4535. Acc: 0.479995. Loss: 1.445632. Batch_acc: 0.511732. Batch_loss: 1.363280 \n",
      "Batch: 4536. Acc: 0.480000. Loss: 1.445612. Batch_acc: 0.502600. Batch_loss: 1.355834 \n",
      "Batch: 4537. Acc: 0.480004. Loss: 1.445599. Batch_acc: 0.496205. Batch_loss: 1.384400 \n",
      "Batch: 4538. Acc: 0.480010. Loss: 1.445584. Batch_acc: 0.508028. Batch_loss: 1.377259 \n",
      "Batch: 4539. Acc: 0.480016. Loss: 1.445578. Batch_acc: 0.506721. Batch_loss: 1.418051 \n",
      "Batch: 4540. Acc: 0.480023. Loss: 1.445558. Batch_acc: 0.511601. Batch_loss: 1.357544 \n",
      "Batch: 4541. Acc: 0.480028. Loss: 1.445547. Batch_acc: 0.504603. Batch_loss: 1.392741 \n",
      "Batch: 4542. Acc: 0.480032. Loss: 1.445533. Batch_acc: 0.498585. Batch_loss: 1.384526 \n",
      "Batch: 4543. Acc: 0.480035. Loss: 1.445525. Batch_acc: 0.491633. Batch_loss: 1.408201 \n",
      "Batch: 4544. Acc: 0.480043. Loss: 1.445499. Batch_acc: 0.518560. Batch_loss: 1.331197 \n",
      "Batch: 4545. Acc: 0.480047. Loss: 1.445491. Batch_acc: 0.497719. Batch_loss: 1.407696 \n",
      "Batch: 4546. Acc: 0.480046. Loss: 1.445492. Batch_acc: 0.473870. Batch_loss: 1.452288 \n",
      "Batch: 4547. Acc: 0.480051. Loss: 1.445474. Batch_acc: 0.503488. Batch_loss: 1.359566 \n",
      "Batch: 4548. Acc: 0.480051. Loss: 1.445466. Batch_acc: 0.481567. Batch_loss: 1.412482 \n",
      "Batch: 4549. Acc: 0.480054. Loss: 1.445450. Batch_acc: 0.492415. Batch_loss: 1.369280 \n",
      "Batch: 4550. Acc: 0.480056. Loss: 1.445437. Batch_acc: 0.490262. Batch_loss: 1.388251 \n",
      "Batch: 4551. Acc: 0.480060. Loss: 1.445433. Batch_acc: 0.495591. Batch_loss: 1.425414 \n",
      "Batch: 4552. Acc: 0.480064. Loss: 1.445415. Batch_acc: 0.499135. Batch_loss: 1.364949 \n",
      "Batch: 4553. Acc: 0.480070. Loss: 1.445391. Batch_acc: 0.509572. Batch_loss: 1.339549 \n",
      "Batch: 4554. Acc: 0.480078. Loss: 1.445368. Batch_acc: 0.513341. Batch_loss: 1.339719 \n",
      "Batch: 4555. Acc: 0.480086. Loss: 1.445350. Batch_acc: 0.516968. Batch_loss: 1.362156 \n",
      "Batch: 4556. Acc: 0.480090. Loss: 1.445336. Batch_acc: 0.500577. Batch_loss: 1.384634 \n",
      "Batch: 4557. Acc: 0.480088. Loss: 1.445334. Batch_acc: 0.470000. Batch_loss: 1.432185 \n",
      "Batch: 4558. Acc: 0.480092. Loss: 1.445321. Batch_acc: 0.495455. Batch_loss: 1.387406 \n",
      "Batch: 4559. Acc: 0.480101. Loss: 1.445299. Batch_acc: 0.523838. Batch_loss: 1.343251 \n",
      "Batch: 4560. Acc: 0.480110. Loss: 1.445269. Batch_acc: 0.520067. Batch_loss: 1.312503 \n",
      "Batch: 4561. Acc: 0.480116. Loss: 1.445254. Batch_acc: 0.506780. Batch_loss: 1.378873 \n",
      "Batch: 4562. Acc: 0.480118. Loss: 1.445242. Batch_acc: 0.488928. Batch_loss: 1.388608 \n",
      "Batch: 4563. Acc: 0.480124. Loss: 1.445226. Batch_acc: 0.507135. Batch_loss: 1.376045 \n",
      "Batch: 4564. Acc: 0.480127. Loss: 1.445219. Batch_acc: 0.494428. Batch_loss: 1.412985 \n",
      "Batch: 4565. Acc: 0.480138. Loss: 1.445193. Batch_acc: 0.530415. Batch_loss: 1.327695 \n",
      "Batch: 4566. Acc: 0.480141. Loss: 1.445186. Batch_acc: 0.493031. Batch_loss: 1.415690 \n",
      "Batch: 4567. Acc: 0.480146. Loss: 1.445176. Batch_acc: 0.502053. Batch_loss: 1.397770 \n",
      "Batch: 4568. Acc: 0.480149. Loss: 1.445167. Batch_acc: 0.493197. Batch_loss: 1.404934 \n",
      "Batch: 4569. Acc: 0.480156. Loss: 1.445151. Batch_acc: 0.514518. Batch_loss: 1.372012 \n",
      "Batch: 4570. Acc: 0.480161. Loss: 1.445136. Batch_acc: 0.501140. Batch_loss: 1.375952 \n",
      "Batch: 4571. Acc: 0.480164. Loss: 1.445128. Batch_acc: 0.494179. Batch_loss: 1.408506 \n",
      "Batch: 4572. Acc: 0.480168. Loss: 1.445119. Batch_acc: 0.497146. Batch_loss: 1.401018 \n",
      "Batch: 4573. Acc: 0.480167. Loss: 1.445113. Batch_acc: 0.475533. Batch_loss: 1.420943 \n",
      "Batch: 4574. Acc: 0.480175. Loss: 1.445092. Batch_acc: 0.520142. Batch_loss: 1.342846 \n",
      "Batch: 4575. Acc: 0.480180. Loss: 1.445077. Batch_acc: 0.501140. Batch_loss: 1.377051 \n",
      "Batch: 4576. Acc: 0.480184. Loss: 1.445064. Batch_acc: 0.499702. Batch_loss: 1.386370 \n",
      "Batch: 4577. Acc: 0.480190. Loss: 1.445046. Batch_acc: 0.506329. Batch_loss: 1.360874 \n",
      "Batch: 4578. Acc: 0.480196. Loss: 1.445034. Batch_acc: 0.507808. Batch_loss: 1.391611 \n",
      "Batch: 4579. Acc: 0.480198. Loss: 1.445026. Batch_acc: 0.490105. Batch_loss: 1.406828 \n",
      "Batch: 4580. Acc: 0.480202. Loss: 1.445015. Batch_acc: 0.501136. Batch_loss: 1.393487 \n",
      "Batch: 4581. Acc: 0.480211. Loss: 1.444994. Batch_acc: 0.517320. Batch_loss: 1.354050 \n",
      "Batch: 4582. Acc: 0.480223. Loss: 1.444962. Batch_acc: 0.535774. Batch_loss: 1.300812 \n",
      "Batch: 4583. Acc: 0.480226. Loss: 1.444947. Batch_acc: 0.493856. Batch_loss: 1.375897 \n",
      "Batch: 4584. Acc: 0.480231. Loss: 1.444931. Batch_acc: 0.504734. Batch_loss: 1.369876 \n",
      "Batch: 4585. Acc: 0.480235. Loss: 1.444918. Batch_acc: 0.498856. Batch_loss: 1.385000 \n",
      "Batch: 4586. Acc: 0.480240. Loss: 1.444902. Batch_acc: 0.501705. Batch_loss: 1.373383 \n",
      "Batch: 4587. Acc: 0.480249. Loss: 1.444879. Batch_acc: 0.519166. Batch_loss: 1.340634 \n",
      "Batch: 4588. Acc: 0.480260. Loss: 1.444853. Batch_acc: 0.532646. Batch_loss: 1.326389 \n",
      "Batch: 4589. Acc: 0.480268. Loss: 1.444831. Batch_acc: 0.516964. Batch_loss: 1.341828 \n",
      "Batch: 4590. Acc: 0.480275. Loss: 1.444811. Batch_acc: 0.512600. Batch_loss: 1.357105 \n",
      "Batch: 4591. Acc: 0.480283. Loss: 1.444794. Batch_acc: 0.517003. Batch_loss: 1.366891 \n",
      "Batch: 4592. Acc: 0.480288. Loss: 1.444779. Batch_acc: 0.500859. Batch_loss: 1.373186 \n",
      "Batch: 4593. Acc: 0.480287. Loss: 1.444775. Batch_acc: 0.477855. Batch_loss: 1.428917 \n",
      "Batch: 4594. Acc: 0.480294. Loss: 1.444765. Batch_acc: 0.512080. Batch_loss: 1.396370 \n",
      "Batch: 4595. Acc: 0.480296. Loss: 1.444759. Batch_acc: 0.487861. Batch_loss: 1.417917 \n",
      "Batch: 4596. Acc: 0.480302. Loss: 1.444749. Batch_acc: 0.508923. Batch_loss: 1.395652 \n",
      "Batch: 4597. Acc: 0.480311. Loss: 1.444724. Batch_acc: 0.522034. Batch_loss: 1.335443 \n",
      "Batch: 4598. Acc: 0.480312. Loss: 1.444720. Batch_acc: 0.486517. Batch_loss: 1.426601 \n",
      "Batch: 4599. Acc: 0.480322. Loss: 1.444694. Batch_acc: 0.525346. Batch_loss: 1.323437 \n",
      "Batch: 4600. Acc: 0.480324. Loss: 1.444690. Batch_acc: 0.488532. Batch_loss: 1.426260 \n",
      "Batch: 4601. Acc: 0.480329. Loss: 1.444666. Batch_acc: 0.504805. Batch_loss: 1.337520 \n",
      "Batch: 4602. Acc: 0.480329. Loss: 1.444675. Batch_acc: 0.478186. Batch_loss: 1.486480 \n",
      "Batch: 4603. Acc: 0.480333. Loss: 1.444666. Batch_acc: 0.499133. Batch_loss: 1.402634 \n",
      "Batch: 4604. Acc: 0.480338. Loss: 1.444650. Batch_acc: 0.501135. Batch_loss: 1.369391 \n",
      "Batch: 4605. Acc: 0.480338. Loss: 1.444647. Batch_acc: 0.480000. Batch_loss: 1.432472 \n",
      "Batch: 4606. Acc: 0.480340. Loss: 1.444641. Batch_acc: 0.491728. Batch_loss: 1.414341 \n",
      "Batch: 4607. Acc: 0.480338. Loss: 1.444638. Batch_acc: 0.472042. Batch_loss: 1.430381 \n",
      "Batch: 4608. Acc: 0.480345. Loss: 1.444615. Batch_acc: 0.511098. Batch_loss: 1.339394 \n",
      "Batch: 4609. Acc: 0.480354. Loss: 1.444585. Batch_acc: 0.524244. Batch_loss: 1.309237 \n",
      "Batch: 4610. Acc: 0.480355. Loss: 1.444589. Batch_acc: 0.482353. Batch_loss: 1.463685 \n",
      "Batch: 4611. Acc: 0.480357. Loss: 1.444584. Batch_acc: 0.492072. Batch_loss: 1.421716 \n",
      "Batch: 4612. Acc: 0.480358. Loss: 1.444585. Batch_acc: 0.483478. Batch_loss: 1.448009 \n",
      "Batch: 4613. Acc: 0.480363. Loss: 1.444567. Batch_acc: 0.503130. Batch_loss: 1.360574 \n",
      "Batch: 4614. Acc: 0.480368. Loss: 1.444553. Batch_acc: 0.503330. Batch_loss: 1.383051 \n",
      "Batch: 4615. Acc: 0.480376. Loss: 1.444526. Batch_acc: 0.515429. Batch_loss: 1.322163 \n",
      "Batch: 4616. Acc: 0.480384. Loss: 1.444501. Batch_acc: 0.520444. Batch_loss: 1.324461 \n",
      "Batch: 4617. Acc: 0.480391. Loss: 1.444478. Batch_acc: 0.511706. Batch_loss: 1.343280 \n",
      "Batch: 4618. Acc: 0.480397. Loss: 1.444466. Batch_acc: 0.503704. Batch_loss: 1.388185 \n",
      "Batch: 4619. Acc: 0.480394. Loss: 1.444469. Batch_acc: 0.468060. Batch_loss: 1.460427 \n",
      "Batch: 4620. Acc: 0.480399. Loss: 1.444454. Batch_acc: 0.502320. Batch_loss: 1.372660 \n",
      "Batch: 4621. Acc: 0.480406. Loss: 1.444435. Batch_acc: 0.513482. Batch_loss: 1.357680 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4622. Acc: 0.480411. Loss: 1.444426. Batch_acc: 0.503505. Batch_loss: 1.399310 \n",
      "Batch: 4623. Acc: 0.480416. Loss: 1.444418. Batch_acc: 0.505137. Batch_loss: 1.408845 \n",
      "Batch: 4624. Acc: 0.480420. Loss: 1.444404. Batch_acc: 0.497507. Batch_loss: 1.381767 \n",
      "Batch: 4625. Acc: 0.480421. Loss: 1.444401. Batch_acc: 0.486736. Batch_loss: 1.431001 \n",
      "Batch: 4626. Acc: 0.480430. Loss: 1.444373. Batch_acc: 0.518126. Batch_loss: 1.319650 \n",
      "Batch: 4627. Acc: 0.480439. Loss: 1.444354. Batch_acc: 0.521864. Batch_loss: 1.354002 \n",
      "Batch: 4628. Acc: 0.480445. Loss: 1.444334. Batch_acc: 0.510006. Batch_loss: 1.353029 \n",
      "Batch: 4629. Acc: 0.480448. Loss: 1.444313. Batch_acc: 0.494531. Batch_loss: 1.347469 \n",
      "Batch: 4630. Acc: 0.480459. Loss: 1.444287. Batch_acc: 0.529073. Batch_loss: 1.325063 \n",
      "Batch: 4631. Acc: 0.480458. Loss: 1.444286. Batch_acc: 0.477483. Batch_loss: 1.440633 \n",
      "Batch: 4632. Acc: 0.480460. Loss: 1.444279. Batch_acc: 0.492529. Batch_loss: 1.412100 \n",
      "Batch: 4633. Acc: 0.480471. Loss: 1.444251. Batch_acc: 0.527263. Batch_loss: 1.317426 \n",
      "Batch: 4634. Acc: 0.480476. Loss: 1.444231. Batch_acc: 0.506395. Batch_loss: 1.347470 \n",
      "Batch: 4635. Acc: 0.480483. Loss: 1.444208. Batch_acc: 0.510800. Batch_loss: 1.336345 \n",
      "Batch: 4636. Acc: 0.480489. Loss: 1.444195. Batch_acc: 0.506464. Batch_loss: 1.384612 \n",
      "Batch: 4637. Acc: 0.480496. Loss: 1.444178. Batch_acc: 0.518235. Batch_loss: 1.365547 \n",
      "Batch: 4638. Acc: 0.480501. Loss: 1.444164. Batch_acc: 0.501131. Batch_loss: 1.380424 \n",
      "Batch: 4639. Acc: 0.480507. Loss: 1.444148. Batch_acc: 0.510689. Batch_loss: 1.366569 \n",
      "Batch: 4640. Acc: 0.480515. Loss: 1.444129. Batch_acc: 0.516185. Batch_loss: 1.356061 \n",
      "Batch: 4641. Acc: 0.480517. Loss: 1.444117. Batch_acc: 0.489983. Batch_loss: 1.388299 \n",
      "Batch: 4642. Acc: 0.480522. Loss: 1.444104. Batch_acc: 0.502603. Batch_loss: 1.385457 \n",
      "Batch: 4643. Acc: 0.480526. Loss: 1.444097. Batch_acc: 0.501744. Batch_loss: 1.411902 \n",
      "Batch: 4644. Acc: 0.480530. Loss: 1.444088. Batch_acc: 0.496548. Batch_loss: 1.398435 \n",
      "Batch: 4645. Acc: 0.480533. Loss: 1.444081. Batch_acc: 0.494044. Batch_loss: 1.412060 \n",
      "Batch: 4646. Acc: 0.480538. Loss: 1.444063. Batch_acc: 0.507817. Batch_loss: 1.363783 \n",
      "Batch: 4647. Acc: 0.480546. Loss: 1.444042. Batch_acc: 0.517023. Batch_loss: 1.345236 \n",
      "Batch: 4648. Acc: 0.480552. Loss: 1.444024. Batch_acc: 0.503880. Batch_loss: 1.360946 \n",
      "Batch: 4649. Acc: 0.480554. Loss: 1.444010. Batch_acc: 0.493294. Batch_loss: 1.378009 \n",
      "Batch: 4650. Acc: 0.480554. Loss: 1.444012. Batch_acc: 0.480000. Batch_loss: 1.455865 \n",
      "Batch: 4651. Acc: 0.480560. Loss: 1.443997. Batch_acc: 0.506038. Batch_loss: 1.374175 \n",
      "Batch: 4652. Acc: 0.480562. Loss: 1.443988. Batch_acc: 0.494145. Batch_loss: 1.398355 \n",
      "Batch: 4653. Acc: 0.480566. Loss: 1.443973. Batch_acc: 0.497691. Batch_loss: 1.377286 \n",
      "Batch: 4654. Acc: 0.480568. Loss: 1.443966. Batch_acc: 0.487679. Batch_loss: 1.409209 \n",
      "Batch: 4655. Acc: 0.480573. Loss: 1.443949. Batch_acc: 0.504318. Batch_loss: 1.363692 \n",
      "Batch: 4656. Acc: 0.480579. Loss: 1.443930. Batch_acc: 0.508028. Batch_loss: 1.355666 \n",
      "Batch: 4657. Acc: 0.480584. Loss: 1.443913. Batch_acc: 0.505760. Batch_loss: 1.365148 \n",
      "Batch: 4658. Acc: 0.480590. Loss: 1.443887. Batch_acc: 0.510029. Batch_loss: 1.323398 \n",
      "Batch: 4659. Acc: 0.480600. Loss: 1.443856. Batch_acc: 0.524646. Batch_loss: 1.303057 \n",
      "Batch: 4660. Acc: 0.480608. Loss: 1.443836. Batch_acc: 0.520468. Batch_loss: 1.347456 \n",
      "Batch: 4661. Acc: 0.480617. Loss: 1.443810. Batch_acc: 0.521302. Batch_loss: 1.319384 \n",
      "Batch: 4662. Acc: 0.480625. Loss: 1.443792. Batch_acc: 0.515982. Batch_loss: 1.361834 \n",
      "Batch: 4663. Acc: 0.480629. Loss: 1.443781. Batch_acc: 0.501684. Batch_loss: 1.392141 \n",
      "Batch: 4664. Acc: 0.480636. Loss: 1.443757. Batch_acc: 0.512909. Batch_loss: 1.331407 \n",
      "Batch: 4665. Acc: 0.480641. Loss: 1.443738. Batch_acc: 0.505488. Batch_loss: 1.358175 \n",
      "Batch: 4666. Acc: 0.480645. Loss: 1.443728. Batch_acc: 0.497083. Batch_loss: 1.397184 \n",
      "Batch: 4667. Acc: 0.480646. Loss: 1.443727. Batch_acc: 0.486612. Batch_loss: 1.439139 \n",
      "Batch: 4668. Acc: 0.480651. Loss: 1.443715. Batch_acc: 0.505245. Batch_loss: 1.384021 \n",
      "Batch: 4669. Acc: 0.480654. Loss: 1.443707. Batch_acc: 0.494111. Batch_loss: 1.405046 \n",
      "Batch: 4670. Acc: 0.480662. Loss: 1.443684. Batch_acc: 0.515289. Batch_loss: 1.341355 \n",
      "Batch: 4671. Acc: 0.480663. Loss: 1.443677. Batch_acc: 0.484384. Batch_loss: 1.409139 \n",
      "Batch: 4672. Acc: 0.480667. Loss: 1.443662. Batch_acc: 0.501404. Batch_loss: 1.376895 \n",
      "Batch: 4673. Acc: 0.480671. Loss: 1.443655. Batch_acc: 0.498554. Batch_loss: 1.407678 \n",
      "Batch: 4674. Acc: 0.480675. Loss: 1.443636. Batch_acc: 0.502027. Batch_loss: 1.356513 \n",
      "Batch: 4675. Acc: 0.480683. Loss: 1.443617. Batch_acc: 0.515819. Batch_loss: 1.356454 \n",
      "Batch: 4676. Acc: 0.480687. Loss: 1.443603. Batch_acc: 0.501155. Batch_loss: 1.378668 \n",
      "Batch: 4677. Acc: 0.480700. Loss: 1.443571. Batch_acc: 0.539744. Batch_loss: 1.296856 \n",
      "Batch: 4678. Acc: 0.480709. Loss: 1.443549. Batch_acc: 0.519296. Batch_loss: 1.342832 \n",
      "Batch: 4679. Acc: 0.480711. Loss: 1.443544. Batch_acc: 0.489728. Batch_loss: 1.421185 \n",
      "Batch: 4680. Acc: 0.480708. Loss: 1.443552. Batch_acc: 0.467911. Batch_loss: 1.482275 \n",
      "Batch: 4681. Acc: 0.480711. Loss: 1.443537. Batch_acc: 0.492999. Batch_loss: 1.368697 \n",
      "Batch: 4682. Acc: 0.480720. Loss: 1.443510. Batch_acc: 0.523086. Batch_loss: 1.324046 \n",
      "Batch: 4683. Acc: 0.480724. Loss: 1.443497. Batch_acc: 0.498580. Batch_loss: 1.379298 \n",
      "Batch: 4684. Acc: 0.480729. Loss: 1.443482. Batch_acc: 0.506381. Batch_loss: 1.373271 \n",
      "Batch: 4685. Acc: 0.480728. Loss: 1.443478. Batch_acc: 0.475419. Batch_loss: 1.424333 \n",
      "Batch: 4686. Acc: 0.480736. Loss: 1.443455. Batch_acc: 0.517689. Batch_loss: 1.333874 \n",
      "Batch: 4687. Acc: 0.480738. Loss: 1.443446. Batch_acc: 0.498270. Batch_loss: 1.363335 \n",
      "[Training]  loss: 1.4434462836416848, ppl:  4.235267, accuracy: 48.074 %, elapse: 3758581.695ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.3074069915206943,  ppl:  3.69658, accuracy: 53.287 %, elapse: 37896.687ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1127.5153160095215ms\n",
      "[ Epoch: 4 / 8, Run Batch: 18752 / None]\n",
      "Batch: 0. Acc: 0.483649. Loss: 1.425880. Batch_acc: 0.483649. Batch_loss: 1.425880 \n",
      "Batch: 1. Acc: 0.488819. Loss: 1.417410. Batch_acc: 0.493983. Batch_loss: 1.408949 \n",
      "Batch: 2. Acc: 0.500769. Loss: 1.391795. Batch_acc: 0.525117. Batch_loss: 1.339609 \n",
      "Batch: 3. Acc: 0.502566. Loss: 1.381323. Batch_acc: 0.507718. Batch_loss: 1.351304 \n",
      "Batch: 4. Acc: 0.504336. Loss: 1.380962. Batch_acc: 0.511429. Batch_loss: 1.379512 \n",
      "Batch: 5. Acc: 0.503372. Loss: 1.385806. Batch_acc: 0.498584. Batch_loss: 1.409860 \n",
      "Batch: 6. Acc: 0.505363. Loss: 1.381740. Batch_acc: 0.517164. Batch_loss: 1.357648 \n",
      "Batch: 7. Acc: 0.506551. Loss: 1.377108. Batch_acc: 0.514960. Batch_loss: 1.344312 \n",
      "Batch: 8. Acc: 0.507634. Loss: 1.371841. Batch_acc: 0.516706. Batch_loss: 1.327708 \n",
      "Batch: 9. Acc: 0.507156. Loss: 1.370972. Batch_acc: 0.502860. Batch_loss: 1.363159 \n",
      "Batch: 10. Acc: 0.505390. Loss: 1.376961. Batch_acc: 0.487608. Batch_loss: 1.437250 \n",
      "Batch: 11. Acc: 0.503290. Loss: 1.382719. Batch_acc: 0.480497. Batch_loss: 1.445231 \n",
      "Batch: 12. Acc: 0.502179. Loss: 1.383791. Batch_acc: 0.488851. Batch_loss: 1.396638 \n",
      "Batch: 13. Acc: 0.502652. Loss: 1.384609. Batch_acc: 0.508674. Batch_loss: 1.395011 \n",
      "Batch: 14. Acc: 0.501832. Loss: 1.386459. Batch_acc: 0.489953. Batch_loss: 1.413255 \n",
      "Batch: 15. Acc: 0.502628. Loss: 1.382173. Batch_acc: 0.514464. Batch_loss: 1.318482 \n",
      "Batch: 16. Acc: 0.503552. Loss: 1.379827. Batch_acc: 0.518433. Batch_loss: 1.342042 \n",
      "Batch: 17. Acc: 0.504229. Loss: 1.377480. Batch_acc: 0.515723. Batch_loss: 1.337620 \n",
      "Batch: 18. Acc: 0.504052. Loss: 1.375997. Batch_acc: 0.500860. Batch_loss: 1.349276 \n",
      "Batch: 19. Acc: 0.504633. Loss: 1.374774. Batch_acc: 0.516206. Batch_loss: 1.350407 \n",
      "Batch: 20. Acc: 0.504690. Loss: 1.373534. Batch_acc: 0.505848. Batch_loss: 1.348247 \n",
      "Batch: 21. Acc: 0.504954. Loss: 1.373832. Batch_acc: 0.510387. Batch_loss: 1.379956 \n",
      "Batch: 22. Acc: 0.504862. Loss: 1.375079. Batch_acc: 0.502841. Batch_loss: 1.402257 \n",
      "Batch: 23. Acc: 0.504899. Loss: 1.375634. Batch_acc: 0.505767. Batch_loss: 1.388464 \n",
      "Batch: 24. Acc: 0.504685. Loss: 1.374325. Batch_acc: 0.499411. Batch_loss: 1.342082 \n",
      "Batch: 25. Acc: 0.504553. Loss: 1.374600. Batch_acc: 0.501175. Batch_loss: 1.381618 \n",
      "Batch: 26. Acc: 0.504021. Loss: 1.375174. Batch_acc: 0.490319. Batch_loss: 1.389978 \n",
      "Batch: 27. Acc: 0.504554. Loss: 1.374259. Batch_acc: 0.518922. Batch_loss: 1.349605 \n",
      "Batch: 28. Acc: 0.504011. Loss: 1.375421. Batch_acc: 0.488825. Batch_loss: 1.407863 \n",
      "Batch: 29. Acc: 0.504212. Loss: 1.373694. Batch_acc: 0.510040. Batch_loss: 1.323671 \n",
      "Batch: 30. Acc: 0.503940. Loss: 1.374106. Batch_acc: 0.495591. Batch_loss: 1.386757 \n",
      "Batch: 31. Acc: 0.504482. Loss: 1.372999. Batch_acc: 0.521289. Batch_loss: 1.338650 \n",
      "Batch: 32. Acc: 0.504216. Loss: 1.374302. Batch_acc: 0.495667. Batch_loss: 1.416209 \n",
      "Batch: 33. Acc: 0.503831. Loss: 1.375443. Batch_acc: 0.491004. Batch_loss: 1.413469 \n",
      "Batch: 34. Acc: 0.504365. Loss: 1.374463. Batch_acc: 0.521835. Batch_loss: 1.342432 \n",
      "Batch: 35. Acc: 0.504226. Loss: 1.374784. Batch_acc: 0.499438. Batch_loss: 1.385754 \n",
      "Batch: 36. Acc: 0.503562. Loss: 1.375227. Batch_acc: 0.479276. Batch_loss: 1.391441 \n",
      "Batch: 37. Acc: 0.503884. Loss: 1.374400. Batch_acc: 0.515796. Batch_loss: 1.343807 \n",
      "Batch: 38. Acc: 0.503887. Loss: 1.374854. Batch_acc: 0.504000. Batch_loss: 1.392000 \n",
      "Batch: 39. Acc: 0.503813. Loss: 1.374781. Batch_acc: 0.500878. Batch_loss: 1.371890 \n",
      "Batch: 40. Acc: 0.503405. Loss: 1.375060. Batch_acc: 0.487002. Batch_loss: 1.386299 \n",
      "Batch: 41. Acc: 0.503460. Loss: 1.375195. Batch_acc: 0.505701. Batch_loss: 1.380659 \n",
      "Batch: 42. Acc: 0.503709. Loss: 1.374944. Batch_acc: 0.514386. Batch_loss: 1.364193 \n",
      "Batch: 43. Acc: 0.503806. Loss: 1.374633. Batch_acc: 0.507919. Batch_loss: 1.361483 \n",
      "Batch: 44. Acc: 0.503851. Loss: 1.374727. Batch_acc: 0.505869. Batch_loss: 1.378956 \n",
      "Batch: 45. Acc: 0.503760. Loss: 1.374203. Batch_acc: 0.499717. Batch_loss: 1.350953 \n",
      "Batch: 46. Acc: 0.503272. Loss: 1.375659. Batch_acc: 0.480259. Batch_loss: 1.444319 \n",
      "Batch: 47. Acc: 0.503007. Loss: 1.376382. Batch_acc: 0.490479. Batch_loss: 1.410514 \n",
      "Batch: 48. Acc: 0.503666. Loss: 1.374773. Batch_acc: 0.534765. Batch_loss: 1.298850 \n",
      "Batch: 49. Acc: 0.503465. Loss: 1.374595. Batch_acc: 0.493721. Batch_loss: 1.365911 \n",
      "Batch: 50. Acc: 0.503763. Loss: 1.373651. Batch_acc: 0.518540. Batch_loss: 1.326814 \n",
      "Batch: 51. Acc: 0.504010. Loss: 1.373243. Batch_acc: 0.516496. Batch_loss: 1.352608 \n",
      "Batch: 52. Acc: 0.503911. Loss: 1.373020. Batch_acc: 0.498491. Batch_loss: 1.360861 \n",
      "Batch: 53. Acc: 0.503786. Loss: 1.373535. Batch_acc: 0.497106. Batch_loss: 1.401012 \n",
      "Batch: 54. Acc: 0.504130. Loss: 1.372840. Batch_acc: 0.522533. Batch_loss: 1.335611 \n",
      "Batch: 55. Acc: 0.503963. Loss: 1.373363. Batch_acc: 0.494822. Batch_loss: 1.402115 \n",
      "Batch: 56. Acc: 0.504200. Loss: 1.373503. Batch_acc: 0.517241. Batch_loss: 1.381255 \n",
      "Batch: 57. Acc: 0.504572. Loss: 1.372946. Batch_acc: 0.525281. Batch_loss: 1.341899 \n",
      "Batch: 58. Acc: 0.504564. Loss: 1.373020. Batch_acc: 0.504070. Batch_loss: 1.377352 \n",
      "Batch: 59. Acc: 0.504474. Loss: 1.373408. Batch_acc: 0.499129. Batch_loss: 1.396508 \n",
      "Batch: 60. Acc: 0.504537. Loss: 1.373161. Batch_acc: 0.508253. Batch_loss: 1.358492 \n",
      "Batch: 61. Acc: 0.504773. Loss: 1.372419. Batch_acc: 0.518937. Batch_loss: 1.327932 \n",
      "Batch: 62. Acc: 0.504384. Loss: 1.373440. Batch_acc: 0.479694. Batch_loss: 1.438277 \n",
      "Batch: 63. Acc: 0.504545. Loss: 1.372855. Batch_acc: 0.514783. Batch_loss: 1.335665 \n",
      "Batch: 64. Acc: 0.504633. Loss: 1.372785. Batch_acc: 0.510147. Batch_loss: 1.368436 \n",
      "Batch: 65. Acc: 0.504967. Loss: 1.372301. Batch_acc: 0.526587. Batch_loss: 1.340948 \n",
      "Batch: 66. Acc: 0.504893. Loss: 1.372655. Batch_acc: 0.500000. Batch_loss: 1.396153 \n",
      "Batch: 67. Acc: 0.504863. Loss: 1.373024. Batch_acc: 0.502838. Batch_loss: 1.397452 \n",
      "Batch: 68. Acc: 0.504493. Loss: 1.373952. Batch_acc: 0.479070. Batch_loss: 1.437821 \n",
      "Batch: 69. Acc: 0.504445. Loss: 1.374518. Batch_acc: 0.501136. Batch_loss: 1.413072 \n",
      "Batch: 70. Acc: 0.504266. Loss: 1.375244. Batch_acc: 0.491555. Batch_loss: 1.426798 \n",
      "Batch: 71. Acc: 0.504183. Loss: 1.375126. Batch_acc: 0.498248. Batch_loss: 1.366607 \n",
      "Batch: 72. Acc: 0.504375. Loss: 1.374688. Batch_acc: 0.518240. Batch_loss: 1.342885 \n",
      "Batch: 73. Acc: 0.504340. Loss: 1.374557. Batch_acc: 0.501758. Batch_loss: 1.364853 \n",
      "Batch: 74. Acc: 0.503931. Loss: 1.375386. Batch_acc: 0.472909. Batch_loss: 1.438175 \n",
      "Batch: 75. Acc: 0.503963. Loss: 1.375176. Batch_acc: 0.506381. Batch_loss: 1.359299 \n",
      "Batch: 76. Acc: 0.503989. Loss: 1.375635. Batch_acc: 0.506003. Batch_loss: 1.410331 \n",
      "Batch: 77. Acc: 0.504034. Loss: 1.375694. Batch_acc: 0.507471. Batch_loss: 1.380252 \n",
      "Batch: 78. Acc: 0.504092. Loss: 1.375532. Batch_acc: 0.508562. Batch_loss: 1.362998 \n",
      "Batch: 79. Acc: 0.504106. Loss: 1.375424. Batch_acc: 0.505263. Batch_loss: 1.366746 \n",
      "Batch: 80. Acc: 0.504180. Loss: 1.375163. Batch_acc: 0.510133. Batch_loss: 1.354143 \n",
      "Batch: 81. Acc: 0.504284. Loss: 1.374815. Batch_acc: 0.512761. Batch_loss: 1.346354 \n",
      "Batch: 82. Acc: 0.504027. Loss: 1.375376. Batch_acc: 0.483362. Batch_loss: 1.420466 \n",
      "Batch: 83. Acc: 0.504139. Loss: 1.375329. Batch_acc: 0.513467. Batch_loss: 1.371445 \n",
      "Batch: 84. Acc: 0.504237. Loss: 1.375500. Batch_acc: 0.512625. Batch_loss: 1.390193 \n",
      "Batch: 85. Acc: 0.504252. Loss: 1.375421. Batch_acc: 0.505469. Batch_loss: 1.368719 \n",
      "Batch: 86. Acc: 0.504284. Loss: 1.375046. Batch_acc: 0.507050. Batch_loss: 1.343405 \n",
      "Batch: 87. Acc: 0.504366. Loss: 1.374835. Batch_acc: 0.511390. Batch_loss: 1.356625 \n",
      "Batch: 88. Acc: 0.504435. Loss: 1.374781. Batch_acc: 0.510434. Batch_loss: 1.370188 \n",
      "Batch: 89. Acc: 0.504430. Loss: 1.374572. Batch_acc: 0.503933. Batch_loss: 1.356331 \n",
      "Batch: 90. Acc: 0.504700. Loss: 1.374020. Batch_acc: 0.528874. Batch_loss: 1.324680 \n",
      "Batch: 91. Acc: 0.504782. Loss: 1.373815. Batch_acc: 0.512181. Batch_loss: 1.355357 \n",
      "Batch: 92. Acc: 0.504906. Loss: 1.373376. Batch_acc: 0.516166. Batch_loss: 1.333540 \n",
      "Batch: 93. Acc: 0.504929. Loss: 1.373181. Batch_acc: 0.507034. Batch_loss: 1.355398 \n",
      "Batch: 94. Acc: 0.505000. Loss: 1.373401. Batch_acc: 0.511933. Batch_loss: 1.394932 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.505097. Loss: 1.373178. Batch_acc: 0.514061. Batch_loss: 1.352473 \n",
      "Batch: 96. Acc: 0.505310. Loss: 1.372796. Batch_acc: 0.525395. Batch_loss: 1.336783 \n",
      "Batch: 97. Acc: 0.505315. Loss: 1.372876. Batch_acc: 0.505821. Batch_loss: 1.380691 \n",
      "Batch: 98. Acc: 0.505549. Loss: 1.372169. Batch_acc: 0.528399. Batch_loss: 1.302993 \n",
      "Batch: 99. Acc: 0.505502. Loss: 1.372254. Batch_acc: 0.500865. Batch_loss: 1.380705 \n",
      "Batch: 100. Acc: 0.505328. Loss: 1.372454. Batch_acc: 0.487833. Batch_loss: 1.392649 \n",
      "Batch: 101. Acc: 0.505248. Loss: 1.372396. Batch_acc: 0.497133. Batch_loss: 1.366505 \n",
      "Batch: 102. Acc: 0.505292. Loss: 1.372104. Batch_acc: 0.509884. Batch_loss: 1.342028 \n",
      "Batch: 103. Acc: 0.505288. Loss: 1.372040. Batch_acc: 0.504854. Batch_loss: 1.365490 \n",
      "Batch: 104. Acc: 0.505432. Loss: 1.371667. Batch_acc: 0.520438. Batch_loss: 1.332800 \n",
      "Batch: 105. Acc: 0.505567. Loss: 1.371127. Batch_acc: 0.519658. Batch_loss: 1.314840 \n",
      "Batch: 106. Acc: 0.505670. Loss: 1.370989. Batch_acc: 0.516421. Batch_loss: 1.356637 \n",
      "Batch: 107. Acc: 0.505491. Loss: 1.371305. Batch_acc: 0.486095. Batch_loss: 1.405336 \n",
      "Batch: 108. Acc: 0.505739. Loss: 1.370851. Batch_acc: 0.532830. Batch_loss: 1.321251 \n",
      "Batch: 109. Acc: 0.505919. Loss: 1.370248. Batch_acc: 0.525443. Batch_loss: 1.304905 \n",
      "Batch: 110. Acc: 0.506082. Loss: 1.370008. Batch_acc: 0.523783. Batch_loss: 1.344017 \n",
      "Batch: 111. Acc: 0.506007. Loss: 1.370202. Batch_acc: 0.497730. Batch_loss: 1.391487 \n",
      "Batch: 112. Acc: 0.506092. Loss: 1.369785. Batch_acc: 0.515441. Batch_loss: 1.324133 \n",
      "Batch: 113. Acc: 0.506125. Loss: 1.369932. Batch_acc: 0.509838. Batch_loss: 1.386629 \n",
      "Batch: 114. Acc: 0.506037. Loss: 1.370225. Batch_acc: 0.495892. Batch_loss: 1.404390 \n",
      "Batch: 115. Acc: 0.506119. Loss: 1.369956. Batch_acc: 0.515376. Batch_loss: 1.339236 \n",
      "Batch: 116. Acc: 0.506191. Loss: 1.369733. Batch_acc: 0.514464. Batch_loss: 1.344225 \n",
      "Batch: 117. Acc: 0.506174. Loss: 1.369719. Batch_acc: 0.504197. Batch_loss: 1.368117 \n",
      "Batch: 118. Acc: 0.506117. Loss: 1.369507. Batch_acc: 0.499421. Batch_loss: 1.344239 \n",
      "Batch: 119. Acc: 0.506128. Loss: 1.369426. Batch_acc: 0.507403. Batch_loss: 1.359871 \n",
      "Batch: 120. Acc: 0.505929. Loss: 1.369678. Batch_acc: 0.481394. Batch_loss: 1.400850 \n",
      "Batch: 121. Acc: 0.505716. Loss: 1.370203. Batch_acc: 0.479908. Batch_loss: 1.433613 \n",
      "Batch: 122. Acc: 0.505790. Loss: 1.370265. Batch_acc: 0.515044. Batch_loss: 1.378041 \n",
      "Batch: 123. Acc: 0.505923. Loss: 1.369787. Batch_acc: 0.522159. Batch_loss: 1.311660 \n",
      "Batch: 124. Acc: 0.505753. Loss: 1.370255. Batch_acc: 0.484211. Batch_loss: 1.429361 \n",
      "Batch: 125. Acc: 0.505710. Loss: 1.370518. Batch_acc: 0.500296. Batch_loss: 1.404438 \n",
      "Batch: 126. Acc: 0.505706. Loss: 1.370571. Batch_acc: 0.505196. Batch_loss: 1.377203 \n",
      "Batch: 127. Acc: 0.505700. Loss: 1.370695. Batch_acc: 0.504838. Batch_loss: 1.386356 \n",
      "Batch: 128. Acc: 0.505723. Loss: 1.370760. Batch_acc: 0.508813. Batch_loss: 1.379235 \n",
      "Batch: 129. Acc: 0.505494. Loss: 1.371416. Batch_acc: 0.475581. Batch_loss: 1.456972 \n",
      "Batch: 130. Acc: 0.505431. Loss: 1.371585. Batch_acc: 0.497069. Batch_loss: 1.394050 \n",
      "Batch: 131. Acc: 0.505449. Loss: 1.371503. Batch_acc: 0.507853. Batch_loss: 1.360620 \n",
      "Batch: 132. Acc: 0.505449. Loss: 1.371512. Batch_acc: 0.505469. Batch_loss: 1.372718 \n",
      "Batch: 133. Acc: 0.505393. Loss: 1.371697. Batch_acc: 0.497994. Batch_loss: 1.396239 \n",
      "Batch: 134. Acc: 0.505423. Loss: 1.371465. Batch_acc: 0.509423. Batch_loss: 1.340513 \n",
      "Batch: 135. Acc: 0.505439. Loss: 1.371593. Batch_acc: 0.507665. Batch_loss: 1.389352 \n",
      "Batch: 136. Acc: 0.505425. Loss: 1.371730. Batch_acc: 0.503448. Batch_loss: 1.390373 \n",
      "Batch: 137. Acc: 0.505485. Loss: 1.371580. Batch_acc: 0.513498. Batch_loss: 1.351423 \n",
      "Batch: 138. Acc: 0.505493. Loss: 1.371514. Batch_acc: 0.506698. Batch_loss: 1.362273 \n",
      "Batch: 139. Acc: 0.505518. Loss: 1.371202. Batch_acc: 0.508903. Batch_loss: 1.327916 \n",
      "Batch: 140. Acc: 0.505561. Loss: 1.371173. Batch_acc: 0.511655. Batch_loss: 1.367065 \n",
      "Batch: 141. Acc: 0.505650. Loss: 1.370850. Batch_acc: 0.518325. Batch_loss: 1.324786 \n",
      "Batch: 142. Acc: 0.505627. Loss: 1.370976. Batch_acc: 0.502326. Batch_loss: 1.389027 \n",
      "Batch: 143. Acc: 0.505503. Loss: 1.371143. Batch_acc: 0.488122. Batch_loss: 1.394640 \n",
      "Batch: 144. Acc: 0.505481. Loss: 1.371117. Batch_acc: 0.502281. Batch_loss: 1.367389 \n",
      "Batch: 145. Acc: 0.505561. Loss: 1.371008. Batch_acc: 0.517361. Batch_loss: 1.355179 \n",
      "Batch: 146. Acc: 0.505417. Loss: 1.371380. Batch_acc: 0.483833. Batch_loss: 1.426901 \n",
      "Batch: 147. Acc: 0.505433. Loss: 1.371627. Batch_acc: 0.507872. Batch_loss: 1.408354 \n",
      "Batch: 148. Acc: 0.505416. Loss: 1.371569. Batch_acc: 0.502874. Batch_loss: 1.363102 \n",
      "Batch: 149. Acc: 0.505577. Loss: 1.371165. Batch_acc: 0.529378. Batch_loss: 1.311436 \n",
      "Batch: 150. Acc: 0.505565. Loss: 1.371203. Batch_acc: 0.503733. Batch_loss: 1.376880 \n",
      "Batch: 151. Acc: 0.505721. Loss: 1.370664. Batch_acc: 0.529143. Batch_loss: 1.289769 \n",
      "Batch: 152. Acc: 0.505705. Loss: 1.370618. Batch_acc: 0.503375. Batch_loss: 1.363836 \n",
      "Batch: 153. Acc: 0.505732. Loss: 1.370658. Batch_acc: 0.509770. Batch_loss: 1.376729 \n",
      "Batch: 154. Acc: 0.505552. Loss: 1.370958. Batch_acc: 0.477810. Batch_loss: 1.417313 \n",
      "Batch: 155. Acc: 0.505650. Loss: 1.370795. Batch_acc: 0.521053. Batch_loss: 1.345079 \n",
      "Batch: 156. Acc: 0.505420. Loss: 1.371365. Batch_acc: 0.469150. Batch_loss: 1.461309 \n",
      "Batch: 157. Acc: 0.505448. Loss: 1.371299. Batch_acc: 0.509781. Batch_loss: 1.361024 \n",
      "Batch: 158. Acc: 0.505521. Loss: 1.371096. Batch_acc: 0.517007. Batch_loss: 1.339366 \n",
      "Batch: 159. Acc: 0.505535. Loss: 1.370984. Batch_acc: 0.507772. Batch_loss: 1.353286 \n",
      "Batch: 160. Acc: 0.505660. Loss: 1.370587. Batch_acc: 0.526008. Batch_loss: 1.305970 \n",
      "Batch: 161. Acc: 0.505590. Loss: 1.370534. Batch_acc: 0.494279. Batch_loss: 1.362108 \n",
      "Batch: 162. Acc: 0.505670. Loss: 1.370351. Batch_acc: 0.518689. Batch_loss: 1.340676 \n",
      "Batch: 163. Acc: 0.505588. Loss: 1.370707. Batch_acc: 0.491627. Batch_loss: 1.430952 \n",
      "Batch: 164. Acc: 0.505582. Loss: 1.370863. Batch_acc: 0.504561. Batch_loss: 1.396332 \n",
      "Batch: 165. Acc: 0.505571. Loss: 1.370729. Batch_acc: 0.503808. Batch_loss: 1.348117 \n",
      "Batch: 166. Acc: 0.505620. Loss: 1.370651. Batch_acc: 0.513559. Batch_loss: 1.357938 \n",
      "Batch: 167. Acc: 0.505573. Loss: 1.370967. Batch_acc: 0.497642. Batch_loss: 1.425175 \n",
      "Batch: 168. Acc: 0.505647. Loss: 1.370727. Batch_acc: 0.517867. Batch_loss: 1.330917 \n",
      "Batch: 169. Acc: 0.505661. Loss: 1.370640. Batch_acc: 0.507955. Batch_loss: 1.356122 \n",
      "Batch: 170. Acc: 0.505635. Loss: 1.370817. Batch_acc: 0.501149. Batch_loss: 1.400945 \n",
      "Batch: 171. Acc: 0.505653. Loss: 1.370780. Batch_acc: 0.508772. Batch_loss: 1.364223 \n",
      "Batch: 172. Acc: 0.505698. Loss: 1.370641. Batch_acc: 0.513719. Batch_loss: 1.346435 \n",
      "Batch: 173. Acc: 0.505690. Loss: 1.370825. Batch_acc: 0.504313. Batch_loss: 1.402539 \n",
      "Batch: 174. Acc: 0.505695. Loss: 1.370859. Batch_acc: 0.506425. Batch_loss: 1.376900 \n",
      "Batch: 175. Acc: 0.505729. Loss: 1.370874. Batch_acc: 0.511654. Batch_loss: 1.373466 \n",
      "Batch: 176. Acc: 0.505709. Loss: 1.370885. Batch_acc: 0.502053. Batch_loss: 1.372885 \n",
      "Batch: 177. Acc: 0.505635. Loss: 1.370885. Batch_acc: 0.492966. Batch_loss: 1.370867 \n",
      "Batch: 178. Acc: 0.505711. Loss: 1.370535. Batch_acc: 0.519045. Batch_loss: 1.309096 \n",
      "Batch: 179. Acc: 0.505697. Loss: 1.370581. Batch_acc: 0.503203. Batch_loss: 1.378803 \n",
      "Batch: 180. Acc: 0.505769. Loss: 1.370494. Batch_acc: 0.518497. Batch_loss: 1.354955 \n",
      "Batch: 181. Acc: 0.505762. Loss: 1.370533. Batch_acc: 0.504488. Batch_loss: 1.377881 \n",
      "Batch: 182. Acc: 0.505637. Loss: 1.370873. Batch_acc: 0.482249. Batch_loss: 1.434538 \n",
      "Batch: 183. Acc: 0.505641. Loss: 1.370865. Batch_acc: 0.506257. Batch_loss: 1.369431 \n",
      "Batch: 184. Acc: 0.505604. Loss: 1.370945. Batch_acc: 0.498858. Batch_loss: 1.385653 \n",
      "Batch: 185. Acc: 0.505581. Loss: 1.370939. Batch_acc: 0.501448. Batch_loss: 1.369753 \n",
      "Batch: 186. Acc: 0.505518. Loss: 1.371157. Batch_acc: 0.493567. Batch_loss: 1.412427 \n",
      "Batch: 187. Acc: 0.505426. Loss: 1.371282. Batch_acc: 0.488102. Batch_loss: 1.394714 \n",
      "Batch: 188. Acc: 0.505437. Loss: 1.371253. Batch_acc: 0.507463. Batch_loss: 1.365801 \n",
      "Batch: 189. Acc: 0.505232. Loss: 1.371834. Batch_acc: 0.465729. Batch_loss: 1.483697 \n",
      "Batch: 190. Acc: 0.505305. Loss: 1.371800. Batch_acc: 0.519220. Batch_loss: 1.365291 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.505159. Loss: 1.372152. Batch_acc: 0.476247. Batch_loss: 1.441591 \n",
      "Batch: 192. Acc: 0.505226. Loss: 1.372033. Batch_acc: 0.518282. Batch_loss: 1.348909 \n",
      "Batch: 193. Acc: 0.505205. Loss: 1.372130. Batch_acc: 0.501157. Batch_loss: 1.391012 \n",
      "Batch: 194. Acc: 0.505241. Loss: 1.372118. Batch_acc: 0.512195. Batch_loss: 1.369851 \n",
      "Batch: 195. Acc: 0.505171. Loss: 1.372292. Batch_acc: 0.491643. Batch_loss: 1.406252 \n",
      "Batch: 196. Acc: 0.505192. Loss: 1.372293. Batch_acc: 0.509292. Batch_loss: 1.372372 \n",
      "Batch: 197. Acc: 0.505241. Loss: 1.372151. Batch_acc: 0.514640. Batch_loss: 1.344902 \n",
      "Batch: 198. Acc: 0.505232. Loss: 1.372276. Batch_acc: 0.503521. Batch_loss: 1.397536 \n",
      "Batch: 199. Acc: 0.505316. Loss: 1.372018. Batch_acc: 0.521544. Batch_loss: 1.322087 \n",
      "Batch: 200. Acc: 0.505377. Loss: 1.371725. Batch_acc: 0.517539. Batch_loss: 1.313179 \n",
      "Batch: 201. Acc: 0.505536. Loss: 1.371361. Batch_acc: 0.536168. Batch_loss: 1.301079 \n",
      "Batch: 202. Acc: 0.505505. Loss: 1.371452. Batch_acc: 0.499126. Batch_loss: 1.390173 \n",
      "Batch: 203. Acc: 0.505498. Loss: 1.371344. Batch_acc: 0.504162. Batch_loss: 1.348550 \n",
      "Batch: 204. Acc: 0.505463. Loss: 1.371518. Batch_acc: 0.498276. Batch_loss: 1.407060 \n",
      "Batch: 205. Acc: 0.505370. Loss: 1.371779. Batch_acc: 0.486014. Batch_loss: 1.425860 \n",
      "Batch: 206. Acc: 0.505395. Loss: 1.371656. Batch_acc: 0.510613. Batch_loss: 1.345764 \n",
      "Batch: 207. Acc: 0.505446. Loss: 1.371509. Batch_acc: 0.516018. Batch_loss: 1.341327 \n",
      "Batch: 208. Acc: 0.505502. Loss: 1.371315. Batch_acc: 0.516873. Batch_loss: 1.331893 \n",
      "Batch: 209. Acc: 0.505421. Loss: 1.371349. Batch_acc: 0.488426. Batch_loss: 1.378427 \n",
      "Batch: 210. Acc: 0.505333. Loss: 1.371404. Batch_acc: 0.487381. Batch_loss: 1.382732 \n",
      "Batch: 211. Acc: 0.505329. Loss: 1.371332. Batch_acc: 0.504313. Batch_loss: 1.356116 \n",
      "Batch: 212. Acc: 0.505262. Loss: 1.371560. Batch_acc: 0.490779. Batch_loss: 1.421450 \n",
      "Batch: 213. Acc: 0.505324. Loss: 1.371423. Batch_acc: 0.518046. Batch_loss: 1.343347 \n",
      "Batch: 214. Acc: 0.505344. Loss: 1.371440. Batch_acc: 0.509587. Batch_loss: 1.375158 \n",
      "Batch: 215. Acc: 0.505271. Loss: 1.371610. Batch_acc: 0.489607. Batch_loss: 1.408246 \n",
      "Batch: 216. Acc: 0.505305. Loss: 1.371476. Batch_acc: 0.512629. Batch_loss: 1.342541 \n",
      "Batch: 217. Acc: 0.505310. Loss: 1.371490. Batch_acc: 0.506381. Batch_loss: 1.374521 \n",
      "Batch: 218. Acc: 0.505324. Loss: 1.371479. Batch_acc: 0.508281. Batch_loss: 1.369211 \n",
      "Batch: 219. Acc: 0.505258. Loss: 1.371701. Batch_acc: 0.490909. Batch_loss: 1.419621 \n",
      "Batch: 220. Acc: 0.505219. Loss: 1.371695. Batch_acc: 0.496929. Batch_loss: 1.370371 \n",
      "Batch: 221. Acc: 0.505301. Loss: 1.371627. Batch_acc: 0.523509. Batch_loss: 1.356618 \n",
      "Batch: 222. Acc: 0.505294. Loss: 1.371819. Batch_acc: 0.503563. Batch_loss: 1.415879 \n",
      "Batch: 223. Acc: 0.505249. Loss: 1.372069. Batch_acc: 0.495050. Batch_loss: 1.428490 \n",
      "Batch: 224. Acc: 0.505253. Loss: 1.372035. Batch_acc: 0.506307. Batch_loss: 1.364400 \n",
      "Batch: 225. Acc: 0.505139. Loss: 1.372315. Batch_acc: 0.478947. Batch_loss: 1.436438 \n",
      "Batch: 226. Acc: 0.505154. Loss: 1.372106. Batch_acc: 0.508711. Batch_loss: 1.324518 \n",
      "Batch: 227. Acc: 0.505138. Loss: 1.372199. Batch_acc: 0.501456. Batch_loss: 1.393396 \n",
      "Batch: 228. Acc: 0.505121. Loss: 1.372328. Batch_acc: 0.501130. Batch_loss: 1.401227 \n",
      "Batch: 229. Acc: 0.505056. Loss: 1.372494. Batch_acc: 0.490275. Batch_loss: 1.410375 \n",
      "Batch: 230. Acc: 0.505159. Loss: 1.372250. Batch_acc: 0.528940. Batch_loss: 1.316229 \n",
      "Batch: 231. Acc: 0.505043. Loss: 1.372541. Batch_acc: 0.478136. Batch_loss: 1.439817 \n",
      "Batch: 232. Acc: 0.505148. Loss: 1.372415. Batch_acc: 0.529649. Batch_loss: 1.343236 \n",
      "Batch: 233. Acc: 0.505238. Loss: 1.372189. Batch_acc: 0.525956. Batch_loss: 1.319854 \n",
      "Batch: 234. Acc: 0.505255. Loss: 1.372113. Batch_acc: 0.509195. Batch_loss: 1.354503 \n",
      "Batch: 235. Acc: 0.505222. Loss: 1.372207. Batch_acc: 0.497336. Batch_loss: 1.394885 \n",
      "Batch: 236. Acc: 0.505230. Loss: 1.372244. Batch_acc: 0.507106. Batch_loss: 1.380875 \n",
      "Batch: 237. Acc: 0.505254. Loss: 1.372227. Batch_acc: 0.510812. Batch_loss: 1.368049 \n",
      "Batch: 238. Acc: 0.505213. Loss: 1.372304. Batch_acc: 0.495726. Batch_loss: 1.390529 \n",
      "Batch: 239. Acc: 0.505120. Loss: 1.372479. Batch_acc: 0.482759. Batch_loss: 1.414248 \n",
      "Batch: 240. Acc: 0.505138. Loss: 1.372573. Batch_acc: 0.509610. Batch_loss: 1.395332 \n",
      "Batch: 241. Acc: 0.505175. Loss: 1.372469. Batch_acc: 0.513865. Batch_loss: 1.347758 \n",
      "Batch: 242. Acc: 0.505024. Loss: 1.372867. Batch_acc: 0.467262. Batch_loss: 1.472656 \n",
      "Batch: 243. Acc: 0.504951. Loss: 1.373068. Batch_acc: 0.487486. Batch_loss: 1.421271 \n",
      "Batch: 244. Acc: 0.504953. Loss: 1.373176. Batch_acc: 0.505376. Batch_loss: 1.399135 \n",
      "Batch: 245. Acc: 0.504895. Loss: 1.373254. Batch_acc: 0.490231. Batch_loss: 1.392860 \n",
      "Batch: 246. Acc: 0.504964. Loss: 1.373186. Batch_acc: 0.522013. Batch_loss: 1.356644 \n",
      "Batch: 247. Acc: 0.504991. Loss: 1.373150. Batch_acc: 0.511429. Batch_loss: 1.364132 \n",
      "Batch: 248. Acc: 0.505018. Loss: 1.373071. Batch_acc: 0.511884. Batch_loss: 1.353514 \n",
      "Batch: 249. Acc: 0.505090. Loss: 1.372924. Batch_acc: 0.522472. Batch_loss: 1.337215 \n",
      "Batch: 250. Acc: 0.505028. Loss: 1.373090. Batch_acc: 0.489761. Batch_loss: 1.413876 \n",
      "Batch: 251. Acc: 0.505078. Loss: 1.372982. Batch_acc: 0.517499. Batch_loss: 1.346126 \n",
      "Checkpointing on batch: 251. Accuracy: 0.5050775450537904. Loss per char: 1.3729821942684184. Time: 1627218130.7442238\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 18, 15, 19, 18, 18, 25,\n",
      "        24, 25, 21, 17, 19, 24,  1, 14,  1, 17, 15, 24, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.505020. Loss: 1.373092. Batch_acc: 0.490345. Batch_loss: 1.401184 \n",
      "Batch: 253. Acc: 0.504978. Loss: 1.373182. Batch_acc: 0.494279. Batch_loss: 1.395743 \n",
      "Batch: 254. Acc: 0.505058. Loss: 1.373045. Batch_acc: 0.525943. Batch_loss: 1.337521 \n",
      "Batch: 255. Acc: 0.505040. Loss: 1.373165. Batch_acc: 0.500569. Batch_loss: 1.403317 \n",
      "Batch: 256. Acc: 0.505122. Loss: 1.372953. Batch_acc: 0.526347. Batch_loss: 1.317813 \n",
      "Batch: 257. Acc: 0.505134. Loss: 1.372889. Batch_acc: 0.508435. Batch_loss: 1.356246 \n",
      "Batch: 258. Acc: 0.505108. Loss: 1.372911. Batch_acc: 0.498262. Batch_loss: 1.378602 \n",
      "Batch: 259. Acc: 0.505138. Loss: 1.372827. Batch_acc: 0.513064. Batch_loss: 1.350449 \n",
      "Batch: 260. Acc: 0.505120. Loss: 1.372966. Batch_acc: 0.500294. Batch_loss: 1.409894 \n",
      "Batch: 261. Acc: 0.505158. Loss: 1.372794. Batch_acc: 0.515362. Batch_loss: 1.327722 \n",
      "Batch: 262. Acc: 0.505231. Loss: 1.372570. Batch_acc: 0.524277. Batch_loss: 1.313545 \n",
      "Batch: 263. Acc: 0.505255. Loss: 1.372517. Batch_acc: 0.511628. Batch_loss: 1.358466 \n",
      "Batch: 264. Acc: 0.505207. Loss: 1.372616. Batch_acc: 0.492477. Batch_loss: 1.398876 \n",
      "Batch: 265. Acc: 0.505244. Loss: 1.372488. Batch_acc: 0.515029. Batch_loss: 1.338352 \n",
      "Batch: 266. Acc: 0.505261. Loss: 1.372463. Batch_acc: 0.509884. Batch_loss: 1.365745 \n",
      "Batch: 267. Acc: 0.505228. Loss: 1.372466. Batch_acc: 0.496678. Batch_loss: 1.373294 \n",
      "Batch: 268. Acc: 0.505180. Loss: 1.372556. Batch_acc: 0.492588. Batch_loss: 1.396549 \n",
      "Batch: 269. Acc: 0.505251. Loss: 1.372376. Batch_acc: 0.523624. Batch_loss: 1.325446 \n",
      "Batch: 270. Acc: 0.505239. Loss: 1.372408. Batch_acc: 0.502020. Batch_loss: 1.381267 \n",
      "Batch: 271. Acc: 0.505210. Loss: 1.372446. Batch_acc: 0.497394. Batch_loss: 1.382796 \n",
      "Batch: 272. Acc: 0.505237. Loss: 1.372432. Batch_acc: 0.512586. Batch_loss: 1.368470 \n",
      "Batch: 273. Acc: 0.505213. Loss: 1.372612. Batch_acc: 0.498537. Batch_loss: 1.422590 \n",
      "Batch: 274. Acc: 0.505171. Loss: 1.372495. Batch_acc: 0.493721. Batch_loss: 1.340787 \n",
      "Batch: 275. Acc: 0.505116. Loss: 1.372510. Batch_acc: 0.489960. Batch_loss: 1.376539 \n",
      "Batch: 276. Acc: 0.505205. Loss: 1.372193. Batch_acc: 0.529312. Batch_loss: 1.286575 \n",
      "Batch: 277. Acc: 0.505160. Loss: 1.372223. Batch_acc: 0.492353. Batch_loss: 1.380670 \n",
      "Batch: 278. Acc: 0.505177. Loss: 1.372156. Batch_acc: 0.509781. Batch_loss: 1.353691 \n",
      "Batch: 279. Acc: 0.505203. Loss: 1.372123. Batch_acc: 0.512731. Batch_loss: 1.362676 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.505150. Loss: 1.372209. Batch_acc: 0.490023. Batch_loss: 1.396885 \n",
      "Batch: 281. Acc: 0.505156. Loss: 1.372277. Batch_acc: 0.506721. Batch_loss: 1.391672 \n",
      "Batch: 282. Acc: 0.505127. Loss: 1.372394. Batch_acc: 0.496819. Batch_loss: 1.405461 \n",
      "Batch: 283. Acc: 0.505106. Loss: 1.372448. Batch_acc: 0.499126. Batch_loss: 1.388070 \n",
      "Batch: 284. Acc: 0.505149. Loss: 1.372322. Batch_acc: 0.517087. Batch_loss: 1.337505 \n",
      "Batch: 285. Acc: 0.505088. Loss: 1.372564. Batch_acc: 0.487240. Batch_loss: 1.443454 \n",
      "Batch: 286. Acc: 0.505146. Loss: 1.372364. Batch_acc: 0.521566. Batch_loss: 1.316202 \n",
      "Batch: 287. Acc: 0.505111. Loss: 1.372433. Batch_acc: 0.494798. Batch_loss: 1.392169 \n",
      "Batch: 288. Acc: 0.505153. Loss: 1.372257. Batch_acc: 0.517857. Batch_loss: 1.319957 \n",
      "Batch: 289. Acc: 0.505146. Loss: 1.372317. Batch_acc: 0.503095. Batch_loss: 1.389151 \n",
      "Batch: 290. Acc: 0.505130. Loss: 1.372371. Batch_acc: 0.500581. Batch_loss: 1.388271 \n",
      "Batch: 291. Acc: 0.505165. Loss: 1.372370. Batch_acc: 0.515065. Batch_loss: 1.371940 \n",
      "Batch: 292. Acc: 0.505159. Loss: 1.372348. Batch_acc: 0.503452. Batch_loss: 1.365993 \n",
      "Batch: 293. Acc: 0.505252. Loss: 1.372131. Batch_acc: 0.532304. Batch_loss: 1.309082 \n",
      "Batch: 294. Acc: 0.505287. Loss: 1.371938. Batch_acc: 0.515323. Batch_loss: 1.315792 \n",
      "Batch: 295. Acc: 0.505229. Loss: 1.372054. Batch_acc: 0.488171. Batch_loss: 1.406544 \n",
      "Batch: 296. Acc: 0.505263. Loss: 1.371957. Batch_acc: 0.515256. Batch_loss: 1.343092 \n",
      "Batch: 297. Acc: 0.505199. Loss: 1.372173. Batch_acc: 0.486301. Batch_loss: 1.435733 \n",
      "Batch: 298. Acc: 0.505256. Loss: 1.372020. Batch_acc: 0.522260. Batch_loss: 1.326838 \n",
      "Batch: 299. Acc: 0.505286. Loss: 1.371880. Batch_acc: 0.514557. Batch_loss: 1.328697 \n",
      "Batch: 300. Acc: 0.505215. Loss: 1.372043. Batch_acc: 0.483852. Batch_loss: 1.421167 \n",
      "Batch: 301. Acc: 0.505302. Loss: 1.371735. Batch_acc: 0.530761. Batch_loss: 1.281674 \n",
      "Batch: 302. Acc: 0.505276. Loss: 1.371809. Batch_acc: 0.497052. Batch_loss: 1.394514 \n",
      "Batch: 303. Acc: 0.505230. Loss: 1.371884. Batch_acc: 0.491468. Batch_loss: 1.394382 \n",
      "Batch: 304. Acc: 0.505200. Loss: 1.371839. Batch_acc: 0.496309. Batch_loss: 1.358520 \n",
      "Batch: 305. Acc: 0.505232. Loss: 1.371791. Batch_acc: 0.515046. Batch_loss: 1.357041 \n",
      "Batch: 306. Acc: 0.505237. Loss: 1.371787. Batch_acc: 0.506904. Batch_loss: 1.370526 \n",
      "Batch: 307. Acc: 0.505251. Loss: 1.371753. Batch_acc: 0.509423. Batch_loss: 1.361258 \n",
      "Batch: 308. Acc: 0.505224. Loss: 1.371847. Batch_acc: 0.496826. Batch_loss: 1.401034 \n",
      "Batch: 309. Acc: 0.505281. Loss: 1.371709. Batch_acc: 0.522831. Batch_loss: 1.329332 \n",
      "Batch: 310. Acc: 0.505301. Loss: 1.371604. Batch_acc: 0.511410. Batch_loss: 1.338691 \n",
      "Batch: 311. Acc: 0.505245. Loss: 1.371719. Batch_acc: 0.487875. Batch_loss: 1.407349 \n",
      "Batch: 312. Acc: 0.505193. Loss: 1.371846. Batch_acc: 0.489192. Batch_loss: 1.411205 \n",
      "Batch: 313. Acc: 0.505243. Loss: 1.371644. Batch_acc: 0.520750. Batch_loss: 1.309218 \n",
      "Batch: 314. Acc: 0.505197. Loss: 1.371660. Batch_acc: 0.490868. Batch_loss: 1.376646 \n",
      "Batch: 315. Acc: 0.505235. Loss: 1.371635. Batch_acc: 0.517104. Batch_loss: 1.363723 \n",
      "Batch: 316. Acc: 0.505326. Loss: 1.371442. Batch_acc: 0.533637. Batch_loss: 1.310992 \n",
      "Batch: 317. Acc: 0.505373. Loss: 1.371256. Batch_acc: 0.520485. Batch_loss: 1.312215 \n",
      "Batch: 318. Acc: 0.505353. Loss: 1.371264. Batch_acc: 0.498819. Batch_loss: 1.373981 \n",
      "Batch: 319. Acc: 0.505367. Loss: 1.371205. Batch_acc: 0.509804. Batch_loss: 1.352395 \n",
      "Batch: 320. Acc: 0.505407. Loss: 1.371112. Batch_acc: 0.517978. Batch_loss: 1.341901 \n",
      "Batch: 321. Acc: 0.505410. Loss: 1.371147. Batch_acc: 0.506300. Batch_loss: 1.382347 \n",
      "Batch: 322. Acc: 0.505364. Loss: 1.371327. Batch_acc: 0.490609. Batch_loss: 1.428756 \n",
      "Batch: 323. Acc: 0.505437. Loss: 1.371251. Batch_acc: 0.528907. Batch_loss: 1.346611 \n",
      "Batch: 324. Acc: 0.505420. Loss: 1.371362. Batch_acc: 0.500000. Batch_loss: 1.408360 \n",
      "Batch: 325. Acc: 0.505442. Loss: 1.371352. Batch_acc: 0.512464. Batch_loss: 1.367982 \n",
      "Batch: 326. Acc: 0.505505. Loss: 1.371235. Batch_acc: 0.525956. Batch_loss: 1.333699 \n",
      "Batch: 327. Acc: 0.505495. Loss: 1.371317. Batch_acc: 0.502027. Batch_loss: 1.398278 \n",
      "Batch: 328. Acc: 0.505568. Loss: 1.371121. Batch_acc: 0.529014. Batch_loss: 1.308171 \n",
      "Batch: 329. Acc: 0.505552. Loss: 1.371150. Batch_acc: 0.500290. Batch_loss: 1.380813 \n",
      "Batch: 330. Acc: 0.505527. Loss: 1.371218. Batch_acc: 0.497409. Batch_loss: 1.393678 \n",
      "Batch: 331. Acc: 0.505565. Loss: 1.371068. Batch_acc: 0.517888. Batch_loss: 1.322033 \n",
      "Batch: 332. Acc: 0.505538. Loss: 1.371109. Batch_acc: 0.496520. Batch_loss: 1.384728 \n",
      "Batch: 333. Acc: 0.505534. Loss: 1.371066. Batch_acc: 0.504298. Batch_loss: 1.356882 \n",
      "Batch: 334. Acc: 0.505488. Loss: 1.371237. Batch_acc: 0.489890. Batch_loss: 1.428376 \n",
      "Batch: 335. Acc: 0.505539. Loss: 1.371093. Batch_acc: 0.522819. Batch_loss: 1.322735 \n",
      "Batch: 336. Acc: 0.505506. Loss: 1.371177. Batch_acc: 0.494562. Batch_loss: 1.399219 \n",
      "Batch: 337. Acc: 0.505556. Loss: 1.371026. Batch_acc: 0.521691. Batch_loss: 1.321949 \n",
      "Batch: 338. Acc: 0.505550. Loss: 1.371081. Batch_acc: 0.503468. Batch_loss: 1.389646 \n",
      "Batch: 339. Acc: 0.505495. Loss: 1.371186. Batch_acc: 0.486674. Batch_loss: 1.407124 \n",
      "Batch: 340. Acc: 0.505419. Loss: 1.371330. Batch_acc: 0.479862. Batch_loss: 1.420245 \n",
      "Batch: 341. Acc: 0.505433. Loss: 1.371321. Batch_acc: 0.510098. Batch_loss: 1.368281 \n",
      "Batch: 342. Acc: 0.505442. Loss: 1.371328. Batch_acc: 0.508484. Batch_loss: 1.373660 \n",
      "Batch: 343. Acc: 0.505433. Loss: 1.371337. Batch_acc: 0.502326. Batch_loss: 1.374671 \n",
      "Batch: 344. Acc: 0.505425. Loss: 1.371362. Batch_acc: 0.502655. Batch_loss: 1.379874 \n",
      "Batch: 345. Acc: 0.505473. Loss: 1.371220. Batch_acc: 0.522293. Batch_loss: 1.321949 \n",
      "Batch: 346. Acc: 0.505430. Loss: 1.371355. Batch_acc: 0.490093. Batch_loss: 1.418862 \n",
      "Batch: 347. Acc: 0.505437. Loss: 1.371285. Batch_acc: 0.507844. Batch_loss: 1.346664 \n",
      "Batch: 348. Acc: 0.505406. Loss: 1.371414. Batch_acc: 0.494761. Batch_loss: 1.416890 \n",
      "Batch: 349. Acc: 0.505436. Loss: 1.371346. Batch_acc: 0.515723. Batch_loss: 1.347823 \n",
      "Batch: 350. Acc: 0.505439. Loss: 1.371279. Batch_acc: 0.506351. Batch_loss: 1.347750 \n",
      "Batch: 351. Acc: 0.505481. Loss: 1.371189. Batch_acc: 0.520710. Batch_loss: 1.338513 \n",
      "Batch: 352. Acc: 0.505481. Loss: 1.371142. Batch_acc: 0.505585. Batch_loss: 1.354531 \n",
      "Batch: 353. Acc: 0.505453. Loss: 1.371284. Batch_acc: 0.495386. Batch_loss: 1.421327 \n",
      "Batch: 354. Acc: 0.505454. Loss: 1.371247. Batch_acc: 0.505997. Batch_loss: 1.358420 \n",
      "Batch: 355. Acc: 0.505460. Loss: 1.371245. Batch_acc: 0.507412. Batch_loss: 1.370309 \n",
      "Batch: 356. Acc: 0.505427. Loss: 1.371391. Batch_acc: 0.493575. Batch_loss: 1.424082 \n",
      "Batch: 357. Acc: 0.505400. Loss: 1.371491. Batch_acc: 0.496032. Batch_loss: 1.406647 \n",
      "Batch: 358. Acc: 0.505430. Loss: 1.371431. Batch_acc: 0.516129. Batch_loss: 1.349821 \n",
      "Batch: 359. Acc: 0.505443. Loss: 1.371370. Batch_acc: 0.510393. Batch_loss: 1.349284 \n",
      "Batch: 360. Acc: 0.505398. Loss: 1.371470. Batch_acc: 0.488941. Batch_loss: 1.407829 \n",
      "Batch: 361. Acc: 0.505378. Loss: 1.371570. Batch_acc: 0.498003. Batch_loss: 1.407168 \n",
      "Batch: 362. Acc: 0.505444. Loss: 1.371411. Batch_acc: 0.528981. Batch_loss: 1.315264 \n",
      "Batch: 363. Acc: 0.505490. Loss: 1.371339. Batch_acc: 0.522034. Batch_loss: 1.345826 \n",
      "Batch: 364. Acc: 0.505485. Loss: 1.371359. Batch_acc: 0.503546. Batch_loss: 1.378869 \n",
      "Batch: 365. Acc: 0.505447. Loss: 1.371436. Batch_acc: 0.491399. Batch_loss: 1.399473 \n",
      "Batch: 366. Acc: 0.505476. Loss: 1.371272. Batch_acc: 0.516279. Batch_loss: 1.310673 \n",
      "Batch: 367. Acc: 0.505491. Loss: 1.371278. Batch_acc: 0.511149. Batch_loss: 1.373268 \n",
      "Batch: 368. Acc: 0.505505. Loss: 1.371250. Batch_acc: 0.510357. Batch_loss: 1.361049 \n",
      "Batch: 369. Acc: 0.505498. Loss: 1.371271. Batch_acc: 0.503159. Batch_loss: 1.378793 \n",
      "Batch: 370. Acc: 0.505513. Loss: 1.371246. Batch_acc: 0.511059. Batch_loss: 1.362206 \n",
      "Batch: 371. Acc: 0.505488. Loss: 1.371333. Batch_acc: 0.496210. Batch_loss: 1.403978 \n",
      "Batch: 372. Acc: 0.505453. Loss: 1.371388. Batch_acc: 0.492183. Batch_loss: 1.391791 \n",
      "Batch: 373. Acc: 0.505477. Loss: 1.371385. Batch_acc: 0.514318. Batch_loss: 1.370397 \n",
      "Batch: 374. Acc: 0.505432. Loss: 1.371492. Batch_acc: 0.489185. Batch_loss: 1.409831 \n",
      "Batch: 375. Acc: 0.505443. Loss: 1.371486. Batch_acc: 0.509632. Batch_loss: 1.369512 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.505420. Loss: 1.371582. Batch_acc: 0.497143. Batch_loss: 1.407119 \n",
      "Batch: 377. Acc: 0.505429. Loss: 1.371622. Batch_acc: 0.508534. Batch_loss: 1.387123 \n",
      "Batch: 378. Acc: 0.505402. Loss: 1.371695. Batch_acc: 0.495423. Batch_loss: 1.399144 \n",
      "Batch: 379. Acc: 0.505374. Loss: 1.371840. Batch_acc: 0.494774. Batch_loss: 1.427128 \n",
      "Batch: 380. Acc: 0.505368. Loss: 1.371866. Batch_acc: 0.503170. Batch_loss: 1.382018 \n",
      "Batch: 381. Acc: 0.505316. Loss: 1.372041. Batch_acc: 0.484634. Batch_loss: 1.440264 \n",
      "Batch: 382. Acc: 0.505317. Loss: 1.372026. Batch_acc: 0.505734. Batch_loss: 1.366490 \n",
      "Batch: 383. Acc: 0.505414. Loss: 1.371824. Batch_acc: 0.542450. Batch_loss: 1.295011 \n",
      "Batch: 384. Acc: 0.505438. Loss: 1.371761. Batch_acc: 0.514563. Batch_loss: 1.347917 \n",
      "Batch: 385. Acc: 0.505417. Loss: 1.371801. Batch_acc: 0.497162. Batch_loss: 1.387030 \n",
      "Batch: 386. Acc: 0.505423. Loss: 1.371771. Batch_acc: 0.507874. Batch_loss: 1.360289 \n",
      "Batch: 387. Acc: 0.505378. Loss: 1.371825. Batch_acc: 0.487931. Batch_loss: 1.392700 \n",
      "Batch: 388. Acc: 0.505403. Loss: 1.371727. Batch_acc: 0.515117. Batch_loss: 1.334188 \n",
      "Batch: 389. Acc: 0.505407. Loss: 1.371715. Batch_acc: 0.506745. Batch_loss: 1.366842 \n",
      "Batch: 390. Acc: 0.505385. Loss: 1.371752. Batch_acc: 0.496797. Batch_loss: 1.386410 \n",
      "Batch: 391. Acc: 0.505351. Loss: 1.371811. Batch_acc: 0.492119. Batch_loss: 1.395244 \n",
      "Batch: 392. Acc: 0.505346. Loss: 1.371740. Batch_acc: 0.503401. Batch_loss: 1.344414 \n",
      "Batch: 393. Acc: 0.505333. Loss: 1.371796. Batch_acc: 0.500000. Batch_loss: 1.393254 \n",
      "Batch: 394. Acc: 0.505388. Loss: 1.371613. Batch_acc: 0.526492. Batch_loss: 1.301844 \n",
      "Batch: 395. Acc: 0.505436. Loss: 1.371515. Batch_acc: 0.524189. Batch_loss: 1.333158 \n",
      "Batch: 396. Acc: 0.505470. Loss: 1.371412. Batch_acc: 0.518519. Batch_loss: 1.331798 \n",
      "Batch: 397. Acc: 0.505442. Loss: 1.371440. Batch_acc: 0.494505. Batch_loss: 1.382684 \n",
      "Batch: 398. Acc: 0.505442. Loss: 1.371508. Batch_acc: 0.505269. Batch_loss: 1.399036 \n",
      "Batch: 399. Acc: 0.505405. Loss: 1.371604. Batch_acc: 0.490196. Batch_loss: 1.410918 \n",
      "Batch: 400. Acc: 0.505370. Loss: 1.371680. Batch_acc: 0.490845. Batch_loss: 1.402852 \n",
      "Batch: 401. Acc: 0.505367. Loss: 1.371676. Batch_acc: 0.504515. Batch_loss: 1.370143 \n",
      "Batch: 402. Acc: 0.505360. Loss: 1.371715. Batch_acc: 0.502389. Batch_loss: 1.388156 \n",
      "Batch: 403. Acc: 0.505362. Loss: 1.371676. Batch_acc: 0.506059. Batch_loss: 1.355859 \n",
      "Batch: 404. Acc: 0.505346. Loss: 1.371763. Batch_acc: 0.498864. Batch_loss: 1.406528 \n",
      "Batch: 405. Acc: 0.505325. Loss: 1.371811. Batch_acc: 0.496855. Batch_loss: 1.391143 \n",
      "Batch: 406. Acc: 0.505273. Loss: 1.371925. Batch_acc: 0.484465. Batch_loss: 1.418067 \n",
      "Batch: 407. Acc: 0.505251. Loss: 1.371969. Batch_acc: 0.496321. Batch_loss: 1.389443 \n",
      "Batch: 408. Acc: 0.505249. Loss: 1.372011. Batch_acc: 0.504323. Batch_loss: 1.389143 \n",
      "Batch: 409. Acc: 0.505286. Loss: 1.371967. Batch_acc: 0.520642. Batch_loss: 1.354309 \n",
      "Batch: 410. Acc: 0.505278. Loss: 1.371944. Batch_acc: 0.501744. Batch_loss: 1.362177 \n",
      "Batch: 411. Acc: 0.505354. Loss: 1.371729. Batch_acc: 0.535714. Batch_loss: 1.286383 \n",
      "Batch: 412. Acc: 0.505359. Loss: 1.371665. Batch_acc: 0.507163. Batch_loss: 1.345319 \n",
      "Batch: 413. Acc: 0.505405. Loss: 1.371604. Batch_acc: 0.524752. Batch_loss: 1.345917 \n",
      "Batch: 414. Acc: 0.505370. Loss: 1.371675. Batch_acc: 0.490730. Batch_loss: 1.401503 \n",
      "Batch: 415. Acc: 0.505387. Loss: 1.371596. Batch_acc: 0.512318. Batch_loss: 1.339489 \n",
      "Batch: 416. Acc: 0.505353. Loss: 1.371677. Batch_acc: 0.491107. Batch_loss: 1.405190 \n",
      "Batch: 417. Acc: 0.505365. Loss: 1.371661. Batch_acc: 0.510369. Batch_loss: 1.364959 \n",
      "Batch: 418. Acc: 0.505338. Loss: 1.371779. Batch_acc: 0.494125. Batch_loss: 1.422320 \n",
      "Batch: 419. Acc: 0.505374. Loss: 1.371698. Batch_acc: 0.520414. Batch_loss: 1.337876 \n",
      "Batch: 420. Acc: 0.505424. Loss: 1.371598. Batch_acc: 0.525670. Batch_loss: 1.330895 \n",
      "Batch: 421. Acc: 0.505429. Loss: 1.371623. Batch_acc: 0.507386. Batch_loss: 1.382009 \n",
      "Batch: 422. Acc: 0.505441. Loss: 1.371590. Batch_acc: 0.510762. Batch_loss: 1.357419 \n",
      "Batch: 423. Acc: 0.505423. Loss: 1.371584. Batch_acc: 0.497669. Batch_loss: 1.369191 \n",
      "Batch: 424. Acc: 0.505466. Loss: 1.371487. Batch_acc: 0.523354. Batch_loss: 1.330963 \n",
      "Batch: 425. Acc: 0.505381. Loss: 1.371695. Batch_acc: 0.469481. Batch_loss: 1.459241 \n",
      "Batch: 426. Acc: 0.505372. Loss: 1.371667. Batch_acc: 0.501712. Batch_loss: 1.360018 \n",
      "Batch: 427. Acc: 0.505399. Loss: 1.371687. Batch_acc: 0.516867. Batch_loss: 1.380202 \n",
      "Batch: 428. Acc: 0.505415. Loss: 1.371655. Batch_acc: 0.512099. Batch_loss: 1.358414 \n",
      "Batch: 429. Acc: 0.505443. Loss: 1.371531. Batch_acc: 0.517462. Batch_loss: 1.317399 \n",
      "Batch: 430. Acc: 0.505485. Loss: 1.371480. Batch_acc: 0.524266. Batch_loss: 1.348675 \n",
      "Batch: 431. Acc: 0.505460. Loss: 1.371544. Batch_acc: 0.494910. Batch_loss: 1.398936 \n",
      "Batch: 432. Acc: 0.505494. Loss: 1.371403. Batch_acc: 0.520540. Batch_loss: 1.309180 \n",
      "Batch: 433. Acc: 0.505494. Loss: 1.371393. Batch_acc: 0.505208. Batch_loss: 1.367134 \n",
      "Batch: 434. Acc: 0.505512. Loss: 1.371345. Batch_acc: 0.513375. Batch_loss: 1.350739 \n",
      "Batch: 435. Acc: 0.505544. Loss: 1.371197. Batch_acc: 0.519384. Batch_loss: 1.307262 \n",
      "Batch: 436. Acc: 0.505543. Loss: 1.371257. Batch_acc: 0.505178. Batch_loss: 1.397265 \n",
      "Batch: 437. Acc: 0.505512. Loss: 1.371278. Batch_acc: 0.492099. Batch_loss: 1.380301 \n",
      "Batch: 438. Acc: 0.505476. Loss: 1.371324. Batch_acc: 0.490107. Batch_loss: 1.391494 \n",
      "Batch: 439. Acc: 0.505451. Loss: 1.371370. Batch_acc: 0.494467. Batch_loss: 1.391520 \n",
      "Batch: 440. Acc: 0.505462. Loss: 1.371387. Batch_acc: 0.510227. Batch_loss: 1.378628 \n",
      "Batch: 441. Acc: 0.505471. Loss: 1.371255. Batch_acc: 0.509412. Batch_loss: 1.313567 \n",
      "Batch: 442. Acc: 0.505497. Loss: 1.371232. Batch_acc: 0.516752. Batch_loss: 1.361606 \n",
      "Batch: 443. Acc: 0.505476. Loss: 1.371283. Batch_acc: 0.496228. Batch_loss: 1.393901 \n",
      "Batch: 444. Acc: 0.505442. Loss: 1.371348. Batch_acc: 0.490286. Batch_loss: 1.399796 \n",
      "Batch: 445. Acc: 0.505465. Loss: 1.371268. Batch_acc: 0.515850. Batch_loss: 1.335944 \n",
      "Batch: 446. Acc: 0.505458. Loss: 1.371194. Batch_acc: 0.502323. Batch_loss: 1.337572 \n",
      "Batch: 447. Acc: 0.505472. Loss: 1.371168. Batch_acc: 0.511708. Batch_loss: 1.359921 \n",
      "Batch: 448. Acc: 0.505503. Loss: 1.371114. Batch_acc: 0.519119. Batch_loss: 1.346454 \n",
      "Batch: 449. Acc: 0.505513. Loss: 1.371141. Batch_acc: 0.509859. Batch_loss: 1.383404 \n",
      "Batch: 450. Acc: 0.505551. Loss: 1.370989. Batch_acc: 0.522559. Batch_loss: 1.302916 \n",
      "Batch: 451. Acc: 0.505533. Loss: 1.371033. Batch_acc: 0.497680. Batch_loss: 1.390867 \n",
      "Batch: 452. Acc: 0.505548. Loss: 1.371019. Batch_acc: 0.511891. Batch_loss: 1.364776 \n",
      "Batch: 453. Acc: 0.505551. Loss: 1.370943. Batch_acc: 0.507255. Batch_loss: 1.336314 \n",
      "Batch: 454. Acc: 0.505529. Loss: 1.370980. Batch_acc: 0.495746. Batch_loss: 1.387422 \n",
      "Batch: 455. Acc: 0.505519. Loss: 1.371027. Batch_acc: 0.501112. Batch_loss: 1.391791 \n",
      "Batch: 456. Acc: 0.505557. Loss: 1.370943. Batch_acc: 0.522254. Batch_loss: 1.333644 \n",
      "Batch: 457. Acc: 0.505603. Loss: 1.370848. Batch_acc: 0.526498. Batch_loss: 1.327390 \n",
      "Batch: 458. Acc: 0.505652. Loss: 1.370695. Batch_acc: 0.527590. Batch_loss: 1.302210 \n",
      "Batch: 459. Acc: 0.505703. Loss: 1.370535. Batch_acc: 0.529344. Batch_loss: 1.296759 \n",
      "Batch: 460. Acc: 0.505749. Loss: 1.370485. Batch_acc: 0.526464. Batch_loss: 1.347987 \n",
      "Batch: 461. Acc: 0.505751. Loss: 1.370513. Batch_acc: 0.506486. Batch_loss: 1.383504 \n",
      "Batch: 462. Acc: 0.505790. Loss: 1.370447. Batch_acc: 0.524138. Batch_loss: 1.339911 \n",
      "Batch: 463. Acc: 0.505753. Loss: 1.370500. Batch_acc: 0.488152. Batch_loss: 1.395482 \n",
      "Batch: 464. Acc: 0.505765. Loss: 1.370408. Batch_acc: 0.511213. Batch_loss: 1.327724 \n",
      "Batch: 465. Acc: 0.505732. Loss: 1.370531. Batch_acc: 0.489489. Batch_loss: 1.430343 \n",
      "Batch: 466. Acc: 0.505696. Loss: 1.370618. Batch_acc: 0.488630. Batch_loss: 1.411961 \n",
      "Batch: 467. Acc: 0.505722. Loss: 1.370548. Batch_acc: 0.517148. Batch_loss: 1.339315 \n",
      "Batch: 468. Acc: 0.505744. Loss: 1.370488. Batch_acc: 0.516336. Batch_loss: 1.341943 \n",
      "Batch: 469. Acc: 0.505774. Loss: 1.370396. Batch_acc: 0.520138. Batch_loss: 1.327255 \n",
      "Batch: 470. Acc: 0.505743. Loss: 1.370489. Batch_acc: 0.491066. Batch_loss: 1.414568 \n",
      "Batch: 471. Acc: 0.505714. Loss: 1.370533. Batch_acc: 0.491803. Batch_loss: 1.391393 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.505735. Loss: 1.370441. Batch_acc: 0.515571. Batch_loss: 1.327156 \n",
      "Batch: 473. Acc: 0.505725. Loss: 1.370463. Batch_acc: 0.500851. Batch_loss: 1.380616 \n",
      "Batch: 474. Acc: 0.505699. Loss: 1.370494. Batch_acc: 0.493736. Batch_loss: 1.385008 \n",
      "Batch: 475. Acc: 0.505746. Loss: 1.370350. Batch_acc: 0.527698. Batch_loss: 1.302588 \n",
      "Batch: 476. Acc: 0.505727. Loss: 1.370402. Batch_acc: 0.497156. Batch_loss: 1.394891 \n",
      "Batch: 477. Acc: 0.505713. Loss: 1.370469. Batch_acc: 0.498814. Batch_loss: 1.403537 \n",
      "Batch: 478. Acc: 0.505691. Loss: 1.370499. Batch_acc: 0.495061. Batch_loss: 1.384573 \n",
      "Batch: 479. Acc: 0.505723. Loss: 1.370377. Batch_acc: 0.520761. Batch_loss: 1.312048 \n",
      "Batch: 480. Acc: 0.505669. Loss: 1.370487. Batch_acc: 0.479314. Batch_loss: 1.424630 \n",
      "Batch: 481. Acc: 0.505681. Loss: 1.370415. Batch_acc: 0.511534. Batch_loss: 1.335891 \n",
      "Batch: 482. Acc: 0.505737. Loss: 1.370312. Batch_acc: 0.531724. Batch_loss: 1.321862 \n",
      "Batch: 483. Acc: 0.505741. Loss: 1.370273. Batch_acc: 0.507821. Batch_loss: 1.351628 \n",
      "Batch: 484. Acc: 0.505757. Loss: 1.370215. Batch_acc: 0.513467. Batch_loss: 1.342653 \n",
      "Batch: 485. Acc: 0.505808. Loss: 1.370093. Batch_acc: 0.530901. Batch_loss: 1.309588 \n",
      "Batch: 486. Acc: 0.505810. Loss: 1.370142. Batch_acc: 0.506810. Batch_loss: 1.393273 \n",
      "Batch: 487. Acc: 0.505783. Loss: 1.370221. Batch_acc: 0.492477. Batch_loss: 1.409227 \n",
      "Batch: 488. Acc: 0.505778. Loss: 1.370235. Batch_acc: 0.503256. Batch_loss: 1.376931 \n",
      "Batch: 489. Acc: 0.505738. Loss: 1.370325. Batch_acc: 0.486440. Batch_loss: 1.414679 \n",
      "Batch: 490. Acc: 0.505696. Loss: 1.370442. Batch_acc: 0.484439. Batch_loss: 1.428911 \n",
      "Batch: 491. Acc: 0.505674. Loss: 1.370548. Batch_acc: 0.494687. Batch_loss: 1.423706 \n",
      "Batch: 492. Acc: 0.505645. Loss: 1.370639. Batch_acc: 0.491554. Batch_loss: 1.414527 \n",
      "Batch: 493. Acc: 0.505692. Loss: 1.370538. Batch_acc: 0.528071. Batch_loss: 1.322737 \n",
      "Batch: 494. Acc: 0.505698. Loss: 1.370513. Batch_acc: 0.508641. Batch_loss: 1.358096 \n",
      "Batch: 495. Acc: 0.505634. Loss: 1.370646. Batch_acc: 0.473988. Batch_loss: 1.436507 \n",
      "Batch: 496. Acc: 0.505609. Loss: 1.370716. Batch_acc: 0.493417. Batch_loss: 1.405357 \n",
      "Batch: 497. Acc: 0.505637. Loss: 1.370658. Batch_acc: 0.519671. Batch_loss: 1.341286 \n",
      "Batch: 498. Acc: 0.505592. Loss: 1.370809. Batch_acc: 0.482961. Batch_loss: 1.447739 \n",
      "Batch: 499. Acc: 0.505551. Loss: 1.370880. Batch_acc: 0.485126. Batch_loss: 1.406096 \n",
      "Batch: 500. Acc: 0.505545. Loss: 1.370900. Batch_acc: 0.502299. Batch_loss: 1.380592 \n",
      "Batch: 501. Acc: 0.505611. Loss: 1.370718. Batch_acc: 0.538636. Batch_loss: 1.280683 \n",
      "Batch: 502. Acc: 0.505602. Loss: 1.370752. Batch_acc: 0.500867. Batch_loss: 1.387979 \n",
      "Checkpointing on batch: 502. Accuracy: 0.5056020502142313. Loss per char: 1.370751909271835. Time: 1627218336.2494016\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 21, 25, 23, 22, 18, 24,  1,\n",
      "        81, 77, 86, 84,  1, 17, 15, 23, 22, 19, 23, 25, 23, 32,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.505639. Loss: 1.370701. Batch_acc: 0.524052. Batch_loss: 1.345531 \n",
      "Batch: 504. Acc: 0.505625. Loss: 1.370707. Batch_acc: 0.498549. Batch_loss: 1.373740 \n",
      "Batch: 505. Acc: 0.505587. Loss: 1.370823. Batch_acc: 0.486014. Batch_loss: 1.430200 \n",
      "Batch: 506. Acc: 0.505592. Loss: 1.370806. Batch_acc: 0.507901. Batch_loss: 1.362371 \n",
      "Batch: 507. Acc: 0.505653. Loss: 1.370717. Batch_acc: 0.537507. Batch_loss: 1.324435 \n",
      "Batch: 508. Acc: 0.505643. Loss: 1.370695. Batch_acc: 0.500295. Batch_loss: 1.359151 \n",
      "Batch: 509. Acc: 0.505657. Loss: 1.370672. Batch_acc: 0.513128. Batch_loss: 1.358981 \n",
      "Batch: 510. Acc: 0.505659. Loss: 1.370685. Batch_acc: 0.506472. Batch_loss: 1.377351 \n",
      "Batch: 511. Acc: 0.505634. Loss: 1.370753. Batch_acc: 0.492787. Batch_loss: 1.405711 \n",
      "Batch: 512. Acc: 0.505644. Loss: 1.370778. Batch_acc: 0.510820. Batch_loss: 1.383107 \n",
      "Batch: 513. Acc: 0.505689. Loss: 1.370705. Batch_acc: 0.528563. Batch_loss: 1.333096 \n",
      "Batch: 514. Acc: 0.505693. Loss: 1.370685. Batch_acc: 0.507736. Batch_loss: 1.360411 \n",
      "Batch: 515. Acc: 0.505704. Loss: 1.370662. Batch_acc: 0.511410. Batch_loss: 1.358822 \n",
      "Batch: 516. Acc: 0.505640. Loss: 1.370789. Batch_acc: 0.472685. Batch_loss: 1.436411 \n",
      "Batch: 517. Acc: 0.505639. Loss: 1.370759. Batch_acc: 0.505161. Batch_loss: 1.355202 \n",
      "Batch: 518. Acc: 0.505601. Loss: 1.370893. Batch_acc: 0.486270. Batch_loss: 1.440052 \n",
      "Batch: 519. Acc: 0.505602. Loss: 1.370894. Batch_acc: 0.506130. Batch_loss: 1.371403 \n",
      "Batch: 520. Acc: 0.505566. Loss: 1.370939. Batch_acc: 0.486265. Batch_loss: 1.394570 \n",
      "Batch: 521. Acc: 0.505560. Loss: 1.371009. Batch_acc: 0.502609. Batch_loss: 1.407490 \n",
      "Batch: 522. Acc: 0.505580. Loss: 1.370879. Batch_acc: 0.515670. Batch_loss: 1.303825 \n",
      "Batch: 523. Acc: 0.505628. Loss: 1.370795. Batch_acc: 0.530800. Batch_loss: 1.326862 \n",
      "Batch: 524. Acc: 0.505630. Loss: 1.370770. Batch_acc: 0.506749. Batch_loss: 1.358284 \n",
      "Batch: 525. Acc: 0.505628. Loss: 1.370755. Batch_acc: 0.504619. Batch_loss: 1.362768 \n",
      "Batch: 526. Acc: 0.505629. Loss: 1.370795. Batch_acc: 0.505997. Batch_loss: 1.391309 \n",
      "Batch: 527. Acc: 0.505608. Loss: 1.370815. Batch_acc: 0.494810. Batch_loss: 1.381700 \n",
      "Batch: 528. Acc: 0.505607. Loss: 1.370797. Batch_acc: 0.505143. Batch_loss: 1.361399 \n",
      "Batch: 529. Acc: 0.505565. Loss: 1.370901. Batch_acc: 0.483210. Batch_loss: 1.425236 \n",
      "Batch: 530. Acc: 0.505570. Loss: 1.370915. Batch_acc: 0.508416. Batch_loss: 1.378392 \n",
      "Batch: 531. Acc: 0.505530. Loss: 1.371072. Batch_acc: 0.483890. Batch_loss: 1.455733 \n",
      "Batch: 532. Acc: 0.505534. Loss: 1.371083. Batch_acc: 0.507640. Batch_loss: 1.376841 \n",
      "Batch: 533. Acc: 0.505547. Loss: 1.371057. Batch_acc: 0.512378. Batch_loss: 1.357211 \n",
      "Batch: 534. Acc: 0.505523. Loss: 1.371124. Batch_acc: 0.493363. Batch_loss: 1.405467 \n",
      "Batch: 535. Acc: 0.505499. Loss: 1.371155. Batch_acc: 0.492820. Batch_loss: 1.387770 \n",
      "Batch: 536. Acc: 0.505493. Loss: 1.371165. Batch_acc: 0.502006. Batch_loss: 1.376603 \n",
      "Batch: 537. Acc: 0.505530. Loss: 1.371115. Batch_acc: 0.526100. Batch_loss: 1.343689 \n",
      "Batch: 538. Acc: 0.505522. Loss: 1.371138. Batch_acc: 0.501144. Batch_loss: 1.383296 \n",
      "Batch: 539. Acc: 0.505534. Loss: 1.371086. Batch_acc: 0.512181. Batch_loss: 1.342098 \n",
      "Batch: 540. Acc: 0.505539. Loss: 1.371103. Batch_acc: 0.508140. Batch_loss: 1.380634 \n",
      "Batch: 541. Acc: 0.505529. Loss: 1.371081. Batch_acc: 0.500283. Batch_loss: 1.359496 \n",
      "Batch: 542. Acc: 0.505568. Loss: 1.370992. Batch_acc: 0.526644. Batch_loss: 1.323212 \n",
      "Batch: 543. Acc: 0.505573. Loss: 1.370966. Batch_acc: 0.508262. Batch_loss: 1.356928 \n",
      "Batch: 544. Acc: 0.505596. Loss: 1.370861. Batch_acc: 0.518044. Batch_loss: 1.313098 \n",
      "Batch: 545. Acc: 0.505601. Loss: 1.370897. Batch_acc: 0.508435. Batch_loss: 1.391151 \n",
      "Batch: 546. Acc: 0.505644. Loss: 1.370801. Batch_acc: 0.528841. Batch_loss: 1.318350 \n",
      "Batch: 547. Acc: 0.505653. Loss: 1.370782. Batch_acc: 0.510286. Batch_loss: 1.360533 \n",
      "Batch: 548. Acc: 0.505653. Loss: 1.370798. Batch_acc: 0.505889. Batch_loss: 1.379776 \n",
      "Batch: 549. Acc: 0.505648. Loss: 1.370836. Batch_acc: 0.503155. Batch_loss: 1.391562 \n",
      "Batch: 550. Acc: 0.505637. Loss: 1.370921. Batch_acc: 0.499417. Batch_loss: 1.418534 \n",
      "Batch: 551. Acc: 0.505626. Loss: 1.370938. Batch_acc: 0.499718. Batch_loss: 1.380005 \n",
      "Batch: 552. Acc: 0.505649. Loss: 1.370900. Batch_acc: 0.518093. Batch_loss: 1.349855 \n",
      "Batch: 553. Acc: 0.505681. Loss: 1.370814. Batch_acc: 0.523343. Batch_loss: 1.323420 \n",
      "Batch: 554. Acc: 0.505697. Loss: 1.370865. Batch_acc: 0.514630. Batch_loss: 1.399259 \n",
      "Batch: 555. Acc: 0.505717. Loss: 1.370800. Batch_acc: 0.516802. Batch_loss: 1.333972 \n",
      "Batch: 556. Acc: 0.505696. Loss: 1.370862. Batch_acc: 0.494044. Batch_loss: 1.405239 \n",
      "Batch: 557. Acc: 0.505689. Loss: 1.370857. Batch_acc: 0.502008. Batch_loss: 1.367934 \n",
      "Batch: 558. Acc: 0.505683. Loss: 1.370858. Batch_acc: 0.502232. Batch_loss: 1.371148 \n",
      "Batch: 559. Acc: 0.505690. Loss: 1.370908. Batch_acc: 0.509861. Batch_loss: 1.399596 \n",
      "Batch: 560. Acc: 0.505683. Loss: 1.370982. Batch_acc: 0.501485. Batch_loss: 1.413310 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 561. Acc: 0.505692. Loss: 1.370940. Batch_acc: 0.511163. Batch_loss: 1.347001 \n",
      "Batch: 562. Acc: 0.505677. Loss: 1.370930. Batch_acc: 0.497123. Batch_loss: 1.365273 \n",
      "Batch: 563. Acc: 0.505711. Loss: 1.370915. Batch_acc: 0.524452. Batch_loss: 1.362662 \n",
      "Batch: 564. Acc: 0.505738. Loss: 1.370862. Batch_acc: 0.520563. Batch_loss: 1.341803 \n",
      "Batch: 565. Acc: 0.505762. Loss: 1.370807. Batch_acc: 0.519296. Batch_loss: 1.340183 \n",
      "Batch: 566. Acc: 0.505763. Loss: 1.370857. Batch_acc: 0.506463. Batch_loss: 1.399571 \n",
      "Batch: 567. Acc: 0.505788. Loss: 1.370830. Batch_acc: 0.520046. Batch_loss: 1.355433 \n",
      "Batch: 568. Acc: 0.505783. Loss: 1.370831. Batch_acc: 0.502890. Batch_loss: 1.371129 \n",
      "Batch: 569. Acc: 0.505780. Loss: 1.370799. Batch_acc: 0.503666. Batch_loss: 1.353380 \n",
      "Batch: 570. Acc: 0.505787. Loss: 1.370765. Batch_acc: 0.510086. Batch_loss: 1.350899 \n",
      "Batch: 571. Acc: 0.505760. Loss: 1.370807. Batch_acc: 0.490379. Batch_loss: 1.395600 \n",
      "Batch: 572. Acc: 0.505768. Loss: 1.370743. Batch_acc: 0.510274. Batch_loss: 1.334188 \n",
      "Batch: 573. Acc: 0.505790. Loss: 1.370705. Batch_acc: 0.518161. Batch_loss: 1.349087 \n",
      "Batch: 574. Acc: 0.505801. Loss: 1.370670. Batch_acc: 0.511628. Batch_loss: 1.350837 \n",
      "Batch: 575. Acc: 0.505841. Loss: 1.370547. Batch_acc: 0.529446. Batch_loss: 1.299221 \n",
      "Batch: 576. Acc: 0.505811. Loss: 1.370599. Batch_acc: 0.488889. Batch_loss: 1.400131 \n",
      "Batch: 577. Acc: 0.505847. Loss: 1.370519. Batch_acc: 0.526286. Batch_loss: 1.324575 \n",
      "Batch: 578. Acc: 0.505859. Loss: 1.370441. Batch_acc: 0.512865. Batch_loss: 1.324689 \n",
      "Batch: 579. Acc: 0.505866. Loss: 1.370428. Batch_acc: 0.509849. Batch_loss: 1.362981 \n",
      "Batch: 580. Acc: 0.505877. Loss: 1.370442. Batch_acc: 0.512281. Batch_loss: 1.378772 \n",
      "Batch: 581. Acc: 0.505883. Loss: 1.370383. Batch_acc: 0.509402. Batch_loss: 1.336073 \n",
      "Batch: 582. Acc: 0.505885. Loss: 1.370363. Batch_acc: 0.506985. Batch_loss: 1.358515 \n",
      "Batch: 583. Acc: 0.505897. Loss: 1.370309. Batch_acc: 0.512748. Batch_loss: 1.339356 \n",
      "Batch: 584. Acc: 0.505925. Loss: 1.370255. Batch_acc: 0.522780. Batch_loss: 1.338445 \n",
      "Batch: 585. Acc: 0.505949. Loss: 1.370178. Batch_acc: 0.520023. Batch_loss: 1.324578 \n",
      "Batch: 586. Acc: 0.505985. Loss: 1.370103. Batch_acc: 0.526492. Batch_loss: 1.327525 \n",
      "Batch: 587. Acc: 0.505974. Loss: 1.370111. Batch_acc: 0.499426. Batch_loss: 1.375231 \n",
      "Batch: 588. Acc: 0.505990. Loss: 1.370078. Batch_acc: 0.515291. Batch_loss: 1.350426 \n",
      "Batch: 589. Acc: 0.506002. Loss: 1.370071. Batch_acc: 0.513043. Batch_loss: 1.365849 \n",
      "Batch: 590. Acc: 0.505996. Loss: 1.370090. Batch_acc: 0.502844. Batch_loss: 1.381436 \n",
      "Batch: 591. Acc: 0.506063. Loss: 1.369933. Batch_acc: 0.545718. Batch_loss: 1.276573 \n",
      "Batch: 592. Acc: 0.506043. Loss: 1.369963. Batch_acc: 0.494518. Batch_loss: 1.387713 \n",
      "Batch: 593. Acc: 0.506063. Loss: 1.369937. Batch_acc: 0.517396. Batch_loss: 1.354989 \n",
      "Batch: 594. Acc: 0.506076. Loss: 1.369933. Batch_acc: 0.513761. Batch_loss: 1.367460 \n",
      "Batch: 595. Acc: 0.506069. Loss: 1.369934. Batch_acc: 0.501754. Batch_loss: 1.370164 \n",
      "Batch: 596. Acc: 0.506111. Loss: 1.369899. Batch_acc: 0.531395. Batch_loss: 1.349036 \n",
      "Batch: 597. Acc: 0.506118. Loss: 1.369881. Batch_acc: 0.510381. Batch_loss: 1.359394 \n",
      "Batch: 598. Acc: 0.506148. Loss: 1.369811. Batch_acc: 0.524166. Batch_loss: 1.327687 \n",
      "Batch: 599. Acc: 0.506187. Loss: 1.369722. Batch_acc: 0.528814. Batch_loss: 1.317082 \n",
      "Batch: 600. Acc: 0.506189. Loss: 1.369700. Batch_acc: 0.507763. Batch_loss: 1.356807 \n",
      "Batch: 601. Acc: 0.506249. Loss: 1.369536. Batch_acc: 0.542002. Batch_loss: 1.270713 \n",
      "Batch: 602. Acc: 0.506237. Loss: 1.369559. Batch_acc: 0.499128. Batch_loss: 1.383843 \n",
      "Batch: 603. Acc: 0.506193. Loss: 1.369705. Batch_acc: 0.479609. Batch_loss: 1.457788 \n",
      "Batch: 604. Acc: 0.506185. Loss: 1.369731. Batch_acc: 0.501456. Batch_loss: 1.385281 \n",
      "Batch: 605. Acc: 0.506180. Loss: 1.369677. Batch_acc: 0.503134. Batch_loss: 1.337713 \n",
      "Batch: 606. Acc: 0.506210. Loss: 1.369600. Batch_acc: 0.524439. Batch_loss: 1.322494 \n",
      "Batch: 607. Acc: 0.506219. Loss: 1.369561. Batch_acc: 0.511561. Batch_loss: 1.345836 \n",
      "Batch: 608. Acc: 0.506185. Loss: 1.369608. Batch_acc: 0.485242. Batch_loss: 1.398928 \n",
      "Batch: 609. Acc: 0.506184. Loss: 1.369566. Batch_acc: 0.505214. Batch_loss: 1.343732 \n",
      "Batch: 610. Acc: 0.506176. Loss: 1.369563. Batch_acc: 0.501691. Batch_loss: 1.368103 \n",
      "Batch: 611. Acc: 0.506204. Loss: 1.369478. Batch_acc: 0.523183. Batch_loss: 1.317803 \n",
      "Batch: 612. Acc: 0.506223. Loss: 1.369455. Batch_acc: 0.517459. Batch_loss: 1.355187 \n",
      "Batch: 613. Acc: 0.506207. Loss: 1.369452. Batch_acc: 0.496848. Batch_loss: 1.367732 \n",
      "Batch: 614. Acc: 0.506199. Loss: 1.369508. Batch_acc: 0.500863. Batch_loss: 1.404082 \n",
      "Batch: 615. Acc: 0.506220. Loss: 1.369422. Batch_acc: 0.519209. Batch_loss: 1.317590 \n",
      "Batch: 616. Acc: 0.506222. Loss: 1.369367. Batch_acc: 0.507295. Batch_loss: 1.336261 \n",
      "Batch: 617. Acc: 0.506225. Loss: 1.369379. Batch_acc: 0.508206. Batch_loss: 1.376435 \n",
      "Batch: 618. Acc: 0.506177. Loss: 1.369436. Batch_acc: 0.477157. Batch_loss: 1.404006 \n",
      "Batch: 619. Acc: 0.506168. Loss: 1.369466. Batch_acc: 0.500290. Batch_loss: 1.388444 \n",
      "Batch: 620. Acc: 0.506172. Loss: 1.369429. Batch_acc: 0.508893. Batch_loss: 1.345989 \n",
      "Batch: 621. Acc: 0.506196. Loss: 1.369417. Batch_acc: 0.520750. Batch_loss: 1.362028 \n",
      "Batch: 622. Acc: 0.506229. Loss: 1.369340. Batch_acc: 0.527019. Batch_loss: 1.321415 \n",
      "Batch: 623. Acc: 0.506249. Loss: 1.369295. Batch_acc: 0.518710. Batch_loss: 1.340955 \n",
      "Batch: 624. Acc: 0.506252. Loss: 1.369263. Batch_acc: 0.508009. Batch_loss: 1.349837 \n",
      "Batch: 625. Acc: 0.506276. Loss: 1.369198. Batch_acc: 0.521233. Batch_loss: 1.327941 \n",
      "Batch: 626. Acc: 0.506282. Loss: 1.369196. Batch_acc: 0.510502. Batch_loss: 1.367654 \n",
      "Batch: 627. Acc: 0.506306. Loss: 1.369163. Batch_acc: 0.520989. Batch_loss: 1.348551 \n",
      "Batch: 628. Acc: 0.506280. Loss: 1.369205. Batch_acc: 0.490544. Batch_loss: 1.395371 \n",
      "Batch: 629. Acc: 0.506276. Loss: 1.369205. Batch_acc: 0.503188. Batch_loss: 1.369720 \n",
      "Batch: 630. Acc: 0.506287. Loss: 1.369138. Batch_acc: 0.513590. Batch_loss: 1.327073 \n",
      "Batch: 631. Acc: 0.506265. Loss: 1.369183. Batch_acc: 0.491374. Batch_loss: 1.398862 \n",
      "Batch: 632. Acc: 0.506259. Loss: 1.369185. Batch_acc: 0.502550. Batch_loss: 1.370132 \n",
      "Batch: 633. Acc: 0.506247. Loss: 1.369216. Batch_acc: 0.498818. Batch_loss: 1.389907 \n",
      "Batch: 634. Acc: 0.506313. Loss: 1.369055. Batch_acc: 0.548667. Batch_loss: 1.266006 \n",
      "Batch: 635. Acc: 0.506329. Loss: 1.369011. Batch_acc: 0.515945. Batch_loss: 1.341427 \n",
      "Batch: 636. Acc: 0.506346. Loss: 1.369000. Batch_acc: 0.517321. Batch_loss: 1.362034 \n",
      "Batch: 637. Acc: 0.506372. Loss: 1.368952. Batch_acc: 0.523095. Batch_loss: 1.337830 \n",
      "Batch: 638. Acc: 0.506376. Loss: 1.368967. Batch_acc: 0.509070. Batch_loss: 1.378506 \n",
      "Batch: 639. Acc: 0.506422. Loss: 1.368837. Batch_acc: 0.535003. Batch_loss: 1.286654 \n",
      "Batch: 640. Acc: 0.506415. Loss: 1.368862. Batch_acc: 0.502309. Batch_loss: 1.384974 \n",
      "Batch: 641. Acc: 0.506378. Loss: 1.368892. Batch_acc: 0.482019. Batch_loss: 1.388346 \n",
      "Batch: 642. Acc: 0.506394. Loss: 1.368874. Batch_acc: 0.517201. Batch_loss: 1.356908 \n",
      "Batch: 643. Acc: 0.506421. Loss: 1.368815. Batch_acc: 0.523349. Batch_loss: 1.331478 \n",
      "Batch: 644. Acc: 0.506446. Loss: 1.368715. Batch_acc: 0.522779. Batch_loss: 1.305166 \n",
      "Batch: 645. Acc: 0.506454. Loss: 1.368774. Batch_acc: 0.511587. Batch_loss: 1.406916 \n",
      "Batch: 646. Acc: 0.506460. Loss: 1.368746. Batch_acc: 0.510052. Batch_loss: 1.351041 \n",
      "Batch: 647. Acc: 0.506520. Loss: 1.368549. Batch_acc: 0.544734. Batch_loss: 1.242938 \n",
      "Batch: 648. Acc: 0.506492. Loss: 1.368580. Batch_acc: 0.488166. Batch_loss: 1.389179 \n",
      "Batch: 649. Acc: 0.506487. Loss: 1.368591. Batch_acc: 0.503230. Batch_loss: 1.375575 \n",
      "Batch: 650. Acc: 0.506481. Loss: 1.368623. Batch_acc: 0.502262. Batch_loss: 1.389059 \n",
      "Batch: 651. Acc: 0.506482. Loss: 1.368587. Batch_acc: 0.507147. Batch_loss: 1.345458 \n",
      "Batch: 652. Acc: 0.506451. Loss: 1.368686. Batch_acc: 0.486471. Batch_loss: 1.433181 \n",
      "Batch: 653. Acc: 0.506444. Loss: 1.368696. Batch_acc: 0.501992. Batch_loss: 1.375449 \n",
      "Batch: 654. Acc: 0.506464. Loss: 1.368641. Batch_acc: 0.518987. Batch_loss: 1.332708 \n",
      "Batch: 655. Acc: 0.506464. Loss: 1.368695. Batch_acc: 0.506721. Batch_loss: 1.404496 \n",
      "Batch: 656. Acc: 0.506482. Loss: 1.368640. Batch_acc: 0.517897. Batch_loss: 1.333388 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 657. Acc: 0.506481. Loss: 1.368682. Batch_acc: 0.506010. Batch_loss: 1.396342 \n",
      "Batch: 658. Acc: 0.506481. Loss: 1.368692. Batch_acc: 0.506264. Batch_loss: 1.375010 \n",
      "Batch: 659. Acc: 0.506450. Loss: 1.368738. Batch_acc: 0.486143. Batch_loss: 1.399346 \n",
      "Batch: 660. Acc: 0.506473. Loss: 1.368680. Batch_acc: 0.521441. Batch_loss: 1.330871 \n",
      "Batch: 661. Acc: 0.506468. Loss: 1.368720. Batch_acc: 0.503429. Batch_loss: 1.395028 \n",
      "Batch: 662. Acc: 0.506449. Loss: 1.368743. Batch_acc: 0.493664. Batch_loss: 1.383762 \n",
      "Batch: 663. Acc: 0.506460. Loss: 1.368674. Batch_acc: 0.513970. Batch_loss: 1.322574 \n",
      "Batch: 664. Acc: 0.506459. Loss: 1.368696. Batch_acc: 0.505476. Batch_loss: 1.383388 \n",
      "Batch: 665. Acc: 0.506443. Loss: 1.368692. Batch_acc: 0.495991. Batch_loss: 1.365547 \n",
      "Batch: 666. Acc: 0.506473. Loss: 1.368606. Batch_acc: 0.526107. Batch_loss: 1.312292 \n",
      "Batch: 667. Acc: 0.506460. Loss: 1.368637. Batch_acc: 0.497947. Batch_loss: 1.389930 \n",
      "Batch: 668. Acc: 0.506442. Loss: 1.368714. Batch_acc: 0.493885. Batch_loss: 1.420374 \n",
      "Batch: 669. Acc: 0.506426. Loss: 1.368712. Batch_acc: 0.496262. Batch_loss: 1.367540 \n",
      "Batch: 670. Acc: 0.506418. Loss: 1.368744. Batch_acc: 0.501135. Batch_loss: 1.390119 \n",
      "Batch: 671. Acc: 0.506443. Loss: 1.368717. Batch_acc: 0.522447. Batch_loss: 1.350860 \n",
      "Batch: 672. Acc: 0.506479. Loss: 1.368596. Batch_acc: 0.530943. Batch_loss: 1.286652 \n",
      "Batch: 673. Acc: 0.506499. Loss: 1.368584. Batch_acc: 0.520046. Batch_loss: 1.360401 \n",
      "Batch: 674. Acc: 0.506485. Loss: 1.368661. Batch_acc: 0.496778. Batch_loss: 1.421754 \n",
      "Batch: 675. Acc: 0.506482. Loss: 1.368671. Batch_acc: 0.504378. Batch_loss: 1.375777 \n",
      "Batch: 676. Acc: 0.506465. Loss: 1.368703. Batch_acc: 0.495162. Batch_loss: 1.389667 \n",
      "Batch: 677. Acc: 0.506486. Loss: 1.368656. Batch_acc: 0.520045. Batch_loss: 1.337766 \n",
      "Batch: 678. Acc: 0.506459. Loss: 1.368742. Batch_acc: 0.487934. Batch_loss: 1.428386 \n",
      "Batch: 679. Acc: 0.506518. Loss: 1.368667. Batch_acc: 0.544900. Batch_loss: 1.319394 \n",
      "Batch: 680. Acc: 0.506510. Loss: 1.368695. Batch_acc: 0.501148. Batch_loss: 1.387925 \n",
      "Batch: 681. Acc: 0.506546. Loss: 1.368632. Batch_acc: 0.530578. Batch_loss: 1.326530 \n",
      "Batch: 682. Acc: 0.506559. Loss: 1.368598. Batch_acc: 0.516224. Batch_loss: 1.344642 \n",
      "Batch: 683. Acc: 0.506551. Loss: 1.368615. Batch_acc: 0.500853. Batch_loss: 1.380137 \n",
      "Batch: 684. Acc: 0.506557. Loss: 1.368605. Batch_acc: 0.510812. Batch_loss: 1.361863 \n",
      "Batch: 685. Acc: 0.506577. Loss: 1.368594. Batch_acc: 0.520117. Batch_loss: 1.360624 \n",
      "Batch: 686. Acc: 0.506543. Loss: 1.368701. Batch_acc: 0.483081. Batch_loss: 1.442834 \n",
      "Batch: 687. Acc: 0.506553. Loss: 1.368656. Batch_acc: 0.513825. Batch_loss: 1.337721 \n",
      "Batch: 688. Acc: 0.506544. Loss: 1.368663. Batch_acc: 0.500000. Batch_loss: 1.373614 \n",
      "Batch: 689. Acc: 0.506551. Loss: 1.368662. Batch_acc: 0.511459. Batch_loss: 1.368491 \n",
      "Batch: 690. Acc: 0.506573. Loss: 1.368595. Batch_acc: 0.521562. Batch_loss: 1.321728 \n",
      "Batch: 691. Acc: 0.506585. Loss: 1.368555. Batch_acc: 0.514800. Batch_loss: 1.340480 \n",
      "Batch: 692. Acc: 0.506567. Loss: 1.368583. Batch_acc: 0.494486. Batch_loss: 1.388251 \n",
      "Batch: 693. Acc: 0.506581. Loss: 1.368535. Batch_acc: 0.516258. Batch_loss: 1.335238 \n",
      "Batch: 694. Acc: 0.506594. Loss: 1.368545. Batch_acc: 0.515423. Batch_loss: 1.375368 \n",
      "Batch: 695. Acc: 0.506588. Loss: 1.368577. Batch_acc: 0.501750. Batch_loss: 1.391169 \n",
      "Batch: 696. Acc: 0.506561. Loss: 1.368666. Batch_acc: 0.487959. Batch_loss: 1.430670 \n",
      "Batch: 697. Acc: 0.506565. Loss: 1.368699. Batch_acc: 0.509626. Batch_loss: 1.391190 \n",
      "Batch: 698. Acc: 0.506597. Loss: 1.368636. Batch_acc: 0.529481. Batch_loss: 1.323622 \n",
      "Batch: 699. Acc: 0.506626. Loss: 1.368597. Batch_acc: 0.526674. Batch_loss: 1.341683 \n",
      "Batch: 700. Acc: 0.506587. Loss: 1.368671. Batch_acc: 0.478816. Batch_loss: 1.420917 \n",
      "Batch: 701. Acc: 0.506627. Loss: 1.368567. Batch_acc: 0.534473. Batch_loss: 1.295964 \n",
      "Batch: 702. Acc: 0.506614. Loss: 1.368595. Batch_acc: 0.497126. Batch_loss: 1.388335 \n",
      "Batch: 703. Acc: 0.506586. Loss: 1.368627. Batch_acc: 0.487400. Batch_loss: 1.390892 \n",
      "Batch: 704. Acc: 0.506595. Loss: 1.368644. Batch_acc: 0.512746. Batch_loss: 1.380859 \n",
      "Batch: 705. Acc: 0.506562. Loss: 1.368692. Batch_acc: 0.482718. Batch_loss: 1.403685 \n",
      "Batch: 706. Acc: 0.506597. Loss: 1.368624. Batch_acc: 0.530984. Batch_loss: 1.321005 \n",
      "Batch: 707. Acc: 0.506603. Loss: 1.368624. Batch_acc: 0.511098. Batch_loss: 1.368672 \n",
      "Batch: 708. Acc: 0.506596. Loss: 1.368637. Batch_acc: 0.501454. Batch_loss: 1.378088 \n",
      "Batch: 709. Acc: 0.506609. Loss: 1.368623. Batch_acc: 0.515982. Batch_loss: 1.358434 \n",
      "Batch: 710. Acc: 0.506616. Loss: 1.368603. Batch_acc: 0.511390. Batch_loss: 1.354731 \n",
      "Batch: 711. Acc: 0.506648. Loss: 1.368547. Batch_acc: 0.529686. Batch_loss: 1.327912 \n",
      "Batch: 712. Acc: 0.506655. Loss: 1.368507. Batch_acc: 0.511641. Batch_loss: 1.340006 \n",
      "Batch: 713. Acc: 0.506678. Loss: 1.368461. Batch_acc: 0.522676. Batch_loss: 1.335715 \n",
      "Batch: 714. Acc: 0.506684. Loss: 1.368422. Batch_acc: 0.511188. Batch_loss: 1.341143 \n",
      "Batch: 715. Acc: 0.506660. Loss: 1.368458. Batch_acc: 0.489691. Batch_loss: 1.393812 \n",
      "Batch: 716. Acc: 0.506712. Loss: 1.368366. Batch_acc: 0.544289. Batch_loss: 1.301363 \n",
      "Batch: 717. Acc: 0.506708. Loss: 1.368369. Batch_acc: 0.504283. Batch_loss: 1.371064 \n",
      "Batch: 718. Acc: 0.506726. Loss: 1.368294. Batch_acc: 0.519208. Batch_loss: 1.313280 \n",
      "Batch: 719. Acc: 0.506725. Loss: 1.368292. Batch_acc: 0.506031. Batch_loss: 1.366964 \n",
      "Batch: 720. Acc: 0.506721. Loss: 1.368258. Batch_acc: 0.504249. Batch_loss: 1.344496 \n",
      "Batch: 721. Acc: 0.506691. Loss: 1.368323. Batch_acc: 0.484174. Batch_loss: 1.415742 \n",
      "Batch: 722. Acc: 0.506696. Loss: 1.368275. Batch_acc: 0.510983. Batch_loss: 1.333435 \n",
      "Batch: 723. Acc: 0.506654. Loss: 1.368366. Batch_acc: 0.474867. Batch_loss: 1.436386 \n",
      "Batch: 724. Acc: 0.506672. Loss: 1.368328. Batch_acc: 0.520187. Batch_loss: 1.340076 \n",
      "Batch: 725. Acc: 0.506697. Loss: 1.368320. Batch_acc: 0.525305. Batch_loss: 1.362871 \n",
      "Batch: 726. Acc: 0.506690. Loss: 1.368295. Batch_acc: 0.501167. Batch_loss: 1.349199 \n",
      "Batch: 727. Acc: 0.506639. Loss: 1.368386. Batch_acc: 0.468658. Batch_loss: 1.436040 \n",
      "Batch: 728. Acc: 0.506645. Loss: 1.368356. Batch_acc: 0.510983. Batch_loss: 1.346179 \n",
      "Batch: 729. Acc: 0.506611. Loss: 1.368420. Batch_acc: 0.481654. Batch_loss: 1.416091 \n",
      "Batch: 730. Acc: 0.506621. Loss: 1.368424. Batch_acc: 0.514569. Batch_loss: 1.371420 \n",
      "Batch: 731. Acc: 0.506618. Loss: 1.368415. Batch_acc: 0.503772. Batch_loss: 1.361730 \n",
      "Batch: 732. Acc: 0.506622. Loss: 1.368421. Batch_acc: 0.510180. Batch_loss: 1.372622 \n",
      "Batch: 733. Acc: 0.506679. Loss: 1.368301. Batch_acc: 0.547891. Batch_loss: 1.281315 \n",
      "Batch: 734. Acc: 0.506703. Loss: 1.368245. Batch_acc: 0.524355. Batch_loss: 1.326940 \n",
      "Batch: 735. Acc: 0.506707. Loss: 1.368234. Batch_acc: 0.509270. Batch_loss: 1.360546 \n",
      "Batch: 736. Acc: 0.506729. Loss: 1.368200. Batch_acc: 0.522872. Batch_loss: 1.342964 \n",
      "Batch: 737. Acc: 0.506725. Loss: 1.368239. Batch_acc: 0.504023. Batch_loss: 1.397037 \n",
      "Batch: 738. Acc: 0.506749. Loss: 1.368169. Batch_acc: 0.523996. Batch_loss: 1.318159 \n",
      "Batch: 739. Acc: 0.506767. Loss: 1.368123. Batch_acc: 0.520023. Batch_loss: 1.334282 \n",
      "Batch: 740. Acc: 0.506770. Loss: 1.368104. Batch_acc: 0.508975. Batch_loss: 1.353436 \n",
      "Batch: 741. Acc: 0.506794. Loss: 1.368092. Batch_acc: 0.524942. Batch_loss: 1.359336 \n",
      "Batch: 742. Acc: 0.506799. Loss: 1.368088. Batch_acc: 0.510251. Batch_loss: 1.365269 \n",
      "Batch: 743. Acc: 0.506821. Loss: 1.368026. Batch_acc: 0.523478. Batch_loss: 1.321707 \n",
      "Batch: 744. Acc: 0.506826. Loss: 1.368013. Batch_acc: 0.510429. Batch_loss: 1.357837 \n",
      "Batch: 745. Acc: 0.506848. Loss: 1.367954. Batch_acc: 0.522868. Batch_loss: 1.325140 \n",
      "Batch: 746. Acc: 0.506841. Loss: 1.367999. Batch_acc: 0.501738. Batch_loss: 1.401792 \n",
      "Batch: 747. Acc: 0.506857. Loss: 1.367938. Batch_acc: 0.517887. Batch_loss: 1.324412 \n",
      "Batch: 748. Acc: 0.506859. Loss: 1.367924. Batch_acc: 0.508802. Batch_loss: 1.357533 \n",
      "Batch: 749. Acc: 0.506877. Loss: 1.367891. Batch_acc: 0.519821. Batch_loss: 1.343840 \n",
      "Batch: 750. Acc: 0.506872. Loss: 1.367913. Batch_acc: 0.502890. Batch_loss: 1.384564 \n",
      "Batch: 751. Acc: 0.506915. Loss: 1.367799. Batch_acc: 0.539527. Batch_loss: 1.281953 \n",
      "Batch: 752. Acc: 0.506909. Loss: 1.367796. Batch_acc: 0.502315. Batch_loss: 1.365610 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 753. Acc: 0.506931. Loss: 1.367731. Batch_acc: 0.523243. Batch_loss: 1.319275 \n",
      "Checkpointing on batch: 753. Accuracy: 0.5069310164320717. Loss per char: 1.36773081920145. Time: 1627218540.7677608\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 26, 25, 23, 26, 22, 24, 25, 23, 21,\n",
      "         1, 12,  1, 14, 23, 25, 15, 24, 25, 24, 32,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.506956. Loss: 1.367670. Batch_acc: 0.525708. Batch_loss: 1.321521 \n",
      "Batch: 755. Acc: 0.506975. Loss: 1.367573. Batch_acc: 0.521095. Batch_loss: 1.294866 \n",
      "Batch: 756. Acc: 0.506984. Loss: 1.367525. Batch_acc: 0.513873. Batch_loss: 1.331491 \n",
      "Batch: 757. Acc: 0.506978. Loss: 1.367549. Batch_acc: 0.502573. Batch_loss: 1.385184 \n",
      "Batch: 758. Acc: 0.506962. Loss: 1.367551. Batch_acc: 0.494755. Batch_loss: 1.369576 \n",
      "Batch: 759. Acc: 0.506992. Loss: 1.367504. Batch_acc: 0.528819. Batch_loss: 1.332337 \n",
      "Batch: 760. Acc: 0.506985. Loss: 1.367528. Batch_acc: 0.501981. Batch_loss: 1.385642 \n",
      "Batch: 761. Acc: 0.506967. Loss: 1.367602. Batch_acc: 0.493678. Batch_loss: 1.424126 \n",
      "Batch: 762. Acc: 0.506994. Loss: 1.367546. Batch_acc: 0.527074. Batch_loss: 1.324993 \n",
      "Batch: 763. Acc: 0.507017. Loss: 1.367495. Batch_acc: 0.524971. Batch_loss: 1.328224 \n",
      "Batch: 764. Acc: 0.507051. Loss: 1.367425. Batch_acc: 0.532402. Batch_loss: 1.315264 \n",
      "Batch: 765. Acc: 0.507058. Loss: 1.367388. Batch_acc: 0.512500. Batch_loss: 1.338276 \n",
      "Batch: 766. Acc: 0.507049. Loss: 1.367423. Batch_acc: 0.500276. Batch_loss: 1.393183 \n",
      "Batch: 767. Acc: 0.507053. Loss: 1.367395. Batch_acc: 0.510124. Batch_loss: 1.345719 \n",
      "Batch: 768. Acc: 0.507057. Loss: 1.367405. Batch_acc: 0.510286. Batch_loss: 1.375182 \n",
      "Batch: 769. Acc: 0.507067. Loss: 1.367377. Batch_acc: 0.515029. Batch_loss: 1.345838 \n",
      "Batch: 770. Acc: 0.507048. Loss: 1.367407. Batch_acc: 0.491466. Batch_loss: 1.391163 \n",
      "Batch: 771. Acc: 0.507072. Loss: 1.367332. Batch_acc: 0.525721. Batch_loss: 1.310485 \n",
      "Batch: 772. Acc: 0.507080. Loss: 1.367323. Batch_acc: 0.512687. Batch_loss: 1.360639 \n",
      "Batch: 773. Acc: 0.507101. Loss: 1.367268. Batch_acc: 0.523424. Batch_loss: 1.324465 \n",
      "Batch: 774. Acc: 0.507141. Loss: 1.367169. Batch_acc: 0.538595. Batch_loss: 1.289781 \n",
      "Batch: 775. Acc: 0.507155. Loss: 1.367157. Batch_acc: 0.517775. Batch_loss: 1.358029 \n",
      "Batch: 776. Acc: 0.507161. Loss: 1.367124. Batch_acc: 0.512209. Batch_loss: 1.341636 \n",
      "Batch: 777. Acc: 0.507173. Loss: 1.367086. Batch_acc: 0.516609. Batch_loss: 1.337850 \n",
      "Batch: 778. Acc: 0.507193. Loss: 1.367067. Batch_acc: 0.522260. Batch_loss: 1.352112 \n",
      "Batch: 779. Acc: 0.507195. Loss: 1.367034. Batch_acc: 0.508721. Batch_loss: 1.340801 \n",
      "Batch: 780. Acc: 0.507207. Loss: 1.367020. Batch_acc: 0.516628. Batch_loss: 1.356067 \n",
      "Batch: 781. Acc: 0.507212. Loss: 1.367019. Batch_acc: 0.511344. Batch_loss: 1.366706 \n",
      "Batch: 782. Acc: 0.507205. Loss: 1.367040. Batch_acc: 0.501425. Batch_loss: 1.383335 \n",
      "Batch: 783. Acc: 0.507266. Loss: 1.366870. Batch_acc: 0.554556. Batch_loss: 1.236626 \n",
      "Batch: 784. Acc: 0.507279. Loss: 1.366854. Batch_acc: 0.517301. Batch_loss: 1.354490 \n",
      "Batch: 785. Acc: 0.507292. Loss: 1.366847. Batch_acc: 0.517579. Batch_loss: 1.361076 \n",
      "Batch: 786. Acc: 0.507259. Loss: 1.366915. Batch_acc: 0.481181. Batch_loss: 1.420730 \n",
      "Batch: 787. Acc: 0.507275. Loss: 1.366869. Batch_acc: 0.519653. Batch_loss: 1.330295 \n",
      "Batch: 788. Acc: 0.507282. Loss: 1.366849. Batch_acc: 0.512821. Batch_loss: 1.351457 \n",
      "Batch: 789. Acc: 0.507278. Loss: 1.366851. Batch_acc: 0.504264. Batch_loss: 1.368615 \n",
      "Batch: 790. Acc: 0.507305. Loss: 1.366819. Batch_acc: 0.528291. Batch_loss: 1.341288 \n",
      "Batch: 791. Acc: 0.507308. Loss: 1.366806. Batch_acc: 0.509942. Batch_loss: 1.356563 \n",
      "Batch: 792. Acc: 0.507305. Loss: 1.366793. Batch_acc: 0.505358. Batch_loss: 1.356258 \n",
      "Batch: 793. Acc: 0.507334. Loss: 1.366734. Batch_acc: 0.529817. Batch_loss: 1.320316 \n",
      "Batch: 794. Acc: 0.507347. Loss: 1.366777. Batch_acc: 0.517775. Batch_loss: 1.400463 \n",
      "Batch: 795. Acc: 0.507351. Loss: 1.366809. Batch_acc: 0.510514. Batch_loss: 1.392838 \n",
      "Batch: 796. Acc: 0.507359. Loss: 1.366797. Batch_acc: 0.513873. Batch_loss: 1.357676 \n",
      "Batch: 797. Acc: 0.507355. Loss: 1.366821. Batch_acc: 0.503858. Batch_loss: 1.385969 \n",
      "Batch: 798. Acc: 0.507331. Loss: 1.366859. Batch_acc: 0.487805. Batch_loss: 1.398097 \n",
      "Batch: 799. Acc: 0.507366. Loss: 1.366795. Batch_acc: 0.535123. Batch_loss: 1.315282 \n",
      "Batch: 800. Acc: 0.507386. Loss: 1.366769. Batch_acc: 0.523643. Batch_loss: 1.346028 \n",
      "Batch: 801. Acc: 0.507420. Loss: 1.366737. Batch_acc: 0.534395. Batch_loss: 1.341158 \n",
      "Batch: 802. Acc: 0.507447. Loss: 1.366689. Batch_acc: 0.529378. Batch_loss: 1.328825 \n",
      "Batch: 803. Acc: 0.507427. Loss: 1.366725. Batch_acc: 0.491365. Batch_loss: 1.394770 \n",
      "Batch: 804. Acc: 0.507459. Loss: 1.366676. Batch_acc: 0.534411. Batch_loss: 1.325321 \n",
      "Batch: 805. Acc: 0.507490. Loss: 1.366598. Batch_acc: 0.533294. Batch_loss: 1.301821 \n",
      "Batch: 806. Acc: 0.507488. Loss: 1.366624. Batch_acc: 0.505814. Batch_loss: 1.387556 \n",
      "Batch: 807. Acc: 0.507491. Loss: 1.366615. Batch_acc: 0.510181. Batch_loss: 1.359517 \n",
      "Batch: 808. Acc: 0.507473. Loss: 1.366647. Batch_acc: 0.492703. Batch_loss: 1.393020 \n",
      "Batch: 809. Acc: 0.507488. Loss: 1.366624. Batch_acc: 0.519045. Batch_loss: 1.348054 \n",
      "Batch: 810. Acc: 0.507521. Loss: 1.366528. Batch_acc: 0.533865. Batch_loss: 1.289899 \n",
      "Batch: 811. Acc: 0.507505. Loss: 1.366559. Batch_acc: 0.495061. Batch_loss: 1.391837 \n",
      "Batch: 812. Acc: 0.507511. Loss: 1.366517. Batch_acc: 0.512111. Batch_loss: 1.332841 \n",
      "Batch: 813. Acc: 0.507546. Loss: 1.366440. Batch_acc: 0.535196. Batch_loss: 1.305277 \n",
      "Batch: 814. Acc: 0.507546. Loss: 1.366475. Batch_acc: 0.507710. Batch_loss: 1.395085 \n",
      "Batch: 815. Acc: 0.507566. Loss: 1.366441. Batch_acc: 0.523921. Batch_loss: 1.338219 \n",
      "Batch: 816. Acc: 0.507561. Loss: 1.366503. Batch_acc: 0.503170. Batch_loss: 1.416692 \n",
      "Batch: 817. Acc: 0.507557. Loss: 1.366517. Batch_acc: 0.504832. Batch_loss: 1.377953 \n",
      "Batch: 818. Acc: 0.507566. Loss: 1.366510. Batch_acc: 0.514714. Batch_loss: 1.361287 \n",
      "Batch: 819. Acc: 0.507584. Loss: 1.366466. Batch_acc: 0.522727. Batch_loss: 1.329839 \n",
      "Batch: 820. Acc: 0.507625. Loss: 1.366378. Batch_acc: 0.540927. Batch_loss: 1.294128 \n",
      "Batch: 821. Acc: 0.507627. Loss: 1.366348. Batch_acc: 0.509080. Batch_loss: 1.341870 \n",
      "Batch: 822. Acc: 0.507646. Loss: 1.366316. Batch_acc: 0.523451. Batch_loss: 1.339872 \n",
      "Batch: 823. Acc: 0.507649. Loss: 1.366303. Batch_acc: 0.510539. Batch_loss: 1.354925 \n",
      "Batch: 824. Acc: 0.507668. Loss: 1.366257. Batch_acc: 0.522727. Batch_loss: 1.329283 \n",
      "Batch: 825. Acc: 0.507644. Loss: 1.366289. Batch_acc: 0.487679. Batch_loss: 1.392239 \n",
      "Batch: 826. Acc: 0.507661. Loss: 1.366253. Batch_acc: 0.522119. Batch_loss: 1.336073 \n",
      "Batch: 827. Acc: 0.507679. Loss: 1.366215. Batch_acc: 0.522872. Batch_loss: 1.334849 \n",
      "Batch: 828. Acc: 0.507684. Loss: 1.366169. Batch_acc: 0.511628. Batch_loss: 1.328804 \n",
      "Batch: 829. Acc: 0.507679. Loss: 1.366170. Batch_acc: 0.503959. Batch_loss: 1.366723 \n",
      "Batch: 830. Acc: 0.507666. Loss: 1.366192. Batch_acc: 0.496487. Batch_loss: 1.384504 \n",
      "Batch: 831. Acc: 0.507680. Loss: 1.366124. Batch_acc: 0.519671. Batch_loss: 1.308661 \n",
      "Batch: 832. Acc: 0.507695. Loss: 1.366114. Batch_acc: 0.520164. Batch_loss: 1.357715 \n",
      "Batch: 833. Acc: 0.507703. Loss: 1.366095. Batch_acc: 0.514318. Batch_loss: 1.350478 \n",
      "Batch: 834. Acc: 0.507697. Loss: 1.366114. Batch_acc: 0.502552. Batch_loss: 1.381625 \n",
      "Batch: 835. Acc: 0.507695. Loss: 1.366117. Batch_acc: 0.506073. Batch_loss: 1.368516 \n",
      "Batch: 836. Acc: 0.507702. Loss: 1.366109. Batch_acc: 0.513857. Batch_loss: 1.359349 \n",
      "Batch: 837. Acc: 0.507702. Loss: 1.366092. Batch_acc: 0.507874. Batch_loss: 1.352109 \n",
      "Batch: 838. Acc: 0.507694. Loss: 1.366096. Batch_acc: 0.500561. Batch_loss: 1.369482 \n",
      "Batch: 839. Acc: 0.507719. Loss: 1.366020. Batch_acc: 0.528935. Batch_loss: 1.302337 \n",
      "Batch: 840. Acc: 0.507731. Loss: 1.365990. Batch_acc: 0.517784. Batch_loss: 1.340373 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 841. Acc: 0.507724. Loss: 1.365992. Batch_acc: 0.501754. Batch_loss: 1.367396 \n",
      "Batch: 842. Acc: 0.507759. Loss: 1.365957. Batch_acc: 0.536848. Batch_loss: 1.336721 \n",
      "Batch: 843. Acc: 0.507753. Loss: 1.365963. Batch_acc: 0.503152. Batch_loss: 1.371271 \n",
      "Batch: 844. Acc: 0.507782. Loss: 1.365900. Batch_acc: 0.532902. Batch_loss: 1.311409 \n",
      "Batch: 845. Acc: 0.507802. Loss: 1.365832. Batch_acc: 0.524581. Batch_loss: 1.307992 \n",
      "Batch: 846. Acc: 0.507788. Loss: 1.365880. Batch_acc: 0.496262. Batch_loss: 1.406906 \n",
      "Batch: 847. Acc: 0.507779. Loss: 1.365902. Batch_acc: 0.499704. Batch_loss: 1.384429 \n",
      "Batch: 848. Acc: 0.507788. Loss: 1.365878. Batch_acc: 0.515291. Batch_loss: 1.345941 \n",
      "Batch: 849. Acc: 0.507783. Loss: 1.365862. Batch_acc: 0.503772. Batch_loss: 1.351938 \n",
      "Batch: 850. Acc: 0.507791. Loss: 1.365867. Batch_acc: 0.514477. Batch_loss: 1.370130 \n",
      "Batch: 851. Acc: 0.507765. Loss: 1.365918. Batch_acc: 0.484524. Batch_loss: 1.411103 \n",
      "Batch: 852. Acc: 0.507738. Loss: 1.365990. Batch_acc: 0.484638. Batch_loss: 1.427537 \n",
      "Batch: 853. Acc: 0.507732. Loss: 1.365993. Batch_acc: 0.502283. Batch_loss: 1.368208 \n",
      "Batch: 854. Acc: 0.507726. Loss: 1.366006. Batch_acc: 0.502652. Batch_loss: 1.377801 \n",
      "Batch: 855. Acc: 0.507737. Loss: 1.365979. Batch_acc: 0.516582. Batch_loss: 1.343154 \n",
      "Batch: 856. Acc: 0.507748. Loss: 1.365978. Batch_acc: 0.517222. Batch_loss: 1.365516 \n",
      "Batch: 857. Acc: 0.507742. Loss: 1.366004. Batch_acc: 0.502914. Batch_loss: 1.387885 \n",
      "Batch: 858. Acc: 0.507792. Loss: 1.365851. Batch_acc: 0.549832. Batch_loss: 1.238394 \n",
      "Batch: 859. Acc: 0.507797. Loss: 1.365790. Batch_acc: 0.511802. Batch_loss: 1.313707 \n",
      "Batch: 860. Acc: 0.507787. Loss: 1.365814. Batch_acc: 0.498845. Batch_loss: 1.386474 \n",
      "Batch: 861. Acc: 0.507810. Loss: 1.365726. Batch_acc: 0.527119. Batch_loss: 1.290827 \n",
      "Batch: 862. Acc: 0.507795. Loss: 1.365791. Batch_acc: 0.494731. Batch_loss: 1.423101 \n",
      "Batch: 863. Acc: 0.507776. Loss: 1.365844. Batch_acc: 0.491399. Batch_loss: 1.411826 \n",
      "Batch: 864. Acc: 0.507765. Loss: 1.365864. Batch_acc: 0.498571. Batch_loss: 1.382228 \n",
      "Batch: 865. Acc: 0.507753. Loss: 1.365857. Batch_acc: 0.497427. Batch_loss: 1.360148 \n",
      "Batch: 866. Acc: 0.507733. Loss: 1.365908. Batch_acc: 0.490230. Batch_loss: 1.410491 \n",
      "Batch: 867. Acc: 0.507734. Loss: 1.365887. Batch_acc: 0.509357. Batch_loss: 1.347137 \n",
      "Batch: 868. Acc: 0.507754. Loss: 1.365812. Batch_acc: 0.524741. Batch_loss: 1.300456 \n",
      "Batch: 869. Acc: 0.507773. Loss: 1.365770. Batch_acc: 0.524552. Batch_loss: 1.328835 \n",
      "Batch: 870. Acc: 0.507790. Loss: 1.365750. Batch_acc: 0.521984. Batch_loss: 1.349528 \n",
      "Batch: 871. Acc: 0.507803. Loss: 1.365734. Batch_acc: 0.518750. Batch_loss: 1.351444 \n",
      "Batch: 872. Acc: 0.507808. Loss: 1.365733. Batch_acc: 0.512640. Batch_loss: 1.365327 \n",
      "Batch: 873. Acc: 0.507801. Loss: 1.365735. Batch_acc: 0.501171. Batch_loss: 1.366782 \n",
      "Batch: 874. Acc: 0.507797. Loss: 1.365734. Batch_acc: 0.504877. Batch_loss: 1.364862 \n",
      "Batch: 875. Acc: 0.507792. Loss: 1.365780. Batch_acc: 0.502924. Batch_loss: 1.407091 \n",
      "Batch: 876. Acc: 0.507786. Loss: 1.365812. Batch_acc: 0.503102. Batch_loss: 1.393487 \n",
      "Batch: 877. Acc: 0.507787. Loss: 1.365818. Batch_acc: 0.508523. Batch_loss: 1.370352 \n",
      "Batch: 878. Acc: 0.507775. Loss: 1.365860. Batch_acc: 0.497397. Batch_loss: 1.403303 \n",
      "Batch: 879. Acc: 0.507744. Loss: 1.365880. Batch_acc: 0.480682. Batch_loss: 1.383307 \n",
      "Batch: 880. Acc: 0.507741. Loss: 1.365889. Batch_acc: 0.504420. Batch_loss: 1.374287 \n",
      "Batch: 881. Acc: 0.507718. Loss: 1.365950. Batch_acc: 0.487959. Batch_loss: 1.419103 \n",
      "Batch: 882. Acc: 0.507739. Loss: 1.365889. Batch_acc: 0.525952. Batch_loss: 1.311970 \n",
      "Batch: 883. Acc: 0.507765. Loss: 1.365837. Batch_acc: 0.530765. Batch_loss: 1.320058 \n",
      "Batch: 884. Acc: 0.507794. Loss: 1.365762. Batch_acc: 0.533952. Batch_loss: 1.298551 \n",
      "Batch: 885. Acc: 0.507818. Loss: 1.365707. Batch_acc: 0.528677. Batch_loss: 1.318376 \n",
      "Batch: 886. Acc: 0.507812. Loss: 1.365700. Batch_acc: 0.502851. Batch_loss: 1.359323 \n",
      "Batch: 887. Acc: 0.507811. Loss: 1.365698. Batch_acc: 0.506636. Batch_loss: 1.363835 \n",
      "Batch: 888. Acc: 0.507827. Loss: 1.365648. Batch_acc: 0.522093. Batch_loss: 1.320533 \n",
      "Batch: 889. Acc: 0.507827. Loss: 1.365624. Batch_acc: 0.507497. Batch_loss: 1.344016 \n",
      "Batch: 890. Acc: 0.507844. Loss: 1.365581. Batch_acc: 0.523041. Batch_loss: 1.327475 \n",
      "Batch: 891. Acc: 0.507866. Loss: 1.365521. Batch_acc: 0.527232. Batch_loss: 1.313711 \n",
      "Batch: 892. Acc: 0.507883. Loss: 1.365512. Batch_acc: 0.522664. Batch_loss: 1.357382 \n",
      "Batch: 893. Acc: 0.507904. Loss: 1.365432. Batch_acc: 0.526228. Batch_loss: 1.296550 \n",
      "Batch: 894. Acc: 0.507914. Loss: 1.365392. Batch_acc: 0.516129. Batch_loss: 1.330277 \n",
      "Batch: 895. Acc: 0.507912. Loss: 1.365377. Batch_acc: 0.506322. Batch_loss: 1.352636 \n",
      "Batch: 896. Acc: 0.507921. Loss: 1.365317. Batch_acc: 0.516148. Batch_loss: 1.311284 \n",
      "Batch: 897. Acc: 0.507926. Loss: 1.365335. Batch_acc: 0.512209. Batch_loss: 1.381386 \n",
      "Batch: 898. Acc: 0.507933. Loss: 1.365284. Batch_acc: 0.514697. Batch_loss: 1.319634 \n",
      "Batch: 899. Acc: 0.507932. Loss: 1.365258. Batch_acc: 0.506628. Batch_loss: 1.341237 \n",
      "Batch: 900. Acc: 0.507925. Loss: 1.365282. Batch_acc: 0.501458. Batch_loss: 1.387413 \n",
      "Batch: 901. Acc: 0.507907. Loss: 1.365349. Batch_acc: 0.491637. Batch_loss: 1.428374 \n",
      "Batch: 902. Acc: 0.507923. Loss: 1.365319. Batch_acc: 0.522016. Batch_loss: 1.338232 \n",
      "Batch: 903. Acc: 0.507943. Loss: 1.365254. Batch_acc: 0.526437. Batch_loss: 1.305949 \n",
      "Batch: 904. Acc: 0.507932. Loss: 1.365273. Batch_acc: 0.497942. Batch_loss: 1.382877 \n",
      "Batch: 905. Acc: 0.507916. Loss: 1.365309. Batch_acc: 0.492999. Batch_loss: 1.398429 \n",
      "Batch: 906. Acc: 0.507931. Loss: 1.365297. Batch_acc: 0.520880. Batch_loss: 1.354601 \n",
      "Batch: 907. Acc: 0.507957. Loss: 1.365229. Batch_acc: 0.532705. Batch_loss: 1.302557 \n",
      "Batch: 908. Acc: 0.507986. Loss: 1.365203. Batch_acc: 0.534071. Batch_loss: 1.340857 \n",
      "Batch: 909. Acc: 0.507998. Loss: 1.365130. Batch_acc: 0.519343. Batch_loss: 1.297382 \n",
      "Batch: 910. Acc: 0.508025. Loss: 1.365050. Batch_acc: 0.532609. Batch_loss: 1.293437 \n",
      "Batch: 911. Acc: 0.508025. Loss: 1.365007. Batch_acc: 0.507446. Batch_loss: 1.325629 \n",
      "Batch: 912. Acc: 0.508055. Loss: 1.364910. Batch_acc: 0.536028. Batch_loss: 1.275125 \n",
      "Batch: 913. Acc: 0.508065. Loss: 1.364891. Batch_acc: 0.516911. Batch_loss: 1.347570 \n",
      "Batch: 914. Acc: 0.508066. Loss: 1.364867. Batch_acc: 0.509249. Batch_loss: 1.342390 \n",
      "Batch: 915. Acc: 0.508072. Loss: 1.364883. Batch_acc: 0.513326. Batch_loss: 1.379737 \n",
      "Batch: 916. Acc: 0.508051. Loss: 1.364941. Batch_acc: 0.488837. Batch_loss: 1.419158 \n",
      "Batch: 917. Acc: 0.508062. Loss: 1.364884. Batch_acc: 0.518310. Batch_loss: 1.313928 \n",
      "Batch: 918. Acc: 0.508084. Loss: 1.364823. Batch_acc: 0.527510. Batch_loss: 1.309727 \n",
      "Batch: 919. Acc: 0.508114. Loss: 1.364780. Batch_acc: 0.534473. Batch_loss: 1.326695 \n",
      "Batch: 920. Acc: 0.508126. Loss: 1.364777. Batch_acc: 0.519132. Batch_loss: 1.362116 \n",
      "Batch: 921. Acc: 0.508120. Loss: 1.364804. Batch_acc: 0.502904. Batch_loss: 1.390053 \n",
      "Batch: 922. Acc: 0.508135. Loss: 1.364786. Batch_acc: 0.521589. Batch_loss: 1.347778 \n",
      "Batch: 923. Acc: 0.508108. Loss: 1.364847. Batch_acc: 0.482779. Batch_loss: 1.422457 \n",
      "Batch: 924. Acc: 0.508096. Loss: 1.364880. Batch_acc: 0.496433. Batch_loss: 1.396623 \n",
      "Batch: 925. Acc: 0.508088. Loss: 1.364910. Batch_acc: 0.500869. Batch_loss: 1.392149 \n",
      "Batch: 926. Acc: 0.508083. Loss: 1.364930. Batch_acc: 0.503484. Batch_loss: 1.383648 \n",
      "Batch: 927. Acc: 0.508067. Loss: 1.364968. Batch_acc: 0.493685. Batch_loss: 1.400036 \n",
      "Batch: 928. Acc: 0.508079. Loss: 1.364951. Batch_acc: 0.518498. Batch_loss: 1.350272 \n",
      "Batch: 929. Acc: 0.508068. Loss: 1.365003. Batch_acc: 0.498030. Batch_loss: 1.411897 \n",
      "Batch: 930. Acc: 0.508082. Loss: 1.364987. Batch_acc: 0.521639. Batch_loss: 1.350242 \n",
      "Batch: 931. Acc: 0.508069. Loss: 1.365018. Batch_acc: 0.495925. Batch_loss: 1.393682 \n",
      "Batch: 932. Acc: 0.508080. Loss: 1.365002. Batch_acc: 0.517539. Batch_loss: 1.350326 \n",
      "Batch: 933. Acc: 0.508098. Loss: 1.364970. Batch_acc: 0.525014. Batch_loss: 1.335740 \n",
      "Batch: 934. Acc: 0.508103. Loss: 1.364979. Batch_acc: 0.512983. Batch_loss: 1.372808 \n",
      "Batch: 935. Acc: 0.508131. Loss: 1.364903. Batch_acc: 0.533630. Batch_loss: 1.296205 \n",
      "Batch: 936. Acc: 0.508119. Loss: 1.364924. Batch_acc: 0.495752. Batch_loss: 1.385826 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 937. Acc: 0.508102. Loss: 1.364922. Batch_acc: 0.492554. Batch_loss: 1.363428 \n",
      "Batch: 938. Acc: 0.508085. Loss: 1.364984. Batch_acc: 0.492563. Batch_loss: 1.422845 \n",
      "Batch: 939. Acc: 0.508104. Loss: 1.364967. Batch_acc: 0.525434. Batch_loss: 1.348485 \n",
      "Batch: 940. Acc: 0.508098. Loss: 1.364977. Batch_acc: 0.502558. Batch_loss: 1.374242 \n",
      "Batch: 941. Acc: 0.508114. Loss: 1.364951. Batch_acc: 0.523310. Batch_loss: 1.340741 \n",
      "Batch: 942. Acc: 0.508102. Loss: 1.364965. Batch_acc: 0.497031. Batch_loss: 1.378093 \n",
      "Batch: 943. Acc: 0.508115. Loss: 1.364949. Batch_acc: 0.519613. Batch_loss: 1.350068 \n",
      "Batch: 944. Acc: 0.508108. Loss: 1.364936. Batch_acc: 0.501720. Batch_loss: 1.352908 \n",
      "Batch: 945. Acc: 0.508106. Loss: 1.364928. Batch_acc: 0.506486. Batch_loss: 1.356558 \n",
      "Batch: 946. Acc: 0.508106. Loss: 1.364899. Batch_acc: 0.507946. Batch_loss: 1.338607 \n",
      "Batch: 947. Acc: 0.508123. Loss: 1.364862. Batch_acc: 0.524513. Batch_loss: 1.328119 \n",
      "Batch: 948. Acc: 0.508135. Loss: 1.364826. Batch_acc: 0.518980. Batch_loss: 1.331987 \n",
      "Batch: 949. Acc: 0.508104. Loss: 1.364908. Batch_acc: 0.478890. Batch_loss: 1.442834 \n",
      "Batch: 950. Acc: 0.508097. Loss: 1.364914. Batch_acc: 0.501992. Batch_loss: 1.370277 \n",
      "Batch: 951. Acc: 0.508109. Loss: 1.364883. Batch_acc: 0.518895. Batch_loss: 1.336350 \n",
      "Batch: 952. Acc: 0.508143. Loss: 1.364829. Batch_acc: 0.540650. Batch_loss: 1.312729 \n",
      "Batch: 953. Acc: 0.508149. Loss: 1.364774. Batch_acc: 0.514353. Batch_loss: 1.311602 \n",
      "Batch: 954. Acc: 0.508137. Loss: 1.364789. Batch_acc: 0.496223. Batch_loss: 1.379220 \n",
      "Batch: 955. Acc: 0.508154. Loss: 1.364753. Batch_acc: 0.523468. Batch_loss: 1.332073 \n",
      "Batch: 956. Acc: 0.508131. Loss: 1.364828. Batch_acc: 0.485816. Batch_loss: 1.438315 \n",
      "Batch: 957. Acc: 0.508169. Loss: 1.364731. Batch_acc: 0.544076. Batch_loss: 1.273513 \n",
      "Batch: 958. Acc: 0.508195. Loss: 1.364660. Batch_acc: 0.532951. Batch_loss: 1.297178 \n",
      "Batch: 959. Acc: 0.508180. Loss: 1.364729. Batch_acc: 0.493183. Batch_loss: 1.433407 \n",
      "Batch: 960. Acc: 0.508206. Loss: 1.364680. Batch_acc: 0.533489. Batch_loss: 1.316540 \n",
      "Batch: 961. Acc: 0.508195. Loss: 1.364671. Batch_acc: 0.497997. Batch_loss: 1.355844 \n",
      "Batch: 962. Acc: 0.508237. Loss: 1.364598. Batch_acc: 0.547524. Batch_loss: 1.295617 \n",
      "Batch: 963. Acc: 0.508238. Loss: 1.364588. Batch_acc: 0.509223. Batch_loss: 1.355298 \n",
      "Batch: 964. Acc: 0.508224. Loss: 1.364595. Batch_acc: 0.495072. Batch_loss: 1.371060 \n",
      "Batch: 965. Acc: 0.508217. Loss: 1.364624. Batch_acc: 0.501404. Batch_loss: 1.391862 \n",
      "Batch: 966. Acc: 0.508218. Loss: 1.364595. Batch_acc: 0.509456. Batch_loss: 1.336614 \n",
      "Batch: 967. Acc: 0.508226. Loss: 1.364574. Batch_acc: 0.516260. Batch_loss: 1.344665 \n",
      "Batch: 968. Acc: 0.508227. Loss: 1.364585. Batch_acc: 0.508721. Batch_loss: 1.374727 \n",
      "Batch: 969. Acc: 0.508223. Loss: 1.364584. Batch_acc: 0.504520. Batch_loss: 1.363798 \n",
      "Batch: 970. Acc: 0.508234. Loss: 1.364544. Batch_acc: 0.518331. Batch_loss: 1.326712 \n",
      "Batch: 971. Acc: 0.508239. Loss: 1.364539. Batch_acc: 0.513529. Batch_loss: 1.359513 \n",
      "Batch: 972. Acc: 0.508217. Loss: 1.364590. Batch_acc: 0.486902. Batch_loss: 1.413214 \n",
      "Batch: 973. Acc: 0.508214. Loss: 1.364589. Batch_acc: 0.505855. Batch_loss: 1.364120 \n",
      "Batch: 974. Acc: 0.508227. Loss: 1.364560. Batch_acc: 0.520092. Batch_loss: 1.336747 \n",
      "Batch: 975. Acc: 0.508238. Loss: 1.364511. Batch_acc: 0.519653. Batch_loss: 1.315990 \n",
      "Batch: 976. Acc: 0.508242. Loss: 1.364476. Batch_acc: 0.511945. Batch_loss: 1.330716 \n",
      "Batch: 977. Acc: 0.508242. Loss: 1.364491. Batch_acc: 0.507863. Batch_loss: 1.379612 \n",
      "Batch: 978. Acc: 0.508273. Loss: 1.364393. Batch_acc: 0.538462. Batch_loss: 1.269997 \n",
      "Batch: 979. Acc: 0.508282. Loss: 1.364350. Batch_acc: 0.516809. Batch_loss: 1.322463 \n",
      "Batch: 980. Acc: 0.508277. Loss: 1.364380. Batch_acc: 0.503188. Batch_loss: 1.393651 \n",
      "Batch: 981. Acc: 0.508262. Loss: 1.364429. Batch_acc: 0.493856. Batch_loss: 1.413924 \n",
      "Batch: 982. Acc: 0.508280. Loss: 1.364374. Batch_acc: 0.526316. Batch_loss: 1.308969 \n",
      "Batch: 983. Acc: 0.508283. Loss: 1.364387. Batch_acc: 0.511111. Batch_loss: 1.377803 \n",
      "Batch: 984. Acc: 0.508252. Loss: 1.364462. Batch_acc: 0.476950. Batch_loss: 1.440667 \n",
      "Batch: 985. Acc: 0.508232. Loss: 1.364482. Batch_acc: 0.488617. Batch_loss: 1.382811 \n",
      "Batch: 986. Acc: 0.508279. Loss: 1.364364. Batch_acc: 0.555102. Batch_loss: 1.246981 \n",
      "Batch: 987. Acc: 0.508279. Loss: 1.364325. Batch_acc: 0.509027. Batch_loss: 1.324761 \n",
      "Batch: 988. Acc: 0.508292. Loss: 1.364287. Batch_acc: 0.521412. Batch_loss: 1.326626 \n",
      "Batch: 989. Acc: 0.508287. Loss: 1.364289. Batch_acc: 0.503230. Batch_loss: 1.366093 \n",
      "Batch: 990. Acc: 0.508298. Loss: 1.364281. Batch_acc: 0.518540. Batch_loss: 1.356454 \n",
      "Batch: 991. Acc: 0.508318. Loss: 1.364211. Batch_acc: 0.528769. Batch_loss: 1.294604 \n",
      "Batch: 992. Acc: 0.508316. Loss: 1.364230. Batch_acc: 0.505856. Batch_loss: 1.383371 \n",
      "Batch: 993. Acc: 0.508344. Loss: 1.364178. Batch_acc: 0.535556. Batch_loss: 1.314169 \n",
      "Batch: 994. Acc: 0.508361. Loss: 1.364148. Batch_acc: 0.525434. Batch_loss: 1.333935 \n",
      "Batch: 995. Acc: 0.508382. Loss: 1.364111. Batch_acc: 0.528716. Batch_loss: 1.328310 \n",
      "Batch: 996. Acc: 0.508394. Loss: 1.364073. Batch_acc: 0.520330. Batch_loss: 1.324933 \n",
      "Batch: 997. Acc: 0.508401. Loss: 1.364064. Batch_acc: 0.515289. Batch_loss: 1.355095 \n",
      "Batch: 998. Acc: 0.508412. Loss: 1.364075. Batch_acc: 0.519264. Batch_loss: 1.375461 \n",
      "Batch: 999. Acc: 0.508412. Loss: 1.364050. Batch_acc: 0.508844. Batch_loss: 1.337851 \n",
      "Batch: 1000. Acc: 0.508429. Loss: 1.363987. Batch_acc: 0.524957. Batch_loss: 1.301537 \n",
      "Batch: 1001. Acc: 0.508450. Loss: 1.363954. Batch_acc: 0.529714. Batch_loss: 1.331021 \n",
      "Batch: 1002. Acc: 0.508466. Loss: 1.363916. Batch_acc: 0.523702. Batch_loss: 1.326881 \n",
      "Batch: 1003. Acc: 0.508485. Loss: 1.363842. Batch_acc: 0.527590. Batch_loss: 1.291141 \n",
      "Batch: 1004. Acc: 0.508499. Loss: 1.363831. Batch_acc: 0.522860. Batch_loss: 1.352374 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.5084990384874111. Loss per char: 1.3638308813437665. Time: 1627218744.1332915\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 17, 15, 21,  1, 85, 66, 76, 70,\n",
      "         1, 66, 88, 66, 90,  1, 14, 18, 17, 21, 25, 24, 25, 25, 23, 17, 26, 18,\n",
      "        21, 23, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.508517. Loss: 1.363759. Batch_acc: 0.526765. Batch_loss: 1.292178 \n",
      "Batch: 1006. Acc: 0.508525. Loss: 1.363754. Batch_acc: 0.515949. Batch_loss: 1.359346 \n",
      "Batch: 1007. Acc: 0.508508. Loss: 1.363798. Batch_acc: 0.491435. Batch_loss: 1.409063 \n",
      "Batch: 1008. Acc: 0.508528. Loss: 1.363754. Batch_acc: 0.528422. Batch_loss: 1.318869 \n",
      "Batch: 1009. Acc: 0.508550. Loss: 1.363696. Batch_acc: 0.531106. Batch_loss: 1.305221 \n",
      "Batch: 1010. Acc: 0.508534. Loss: 1.363729. Batch_acc: 0.492237. Batch_loss: 1.396831 \n",
      "Batch: 1011. Acc: 0.508551. Loss: 1.363666. Batch_acc: 0.525316. Batch_loss: 1.300334 \n",
      "Batch: 1012. Acc: 0.508536. Loss: 1.363682. Batch_acc: 0.493899. Batch_loss: 1.379599 \n",
      "Batch: 1013. Acc: 0.508558. Loss: 1.363624. Batch_acc: 0.530217. Batch_loss: 1.305237 \n",
      "Batch: 1014. Acc: 0.508543. Loss: 1.363684. Batch_acc: 0.492599. Batch_loss: 1.426726 \n",
      "Batch: 1015. Acc: 0.508529. Loss: 1.363704. Batch_acc: 0.494875. Batch_loss: 1.383247 \n",
      "Batch: 1016. Acc: 0.508522. Loss: 1.363718. Batch_acc: 0.500892. Batch_loss: 1.378667 \n",
      "Batch: 1017. Acc: 0.508535. Loss: 1.363688. Batch_acc: 0.521739. Batch_loss: 1.333646 \n",
      "Batch: 1018. Acc: 0.508583. Loss: 1.363564. Batch_acc: 0.556948. Batch_loss: 1.239000 \n",
      "Batch: 1019. Acc: 0.508572. Loss: 1.363576. Batch_acc: 0.497717. Batch_loss: 1.375683 \n",
      "Batch: 1020. Acc: 0.508593. Loss: 1.363529. Batch_acc: 0.529345. Batch_loss: 1.316489 \n",
      "Batch: 1021. Acc: 0.508584. Loss: 1.363558. Batch_acc: 0.498841. Batch_loss: 1.393180 \n",
      "Batch: 1022. Acc: 0.508606. Loss: 1.363501. Batch_acc: 0.531782. Batch_loss: 1.305647 \n",
      "Batch: 1023. Acc: 0.508612. Loss: 1.363499. Batch_acc: 0.514471. Batch_loss: 1.361817 \n",
      "Batch: 1024. Acc: 0.508631. Loss: 1.363477. Batch_acc: 0.528161. Batch_loss: 1.340838 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1025. Acc: 0.508631. Loss: 1.363471. Batch_acc: 0.507955. Batch_loss: 1.357365 \n",
      "Batch: 1026. Acc: 0.508642. Loss: 1.363423. Batch_acc: 0.520595. Batch_loss: 1.314501 \n",
      "Batch: 1027. Acc: 0.508622. Loss: 1.363458. Batch_acc: 0.488047. Batch_loss: 1.399363 \n",
      "Batch: 1028. Acc: 0.508620. Loss: 1.363469. Batch_acc: 0.506293. Batch_loss: 1.375145 \n",
      "Batch: 1029. Acc: 0.508615. Loss: 1.363476. Batch_acc: 0.503436. Batch_loss: 1.370557 \n",
      "Batch: 1030. Acc: 0.508589. Loss: 1.363518. Batch_acc: 0.481181. Batch_loss: 1.407571 \n",
      "Batch: 1031. Acc: 0.508605. Loss: 1.363470. Batch_acc: 0.525619. Batch_loss: 1.313844 \n",
      "Batch: 1032. Acc: 0.508604. Loss: 1.363459. Batch_acc: 0.507429. Batch_loss: 1.351569 \n",
      "Batch: 1033. Acc: 0.508602. Loss: 1.363429. Batch_acc: 0.506101. Batch_loss: 1.332705 \n",
      "Batch: 1034. Acc: 0.508623. Loss: 1.363372. Batch_acc: 0.530787. Batch_loss: 1.304676 \n",
      "Batch: 1035. Acc: 0.508620. Loss: 1.363360. Batch_acc: 0.505578. Batch_loss: 1.350525 \n",
      "Batch: 1036. Acc: 0.508618. Loss: 1.363348. Batch_acc: 0.505747. Batch_loss: 1.351341 \n",
      "Batch: 1037. Acc: 0.508579. Loss: 1.363435. Batch_acc: 0.467257. Batch_loss: 1.455638 \n",
      "Batch: 1038. Acc: 0.508602. Loss: 1.363365. Batch_acc: 0.531795. Batch_loss: 1.292502 \n",
      "Batch: 1039. Acc: 0.508606. Loss: 1.363330. Batch_acc: 0.513719. Batch_loss: 1.326347 \n",
      "Batch: 1040. Acc: 0.508624. Loss: 1.363287. Batch_acc: 0.526524. Batch_loss: 1.319728 \n",
      "Batch: 1041. Acc: 0.508642. Loss: 1.363280. Batch_acc: 0.527027. Batch_loss: 1.356104 \n",
      "Batch: 1042. Acc: 0.508660. Loss: 1.363228. Batch_acc: 0.526524. Batch_loss: 1.309996 \n",
      "Batch: 1043. Acc: 0.508650. Loss: 1.363208. Batch_acc: 0.498833. Batch_loss: 1.341866 \n",
      "Batch: 1044. Acc: 0.508686. Loss: 1.363113. Batch_acc: 0.544789. Batch_loss: 1.266376 \n",
      "Batch: 1045. Acc: 0.508680. Loss: 1.363134. Batch_acc: 0.503192. Batch_loss: 1.384416 \n",
      "Batch: 1046. Acc: 0.508679. Loss: 1.363158. Batch_acc: 0.507345. Batch_loss: 1.388517 \n",
      "Batch: 1047. Acc: 0.508698. Loss: 1.363106. Batch_acc: 0.529273. Batch_loss: 1.306670 \n",
      "Batch: 1048. Acc: 0.508694. Loss: 1.363106. Batch_acc: 0.504662. Batch_loss: 1.363615 \n",
      "Batch: 1049. Acc: 0.508704. Loss: 1.363068. Batch_acc: 0.518539. Batch_loss: 1.323416 \n",
      "Batch: 1050. Acc: 0.508697. Loss: 1.363081. Batch_acc: 0.501171. Batch_loss: 1.377198 \n",
      "Batch: 1051. Acc: 0.508683. Loss: 1.363102. Batch_acc: 0.493878. Batch_loss: 1.386062 \n",
      "Batch: 1052. Acc: 0.508678. Loss: 1.363098. Batch_acc: 0.503177. Batch_loss: 1.358511 \n",
      "Batch: 1053. Acc: 0.508695. Loss: 1.363054. Batch_acc: 0.526796. Batch_loss: 1.316912 \n",
      "Batch: 1054. Acc: 0.508710. Loss: 1.363021. Batch_acc: 0.524956. Batch_loss: 1.327315 \n",
      "Batch: 1055. Acc: 0.508723. Loss: 1.363002. Batch_acc: 0.521421. Batch_loss: 1.343817 \n",
      "Batch: 1056. Acc: 0.508700. Loss: 1.363064. Batch_acc: 0.485393. Batch_loss: 1.427352 \n",
      "Batch: 1057. Acc: 0.508709. Loss: 1.363034. Batch_acc: 0.517990. Batch_loss: 1.331510 \n",
      "Batch: 1058. Acc: 0.508717. Loss: 1.363008. Batch_acc: 0.517281. Batch_loss: 1.335276 \n",
      "Batch: 1059. Acc: 0.508679. Loss: 1.363090. Batch_acc: 0.467340. Batch_loss: 1.452522 \n",
      "Batch: 1060. Acc: 0.508690. Loss: 1.363068. Batch_acc: 0.520431. Batch_loss: 1.340298 \n",
      "Batch: 1061. Acc: 0.508685. Loss: 1.363076. Batch_acc: 0.503472. Batch_loss: 1.371675 \n",
      "Batch: 1062. Acc: 0.508695. Loss: 1.363058. Batch_acc: 0.518583. Batch_loss: 1.343937 \n",
      "Batch: 1063. Acc: 0.508691. Loss: 1.363060. Batch_acc: 0.505190. Batch_loss: 1.364904 \n",
      "Batch: 1064. Acc: 0.508690. Loss: 1.363046. Batch_acc: 0.506961. Batch_loss: 1.348212 \n",
      "Batch: 1065. Acc: 0.508707. Loss: 1.363001. Batch_acc: 0.527180. Batch_loss: 1.315427 \n",
      "Batch: 1066. Acc: 0.508726. Loss: 1.362941. Batch_acc: 0.528302. Batch_loss: 1.301730 \n",
      "Batch: 1067. Acc: 0.508732. Loss: 1.362881. Batch_acc: 0.514623. Batch_loss: 1.300323 \n",
      "Batch: 1068. Acc: 0.508753. Loss: 1.362835. Batch_acc: 0.531195. Batch_loss: 1.312873 \n",
      "Batch: 1069. Acc: 0.508744. Loss: 1.362862. Batch_acc: 0.499710. Batch_loss: 1.391876 \n",
      "Batch: 1070. Acc: 0.508723. Loss: 1.362927. Batch_acc: 0.485079. Batch_loss: 1.433530 \n",
      "Batch: 1071. Acc: 0.508723. Loss: 1.362941. Batch_acc: 0.509456. Batch_loss: 1.377431 \n",
      "Batch: 1072. Acc: 0.508733. Loss: 1.362925. Batch_acc: 0.518644. Batch_loss: 1.346665 \n",
      "Batch: 1073. Acc: 0.508738. Loss: 1.362906. Batch_acc: 0.514590. Batch_loss: 1.343041 \n",
      "Batch: 1074. Acc: 0.508719. Loss: 1.362943. Batch_acc: 0.488068. Batch_loss: 1.402165 \n",
      "Batch: 1075. Acc: 0.508742. Loss: 1.362887. Batch_acc: 0.534223. Batch_loss: 1.302034 \n",
      "Batch: 1076. Acc: 0.508732. Loss: 1.362912. Batch_acc: 0.497622. Batch_loss: 1.390718 \n",
      "Batch: 1077. Acc: 0.508725. Loss: 1.362942. Batch_acc: 0.501161. Batch_loss: 1.395527 \n",
      "Batch: 1078. Acc: 0.508710. Loss: 1.362970. Batch_acc: 0.491546. Batch_loss: 1.394155 \n",
      "Batch: 1079. Acc: 0.508740. Loss: 1.362880. Batch_acc: 0.539363. Batch_loss: 1.268483 \n",
      "Batch: 1080. Acc: 0.508743. Loss: 1.362858. Batch_acc: 0.512373. Batch_loss: 1.340277 \n",
      "Batch: 1081. Acc: 0.508770. Loss: 1.362782. Batch_acc: 0.537982. Batch_loss: 1.281219 \n",
      "Batch: 1082. Acc: 0.508773. Loss: 1.362752. Batch_acc: 0.511370. Batch_loss: 1.330475 \n",
      "Batch: 1083. Acc: 0.508785. Loss: 1.362719. Batch_acc: 0.522465. Batch_loss: 1.327303 \n",
      "Batch: 1084. Acc: 0.508793. Loss: 1.362690. Batch_acc: 0.517181. Batch_loss: 1.330270 \n",
      "Batch: 1085. Acc: 0.508798. Loss: 1.362661. Batch_acc: 0.513834. Batch_loss: 1.332327 \n",
      "Batch: 1086. Acc: 0.508786. Loss: 1.362696. Batch_acc: 0.496275. Batch_loss: 1.400000 \n",
      "Batch: 1087. Acc: 0.508784. Loss: 1.362695. Batch_acc: 0.505949. Batch_loss: 1.361394 \n",
      "Batch: 1088. Acc: 0.508796. Loss: 1.362654. Batch_acc: 0.522059. Batch_loss: 1.319057 \n",
      "Batch: 1089. Acc: 0.508789. Loss: 1.362667. Batch_acc: 0.501159. Batch_loss: 1.376673 \n",
      "Batch: 1090. Acc: 0.508760. Loss: 1.362739. Batch_acc: 0.475845. Batch_loss: 1.445602 \n",
      "Batch: 1091. Acc: 0.508778. Loss: 1.362721. Batch_acc: 0.528193. Batch_loss: 1.342998 \n",
      "Batch: 1092. Acc: 0.508765. Loss: 1.362749. Batch_acc: 0.494938. Batch_loss: 1.392094 \n",
      "Batch: 1093. Acc: 0.508775. Loss: 1.362718. Batch_acc: 0.519744. Batch_loss: 1.329283 \n",
      "Batch: 1094. Acc: 0.508778. Loss: 1.362713. Batch_acc: 0.512000. Batch_loss: 1.356479 \n",
      "Batch: 1095. Acc: 0.508789. Loss: 1.362690. Batch_acc: 0.520321. Batch_loss: 1.338479 \n",
      "Batch: 1096. Acc: 0.508788. Loss: 1.362712. Batch_acc: 0.508585. Batch_loss: 1.387477 \n",
      "Batch: 1097. Acc: 0.508784. Loss: 1.362765. Batch_acc: 0.503670. Batch_loss: 1.419274 \n",
      "Batch: 1098. Acc: 0.508815. Loss: 1.362691. Batch_acc: 0.542535. Batch_loss: 1.283318 \n",
      "Batch: 1099. Acc: 0.508814. Loss: 1.362706. Batch_acc: 0.507401. Batch_loss: 1.379476 \n",
      "Batch: 1100. Acc: 0.508834. Loss: 1.362669. Batch_acc: 0.532078. Batch_loss: 1.320768 \n",
      "Batch: 1101. Acc: 0.508826. Loss: 1.362683. Batch_acc: 0.500000. Batch_loss: 1.378941 \n",
      "Batch: 1102. Acc: 0.508820. Loss: 1.362683. Batch_acc: 0.502053. Batch_loss: 1.361972 \n",
      "Batch: 1103. Acc: 0.508845. Loss: 1.362620. Batch_acc: 0.535937. Batch_loss: 1.294184 \n",
      "Batch: 1104. Acc: 0.508861. Loss: 1.362600. Batch_acc: 0.526587. Batch_loss: 1.340828 \n",
      "Batch: 1105. Acc: 0.508853. Loss: 1.362625. Batch_acc: 0.500000. Batch_loss: 1.390513 \n",
      "Batch: 1106. Acc: 0.508881. Loss: 1.362564. Batch_acc: 0.539199. Batch_loss: 1.295713 \n",
      "Batch: 1107. Acc: 0.508891. Loss: 1.362544. Batch_acc: 0.519741. Batch_loss: 1.340128 \n",
      "Batch: 1108. Acc: 0.508885. Loss: 1.362568. Batch_acc: 0.502588. Batch_loss: 1.389267 \n",
      "Batch: 1109. Acc: 0.508886. Loss: 1.362569. Batch_acc: 0.509942. Batch_loss: 1.364343 \n",
      "Batch: 1110. Acc: 0.508898. Loss: 1.362560. Batch_acc: 0.521813. Batch_loss: 1.352536 \n",
      "Batch: 1111. Acc: 0.508911. Loss: 1.362540. Batch_acc: 0.523539. Batch_loss: 1.340002 \n",
      "Batch: 1112. Acc: 0.508917. Loss: 1.362507. Batch_acc: 0.515169. Batch_loss: 1.326146 \n",
      "Batch: 1113. Acc: 0.508945. Loss: 1.362453. Batch_acc: 0.540462. Batch_loss: 1.301571 \n",
      "Batch: 1114. Acc: 0.508953. Loss: 1.362428. Batch_acc: 0.517222. Batch_loss: 1.334954 \n",
      "Batch: 1115. Acc: 0.508939. Loss: 1.362439. Batch_acc: 0.493693. Batch_loss: 1.374578 \n",
      "Batch: 1116. Acc: 0.508944. Loss: 1.362434. Batch_acc: 0.514464. Batch_loss: 1.357328 \n",
      "Batch: 1117. Acc: 0.508966. Loss: 1.362364. Batch_acc: 0.534401. Batch_loss: 1.281890 \n",
      "Batch: 1118. Acc: 0.508994. Loss: 1.362287. Batch_acc: 0.539888. Batch_loss: 1.278149 \n",
      "Batch: 1119. Acc: 0.508974. Loss: 1.362311. Batch_acc: 0.485225. Batch_loss: 1.389808 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1120. Acc: 0.508986. Loss: 1.362277. Batch_acc: 0.522767. Batch_loss: 1.323627 \n",
      "Batch: 1121. Acc: 0.508979. Loss: 1.362259. Batch_acc: 0.501156. Batch_loss: 1.342192 \n",
      "Batch: 1122. Acc: 0.508992. Loss: 1.362222. Batch_acc: 0.523509. Batch_loss: 1.320972 \n",
      "Batch: 1123. Acc: 0.509001. Loss: 1.362195. Batch_acc: 0.518889. Batch_loss: 1.332959 \n",
      "Batch: 1124. Acc: 0.508987. Loss: 1.362228. Batch_acc: 0.493678. Batch_loss: 1.399074 \n",
      "Batch: 1125. Acc: 0.508986. Loss: 1.362206. Batch_acc: 0.507572. Batch_loss: 1.338004 \n",
      "Batch: 1126. Acc: 0.508968. Loss: 1.362240. Batch_acc: 0.488479. Batch_loss: 1.400475 \n",
      "Batch: 1127. Acc: 0.508992. Loss: 1.362171. Batch_acc: 0.536117. Batch_loss: 1.286766 \n",
      "Batch: 1128. Acc: 0.509010. Loss: 1.362145. Batch_acc: 0.529516. Batch_loss: 1.331104 \n",
      "Batch: 1129. Acc: 0.508993. Loss: 1.362196. Batch_acc: 0.489960. Batch_loss: 1.420097 \n",
      "Batch: 1130. Acc: 0.508987. Loss: 1.362205. Batch_acc: 0.501736. Batch_loss: 1.371862 \n",
      "Batch: 1131. Acc: 0.508986. Loss: 1.362198. Batch_acc: 0.507901. Batch_loss: 1.355253 \n",
      "Batch: 1132. Acc: 0.508987. Loss: 1.362173. Batch_acc: 0.510381. Batch_loss: 1.333444 \n",
      "Batch: 1133. Acc: 0.508968. Loss: 1.362220. Batch_acc: 0.487209. Batch_loss: 1.416069 \n",
      "Batch: 1134. Acc: 0.508986. Loss: 1.362186. Batch_acc: 0.529683. Batch_loss: 1.323614 \n",
      "Batch: 1135. Acc: 0.508997. Loss: 1.362173. Batch_acc: 0.521119. Batch_loss: 1.347484 \n",
      "Batch: 1136. Acc: 0.508974. Loss: 1.362203. Batch_acc: 0.482477. Batch_loss: 1.396360 \n",
      "Batch: 1137. Acc: 0.508974. Loss: 1.362214. Batch_acc: 0.508792. Batch_loss: 1.374707 \n",
      "Batch: 1138. Acc: 0.508974. Loss: 1.362208. Batch_acc: 0.509249. Batch_loss: 1.355360 \n",
      "Batch: 1139. Acc: 0.508985. Loss: 1.362156. Batch_acc: 0.520869. Batch_loss: 1.303672 \n",
      "Batch: 1140. Acc: 0.508994. Loss: 1.362107. Batch_acc: 0.519839. Batch_loss: 1.306161 \n",
      "Batch: 1141. Acc: 0.508997. Loss: 1.362094. Batch_acc: 0.511587. Batch_loss: 1.346913 \n",
      "Batch: 1142. Acc: 0.509002. Loss: 1.362076. Batch_acc: 0.514886. Batch_loss: 1.340957 \n",
      "Batch: 1143. Acc: 0.509015. Loss: 1.362035. Batch_acc: 0.523947. Batch_loss: 1.316087 \n",
      "Batch: 1144. Acc: 0.509017. Loss: 1.362028. Batch_acc: 0.511410. Batch_loss: 1.353643 \n",
      "Batch: 1145. Acc: 0.509016. Loss: 1.362037. Batch_acc: 0.507865. Batch_loss: 1.371426 \n",
      "Batch: 1146. Acc: 0.509030. Loss: 1.361996. Batch_acc: 0.526224. Batch_loss: 1.314730 \n",
      "Batch: 1147. Acc: 0.509037. Loss: 1.361970. Batch_acc: 0.516828. Batch_loss: 1.332328 \n",
      "Batch: 1148. Acc: 0.509058. Loss: 1.361915. Batch_acc: 0.533257. Batch_loss: 1.299480 \n",
      "Batch: 1149. Acc: 0.509057. Loss: 1.361909. Batch_acc: 0.506961. Batch_loss: 1.354008 \n",
      "Batch: 1150. Acc: 0.509092. Loss: 1.361843. Batch_acc: 0.548767. Batch_loss: 1.288704 \n",
      "Batch: 1151. Acc: 0.509093. Loss: 1.361813. Batch_acc: 0.510663. Batch_loss: 1.327371 \n",
      "Batch: 1152. Acc: 0.509079. Loss: 1.361812. Batch_acc: 0.492580. Batch_loss: 1.360678 \n",
      "Batch: 1153. Acc: 0.509065. Loss: 1.361844. Batch_acc: 0.492571. Batch_loss: 1.397693 \n",
      "Batch: 1154. Acc: 0.509070. Loss: 1.361818. Batch_acc: 0.515695. Batch_loss: 1.332692 \n",
      "Batch: 1155. Acc: 0.509073. Loss: 1.361791. Batch_acc: 0.511829. Batch_loss: 1.330632 \n",
      "Batch: 1156. Acc: 0.509077. Loss: 1.361769. Batch_acc: 0.513960. Batch_loss: 1.336661 \n",
      "Batch: 1157. Acc: 0.509103. Loss: 1.361716. Batch_acc: 0.538034. Batch_loss: 1.302458 \n",
      "Batch: 1158. Acc: 0.509107. Loss: 1.361691. Batch_acc: 0.513777. Batch_loss: 1.332934 \n",
      "Batch: 1159. Acc: 0.509127. Loss: 1.361648. Batch_acc: 0.531915. Batch_loss: 1.311836 \n",
      "Batch: 1160. Acc: 0.509143. Loss: 1.361577. Batch_acc: 0.527936. Batch_loss: 1.280125 \n",
      "Batch: 1161. Acc: 0.509143. Loss: 1.361566. Batch_acc: 0.508701. Batch_loss: 1.348861 \n",
      "Batch: 1162. Acc: 0.509152. Loss: 1.361545. Batch_acc: 0.520556. Batch_loss: 1.337176 \n",
      "Batch: 1163. Acc: 0.509169. Loss: 1.361479. Batch_acc: 0.527991. Batch_loss: 1.288007 \n",
      "Batch: 1164. Acc: 0.509184. Loss: 1.361454. Batch_acc: 0.526655. Batch_loss: 1.331389 \n",
      "Batch: 1165. Acc: 0.509183. Loss: 1.361459. Batch_acc: 0.507580. Batch_loss: 1.368072 \n",
      "Batch: 1166. Acc: 0.509193. Loss: 1.361418. Batch_acc: 0.521258. Batch_loss: 1.313033 \n",
      "Batch: 1167. Acc: 0.509168. Loss: 1.361475. Batch_acc: 0.478947. Batch_loss: 1.428769 \n",
      "Batch: 1168. Acc: 0.509172. Loss: 1.361478. Batch_acc: 0.514418. Batch_loss: 1.364416 \n",
      "Batch: 1169. Acc: 0.509178. Loss: 1.361459. Batch_acc: 0.515643. Batch_loss: 1.339878 \n",
      "Batch: 1170. Acc: 0.509173. Loss: 1.361489. Batch_acc: 0.503699. Batch_loss: 1.396486 \n",
      "Batch: 1171. Acc: 0.509177. Loss: 1.361497. Batch_acc: 0.514269. Batch_loss: 1.371028 \n",
      "Batch: 1172. Acc: 0.509174. Loss: 1.361474. Batch_acc: 0.505178. Batch_loss: 1.333947 \n",
      "Batch: 1173. Acc: 0.509187. Loss: 1.361451. Batch_acc: 0.524439. Batch_loss: 1.334402 \n",
      "Batch: 1174. Acc: 0.509185. Loss: 1.361452. Batch_acc: 0.506486. Batch_loss: 1.362431 \n",
      "Batch: 1175. Acc: 0.509200. Loss: 1.361438. Batch_acc: 0.527136. Batch_loss: 1.345447 \n",
      "Batch: 1176. Acc: 0.509208. Loss: 1.361410. Batch_acc: 0.518890. Batch_loss: 1.327475 \n",
      "Batch: 1177. Acc: 0.509195. Loss: 1.361440. Batch_acc: 0.494512. Batch_loss: 1.397274 \n",
      "Batch: 1178. Acc: 0.509198. Loss: 1.361445. Batch_acc: 0.512181. Batch_loss: 1.367220 \n",
      "Batch: 1179. Acc: 0.509204. Loss: 1.361421. Batch_acc: 0.516279. Batch_loss: 1.332078 \n",
      "Batch: 1180. Acc: 0.509220. Loss: 1.361375. Batch_acc: 0.527778. Batch_loss: 1.309619 \n",
      "Batch: 1181. Acc: 0.509206. Loss: 1.361380. Batch_acc: 0.493127. Batch_loss: 1.366635 \n",
      "Batch: 1182. Acc: 0.509217. Loss: 1.361336. Batch_acc: 0.521167. Batch_loss: 1.309714 \n",
      "Batch: 1183. Acc: 0.509209. Loss: 1.361350. Batch_acc: 0.499709. Batch_loss: 1.378235 \n",
      "Batch: 1184. Acc: 0.509213. Loss: 1.361326. Batch_acc: 0.514068. Batch_loss: 1.332063 \n",
      "Batch: 1185. Acc: 0.509195. Loss: 1.361336. Batch_acc: 0.488263. Batch_loss: 1.374308 \n",
      "Batch: 1186. Acc: 0.509183. Loss: 1.361355. Batch_acc: 0.494337. Batch_loss: 1.382632 \n",
      "Batch: 1187. Acc: 0.509206. Loss: 1.361287. Batch_acc: 0.536812. Batch_loss: 1.280955 \n",
      "Batch: 1188. Acc: 0.509191. Loss: 1.361314. Batch_acc: 0.491972. Batch_loss: 1.392799 \n",
      "Batch: 1189. Acc: 0.509190. Loss: 1.361326. Batch_acc: 0.507835. Batch_loss: 1.375872 \n",
      "Batch: 1190. Acc: 0.509185. Loss: 1.361312. Batch_acc: 0.503513. Batch_loss: 1.344422 \n",
      "Batch: 1191. Acc: 0.509177. Loss: 1.361328. Batch_acc: 0.498836. Batch_loss: 1.380447 \n",
      "Batch: 1192. Acc: 0.509188. Loss: 1.361304. Batch_acc: 0.522321. Batch_loss: 1.334052 \n",
      "Batch: 1193. Acc: 0.509201. Loss: 1.361284. Batch_acc: 0.524600. Batch_loss: 1.337145 \n",
      "Batch: 1194. Acc: 0.509220. Loss: 1.361235. Batch_acc: 0.532362. Batch_loss: 1.302414 \n",
      "Batch: 1195. Acc: 0.509225. Loss: 1.361203. Batch_acc: 0.514723. Batch_loss: 1.320929 \n",
      "Batch: 1196. Acc: 0.509225. Loss: 1.361205. Batch_acc: 0.509983. Batch_loss: 1.364186 \n",
      "Batch: 1197. Acc: 0.509242. Loss: 1.361194. Batch_acc: 0.528749. Batch_loss: 1.347701 \n",
      "Batch: 1198. Acc: 0.509252. Loss: 1.361178. Batch_acc: 0.521216. Batch_loss: 1.342299 \n",
      "Batch: 1199. Acc: 0.509277. Loss: 1.361100. Batch_acc: 0.538418. Batch_loss: 1.270096 \n",
      "Batch: 1200. Acc: 0.509268. Loss: 1.361108. Batch_acc: 0.498826. Batch_loss: 1.370819 \n",
      "Batch: 1201. Acc: 0.509311. Loss: 1.361000. Batch_acc: 0.560364. Batch_loss: 1.232516 \n",
      "Batch: 1202. Acc: 0.509312. Loss: 1.360996. Batch_acc: 0.509965. Batch_loss: 1.355754 \n",
      "Batch: 1203. Acc: 0.509326. Loss: 1.360974. Batch_acc: 0.525750. Batch_loss: 1.334769 \n",
      "Batch: 1204. Acc: 0.509335. Loss: 1.360942. Batch_acc: 0.520676. Batch_loss: 1.321919 \n",
      "Batch: 1205. Acc: 0.509361. Loss: 1.360878. Batch_acc: 0.541788. Batch_loss: 1.282653 \n",
      "Batch: 1206. Acc: 0.509367. Loss: 1.360851. Batch_acc: 0.516716. Batch_loss: 1.328297 \n",
      "Batch: 1207. Acc: 0.509356. Loss: 1.360864. Batch_acc: 0.495455. Batch_loss: 1.375466 \n",
      "Batch: 1208. Acc: 0.509355. Loss: 1.360887. Batch_acc: 0.508842. Batch_loss: 1.388994 \n",
      "Batch: 1209. Acc: 0.509357. Loss: 1.360892. Batch_acc: 0.510882. Batch_loss: 1.366303 \n",
      "Batch: 1210. Acc: 0.509371. Loss: 1.360855. Batch_acc: 0.526376. Batch_loss: 1.316415 \n",
      "Batch: 1211. Acc: 0.509367. Loss: 1.360868. Batch_acc: 0.505364. Batch_loss: 1.376489 \n",
      "Batch: 1212. Acc: 0.509383. Loss: 1.360812. Batch_acc: 0.529002. Batch_loss: 1.292406 \n",
      "Batch: 1213. Acc: 0.509390. Loss: 1.360798. Batch_acc: 0.517494. Batch_loss: 1.344258 \n",
      "Batch: 1214. Acc: 0.509392. Loss: 1.360811. Batch_acc: 0.512153. Batch_loss: 1.376078 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1215. Acc: 0.509394. Loss: 1.360783. Batch_acc: 0.512009. Batch_loss: 1.326706 \n",
      "Batch: 1216. Acc: 0.509396. Loss: 1.360766. Batch_acc: 0.511775. Batch_loss: 1.340426 \n",
      "Batch: 1217. Acc: 0.509369. Loss: 1.360841. Batch_acc: 0.475553. Batch_loss: 1.452370 \n",
      "Batch: 1218. Acc: 0.509369. Loss: 1.360830. Batch_acc: 0.508975. Batch_loss: 1.348015 \n",
      "Batch: 1219. Acc: 0.509360. Loss: 1.360852. Batch_acc: 0.498577. Batch_loss: 1.387055 \n",
      "Batch: 1220. Acc: 0.509366. Loss: 1.360867. Batch_acc: 0.517164. Batch_loss: 1.379440 \n",
      "Batch: 1221. Acc: 0.509386. Loss: 1.360828. Batch_acc: 0.533410. Batch_loss: 1.312234 \n",
      "Batch: 1222. Acc: 0.509401. Loss: 1.360767. Batch_acc: 0.527590. Batch_loss: 1.287746 \n",
      "Batch: 1223. Acc: 0.509403. Loss: 1.360744. Batch_acc: 0.512099. Batch_loss: 1.334116 \n",
      "Batch: 1224. Acc: 0.509404. Loss: 1.360732. Batch_acc: 0.509666. Batch_loss: 1.345665 \n",
      "Batch: 1225. Acc: 0.509404. Loss: 1.360740. Batch_acc: 0.510453. Batch_loss: 1.369631 \n",
      "Batch: 1226. Acc: 0.509396. Loss: 1.360769. Batch_acc: 0.499129. Batch_loss: 1.397563 \n",
      "Batch: 1227. Acc: 0.509400. Loss: 1.360762. Batch_acc: 0.514024. Batch_loss: 1.351385 \n",
      "Batch: 1228. Acc: 0.509388. Loss: 1.360766. Batch_acc: 0.494845. Batch_loss: 1.365624 \n",
      "Batch: 1229. Acc: 0.509388. Loss: 1.360778. Batch_acc: 0.509379. Batch_loss: 1.376203 \n",
      "Batch: 1230. Acc: 0.509380. Loss: 1.360798. Batch_acc: 0.500000. Batch_loss: 1.385588 \n",
      "Batch: 1231. Acc: 0.509403. Loss: 1.360743. Batch_acc: 0.536854. Batch_loss: 1.292713 \n",
      "Batch: 1232. Acc: 0.509386. Loss: 1.360804. Batch_acc: 0.488413. Batch_loss: 1.436563 \n",
      "Batch: 1233. Acc: 0.509383. Loss: 1.360816. Batch_acc: 0.506523. Batch_loss: 1.374981 \n",
      "Batch: 1234. Acc: 0.509385. Loss: 1.360813. Batch_acc: 0.511891. Batch_loss: 1.357163 \n",
      "Batch: 1235. Acc: 0.509397. Loss: 1.360767. Batch_acc: 0.523863. Batch_loss: 1.306219 \n",
      "Batch: 1236. Acc: 0.509414. Loss: 1.360707. Batch_acc: 0.529842. Batch_loss: 1.287137 \n",
      "Batch: 1237. Acc: 0.509423. Loss: 1.360690. Batch_acc: 0.520000. Batch_loss: 1.340400 \n",
      "Batch: 1238. Acc: 0.509432. Loss: 1.360681. Batch_acc: 0.520255. Batch_loss: 1.349603 \n",
      "Batch: 1239. Acc: 0.509444. Loss: 1.360652. Batch_acc: 0.524487. Batch_loss: 1.325230 \n",
      "Batch: 1240. Acc: 0.509460. Loss: 1.360603. Batch_acc: 0.528940. Batch_loss: 1.300103 \n",
      "Batch: 1241. Acc: 0.509450. Loss: 1.360595. Batch_acc: 0.497479. Batch_loss: 1.350373 \n",
      "Batch: 1242. Acc: 0.509426. Loss: 1.360674. Batch_acc: 0.478520. Batch_loss: 1.462067 \n",
      "Batch: 1243. Acc: 0.509434. Loss: 1.360652. Batch_acc: 0.519511. Batch_loss: 1.332924 \n",
      "Batch: 1244. Acc: 0.509439. Loss: 1.360642. Batch_acc: 0.516295. Batch_loss: 1.348184 \n",
      "Batch: 1245. Acc: 0.509452. Loss: 1.360590. Batch_acc: 0.524928. Batch_loss: 1.296100 \n",
      "Batch: 1246. Acc: 0.509450. Loss: 1.360558. Batch_acc: 0.507657. Batch_loss: 1.322134 \n",
      "Batch: 1247. Acc: 0.509440. Loss: 1.360579. Batch_acc: 0.496236. Batch_loss: 1.387220 \n",
      "Batch: 1248. Acc: 0.509431. Loss: 1.360601. Batch_acc: 0.498546. Batch_loss: 1.388265 \n",
      "Batch: 1249. Acc: 0.509421. Loss: 1.360609. Batch_acc: 0.496499. Batch_loss: 1.370631 \n",
      "Batch: 1250. Acc: 0.509442. Loss: 1.360585. Batch_acc: 0.535940. Batch_loss: 1.330224 \n",
      "Batch: 1251. Acc: 0.509439. Loss: 1.360580. Batch_acc: 0.505605. Batch_loss: 1.353727 \n",
      "Batch: 1252. Acc: 0.509442. Loss: 1.360558. Batch_acc: 0.512994. Batch_loss: 1.333699 \n",
      "Batch: 1253. Acc: 0.509445. Loss: 1.360553. Batch_acc: 0.513068. Batch_loss: 1.354632 \n",
      "Batch: 1254. Acc: 0.509461. Loss: 1.360521. Batch_acc: 0.529647. Batch_loss: 1.321013 \n",
      "Batch: 1255. Acc: 0.509479. Loss: 1.360482. Batch_acc: 0.532295. Batch_loss: 1.311738 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.5094793524633491. Loss per char: 1.360482497921203. Time: 1627218948.2357824\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 22, 23, 15, 17, 17, 21, 26, 22,\n",
      "        24, 23,  1, 14,  1, 14, 18, 22, 26, 25, 19, 32,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.509467. Loss: 1.360501. Batch_acc: 0.494131. Batch_loss: 1.383603 \n",
      "Batch: 1257. Acc: 0.509477. Loss: 1.360483. Batch_acc: 0.521564. Batch_loss: 1.338134 \n",
      "Batch: 1258. Acc: 0.509487. Loss: 1.360473. Batch_acc: 0.521614. Batch_loss: 1.348009 \n",
      "Batch: 1259. Acc: 0.509478. Loss: 1.360505. Batch_acc: 0.498552. Batch_loss: 1.400868 \n",
      "Batch: 1260. Acc: 0.509463. Loss: 1.360521. Batch_acc: 0.489857. Batch_loss: 1.382138 \n",
      "Batch: 1261. Acc: 0.509470. Loss: 1.360539. Batch_acc: 0.518389. Batch_loss: 1.382629 \n",
      "Batch: 1262. Acc: 0.509478. Loss: 1.360536. Batch_acc: 0.519187. Batch_loss: 1.357428 \n",
      "Batch: 1263. Acc: 0.509480. Loss: 1.360531. Batch_acc: 0.511721. Batch_loss: 1.353925 \n",
      "Batch: 1264. Acc: 0.509500. Loss: 1.360505. Batch_acc: 0.535108. Batch_loss: 1.328419 \n",
      "Batch: 1265. Acc: 0.509529. Loss: 1.360412. Batch_acc: 0.544693. Batch_loss: 1.246159 \n",
      "Batch: 1266. Acc: 0.509527. Loss: 1.360398. Batch_acc: 0.507263. Batch_loss: 1.342826 \n",
      "Batch: 1267. Acc: 0.509531. Loss: 1.360363. Batch_acc: 0.514484. Batch_loss: 1.315638 \n",
      "Batch: 1268. Acc: 0.509539. Loss: 1.360347. Batch_acc: 0.519663. Batch_loss: 1.340368 \n",
      "Batch: 1269. Acc: 0.509550. Loss: 1.360308. Batch_acc: 0.522779. Batch_loss: 1.311623 \n",
      "Batch: 1270. Acc: 0.509553. Loss: 1.360306. Batch_acc: 0.514035. Batch_loss: 1.357861 \n",
      "Batch: 1271. Acc: 0.509561. Loss: 1.360258. Batch_acc: 0.519045. Batch_loss: 1.299288 \n",
      "Batch: 1272. Acc: 0.509578. Loss: 1.360215. Batch_acc: 0.531638. Batch_loss: 1.304452 \n",
      "Batch: 1273. Acc: 0.509589. Loss: 1.360207. Batch_acc: 0.523919. Batch_loss: 1.349545 \n",
      "Batch: 1274. Acc: 0.509616. Loss: 1.360153. Batch_acc: 0.544341. Batch_loss: 1.291141 \n",
      "Batch: 1275. Acc: 0.509595. Loss: 1.360214. Batch_acc: 0.482575. Batch_loss: 1.439597 \n",
      "Batch: 1276. Acc: 0.509602. Loss: 1.360197. Batch_acc: 0.519343. Batch_loss: 1.337883 \n",
      "Batch: 1277. Acc: 0.509628. Loss: 1.360151. Batch_acc: 0.541714. Batch_loss: 1.302197 \n",
      "Batch: 1278. Acc: 0.509634. Loss: 1.360148. Batch_acc: 0.517221. Batch_loss: 1.355807 \n",
      "Batch: 1279. Acc: 0.509649. Loss: 1.360119. Batch_acc: 0.529683. Batch_loss: 1.322909 \n",
      "Batch: 1280. Acc: 0.509647. Loss: 1.360097. Batch_acc: 0.507180. Batch_loss: 1.332722 \n",
      "Batch: 1281. Acc: 0.509678. Loss: 1.360012. Batch_acc: 0.548963. Batch_loss: 1.250711 \n",
      "Batch: 1282. Acc: 0.509688. Loss: 1.359959. Batch_acc: 0.522286. Batch_loss: 1.292079 \n",
      "Batch: 1283. Acc: 0.509689. Loss: 1.359977. Batch_acc: 0.511494. Batch_loss: 1.383003 \n",
      "Batch: 1284. Acc: 0.509675. Loss: 1.360021. Batch_acc: 0.491056. Batch_loss: 1.417098 \n",
      "Batch: 1285. Acc: 0.509671. Loss: 1.360039. Batch_acc: 0.504635. Batch_loss: 1.383604 \n",
      "Batch: 1286. Acc: 0.509684. Loss: 1.360006. Batch_acc: 0.526286. Batch_loss: 1.317802 \n",
      "Batch: 1287. Acc: 0.509677. Loss: 1.360010. Batch_acc: 0.500288. Batch_loss: 1.365372 \n",
      "Batch: 1288. Acc: 0.509690. Loss: 1.359978. Batch_acc: 0.526617. Batch_loss: 1.318298 \n",
      "Batch: 1289. Acc: 0.509698. Loss: 1.359943. Batch_acc: 0.519668. Batch_loss: 1.317513 \n",
      "Batch: 1290. Acc: 0.509727. Loss: 1.359863. Batch_acc: 0.546223. Batch_loss: 1.258592 \n",
      "Batch: 1291. Acc: 0.509745. Loss: 1.359819. Batch_acc: 0.532876. Batch_loss: 1.302906 \n",
      "Batch: 1292. Acc: 0.509749. Loss: 1.359805. Batch_acc: 0.515186. Batch_loss: 1.341959 \n",
      "Batch: 1293. Acc: 0.509753. Loss: 1.359784. Batch_acc: 0.514302. Batch_loss: 1.333392 \n",
      "Batch: 1294. Acc: 0.509748. Loss: 1.359782. Batch_acc: 0.502952. Batch_loss: 1.356450 \n",
      "Batch: 1295. Acc: 0.509742. Loss: 1.359788. Batch_acc: 0.502649. Batch_loss: 1.367655 \n",
      "Batch: 1296. Acc: 0.509739. Loss: 1.359762. Batch_acc: 0.505533. Batch_loss: 1.326096 \n",
      "Batch: 1297. Acc: 0.509740. Loss: 1.359781. Batch_acc: 0.510337. Batch_loss: 1.385561 \n",
      "Batch: 1298. Acc: 0.509757. Loss: 1.359721. Batch_acc: 0.532358. Batch_loss: 1.283674 \n",
      "Batch: 1299. Acc: 0.509759. Loss: 1.359699. Batch_acc: 0.511721. Batch_loss: 1.330847 \n",
      "Batch: 1300. Acc: 0.509764. Loss: 1.359674. Batch_acc: 0.517082. Batch_loss: 1.326716 \n",
      "Batch: 1301. Acc: 0.509765. Loss: 1.359682. Batch_acc: 0.510889. Batch_loss: 1.370756 \n",
      "Batch: 1302. Acc: 0.509786. Loss: 1.359666. Batch_acc: 0.536726. Batch_loss: 1.338028 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1303. Acc: 0.509779. Loss: 1.359666. Batch_acc: 0.500879. Batch_loss: 1.360031 \n",
      "Batch: 1304. Acc: 0.509788. Loss: 1.359624. Batch_acc: 0.521839. Batch_loss: 1.305420 \n",
      "Batch: 1305. Acc: 0.509784. Loss: 1.359638. Batch_acc: 0.503501. Batch_loss: 1.378078 \n",
      "Batch: 1306. Acc: 0.509785. Loss: 1.359627. Batch_acc: 0.512153. Batch_loss: 1.344837 \n",
      "Batch: 1307. Acc: 0.509791. Loss: 1.359627. Batch_acc: 0.516886. Batch_loss: 1.359273 \n",
      "Batch: 1308. Acc: 0.509799. Loss: 1.359615. Batch_acc: 0.520750. Batch_loss: 1.345012 \n",
      "Batch: 1309. Acc: 0.509814. Loss: 1.359576. Batch_acc: 0.528841. Batch_loss: 1.309084 \n",
      "Batch: 1310. Acc: 0.509822. Loss: 1.359551. Batch_acc: 0.520612. Batch_loss: 1.325024 \n",
      "Batch: 1311. Acc: 0.509842. Loss: 1.359512. Batch_acc: 0.536005. Batch_loss: 1.308040 \n",
      "Batch: 1312. Acc: 0.509831. Loss: 1.359518. Batch_acc: 0.495449. Batch_loss: 1.367973 \n",
      "Batch: 1313. Acc: 0.509834. Loss: 1.359518. Batch_acc: 0.513436. Batch_loss: 1.359070 \n",
      "Batch: 1314. Acc: 0.509840. Loss: 1.359508. Batch_acc: 0.518144. Batch_loss: 1.345274 \n",
      "Batch: 1315. Acc: 0.509860. Loss: 1.359445. Batch_acc: 0.535877. Batch_loss: 1.277440 \n",
      "Batch: 1316. Acc: 0.509867. Loss: 1.359417. Batch_acc: 0.519774. Batch_loss: 1.324465 \n",
      "Batch: 1317. Acc: 0.509837. Loss: 1.359484. Batch_acc: 0.469042. Batch_loss: 1.448908 \n",
      "Batch: 1318. Acc: 0.509823. Loss: 1.359506. Batch_acc: 0.491289. Batch_loss: 1.388557 \n",
      "Batch: 1319. Acc: 0.509824. Loss: 1.359499. Batch_acc: 0.510750. Batch_loss: 1.349943 \n",
      "Batch: 1320. Acc: 0.509816. Loss: 1.359538. Batch_acc: 0.500000. Batch_loss: 1.411649 \n",
      "Batch: 1321. Acc: 0.509805. Loss: 1.359538. Batch_acc: 0.495455. Batch_loss: 1.358819 \n",
      "Batch: 1322. Acc: 0.509823. Loss: 1.359518. Batch_acc: 0.532759. Batch_loss: 1.333310 \n",
      "Batch: 1323. Acc: 0.509825. Loss: 1.359523. Batch_acc: 0.513593. Batch_loss: 1.366592 \n",
      "Batch: 1324. Acc: 0.509834. Loss: 1.359529. Batch_acc: 0.521295. Batch_loss: 1.367306 \n",
      "Batch: 1325. Acc: 0.509824. Loss: 1.359551. Batch_acc: 0.495954. Batch_loss: 1.388874 \n",
      "Batch: 1326. Acc: 0.509827. Loss: 1.359554. Batch_acc: 0.514089. Batch_loss: 1.363833 \n",
      "Batch: 1327. Acc: 0.509825. Loss: 1.359535. Batch_acc: 0.506849. Batch_loss: 1.333551 \n",
      "Batch: 1328. Acc: 0.509812. Loss: 1.359542. Batch_acc: 0.492966. Batch_loss: 1.369687 \n",
      "Batch: 1329. Acc: 0.509798. Loss: 1.359588. Batch_acc: 0.490783. Batch_loss: 1.420609 \n",
      "Batch: 1330. Acc: 0.509808. Loss: 1.359565. Batch_acc: 0.522872. Batch_loss: 1.328184 \n",
      "Batch: 1331. Acc: 0.509797. Loss: 1.359589. Batch_acc: 0.495902. Batch_loss: 1.392823 \n",
      "Batch: 1332. Acc: 0.509797. Loss: 1.359597. Batch_acc: 0.509182. Batch_loss: 1.369887 \n",
      "Batch: 1333. Acc: 0.509797. Loss: 1.359629. Batch_acc: 0.509804. Batch_loss: 1.402134 \n",
      "Batch: 1334. Acc: 0.509808. Loss: 1.359583. Batch_acc: 0.524184. Batch_loss: 1.299658 \n",
      "Batch: 1335. Acc: 0.509801. Loss: 1.359584. Batch_acc: 0.500869. Batch_loss: 1.360722 \n",
      "Batch: 1336. Acc: 0.509813. Loss: 1.359559. Batch_acc: 0.526471. Batch_loss: 1.326291 \n",
      "Batch: 1337. Acc: 0.509814. Loss: 1.359551. Batch_acc: 0.510465. Batch_loss: 1.347949 \n",
      "Batch: 1338. Acc: 0.509833. Loss: 1.359499. Batch_acc: 0.535371. Batch_loss: 1.290898 \n",
      "Batch: 1339. Acc: 0.509826. Loss: 1.359501. Batch_acc: 0.500291. Batch_loss: 1.362262 \n",
      "Batch: 1340. Acc: 0.509837. Loss: 1.359487. Batch_acc: 0.524695. Batch_loss: 1.340676 \n",
      "Batch: 1341. Acc: 0.509855. Loss: 1.359450. Batch_acc: 0.533485. Batch_loss: 1.310168 \n",
      "Batch: 1342. Acc: 0.509864. Loss: 1.359417. Batch_acc: 0.522286. Batch_loss: 1.316336 \n",
      "Batch: 1343. Acc: 0.509852. Loss: 1.359441. Batch_acc: 0.493736. Batch_loss: 1.391294 \n",
      "Batch: 1344. Acc: 0.509866. Loss: 1.359403. Batch_acc: 0.527222. Batch_loss: 1.310056 \n",
      "Batch: 1345. Acc: 0.509870. Loss: 1.359374. Batch_acc: 0.515873. Batch_loss: 1.320963 \n",
      "Batch: 1346. Acc: 0.509877. Loss: 1.359342. Batch_acc: 0.519518. Batch_loss: 1.316114 \n",
      "Batch: 1347. Acc: 0.509894. Loss: 1.359334. Batch_acc: 0.531588. Batch_loss: 1.348137 \n",
      "Batch: 1348. Acc: 0.509883. Loss: 1.359339. Batch_acc: 0.495949. Batch_loss: 1.366124 \n",
      "Batch: 1349. Acc: 0.509884. Loss: 1.359332. Batch_acc: 0.510145. Batch_loss: 1.349839 \n",
      "Batch: 1350. Acc: 0.509895. Loss: 1.359293. Batch_acc: 0.524786. Batch_loss: 1.307589 \n",
      "Batch: 1351. Acc: 0.509893. Loss: 1.359277. Batch_acc: 0.507497. Batch_loss: 1.338263 \n",
      "Batch: 1352. Acc: 0.509907. Loss: 1.359235. Batch_acc: 0.528483. Batch_loss: 1.302827 \n",
      "Batch: 1353. Acc: 0.509922. Loss: 1.359207. Batch_acc: 0.529148. Batch_loss: 1.322764 \n",
      "Batch: 1354. Acc: 0.509932. Loss: 1.359181. Batch_acc: 0.524076. Batch_loss: 1.325077 \n",
      "Batch: 1355. Acc: 0.509937. Loss: 1.359163. Batch_acc: 0.516828. Batch_loss: 1.333880 \n",
      "Batch: 1356. Acc: 0.509941. Loss: 1.359138. Batch_acc: 0.514698. Batch_loss: 1.327066 \n",
      "Batch: 1357. Acc: 0.509958. Loss: 1.359097. Batch_acc: 0.532710. Batch_loss: 1.301983 \n",
      "Batch: 1358. Acc: 0.509964. Loss: 1.359078. Batch_acc: 0.518540. Batch_loss: 1.334624 \n",
      "Batch: 1359. Acc: 0.509963. Loss: 1.359067. Batch_acc: 0.508631. Batch_loss: 1.343509 \n",
      "Batch: 1360. Acc: 0.509966. Loss: 1.359052. Batch_acc: 0.513960. Batch_loss: 1.339344 \n",
      "Batch: 1361. Acc: 0.509969. Loss: 1.359028. Batch_acc: 0.514068. Batch_loss: 1.324571 \n",
      "Batch: 1362. Acc: 0.509978. Loss: 1.358990. Batch_acc: 0.522063. Batch_loss: 1.308484 \n",
      "Batch: 1363. Acc: 0.509990. Loss: 1.358974. Batch_acc: 0.526524. Batch_loss: 1.336755 \n",
      "Batch: 1364. Acc: 0.510000. Loss: 1.358962. Batch_acc: 0.522538. Batch_loss: 1.343568 \n",
      "Batch: 1365. Acc: 0.510007. Loss: 1.358940. Batch_acc: 0.520302. Batch_loss: 1.328734 \n",
      "Batch: 1366. Acc: 0.510006. Loss: 1.358937. Batch_acc: 0.508762. Batch_loss: 1.354696 \n",
      "Batch: 1367. Acc: 0.510020. Loss: 1.358890. Batch_acc: 0.528736. Batch_loss: 1.295064 \n",
      "Batch: 1368. Acc: 0.510011. Loss: 1.358916. Batch_acc: 0.498276. Batch_loss: 1.394028 \n",
      "Batch: 1369. Acc: 0.509993. Loss: 1.358945. Batch_acc: 0.483676. Batch_loss: 1.401079 \n",
      "Batch: 1370. Acc: 0.509998. Loss: 1.358925. Batch_acc: 0.516611. Batch_loss: 1.332049 \n",
      "Batch: 1371. Acc: 0.509991. Loss: 1.358932. Batch_acc: 0.500000. Batch_loss: 1.368322 \n",
      "Batch: 1372. Acc: 0.509999. Loss: 1.358896. Batch_acc: 0.521240. Batch_loss: 1.310001 \n",
      "Batch: 1373. Acc: 0.509986. Loss: 1.358943. Batch_acc: 0.492353. Batch_loss: 1.425402 \n",
      "Batch: 1374. Acc: 0.509994. Loss: 1.358912. Batch_acc: 0.520680. Batch_loss: 1.317007 \n",
      "Batch: 1375. Acc: 0.510010. Loss: 1.358858. Batch_acc: 0.530857. Batch_loss: 1.284247 \n",
      "Batch: 1376. Acc: 0.509998. Loss: 1.358887. Batch_acc: 0.493664. Batch_loss: 1.398623 \n",
      "Batch: 1377. Acc: 0.510008. Loss: 1.358859. Batch_acc: 0.524571. Batch_loss: 1.321087 \n",
      "Batch: 1378. Acc: 0.510013. Loss: 1.358843. Batch_acc: 0.516370. Batch_loss: 1.336849 \n",
      "Batch: 1379. Acc: 0.509998. Loss: 1.358875. Batch_acc: 0.489583. Batch_loss: 1.403008 \n",
      "Batch: 1380. Acc: 0.509989. Loss: 1.358907. Batch_acc: 0.497704. Batch_loss: 1.403494 \n",
      "Batch: 1381. Acc: 0.510009. Loss: 1.358843. Batch_acc: 0.536036. Batch_loss: 1.272653 \n",
      "Batch: 1382. Acc: 0.510018. Loss: 1.358811. Batch_acc: 0.523502. Batch_loss: 1.313424 \n",
      "Batch: 1383. Acc: 0.510024. Loss: 1.358771. Batch_acc: 0.518261. Batch_loss: 1.303285 \n",
      "Batch: 1384. Acc: 0.510010. Loss: 1.358789. Batch_acc: 0.490566. Batch_loss: 1.383147 \n",
      "Batch: 1385. Acc: 0.510010. Loss: 1.358792. Batch_acc: 0.509302. Batch_loss: 1.363071 \n",
      "Batch: 1386. Acc: 0.510016. Loss: 1.358788. Batch_acc: 0.518331. Batch_loss: 1.353438 \n",
      "Batch: 1387. Acc: 0.510017. Loss: 1.358780. Batch_acc: 0.510914. Batch_loss: 1.347306 \n",
      "Batch: 1388. Acc: 0.509996. Loss: 1.358818. Batch_acc: 0.481265. Batch_loss: 1.413569 \n",
      "Batch: 1389. Acc: 0.510006. Loss: 1.358800. Batch_acc: 0.524005. Batch_loss: 1.332038 \n",
      "Batch: 1390. Acc: 0.510001. Loss: 1.358809. Batch_acc: 0.502636. Batch_loss: 1.372694 \n",
      "Batch: 1391. Acc: 0.509993. Loss: 1.358801. Batch_acc: 0.499717. Batch_loss: 1.347553 \n",
      "Batch: 1392. Acc: 0.509986. Loss: 1.358803. Batch_acc: 0.499146. Batch_loss: 1.361626 \n",
      "Batch: 1393. Acc: 0.509972. Loss: 1.358846. Batch_acc: 0.490588. Batch_loss: 1.420376 \n",
      "Batch: 1394. Acc: 0.509977. Loss: 1.358833. Batch_acc: 0.517479. Batch_loss: 1.340569 \n",
      "Batch: 1395. Acc: 0.509966. Loss: 1.358850. Batch_acc: 0.494048. Batch_loss: 1.383659 \n",
      "Batch: 1396. Acc: 0.509976. Loss: 1.358824. Batch_acc: 0.522883. Batch_loss: 1.322416 \n",
      "Batch: 1397. Acc: 0.509975. Loss: 1.358833. Batch_acc: 0.508475. Batch_loss: 1.371361 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1398. Acc: 0.509991. Loss: 1.358794. Batch_acc: 0.532230. Batch_loss: 1.304054 \n",
      "Batch: 1399. Acc: 0.509994. Loss: 1.358792. Batch_acc: 0.515256. Batch_loss: 1.357236 \n",
      "Batch: 1400. Acc: 0.509991. Loss: 1.358782. Batch_acc: 0.505501. Batch_loss: 1.344496 \n",
      "Batch: 1401. Acc: 0.509991. Loss: 1.358782. Batch_acc: 0.509091. Batch_loss: 1.358615 \n",
      "Batch: 1402. Acc: 0.509997. Loss: 1.358785. Batch_acc: 0.518476. Batch_loss: 1.362312 \n",
      "Batch: 1403. Acc: 0.509987. Loss: 1.358792. Batch_acc: 0.496852. Batch_loss: 1.368519 \n",
      "Batch: 1404. Acc: 0.509993. Loss: 1.358782. Batch_acc: 0.517579. Batch_loss: 1.344700 \n",
      "Batch: 1405. Acc: 0.509996. Loss: 1.358769. Batch_acc: 0.514121. Batch_loss: 1.341517 \n",
      "Batch: 1406. Acc: 0.510001. Loss: 1.358767. Batch_acc: 0.517161. Batch_loss: 1.354695 \n",
      "Batch: 1407. Acc: 0.510018. Loss: 1.358724. Batch_acc: 0.534562. Batch_loss: 1.298552 \n",
      "Batch: 1408. Acc: 0.510029. Loss: 1.358696. Batch_acc: 0.524913. Batch_loss: 1.319126 \n",
      "Batch: 1409. Acc: 0.510010. Loss: 1.358713. Batch_acc: 0.483626. Batch_loss: 1.383552 \n",
      "Batch: 1410. Acc: 0.510018. Loss: 1.358698. Batch_acc: 0.521216. Batch_loss: 1.336917 \n",
      "Batch: 1411. Acc: 0.510022. Loss: 1.358682. Batch_acc: 0.515832. Batch_loss: 1.336342 \n",
      "Batch: 1412. Acc: 0.510034. Loss: 1.358674. Batch_acc: 0.526226. Batch_loss: 1.348168 \n",
      "Batch: 1413. Acc: 0.510037. Loss: 1.358655. Batch_acc: 0.514480. Batch_loss: 1.332281 \n",
      "Batch: 1414. Acc: 0.510045. Loss: 1.358621. Batch_acc: 0.520737. Batch_loss: 1.309520 \n",
      "Batch: 1415. Acc: 0.510056. Loss: 1.358597. Batch_acc: 0.526316. Batch_loss: 1.324547 \n",
      "Batch: 1416. Acc: 0.510064. Loss: 1.358566. Batch_acc: 0.521790. Batch_loss: 1.314567 \n",
      "Batch: 1417. Acc: 0.510045. Loss: 1.358583. Batch_acc: 0.483447. Batch_loss: 1.382879 \n",
      "Batch: 1418. Acc: 0.510046. Loss: 1.358578. Batch_acc: 0.510626. Batch_loss: 1.352066 \n",
      "Batch: 1419. Acc: 0.510066. Loss: 1.358539. Batch_acc: 0.539766. Batch_loss: 1.301803 \n",
      "Batch: 1420. Acc: 0.510057. Loss: 1.358551. Batch_acc: 0.496262. Batch_loss: 1.374779 \n",
      "Batch: 1421. Acc: 0.510068. Loss: 1.358516. Batch_acc: 0.526377. Batch_loss: 1.308976 \n",
      "Batch: 1422. Acc: 0.510056. Loss: 1.358525. Batch_acc: 0.492398. Batch_loss: 1.371689 \n",
      "Batch: 1423. Acc: 0.510030. Loss: 1.358595. Batch_acc: 0.471765. Batch_loss: 1.460061 \n",
      "Batch: 1424. Acc: 0.510024. Loss: 1.358615. Batch_acc: 0.501740. Batch_loss: 1.386987 \n",
      "Batch: 1425. Acc: 0.510032. Loss: 1.358600. Batch_acc: 0.520999. Batch_loss: 1.338789 \n",
      "Batch: 1426. Acc: 0.510025. Loss: 1.358620. Batch_acc: 0.500289. Batch_loss: 1.386139 \n",
      "Batch: 1427. Acc: 0.510037. Loss: 1.358596. Batch_acc: 0.527453. Batch_loss: 1.324183 \n",
      "Batch: 1428. Acc: 0.510022. Loss: 1.358622. Batch_acc: 0.489601. Batch_loss: 1.394552 \n",
      "Batch: 1429. Acc: 0.510034. Loss: 1.358585. Batch_acc: 0.526375. Batch_loss: 1.307029 \n",
      "Batch: 1430. Acc: 0.510036. Loss: 1.358593. Batch_acc: 0.513683. Batch_loss: 1.369333 \n",
      "Batch: 1431. Acc: 0.510035. Loss: 1.358588. Batch_acc: 0.508544. Batch_loss: 1.351820 \n",
      "Batch: 1432. Acc: 0.510054. Loss: 1.358519. Batch_acc: 0.537048. Batch_loss: 1.260435 \n",
      "Batch: 1433. Acc: 0.510050. Loss: 1.358537. Batch_acc: 0.503534. Batch_loss: 1.384972 \n",
      "Batch: 1434. Acc: 0.510051. Loss: 1.358514. Batch_acc: 0.511798. Batch_loss: 1.325823 \n",
      "Batch: 1435. Acc: 0.510045. Loss: 1.358521. Batch_acc: 0.502022. Batch_loss: 1.368718 \n",
      "Batch: 1436. Acc: 0.510038. Loss: 1.358535. Batch_acc: 0.499133. Batch_loss: 1.378142 \n",
      "Batch: 1437. Acc: 0.510051. Loss: 1.358493. Batch_acc: 0.528555. Batch_loss: 1.297610 \n",
      "Batch: 1438. Acc: 0.510062. Loss: 1.358475. Batch_acc: 0.525714. Batch_loss: 1.332860 \n",
      "Batch: 1439. Acc: 0.510081. Loss: 1.358424. Batch_acc: 0.537373. Batch_loss: 1.286225 \n",
      "Batch: 1440. Acc: 0.510076. Loss: 1.358447. Batch_acc: 0.503181. Batch_loss: 1.391075 \n",
      "Batch: 1441. Acc: 0.510100. Loss: 1.358382. Batch_acc: 0.543810. Batch_loss: 1.266760 \n",
      "Batch: 1442. Acc: 0.510104. Loss: 1.358363. Batch_acc: 0.516332. Batch_loss: 1.331464 \n",
      "Batch: 1443. Acc: 0.510098. Loss: 1.358390. Batch_acc: 0.501466. Batch_loss: 1.397885 \n",
      "Batch: 1444. Acc: 0.510110. Loss: 1.358348. Batch_acc: 0.526257. Batch_loss: 1.299751 \n",
      "Batch: 1445. Acc: 0.510119. Loss: 1.358320. Batch_acc: 0.522688. Batch_loss: 1.317564 \n",
      "Batch: 1446. Acc: 0.510122. Loss: 1.358299. Batch_acc: 0.515789. Batch_loss: 1.326949 \n",
      "Batch: 1447. Acc: 0.510110. Loss: 1.358340. Batch_acc: 0.492787. Batch_loss: 1.417700 \n",
      "Batch: 1448. Acc: 0.510113. Loss: 1.358346. Batch_acc: 0.513607. Batch_loss: 1.367998 \n",
      "Batch: 1449. Acc: 0.510104. Loss: 1.358360. Batch_acc: 0.497354. Batch_loss: 1.379622 \n",
      "Batch: 1450. Acc: 0.510115. Loss: 1.358323. Batch_acc: 0.524986. Batch_loss: 1.305585 \n",
      "Batch: 1451. Acc: 0.510099. Loss: 1.358352. Batch_acc: 0.488027. Batch_loss: 1.399495 \n",
      "Batch: 1452. Acc: 0.510104. Loss: 1.358340. Batch_acc: 0.517059. Batch_loss: 1.341462 \n",
      "Batch: 1453. Acc: 0.510110. Loss: 1.358346. Batch_acc: 0.518884. Batch_loss: 1.366657 \n",
      "Batch: 1454. Acc: 0.510103. Loss: 1.358357. Batch_acc: 0.500000. Batch_loss: 1.374651 \n",
      "Batch: 1455. Acc: 0.510107. Loss: 1.358352. Batch_acc: 0.515398. Batch_loss: 1.350317 \n",
      "Batch: 1456. Acc: 0.510110. Loss: 1.358326. Batch_acc: 0.515341. Batch_loss: 1.320723 \n",
      "Batch: 1457. Acc: 0.510126. Loss: 1.358272. Batch_acc: 0.532194. Batch_loss: 1.280794 \n",
      "Batch: 1458. Acc: 0.510138. Loss: 1.358225. Batch_acc: 0.527841. Batch_loss: 1.290782 \n",
      "Batch: 1459. Acc: 0.510144. Loss: 1.358195. Batch_acc: 0.519384. Batch_loss: 1.314897 \n",
      "Batch: 1460. Acc: 0.510160. Loss: 1.358134. Batch_acc: 0.532731. Batch_loss: 1.270893 \n",
      "Batch: 1461. Acc: 0.510167. Loss: 1.358108. Batch_acc: 0.520761. Batch_loss: 1.320119 \n",
      "Batch: 1462. Acc: 0.510177. Loss: 1.358084. Batch_acc: 0.524942. Batch_loss: 1.322384 \n",
      "Batch: 1463. Acc: 0.510166. Loss: 1.358100. Batch_acc: 0.493955. Batch_loss: 1.381453 \n",
      "Batch: 1464. Acc: 0.510155. Loss: 1.358150. Batch_acc: 0.493402. Batch_loss: 1.430291 \n",
      "Batch: 1465. Acc: 0.510158. Loss: 1.358157. Batch_acc: 0.514420. Batch_loss: 1.369265 \n",
      "Batch: 1466. Acc: 0.510172. Loss: 1.358124. Batch_acc: 0.530963. Batch_loss: 1.309525 \n",
      "Batch: 1467. Acc: 0.510163. Loss: 1.358119. Batch_acc: 0.496532. Batch_loss: 1.351486 \n",
      "Batch: 1468. Acc: 0.510183. Loss: 1.358058. Batch_acc: 0.540448. Batch_loss: 1.268366 \n",
      "Batch: 1469. Acc: 0.510203. Loss: 1.358001. Batch_acc: 0.539701. Batch_loss: 1.273775 \n",
      "Batch: 1470. Acc: 0.510212. Loss: 1.357950. Batch_acc: 0.523138. Batch_loss: 1.284250 \n",
      "Batch: 1471. Acc: 0.510226. Loss: 1.357911. Batch_acc: 0.530495. Batch_loss: 1.301836 \n",
      "Batch: 1472. Acc: 0.510253. Loss: 1.357843. Batch_acc: 0.549488. Batch_loss: 1.258635 \n",
      "Batch: 1473. Acc: 0.510257. Loss: 1.357817. Batch_acc: 0.515961. Batch_loss: 1.319100 \n",
      "Batch: 1474. Acc: 0.510250. Loss: 1.357828. Batch_acc: 0.499712. Batch_loss: 1.373626 \n",
      "Batch: 1475. Acc: 0.510256. Loss: 1.357813. Batch_acc: 0.519318. Batch_loss: 1.335625 \n",
      "Batch: 1476. Acc: 0.510268. Loss: 1.357759. Batch_acc: 0.528014. Batch_loss: 1.279760 \n",
      "Batch: 1477. Acc: 0.510264. Loss: 1.357766. Batch_acc: 0.504269. Batch_loss: 1.368705 \n",
      "Batch: 1478. Acc: 0.510277. Loss: 1.357751. Batch_acc: 0.529412. Batch_loss: 1.334549 \n",
      "Batch: 1479. Acc: 0.510295. Loss: 1.357702. Batch_acc: 0.536041. Batch_loss: 1.286820 \n",
      "Batch: 1480. Acc: 0.510298. Loss: 1.357685. Batch_acc: 0.515309. Batch_loss: 1.332494 \n",
      "Batch: 1481. Acc: 0.510285. Loss: 1.357740. Batch_acc: 0.489893. Batch_loss: 1.441362 \n",
      "Batch: 1482. Acc: 0.510293. Loss: 1.357720. Batch_acc: 0.522088. Batch_loss: 1.328727 \n",
      "Batch: 1483. Acc: 0.510287. Loss: 1.357731. Batch_acc: 0.502803. Batch_loss: 1.373625 \n",
      "Batch: 1484. Acc: 0.510293. Loss: 1.357706. Batch_acc: 0.518454. Batch_loss: 1.320263 \n",
      "Batch: 1485. Acc: 0.510289. Loss: 1.357721. Batch_acc: 0.504860. Batch_loss: 1.379453 \n",
      "Batch: 1486. Acc: 0.510286. Loss: 1.357742. Batch_acc: 0.505125. Batch_loss: 1.388086 \n",
      "Batch: 1487. Acc: 0.510300. Loss: 1.357704. Batch_acc: 0.531704. Batch_loss: 1.301837 \n",
      "Batch: 1488. Acc: 0.510326. Loss: 1.357635. Batch_acc: 0.548703. Batch_loss: 1.254379 \n",
      "Batch: 1489. Acc: 0.510347. Loss: 1.357583. Batch_acc: 0.540662. Batch_loss: 1.281355 \n",
      "Batch: 1490. Acc: 0.510347. Loss: 1.357592. Batch_acc: 0.510864. Batch_loss: 1.370499 \n",
      "Batch: 1491. Acc: 0.510358. Loss: 1.357562. Batch_acc: 0.527335. Batch_loss: 1.314297 \n",
      "Batch: 1492. Acc: 0.510350. Loss: 1.357587. Batch_acc: 0.497406. Batch_loss: 1.394892 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1493. Acc: 0.510333. Loss: 1.357620. Batch_acc: 0.485634. Batch_loss: 1.405387 \n",
      "Batch: 1494. Acc: 0.510325. Loss: 1.357629. Batch_acc: 0.497969. Batch_loss: 1.370960 \n",
      "Batch: 1495. Acc: 0.510329. Loss: 1.357618. Batch_acc: 0.516110. Batch_loss: 1.341743 \n",
      "Batch: 1496. Acc: 0.510333. Loss: 1.357605. Batch_acc: 0.517341. Batch_loss: 1.337117 \n",
      "Batch: 1497. Acc: 0.510348. Loss: 1.357570. Batch_acc: 0.532453. Batch_loss: 1.305774 \n",
      "Batch: 1498. Acc: 0.510357. Loss: 1.357547. Batch_acc: 0.523349. Batch_loss: 1.323936 \n",
      "Batch: 1499. Acc: 0.510367. Loss: 1.357522. Batch_acc: 0.525560. Batch_loss: 1.319475 \n",
      "Batch: 1500. Acc: 0.510375. Loss: 1.357503. Batch_acc: 0.523121. Batch_loss: 1.329680 \n",
      "Batch: 1501. Acc: 0.510380. Loss: 1.357482. Batch_acc: 0.517730. Batch_loss: 1.325177 \n",
      "Batch: 1502. Acc: 0.510390. Loss: 1.357465. Batch_acc: 0.525761. Batch_loss: 1.330079 \n",
      "Batch: 1503. Acc: 0.510398. Loss: 1.357446. Batch_acc: 0.521640. Batch_loss: 1.329676 \n",
      "Batch: 1504. Acc: 0.510385. Loss: 1.357480. Batch_acc: 0.491700. Batch_loss: 1.408308 \n",
      "Batch: 1505. Acc: 0.510390. Loss: 1.357459. Batch_acc: 0.517183. Batch_loss: 1.326493 \n",
      "Batch: 1506. Acc: 0.510400. Loss: 1.357427. Batch_acc: 0.526132. Batch_loss: 1.308632 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.5104002834081046. Loss per char: 1.3574266994806932. Time: 1627219152.5407531\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 84, 85, 66,\n",
      "        79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 22, 26, 19, 26, 18,  1,\n",
      "        66, 79, 69,  1, 14, 17, 15, 20, 18, 19, 24, 25, 24, 24, 32,  3,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.510416. Loss: 1.357396. Batch_acc: 0.534513. Batch_loss: 1.309322 \n",
      "Batch: 1508. Acc: 0.510413. Loss: 1.357406. Batch_acc: 0.505828. Batch_loss: 1.373168 \n",
      "Batch: 1509. Acc: 0.510407. Loss: 1.357411. Batch_acc: 0.501153. Batch_loss: 1.364690 \n",
      "Batch: 1510. Acc: 0.510425. Loss: 1.357371. Batch_acc: 0.537536. Batch_loss: 1.297376 \n",
      "Batch: 1511. Acc: 0.510423. Loss: 1.357384. Batch_acc: 0.507437. Batch_loss: 1.377733 \n",
      "Batch: 1512. Acc: 0.510439. Loss: 1.357332. Batch_acc: 0.534424. Batch_loss: 1.279013 \n",
      "Batch: 1513. Acc: 0.510440. Loss: 1.357327. Batch_acc: 0.512291. Batch_loss: 1.350108 \n",
      "Batch: 1514. Acc: 0.510437. Loss: 1.357321. Batch_acc: 0.506271. Batch_loss: 1.349567 \n",
      "Batch: 1515. Acc: 0.510440. Loss: 1.357319. Batch_acc: 0.513815. Batch_loss: 1.353357 \n",
      "Batch: 1516. Acc: 0.510450. Loss: 1.357315. Batch_acc: 0.526346. Batch_loss: 1.351918 \n",
      "Batch: 1517. Acc: 0.510453. Loss: 1.357333. Batch_acc: 0.515499. Batch_loss: 1.383472 \n",
      "Batch: 1518. Acc: 0.510465. Loss: 1.357307. Batch_acc: 0.528302. Batch_loss: 1.318188 \n",
      "Batch: 1519. Acc: 0.510451. Loss: 1.357338. Batch_acc: 0.488889. Batch_loss: 1.403779 \n",
      "Batch: 1520. Acc: 0.510449. Loss: 1.357337. Batch_acc: 0.507611. Batch_loss: 1.357040 \n",
      "Batch: 1521. Acc: 0.510436. Loss: 1.357370. Batch_acc: 0.490357. Batch_loss: 1.407330 \n",
      "Batch: 1522. Acc: 0.510432. Loss: 1.357403. Batch_acc: 0.503803. Batch_loss: 1.408793 \n",
      "Batch: 1523. Acc: 0.510447. Loss: 1.357368. Batch_acc: 0.533179. Batch_loss: 1.304131 \n",
      "Batch: 1524. Acc: 0.510448. Loss: 1.357373. Batch_acc: 0.512152. Batch_loss: 1.364494 \n",
      "Batch: 1525. Acc: 0.510434. Loss: 1.357393. Batch_acc: 0.489225. Batch_loss: 1.389129 \n",
      "Batch: 1526. Acc: 0.510442. Loss: 1.357368. Batch_acc: 0.522067. Batch_loss: 1.318268 \n",
      "Batch: 1527. Acc: 0.510451. Loss: 1.357342. Batch_acc: 0.524327. Batch_loss: 1.317877 \n",
      "Batch: 1528. Acc: 0.510474. Loss: 1.357297. Batch_acc: 0.545246. Batch_loss: 1.289720 \n",
      "Batch: 1529. Acc: 0.510470. Loss: 1.357300. Batch_acc: 0.505161. Batch_loss: 1.360670 \n",
      "Batch: 1530. Acc: 0.510482. Loss: 1.357267. Batch_acc: 0.529208. Batch_loss: 1.307300 \n",
      "Batch: 1531. Acc: 0.510487. Loss: 1.357274. Batch_acc: 0.516704. Batch_loss: 1.367431 \n",
      "Batch: 1532. Acc: 0.510498. Loss: 1.357240. Batch_acc: 0.528045. Batch_loss: 1.305968 \n",
      "Batch: 1533. Acc: 0.510511. Loss: 1.357213. Batch_acc: 0.529649. Batch_loss: 1.316186 \n",
      "Batch: 1534. Acc: 0.510502. Loss: 1.357237. Batch_acc: 0.496101. Batch_loss: 1.395774 \n",
      "Batch: 1535. Acc: 0.510508. Loss: 1.357230. Batch_acc: 0.520367. Batch_loss: 1.345292 \n",
      "Batch: 1536. Acc: 0.510515. Loss: 1.357220. Batch_acc: 0.521253. Batch_loss: 1.343439 \n",
      "Batch: 1537. Acc: 0.510523. Loss: 1.357198. Batch_acc: 0.521968. Batch_loss: 1.321585 \n",
      "Batch: 1538. Acc: 0.510530. Loss: 1.357193. Batch_acc: 0.522554. Batch_loss: 1.349474 \n",
      "Batch: 1539. Acc: 0.510548. Loss: 1.357150. Batch_acc: 0.538286. Batch_loss: 1.291869 \n",
      "Batch: 1540. Acc: 0.510552. Loss: 1.357143. Batch_acc: 0.515488. Batch_loss: 1.346149 \n",
      "Batch: 1541. Acc: 0.510547. Loss: 1.357156. Batch_acc: 0.502847. Batch_loss: 1.376685 \n",
      "Batch: 1542. Acc: 0.510554. Loss: 1.357140. Batch_acc: 0.522701. Batch_loss: 1.332947 \n",
      "Batch: 1543. Acc: 0.510531. Loss: 1.357210. Batch_acc: 0.473839. Batch_loss: 1.467299 \n",
      "Batch: 1544. Acc: 0.510532. Loss: 1.357202. Batch_acc: 0.512125. Batch_loss: 1.344731 \n",
      "Batch: 1545. Acc: 0.510514. Loss: 1.357223. Batch_acc: 0.482143. Batch_loss: 1.389673 \n",
      "Batch: 1546. Acc: 0.510524. Loss: 1.357193. Batch_acc: 0.526678. Batch_loss: 1.311597 \n",
      "Batch: 1547. Acc: 0.510533. Loss: 1.357164. Batch_acc: 0.524695. Batch_loss: 1.311620 \n",
      "Batch: 1548. Acc: 0.510554. Loss: 1.357116. Batch_acc: 0.542245. Batch_loss: 1.281674 \n",
      "Batch: 1549. Acc: 0.510547. Loss: 1.357136. Batch_acc: 0.500866. Batch_loss: 1.389332 \n",
      "Batch: 1550. Acc: 0.510545. Loss: 1.357150. Batch_acc: 0.507675. Batch_loss: 1.377823 \n",
      "Batch: 1551. Acc: 0.510548. Loss: 1.357148. Batch_acc: 0.515083. Batch_loss: 1.353663 \n",
      "Batch: 1552. Acc: 0.510568. Loss: 1.357106. Batch_acc: 0.540602. Batch_loss: 1.293848 \n",
      "Batch: 1553. Acc: 0.510574. Loss: 1.357082. Batch_acc: 0.520185. Batch_loss: 1.319579 \n",
      "Batch: 1554. Acc: 0.510566. Loss: 1.357104. Batch_acc: 0.497394. Batch_loss: 1.391083 \n",
      "Batch: 1555. Acc: 0.510572. Loss: 1.357080. Batch_acc: 0.519641. Batch_loss: 1.320513 \n",
      "Batch: 1556. Acc: 0.510570. Loss: 1.357075. Batch_acc: 0.507927. Batch_loss: 1.349976 \n",
      "Batch: 1557. Acc: 0.510576. Loss: 1.357046. Batch_acc: 0.520735. Batch_loss: 1.310014 \n",
      "Batch: 1558. Acc: 0.510568. Loss: 1.357066. Batch_acc: 0.496812. Batch_loss: 1.388123 \n",
      "Batch: 1559. Acc: 0.510563. Loss: 1.357065. Batch_acc: 0.503982. Batch_loss: 1.355684 \n",
      "Batch: 1560. Acc: 0.510564. Loss: 1.357075. Batch_acc: 0.510800. Batch_loss: 1.373279 \n",
      "Batch: 1561. Acc: 0.510557. Loss: 1.357082. Batch_acc: 0.499398. Batch_loss: 1.368545 \n",
      "Batch: 1562. Acc: 0.510565. Loss: 1.357062. Batch_acc: 0.523590. Batch_loss: 1.325320 \n",
      "Batch: 1563. Acc: 0.510580. Loss: 1.357021. Batch_acc: 0.534602. Batch_loss: 1.293017 \n",
      "Batch: 1564. Acc: 0.510577. Loss: 1.357012. Batch_acc: 0.504646. Batch_loss: 1.342534 \n",
      "Batch: 1565. Acc: 0.510576. Loss: 1.357004. Batch_acc: 0.509793. Batch_loss: 1.344224 \n",
      "Batch: 1566. Acc: 0.510574. Loss: 1.357011. Batch_acc: 0.507357. Batch_loss: 1.368577 \n",
      "Batch: 1567. Acc: 0.510591. Loss: 1.357002. Batch_acc: 0.536842. Batch_loss: 1.342599 \n",
      "Batch: 1568. Acc: 0.510579. Loss: 1.357024. Batch_acc: 0.491991. Batch_loss: 1.390778 \n",
      "Batch: 1569. Acc: 0.510570. Loss: 1.357035. Batch_acc: 0.496800. Batch_loss: 1.375456 \n",
      "Batch: 1570. Acc: 0.510566. Loss: 1.357041. Batch_acc: 0.503488. Batch_loss: 1.366414 \n",
      "Batch: 1571. Acc: 0.510574. Loss: 1.357024. Batch_acc: 0.524419. Batch_loss: 1.329470 \n",
      "Batch: 1572. Acc: 0.510585. Loss: 1.357008. Batch_acc: 0.526670. Batch_loss: 1.332916 \n",
      "Batch: 1573. Acc: 0.510578. Loss: 1.357032. Batch_acc: 0.499413. Batch_loss: 1.396264 \n",
      "Batch: 1574. Acc: 0.510596. Loss: 1.356983. Batch_acc: 0.539165. Batch_loss: 1.279730 \n",
      "Batch: 1575. Acc: 0.510594. Loss: 1.357014. Batch_acc: 0.508000. Batch_loss: 1.404760 \n",
      "Batch: 1576. Acc: 0.510587. Loss: 1.357013. Batch_acc: 0.499123. Batch_loss: 1.356143 \n",
      "Batch: 1577. Acc: 0.510605. Loss: 1.356953. Batch_acc: 0.538196. Batch_loss: 1.262087 \n",
      "Batch: 1578. Acc: 0.510609. Loss: 1.356949. Batch_acc: 0.517121. Batch_loss: 1.350692 \n",
      "Batch: 1579. Acc: 0.510619. Loss: 1.356950. Batch_acc: 0.526223. Batch_loss: 1.358979 \n",
      "Batch: 1580. Acc: 0.510625. Loss: 1.356936. Batch_acc: 0.521396. Batch_loss: 1.335735 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1581. Acc: 0.510625. Loss: 1.356942. Batch_acc: 0.510321. Batch_loss: 1.365306 \n",
      "Batch: 1582. Acc: 0.510641. Loss: 1.356901. Batch_acc: 0.536290. Batch_loss: 1.292114 \n",
      "Batch: 1583. Acc: 0.510646. Loss: 1.356893. Batch_acc: 0.517919. Batch_loss: 1.343855 \n",
      "Batch: 1584. Acc: 0.510652. Loss: 1.356894. Batch_acc: 0.519796. Batch_loss: 1.358436 \n",
      "Batch: 1585. Acc: 0.510678. Loss: 1.356826. Batch_acc: 0.550549. Batch_loss: 1.254648 \n",
      "Batch: 1586. Acc: 0.510698. Loss: 1.356776. Batch_acc: 0.542078. Batch_loss: 1.276477 \n",
      "Batch: 1587. Acc: 0.510708. Loss: 1.356762. Batch_acc: 0.526964. Batch_loss: 1.334508 \n",
      "Batch: 1588. Acc: 0.510711. Loss: 1.356773. Batch_acc: 0.515116. Batch_loss: 1.374496 \n",
      "Batch: 1589. Acc: 0.510728. Loss: 1.356734. Batch_acc: 0.538773. Batch_loss: 1.293602 \n",
      "Batch: 1590. Acc: 0.510733. Loss: 1.356738. Batch_acc: 0.518797. Batch_loss: 1.363824 \n",
      "Batch: 1591. Acc: 0.510736. Loss: 1.356729. Batch_acc: 0.514525. Batch_loss: 1.343032 \n",
      "Batch: 1592. Acc: 0.510743. Loss: 1.356711. Batch_acc: 0.522741. Batch_loss: 1.326512 \n",
      "Batch: 1593. Acc: 0.510752. Loss: 1.356678. Batch_acc: 0.524349. Batch_loss: 1.305854 \n",
      "Batch: 1594. Acc: 0.510749. Loss: 1.356686. Batch_acc: 0.505841. Batch_loss: 1.369502 \n",
      "Batch: 1595. Acc: 0.510751. Loss: 1.356678. Batch_acc: 0.515222. Batch_loss: 1.343782 \n",
      "Batch: 1596. Acc: 0.510751. Loss: 1.356684. Batch_acc: 0.509423. Batch_loss: 1.366158 \n",
      "Batch: 1597. Acc: 0.510749. Loss: 1.356675. Batch_acc: 0.508671. Batch_loss: 1.341553 \n",
      "Batch: 1598. Acc: 0.510734. Loss: 1.356687. Batch_acc: 0.487165. Batch_loss: 1.376871 \n",
      "Batch: 1599. Acc: 0.510727. Loss: 1.356700. Batch_acc: 0.499145. Batch_loss: 1.377219 \n",
      "Batch: 1600. Acc: 0.510734. Loss: 1.356675. Batch_acc: 0.521071. Batch_loss: 1.316900 \n",
      "Batch: 1601. Acc: 0.510741. Loss: 1.356653. Batch_acc: 0.522465. Batch_loss: 1.321667 \n",
      "Batch: 1602. Acc: 0.510746. Loss: 1.356637. Batch_acc: 0.518187. Batch_loss: 1.331264 \n",
      "Batch: 1603. Acc: 0.510741. Loss: 1.356647. Batch_acc: 0.502948. Batch_loss: 1.372725 \n",
      "Batch: 1604. Acc: 0.510727. Loss: 1.356673. Batch_acc: 0.488279. Batch_loss: 1.398497 \n",
      "Batch: 1605. Acc: 0.510720. Loss: 1.356675. Batch_acc: 0.500287. Batch_loss: 1.359108 \n",
      "Batch: 1606. Acc: 0.510722. Loss: 1.356666. Batch_acc: 0.512619. Batch_loss: 1.343761 \n",
      "Batch: 1607. Acc: 0.510722. Loss: 1.356657. Batch_acc: 0.511721. Batch_loss: 1.340919 \n",
      "Batch: 1608. Acc: 0.510736. Loss: 1.356613. Batch_acc: 0.532285. Batch_loss: 1.288844 \n",
      "Batch: 1609. Acc: 0.510748. Loss: 1.356594. Batch_acc: 0.530197. Batch_loss: 1.324323 \n",
      "Batch: 1610. Acc: 0.510745. Loss: 1.356600. Batch_acc: 0.506314. Batch_loss: 1.367144 \n",
      "Batch: 1611. Acc: 0.510755. Loss: 1.356566. Batch_acc: 0.526134. Batch_loss: 1.302194 \n",
      "Batch: 1612. Acc: 0.510750. Loss: 1.356571. Batch_acc: 0.503394. Batch_loss: 1.363786 \n",
      "Batch: 1613. Acc: 0.510758. Loss: 1.356553. Batch_acc: 0.524114. Batch_loss: 1.327772 \n",
      "Batch: 1614. Acc: 0.510769. Loss: 1.356523. Batch_acc: 0.527105. Batch_loss: 1.307573 \n",
      "Batch: 1615. Acc: 0.510764. Loss: 1.356510. Batch_acc: 0.503492. Batch_loss: 1.335243 \n",
      "Batch: 1616. Acc: 0.510767. Loss: 1.356499. Batch_acc: 0.515204. Batch_loss: 1.339931 \n",
      "Batch: 1617. Acc: 0.510776. Loss: 1.356474. Batch_acc: 0.525385. Batch_loss: 1.316468 \n",
      "Batch: 1618. Acc: 0.510782. Loss: 1.356468. Batch_acc: 0.520118. Batch_loss: 1.346114 \n",
      "Batch: 1619. Acc: 0.510787. Loss: 1.356464. Batch_acc: 0.518879. Batch_loss: 1.350065 \n",
      "Batch: 1620. Acc: 0.510784. Loss: 1.356470. Batch_acc: 0.505841. Batch_loss: 1.366603 \n",
      "Batch: 1621. Acc: 0.510791. Loss: 1.356462. Batch_acc: 0.522872. Batch_loss: 1.342404 \n",
      "Batch: 1622. Acc: 0.510808. Loss: 1.356434. Batch_acc: 0.538860. Batch_loss: 1.311209 \n",
      "Batch: 1623. Acc: 0.510818. Loss: 1.356413. Batch_acc: 0.526069. Batch_loss: 1.322000 \n",
      "Batch: 1624. Acc: 0.510829. Loss: 1.356389. Batch_acc: 0.529412. Batch_loss: 1.317559 \n",
      "Batch: 1625. Acc: 0.510849. Loss: 1.356349. Batch_acc: 0.541877. Batch_loss: 1.292894 \n",
      "Batch: 1626. Acc: 0.510850. Loss: 1.356338. Batch_acc: 0.512478. Batch_loss: 1.339209 \n",
      "Batch: 1627. Acc: 0.510853. Loss: 1.356307. Batch_acc: 0.516900. Batch_loss: 1.304469 \n",
      "Batch: 1628. Acc: 0.510868. Loss: 1.356284. Batch_acc: 0.533986. Batch_loss: 1.318635 \n",
      "Batch: 1629. Acc: 0.510865. Loss: 1.356291. Batch_acc: 0.507366. Batch_loss: 1.367992 \n",
      "Batch: 1630. Acc: 0.510862. Loss: 1.356311. Batch_acc: 0.505300. Batch_loss: 1.390319 \n",
      "Batch: 1631. Acc: 0.510867. Loss: 1.356309. Batch_acc: 0.518966. Batch_loss: 1.352862 \n",
      "Batch: 1632. Acc: 0.510871. Loss: 1.356318. Batch_acc: 0.517847. Batch_loss: 1.370797 \n",
      "Batch: 1633. Acc: 0.510873. Loss: 1.356313. Batch_acc: 0.513560. Batch_loss: 1.347780 \n",
      "Batch: 1634. Acc: 0.510879. Loss: 1.356301. Batch_acc: 0.519839. Batch_loss: 1.336619 \n",
      "Batch: 1635. Acc: 0.510899. Loss: 1.356273. Batch_acc: 0.543810. Batch_loss: 1.312061 \n",
      "Batch: 1636. Acc: 0.510916. Loss: 1.356228. Batch_acc: 0.537806. Batch_loss: 1.283154 \n",
      "Batch: 1637. Acc: 0.510904. Loss: 1.356256. Batch_acc: 0.491898. Batch_loss: 1.402089 \n",
      "Batch: 1638. Acc: 0.510903. Loss: 1.356261. Batch_acc: 0.509390. Batch_loss: 1.364500 \n",
      "Batch: 1639. Acc: 0.510924. Loss: 1.356218. Batch_acc: 0.544275. Batch_loss: 1.286989 \n",
      "Batch: 1640. Acc: 0.510935. Loss: 1.356185. Batch_acc: 0.528879. Batch_loss: 1.303482 \n",
      "Batch: 1641. Acc: 0.510950. Loss: 1.356134. Batch_acc: 0.535267. Batch_loss: 1.273704 \n",
      "Batch: 1642. Acc: 0.510953. Loss: 1.356134. Batch_acc: 0.515850. Batch_loss: 1.355859 \n",
      "Batch: 1643. Acc: 0.510967. Loss: 1.356093. Batch_acc: 0.532764. Batch_loss: 1.288905 \n",
      "Batch: 1644. Acc: 0.510955. Loss: 1.356112. Batch_acc: 0.491448. Batch_loss: 1.386769 \n",
      "Batch: 1645. Acc: 0.510966. Loss: 1.356075. Batch_acc: 0.529825. Batch_loss: 1.294538 \n",
      "Batch: 1646. Acc: 0.510986. Loss: 1.356024. Batch_acc: 0.544820. Batch_loss: 1.270735 \n",
      "Batch: 1647. Acc: 0.510984. Loss: 1.356022. Batch_acc: 0.507629. Batch_loss: 1.353470 \n",
      "Batch: 1648. Acc: 0.510991. Loss: 1.356002. Batch_acc: 0.521815. Batch_loss: 1.322554 \n",
      "Batch: 1649. Acc: 0.511008. Loss: 1.355958. Batch_acc: 0.539205. Batch_loss: 1.284769 \n",
      "Batch: 1650. Acc: 0.511003. Loss: 1.355991. Batch_acc: 0.502838. Batch_loss: 1.409993 \n",
      "Batch: 1651. Acc: 0.510997. Loss: 1.355998. Batch_acc: 0.500571. Batch_loss: 1.366867 \n",
      "Batch: 1652. Acc: 0.511007. Loss: 1.355966. Batch_acc: 0.527429. Batch_loss: 1.303148 \n",
      "Batch: 1653. Acc: 0.511014. Loss: 1.355937. Batch_acc: 0.522914. Batch_loss: 1.307017 \n",
      "Batch: 1654. Acc: 0.511010. Loss: 1.355938. Batch_acc: 0.505501. Batch_loss: 1.358434 \n",
      "Batch: 1655. Acc: 0.511013. Loss: 1.355925. Batch_acc: 0.515274. Batch_loss: 1.333664 \n",
      "Batch: 1656. Acc: 0.511006. Loss: 1.355931. Batch_acc: 0.500291. Batch_loss: 1.366510 \n",
      "Batch: 1657. Acc: 0.511017. Loss: 1.355902. Batch_acc: 0.528614. Batch_loss: 1.306753 \n",
      "Batch: 1658. Acc: 0.511001. Loss: 1.355957. Batch_acc: 0.483412. Batch_loss: 1.449640 \n",
      "Batch: 1659. Acc: 0.511009. Loss: 1.355949. Batch_acc: 0.524713. Batch_loss: 1.342085 \n",
      "Batch: 1660. Acc: 0.511021. Loss: 1.355925. Batch_acc: 0.530495. Batch_loss: 1.316495 \n",
      "Batch: 1661. Acc: 0.511011. Loss: 1.355931. Batch_acc: 0.495775. Batch_loss: 1.365659 \n",
      "Batch: 1662. Acc: 0.511007. Loss: 1.355934. Batch_acc: 0.503456. Batch_loss: 1.360196 \n",
      "Batch: 1663. Acc: 0.511009. Loss: 1.355920. Batch_acc: 0.515434. Batch_loss: 1.333330 \n",
      "Batch: 1664. Acc: 0.511011. Loss: 1.355903. Batch_acc: 0.514105. Batch_loss: 1.326887 \n",
      "Batch: 1665. Acc: 0.511023. Loss: 1.355875. Batch_acc: 0.530217. Batch_loss: 1.309493 \n",
      "Batch: 1666. Acc: 0.511015. Loss: 1.355901. Batch_acc: 0.497966. Batch_loss: 1.400356 \n",
      "Batch: 1667. Acc: 0.511004. Loss: 1.355914. Batch_acc: 0.493056. Batch_loss: 1.377119 \n",
      "Batch: 1668. Acc: 0.511008. Loss: 1.355911. Batch_acc: 0.517494. Batch_loss: 1.350916 \n",
      "Batch: 1669. Acc: 0.510991. Loss: 1.355945. Batch_acc: 0.483278. Batch_loss: 1.410623 \n",
      "Batch: 1670. Acc: 0.510991. Loss: 1.355951. Batch_acc: 0.510551. Batch_loss: 1.367701 \n",
      "Batch: 1671. Acc: 0.510992. Loss: 1.355950. Batch_acc: 0.512265. Batch_loss: 1.353337 \n",
      "Batch: 1672. Acc: 0.510980. Loss: 1.355973. Batch_acc: 0.492334. Batch_loss: 1.393444 \n",
      "Batch: 1673. Acc: 0.510979. Loss: 1.355957. Batch_acc: 0.507781. Batch_loss: 1.329679 \n",
      "Batch: 1674. Acc: 0.510983. Loss: 1.355938. Batch_acc: 0.518959. Batch_loss: 1.324877 \n",
      "Batch: 1675. Acc: 0.511000. Loss: 1.355906. Batch_acc: 0.539917. Batch_loss: 1.300146 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1676. Acc: 0.511000. Loss: 1.355903. Batch_acc: 0.510240. Batch_loss: 1.351182 \n",
      "Batch: 1677. Acc: 0.511013. Loss: 1.355881. Batch_acc: 0.532801. Batch_loss: 1.319146 \n",
      "Batch: 1678. Acc: 0.511031. Loss: 1.355843. Batch_acc: 0.541002. Batch_loss: 1.293195 \n",
      "Batch: 1679. Acc: 0.511048. Loss: 1.355810. Batch_acc: 0.539511. Batch_loss: 1.300526 \n",
      "Batch: 1680. Acc: 0.511045. Loss: 1.355826. Batch_acc: 0.505009. Batch_loss: 1.383956 \n",
      "Batch: 1681. Acc: 0.511051. Loss: 1.355805. Batch_acc: 0.521295. Batch_loss: 1.320629 \n",
      "Batch: 1682. Acc: 0.511054. Loss: 1.355800. Batch_acc: 0.516828. Batch_loss: 1.348388 \n",
      "Batch: 1683. Acc: 0.511057. Loss: 1.355776. Batch_acc: 0.516716. Batch_loss: 1.314133 \n",
      "Batch: 1684. Acc: 0.511060. Loss: 1.355743. Batch_acc: 0.515734. Batch_loss: 1.299474 \n",
      "Batch: 1685. Acc: 0.511062. Loss: 1.355746. Batch_acc: 0.514617. Batch_loss: 1.360814 \n",
      "Batch: 1686. Acc: 0.511066. Loss: 1.355744. Batch_acc: 0.517816. Batch_loss: 1.352452 \n",
      "Batch: 1687. Acc: 0.511064. Loss: 1.355752. Batch_acc: 0.506264. Batch_loss: 1.368246 \n",
      "Batch: 1688. Acc: 0.511078. Loss: 1.355699. Batch_acc: 0.535093. Batch_loss: 1.269192 \n",
      "Batch: 1689. Acc: 0.511090. Loss: 1.355672. Batch_acc: 0.530251. Batch_loss: 1.310233 \n",
      "Batch: 1690. Acc: 0.511092. Loss: 1.355678. Batch_acc: 0.514448. Batch_loss: 1.365624 \n",
      "Batch: 1691. Acc: 0.511107. Loss: 1.355654. Batch_acc: 0.537204. Batch_loss: 1.315175 \n",
      "Batch: 1692. Acc: 0.511119. Loss: 1.355619. Batch_acc: 0.531196. Batch_loss: 1.297011 \n",
      "Batch: 1693. Acc: 0.511126. Loss: 1.355587. Batch_acc: 0.521690. Batch_loss: 1.302476 \n",
      "Batch: 1694. Acc: 0.511132. Loss: 1.355570. Batch_acc: 0.522780. Batch_loss: 1.326490 \n",
      "Batch: 1695. Acc: 0.511129. Loss: 1.355575. Batch_acc: 0.504939. Batch_loss: 1.364513 \n",
      "Batch: 1696. Acc: 0.511132. Loss: 1.355547. Batch_acc: 0.516676. Batch_loss: 1.306055 \n",
      "Batch: 1697. Acc: 0.511141. Loss: 1.355535. Batch_acc: 0.525982. Batch_loss: 1.335065 \n",
      "Batch: 1698. Acc: 0.511156. Loss: 1.355521. Batch_acc: 0.536713. Batch_loss: 1.332363 \n",
      "Batch: 1699. Acc: 0.511164. Loss: 1.355481. Batch_acc: 0.525708. Batch_loss: 1.287294 \n",
      "Batch: 1700. Acc: 0.511168. Loss: 1.355477. Batch_acc: 0.517181. Batch_loss: 1.348639 \n",
      "Batch: 1701. Acc: 0.511166. Loss: 1.355463. Batch_acc: 0.508065. Batch_loss: 1.331943 \n",
      "Batch: 1702. Acc: 0.511159. Loss: 1.355464. Batch_acc: 0.499139. Batch_loss: 1.356242 \n",
      "Batch: 1703. Acc: 0.511171. Loss: 1.355419. Batch_acc: 0.531465. Batch_loss: 1.279695 \n",
      "Batch: 1704. Acc: 0.511170. Loss: 1.355425. Batch_acc: 0.510453. Batch_loss: 1.365199 \n",
      "Batch: 1705. Acc: 0.511184. Loss: 1.355374. Batch_acc: 0.535301. Batch_loss: 1.268499 \n",
      "Batch: 1706. Acc: 0.511180. Loss: 1.355380. Batch_acc: 0.504127. Batch_loss: 1.365883 \n",
      "Batch: 1707. Acc: 0.511170. Loss: 1.355403. Batch_acc: 0.493842. Batch_loss: 1.395738 \n",
      "Batch: 1708. Acc: 0.511189. Loss: 1.355343. Batch_acc: 0.541998. Batch_loss: 1.254104 \n",
      "Batch: 1709. Acc: 0.511187. Loss: 1.355348. Batch_acc: 0.508206. Batch_loss: 1.364140 \n",
      "Batch: 1710. Acc: 0.511202. Loss: 1.355301. Batch_acc: 0.537004. Batch_loss: 1.272077 \n",
      "Batch: 1711. Acc: 0.511205. Loss: 1.355298. Batch_acc: 0.516618. Batch_loss: 1.350765 \n",
      "Batch: 1712. Acc: 0.511201. Loss: 1.355312. Batch_acc: 0.505166. Batch_loss: 1.377993 \n",
      "Batch: 1713. Acc: 0.511212. Loss: 1.355288. Batch_acc: 0.529278. Batch_loss: 1.315757 \n",
      "Batch: 1714. Acc: 0.511222. Loss: 1.355253. Batch_acc: 0.528355. Batch_loss: 1.296654 \n",
      "Batch: 1715. Acc: 0.511216. Loss: 1.355257. Batch_acc: 0.500000. Batch_loss: 1.361232 \n",
      "Batch: 1716. Acc: 0.511218. Loss: 1.355255. Batch_acc: 0.514318. Batch_loss: 1.353143 \n",
      "Batch: 1717. Acc: 0.511218. Loss: 1.355251. Batch_acc: 0.512776. Batch_loss: 1.347932 \n",
      "Batch: 1718. Acc: 0.511221. Loss: 1.355244. Batch_acc: 0.516222. Batch_loss: 1.342122 \n",
      "Batch: 1719. Acc: 0.511215. Loss: 1.355241. Batch_acc: 0.501157. Batch_loss: 1.351072 \n",
      "Batch: 1720. Acc: 0.511208. Loss: 1.355259. Batch_acc: 0.498833. Batch_loss: 1.386079 \n",
      "Batch: 1721. Acc: 0.511206. Loss: 1.355271. Batch_acc: 0.506636. Batch_loss: 1.376527 \n",
      "Batch: 1722. Acc: 0.511206. Loss: 1.355270. Batch_acc: 0.512429. Batch_loss: 1.352788 \n",
      "Batch: 1723. Acc: 0.511206. Loss: 1.355278. Batch_acc: 0.510086. Batch_loss: 1.370069 \n",
      "Batch: 1724. Acc: 0.511205. Loss: 1.355293. Batch_acc: 0.509143. Batch_loss: 1.380232 \n",
      "Batch: 1725. Acc: 0.511205. Loss: 1.355292. Batch_acc: 0.512265. Batch_loss: 1.354042 \n",
      "Batch: 1726. Acc: 0.511197. Loss: 1.355318. Batch_acc: 0.495892. Batch_loss: 1.400753 \n",
      "Batch: 1727. Acc: 0.511198. Loss: 1.355300. Batch_acc: 0.513482. Batch_loss: 1.324095 \n",
      "Batch: 1728. Acc: 0.511193. Loss: 1.355313. Batch_acc: 0.503452. Batch_loss: 1.377414 \n",
      "Batch: 1729. Acc: 0.511199. Loss: 1.355308. Batch_acc: 0.521216. Batch_loss: 1.347239 \n",
      "Batch: 1730. Acc: 0.511217. Loss: 1.355268. Batch_acc: 0.542323. Batch_loss: 1.284337 \n",
      "Batch: 1731. Acc: 0.511218. Loss: 1.355264. Batch_acc: 0.513756. Batch_loss: 1.348492 \n",
      "Batch: 1732. Acc: 0.511218. Loss: 1.355258. Batch_acc: 0.511073. Batch_loss: 1.345742 \n",
      "Batch: 1733. Acc: 0.511214. Loss: 1.355265. Batch_acc: 0.503192. Batch_loss: 1.367808 \n",
      "Batch: 1734. Acc: 0.511210. Loss: 1.355279. Batch_acc: 0.505526. Batch_loss: 1.378711 \n",
      "Batch: 1735. Acc: 0.511211. Loss: 1.355269. Batch_acc: 0.511455. Batch_loss: 1.339253 \n",
      "Batch: 1736. Acc: 0.511199. Loss: 1.355284. Batch_acc: 0.491349. Batch_loss: 1.380591 \n",
      "Batch: 1737. Acc: 0.511203. Loss: 1.355294. Batch_acc: 0.518605. Batch_loss: 1.373518 \n",
      "Batch: 1738. Acc: 0.511191. Loss: 1.355323. Batch_acc: 0.489655. Batch_loss: 1.404157 \n",
      "Batch: 1739. Acc: 0.511185. Loss: 1.355341. Batch_acc: 0.501168. Batch_loss: 1.387586 \n",
      "Batch: 1740. Acc: 0.511184. Loss: 1.355334. Batch_acc: 0.508611. Batch_loss: 1.343611 \n",
      "Batch: 1741. Acc: 0.511192. Loss: 1.355312. Batch_acc: 0.524600. Batch_loss: 1.317077 \n",
      "Batch: 1742. Acc: 0.511190. Loss: 1.355323. Batch_acc: 0.508319. Batch_loss: 1.375121 \n",
      "Batch: 1743. Acc: 0.511201. Loss: 1.355300. Batch_acc: 0.529607. Batch_loss: 1.316359 \n",
      "Batch: 1744. Acc: 0.511215. Loss: 1.355269. Batch_acc: 0.535227. Batch_loss: 1.301907 \n",
      "Batch: 1745. Acc: 0.511225. Loss: 1.355248. Batch_acc: 0.528644. Batch_loss: 1.318530 \n",
      "Batch: 1746. Acc: 0.511230. Loss: 1.355223. Batch_acc: 0.519242. Batch_loss: 1.311408 \n",
      "Batch: 1747. Acc: 0.511235. Loss: 1.355202. Batch_acc: 0.520619. Batch_loss: 1.319690 \n",
      "Batch: 1748. Acc: 0.511236. Loss: 1.355214. Batch_acc: 0.512507. Batch_loss: 1.375099 \n",
      "Batch: 1749. Acc: 0.511234. Loss: 1.355210. Batch_acc: 0.507675. Batch_loss: 1.348408 \n",
      "Batch: 1750. Acc: 0.511227. Loss: 1.355223. Batch_acc: 0.498841. Batch_loss: 1.379373 \n",
      "Batch: 1751. Acc: 0.511240. Loss: 1.355179. Batch_acc: 0.533981. Batch_loss: 1.277720 \n",
      "Batch: 1752. Acc: 0.511237. Loss: 1.355188. Batch_acc: 0.506818. Batch_loss: 1.371082 \n",
      "Batch: 1753. Acc: 0.511237. Loss: 1.355179. Batch_acc: 0.511628. Batch_loss: 1.339638 \n",
      "Batch: 1754. Acc: 0.511266. Loss: 1.355114. Batch_acc: 0.561343. Batch_loss: 1.239761 \n",
      "Batch: 1755. Acc: 0.511271. Loss: 1.355106. Batch_acc: 0.519885. Batch_loss: 1.341209 \n",
      "Batch: 1756. Acc: 0.511277. Loss: 1.355089. Batch_acc: 0.522038. Batch_loss: 1.326600 \n",
      "Batch: 1757. Acc: 0.511278. Loss: 1.355088. Batch_acc: 0.513976. Batch_loss: 1.352482 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.5112783849719285. Loss per char: 1.3550878052964932. Time: 1627219356.2011127\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 20, 26, 18,  1, 71, 83, 80, 78,\n",
      "         1, 14, 19, 23, 23, 25, 17, 21, 22, 25, 17, 17, 22, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.511279. Loss: 1.355110. Batch_acc: 0.512238. Batch_loss: 1.395494 \n",
      "Batch: 1759. Acc: 0.511293. Loss: 1.355096. Batch_acc: 0.537322. Batch_loss: 1.328292 \n",
      "Batch: 1760. Acc: 0.511293. Loss: 1.355081. Batch_acc: 0.511111. Batch_loss: 1.329740 \n",
      "Batch: 1761. Acc: 0.511319. Loss: 1.355022. Batch_acc: 0.554994. Batch_loss: 1.253270 \n",
      "Batch: 1762. Acc: 0.511320. Loss: 1.355008. Batch_acc: 0.513314. Batch_loss: 1.331045 \n",
      "Batch: 1763. Acc: 0.511329. Loss: 1.354973. Batch_acc: 0.526644. Batch_loss: 1.295238 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1764. Acc: 0.511350. Loss: 1.354932. Batch_acc: 0.549361. Batch_loss: 1.281155 \n",
      "Batch: 1765. Acc: 0.511356. Loss: 1.354920. Batch_acc: 0.522159. Batch_loss: 1.334469 \n",
      "Batch: 1766. Acc: 0.511359. Loss: 1.354906. Batch_acc: 0.515679. Batch_loss: 1.330377 \n",
      "Batch: 1767. Acc: 0.511379. Loss: 1.354879. Batch_acc: 0.547921. Batch_loss: 1.306058 \n",
      "Batch: 1768. Acc: 0.511385. Loss: 1.354849. Batch_acc: 0.521714. Batch_loss: 1.302425 \n",
      "Batch: 1769. Acc: 0.511394. Loss: 1.354823. Batch_acc: 0.528083. Batch_loss: 1.308030 \n",
      "Batch: 1770. Acc: 0.511410. Loss: 1.354791. Batch_acc: 0.538074. Batch_loss: 1.299311 \n",
      "Batch: 1771. Acc: 0.511412. Loss: 1.354800. Batch_acc: 0.514302. Batch_loss: 1.372189 \n",
      "Batch: 1772. Acc: 0.511410. Loss: 1.354804. Batch_acc: 0.509038. Batch_loss: 1.361553 \n",
      "Batch: 1773. Acc: 0.511406. Loss: 1.354808. Batch_acc: 0.504577. Batch_loss: 1.362810 \n",
      "Batch: 1774. Acc: 0.511411. Loss: 1.354789. Batch_acc: 0.519841. Batch_loss: 1.320166 \n",
      "Batch: 1775. Acc: 0.511401. Loss: 1.354819. Batch_acc: 0.492026. Batch_loss: 1.409615 \n",
      "Batch: 1776. Acc: 0.511408. Loss: 1.354786. Batch_acc: 0.525086. Batch_loss: 1.296996 \n",
      "Batch: 1777. Acc: 0.511411. Loss: 1.354776. Batch_acc: 0.516968. Batch_loss: 1.337910 \n",
      "Batch: 1778. Acc: 0.511423. Loss: 1.354748. Batch_acc: 0.532221. Batch_loss: 1.304963 \n",
      "Batch: 1779. Acc: 0.511434. Loss: 1.354726. Batch_acc: 0.530017. Batch_loss: 1.314667 \n",
      "Batch: 1780. Acc: 0.511452. Loss: 1.354670. Batch_acc: 0.544000. Batch_loss: 1.256980 \n",
      "Batch: 1781. Acc: 0.511455. Loss: 1.354654. Batch_acc: 0.516459. Batch_loss: 1.326194 \n",
      "Batch: 1782. Acc: 0.511450. Loss: 1.354669. Batch_acc: 0.503192. Batch_loss: 1.382215 \n",
      "Batch: 1783. Acc: 0.511445. Loss: 1.354672. Batch_acc: 0.502312. Batch_loss: 1.359236 \n",
      "Batch: 1784. Acc: 0.511452. Loss: 1.354655. Batch_acc: 0.524306. Batch_loss: 1.324352 \n",
      "Batch: 1785. Acc: 0.511459. Loss: 1.354647. Batch_acc: 0.522989. Batch_loss: 1.340558 \n",
      "Batch: 1786. Acc: 0.511463. Loss: 1.354634. Batch_acc: 0.518602. Batch_loss: 1.331818 \n",
      "Batch: 1787. Acc: 0.511468. Loss: 1.354639. Batch_acc: 0.520588. Batch_loss: 1.363330 \n",
      "Batch: 1788. Acc: 0.511472. Loss: 1.354620. Batch_acc: 0.519285. Batch_loss: 1.321022 \n",
      "Batch: 1789. Acc: 0.511485. Loss: 1.354591. Batch_acc: 0.533918. Batch_loss: 1.302343 \n",
      "Batch: 1790. Acc: 0.511491. Loss: 1.354581. Batch_acc: 0.522754. Batch_loss: 1.337432 \n",
      "Batch: 1791. Acc: 0.511490. Loss: 1.354610. Batch_acc: 0.509758. Batch_loss: 1.407493 \n",
      "Batch: 1792. Acc: 0.511489. Loss: 1.354612. Batch_acc: 0.510517. Batch_loss: 1.357157 \n",
      "Batch: 1793. Acc: 0.511499. Loss: 1.354581. Batch_acc: 0.528907. Batch_loss: 1.300485 \n",
      "Batch: 1794. Acc: 0.511493. Loss: 1.354609. Batch_acc: 0.500861. Batch_loss: 1.404037 \n",
      "Batch: 1795. Acc: 0.511502. Loss: 1.354592. Batch_acc: 0.527682. Batch_loss: 1.324672 \n",
      "Batch: 1796. Acc: 0.511503. Loss: 1.354568. Batch_acc: 0.513181. Batch_loss: 1.310332 \n",
      "Batch: 1797. Acc: 0.511512. Loss: 1.354535. Batch_acc: 0.527904. Batch_loss: 1.295809 \n",
      "Batch: 1798. Acc: 0.511515. Loss: 1.354507. Batch_acc: 0.515169. Batch_loss: 1.305346 \n",
      "Batch: 1799. Acc: 0.511525. Loss: 1.354471. Batch_acc: 0.529915. Batch_loss: 1.289689 \n",
      "Batch: 1800. Acc: 0.511525. Loss: 1.354458. Batch_acc: 0.511926. Batch_loss: 1.331666 \n",
      "Batch: 1801. Acc: 0.511531. Loss: 1.354435. Batch_acc: 0.522311. Batch_loss: 1.313418 \n",
      "Batch: 1802. Acc: 0.511537. Loss: 1.354401. Batch_acc: 0.522946. Batch_loss: 1.293131 \n",
      "Batch: 1803. Acc: 0.511550. Loss: 1.354357. Batch_acc: 0.534483. Batch_loss: 1.275414 \n",
      "Batch: 1804. Acc: 0.511551. Loss: 1.354366. Batch_acc: 0.512435. Batch_loss: 1.371526 \n",
      "Batch: 1805. Acc: 0.511558. Loss: 1.354351. Batch_acc: 0.525522. Batch_loss: 1.325669 \n",
      "Batch: 1806. Acc: 0.511558. Loss: 1.354356. Batch_acc: 0.511188. Batch_loss: 1.364872 \n",
      "Batch: 1807. Acc: 0.511558. Loss: 1.354355. Batch_acc: 0.511249. Batch_loss: 1.351342 \n",
      "Batch: 1808. Acc: 0.511558. Loss: 1.354354. Batch_acc: 0.511124. Batch_loss: 1.353213 \n",
      "Batch: 1809. Acc: 0.511566. Loss: 1.354354. Batch_acc: 0.525943. Batch_loss: 1.354663 \n",
      "Batch: 1810. Acc: 0.511571. Loss: 1.354334. Batch_acc: 0.522554. Batch_loss: 1.316587 \n",
      "Batch: 1811. Acc: 0.511562. Loss: 1.354361. Batch_acc: 0.494145. Batch_loss: 1.403818 \n",
      "Batch: 1812. Acc: 0.511584. Loss: 1.354297. Batch_acc: 0.550114. Batch_loss: 1.240824 \n",
      "Batch: 1813. Acc: 0.511605. Loss: 1.354255. Batch_acc: 0.551326. Batch_loss: 1.277355 \n",
      "Batch: 1814. Acc: 0.511607. Loss: 1.354260. Batch_acc: 0.514689. Batch_loss: 1.363545 \n",
      "Batch: 1815. Acc: 0.511613. Loss: 1.354258. Batch_acc: 0.523015. Batch_loss: 1.350759 \n",
      "Batch: 1816. Acc: 0.511619. Loss: 1.354246. Batch_acc: 0.522042. Batch_loss: 1.332085 \n",
      "Batch: 1817. Acc: 0.511632. Loss: 1.354216. Batch_acc: 0.535714. Batch_loss: 1.298832 \n",
      "Batch: 1818. Acc: 0.511645. Loss: 1.354197. Batch_acc: 0.535632. Batch_loss: 1.319398 \n",
      "Batch: 1819. Acc: 0.511642. Loss: 1.354201. Batch_acc: 0.506395. Batch_loss: 1.360441 \n",
      "Batch: 1820. Acc: 0.511644. Loss: 1.354195. Batch_acc: 0.515169. Batch_loss: 1.344727 \n",
      "Batch: 1821. Acc: 0.511636. Loss: 1.354223. Batch_acc: 0.497103. Batch_loss: 1.405755 \n",
      "Batch: 1822. Acc: 0.511637. Loss: 1.354215. Batch_acc: 0.513218. Batch_loss: 1.338254 \n",
      "Batch: 1823. Acc: 0.511633. Loss: 1.354218. Batch_acc: 0.504211. Batch_loss: 1.360473 \n",
      "Batch: 1824. Acc: 0.511636. Loss: 1.354220. Batch_acc: 0.515982. Batch_loss: 1.358192 \n",
      "Batch: 1825. Acc: 0.511637. Loss: 1.354216. Batch_acc: 0.513889. Batch_loss: 1.345483 \n",
      "Batch: 1826. Acc: 0.511632. Loss: 1.354212. Batch_acc: 0.502273. Batch_loss: 1.347866 \n",
      "Batch: 1827. Acc: 0.511629. Loss: 1.354222. Batch_acc: 0.506713. Batch_loss: 1.373230 \n",
      "Batch: 1828. Acc: 0.511624. Loss: 1.354220. Batch_acc: 0.502320. Batch_loss: 1.350230 \n",
      "Batch: 1829. Acc: 0.511632. Loss: 1.354191. Batch_acc: 0.525656. Batch_loss: 1.300493 \n",
      "Batch: 1830. Acc: 0.511645. Loss: 1.354145. Batch_acc: 0.537209. Batch_loss: 1.270144 \n",
      "Batch: 1831. Acc: 0.511634. Loss: 1.354177. Batch_acc: 0.490983. Batch_loss: 1.412990 \n",
      "Batch: 1832. Acc: 0.511640. Loss: 1.354159. Batch_acc: 0.522779. Batch_loss: 1.321734 \n",
      "Batch: 1833. Acc: 0.511651. Loss: 1.354129. Batch_acc: 0.529938. Batch_loss: 1.300197 \n",
      "Batch: 1834. Acc: 0.511660. Loss: 1.354098. Batch_acc: 0.529245. Batch_loss: 1.298252 \n",
      "Batch: 1835. Acc: 0.511665. Loss: 1.354076. Batch_acc: 0.520455. Batch_loss: 1.315326 \n",
      "Batch: 1836. Acc: 0.511669. Loss: 1.354057. Batch_acc: 0.519286. Batch_loss: 1.318710 \n",
      "Batch: 1837. Acc: 0.511669. Loss: 1.354051. Batch_acc: 0.510133. Batch_loss: 1.342987 \n",
      "Batch: 1838. Acc: 0.511674. Loss: 1.354034. Batch_acc: 0.521518. Batch_loss: 1.323043 \n",
      "Batch: 1839. Acc: 0.511677. Loss: 1.354011. Batch_acc: 0.517164. Batch_loss: 1.313025 \n",
      "Batch: 1840. Acc: 0.511692. Loss: 1.353960. Batch_acc: 0.539249. Batch_loss: 1.260162 \n",
      "Batch: 1841. Acc: 0.511697. Loss: 1.353951. Batch_acc: 0.519613. Batch_loss: 1.337357 \n",
      "Batch: 1842. Acc: 0.511683. Loss: 1.353976. Batch_acc: 0.487062. Batch_loss: 1.400413 \n",
      "Batch: 1843. Acc: 0.511690. Loss: 1.353959. Batch_acc: 0.523451. Batch_loss: 1.321970 \n",
      "Batch: 1844. Acc: 0.511697. Loss: 1.353941. Batch_acc: 0.525773. Batch_loss: 1.322107 \n",
      "Batch: 1845. Acc: 0.511716. Loss: 1.353908. Batch_acc: 0.545612. Batch_loss: 1.291947 \n",
      "Batch: 1846. Acc: 0.511715. Loss: 1.353888. Batch_acc: 0.509870. Batch_loss: 1.318104 \n",
      "Batch: 1847. Acc: 0.511722. Loss: 1.353869. Batch_acc: 0.526531. Batch_loss: 1.317442 \n",
      "Batch: 1848. Acc: 0.511724. Loss: 1.353855. Batch_acc: 0.514563. Batch_loss: 1.329414 \n",
      "Batch: 1849. Acc: 0.511741. Loss: 1.353810. Batch_acc: 0.543552. Batch_loss: 1.271910 \n",
      "Batch: 1850. Acc: 0.511745. Loss: 1.353785. Batch_acc: 0.518857. Batch_loss: 1.308273 \n",
      "Batch: 1851. Acc: 0.511753. Loss: 1.353758. Batch_acc: 0.525479. Batch_loss: 1.305433 \n",
      "Batch: 1852. Acc: 0.511763. Loss: 1.353741. Batch_acc: 0.529279. Batch_loss: 1.323194 \n",
      "Batch: 1853. Acc: 0.511773. Loss: 1.353710. Batch_acc: 0.529512. Batch_loss: 1.296655 \n",
      "Batch: 1854. Acc: 0.511771. Loss: 1.353699. Batch_acc: 0.509554. Batch_loss: 1.333619 \n",
      "Batch: 1855. Acc: 0.511778. Loss: 1.353694. Batch_acc: 0.525130. Batch_loss: 1.343372 \n",
      "Batch: 1856. Acc: 0.511780. Loss: 1.353686. Batch_acc: 0.514697. Batch_loss: 1.339496 \n",
      "Batch: 1857. Acc: 0.511777. Loss: 1.353703. Batch_acc: 0.506322. Batch_loss: 1.385110 \n",
      "Batch: 1858. Acc: 0.511784. Loss: 1.353671. Batch_acc: 0.524249. Batch_loss: 1.294702 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1859. Acc: 0.511791. Loss: 1.353652. Batch_acc: 0.525146. Batch_loss: 1.316857 \n",
      "Batch: 1860. Acc: 0.511792. Loss: 1.353643. Batch_acc: 0.513326. Batch_loss: 1.337451 \n",
      "Batch: 1861. Acc: 0.511790. Loss: 1.353635. Batch_acc: 0.508822. Batch_loss: 1.338481 \n",
      "Batch: 1862. Acc: 0.511795. Loss: 1.353625. Batch_acc: 0.520157. Batch_loss: 1.335279 \n",
      "Batch: 1863. Acc: 0.511787. Loss: 1.353653. Batch_acc: 0.497693. Batch_loss: 1.406114 \n",
      "Batch: 1864. Acc: 0.511782. Loss: 1.353658. Batch_acc: 0.502281. Batch_loss: 1.362649 \n",
      "Batch: 1865. Acc: 0.511795. Loss: 1.353622. Batch_acc: 0.536461. Batch_loss: 1.288362 \n",
      "Batch: 1866. Acc: 0.511795. Loss: 1.353631. Batch_acc: 0.511325. Batch_loss: 1.369780 \n",
      "Batch: 1867. Acc: 0.511787. Loss: 1.353640. Batch_acc: 0.496823. Batch_loss: 1.371319 \n",
      "Batch: 1868. Acc: 0.511795. Loss: 1.353606. Batch_acc: 0.525797. Batch_loss: 1.289457 \n",
      "Batch: 1869. Acc: 0.511780. Loss: 1.353649. Batch_acc: 0.482981. Batch_loss: 1.435559 \n",
      "Batch: 1870. Acc: 0.511776. Loss: 1.353649. Batch_acc: 0.505688. Batch_loss: 1.352856 \n",
      "Batch: 1871. Acc: 0.511785. Loss: 1.353619. Batch_acc: 0.527232. Batch_loss: 1.299261 \n",
      "Batch: 1872. Acc: 0.511793. Loss: 1.353594. Batch_acc: 0.527386. Batch_loss: 1.307968 \n",
      "Batch: 1873. Acc: 0.511793. Loss: 1.353612. Batch_acc: 0.511918. Batch_loss: 1.386030 \n",
      "Batch: 1874. Acc: 0.511805. Loss: 1.353576. Batch_acc: 0.534775. Batch_loss: 1.286057 \n",
      "Batch: 1875. Acc: 0.511802. Loss: 1.353581. Batch_acc: 0.505501. Batch_loss: 1.362720 \n",
      "Batch: 1876. Acc: 0.511800. Loss: 1.353589. Batch_acc: 0.507429. Batch_loss: 1.368095 \n",
      "Batch: 1877. Acc: 0.511807. Loss: 1.353579. Batch_acc: 0.525626. Batch_loss: 1.333745 \n",
      "Batch: 1878. Acc: 0.511815. Loss: 1.353558. Batch_acc: 0.528346. Batch_loss: 1.313465 \n",
      "Batch: 1879. Acc: 0.511825. Loss: 1.353530. Batch_acc: 0.529709. Batch_loss: 1.301945 \n",
      "Batch: 1880. Acc: 0.511835. Loss: 1.353508. Batch_acc: 0.530127. Batch_loss: 1.312614 \n",
      "Batch: 1881. Acc: 0.511837. Loss: 1.353509. Batch_acc: 0.515616. Batch_loss: 1.354833 \n",
      "Batch: 1882. Acc: 0.511846. Loss: 1.353478. Batch_acc: 0.528796. Batch_loss: 1.295817 \n",
      "Batch: 1883. Acc: 0.511851. Loss: 1.353459. Batch_acc: 0.522319. Batch_loss: 1.315669 \n",
      "Batch: 1884. Acc: 0.511845. Loss: 1.353474. Batch_acc: 0.499708. Batch_loss: 1.383813 \n",
      "Batch: 1885. Acc: 0.511860. Loss: 1.353444. Batch_acc: 0.539692. Batch_loss: 1.296386 \n",
      "Batch: 1886. Acc: 0.511857. Loss: 1.353444. Batch_acc: 0.506388. Batch_loss: 1.352791 \n",
      "Batch: 1887. Acc: 0.511862. Loss: 1.353431. Batch_acc: 0.521313. Batch_loss: 1.330321 \n",
      "Batch: 1888. Acc: 0.511866. Loss: 1.353411. Batch_acc: 0.518670. Batch_loss: 1.314550 \n",
      "Batch: 1889. Acc: 0.511859. Loss: 1.353417. Batch_acc: 0.500291. Batch_loss: 1.365072 \n",
      "Batch: 1890. Acc: 0.511865. Loss: 1.353401. Batch_acc: 0.523121. Batch_loss: 1.323197 \n",
      "Batch: 1891. Acc: 0.511866. Loss: 1.353393. Batch_acc: 0.513218. Batch_loss: 1.337832 \n",
      "Batch: 1892. Acc: 0.511859. Loss: 1.353404. Batch_acc: 0.498556. Batch_loss: 1.373447 \n",
      "Batch: 1893. Acc: 0.511876. Loss: 1.353350. Batch_acc: 0.544653. Batch_loss: 1.250740 \n",
      "Batch: 1894. Acc: 0.511870. Loss: 1.353353. Batch_acc: 0.499107. Batch_loss: 1.359040 \n",
      "Batch: 1895. Acc: 0.511886. Loss: 1.353303. Batch_acc: 0.542217. Batch_loss: 1.257698 \n",
      "Batch: 1896. Acc: 0.511883. Loss: 1.353315. Batch_acc: 0.507143. Batch_loss: 1.377088 \n",
      "Batch: 1897. Acc: 0.511902. Loss: 1.353256. Batch_acc: 0.546814. Batch_loss: 1.246017 \n",
      "Batch: 1898. Acc: 0.511913. Loss: 1.353233. Batch_acc: 0.532914. Batch_loss: 1.308660 \n",
      "Batch: 1899. Acc: 0.511914. Loss: 1.353236. Batch_acc: 0.513560. Batch_loss: 1.359844 \n",
      "Batch: 1900. Acc: 0.511917. Loss: 1.353228. Batch_acc: 0.517439. Batch_loss: 1.338805 \n",
      "Batch: 1901. Acc: 0.511909. Loss: 1.353236. Batch_acc: 0.495940. Batch_loss: 1.368024 \n",
      "Batch: 1902. Acc: 0.511920. Loss: 1.353210. Batch_acc: 0.534144. Batch_loss: 1.303876 \n",
      "Batch: 1903. Acc: 0.511931. Loss: 1.353176. Batch_acc: 0.532110. Batch_loss: 1.288661 \n",
      "Batch: 1904. Acc: 0.511933. Loss: 1.353178. Batch_acc: 0.515152. Batch_loss: 1.356160 \n",
      "Batch: 1905. Acc: 0.511936. Loss: 1.353168. Batch_acc: 0.518561. Batch_loss: 1.334288 \n",
      "Batch: 1906. Acc: 0.511957. Loss: 1.353139. Batch_acc: 0.551587. Batch_loss: 1.299210 \n",
      "Batch: 1907. Acc: 0.511957. Loss: 1.353124. Batch_acc: 0.512083. Batch_loss: 1.324227 \n",
      "Batch: 1908. Acc: 0.511957. Loss: 1.353131. Batch_acc: 0.511779. Batch_loss: 1.366099 \n",
      "Batch: 1909. Acc: 0.511970. Loss: 1.353100. Batch_acc: 0.535513. Batch_loss: 1.296094 \n",
      "Batch: 1910. Acc: 0.511978. Loss: 1.353088. Batch_acc: 0.527004. Batch_loss: 1.329733 \n",
      "Batch: 1911. Acc: 0.511988. Loss: 1.353061. Batch_acc: 0.531526. Batch_loss: 1.301277 \n",
      "Batch: 1912. Acc: 0.511977. Loss: 1.353086. Batch_acc: 0.491071. Batch_loss: 1.401667 \n",
      "Batch: 1913. Acc: 0.511974. Loss: 1.353077. Batch_acc: 0.506388. Batch_loss: 1.335067 \n",
      "Batch: 1914. Acc: 0.511961. Loss: 1.353090. Batch_acc: 0.485580. Batch_loss: 1.379856 \n",
      "Batch: 1915. Acc: 0.511961. Loss: 1.353084. Batch_acc: 0.512378. Batch_loss: 1.340057 \n",
      "Batch: 1916. Acc: 0.511980. Loss: 1.353046. Batch_acc: 0.547699. Batch_loss: 1.282534 \n",
      "Batch: 1917. Acc: 0.511976. Loss: 1.353056. Batch_acc: 0.503795. Batch_loss: 1.372978 \n",
      "Batch: 1918. Acc: 0.511985. Loss: 1.353031. Batch_acc: 0.529245. Batch_loss: 1.305688 \n",
      "Batch: 1919. Acc: 0.511992. Loss: 1.353002. Batch_acc: 0.525922. Batch_loss: 1.297234 \n",
      "Batch: 1920. Acc: 0.512002. Loss: 1.352966. Batch_acc: 0.530175. Batch_loss: 1.284437 \n",
      "Batch: 1921. Acc: 0.511997. Loss: 1.352978. Batch_acc: 0.502864. Batch_loss: 1.377340 \n",
      "Batch: 1922. Acc: 0.512000. Loss: 1.352962. Batch_acc: 0.517280. Batch_loss: 1.321352 \n",
      "Batch: 1923. Acc: 0.512013. Loss: 1.352921. Batch_acc: 0.537330. Batch_loss: 1.275503 \n",
      "Batch: 1924. Acc: 0.512015. Loss: 1.352919. Batch_acc: 0.514535. Batch_loss: 1.350034 \n",
      "Batch: 1925. Acc: 0.512024. Loss: 1.352890. Batch_acc: 0.529445. Batch_loss: 1.297251 \n",
      "Batch: 1926. Acc: 0.512017. Loss: 1.352890. Batch_acc: 0.498264. Batch_loss: 1.352555 \n",
      "Batch: 1927. Acc: 0.512017. Loss: 1.352895. Batch_acc: 0.512881. Batch_loss: 1.362213 \n",
      "Batch: 1928. Acc: 0.512022. Loss: 1.352891. Batch_acc: 0.520961. Batch_loss: 1.345110 \n",
      "Batch: 1929. Acc: 0.512013. Loss: 1.352912. Batch_acc: 0.494598. Batch_loss: 1.396331 \n",
      "Batch: 1930. Acc: 0.512009. Loss: 1.352924. Batch_acc: 0.504373. Batch_loss: 1.376684 \n",
      "Batch: 1931. Acc: 0.512004. Loss: 1.352928. Batch_acc: 0.500593. Batch_loss: 1.361188 \n",
      "Batch: 1932. Acc: 0.512018. Loss: 1.352895. Batch_acc: 0.539527. Batch_loss: 1.287809 \n",
      "Batch: 1933. Acc: 0.512014. Loss: 1.352909. Batch_acc: 0.504333. Batch_loss: 1.379752 \n",
      "Batch: 1934. Acc: 0.512023. Loss: 1.352887. Batch_acc: 0.528377. Batch_loss: 1.311455 \n",
      "Batch: 1935. Acc: 0.512038. Loss: 1.352854. Batch_acc: 0.543275. Batch_loss: 1.287356 \n",
      "Batch: 1936. Acc: 0.512039. Loss: 1.352839. Batch_acc: 0.513068. Batch_loss: 1.325530 \n",
      "Batch: 1937. Acc: 0.512051. Loss: 1.352809. Batch_acc: 0.535469. Batch_loss: 1.294914 \n",
      "Batch: 1938. Acc: 0.512053. Loss: 1.352801. Batch_acc: 0.516055. Batch_loss: 1.337048 \n",
      "Batch: 1939. Acc: 0.512055. Loss: 1.352789. Batch_acc: 0.515306. Batch_loss: 1.330320 \n",
      "Batch: 1940. Acc: 0.512055. Loss: 1.352790. Batch_acc: 0.511446. Batch_loss: 1.354148 \n",
      "Batch: 1941. Acc: 0.512050. Loss: 1.352801. Batch_acc: 0.502315. Batch_loss: 1.373603 \n",
      "Batch: 1942. Acc: 0.512056. Loss: 1.352767. Batch_acc: 0.524900. Batch_loss: 1.288201 \n",
      "Batch: 1943. Acc: 0.512062. Loss: 1.352744. Batch_acc: 0.523008. Batch_loss: 1.307783 \n",
      "Batch: 1944. Acc: 0.512051. Loss: 1.352746. Batch_acc: 0.490490. Batch_loss: 1.357020 \n",
      "Batch: 1945. Acc: 0.512057. Loss: 1.352715. Batch_acc: 0.523727. Batch_loss: 1.292790 \n",
      "Batch: 1946. Acc: 0.512062. Loss: 1.352696. Batch_acc: 0.522660. Batch_loss: 1.314865 \n",
      "Batch: 1947. Acc: 0.512064. Loss: 1.352679. Batch_acc: 0.515753. Batch_loss: 1.319671 \n",
      "Batch: 1948. Acc: 0.512053. Loss: 1.352696. Batch_acc: 0.490173. Batch_loss: 1.385244 \n",
      "Batch: 1949. Acc: 0.512058. Loss: 1.352684. Batch_acc: 0.522456. Batch_loss: 1.328755 \n",
      "Batch: 1950. Acc: 0.512064. Loss: 1.352659. Batch_acc: 0.522740. Batch_loss: 1.304903 \n",
      "Batch: 1951. Acc: 0.512064. Loss: 1.352648. Batch_acc: 0.512069. Batch_loss: 1.331485 \n",
      "Batch: 1952. Acc: 0.512067. Loss: 1.352650. Batch_acc: 0.518950. Batch_loss: 1.356040 \n",
      "Batch: 1953. Acc: 0.512076. Loss: 1.352623. Batch_acc: 0.528522. Batch_loss: 1.299886 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1954. Acc: 0.512105. Loss: 1.352562. Batch_acc: 0.569083. Batch_loss: 1.234577 \n",
      "Batch: 1955. Acc: 0.512098. Loss: 1.352561. Batch_acc: 0.497116. Batch_loss: 1.351242 \n",
      "Batch: 1956. Acc: 0.512094. Loss: 1.352581. Batch_acc: 0.504278. Batch_loss: 1.391190 \n",
      "Batch: 1957. Acc: 0.512115. Loss: 1.352522. Batch_acc: 0.552809. Batch_loss: 1.238584 \n",
      "Batch: 1958. Acc: 0.512126. Loss: 1.352502. Batch_acc: 0.533714. Batch_loss: 1.313437 \n",
      "Batch: 1959. Acc: 0.512127. Loss: 1.352499. Batch_acc: 0.514401. Batch_loss: 1.347063 \n",
      "Batch: 1960. Acc: 0.512132. Loss: 1.352484. Batch_acc: 0.521490. Batch_loss: 1.322798 \n",
      "Batch: 1961. Acc: 0.512133. Loss: 1.352484. Batch_acc: 0.514252. Batch_loss: 1.354222 \n",
      "Batch: 1962. Acc: 0.512126. Loss: 1.352487. Batch_acc: 0.498313. Batch_loss: 1.356696 \n",
      "Batch: 1963. Acc: 0.512125. Loss: 1.352482. Batch_acc: 0.511278. Batch_loss: 1.342523 \n",
      "Batch: 1964. Acc: 0.512133. Loss: 1.352458. Batch_acc: 0.526286. Batch_loss: 1.306529 \n",
      "Batch: 1965. Acc: 0.512143. Loss: 1.352431. Batch_acc: 0.532157. Batch_loss: 1.299445 \n",
      "Batch: 1966. Acc: 0.512144. Loss: 1.352421. Batch_acc: 0.513607. Batch_loss: 1.332483 \n",
      "Batch: 1967. Acc: 0.512144. Loss: 1.352426. Batch_acc: 0.513793. Batch_loss: 1.362467 \n",
      "Batch: 1968. Acc: 0.512137. Loss: 1.352455. Batch_acc: 0.496778. Batch_loss: 1.410692 \n",
      "Batch: 1969. Acc: 0.512125. Loss: 1.352467. Batch_acc: 0.488130. Batch_loss: 1.376366 \n",
      "Batch: 1970. Acc: 0.512141. Loss: 1.352437. Batch_acc: 0.544476. Batch_loss: 1.293670 \n",
      "Batch: 1971. Acc: 0.512148. Loss: 1.352430. Batch_acc: 0.525648. Batch_loss: 1.339474 \n",
      "Batch: 1972. Acc: 0.512162. Loss: 1.352390. Batch_acc: 0.539792. Batch_loss: 1.272716 \n",
      "Batch: 1973. Acc: 0.512163. Loss: 1.352383. Batch_acc: 0.514451. Batch_loss: 1.338480 \n",
      "Batch: 1974. Acc: 0.512157. Loss: 1.352391. Batch_acc: 0.500291. Batch_loss: 1.369266 \n",
      "Batch: 1975. Acc: 0.512163. Loss: 1.352382. Batch_acc: 0.523810. Batch_loss: 1.333933 \n",
      "Batch: 1976. Acc: 0.512166. Loss: 1.352369. Batch_acc: 0.518059. Batch_loss: 1.326933 \n",
      "Batch: 1977. Acc: 0.512173. Loss: 1.352339. Batch_acc: 0.526102. Batch_loss: 1.293840 \n",
      "Batch: 1978. Acc: 0.512182. Loss: 1.352319. Batch_acc: 0.529838. Batch_loss: 1.313234 \n",
      "Batch: 1979. Acc: 0.512185. Loss: 1.352306. Batch_acc: 0.517919. Batch_loss: 1.326465 \n",
      "Batch: 1980. Acc: 0.512166. Loss: 1.352347. Batch_acc: 0.473928. Batch_loss: 1.433535 \n",
      "Batch: 1981. Acc: 0.512158. Loss: 1.352365. Batch_acc: 0.497156. Batch_loss: 1.387862 \n",
      "Batch: 1982. Acc: 0.512169. Loss: 1.352350. Batch_acc: 0.532838. Batch_loss: 1.323630 \n",
      "Batch: 1983. Acc: 0.512175. Loss: 1.352330. Batch_acc: 0.524803. Batch_loss: 1.312687 \n",
      "Batch: 1984. Acc: 0.512178. Loss: 1.352324. Batch_acc: 0.516686. Batch_loss: 1.341120 \n",
      "Batch: 1985. Acc: 0.512172. Loss: 1.352329. Batch_acc: 0.500594. Batch_loss: 1.361190 \n",
      "Batch: 1986. Acc: 0.512175. Loss: 1.352309. Batch_acc: 0.518665. Batch_loss: 1.313739 \n",
      "Batch: 1987. Acc: 0.512165. Loss: 1.352335. Batch_acc: 0.492255. Batch_loss: 1.404159 \n",
      "Batch: 1988. Acc: 0.512168. Loss: 1.352327. Batch_acc: 0.517343. Batch_loss: 1.335273 \n",
      "Batch: 1989. Acc: 0.512170. Loss: 1.352312. Batch_acc: 0.515625. Batch_loss: 1.323340 \n",
      "Batch: 1990. Acc: 0.512178. Loss: 1.352285. Batch_acc: 0.528399. Batch_loss: 1.297422 \n",
      "Batch: 1991. Acc: 0.512191. Loss: 1.352264. Batch_acc: 0.538999. Batch_loss: 1.311678 \n",
      "Batch: 1992. Acc: 0.512192. Loss: 1.352276. Batch_acc: 0.514085. Batch_loss: 1.376935 \n",
      "Batch: 1993. Acc: 0.512196. Loss: 1.352266. Batch_acc: 0.519553. Batch_loss: 1.331301 \n",
      "Batch: 1994. Acc: 0.512190. Loss: 1.352275. Batch_acc: 0.501160. Batch_loss: 1.370450 \n",
      "Batch: 1995. Acc: 0.512207. Loss: 1.352240. Batch_acc: 0.545350. Batch_loss: 1.282954 \n",
      "Batch: 1996. Acc: 0.512212. Loss: 1.352228. Batch_acc: 0.522388. Batch_loss: 1.328148 \n",
      "Batch: 1997. Acc: 0.512205. Loss: 1.352236. Batch_acc: 0.496724. Batch_loss: 1.368036 \n",
      "Batch: 1998. Acc: 0.512215. Loss: 1.352195. Batch_acc: 0.531891. Batch_loss: 1.272544 \n",
      "Batch: 1999. Acc: 0.512215. Loss: 1.352195. Batch_acc: 0.512791. Batch_loss: 1.351232 \n",
      "Batch: 2000. Acc: 0.512220. Loss: 1.352168. Batch_acc: 0.522573. Batch_loss: 1.299420 \n",
      "Batch: 2001. Acc: 0.512225. Loss: 1.352163. Batch_acc: 0.521542. Batch_loss: 1.342966 \n",
      "Batch: 2002. Acc: 0.512225. Loss: 1.352163. Batch_acc: 0.512031. Batch_loss: 1.351545 \n",
      "Batch: 2003. Acc: 0.512233. Loss: 1.352134. Batch_acc: 0.529345. Batch_loss: 1.295036 \n",
      "Batch: 2004. Acc: 0.512240. Loss: 1.352116. Batch_acc: 0.526562. Batch_loss: 1.314732 \n",
      "Batch: 2005. Acc: 0.512232. Loss: 1.352126. Batch_acc: 0.495995. Batch_loss: 1.372812 \n",
      "Batch: 2006. Acc: 0.512242. Loss: 1.352104. Batch_acc: 0.532609. Batch_loss: 1.308116 \n",
      "Batch: 2007. Acc: 0.512247. Loss: 1.352079. Batch_acc: 0.521071. Batch_loss: 1.301191 \n",
      "Batch: 2008. Acc: 0.512265. Loss: 1.352027. Batch_acc: 0.548186. Batch_loss: 1.250716 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.512265028389599. Loss per char: 1.352027385340801. Time: 1627219560.6887949\n",
      "Last question is tensor([ 2, 17, 15, 23, 18, 26, 26, 19, 24, 12, 14, 19, 15, 23, 20, 22, 26,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.512259. Loss: 1.352032. Batch_acc: 0.500000. Batch_loss: 1.361203 \n",
      "Batch: 2010. Acc: 0.512272. Loss: 1.351991. Batch_acc: 0.538198. Batch_loss: 1.271068 \n",
      "Batch: 2011. Acc: 0.512276. Loss: 1.351987. Batch_acc: 0.520917. Batch_loss: 1.343720 \n",
      "Batch: 2012. Acc: 0.512273. Loss: 1.351988. Batch_acc: 0.506560. Batch_loss: 1.353648 \n",
      "Batch: 2013. Acc: 0.512288. Loss: 1.351939. Batch_acc: 0.542923. Batch_loss: 1.252402 \n",
      "Batch: 2014. Acc: 0.512285. Loss: 1.351947. Batch_acc: 0.506366. Batch_loss: 1.367257 \n",
      "Batch: 2015. Acc: 0.512300. Loss: 1.351919. Batch_acc: 0.541572. Batch_loss: 1.296222 \n",
      "Batch: 2016. Acc: 0.512310. Loss: 1.351894. Batch_acc: 0.532147. Batch_loss: 1.301686 \n",
      "Batch: 2017. Acc: 0.512315. Loss: 1.351880. Batch_acc: 0.521689. Batch_loss: 1.324073 \n",
      "Batch: 2018. Acc: 0.512311. Loss: 1.351890. Batch_acc: 0.504028. Batch_loss: 1.372365 \n",
      "Batch: 2019. Acc: 0.512320. Loss: 1.351878. Batch_acc: 0.531501. Batch_loss: 1.327818 \n",
      "Batch: 2020. Acc: 0.512334. Loss: 1.351847. Batch_acc: 0.539604. Batch_loss: 1.291794 \n",
      "Batch: 2021. Acc: 0.512335. Loss: 1.351848. Batch_acc: 0.514056. Batch_loss: 1.354391 \n",
      "Batch: 2022. Acc: 0.512336. Loss: 1.351850. Batch_acc: 0.514019. Batch_loss: 1.354938 \n",
      "Batch: 2023. Acc: 0.512346. Loss: 1.351831. Batch_acc: 0.532221. Batch_loss: 1.313935 \n",
      "Batch: 2024. Acc: 0.512351. Loss: 1.351820. Batch_acc: 0.523209. Batch_loss: 1.328399 \n",
      "Batch: 2025. Acc: 0.512343. Loss: 1.351819. Batch_acc: 0.496483. Batch_loss: 1.349733 \n",
      "Batch: 2026. Acc: 0.512346. Loss: 1.351808. Batch_acc: 0.516834. Batch_loss: 1.328962 \n",
      "Batch: 2027. Acc: 0.512348. Loss: 1.351792. Batch_acc: 0.517784. Batch_loss: 1.319976 \n",
      "Batch: 2028. Acc: 0.512342. Loss: 1.351796. Batch_acc: 0.500000. Batch_loss: 1.360252 \n",
      "Batch: 2029. Acc: 0.512354. Loss: 1.351768. Batch_acc: 0.535735. Batch_loss: 1.295113 \n",
      "Batch: 2030. Acc: 0.512355. Loss: 1.351760. Batch_acc: 0.515046. Batch_loss: 1.335265 \n",
      "Batch: 2031. Acc: 0.512360. Loss: 1.351756. Batch_acc: 0.522846. Batch_loss: 1.342741 \n",
      "Batch: 2032. Acc: 0.512371. Loss: 1.351742. Batch_acc: 0.534097. Batch_loss: 1.324019 \n",
      "Batch: 2033. Acc: 0.512371. Loss: 1.351737. Batch_acc: 0.512658. Batch_loss: 1.341481 \n",
      "Batch: 2034. Acc: 0.512366. Loss: 1.351764. Batch_acc: 0.502874. Batch_loss: 1.407398 \n",
      "Batch: 2035. Acc: 0.512383. Loss: 1.351721. Batch_acc: 0.545094. Batch_loss: 1.265448 \n",
      "Batch: 2036. Acc: 0.512395. Loss: 1.351691. Batch_acc: 0.535933. Batch_loss: 1.291822 \n",
      "Batch: 2037. Acc: 0.512398. Loss: 1.351675. Batch_acc: 0.518433. Batch_loss: 1.320066 \n",
      "Batch: 2038. Acc: 0.512411. Loss: 1.351632. Batch_acc: 0.540138. Batch_loss: 1.263479 \n",
      "Batch: 2039. Acc: 0.512409. Loss: 1.351636. Batch_acc: 0.506866. Batch_loss: 1.359474 \n",
      "Batch: 2040. Acc: 0.512415. Loss: 1.351619. Batch_acc: 0.524758. Batch_loss: 1.318305 \n",
      "Batch: 2041. Acc: 0.512409. Loss: 1.351633. Batch_acc: 0.500590. Batch_loss: 1.381629 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2042. Acc: 0.512419. Loss: 1.351608. Batch_acc: 0.531127. Batch_loss: 1.299961 \n",
      "Batch: 2043. Acc: 0.512424. Loss: 1.351586. Batch_acc: 0.522523. Batch_loss: 1.308303 \n",
      "Batch: 2044. Acc: 0.512444. Loss: 1.351551. Batch_acc: 0.552440. Batch_loss: 1.281366 \n",
      "Batch: 2045. Acc: 0.512454. Loss: 1.351526. Batch_acc: 0.534104. Batch_loss: 1.299954 \n",
      "Batch: 2046. Acc: 0.512461. Loss: 1.351507. Batch_acc: 0.527158. Batch_loss: 1.314377 \n",
      "Batch: 2047. Acc: 0.512470. Loss: 1.351493. Batch_acc: 0.530390. Batch_loss: 1.321666 \n",
      "Batch: 2048. Acc: 0.512481. Loss: 1.351468. Batch_acc: 0.535348. Batch_loss: 1.301971 \n",
      "Batch: 2049. Acc: 0.512475. Loss: 1.351474. Batch_acc: 0.498284. Batch_loss: 1.362239 \n",
      "Batch: 2050. Acc: 0.512478. Loss: 1.351458. Batch_acc: 0.519771. Batch_loss: 1.319549 \n",
      "Batch: 2051. Acc: 0.512473. Loss: 1.351477. Batch_acc: 0.502887. Batch_loss: 1.390261 \n",
      "Batch: 2052. Acc: 0.512483. Loss: 1.351461. Batch_acc: 0.531646. Batch_loss: 1.318614 \n",
      "Batch: 2053. Acc: 0.512479. Loss: 1.351452. Batch_acc: 0.505714. Batch_loss: 1.334053 \n",
      "Batch: 2054. Acc: 0.512477. Loss: 1.351465. Batch_acc: 0.507647. Batch_loss: 1.377550 \n",
      "Batch: 2055. Acc: 0.512484. Loss: 1.351454. Batch_acc: 0.527315. Batch_loss: 1.328808 \n",
      "Batch: 2056. Acc: 0.512479. Loss: 1.351470. Batch_acc: 0.500299. Batch_loss: 1.386117 \n",
      "Batch: 2057. Acc: 0.512486. Loss: 1.351462. Batch_acc: 0.528497. Batch_loss: 1.336028 \n",
      "Batch: 2058. Acc: 0.512484. Loss: 1.351467. Batch_acc: 0.507991. Batch_loss: 1.360420 \n",
      "Batch: 2059. Acc: 0.512481. Loss: 1.351465. Batch_acc: 0.504985. Batch_loss: 1.347415 \n",
      "Batch: 2060. Acc: 0.512486. Loss: 1.351455. Batch_acc: 0.523618. Batch_loss: 1.331208 \n",
      "Batch: 2061. Acc: 0.512495. Loss: 1.351432. Batch_acc: 0.530707. Batch_loss: 1.304610 \n",
      "Batch: 2062. Acc: 0.512499. Loss: 1.351409. Batch_acc: 0.521564. Batch_loss: 1.302568 \n",
      "Batch: 2063. Acc: 0.512503. Loss: 1.351400. Batch_acc: 0.520455. Batch_loss: 1.334305 \n",
      "Batch: 2064. Acc: 0.512508. Loss: 1.351376. Batch_acc: 0.523121. Batch_loss: 1.301220 \n",
      "Batch: 2065. Acc: 0.512509. Loss: 1.351385. Batch_acc: 0.514454. Batch_loss: 1.370361 \n",
      "Batch: 2066. Acc: 0.512516. Loss: 1.351375. Batch_acc: 0.526713. Batch_loss: 1.330492 \n",
      "Batch: 2067. Acc: 0.512519. Loss: 1.351373. Batch_acc: 0.518868. Batch_loss: 1.347045 \n",
      "Batch: 2068. Acc: 0.512516. Loss: 1.351386. Batch_acc: 0.505821. Batch_loss: 1.378723 \n",
      "Batch: 2069. Acc: 0.512513. Loss: 1.351390. Batch_acc: 0.506250. Batch_loss: 1.360056 \n",
      "Batch: 2070. Acc: 0.512521. Loss: 1.351375. Batch_acc: 0.530225. Batch_loss: 1.318859 \n",
      "Batch: 2071. Acc: 0.512535. Loss: 1.351344. Batch_acc: 0.541691. Batch_loss: 1.286321 \n",
      "Batch: 2072. Acc: 0.512536. Loss: 1.351348. Batch_acc: 0.515078. Batch_loss: 1.359647 \n",
      "Batch: 2073. Acc: 0.512531. Loss: 1.351364. Batch_acc: 0.500876. Batch_loss: 1.386169 \n",
      "Batch: 2074. Acc: 0.512533. Loss: 1.351351. Batch_acc: 0.517023. Batch_loss: 1.323411 \n",
      "Batch: 2075. Acc: 0.512545. Loss: 1.351323. Batch_acc: 0.536054. Batch_loss: 1.296493 \n",
      "Batch: 2076. Acc: 0.512545. Loss: 1.351316. Batch_acc: 0.512806. Batch_loss: 1.335528 \n",
      "Batch: 2077. Acc: 0.512558. Loss: 1.351280. Batch_acc: 0.539556. Batch_loss: 1.276428 \n",
      "Batch: 2078. Acc: 0.512565. Loss: 1.351249. Batch_acc: 0.527158. Batch_loss: 1.288195 \n",
      "Batch: 2079. Acc: 0.512571. Loss: 1.351237. Batch_acc: 0.525892. Batch_loss: 1.325701 \n",
      "Batch: 2080. Acc: 0.512577. Loss: 1.351241. Batch_acc: 0.523973. Batch_loss: 1.359343 \n",
      "Batch: 2081. Acc: 0.512573. Loss: 1.351258. Batch_acc: 0.503835. Batch_loss: 1.387917 \n",
      "Batch: 2082. Acc: 0.512578. Loss: 1.351245. Batch_acc: 0.524052. Batch_loss: 1.324266 \n",
      "Batch: 2083. Acc: 0.512580. Loss: 1.351237. Batch_acc: 0.516744. Batch_loss: 1.334673 \n",
      "Batch: 2084. Acc: 0.512584. Loss: 1.351233. Batch_acc: 0.520833. Batch_loss: 1.342426 \n",
      "Batch: 2085. Acc: 0.512594. Loss: 1.351208. Batch_acc: 0.533372. Batch_loss: 1.300483 \n",
      "Batch: 2086. Acc: 0.512587. Loss: 1.351216. Batch_acc: 0.496808. Batch_loss: 1.367399 \n",
      "Batch: 2087. Acc: 0.512592. Loss: 1.351202. Batch_acc: 0.523005. Batch_loss: 1.322191 \n",
      "Batch: 2088. Acc: 0.512595. Loss: 1.351183. Batch_acc: 0.518497. Batch_loss: 1.312644 \n",
      "Batch: 2089. Acc: 0.512590. Loss: 1.351189. Batch_acc: 0.503821. Batch_loss: 1.363935 \n",
      "Batch: 2090. Acc: 0.512589. Loss: 1.351202. Batch_acc: 0.509445. Batch_loss: 1.376595 \n",
      "Batch: 2091. Acc: 0.512590. Loss: 1.351205. Batch_acc: 0.514336. Batch_loss: 1.358460 \n",
      "Batch: 2092. Acc: 0.512600. Loss: 1.351189. Batch_acc: 0.533599. Batch_loss: 1.318679 \n",
      "Batch: 2093. Acc: 0.512602. Loss: 1.351183. Batch_acc: 0.517082. Batch_loss: 1.338047 \n",
      "Batch: 2094. Acc: 0.512604. Loss: 1.351178. Batch_acc: 0.515957. Batch_loss: 1.340894 \n",
      "Batch: 2095. Acc: 0.512612. Loss: 1.351163. Batch_acc: 0.530190. Batch_loss: 1.319069 \n",
      "Batch: 2096. Acc: 0.512614. Loss: 1.351149. Batch_acc: 0.516848. Batch_loss: 1.322003 \n",
      "Batch: 2097. Acc: 0.512635. Loss: 1.351089. Batch_acc: 0.557143. Batch_loss: 1.226204 \n",
      "Batch: 2098. Acc: 0.512623. Loss: 1.351117. Batch_acc: 0.485190. Batch_loss: 1.411919 \n",
      "Batch: 2099. Acc: 0.512636. Loss: 1.351093. Batch_acc: 0.540113. Batch_loss: 1.301886 \n",
      "Batch: 2100. Acc: 0.512628. Loss: 1.351107. Batch_acc: 0.494834. Batch_loss: 1.380579 \n",
      "Batch: 2101. Acc: 0.512636. Loss: 1.351089. Batch_acc: 0.530752. Batch_loss: 1.312221 \n",
      "Batch: 2102. Acc: 0.512632. Loss: 1.351095. Batch_acc: 0.503746. Batch_loss: 1.365234 \n",
      "Batch: 2103. Acc: 0.512644. Loss: 1.351067. Batch_acc: 0.537611. Batch_loss: 1.293822 \n",
      "Batch: 2104. Acc: 0.512643. Loss: 1.351067. Batch_acc: 0.509666. Batch_loss: 1.350266 \n",
      "Batch: 2105. Acc: 0.512651. Loss: 1.351031. Batch_acc: 0.529478. Batch_loss: 1.277118 \n",
      "Batch: 2106. Acc: 0.512650. Loss: 1.351025. Batch_acc: 0.510193. Batch_loss: 1.338538 \n",
      "Batch: 2107. Acc: 0.512648. Loss: 1.351016. Batch_acc: 0.509306. Batch_loss: 1.331695 \n",
      "Batch: 2108. Acc: 0.512645. Loss: 1.351007. Batch_acc: 0.505841. Batch_loss: 1.333021 \n",
      "Batch: 2109. Acc: 0.512654. Loss: 1.350981. Batch_acc: 0.530508. Batch_loss: 1.296872 \n",
      "Batch: 2110. Acc: 0.512664. Loss: 1.350960. Batch_acc: 0.534734. Batch_loss: 1.305606 \n",
      "Batch: 2111. Acc: 0.512664. Loss: 1.350961. Batch_acc: 0.512449. Batch_loss: 1.353700 \n",
      "Batch: 2112. Acc: 0.512653. Loss: 1.350979. Batch_acc: 0.488568. Batch_loss: 1.389006 \n",
      "Batch: 2113. Acc: 0.512657. Loss: 1.350979. Batch_acc: 0.520882. Batch_loss: 1.352985 \n",
      "Batch: 2114. Acc: 0.512656. Loss: 1.350981. Batch_acc: 0.510398. Batch_loss: 1.354332 \n",
      "Batch: 2115. Acc: 0.512656. Loss: 1.350989. Batch_acc: 0.513793. Batch_loss: 1.367286 \n",
      "Batch: 2116. Acc: 0.512667. Loss: 1.350981. Batch_acc: 0.534052. Batch_loss: 1.334948 \n",
      "Batch: 2117. Acc: 0.512666. Loss: 1.350976. Batch_acc: 0.511981. Batch_loss: 1.339533 \n",
      "Batch: 2118. Acc: 0.512671. Loss: 1.350968. Batch_acc: 0.521814. Batch_loss: 1.335650 \n",
      "Batch: 2119. Acc: 0.512672. Loss: 1.350965. Batch_acc: 0.516366. Batch_loss: 1.343581 \n",
      "Batch: 2120. Acc: 0.512672. Loss: 1.350956. Batch_acc: 0.512729. Batch_loss: 1.331965 \n",
      "Batch: 2121. Acc: 0.512672. Loss: 1.350946. Batch_acc: 0.512387. Batch_loss: 1.330496 \n",
      "Batch: 2122. Acc: 0.512679. Loss: 1.350924. Batch_acc: 0.527875. Batch_loss: 1.302724 \n",
      "Batch: 2123. Acc: 0.512675. Loss: 1.350919. Batch_acc: 0.503123. Batch_loss: 1.340637 \n",
      "Batch: 2124. Acc: 0.512686. Loss: 1.350894. Batch_acc: 0.537786. Batch_loss: 1.296549 \n",
      "Batch: 2125. Acc: 0.512689. Loss: 1.350883. Batch_acc: 0.519219. Batch_loss: 1.328013 \n",
      "Batch: 2126. Acc: 0.512690. Loss: 1.350872. Batch_acc: 0.514351. Batch_loss: 1.325848 \n",
      "Batch: 2127. Acc: 0.512708. Loss: 1.350843. Batch_acc: 0.550383. Batch_loss: 1.288349 \n",
      "Batch: 2128. Acc: 0.512703. Loss: 1.350854. Batch_acc: 0.502268. Batch_loss: 1.374048 \n",
      "Batch: 2129. Acc: 0.512704. Loss: 1.350863. Batch_acc: 0.516854. Batch_loss: 1.371199 \n",
      "Batch: 2130. Acc: 0.512709. Loss: 1.350850. Batch_acc: 0.522676. Batch_loss: 1.323266 \n",
      "Batch: 2131. Acc: 0.512721. Loss: 1.350815. Batch_acc: 0.537442. Batch_loss: 1.275197 \n",
      "Batch: 2132. Acc: 0.512733. Loss: 1.350788. Batch_acc: 0.537507. Batch_loss: 1.296115 \n",
      "Batch: 2133. Acc: 0.512738. Loss: 1.350769. Batch_acc: 0.524334. Batch_loss: 1.308207 \n",
      "Batch: 2134. Acc: 0.512731. Loss: 1.350791. Batch_acc: 0.498280. Batch_loss: 1.398163 \n",
      "Batch: 2135. Acc: 0.512734. Loss: 1.350797. Batch_acc: 0.519242. Batch_loss: 1.364207 \n",
      "Batch: 2136. Acc: 0.512739. Loss: 1.350788. Batch_acc: 0.522914. Batch_loss: 1.330677 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2137. Acc: 0.512747. Loss: 1.350767. Batch_acc: 0.529904. Batch_loss: 1.303013 \n",
      "Batch: 2138. Acc: 0.512755. Loss: 1.350748. Batch_acc: 0.531159. Batch_loss: 1.309665 \n",
      "Batch: 2139. Acc: 0.512755. Loss: 1.350762. Batch_acc: 0.512321. Batch_loss: 1.381343 \n",
      "Batch: 2140. Acc: 0.512752. Loss: 1.350774. Batch_acc: 0.505848. Batch_loss: 1.378048 \n",
      "Batch: 2141. Acc: 0.512763. Loss: 1.350754. Batch_acc: 0.536765. Batch_loss: 1.308082 \n",
      "Batch: 2142. Acc: 0.512765. Loss: 1.350746. Batch_acc: 0.516637. Batch_loss: 1.333490 \n",
      "Batch: 2143. Acc: 0.512765. Loss: 1.350738. Batch_acc: 0.512586. Batch_loss: 1.332221 \n",
      "Batch: 2144. Acc: 0.512770. Loss: 1.350721. Batch_acc: 0.523536. Batch_loss: 1.314905 \n",
      "Batch: 2145. Acc: 0.512784. Loss: 1.350683. Batch_acc: 0.543330. Batch_loss: 1.270538 \n",
      "Batch: 2146. Acc: 0.512775. Loss: 1.350702. Batch_acc: 0.492554. Batch_loss: 1.391462 \n",
      "Batch: 2147. Acc: 0.512776. Loss: 1.350697. Batch_acc: 0.515698. Batch_loss: 1.340030 \n",
      "Batch: 2148. Acc: 0.512786. Loss: 1.350682. Batch_acc: 0.533753. Batch_loss: 1.318194 \n",
      "Batch: 2149. Acc: 0.512787. Loss: 1.350685. Batch_acc: 0.514580. Batch_loss: 1.357051 \n",
      "Batch: 2150. Acc: 0.512785. Loss: 1.350677. Batch_acc: 0.508552. Batch_loss: 1.334363 \n",
      "Batch: 2151. Acc: 0.512795. Loss: 1.350658. Batch_acc: 0.534620. Batch_loss: 1.309257 \n",
      "Batch: 2152. Acc: 0.512787. Loss: 1.350673. Batch_acc: 0.494186. Batch_loss: 1.383354 \n",
      "Batch: 2153. Acc: 0.512793. Loss: 1.350673. Batch_acc: 0.527155. Batch_loss: 1.349939 \n",
      "Batch: 2154. Acc: 0.512797. Loss: 1.350665. Batch_acc: 0.520880. Batch_loss: 1.335254 \n",
      "Batch: 2155. Acc: 0.512800. Loss: 1.350657. Batch_acc: 0.520367. Batch_loss: 1.332969 \n",
      "Batch: 2156. Acc: 0.512813. Loss: 1.350625. Batch_acc: 0.540249. Batch_loss: 1.283398 \n",
      "Batch: 2157. Acc: 0.512815. Loss: 1.350636. Batch_acc: 0.515679. Batch_loss: 1.373068 \n",
      "Batch: 2158. Acc: 0.512812. Loss: 1.350649. Batch_acc: 0.507471. Batch_loss: 1.378999 \n",
      "Batch: 2159. Acc: 0.512825. Loss: 1.350616. Batch_acc: 0.539199. Batch_loss: 1.280135 \n",
      "Batch: 2160. Acc: 0.512831. Loss: 1.350602. Batch_acc: 0.526316. Batch_loss: 1.322106 \n",
      "Batch: 2161. Acc: 0.512832. Loss: 1.350592. Batch_acc: 0.516035. Batch_loss: 1.328857 \n",
      "Batch: 2162. Acc: 0.512838. Loss: 1.350576. Batch_acc: 0.524103. Batch_loss: 1.316385 \n",
      "Batch: 2163. Acc: 0.512840. Loss: 1.350556. Batch_acc: 0.518540. Batch_loss: 1.307480 \n",
      "Batch: 2164. Acc: 0.512858. Loss: 1.350514. Batch_acc: 0.551606. Batch_loss: 1.259578 \n",
      "Batch: 2165. Acc: 0.512852. Loss: 1.350528. Batch_acc: 0.499710. Batch_loss: 1.380915 \n",
      "Batch: 2166. Acc: 0.512851. Loss: 1.350524. Batch_acc: 0.509827. Batch_loss: 1.341005 \n",
      "Batch: 2167. Acc: 0.512852. Loss: 1.350511. Batch_acc: 0.514319. Batch_loss: 1.322029 \n",
      "Batch: 2168. Acc: 0.512864. Loss: 1.350483. Batch_acc: 0.540171. Batch_loss: 1.290713 \n",
      "Batch: 2169. Acc: 0.512860. Loss: 1.350489. Batch_acc: 0.504094. Batch_loss: 1.363536 \n",
      "Batch: 2170. Acc: 0.512869. Loss: 1.350464. Batch_acc: 0.531106. Batch_loss: 1.297228 \n",
      "Batch: 2171. Acc: 0.512865. Loss: 1.350488. Batch_acc: 0.504945. Batch_loss: 1.403367 \n",
      "Batch: 2172. Acc: 0.512877. Loss: 1.350461. Batch_acc: 0.539481. Batch_loss: 1.291032 \n",
      "Batch: 2173. Acc: 0.512885. Loss: 1.350453. Batch_acc: 0.529924. Batch_loss: 1.331868 \n",
      "Batch: 2174. Acc: 0.512885. Loss: 1.350438. Batch_acc: 0.513730. Batch_loss: 1.317800 \n",
      "Batch: 2175. Acc: 0.512880. Loss: 1.350453. Batch_acc: 0.500000. Batch_loss: 1.384942 \n",
      "Batch: 2176. Acc: 0.512881. Loss: 1.350433. Batch_acc: 0.516148. Batch_loss: 1.306493 \n",
      "Batch: 2177. Acc: 0.512888. Loss: 1.350422. Batch_acc: 0.528205. Batch_loss: 1.326237 \n",
      "Batch: 2178. Acc: 0.512891. Loss: 1.350407. Batch_acc: 0.519088. Batch_loss: 1.319362 \n",
      "Batch: 2179. Acc: 0.512903. Loss: 1.350376. Batch_acc: 0.539646. Batch_loss: 1.283350 \n",
      "Batch: 2180. Acc: 0.512900. Loss: 1.350383. Batch_acc: 0.504545. Batch_loss: 1.363583 \n",
      "Batch: 2181. Acc: 0.512888. Loss: 1.350402. Batch_acc: 0.487507. Batch_loss: 1.394097 \n",
      "Batch: 2182. Acc: 0.512898. Loss: 1.350374. Batch_acc: 0.535429. Batch_loss: 1.289695 \n",
      "Batch: 2183. Acc: 0.512904. Loss: 1.350368. Batch_acc: 0.524702. Batch_loss: 1.335591 \n",
      "Batch: 2184. Acc: 0.512905. Loss: 1.350377. Batch_acc: 0.516222. Batch_loss: 1.372222 \n",
      "Batch: 2185. Acc: 0.512898. Loss: 1.350383. Batch_acc: 0.497069. Batch_loss: 1.361743 \n",
      "Batch: 2186. Acc: 0.512904. Loss: 1.350367. Batch_acc: 0.524724. Batch_loss: 1.315834 \n",
      "Batch: 2187. Acc: 0.512913. Loss: 1.350353. Batch_acc: 0.534573. Batch_loss: 1.319815 \n",
      "Batch: 2188. Acc: 0.512921. Loss: 1.350334. Batch_acc: 0.529343. Batch_loss: 1.308185 \n",
      "Batch: 2189. Acc: 0.512930. Loss: 1.350316. Batch_acc: 0.533295. Batch_loss: 1.311555 \n",
      "Batch: 2190. Acc: 0.512933. Loss: 1.350290. Batch_acc: 0.518414. Batch_loss: 1.294508 \n",
      "Batch: 2191. Acc: 0.512935. Loss: 1.350279. Batch_acc: 0.518114. Batch_loss: 1.326250 \n",
      "Batch: 2192. Acc: 0.512943. Loss: 1.350275. Batch_acc: 0.530052. Batch_loss: 1.340878 \n",
      "Batch: 2193. Acc: 0.512958. Loss: 1.350232. Batch_acc: 0.545759. Batch_loss: 1.258303 \n",
      "Batch: 2194. Acc: 0.512961. Loss: 1.350222. Batch_acc: 0.519602. Batch_loss: 1.327585 \n",
      "Batch: 2195. Acc: 0.512969. Loss: 1.350200. Batch_acc: 0.529613. Batch_loss: 1.302258 \n",
      "Batch: 2196. Acc: 0.512974. Loss: 1.350178. Batch_acc: 0.523782. Batch_loss: 1.300665 \n",
      "Batch: 2197. Acc: 0.512984. Loss: 1.350148. Batch_acc: 0.533442. Batch_loss: 1.288067 \n",
      "Batch: 2198. Acc: 0.513008. Loss: 1.350088. Batch_acc: 0.567458. Batch_loss: 1.217089 \n",
      "Batch: 2199. Acc: 0.513016. Loss: 1.350071. Batch_acc: 0.528846. Batch_loss: 1.313252 \n",
      "Batch: 2200. Acc: 0.513009. Loss: 1.350080. Batch_acc: 0.499132. Batch_loss: 1.370146 \n",
      "Batch: 2201. Acc: 0.513003. Loss: 1.350092. Batch_acc: 0.500000. Batch_loss: 1.377470 \n",
      "Batch: 2202. Acc: 0.512994. Loss: 1.350115. Batch_acc: 0.490566. Batch_loss: 1.402030 \n",
      "Batch: 2203. Acc: 0.512998. Loss: 1.350098. Batch_acc: 0.522752. Batch_loss: 1.314019 \n",
      "Batch: 2204. Acc: 0.513008. Loss: 1.350078. Batch_acc: 0.534424. Batch_loss: 1.307042 \n",
      "Batch: 2205. Acc: 0.513016. Loss: 1.350066. Batch_acc: 0.532078. Batch_loss: 1.321800 \n",
      "Batch: 2206. Acc: 0.513003. Loss: 1.350095. Batch_acc: 0.483607. Batch_loss: 1.415607 \n",
      "Batch: 2207. Acc: 0.512998. Loss: 1.350095. Batch_acc: 0.502281. Batch_loss: 1.351301 \n",
      "Batch: 2208. Acc: 0.513007. Loss: 1.350068. Batch_acc: 0.531854. Batch_loss: 1.289930 \n",
      "Batch: 2209. Acc: 0.513008. Loss: 1.350044. Batch_acc: 0.516018. Batch_loss: 1.298250 \n",
      "Batch: 2210. Acc: 0.512999. Loss: 1.350064. Batch_acc: 0.492156. Batch_loss: 1.393090 \n",
      "Batch: 2211. Acc: 0.513002. Loss: 1.350056. Batch_acc: 0.520255. Batch_loss: 1.333905 \n",
      "Batch: 2212. Acc: 0.512997. Loss: 1.350067. Batch_acc: 0.501203. Batch_loss: 1.374050 \n",
      "Batch: 2213. Acc: 0.513002. Loss: 1.350058. Batch_acc: 0.523921. Batch_loss: 1.331110 \n",
      "Batch: 2214. Acc: 0.513010. Loss: 1.350041. Batch_acc: 0.530742. Batch_loss: 1.311222 \n",
      "Batch: 2215. Acc: 0.513009. Loss: 1.350044. Batch_acc: 0.510112. Batch_loss: 1.355827 \n",
      "Batch: 2216. Acc: 0.513010. Loss: 1.350046. Batch_acc: 0.515670. Batch_loss: 1.354729 \n",
      "Batch: 2217. Acc: 0.513011. Loss: 1.350049. Batch_acc: 0.514689. Batch_loss: 1.358214 \n",
      "Batch: 2218. Acc: 0.513014. Loss: 1.350045. Batch_acc: 0.520255. Batch_loss: 1.340711 \n",
      "Batch: 2219. Acc: 0.513015. Loss: 1.350040. Batch_acc: 0.516204. Batch_loss: 1.338504 \n",
      "Batch: 2220. Acc: 0.513003. Loss: 1.350059. Batch_acc: 0.484602. Batch_loss: 1.391906 \n",
      "Batch: 2221. Acc: 0.513003. Loss: 1.350063. Batch_acc: 0.512821. Batch_loss: 1.358398 \n",
      "Batch: 2222. Acc: 0.513005. Loss: 1.350049. Batch_acc: 0.518884. Batch_loss: 1.320636 \n",
      "Batch: 2223. Acc: 0.513011. Loss: 1.350036. Batch_acc: 0.526496. Batch_loss: 1.320850 \n",
      "Batch: 2224. Acc: 0.513010. Loss: 1.350032. Batch_acc: 0.509059. Batch_loss: 1.340988 \n",
      "Batch: 2225. Acc: 0.513005. Loss: 1.350036. Batch_acc: 0.502328. Batch_loss: 1.358668 \n",
      "Batch: 2226. Acc: 0.513007. Loss: 1.350027. Batch_acc: 0.516695. Batch_loss: 1.330189 \n",
      "Batch: 2227. Acc: 0.513012. Loss: 1.350015. Batch_acc: 0.524758. Batch_loss: 1.324309 \n",
      "Batch: 2228. Acc: 0.513003. Loss: 1.350044. Batch_acc: 0.493870. Batch_loss: 1.415293 \n",
      "Batch: 2229. Acc: 0.513002. Loss: 1.350061. Batch_acc: 0.510024. Batch_loss: 1.387834 \n",
      "Batch: 2230. Acc: 0.513004. Loss: 1.350053. Batch_acc: 0.517282. Batch_loss: 1.332444 \n",
      "Batch: 2231. Acc: 0.513007. Loss: 1.350049. Batch_acc: 0.519340. Batch_loss: 1.341666 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2232. Acc: 0.513000. Loss: 1.350070. Batch_acc: 0.496859. Batch_loss: 1.396004 \n",
      "Batch: 2233. Acc: 0.513013. Loss: 1.350039. Batch_acc: 0.543503. Batch_loss: 1.280361 \n",
      "Batch: 2234. Acc: 0.513016. Loss: 1.350027. Batch_acc: 0.519164. Batch_loss: 1.323674 \n",
      "Batch: 2235. Acc: 0.513038. Loss: 1.349984. Batch_acc: 0.561707. Batch_loss: 1.253194 \n",
      "Batch: 2236. Acc: 0.513049. Loss: 1.349946. Batch_acc: 0.537943. Batch_loss: 1.266791 \n",
      "Batch: 2237. Acc: 0.513057. Loss: 1.349922. Batch_acc: 0.531144. Batch_loss: 1.296860 \n",
      "Batch: 2238. Acc: 0.513062. Loss: 1.349906. Batch_acc: 0.522998. Batch_loss: 1.313948 \n",
      "Batch: 2239. Acc: 0.513072. Loss: 1.349871. Batch_acc: 0.535411. Batch_loss: 1.273088 \n",
      "Batch: 2240. Acc: 0.513073. Loss: 1.349861. Batch_acc: 0.515957. Batch_loss: 1.327652 \n",
      "Batch: 2241. Acc: 0.513069. Loss: 1.349861. Batch_acc: 0.504060. Batch_loss: 1.348816 \n",
      "Batch: 2242. Acc: 0.513070. Loss: 1.349858. Batch_acc: 0.514351. Batch_loss: 1.343325 \n",
      "Batch: 2243. Acc: 0.513076. Loss: 1.349851. Batch_acc: 0.527366. Batch_loss: 1.335047 \n",
      "Batch: 2244. Acc: 0.513080. Loss: 1.349844. Batch_acc: 0.521968. Batch_loss: 1.334623 \n",
      "Batch: 2245. Acc: 0.513086. Loss: 1.349840. Batch_acc: 0.527326. Batch_loss: 1.339346 \n",
      "Batch: 2246. Acc: 0.513095. Loss: 1.349819. Batch_acc: 0.532460. Batch_loss: 1.303865 \n",
      "Batch: 2247. Acc: 0.513094. Loss: 1.349818. Batch_acc: 0.511163. Batch_loss: 1.347947 \n",
      "Batch: 2248. Acc: 0.513095. Loss: 1.349827. Batch_acc: 0.515882. Batch_loss: 1.369520 \n",
      "Batch: 2249. Acc: 0.513101. Loss: 1.349820. Batch_acc: 0.525127. Batch_loss: 1.333964 \n",
      "Batch: 2250. Acc: 0.513103. Loss: 1.349829. Batch_acc: 0.517878. Batch_loss: 1.372316 \n",
      "Batch: 2251. Acc: 0.513105. Loss: 1.349832. Batch_acc: 0.517654. Batch_loss: 1.354829 \n",
      "Batch: 2252. Acc: 0.513120. Loss: 1.349784. Batch_acc: 0.546023. Batch_loss: 1.243603 \n",
      "Batch: 2253. Acc: 0.513131. Loss: 1.349758. Batch_acc: 0.538995. Batch_loss: 1.291818 \n",
      "Batch: 2254. Acc: 0.513129. Loss: 1.349756. Batch_acc: 0.509249. Batch_loss: 1.344332 \n",
      "Batch: 2255. Acc: 0.513143. Loss: 1.349725. Batch_acc: 0.542458. Batch_loss: 1.281714 \n",
      "Batch: 2256. Acc: 0.513145. Loss: 1.349723. Batch_acc: 0.517462. Batch_loss: 1.346217 \n",
      "Batch: 2257. Acc: 0.513154. Loss: 1.349690. Batch_acc: 0.534239. Batch_loss: 1.274990 \n",
      "Batch: 2258. Acc: 0.513158. Loss: 1.349678. Batch_acc: 0.522235. Batch_loss: 1.323746 \n",
      "Batch: 2259. Acc: 0.513172. Loss: 1.349634. Batch_acc: 0.542129. Batch_loss: 1.254043 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.5131715950361424. Loss per char: 1.3496340637528206. Time: 1627219766.0510178\n",
      "Last question is tensor([ 2, 18, 25, 15, 23, 25, 12, 21, 19, 17, 25, 21, 26, 19, 18, 26, 20, 18,\n",
      "        25,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.513172. Loss: 1.349623. Batch_acc: 0.515064. Batch_loss: 1.324107 \n",
      "Batch: 2261. Acc: 0.513186. Loss: 1.349596. Batch_acc: 0.542679. Batch_loss: 1.290761 \n",
      "Batch: 2262. Acc: 0.513186. Loss: 1.349595. Batch_acc: 0.514765. Batch_loss: 1.346203 \n",
      "Batch: 2263. Acc: 0.513186. Loss: 1.349593. Batch_acc: 0.512911. Batch_loss: 1.344620 \n",
      "Batch: 2264. Acc: 0.513191. Loss: 1.349585. Batch_acc: 0.523918. Batch_loss: 1.332944 \n",
      "Batch: 2265. Acc: 0.513198. Loss: 1.349573. Batch_acc: 0.527972. Batch_loss: 1.321621 \n",
      "Batch: 2266. Acc: 0.513197. Loss: 1.349561. Batch_acc: 0.511344. Batch_loss: 1.321224 \n",
      "Batch: 2267. Acc: 0.513188. Loss: 1.349578. Batch_acc: 0.492035. Batch_loss: 1.389732 \n",
      "Batch: 2268. Acc: 0.513177. Loss: 1.349589. Batch_acc: 0.488166. Batch_loss: 1.375697 \n",
      "Batch: 2269. Acc: 0.513179. Loss: 1.349585. Batch_acc: 0.517973. Batch_loss: 1.340511 \n",
      "Batch: 2270. Acc: 0.513187. Loss: 1.349559. Batch_acc: 0.530814. Batch_loss: 1.288384 \n",
      "Batch: 2271. Acc: 0.513185. Loss: 1.349564. Batch_acc: 0.510482. Batch_loss: 1.361749 \n",
      "Batch: 2272. Acc: 0.513196. Loss: 1.349545. Batch_acc: 0.536041. Batch_loss: 1.306041 \n",
      "Batch: 2273. Acc: 0.513199. Loss: 1.349533. Batch_acc: 0.521790. Batch_loss: 1.323383 \n",
      "Batch: 2274. Acc: 0.513209. Loss: 1.349505. Batch_acc: 0.535572. Batch_loss: 1.285493 \n",
      "Batch: 2275. Acc: 0.513218. Loss: 1.349490. Batch_acc: 0.532258. Batch_loss: 1.315835 \n",
      "Batch: 2276. Acc: 0.513222. Loss: 1.349481. Batch_acc: 0.523837. Batch_loss: 1.328536 \n",
      "Batch: 2277. Acc: 0.513215. Loss: 1.349491. Batch_acc: 0.496301. Batch_loss: 1.371161 \n",
      "Batch: 2278. Acc: 0.513215. Loss: 1.349486. Batch_acc: 0.513466. Batch_loss: 1.339254 \n",
      "Batch: 2279. Acc: 0.513220. Loss: 1.349469. Batch_acc: 0.524819. Batch_loss: 1.310962 \n",
      "Batch: 2280. Acc: 0.513219. Loss: 1.349474. Batch_acc: 0.510204. Batch_loss: 1.361687 \n",
      "Batch: 2281. Acc: 0.513223. Loss: 1.349455. Batch_acc: 0.521940. Batch_loss: 1.305208 \n",
      "Batch: 2282. Acc: 0.513224. Loss: 1.349445. Batch_acc: 0.516914. Batch_loss: 1.326913 \n",
      "Batch: 2283. Acc: 0.513226. Loss: 1.349435. Batch_acc: 0.518452. Batch_loss: 1.324367 \n",
      "Batch: 2284. Acc: 0.513233. Loss: 1.349405. Batch_acc: 0.528949. Batch_loss: 1.284249 \n",
      "Batch: 2285. Acc: 0.513232. Loss: 1.349408. Batch_acc: 0.509769. Batch_loss: 1.356032 \n",
      "Batch: 2286. Acc: 0.513233. Loss: 1.349420. Batch_acc: 0.515687. Batch_loss: 1.375626 \n",
      "Batch: 2287. Acc: 0.513240. Loss: 1.349412. Batch_acc: 0.529678. Batch_loss: 1.331451 \n",
      "Batch: 2288. Acc: 0.513242. Loss: 1.349400. Batch_acc: 0.515945. Batch_loss: 1.322281 \n",
      "Batch: 2289. Acc: 0.513230. Loss: 1.349420. Batch_acc: 0.485532. Batch_loss: 1.395078 \n",
      "Batch: 2290. Acc: 0.513238. Loss: 1.349392. Batch_acc: 0.533256. Batch_loss: 1.285652 \n",
      "Batch: 2291. Acc: 0.513249. Loss: 1.349375. Batch_acc: 0.537975. Batch_loss: 1.310580 \n",
      "Batch: 2292. Acc: 0.513255. Loss: 1.349362. Batch_acc: 0.527180. Batch_loss: 1.320016 \n",
      "Batch: 2293. Acc: 0.513259. Loss: 1.349349. Batch_acc: 0.522190. Batch_loss: 1.318707 \n",
      "Batch: 2294. Acc: 0.513262. Loss: 1.349348. Batch_acc: 0.519110. Batch_loss: 1.347191 \n",
      "Batch: 2295. Acc: 0.513266. Loss: 1.349331. Batch_acc: 0.523370. Batch_loss: 1.311728 \n",
      "Batch: 2296. Acc: 0.513272. Loss: 1.349324. Batch_acc: 0.525926. Batch_loss: 1.332281 \n",
      "Batch: 2297. Acc: 0.513270. Loss: 1.349320. Batch_acc: 0.510602. Batch_loss: 1.341584 \n",
      "Batch: 2298. Acc: 0.513276. Loss: 1.349311. Batch_acc: 0.526559. Batch_loss: 1.327069 \n",
      "Batch: 2299. Acc: 0.513274. Loss: 1.349316. Batch_acc: 0.508999. Batch_loss: 1.361512 \n",
      "Batch: 2300. Acc: 0.513285. Loss: 1.349280. Batch_acc: 0.536723. Batch_loss: 1.267350 \n",
      "Batch: 2301. Acc: 0.513277. Loss: 1.349287. Batch_acc: 0.495184. Batch_loss: 1.366401 \n",
      "Batch: 2302. Acc: 0.513291. Loss: 1.349255. Batch_acc: 0.546119. Batch_loss: 1.275789 \n",
      "Batch: 2303. Acc: 0.513307. Loss: 1.349229. Batch_acc: 0.548278. Batch_loss: 1.291709 \n",
      "Batch: 2304. Acc: 0.513305. Loss: 1.349250. Batch_acc: 0.508512. Batch_loss: 1.395163 \n",
      "Batch: 2305. Acc: 0.513310. Loss: 1.349252. Batch_acc: 0.525394. Batch_loss: 1.352676 \n",
      "Batch: 2306. Acc: 0.513325. Loss: 1.349215. Batch_acc: 0.549623. Batch_loss: 1.262701 \n",
      "Batch: 2307. Acc: 0.513331. Loss: 1.349197. Batch_acc: 0.527011. Batch_loss: 1.308377 \n",
      "Batch: 2308. Acc: 0.513330. Loss: 1.349189. Batch_acc: 0.510686. Batch_loss: 1.331672 \n",
      "Batch: 2309. Acc: 0.513330. Loss: 1.349196. Batch_acc: 0.512382. Batch_loss: 1.364661 \n",
      "Batch: 2310. Acc: 0.513334. Loss: 1.349191. Batch_acc: 0.524533. Batch_loss: 1.339216 \n",
      "Batch: 2311. Acc: 0.513339. Loss: 1.349185. Batch_acc: 0.522972. Batch_loss: 1.335591 \n",
      "Batch: 2312. Acc: 0.513336. Loss: 1.349195. Batch_acc: 0.507909. Batch_loss: 1.372334 \n",
      "Batch: 2313. Acc: 0.513355. Loss: 1.349157. Batch_acc: 0.556818. Batch_loss: 1.262679 \n",
      "Batch: 2314. Acc: 0.513364. Loss: 1.349132. Batch_acc: 0.533256. Batch_loss: 1.289605 \n",
      "Batch: 2315. Acc: 0.513367. Loss: 1.349129. Batch_acc: 0.521639. Batch_loss: 1.342955 \n",
      "Batch: 2316. Acc: 0.513375. Loss: 1.349105. Batch_acc: 0.530692. Batch_loss: 1.293592 \n",
      "Batch: 2317. Acc: 0.513378. Loss: 1.349095. Batch_acc: 0.519703. Batch_loss: 1.327461 \n",
      "Batch: 2318. Acc: 0.513381. Loss: 1.349080. Batch_acc: 0.521790. Batch_loss: 1.313135 \n",
      "Batch: 2319. Acc: 0.513376. Loss: 1.349089. Batch_acc: 0.499714. Batch_loss: 1.369672 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2320. Acc: 0.513383. Loss: 1.349075. Batch_acc: 0.530577. Batch_loss: 1.317443 \n",
      "Batch: 2321. Acc: 0.513381. Loss: 1.349069. Batch_acc: 0.509477. Batch_loss: 1.335531 \n",
      "Batch: 2322. Acc: 0.513391. Loss: 1.349048. Batch_acc: 0.535138. Batch_loss: 1.298782 \n",
      "Batch: 2323. Acc: 0.513388. Loss: 1.349057. Batch_acc: 0.508262. Batch_loss: 1.370834 \n",
      "Batch: 2324. Acc: 0.513401. Loss: 1.349015. Batch_acc: 0.543880. Batch_loss: 1.250490 \n",
      "Batch: 2325. Acc: 0.513414. Loss: 1.348983. Batch_acc: 0.541690. Batch_loss: 1.274982 \n",
      "Batch: 2326. Acc: 0.513410. Loss: 1.348996. Batch_acc: 0.504745. Batch_loss: 1.380146 \n",
      "Batch: 2327. Acc: 0.513408. Loss: 1.349001. Batch_acc: 0.507134. Batch_loss: 1.361161 \n",
      "Batch: 2328. Acc: 0.513407. Loss: 1.348998. Batch_acc: 0.512806. Batch_loss: 1.341475 \n",
      "Batch: 2329. Acc: 0.513407. Loss: 1.348994. Batch_acc: 0.513607. Batch_loss: 1.339407 \n",
      "Batch: 2330. Acc: 0.513415. Loss: 1.348971. Batch_acc: 0.531805. Batch_loss: 1.295480 \n",
      "Batch: 2331. Acc: 0.513416. Loss: 1.348969. Batch_acc: 0.514254. Batch_loss: 1.345190 \n",
      "Batch: 2332. Acc: 0.513424. Loss: 1.348948. Batch_acc: 0.531710. Batch_loss: 1.299992 \n",
      "Batch: 2333. Acc: 0.513430. Loss: 1.348935. Batch_acc: 0.527669. Batch_loss: 1.319535 \n",
      "Batch: 2334. Acc: 0.513422. Loss: 1.348941. Batch_acc: 0.494828. Batch_loss: 1.364974 \n",
      "Batch: 2335. Acc: 0.513430. Loss: 1.348916. Batch_acc: 0.532344. Batch_loss: 1.287052 \n",
      "Batch: 2336. Acc: 0.513420. Loss: 1.348930. Batch_acc: 0.489937. Batch_loss: 1.381481 \n",
      "Batch: 2337. Acc: 0.513425. Loss: 1.348906. Batch_acc: 0.524943. Batch_loss: 1.294960 \n",
      "Batch: 2338. Acc: 0.513435. Loss: 1.348881. Batch_acc: 0.537478. Batch_loss: 1.289152 \n",
      "Batch: 2339. Acc: 0.513440. Loss: 1.348867. Batch_acc: 0.526528. Batch_loss: 1.316200 \n",
      "Batch: 2340. Acc: 0.513434. Loss: 1.348884. Batch_acc: 0.497658. Batch_loss: 1.389588 \n",
      "Batch: 2341. Acc: 0.513427. Loss: 1.348882. Batch_acc: 0.497630. Batch_loss: 1.343795 \n",
      "Batch: 2342. Acc: 0.513432. Loss: 1.348860. Batch_acc: 0.524758. Batch_loss: 1.298144 \n",
      "Batch: 2343. Acc: 0.513433. Loss: 1.348862. Batch_acc: 0.516276. Batch_loss: 1.353250 \n",
      "Batch: 2344. Acc: 0.513440. Loss: 1.348849. Batch_acc: 0.529915. Batch_loss: 1.318170 \n",
      "Batch: 2345. Acc: 0.513450. Loss: 1.348828. Batch_acc: 0.535301. Batch_loss: 1.299888 \n",
      "Batch: 2346. Acc: 0.513454. Loss: 1.348812. Batch_acc: 0.523728. Batch_loss: 1.310764 \n",
      "Batch: 2347. Acc: 0.513458. Loss: 1.348803. Batch_acc: 0.523375. Batch_loss: 1.328001 \n",
      "Batch: 2348. Acc: 0.513463. Loss: 1.348792. Batch_acc: 0.523892. Batch_loss: 1.324570 \n",
      "Batch: 2349. Acc: 0.513466. Loss: 1.348781. Batch_acc: 0.520540. Batch_loss: 1.322879 \n",
      "Batch: 2350. Acc: 0.513461. Loss: 1.348791. Batch_acc: 0.500583. Batch_loss: 1.373154 \n",
      "Batch: 2351. Acc: 0.513463. Loss: 1.348794. Batch_acc: 0.519504. Batch_loss: 1.353986 \n",
      "Batch: 2352. Acc: 0.513465. Loss: 1.348795. Batch_acc: 0.517361. Batch_loss: 1.352335 \n",
      "Batch: 2353. Acc: 0.513477. Loss: 1.348762. Batch_acc: 0.541642. Batch_loss: 1.269010 \n",
      "Batch: 2354. Acc: 0.513478. Loss: 1.348760. Batch_acc: 0.517739. Batch_loss: 1.345612 \n",
      "Batch: 2355. Acc: 0.513486. Loss: 1.348741. Batch_acc: 0.531840. Batch_loss: 1.303301 \n",
      "Batch: 2356. Acc: 0.513498. Loss: 1.348710. Batch_acc: 0.541547. Batch_loss: 1.274809 \n",
      "Batch: 2357. Acc: 0.513509. Loss: 1.348679. Batch_acc: 0.539933. Batch_loss: 1.277166 \n",
      "Batch: 2358. Acc: 0.513518. Loss: 1.348645. Batch_acc: 0.534642. Batch_loss: 1.268067 \n",
      "Batch: 2359. Acc: 0.513526. Loss: 1.348615. Batch_acc: 0.530843. Batch_loss: 1.278634 \n",
      "Batch: 2360. Acc: 0.513535. Loss: 1.348597. Batch_acc: 0.535921. Batch_loss: 1.307294 \n",
      "Batch: 2361. Acc: 0.513535. Loss: 1.348606. Batch_acc: 0.514286. Batch_loss: 1.369293 \n",
      "Batch: 2362. Acc: 0.513534. Loss: 1.348606. Batch_acc: 0.510133. Batch_loss: 1.347984 \n",
      "Batch: 2363. Acc: 0.513542. Loss: 1.348591. Batch_acc: 0.532407. Batch_loss: 1.312304 \n",
      "Batch: 2364. Acc: 0.513550. Loss: 1.348562. Batch_acc: 0.533714. Batch_loss: 1.281309 \n",
      "Batch: 2365. Acc: 0.513550. Loss: 1.348549. Batch_acc: 0.513188. Batch_loss: 1.318871 \n",
      "Batch: 2366. Acc: 0.513564. Loss: 1.348521. Batch_acc: 0.544785. Batch_loss: 1.281396 \n",
      "Batch: 2367. Acc: 0.513563. Loss: 1.348532. Batch_acc: 0.511344. Batch_loss: 1.376027 \n",
      "Batch: 2368. Acc: 0.513561. Loss: 1.348534. Batch_acc: 0.508281. Batch_loss: 1.352502 \n",
      "Batch: 2369. Acc: 0.513571. Loss: 1.348500. Batch_acc: 0.538376. Batch_loss: 1.270739 \n",
      "Batch: 2370. Acc: 0.513571. Loss: 1.348508. Batch_acc: 0.513690. Batch_loss: 1.367682 \n",
      "Batch: 2371. Acc: 0.513580. Loss: 1.348485. Batch_acc: 0.533182. Batch_loss: 1.295373 \n",
      "Batch: 2372. Acc: 0.513590. Loss: 1.348464. Batch_acc: 0.537069. Batch_loss: 1.297468 \n",
      "Batch: 2373. Acc: 0.513591. Loss: 1.348455. Batch_acc: 0.517399. Batch_loss: 1.327658 \n",
      "Batch: 2374. Acc: 0.513588. Loss: 1.348465. Batch_acc: 0.506418. Batch_loss: 1.372600 \n",
      "Batch: 2375. Acc: 0.513591. Loss: 1.348461. Batch_acc: 0.521110. Batch_loss: 1.338638 \n",
      "Batch: 2376. Acc: 0.513591. Loss: 1.348454. Batch_acc: 0.511788. Batch_loss: 1.331637 \n",
      "Batch: 2377. Acc: 0.513600. Loss: 1.348426. Batch_acc: 0.536023. Batch_loss: 1.282793 \n",
      "Batch: 2378. Acc: 0.513598. Loss: 1.348418. Batch_acc: 0.507826. Batch_loss: 1.329774 \n",
      "Batch: 2379. Acc: 0.513599. Loss: 1.348411. Batch_acc: 0.515796. Batch_loss: 1.330065 \n",
      "Batch: 2380. Acc: 0.513602. Loss: 1.348407. Batch_acc: 0.521640. Batch_loss: 1.340499 \n",
      "Batch: 2381. Acc: 0.513603. Loss: 1.348393. Batch_acc: 0.514934. Batch_loss: 1.313618 \n",
      "Batch: 2382. Acc: 0.513610. Loss: 1.348378. Batch_acc: 0.530243. Batch_loss: 1.313859 \n",
      "Batch: 2383. Acc: 0.513627. Loss: 1.348335. Batch_acc: 0.554342. Batch_loss: 1.245924 \n",
      "Batch: 2384. Acc: 0.513617. Loss: 1.348356. Batch_acc: 0.490468. Batch_loss: 1.396883 \n",
      "Batch: 2385. Acc: 0.513609. Loss: 1.348382. Batch_acc: 0.495151. Batch_loss: 1.410400 \n",
      "Batch: 2386. Acc: 0.513616. Loss: 1.348344. Batch_acc: 0.529050. Batch_loss: 1.260786 \n",
      "Batch: 2387. Acc: 0.513617. Loss: 1.348351. Batch_acc: 0.517201. Batch_loss: 1.364093 \n",
      "Batch: 2388. Acc: 0.513632. Loss: 1.348314. Batch_acc: 0.548425. Batch_loss: 1.259215 \n",
      "Batch: 2389. Acc: 0.513644. Loss: 1.348284. Batch_acc: 0.540929. Batch_loss: 1.279504 \n",
      "Batch: 2390. Acc: 0.513642. Loss: 1.348282. Batch_acc: 0.510613. Batch_loss: 1.343930 \n",
      "Batch: 2391. Acc: 0.513646. Loss: 1.348272. Batch_acc: 0.521559. Batch_loss: 1.322160 \n",
      "Batch: 2392. Acc: 0.513660. Loss: 1.348234. Batch_acc: 0.547884. Batch_loss: 1.261756 \n",
      "Batch: 2393. Acc: 0.513665. Loss: 1.348219. Batch_acc: 0.524666. Batch_loss: 1.311355 \n",
      "Batch: 2394. Acc: 0.513668. Loss: 1.348211. Batch_acc: 0.520845. Batch_loss: 1.328812 \n",
      "Batch: 2395. Acc: 0.513670. Loss: 1.348202. Batch_acc: 0.518209. Batch_loss: 1.326302 \n",
      "Batch: 2396. Acc: 0.513683. Loss: 1.348168. Batch_acc: 0.546128. Batch_loss: 1.268851 \n",
      "Batch: 2397. Acc: 0.513697. Loss: 1.348127. Batch_acc: 0.546485. Batch_loss: 1.249658 \n",
      "Batch: 2398. Acc: 0.513708. Loss: 1.348100. Batch_acc: 0.538905. Batch_loss: 1.283187 \n",
      "Batch: 2399. Acc: 0.513713. Loss: 1.348091. Batch_acc: 0.526593. Batch_loss: 1.326120 \n",
      "Batch: 2400. Acc: 0.513710. Loss: 1.348111. Batch_acc: 0.506024. Batch_loss: 1.395919 \n",
      "Batch: 2401. Acc: 0.513713. Loss: 1.348091. Batch_acc: 0.521739. Batch_loss: 1.299952 \n",
      "Batch: 2402. Acc: 0.513718. Loss: 1.348073. Batch_acc: 0.525072. Batch_loss: 1.304704 \n",
      "Batch: 2403. Acc: 0.513732. Loss: 1.348035. Batch_acc: 0.547416. Batch_loss: 1.258953 \n",
      "Batch: 2404. Acc: 0.513737. Loss: 1.348017. Batch_acc: 0.525172. Batch_loss: 1.304826 \n",
      "Batch: 2405. Acc: 0.513750. Loss: 1.347990. Batch_acc: 0.544977. Batch_loss: 1.281607 \n",
      "Batch: 2406. Acc: 0.513750. Loss: 1.347980. Batch_acc: 0.514302. Batch_loss: 1.323776 \n",
      "Batch: 2407. Acc: 0.513762. Loss: 1.347954. Batch_acc: 0.540856. Batch_loss: 1.286640 \n",
      "Batch: 2408. Acc: 0.513775. Loss: 1.347920. Batch_acc: 0.547181. Batch_loss: 1.267020 \n",
      "Batch: 2409. Acc: 0.513794. Loss: 1.347887. Batch_acc: 0.556927. Batch_loss: 1.270564 \n",
      "Batch: 2410. Acc: 0.513784. Loss: 1.347893. Batch_acc: 0.489540. Batch_loss: 1.363767 \n",
      "Batch: 2411. Acc: 0.513781. Loss: 1.347900. Batch_acc: 0.506803. Batch_loss: 1.363164 \n",
      "Batch: 2412. Acc: 0.513785. Loss: 1.347900. Batch_acc: 0.523397. Batch_loss: 1.348577 \n",
      "Batch: 2413. Acc: 0.513776. Loss: 1.347920. Batch_acc: 0.490826. Batch_loss: 1.395850 \n",
      "Batch: 2414. Acc: 0.513781. Loss: 1.347914. Batch_acc: 0.527698. Batch_loss: 1.332512 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2415. Acc: 0.513795. Loss: 1.347881. Batch_acc: 0.544897. Batch_loss: 1.272453 \n",
      "Batch: 2416. Acc: 0.513790. Loss: 1.347896. Batch_acc: 0.502006. Batch_loss: 1.383867 \n",
      "Batch: 2417. Acc: 0.513787. Loss: 1.347908. Batch_acc: 0.507665. Batch_loss: 1.376975 \n",
      "Batch: 2418. Acc: 0.513791. Loss: 1.347908. Batch_acc: 0.521512. Batch_loss: 1.347135 \n",
      "Batch: 2419. Acc: 0.513796. Loss: 1.347894. Batch_acc: 0.527922. Batch_loss: 1.313808 \n",
      "Batch: 2420. Acc: 0.513798. Loss: 1.347884. Batch_acc: 0.518884. Batch_loss: 1.323514 \n",
      "Batch: 2421. Acc: 0.513792. Loss: 1.347897. Batch_acc: 0.498585. Batch_loss: 1.379066 \n",
      "Batch: 2422. Acc: 0.513794. Loss: 1.347899. Batch_acc: 0.519242. Batch_loss: 1.353660 \n",
      "Batch: 2423. Acc: 0.513800. Loss: 1.347879. Batch_acc: 0.527262. Batch_loss: 1.298331 \n",
      "Batch: 2424. Acc: 0.513824. Loss: 1.347827. Batch_acc: 0.571185. Batch_loss: 1.224458 \n",
      "Batch: 2425. Acc: 0.513840. Loss: 1.347775. Batch_acc: 0.553387. Batch_loss: 1.222132 \n",
      "Batch: 2426. Acc: 0.513844. Loss: 1.347761. Batch_acc: 0.523782. Batch_loss: 1.313319 \n",
      "Batch: 2427. Acc: 0.513850. Loss: 1.347741. Batch_acc: 0.528389. Batch_loss: 1.299426 \n",
      "Batch: 2428. Acc: 0.513859. Loss: 1.347724. Batch_acc: 0.536385. Batch_loss: 1.305236 \n",
      "Batch: 2429. Acc: 0.513865. Loss: 1.347700. Batch_acc: 0.527479. Batch_loss: 1.289835 \n",
      "Batch: 2430. Acc: 0.513871. Loss: 1.347678. Batch_acc: 0.527892. Batch_loss: 1.293735 \n",
      "Batch: 2431. Acc: 0.513871. Loss: 1.347678. Batch_acc: 0.514370. Batch_loss: 1.348307 \n",
      "Batch: 2432. Acc: 0.513862. Loss: 1.347694. Batch_acc: 0.493333. Batch_loss: 1.386461 \n",
      "Batch: 2433. Acc: 0.513864. Loss: 1.347689. Batch_acc: 0.517161. Batch_loss: 1.334921 \n",
      "Batch: 2434. Acc: 0.513863. Loss: 1.347685. Batch_acc: 0.511163. Batch_loss: 1.337926 \n",
      "Batch: 2435. Acc: 0.513876. Loss: 1.347664. Batch_acc: 0.544633. Batch_loss: 1.296255 \n",
      "Batch: 2436. Acc: 0.513876. Loss: 1.347648. Batch_acc: 0.513905. Batch_loss: 1.309911 \n",
      "Batch: 2437. Acc: 0.513873. Loss: 1.347650. Batch_acc: 0.507401. Batch_loss: 1.352342 \n",
      "Batch: 2438. Acc: 0.513869. Loss: 1.347661. Batch_acc: 0.504060. Batch_loss: 1.375163 \n",
      "Batch: 2439. Acc: 0.513874. Loss: 1.347652. Batch_acc: 0.525862. Batch_loss: 1.325481 \n",
      "Batch: 2440. Acc: 0.513871. Loss: 1.347654. Batch_acc: 0.506257. Batch_loss: 1.351546 \n",
      "Batch: 2441. Acc: 0.513863. Loss: 1.347662. Batch_acc: 0.495090. Batch_loss: 1.368644 \n",
      "Batch: 2442. Acc: 0.513870. Loss: 1.347639. Batch_acc: 0.530045. Batch_loss: 1.290653 \n",
      "Batch: 2443. Acc: 0.513862. Loss: 1.347660. Batch_acc: 0.495682. Batch_loss: 1.399453 \n",
      "Batch: 2444. Acc: 0.513868. Loss: 1.347636. Batch_acc: 0.527491. Batch_loss: 1.290171 \n",
      "Batch: 2445. Acc: 0.513866. Loss: 1.347651. Batch_acc: 0.510063. Batch_loss: 1.383121 \n",
      "Batch: 2446. Acc: 0.513871. Loss: 1.347637. Batch_acc: 0.524590. Batch_loss: 1.313605 \n",
      "Batch: 2447. Acc: 0.513885. Loss: 1.347594. Batch_acc: 0.548032. Batch_loss: 1.241444 \n",
      "Batch: 2448. Acc: 0.513893. Loss: 1.347582. Batch_acc: 0.533105. Batch_loss: 1.317779 \n",
      "Batch: 2449. Acc: 0.513904. Loss: 1.347562. Batch_acc: 0.541906. Batch_loss: 1.300726 \n",
      "Batch: 2450. Acc: 0.513910. Loss: 1.347550. Batch_acc: 0.528716. Batch_loss: 1.318754 \n",
      "Batch: 2451. Acc: 0.513914. Loss: 1.347531. Batch_acc: 0.524166. Batch_loss: 1.300946 \n",
      "Batch: 2452. Acc: 0.513911. Loss: 1.347535. Batch_acc: 0.504865. Batch_loss: 1.357458 \n",
      "Batch: 2453. Acc: 0.513915. Loss: 1.347541. Batch_acc: 0.524763. Batch_loss: 1.361613 \n",
      "Batch: 2454. Acc: 0.513924. Loss: 1.347513. Batch_acc: 0.534130. Batch_loss: 1.277941 \n",
      "Batch: 2455. Acc: 0.513925. Loss: 1.347511. Batch_acc: 0.518432. Batch_loss: 1.342934 \n",
      "Batch: 2456. Acc: 0.513918. Loss: 1.347530. Batch_acc: 0.497143. Batch_loss: 1.393465 \n",
      "Batch: 2457. Acc: 0.513920. Loss: 1.347520. Batch_acc: 0.516848. Batch_loss: 1.324793 \n",
      "Batch: 2458. Acc: 0.513928. Loss: 1.347502. Batch_acc: 0.534231. Batch_loss: 1.300837 \n",
      "Batch: 2459. Acc: 0.513935. Loss: 1.347483. Batch_acc: 0.531448. Batch_loss: 1.300511 \n",
      "Batch: 2460. Acc: 0.513941. Loss: 1.347468. Batch_acc: 0.529241. Batch_loss: 1.310965 \n",
      "Batch: 2461. Acc: 0.513946. Loss: 1.347451. Batch_acc: 0.525797. Batch_loss: 1.306594 \n",
      "Batch: 2462. Acc: 0.513945. Loss: 1.347430. Batch_acc: 0.512595. Batch_loss: 1.294743 \n",
      "Batch: 2463. Acc: 0.513948. Loss: 1.347417. Batch_acc: 0.520071. Batch_loss: 1.313794 \n",
      "Batch: 2464. Acc: 0.513954. Loss: 1.347398. Batch_acc: 0.529977. Batch_loss: 1.300214 \n",
      "Batch: 2465. Acc: 0.513958. Loss: 1.347385. Batch_acc: 0.521665. Batch_loss: 1.317126 \n",
      "Batch: 2466. Acc: 0.513959. Loss: 1.347393. Batch_acc: 0.518282. Batch_loss: 1.365541 \n",
      "Batch: 2467. Acc: 0.513951. Loss: 1.347407. Batch_acc: 0.492883. Batch_loss: 1.384956 \n",
      "Batch: 2468. Acc: 0.513946. Loss: 1.347413. Batch_acc: 0.501761. Batch_loss: 1.361133 \n",
      "Batch: 2469. Acc: 0.513949. Loss: 1.347406. Batch_acc: 0.521562. Batch_loss: 1.331212 \n",
      "Batch: 2470. Acc: 0.513958. Loss: 1.347378. Batch_acc: 0.535251. Batch_loss: 1.278749 \n",
      "Batch: 2471. Acc: 0.513955. Loss: 1.347377. Batch_acc: 0.506195. Batch_loss: 1.345659 \n",
      "Batch: 2472. Acc: 0.513965. Loss: 1.347350. Batch_acc: 0.538114. Batch_loss: 1.280820 \n",
      "Batch: 2473. Acc: 0.513971. Loss: 1.347333. Batch_acc: 0.529944. Batch_loss: 1.306622 \n",
      "Batch: 2474. Acc: 0.513956. Loss: 1.347369. Batch_acc: 0.475545. Batch_loss: 1.437493 \n",
      "Batch: 2475. Acc: 0.513958. Loss: 1.347358. Batch_acc: 0.517674. Batch_loss: 1.321978 \n",
      "Batch: 2476. Acc: 0.513963. Loss: 1.347346. Batch_acc: 0.527684. Batch_loss: 1.317122 \n",
      "Batch: 2477. Acc: 0.513977. Loss: 1.347312. Batch_acc: 0.547411. Batch_loss: 1.261595 \n",
      "Batch: 2478. Acc: 0.513983. Loss: 1.347298. Batch_acc: 0.528580. Batch_loss: 1.313049 \n",
      "Batch: 2479. Acc: 0.513973. Loss: 1.347306. Batch_acc: 0.491178. Batch_loss: 1.368763 \n",
      "Batch: 2480. Acc: 0.513977. Loss: 1.347297. Batch_acc: 0.522114. Batch_loss: 1.323868 \n",
      "Batch: 2481. Acc: 0.513978. Loss: 1.347291. Batch_acc: 0.516905. Batch_loss: 1.332724 \n",
      "Batch: 2482. Acc: 0.513981. Loss: 1.347270. Batch_acc: 0.521863. Batch_loss: 1.296966 \n",
      "Batch: 2483. Acc: 0.513982. Loss: 1.347261. Batch_acc: 0.515759. Batch_loss: 1.324997 \n",
      "Batch: 2484. Acc: 0.513987. Loss: 1.347245. Batch_acc: 0.527051. Batch_loss: 1.304814 \n",
      "Batch: 2485. Acc: 0.513987. Loss: 1.347241. Batch_acc: 0.513970. Batch_loss: 1.338750 \n",
      "Batch: 2486. Acc: 0.513993. Loss: 1.347207. Batch_acc: 0.528808. Batch_loss: 1.263138 \n",
      "Batch: 2487. Acc: 0.513995. Loss: 1.347196. Batch_acc: 0.519839. Batch_loss: 1.319207 \n",
      "Batch: 2488. Acc: 0.514005. Loss: 1.347171. Batch_acc: 0.536974. Batch_loss: 1.287227 \n",
      "Batch: 2489. Acc: 0.514009. Loss: 1.347161. Batch_acc: 0.524321. Batch_loss: 1.320577 \n",
      "Batch: 2490. Acc: 0.514011. Loss: 1.347160. Batch_acc: 0.519058. Batch_loss: 1.344917 \n",
      "Batch: 2491. Acc: 0.514008. Loss: 1.347165. Batch_acc: 0.507623. Batch_loss: 1.361381 \n",
      "Batch: 2492. Acc: 0.514012. Loss: 1.347150. Batch_acc: 0.522985. Batch_loss: 1.306506 \n",
      "Batch: 2493. Acc: 0.514012. Loss: 1.347142. Batch_acc: 0.513937. Batch_loss: 1.326872 \n",
      "Batch: 2494. Acc: 0.514008. Loss: 1.347149. Batch_acc: 0.503534. Batch_loss: 1.366935 \n",
      "Batch: 2495. Acc: 0.514002. Loss: 1.347167. Batch_acc: 0.499160. Batch_loss: 1.390712 \n",
      "Batch: 2496. Acc: 0.513999. Loss: 1.347180. Batch_acc: 0.508132. Batch_loss: 1.378881 \n",
      "Batch: 2497. Acc: 0.514005. Loss: 1.347162. Batch_acc: 0.527421. Batch_loss: 1.300297 \n",
      "Batch: 2498. Acc: 0.514006. Loss: 1.347149. Batch_acc: 0.517647. Batch_loss: 1.315683 \n",
      "Batch: 2499. Acc: 0.514002. Loss: 1.347149. Batch_acc: 0.504603. Batch_loss: 1.346684 \n",
      "Batch: 2500. Acc: 0.514000. Loss: 1.347151. Batch_acc: 0.509402. Batch_loss: 1.353062 \n",
      "Batch: 2501. Acc: 0.514001. Loss: 1.347159. Batch_acc: 0.515274. Batch_loss: 1.367016 \n",
      "Batch: 2502. Acc: 0.514007. Loss: 1.347136. Batch_acc: 0.528345. Batch_loss: 1.290499 \n",
      "Batch: 2503. Acc: 0.513997. Loss: 1.347158. Batch_acc: 0.489577. Batch_loss: 1.403982 \n",
      "Batch: 2504. Acc: 0.513989. Loss: 1.347169. Batch_acc: 0.493023. Batch_loss: 1.375321 \n",
      "Batch: 2505. Acc: 0.514007. Loss: 1.347126. Batch_acc: 0.558957. Batch_loss: 1.239866 \n",
      "Batch: 2506. Acc: 0.514014. Loss: 1.347107. Batch_acc: 0.530659. Batch_loss: 1.299352 \n",
      "Batch: 2507. Acc: 0.514028. Loss: 1.347074. Batch_acc: 0.549550. Batch_loss: 1.267731 \n",
      "Batch: 2508. Acc: 0.514037. Loss: 1.347061. Batch_acc: 0.534573. Batch_loss: 1.312608 \n",
      "Batch: 2509. Acc: 0.514047. Loss: 1.347027. Batch_acc: 0.540401. Batch_loss: 1.262407 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2510. Acc: 0.514055. Loss: 1.347004. Batch_acc: 0.533295. Batch_loss: 1.291417 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.5140548280240066. Loss per char: 1.347004399827125. Time: 1627219972.4810612\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 17, 15, 17, 22,  1, 66, 79, 69,  1, 21, 26, 22, 24,\n",
      "        15, 21, 22, 23, 19, 23, 17, 18, 24, 18, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.514066. Loss: 1.346969. Batch_acc: 0.543188. Batch_loss: 1.257464 \n",
      "Batch: 2512. Acc: 0.514064. Loss: 1.346980. Batch_acc: 0.507280. Batch_loss: 1.375161 \n",
      "Batch: 2513. Acc: 0.514065. Loss: 1.346988. Batch_acc: 0.517203. Batch_loss: 1.367061 \n",
      "Batch: 2514. Acc: 0.514080. Loss: 1.346959. Batch_acc: 0.553477. Batch_loss: 1.271772 \n",
      "Batch: 2515. Acc: 0.514088. Loss: 1.346936. Batch_acc: 0.532022. Batch_loss: 1.291508 \n",
      "Batch: 2516. Acc: 0.514093. Loss: 1.346918. Batch_acc: 0.526432. Batch_loss: 1.303280 \n",
      "Batch: 2517. Acc: 0.514100. Loss: 1.346885. Batch_acc: 0.532276. Batch_loss: 1.265099 \n",
      "Batch: 2518. Acc: 0.514100. Loss: 1.346888. Batch_acc: 0.513905. Batch_loss: 1.354099 \n",
      "Batch: 2519. Acc: 0.514108. Loss: 1.346871. Batch_acc: 0.533256. Batch_loss: 1.303696 \n",
      "Batch: 2520. Acc: 0.514113. Loss: 1.346857. Batch_acc: 0.528596. Batch_loss: 1.310612 \n",
      "Batch: 2521. Acc: 0.514120. Loss: 1.346838. Batch_acc: 0.529924. Batch_loss: 1.299959 \n",
      "Batch: 2522. Acc: 0.514125. Loss: 1.346821. Batch_acc: 0.527730. Batch_loss: 1.303172 \n",
      "Batch: 2523. Acc: 0.514125. Loss: 1.346802. Batch_acc: 0.512953. Batch_loss: 1.300290 \n",
      "Batch: 2524. Acc: 0.514133. Loss: 1.346781. Batch_acc: 0.534123. Batch_loss: 1.294261 \n",
      "Batch: 2525. Acc: 0.514140. Loss: 1.346769. Batch_acc: 0.531782. Batch_loss: 1.315117 \n",
      "Batch: 2526. Acc: 0.514148. Loss: 1.346747. Batch_acc: 0.534066. Batch_loss: 1.294909 \n",
      "Batch: 2527. Acc: 0.514157. Loss: 1.346723. Batch_acc: 0.537665. Batch_loss: 1.285604 \n",
      "Batch: 2528. Acc: 0.514165. Loss: 1.346698. Batch_acc: 0.533753. Batch_loss: 1.284103 \n",
      "Batch: 2529. Acc: 0.514166. Loss: 1.346698. Batch_acc: 0.516258. Batch_loss: 1.346477 \n",
      "Batch: 2530. Acc: 0.514178. Loss: 1.346667. Batch_acc: 0.545040. Batch_loss: 1.268133 \n",
      "Batch: 2531. Acc: 0.514184. Loss: 1.346650. Batch_acc: 0.528775. Batch_loss: 1.304617 \n",
      "Batch: 2532. Acc: 0.514183. Loss: 1.346662. Batch_acc: 0.511252. Batch_loss: 1.377254 \n",
      "Batch: 2533. Acc: 0.514194. Loss: 1.346633. Batch_acc: 0.541522. Batch_loss: 1.273743 \n",
      "Batch: 2534. Acc: 0.514196. Loss: 1.346636. Batch_acc: 0.521118. Batch_loss: 1.353418 \n",
      "Batch: 2535. Acc: 0.514202. Loss: 1.346627. Batch_acc: 0.528441. Batch_loss: 1.324101 \n",
      "Batch: 2536. Acc: 0.514202. Loss: 1.346631. Batch_acc: 0.514121. Batch_loss: 1.358263 \n",
      "Batch: 2537. Acc: 0.514206. Loss: 1.346627. Batch_acc: 0.525287. Batch_loss: 1.335603 \n",
      "Batch: 2538. Acc: 0.514210. Loss: 1.346614. Batch_acc: 0.523727. Batch_loss: 1.313463 \n",
      "Batch: 2539. Acc: 0.514214. Loss: 1.346608. Batch_acc: 0.524900. Batch_loss: 1.331985 \n",
      "Batch: 2540. Acc: 0.514216. Loss: 1.346606. Batch_acc: 0.517857. Batch_loss: 1.342198 \n",
      "Batch: 2541. Acc: 0.514221. Loss: 1.346599. Batch_acc: 0.528969. Batch_loss: 1.327390 \n",
      "Batch: 2542. Acc: 0.514231. Loss: 1.346563. Batch_acc: 0.538287. Batch_loss: 1.255941 \n",
      "Batch: 2543. Acc: 0.514229. Loss: 1.346562. Batch_acc: 0.509904. Batch_loss: 1.345058 \n",
      "Batch: 2544. Acc: 0.514229. Loss: 1.346565. Batch_acc: 0.513234. Batch_loss: 1.353110 \n",
      "Batch: 2545. Acc: 0.514230. Loss: 1.346556. Batch_acc: 0.516408. Batch_loss: 1.323071 \n",
      "Batch: 2546. Acc: 0.514241. Loss: 1.346523. Batch_acc: 0.543901. Batch_loss: 1.261712 \n",
      "Batch: 2547. Acc: 0.514247. Loss: 1.346507. Batch_acc: 0.527700. Batch_loss: 1.307841 \n",
      "Batch: 2548. Acc: 0.514248. Loss: 1.346487. Batch_acc: 0.517674. Batch_loss: 1.295014 \n",
      "Batch: 2549. Acc: 0.514257. Loss: 1.346454. Batch_acc: 0.537037. Batch_loss: 1.261662 \n",
      "Batch: 2550. Acc: 0.514250. Loss: 1.346470. Batch_acc: 0.496575. Batch_loss: 1.386500 \n",
      "Batch: 2551. Acc: 0.514247. Loss: 1.346482. Batch_acc: 0.506969. Batch_loss: 1.377185 \n",
      "Batch: 2552. Acc: 0.514253. Loss: 1.346472. Batch_acc: 0.530707. Batch_loss: 1.322042 \n",
      "Batch: 2553. Acc: 0.514258. Loss: 1.346452. Batch_acc: 0.526593. Batch_loss: 1.293150 \n",
      "Batch: 2554. Acc: 0.514265. Loss: 1.346436. Batch_acc: 0.531631. Batch_loss: 1.307477 \n",
      "Batch: 2555. Acc: 0.514270. Loss: 1.346422. Batch_acc: 0.528141. Batch_loss: 1.310835 \n",
      "Batch: 2556. Acc: 0.514266. Loss: 1.346436. Batch_acc: 0.501777. Batch_loss: 1.381021 \n",
      "Batch: 2557. Acc: 0.514273. Loss: 1.346405. Batch_acc: 0.531561. Batch_loss: 1.270248 \n",
      "Batch: 2558. Acc: 0.514268. Loss: 1.346411. Batch_acc: 0.503641. Batch_loss: 1.362744 \n",
      "Batch: 2559. Acc: 0.514270. Loss: 1.346401. Batch_acc: 0.518873. Batch_loss: 1.320274 \n",
      "Batch: 2560. Acc: 0.514268. Loss: 1.346403. Batch_acc: 0.508272. Batch_loss: 1.353170 \n",
      "Batch: 2561. Acc: 0.514273. Loss: 1.346396. Batch_acc: 0.526925. Batch_loss: 1.326548 \n",
      "Batch: 2562. Acc: 0.514270. Loss: 1.346401. Batch_acc: 0.507790. Batch_loss: 1.359032 \n",
      "Batch: 2563. Acc: 0.514266. Loss: 1.346423. Batch_acc: 0.502636. Batch_loss: 1.403685 \n",
      "Batch: 2564. Acc: 0.514273. Loss: 1.346400. Batch_acc: 0.533599. Batch_loss: 1.288822 \n",
      "Batch: 2565. Acc: 0.514270. Loss: 1.346405. Batch_acc: 0.504278. Batch_loss: 1.358488 \n",
      "Batch: 2566. Acc: 0.514271. Loss: 1.346406. Batch_acc: 0.517379. Batch_loss: 1.350765 \n",
      "Batch: 2567. Acc: 0.514285. Loss: 1.346381. Batch_acc: 0.550581. Batch_loss: 1.280944 \n",
      "Batch: 2568. Acc: 0.514296. Loss: 1.346347. Batch_acc: 0.542067. Batch_loss: 1.260056 \n",
      "Batch: 2569. Acc: 0.514298. Loss: 1.346332. Batch_acc: 0.520893. Batch_loss: 1.307637 \n",
      "Batch: 2570. Acc: 0.514309. Loss: 1.346313. Batch_acc: 0.541763. Batch_loss: 1.297714 \n",
      "Batch: 2571. Acc: 0.514317. Loss: 1.346283. Batch_acc: 0.534286. Batch_loss: 1.269425 \n",
      "Batch: 2572. Acc: 0.514323. Loss: 1.346274. Batch_acc: 0.529514. Batch_loss: 1.323636 \n",
      "Batch: 2573. Acc: 0.514335. Loss: 1.346247. Batch_acc: 0.545455. Batch_loss: 1.278537 \n",
      "Batch: 2574. Acc: 0.514343. Loss: 1.346216. Batch_acc: 0.535795. Batch_loss: 1.265542 \n",
      "Batch: 2575. Acc: 0.514356. Loss: 1.346182. Batch_acc: 0.546525. Batch_loss: 1.261522 \n",
      "Batch: 2576. Acc: 0.514368. Loss: 1.346151. Batch_acc: 0.545819. Batch_loss: 1.265987 \n",
      "Batch: 2577. Acc: 0.514379. Loss: 1.346121. Batch_acc: 0.541049. Batch_loss: 1.271371 \n",
      "Batch: 2578. Acc: 0.514383. Loss: 1.346105. Batch_acc: 0.524590. Batch_loss: 1.304984 \n",
      "Batch: 2579. Acc: 0.514381. Loss: 1.346110. Batch_acc: 0.509281. Batch_loss: 1.359057 \n",
      "Batch: 2580. Acc: 0.514386. Loss: 1.346089. Batch_acc: 0.528356. Batch_loss: 1.292305 \n",
      "Batch: 2581. Acc: 0.514399. Loss: 1.346052. Batch_acc: 0.546473. Batch_loss: 1.251395 \n",
      "Batch: 2582. Acc: 0.514391. Loss: 1.346067. Batch_acc: 0.493239. Batch_loss: 1.386273 \n",
      "Batch: 2583. Acc: 0.514397. Loss: 1.346045. Batch_acc: 0.530029. Batch_loss: 1.288811 \n",
      "Batch: 2584. Acc: 0.514401. Loss: 1.346032. Batch_acc: 0.524581. Batch_loss: 1.312309 \n",
      "Batch: 2585. Acc: 0.514397. Loss: 1.346040. Batch_acc: 0.503751. Batch_loss: 1.367380 \n",
      "Batch: 2586. Acc: 0.514399. Loss: 1.346031. Batch_acc: 0.520870. Batch_loss: 1.321760 \n",
      "Batch: 2587. Acc: 0.514410. Loss: 1.346011. Batch_acc: 0.540834. Batch_loss: 1.293388 \n",
      "Batch: 2588. Acc: 0.514414. Loss: 1.345997. Batch_acc: 0.525648. Batch_loss: 1.311270 \n",
      "Batch: 2589. Acc: 0.514419. Loss: 1.345987. Batch_acc: 0.526894. Batch_loss: 1.318000 \n",
      "Batch: 2590. Acc: 0.514419. Loss: 1.345990. Batch_acc: 0.515723. Batch_loss: 1.355625 \n",
      "Batch: 2591. Acc: 0.514422. Loss: 1.345993. Batch_acc: 0.521277. Batch_loss: 1.351887 \n",
      "Batch: 2592. Acc: 0.514429. Loss: 1.345976. Batch_acc: 0.534503. Batch_loss: 1.302949 \n",
      "Batch: 2593. Acc: 0.514436. Loss: 1.345961. Batch_acc: 0.532407. Batch_loss: 1.306688 \n",
      "Batch: 2594. Acc: 0.514428. Loss: 1.345978. Batch_acc: 0.492529. Batch_loss: 1.388306 \n",
      "Batch: 2595. Acc: 0.514433. Loss: 1.345954. Batch_acc: 0.526316. Batch_loss: 1.287019 \n",
      "Batch: 2596. Acc: 0.514435. Loss: 1.345954. Batch_acc: 0.520564. Batch_loss: 1.346082 \n",
      "Batch: 2597. Acc: 0.514434. Loss: 1.345961. Batch_acc: 0.511829. Batch_loss: 1.363858 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2598. Acc: 0.514429. Loss: 1.345966. Batch_acc: 0.500583. Batch_loss: 1.358641 \n",
      "Batch: 2599. Acc: 0.514430. Loss: 1.345964. Batch_acc: 0.517775. Batch_loss: 1.340853 \n",
      "Batch: 2600. Acc: 0.514436. Loss: 1.345950. Batch_acc: 0.530600. Batch_loss: 1.309355 \n",
      "Batch: 2601. Acc: 0.514445. Loss: 1.345935. Batch_acc: 0.537026. Batch_loss: 1.306805 \n",
      "Batch: 2602. Acc: 0.514448. Loss: 1.345924. Batch_acc: 0.523727. Batch_loss: 1.317788 \n",
      "Batch: 2603. Acc: 0.514451. Loss: 1.345913. Batch_acc: 0.522517. Batch_loss: 1.317953 \n",
      "Batch: 2604. Acc: 0.514457. Loss: 1.345895. Batch_acc: 0.529748. Batch_loss: 1.298277 \n",
      "Batch: 2605. Acc: 0.514462. Loss: 1.345890. Batch_acc: 0.525685. Batch_loss: 1.333431 \n",
      "Batch: 2606. Acc: 0.514465. Loss: 1.345881. Batch_acc: 0.523328. Batch_loss: 1.322323 \n",
      "Batch: 2607. Acc: 0.514466. Loss: 1.345876. Batch_acc: 0.516988. Batch_loss: 1.334526 \n",
      "Batch: 2608. Acc: 0.514462. Loss: 1.345884. Batch_acc: 0.502914. Batch_loss: 1.366875 \n",
      "Batch: 2609. Acc: 0.514466. Loss: 1.345874. Batch_acc: 0.524915. Batch_loss: 1.319446 \n",
      "Batch: 2610. Acc: 0.514468. Loss: 1.345861. Batch_acc: 0.521313. Batch_loss: 1.310933 \n",
      "Batch: 2611. Acc: 0.514485. Loss: 1.345812. Batch_acc: 0.557877. Batch_loss: 1.220361 \n",
      "Batch: 2612. Acc: 0.514485. Loss: 1.345821. Batch_acc: 0.514077. Batch_loss: 1.369395 \n",
      "Batch: 2613. Acc: 0.514491. Loss: 1.345810. Batch_acc: 0.530822. Batch_loss: 1.316699 \n",
      "Batch: 2614. Acc: 0.514503. Loss: 1.345784. Batch_acc: 0.543528. Batch_loss: 1.277501 \n",
      "Batch: 2615. Acc: 0.514504. Loss: 1.345785. Batch_acc: 0.517606. Batch_loss: 1.350105 \n",
      "Batch: 2616. Acc: 0.514509. Loss: 1.345777. Batch_acc: 0.527366. Batch_loss: 1.323911 \n",
      "Batch: 2617. Acc: 0.514518. Loss: 1.345766. Batch_acc: 0.537978. Batch_loss: 1.318101 \n",
      "Batch: 2618. Acc: 0.514524. Loss: 1.345766. Batch_acc: 0.529478. Batch_loss: 1.344251 \n",
      "Batch: 2619. Acc: 0.514530. Loss: 1.345759. Batch_acc: 0.530899. Batch_loss: 1.330168 \n",
      "Batch: 2620. Acc: 0.514531. Loss: 1.345745. Batch_acc: 0.516752. Batch_loss: 1.307173 \n",
      "Batch: 2621. Acc: 0.514542. Loss: 1.345722. Batch_acc: 0.543403. Batch_loss: 1.286890 \n",
      "Batch: 2622. Acc: 0.514547. Loss: 1.345712. Batch_acc: 0.527650. Batch_loss: 1.319609 \n",
      "Batch: 2623. Acc: 0.514554. Loss: 1.345695. Batch_acc: 0.533333. Batch_loss: 1.301452 \n",
      "Batch: 2624. Acc: 0.514561. Loss: 1.345683. Batch_acc: 0.533333. Batch_loss: 1.312827 \n",
      "Batch: 2625. Acc: 0.514565. Loss: 1.345679. Batch_acc: 0.524719. Batch_loss: 1.335678 \n",
      "Batch: 2626. Acc: 0.514570. Loss: 1.345663. Batch_acc: 0.528546. Batch_loss: 1.302728 \n",
      "Batch: 2627. Acc: 0.514572. Loss: 1.345656. Batch_acc: 0.519953. Batch_loss: 1.328135 \n",
      "Batch: 2628. Acc: 0.514581. Loss: 1.345643. Batch_acc: 0.536983. Batch_loss: 1.309530 \n",
      "Batch: 2629. Acc: 0.514579. Loss: 1.345642. Batch_acc: 0.509185. Batch_loss: 1.343299 \n",
      "Batch: 2630. Acc: 0.514575. Loss: 1.345653. Batch_acc: 0.505760. Batch_loss: 1.376147 \n",
      "Batch: 2631. Acc: 0.514578. Loss: 1.345648. Batch_acc: 0.521013. Batch_loss: 1.330987 \n",
      "Batch: 2632. Acc: 0.514581. Loss: 1.345636. Batch_acc: 0.522507. Batch_loss: 1.316039 \n",
      "Batch: 2633. Acc: 0.514579. Loss: 1.345641. Batch_acc: 0.510110. Batch_loss: 1.357385 \n",
      "Batch: 2634. Acc: 0.514572. Loss: 1.345651. Batch_acc: 0.496544. Batch_loss: 1.372253 \n",
      "Batch: 2635. Acc: 0.514582. Loss: 1.345628. Batch_acc: 0.540525. Batch_loss: 1.287670 \n",
      "Batch: 2636. Acc: 0.514582. Loss: 1.345631. Batch_acc: 0.513690. Batch_loss: 1.353222 \n",
      "Batch: 2637. Acc: 0.514586. Loss: 1.345620. Batch_acc: 0.525576. Batch_loss: 1.318404 \n",
      "Batch: 2638. Acc: 0.514581. Loss: 1.345633. Batch_acc: 0.500000. Batch_loss: 1.377568 \n",
      "Batch: 2639. Acc: 0.514579. Loss: 1.345635. Batch_acc: 0.510539. Batch_loss: 1.350537 \n",
      "Batch: 2640. Acc: 0.514578. Loss: 1.345630. Batch_acc: 0.510239. Batch_loss: 1.332857 \n",
      "Batch: 2641. Acc: 0.514592. Loss: 1.345592. Batch_acc: 0.551977. Batch_loss: 1.248384 \n",
      "Batch: 2642. Acc: 0.514586. Loss: 1.345617. Batch_acc: 0.499408. Batch_loss: 1.413725 \n",
      "Batch: 2643. Acc: 0.514590. Loss: 1.345609. Batch_acc: 0.525000. Batch_loss: 1.322539 \n",
      "Batch: 2644. Acc: 0.514588. Loss: 1.345607. Batch_acc: 0.506969. Batch_loss: 1.342056 \n",
      "Batch: 2645. Acc: 0.514590. Loss: 1.345596. Batch_acc: 0.521714. Batch_loss: 1.317239 \n",
      "Batch: 2646. Acc: 0.514596. Loss: 1.345570. Batch_acc: 0.529988. Batch_loss: 1.275774 \n",
      "Batch: 2647. Acc: 0.514597. Loss: 1.345564. Batch_acc: 0.518177. Batch_loss: 1.330152 \n",
      "Batch: 2648. Acc: 0.514595. Loss: 1.345566. Batch_acc: 0.509477. Batch_loss: 1.348790 \n",
      "Batch: 2649. Acc: 0.514589. Loss: 1.345571. Batch_acc: 0.496540. Batch_loss: 1.360493 \n",
      "Batch: 2650. Acc: 0.514593. Loss: 1.345551. Batch_acc: 0.527145. Batch_loss: 1.292292 \n",
      "Batch: 2651. Acc: 0.514590. Loss: 1.345554. Batch_acc: 0.506667. Batch_loss: 1.353220 \n",
      "Batch: 2652. Acc: 0.514594. Loss: 1.345541. Batch_acc: 0.524897. Batch_loss: 1.310906 \n",
      "Batch: 2653. Acc: 0.514594. Loss: 1.345544. Batch_acc: 0.513913. Batch_loss: 1.351800 \n",
      "Batch: 2654. Acc: 0.514591. Loss: 1.345545. Batch_acc: 0.506944. Batch_loss: 1.347760 \n",
      "Batch: 2655. Acc: 0.514601. Loss: 1.345518. Batch_acc: 0.540618. Batch_loss: 1.274545 \n",
      "Batch: 2656. Acc: 0.514602. Loss: 1.345513. Batch_acc: 0.517121. Batch_loss: 1.333969 \n",
      "Batch: 2657. Acc: 0.514606. Loss: 1.345503. Batch_acc: 0.526894. Batch_loss: 1.317424 \n",
      "Batch: 2658. Acc: 0.514607. Loss: 1.345494. Batch_acc: 0.516355. Batch_loss: 1.321127 \n",
      "Batch: 2659. Acc: 0.514605. Loss: 1.345500. Batch_acc: 0.509348. Batch_loss: 1.360994 \n",
      "Batch: 2660. Acc: 0.514605. Loss: 1.345495. Batch_acc: 0.514040. Batch_loss: 1.332117 \n",
      "Batch: 2661. Acc: 0.514612. Loss: 1.345483. Batch_acc: 0.532386. Batch_loss: 1.313982 \n",
      "Batch: 2662. Acc: 0.514610. Loss: 1.345488. Batch_acc: 0.509445. Batch_loss: 1.360208 \n",
      "Batch: 2663. Acc: 0.514616. Loss: 1.345462. Batch_acc: 0.531732. Batch_loss: 1.275407 \n",
      "Batch: 2664. Acc: 0.514617. Loss: 1.345448. Batch_acc: 0.515982. Batch_loss: 1.309003 \n",
      "Batch: 2665. Acc: 0.514628. Loss: 1.345415. Batch_acc: 0.544118. Batch_loss: 1.257940 \n",
      "Batch: 2666. Acc: 0.514635. Loss: 1.345400. Batch_acc: 0.533333. Batch_loss: 1.306862 \n",
      "Batch: 2667. Acc: 0.514644. Loss: 1.345374. Batch_acc: 0.539104. Batch_loss: 1.272931 \n",
      "Batch: 2668. Acc: 0.514644. Loss: 1.345374. Batch_acc: 0.514697. Batch_loss: 1.346183 \n",
      "Batch: 2669. Acc: 0.514646. Loss: 1.345377. Batch_acc: 0.520258. Batch_loss: 1.351641 \n",
      "Batch: 2670. Acc: 0.514651. Loss: 1.345368. Batch_acc: 0.527136. Batch_loss: 1.320948 \n",
      "Batch: 2671. Acc: 0.514649. Loss: 1.345364. Batch_acc: 0.510364. Batch_loss: 1.337067 \n",
      "Batch: 2672. Acc: 0.514657. Loss: 1.345343. Batch_acc: 0.536960. Batch_loss: 1.287218 \n",
      "Batch: 2673. Acc: 0.514656. Loss: 1.345345. Batch_acc: 0.511905. Batch_loss: 1.350507 \n",
      "Batch: 2674. Acc: 0.514657. Loss: 1.345347. Batch_acc: 0.518002. Batch_loss: 1.350307 \n",
      "Batch: 2675. Acc: 0.514653. Loss: 1.345348. Batch_acc: 0.502288. Batch_loss: 1.348256 \n",
      "Batch: 2676. Acc: 0.514654. Loss: 1.345336. Batch_acc: 0.518207. Batch_loss: 1.314103 \n",
      "Batch: 2677. Acc: 0.514662. Loss: 1.345313. Batch_acc: 0.537133. Batch_loss: 1.283120 \n",
      "Batch: 2678. Acc: 0.514667. Loss: 1.345289. Batch_acc: 0.526469. Batch_loss: 1.281610 \n",
      "Batch: 2679. Acc: 0.514665. Loss: 1.345298. Batch_acc: 0.511377. Batch_loss: 1.366811 \n",
      "Batch: 2680. Acc: 0.514669. Loss: 1.345285. Batch_acc: 0.523590. Batch_loss: 1.310493 \n",
      "Batch: 2681. Acc: 0.514672. Loss: 1.345277. Batch_acc: 0.523864. Batch_loss: 1.326030 \n",
      "Batch: 2682. Acc: 0.514674. Loss: 1.345274. Batch_acc: 0.520208. Batch_loss: 1.336462 \n",
      "Batch: 2683. Acc: 0.514668. Loss: 1.345279. Batch_acc: 0.497379. Batch_loss: 1.358085 \n",
      "Batch: 2684. Acc: 0.514665. Loss: 1.345278. Batch_acc: 0.507761. Batch_loss: 1.344103 \n",
      "Batch: 2685. Acc: 0.514671. Loss: 1.345254. Batch_acc: 0.530235. Batch_loss: 1.280940 \n",
      "Batch: 2686. Acc: 0.514675. Loss: 1.345229. Batch_acc: 0.525327. Batch_loss: 1.278479 \n",
      "Batch: 2687. Acc: 0.514668. Loss: 1.345243. Batch_acc: 0.494725. Batch_loss: 1.385924 \n",
      "Batch: 2688. Acc: 0.514668. Loss: 1.345237. Batch_acc: 0.513655. Batch_loss: 1.327617 \n",
      "Batch: 2689. Acc: 0.514661. Loss: 1.345244. Batch_acc: 0.496014. Batch_loss: 1.363602 \n",
      "Batch: 2690. Acc: 0.514664. Loss: 1.345233. Batch_acc: 0.524928. Batch_loss: 1.316582 \n",
      "Batch: 2691. Acc: 0.514666. Loss: 1.345236. Batch_acc: 0.519862. Batch_loss: 1.352316 \n",
      "Batch: 2692. Acc: 0.514670. Loss: 1.345223. Batch_acc: 0.525223. Batch_loss: 1.309337 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2693. Acc: 0.514680. Loss: 1.345206. Batch_acc: 0.541808. Batch_loss: 1.300264 \n",
      "Batch: 2694. Acc: 0.514688. Loss: 1.345185. Batch_acc: 0.536416. Batch_loss: 1.287623 \n",
      "Batch: 2695. Acc: 0.514685. Loss: 1.345193. Batch_acc: 0.505562. Batch_loss: 1.368008 \n",
      "Batch: 2696. Acc: 0.514683. Loss: 1.345199. Batch_acc: 0.509501. Batch_loss: 1.360893 \n",
      "Batch: 2697. Acc: 0.514692. Loss: 1.345170. Batch_acc: 0.539205. Batch_loss: 1.269111 \n",
      "Batch: 2698. Acc: 0.514690. Loss: 1.345169. Batch_acc: 0.509782. Batch_loss: 1.341493 \n",
      "Batch: 2699. Acc: 0.514699. Loss: 1.345150. Batch_acc: 0.537839. Batch_loss: 1.294003 \n",
      "Batch: 2700. Acc: 0.514702. Loss: 1.345136. Batch_acc: 0.522634. Batch_loss: 1.307072 \n",
      "Batch: 2701. Acc: 0.514708. Loss: 1.345118. Batch_acc: 0.532749. Batch_loss: 1.294391 \n",
      "Batch: 2702. Acc: 0.514720. Loss: 1.345088. Batch_acc: 0.546473. Batch_loss: 1.266956 \n",
      "Batch: 2703. Acc: 0.514727. Loss: 1.345079. Batch_acc: 0.532407. Batch_loss: 1.320909 \n",
      "Batch: 2704. Acc: 0.514731. Loss: 1.345061. Batch_acc: 0.526980. Batch_loss: 1.294704 \n",
      "Batch: 2705. Acc: 0.514736. Loss: 1.345041. Batch_acc: 0.526404. Batch_loss: 1.293614 \n",
      "Batch: 2706. Acc: 0.514739. Loss: 1.345035. Batch_acc: 0.523755. Batch_loss: 1.328152 \n",
      "Batch: 2707. Acc: 0.514749. Loss: 1.345013. Batch_acc: 0.543058. Batch_loss: 1.283965 \n",
      "Batch: 2708. Acc: 0.514758. Loss: 1.344983. Batch_acc: 0.538724. Batch_loss: 1.263828 \n",
      "Batch: 2709. Acc: 0.514761. Loss: 1.344966. Batch_acc: 0.521714. Batch_loss: 1.300548 \n",
      "Batch: 2710. Acc: 0.514764. Loss: 1.344958. Batch_acc: 0.523167. Batch_loss: 1.323592 \n",
      "Batch: 2711. Acc: 0.514766. Loss: 1.344956. Batch_acc: 0.520868. Batch_loss: 1.338087 \n",
      "Batch: 2712. Acc: 0.514770. Loss: 1.344946. Batch_acc: 0.523385. Batch_loss: 1.319861 \n",
      "Batch: 2713. Acc: 0.514775. Loss: 1.344929. Batch_acc: 0.528258. Batch_loss: 1.297464 \n",
      "Batch: 2714. Acc: 0.514773. Loss: 1.344927. Batch_acc: 0.509145. Batch_loss: 1.339620 \n",
      "Batch: 2715. Acc: 0.514773. Loss: 1.344923. Batch_acc: 0.515083. Batch_loss: 1.335620 \n",
      "Batch: 2716. Acc: 0.514763. Loss: 1.344944. Batch_acc: 0.489250. Batch_loss: 1.400189 \n",
      "Batch: 2717. Acc: 0.514768. Loss: 1.344928. Batch_acc: 0.527460. Batch_loss: 1.302370 \n",
      "Batch: 2718. Acc: 0.514768. Loss: 1.344923. Batch_acc: 0.513341. Batch_loss: 1.331079 \n",
      "Batch: 2719. Acc: 0.514769. Loss: 1.344908. Batch_acc: 0.517796. Batch_loss: 1.305762 \n",
      "Batch: 2720. Acc: 0.514779. Loss: 1.344882. Batch_acc: 0.542841. Batch_loss: 1.273998 \n",
      "Batch: 2721. Acc: 0.514778. Loss: 1.344890. Batch_acc: 0.510381. Batch_loss: 1.367786 \n",
      "Batch: 2722. Acc: 0.514785. Loss: 1.344871. Batch_acc: 0.535652. Batch_loss: 1.293303 \n",
      "Batch: 2723. Acc: 0.514792. Loss: 1.344850. Batch_acc: 0.534262. Batch_loss: 1.284789 \n",
      "Batch: 2724. Acc: 0.514797. Loss: 1.344835. Batch_acc: 0.527088. Batch_loss: 1.306923 \n",
      "Batch: 2725. Acc: 0.514802. Loss: 1.344820. Batch_acc: 0.528691. Batch_loss: 1.305548 \n",
      "Batch: 2726. Acc: 0.514809. Loss: 1.344795. Batch_acc: 0.534025. Batch_loss: 1.274428 \n",
      "Batch: 2727. Acc: 0.514816. Loss: 1.344773. Batch_acc: 0.534938. Batch_loss: 1.283784 \n",
      "Batch: 2728. Acc: 0.514822. Loss: 1.344767. Batch_acc: 0.528819. Batch_loss: 1.328207 \n",
      "Batch: 2729. Acc: 0.514824. Loss: 1.344751. Batch_acc: 0.522569. Batch_loss: 1.300977 \n",
      "Batch: 2730. Acc: 0.514824. Loss: 1.344744. Batch_acc: 0.513592. Batch_loss: 1.327093 \n",
      "Batch: 2731. Acc: 0.514818. Loss: 1.344757. Batch_acc: 0.498549. Batch_loss: 1.378986 \n",
      "Batch: 2732. Acc: 0.514827. Loss: 1.344744. Batch_acc: 0.541197. Batch_loss: 1.307839 \n",
      "Batch: 2733. Acc: 0.514842. Loss: 1.344706. Batch_acc: 0.552573. Batch_loss: 1.244616 \n",
      "Batch: 2734. Acc: 0.514840. Loss: 1.344705. Batch_acc: 0.509346. Batch_loss: 1.343624 \n",
      "Batch: 2735. Acc: 0.514843. Loss: 1.344692. Batch_acc: 0.523343. Batch_loss: 1.308776 \n",
      "Batch: 2736. Acc: 0.514844. Loss: 1.344679. Batch_acc: 0.517479. Batch_loss: 1.309596 \n",
      "Batch: 2737. Acc: 0.514849. Loss: 1.344661. Batch_acc: 0.528637. Batch_loss: 1.294263 \n",
      "Batch: 2738. Acc: 0.514849. Loss: 1.344661. Batch_acc: 0.516618. Batch_loss: 1.343679 \n",
      "Batch: 2739. Acc: 0.514855. Loss: 1.344654. Batch_acc: 0.528874. Batch_loss: 1.326731 \n",
      "Batch: 2740. Acc: 0.514854. Loss: 1.344648. Batch_acc: 0.512864. Batch_loss: 1.328719 \n",
      "Batch: 2741. Acc: 0.514855. Loss: 1.344648. Batch_acc: 0.519198. Batch_loss: 1.345708 \n",
      "Batch: 2742. Acc: 0.514861. Loss: 1.344629. Batch_acc: 0.530577. Batch_loss: 1.289755 \n",
      "Batch: 2743. Acc: 0.514856. Loss: 1.344649. Batch_acc: 0.501426. Batch_loss: 1.399228 \n",
      "Batch: 2744. Acc: 0.514860. Loss: 1.344641. Batch_acc: 0.526378. Batch_loss: 1.322757 \n",
      "Batch: 2745. Acc: 0.514872. Loss: 1.344619. Batch_acc: 0.545403. Batch_loss: 1.285726 \n",
      "Batch: 2746. Acc: 0.514877. Loss: 1.344612. Batch_acc: 0.528377. Batch_loss: 1.326400 \n",
      "Batch: 2747. Acc: 0.514885. Loss: 1.344592. Batch_acc: 0.536488. Batch_loss: 1.288928 \n",
      "Batch: 2748. Acc: 0.514890. Loss: 1.344595. Batch_acc: 0.528547. Batch_loss: 1.352504 \n",
      "Batch: 2749. Acc: 0.514891. Loss: 1.344577. Batch_acc: 0.518454. Batch_loss: 1.294490 \n",
      "Batch: 2750. Acc: 0.514899. Loss: 1.344554. Batch_acc: 0.536000. Batch_loss: 1.282822 \n",
      "Batch: 2751. Acc: 0.514900. Loss: 1.344554. Batch_acc: 0.519473. Batch_loss: 1.344001 \n",
      "Batch: 2752. Acc: 0.514906. Loss: 1.344536. Batch_acc: 0.531321. Batch_loss: 1.295456 \n",
      "Batch: 2753. Acc: 0.514909. Loss: 1.344525. Batch_acc: 0.523402. Batch_loss: 1.314102 \n",
      "Batch: 2754. Acc: 0.514911. Loss: 1.344524. Batch_acc: 0.519563. Batch_loss: 1.342600 \n",
      "Batch: 2755. Acc: 0.514918. Loss: 1.344512. Batch_acc: 0.532986. Batch_loss: 1.310176 \n",
      "Batch: 2756. Acc: 0.514934. Loss: 1.344476. Batch_acc: 0.559511. Batch_loss: 1.250134 \n",
      "Batch: 2757. Acc: 0.514934. Loss: 1.344484. Batch_acc: 0.513306. Batch_loss: 1.366383 \n",
      "Batch: 2758. Acc: 0.514936. Loss: 1.344481. Batch_acc: 0.521277. Batch_loss: 1.335096 \n",
      "Batch: 2759. Acc: 0.514936. Loss: 1.344485. Batch_acc: 0.513944. Batch_loss: 1.355326 \n",
      "Batch: 2760. Acc: 0.514943. Loss: 1.344465. Batch_acc: 0.534734. Batch_loss: 1.289427 \n",
      "Batch: 2761. Acc: 0.514946. Loss: 1.344460. Batch_acc: 0.524628. Batch_loss: 1.331607 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.5149463267611454. Loss per char: 1.3444601764506654. Time: 1627220178.18039\n",
      "Last question is tensor([ 2, 56, 80, 83, 76,  1, 80, 86, 85,  1, 19, 15, 19, 17, 24, 21, 22, 20,\n",
      "        25,  1, 12,  1, 14, 20, 24, 24, 24, 19, 17, 15,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.514935. Loss: 1.344488. Batch_acc: 0.484277. Batch_loss: 1.419624 \n",
      "Batch: 2763. Acc: 0.514942. Loss: 1.344474. Batch_acc: 0.532131. Batch_loss: 1.308393 \n",
      "Batch: 2764. Acc: 0.514953. Loss: 1.344448. Batch_acc: 0.547483. Batch_loss: 1.271506 \n",
      "Batch: 2765. Acc: 0.514961. Loss: 1.344416. Batch_acc: 0.537659. Batch_loss: 1.256728 \n",
      "Batch: 2766. Acc: 0.514964. Loss: 1.344405. Batch_acc: 0.522688. Batch_loss: 1.314791 \n",
      "Batch: 2767. Acc: 0.514975. Loss: 1.344377. Batch_acc: 0.544126. Batch_loss: 1.266569 \n",
      "Batch: 2768. Acc: 0.514984. Loss: 1.344355. Batch_acc: 0.539747. Batch_loss: 1.284698 \n",
      "Batch: 2769. Acc: 0.514981. Loss: 1.344347. Batch_acc: 0.507982. Batch_loss: 1.322510 \n",
      "Batch: 2770. Acc: 0.514989. Loss: 1.344325. Batch_acc: 0.534871. Batch_loss: 1.285190 \n",
      "Batch: 2771. Acc: 0.514999. Loss: 1.344306. Batch_acc: 0.542622. Batch_loss: 1.289597 \n",
      "Batch: 2772. Acc: 0.515003. Loss: 1.344285. Batch_acc: 0.527088. Batch_loss: 1.286358 \n",
      "Batch: 2773. Acc: 0.515003. Loss: 1.344285. Batch_acc: 0.515868. Batch_loss: 1.343987 \n",
      "Batch: 2774. Acc: 0.514997. Loss: 1.344301. Batch_acc: 0.495868. Batch_loss: 1.390654 \n",
      "Batch: 2775. Acc: 0.515006. Loss: 1.344271. Batch_acc: 0.539646. Batch_loss: 1.261273 \n",
      "Batch: 2776. Acc: 0.515010. Loss: 1.344270. Batch_acc: 0.527728. Batch_loss: 1.341677 \n",
      "Batch: 2777. Acc: 0.515003. Loss: 1.344286. Batch_acc: 0.496023. Batch_loss: 1.389525 \n",
      "Batch: 2778. Acc: 0.515009. Loss: 1.344261. Batch_acc: 0.530752. Batch_loss: 1.274604 \n",
      "Batch: 2779. Acc: 0.515011. Loss: 1.344252. Batch_acc: 0.522170. Batch_loss: 1.319398 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2780. Acc: 0.515015. Loss: 1.344238. Batch_acc: 0.525264. Batch_loss: 1.303901 \n",
      "Batch: 2781. Acc: 0.515013. Loss: 1.344236. Batch_acc: 0.509112. Batch_loss: 1.339614 \n",
      "Batch: 2782. Acc: 0.515021. Loss: 1.344213. Batch_acc: 0.536761. Batch_loss: 1.282597 \n",
      "Batch: 2783. Acc: 0.515028. Loss: 1.344199. Batch_acc: 0.533753. Batch_loss: 1.305797 \n",
      "Batch: 2784. Acc: 0.515027. Loss: 1.344197. Batch_acc: 0.513953. Batch_loss: 1.337184 \n",
      "Batch: 2785. Acc: 0.515039. Loss: 1.344189. Batch_acc: 0.548516. Batch_loss: 1.322515 \n",
      "Batch: 2786. Acc: 0.515041. Loss: 1.344175. Batch_acc: 0.519793. Batch_loss: 1.305323 \n",
      "Batch: 2787. Acc: 0.515047. Loss: 1.344167. Batch_acc: 0.530943. Batch_loss: 1.321253 \n",
      "Batch: 2788. Acc: 0.515045. Loss: 1.344166. Batch_acc: 0.509643. Batch_loss: 1.341895 \n",
      "Batch: 2789. Acc: 0.515040. Loss: 1.344173. Batch_acc: 0.502309. Batch_loss: 1.362212 \n",
      "Batch: 2790. Acc: 0.515034. Loss: 1.344173. Batch_acc: 0.498561. Batch_loss: 1.344624 \n",
      "Batch: 2791. Acc: 0.515037. Loss: 1.344173. Batch_acc: 0.521587. Batch_loss: 1.345296 \n",
      "Batch: 2792. Acc: 0.515039. Loss: 1.344160. Batch_acc: 0.521889. Batch_loss: 1.307403 \n",
      "Batch: 2793. Acc: 0.515038. Loss: 1.344161. Batch_acc: 0.510613. Batch_loss: 1.347659 \n",
      "Batch: 2794. Acc: 0.515047. Loss: 1.344138. Batch_acc: 0.541761. Batch_loss: 1.280028 \n",
      "Batch: 2795. Acc: 0.515048. Loss: 1.344134. Batch_acc: 0.516037. Batch_loss: 1.334527 \n",
      "Batch: 2796. Acc: 0.515051. Loss: 1.344125. Batch_acc: 0.525276. Batch_loss: 1.318668 \n",
      "Batch: 2797. Acc: 0.515061. Loss: 1.344104. Batch_acc: 0.543303. Batch_loss: 1.283157 \n",
      "Batch: 2798. Acc: 0.515056. Loss: 1.344103. Batch_acc: 0.501130. Batch_loss: 1.342188 \n",
      "Batch: 2799. Acc: 0.515059. Loss: 1.344108. Batch_acc: 0.521564. Batch_loss: 1.359169 \n",
      "Batch: 2800. Acc: 0.515068. Loss: 1.344079. Batch_acc: 0.541150. Batch_loss: 1.263952 \n",
      "Batch: 2801. Acc: 0.515071. Loss: 1.344072. Batch_acc: 0.522573. Batch_loss: 1.324667 \n",
      "Batch: 2802. Acc: 0.515076. Loss: 1.344059. Batch_acc: 0.529172. Batch_loss: 1.306962 \n",
      "Batch: 2803. Acc: 0.515079. Loss: 1.344046. Batch_acc: 0.522674. Batch_loss: 1.307819 \n",
      "Batch: 2804. Acc: 0.515086. Loss: 1.344017. Batch_acc: 0.534648. Batch_loss: 1.264559 \n",
      "Batch: 2805. Acc: 0.515092. Loss: 1.343986. Batch_acc: 0.532838. Batch_loss: 1.257876 \n",
      "Batch: 2806. Acc: 0.515101. Loss: 1.343965. Batch_acc: 0.540268. Batch_loss: 1.285632 \n",
      "Batch: 2807. Acc: 0.515100. Loss: 1.343965. Batch_acc: 0.510588. Batch_loss: 1.344600 \n",
      "Batch: 2808. Acc: 0.515100. Loss: 1.343966. Batch_acc: 0.514697. Batch_loss: 1.344816 \n",
      "Batch: 2809. Acc: 0.515100. Loss: 1.343955. Batch_acc: 0.516686. Batch_loss: 1.315508 \n",
      "Batch: 2810. Acc: 0.515104. Loss: 1.343942. Batch_acc: 0.525335. Batch_loss: 1.304526 \n",
      "Batch: 2811. Acc: 0.515105. Loss: 1.343925. Batch_acc: 0.517687. Batch_loss: 1.299036 \n",
      "Batch: 2812. Acc: 0.515107. Loss: 1.343917. Batch_acc: 0.521283. Batch_loss: 1.321587 \n",
      "Batch: 2813. Acc: 0.515113. Loss: 1.343896. Batch_acc: 0.532062. Batch_loss: 1.283939 \n",
      "Batch: 2814. Acc: 0.515120. Loss: 1.343878. Batch_acc: 0.534897. Batch_loss: 1.293016 \n",
      "Batch: 2815. Acc: 0.515122. Loss: 1.343875. Batch_acc: 0.522581. Batch_loss: 1.335006 \n",
      "Batch: 2816. Acc: 0.515127. Loss: 1.343865. Batch_acc: 0.527434. Batch_loss: 1.313114 \n",
      "Batch: 2817. Acc: 0.515125. Loss: 1.343865. Batch_acc: 0.509804. Batch_loss: 1.345557 \n",
      "Batch: 2818. Acc: 0.515127. Loss: 1.343856. Batch_acc: 0.520556. Batch_loss: 1.318639 \n",
      "Batch: 2819. Acc: 0.515127. Loss: 1.343851. Batch_acc: 0.516576. Batch_loss: 1.328052 \n",
      "Batch: 2820. Acc: 0.515136. Loss: 1.343818. Batch_acc: 0.540449. Batch_loss: 1.252313 \n",
      "Batch: 2821. Acc: 0.515148. Loss: 1.343789. Batch_acc: 0.548518. Batch_loss: 1.262024 \n",
      "Batch: 2822. Acc: 0.515154. Loss: 1.343776. Batch_acc: 0.531123. Batch_loss: 1.305200 \n",
      "Batch: 2823. Acc: 0.515155. Loss: 1.343770. Batch_acc: 0.518707. Batch_loss: 1.328176 \n",
      "Batch: 2824. Acc: 0.515160. Loss: 1.343749. Batch_acc: 0.530554. Batch_loss: 1.283521 \n",
      "Batch: 2825. Acc: 0.515150. Loss: 1.343772. Batch_acc: 0.485499. Batch_loss: 1.410765 \n",
      "Batch: 2826. Acc: 0.515156. Loss: 1.343762. Batch_acc: 0.532660. Batch_loss: 1.314414 \n",
      "Batch: 2827. Acc: 0.515164. Loss: 1.343731. Batch_acc: 0.538373. Batch_loss: 1.256872 \n",
      "Batch: 2828. Acc: 0.515182. Loss: 1.343683. Batch_acc: 0.564146. Batch_loss: 1.212376 \n",
      "Batch: 2829. Acc: 0.515188. Loss: 1.343655. Batch_acc: 0.533601. Batch_loss: 1.263954 \n",
      "Batch: 2830. Acc: 0.515195. Loss: 1.343630. Batch_acc: 0.534492. Batch_loss: 1.275042 \n",
      "Batch: 2831. Acc: 0.515195. Loss: 1.343636. Batch_acc: 0.512702. Batch_loss: 1.360489 \n",
      "Batch: 2832. Acc: 0.515194. Loss: 1.343629. Batch_acc: 0.513905. Batch_loss: 1.321432 \n",
      "Batch: 2833. Acc: 0.515199. Loss: 1.343612. Batch_acc: 0.529885. Batch_loss: 1.297472 \n",
      "Batch: 2834. Acc: 0.515206. Loss: 1.343593. Batch_acc: 0.535108. Batch_loss: 1.289383 \n",
      "Batch: 2835. Acc: 0.515218. Loss: 1.343560. Batch_acc: 0.548276. Batch_loss: 1.252007 \n",
      "Batch: 2836. Acc: 0.515228. Loss: 1.343521. Batch_acc: 0.541853. Batch_loss: 1.234792 \n",
      "Batch: 2837. Acc: 0.515235. Loss: 1.343511. Batch_acc: 0.536374. Batch_loss: 1.314595 \n",
      "Batch: 2838. Acc: 0.515237. Loss: 1.343512. Batch_acc: 0.519885. Batch_loss: 1.346672 \n",
      "Batch: 2839. Acc: 0.515243. Loss: 1.343502. Batch_acc: 0.532880. Batch_loss: 1.316033 \n",
      "Batch: 2840. Acc: 0.515250. Loss: 1.343487. Batch_acc: 0.536028. Batch_loss: 1.300567 \n",
      "Batch: 2841. Acc: 0.515255. Loss: 1.343473. Batch_acc: 0.528392. Batch_loss: 1.300672 \n",
      "Batch: 2842. Acc: 0.515255. Loss: 1.343481. Batch_acc: 0.515116. Batch_loss: 1.367566 \n",
      "Batch: 2843. Acc: 0.515252. Loss: 1.343484. Batch_acc: 0.506166. Batch_loss: 1.351216 \n",
      "Batch: 2844. Acc: 0.515256. Loss: 1.343470. Batch_acc: 0.527794. Batch_loss: 1.302960 \n",
      "Batch: 2845. Acc: 0.515273. Loss: 1.343440. Batch_acc: 0.561219. Batch_loss: 1.261399 \n",
      "Batch: 2846. Acc: 0.515274. Loss: 1.343441. Batch_acc: 0.518824. Batch_loss: 1.347605 \n",
      "Batch: 2847. Acc: 0.515280. Loss: 1.343411. Batch_acc: 0.533218. Batch_loss: 1.257949 \n",
      "Batch: 2848. Acc: 0.515290. Loss: 1.343379. Batch_acc: 0.545401. Batch_loss: 1.248967 \n",
      "Batch: 2849. Acc: 0.515294. Loss: 1.343367. Batch_acc: 0.523919. Batch_loss: 1.310185 \n",
      "Batch: 2850. Acc: 0.515292. Loss: 1.343362. Batch_acc: 0.511816. Batch_loss: 1.326879 \n",
      "Batch: 2851. Acc: 0.515305. Loss: 1.343329. Batch_acc: 0.550113. Batch_loss: 1.252114 \n",
      "Batch: 2852. Acc: 0.515307. Loss: 1.343313. Batch_acc: 0.522701. Batch_loss: 1.296440 \n",
      "Batch: 2853. Acc: 0.515305. Loss: 1.343306. Batch_acc: 0.507946. Batch_loss: 1.322871 \n",
      "Batch: 2854. Acc: 0.515309. Loss: 1.343297. Batch_acc: 0.528868. Batch_loss: 1.317521 \n",
      "Batch: 2855. Acc: 0.515318. Loss: 1.343272. Batch_acc: 0.538730. Batch_loss: 1.273391 \n",
      "Batch: 2856. Acc: 0.515309. Loss: 1.343279. Batch_acc: 0.491178. Batch_loss: 1.362846 \n",
      "Batch: 2857. Acc: 0.515321. Loss: 1.343251. Batch_acc: 0.549741. Batch_loss: 1.262959 \n",
      "Batch: 2858. Acc: 0.515326. Loss: 1.343232. Batch_acc: 0.530251. Batch_loss: 1.290165 \n",
      "Batch: 2859. Acc: 0.515329. Loss: 1.343212. Batch_acc: 0.523836. Batch_loss: 1.287143 \n",
      "Batch: 2860. Acc: 0.515339. Loss: 1.343185. Batch_acc: 0.543379. Batch_loss: 1.265582 \n",
      "Batch: 2861. Acc: 0.515333. Loss: 1.343205. Batch_acc: 0.496552. Batch_loss: 1.401185 \n",
      "Batch: 2862. Acc: 0.515332. Loss: 1.343208. Batch_acc: 0.514008. Batch_loss: 1.351721 \n",
      "Batch: 2863. Acc: 0.515327. Loss: 1.343207. Batch_acc: 0.500293. Batch_loss: 1.338385 \n",
      "Batch: 2864. Acc: 0.515330. Loss: 1.343203. Batch_acc: 0.524581. Batch_loss: 1.332157 \n",
      "Batch: 2865. Acc: 0.515337. Loss: 1.343191. Batch_acc: 0.534097. Batch_loss: 1.310859 \n",
      "Batch: 2866. Acc: 0.515347. Loss: 1.343175. Batch_acc: 0.543578. Batch_loss: 1.297226 \n",
      "Batch: 2867. Acc: 0.515347. Loss: 1.343166. Batch_acc: 0.516129. Batch_loss: 1.315264 \n",
      "Batch: 2868. Acc: 0.515350. Loss: 1.343168. Batch_acc: 0.523590. Batch_loss: 1.349417 \n",
      "Batch: 2869. Acc: 0.515355. Loss: 1.343150. Batch_acc: 0.529245. Batch_loss: 1.291126 \n",
      "Batch: 2870. Acc: 0.515346. Loss: 1.343163. Batch_acc: 0.489311. Batch_loss: 1.383868 \n",
      "Batch: 2871. Acc: 0.515347. Loss: 1.343151. Batch_acc: 0.519308. Batch_loss: 1.307408 \n",
      "Batch: 2872. Acc: 0.515347. Loss: 1.343136. Batch_acc: 0.515705. Batch_loss: 1.301965 \n",
      "Batch: 2873. Acc: 0.515357. Loss: 1.343119. Batch_acc: 0.541835. Batch_loss: 1.291777 \n",
      "Batch: 2874. Acc: 0.515356. Loss: 1.343112. Batch_acc: 0.512536. Batch_loss: 1.323148 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2875. Acc: 0.515371. Loss: 1.343076. Batch_acc: 0.558087. Batch_loss: 1.240226 \n",
      "Batch: 2876. Acc: 0.515380. Loss: 1.343055. Batch_acc: 0.541475. Batch_loss: 1.284561 \n",
      "Batch: 2877. Acc: 0.515388. Loss: 1.343038. Batch_acc: 0.539121. Batch_loss: 1.293583 \n",
      "Batch: 2878. Acc: 0.515391. Loss: 1.343029. Batch_acc: 0.524674. Batch_loss: 1.317873 \n",
      "Batch: 2879. Acc: 0.515398. Loss: 1.343012. Batch_acc: 0.533067. Batch_loss: 1.293602 \n",
      "Batch: 2880. Acc: 0.515403. Loss: 1.342988. Batch_acc: 0.531374. Batch_loss: 1.274930 \n",
      "Batch: 2881. Acc: 0.515408. Loss: 1.342974. Batch_acc: 0.528808. Batch_loss: 1.304319 \n",
      "Batch: 2882. Acc: 0.515419. Loss: 1.342949. Batch_acc: 0.548558. Batch_loss: 1.268993 \n",
      "Batch: 2883. Acc: 0.515426. Loss: 1.342927. Batch_acc: 0.534123. Batch_loss: 1.281430 \n",
      "Batch: 2884. Acc: 0.515431. Loss: 1.342912. Batch_acc: 0.531682. Batch_loss: 1.298579 \n",
      "Batch: 2885. Acc: 0.515446. Loss: 1.342871. Batch_acc: 0.556429. Batch_loss: 1.227686 \n",
      "Batch: 2886. Acc: 0.515454. Loss: 1.342852. Batch_acc: 0.537709. Batch_loss: 1.285921 \n",
      "Batch: 2887. Acc: 0.515452. Loss: 1.342852. Batch_acc: 0.511416. Batch_loss: 1.345519 \n",
      "Batch: 2888. Acc: 0.515462. Loss: 1.342826. Batch_acc: 0.542971. Batch_loss: 1.268186 \n",
      "Batch: 2889. Acc: 0.515476. Loss: 1.342799. Batch_acc: 0.556561. Batch_loss: 1.265740 \n",
      "Batch: 2890. Acc: 0.515484. Loss: 1.342773. Batch_acc: 0.537801. Batch_loss: 1.266958 \n",
      "Batch: 2891. Acc: 0.515488. Loss: 1.342754. Batch_acc: 0.527875. Batch_loss: 1.289028 \n",
      "Batch: 2892. Acc: 0.515494. Loss: 1.342737. Batch_acc: 0.530671. Batch_loss: 1.290707 \n",
      "Batch: 2893. Acc: 0.515490. Loss: 1.342740. Batch_acc: 0.504060. Batch_loss: 1.354011 \n",
      "Batch: 2894. Acc: 0.515493. Loss: 1.342723. Batch_acc: 0.526740. Batch_loss: 1.293215 \n",
      "Batch: 2895. Acc: 0.515505. Loss: 1.342709. Batch_acc: 0.549631. Batch_loss: 1.302357 \n",
      "Batch: 2896. Acc: 0.515511. Loss: 1.342699. Batch_acc: 0.530682. Batch_loss: 1.314815 \n",
      "Batch: 2897. Acc: 0.515515. Loss: 1.342685. Batch_acc: 0.527105. Batch_loss: 1.300375 \n",
      "Batch: 2898. Acc: 0.515528. Loss: 1.342659. Batch_acc: 0.553561. Batch_loss: 1.269630 \n",
      "Batch: 2899. Acc: 0.515537. Loss: 1.342638. Batch_acc: 0.541714. Batch_loss: 1.282954 \n",
      "Batch: 2900. Acc: 0.515537. Loss: 1.342635. Batch_acc: 0.514253. Batch_loss: 1.334540 \n",
      "Batch: 2901. Acc: 0.515544. Loss: 1.342621. Batch_acc: 0.536773. Batch_loss: 1.301925 \n",
      "Batch: 2902. Acc: 0.515543. Loss: 1.342621. Batch_acc: 0.512181. Batch_loss: 1.344302 \n",
      "Batch: 2903. Acc: 0.515546. Loss: 1.342618. Batch_acc: 0.522767. Batch_loss: 1.331661 \n",
      "Batch: 2904. Acc: 0.515552. Loss: 1.342584. Batch_acc: 0.534111. Batch_loss: 1.244942 \n",
      "Batch: 2905. Acc: 0.515558. Loss: 1.342567. Batch_acc: 0.532221. Batch_loss: 1.292312 \n",
      "Batch: 2906. Acc: 0.515552. Loss: 1.342570. Batch_acc: 0.499124. Batch_loss: 1.351521 \n",
      "Batch: 2907. Acc: 0.515550. Loss: 1.342570. Batch_acc: 0.510086. Batch_loss: 1.343458 \n",
      "Batch: 2908. Acc: 0.515563. Loss: 1.342539. Batch_acc: 0.551585. Batch_loss: 1.250666 \n",
      "Batch: 2909. Acc: 0.515565. Loss: 1.342537. Batch_acc: 0.521968. Batch_loss: 1.335867 \n",
      "Batch: 2910. Acc: 0.515574. Loss: 1.342509. Batch_acc: 0.541430. Batch_loss: 1.262362 \n",
      "Batch: 2911. Acc: 0.515576. Loss: 1.342508. Batch_acc: 0.521363. Batch_loss: 1.338835 \n",
      "Batch: 2912. Acc: 0.515579. Loss: 1.342494. Batch_acc: 0.524079. Batch_loss: 1.304774 \n",
      "Batch: 2913. Acc: 0.515586. Loss: 1.342477. Batch_acc: 0.537068. Batch_loss: 1.292039 \n",
      "Batch: 2914. Acc: 0.515597. Loss: 1.342452. Batch_acc: 0.546866. Batch_loss: 1.269132 \n",
      "Batch: 2915. Acc: 0.515600. Loss: 1.342448. Batch_acc: 0.523645. Batch_loss: 1.332264 \n",
      "Batch: 2916. Acc: 0.515600. Loss: 1.342445. Batch_acc: 0.516503. Batch_loss: 1.334746 \n",
      "Batch: 2917. Acc: 0.515602. Loss: 1.342442. Batch_acc: 0.522114. Batch_loss: 1.332871 \n",
      "Batch: 2918. Acc: 0.515607. Loss: 1.342432. Batch_acc: 0.529245. Batch_loss: 1.314462 \n",
      "Batch: 2919. Acc: 0.515616. Loss: 1.342412. Batch_acc: 0.541080. Batch_loss: 1.282471 \n",
      "Batch: 2920. Acc: 0.515622. Loss: 1.342396. Batch_acc: 0.533908. Batch_loss: 1.295175 \n",
      "Batch: 2921. Acc: 0.515634. Loss: 1.342364. Batch_acc: 0.551124. Batch_loss: 1.251888 \n",
      "Batch: 2922. Acc: 0.515638. Loss: 1.342351. Batch_acc: 0.527729. Batch_loss: 1.302454 \n",
      "Batch: 2923. Acc: 0.515636. Loss: 1.342351. Batch_acc: 0.508534. Batch_loss: 1.342637 \n",
      "Batch: 2924. Acc: 0.515638. Loss: 1.342345. Batch_acc: 0.520785. Batch_loss: 1.324947 \n",
      "Batch: 2925. Acc: 0.515642. Loss: 1.342335. Batch_acc: 0.526316. Batch_loss: 1.312577 \n",
      "Batch: 2926. Acc: 0.515641. Loss: 1.342328. Batch_acc: 0.515306. Batch_loss: 1.323326 \n",
      "Batch: 2927. Acc: 0.515649. Loss: 1.342313. Batch_acc: 0.536199. Batch_loss: 1.297523 \n",
      "Batch: 2928. Acc: 0.515658. Loss: 1.342292. Batch_acc: 0.542487. Batch_loss: 1.283174 \n",
      "Batch: 2929. Acc: 0.515653. Loss: 1.342300. Batch_acc: 0.502022. Batch_loss: 1.366706 \n",
      "Batch: 2930. Acc: 0.515662. Loss: 1.342283. Batch_acc: 0.539511. Batch_loss: 1.290295 \n",
      "Batch: 2931. Acc: 0.515674. Loss: 1.342255. Batch_acc: 0.551959. Batch_loss: 1.262268 \n",
      "Batch: 2932. Acc: 0.515681. Loss: 1.342227. Batch_acc: 0.536854. Batch_loss: 1.258404 \n",
      "Batch: 2933. Acc: 0.515680. Loss: 1.342229. Batch_acc: 0.512600. Batch_loss: 1.349636 \n",
      "Batch: 2934. Acc: 0.515687. Loss: 1.342202. Batch_acc: 0.536435. Batch_loss: 1.263839 \n",
      "Batch: 2935. Acc: 0.515692. Loss: 1.342192. Batch_acc: 0.530577. Batch_loss: 1.314285 \n",
      "Batch: 2936. Acc: 0.515696. Loss: 1.342176. Batch_acc: 0.526498. Batch_loss: 1.295539 \n",
      "Batch: 2937. Acc: 0.515710. Loss: 1.342146. Batch_acc: 0.556167. Batch_loss: 1.255994 \n",
      "Batch: 2938. Acc: 0.515716. Loss: 1.342135. Batch_acc: 0.532948. Batch_loss: 1.309275 \n",
      "Batch: 2939. Acc: 0.515721. Loss: 1.342118. Batch_acc: 0.530114. Batch_loss: 1.294224 \n",
      "Batch: 2940. Acc: 0.515723. Loss: 1.342109. Batch_acc: 0.520501. Batch_loss: 1.316619 \n",
      "Batch: 2941. Acc: 0.515726. Loss: 1.342104. Batch_acc: 0.524033. Batch_loss: 1.326044 \n",
      "Batch: 2942. Acc: 0.515733. Loss: 1.342088. Batch_acc: 0.538372. Batch_loss: 1.293904 \n",
      "Batch: 2943. Acc: 0.515745. Loss: 1.342062. Batch_acc: 0.548530. Batch_loss: 1.269275 \n",
      "Batch: 2944. Acc: 0.515748. Loss: 1.342044. Batch_acc: 0.523864. Batch_loss: 1.288483 \n",
      "Batch: 2945. Acc: 0.515753. Loss: 1.342035. Batch_acc: 0.532490. Batch_loss: 1.316853 \n",
      "Batch: 2946. Acc: 0.515751. Loss: 1.342032. Batch_acc: 0.509164. Batch_loss: 1.333154 \n",
      "Batch: 2947. Acc: 0.515762. Loss: 1.342009. Batch_acc: 0.547052. Batch_loss: 1.273593 \n",
      "Batch: 2948. Acc: 0.515767. Loss: 1.341994. Batch_acc: 0.531268. Batch_loss: 1.298677 \n",
      "Batch: 2949. Acc: 0.515769. Loss: 1.341984. Batch_acc: 0.522423. Batch_loss: 1.310944 \n",
      "Batch: 2950. Acc: 0.515782. Loss: 1.341967. Batch_acc: 0.553318. Batch_loss: 1.293038 \n",
      "Batch: 2951. Acc: 0.515792. Loss: 1.341935. Batch_acc: 0.546087. Batch_loss: 1.246199 \n",
      "Batch: 2952. Acc: 0.515796. Loss: 1.341915. Batch_acc: 0.528377. Batch_loss: 1.283486 \n",
      "Batch: 2953. Acc: 0.515798. Loss: 1.341909. Batch_acc: 0.520138. Batch_loss: 1.323832 \n",
      "Batch: 2954. Acc: 0.515800. Loss: 1.341895. Batch_acc: 0.521739. Batch_loss: 1.300408 \n",
      "Batch: 2955. Acc: 0.515799. Loss: 1.341905. Batch_acc: 0.512500. Batch_loss: 1.371649 \n",
      "Batch: 2956. Acc: 0.515797. Loss: 1.341911. Batch_acc: 0.511843. Batch_loss: 1.358775 \n",
      "Batch: 2957. Acc: 0.515800. Loss: 1.341895. Batch_acc: 0.524843. Batch_loss: 1.294747 \n",
      "Batch: 2958. Acc: 0.515804. Loss: 1.341876. Batch_acc: 0.525481. Batch_loss: 1.287837 \n",
      "Batch: 2959. Acc: 0.515800. Loss: 1.341879. Batch_acc: 0.504023. Batch_loss: 1.351659 \n",
      "Batch: 2960. Acc: 0.515810. Loss: 1.341860. Batch_acc: 0.545980. Batch_loss: 1.284208 \n",
      "Batch: 2961. Acc: 0.515818. Loss: 1.341834. Batch_acc: 0.538684. Batch_loss: 1.265507 \n",
      "Batch: 2962. Acc: 0.515827. Loss: 1.341817. Batch_acc: 0.544928. Batch_loss: 1.289238 \n",
      "Batch: 2963. Acc: 0.515826. Loss: 1.341817. Batch_acc: 0.511939. Batch_loss: 1.341767 \n",
      "Batch: 2964. Acc: 0.515829. Loss: 1.341814. Batch_acc: 0.523919. Batch_loss: 1.333356 \n",
      "Batch: 2965. Acc: 0.515835. Loss: 1.341802. Batch_acc: 0.534580. Batch_loss: 1.308464 \n",
      "Batch: 2966. Acc: 0.515837. Loss: 1.341793. Batch_acc: 0.522241. Batch_loss: 1.316004 \n",
      "Batch: 2967. Acc: 0.515838. Loss: 1.341797. Batch_acc: 0.516900. Batch_loss: 1.353258 \n",
      "Batch: 2968. Acc: 0.515845. Loss: 1.341782. Batch_acc: 0.536994. Batch_loss: 1.296046 \n",
      "Batch: 2969. Acc: 0.515846. Loss: 1.341781. Batch_acc: 0.518135. Batch_loss: 1.339694 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2970. Acc: 0.515855. Loss: 1.341771. Batch_acc: 0.544928. Batch_loss: 1.312436 \n",
      "Batch: 2971. Acc: 0.515862. Loss: 1.341740. Batch_acc: 0.535274. Batch_loss: 1.250691 \n",
      "Batch: 2972. Acc: 0.515858. Loss: 1.341743. Batch_acc: 0.504075. Batch_loss: 1.351232 \n",
      "Batch: 2973. Acc: 0.515862. Loss: 1.341733. Batch_acc: 0.527826. Batch_loss: 1.312584 \n",
      "Batch: 2974. Acc: 0.515868. Loss: 1.341714. Batch_acc: 0.534206. Batch_loss: 1.281541 \n",
      "Batch: 2975. Acc: 0.515871. Loss: 1.341698. Batch_acc: 0.525394. Batch_loss: 1.295938 \n",
      "Batch: 2976. Acc: 0.515877. Loss: 1.341677. Batch_acc: 0.532917. Batch_loss: 1.279477 \n",
      "Batch: 2977. Acc: 0.515877. Loss: 1.341670. Batch_acc: 0.516129. Batch_loss: 1.320210 \n",
      "Batch: 2978. Acc: 0.515887. Loss: 1.341645. Batch_acc: 0.546030. Batch_loss: 1.266082 \n",
      "Batch: 2979. Acc: 0.515888. Loss: 1.341634. Batch_acc: 0.519031. Batch_loss: 1.311195 \n",
      "Batch: 2980. Acc: 0.515889. Loss: 1.341633. Batch_acc: 0.516886. Batch_loss: 1.337657 \n",
      "Batch: 2981. Acc: 0.515894. Loss: 1.341607. Batch_acc: 0.532838. Batch_loss: 1.265172 \n",
      "Batch: 2982. Acc: 0.515894. Loss: 1.341603. Batch_acc: 0.514024. Batch_loss: 1.328654 \n",
      "Batch: 2983. Acc: 0.515904. Loss: 1.341578. Batch_acc: 0.545506. Batch_loss: 1.267773 \n",
      "Batch: 2984. Acc: 0.515909. Loss: 1.341564. Batch_acc: 0.530707. Batch_loss: 1.299540 \n",
      "Batch: 2985. Acc: 0.515921. Loss: 1.341536. Batch_acc: 0.551685. Batch_loss: 1.260172 \n",
      "Batch: 2986. Acc: 0.515923. Loss: 1.341532. Batch_acc: 0.522872. Batch_loss: 1.329311 \n",
      "Batch: 2987. Acc: 0.515923. Loss: 1.341541. Batch_acc: 0.517026. Batch_loss: 1.368849 \n",
      "Batch: 2988. Acc: 0.515920. Loss: 1.341551. Batch_acc: 0.504065. Batch_loss: 1.371740 \n",
      "Batch: 2989. Acc: 0.515920. Loss: 1.341546. Batch_acc: 0.516571. Batch_loss: 1.325024 \n",
      "Batch: 2990. Acc: 0.515921. Loss: 1.341541. Batch_acc: 0.518156. Batch_loss: 1.327713 \n",
      "Batch: 2991. Acc: 0.515918. Loss: 1.341542. Batch_acc: 0.509166. Batch_loss: 1.342769 \n",
      "Batch: 2992. Acc: 0.515929. Loss: 1.341510. Batch_acc: 0.548652. Batch_loss: 1.244183 \n",
      "Batch: 2993. Acc: 0.515953. Loss: 1.341450. Batch_acc: 0.585489. Batch_loss: 1.165134 \n",
      "Batch: 2994. Acc: 0.515959. Loss: 1.341436. Batch_acc: 0.534790. Batch_loss: 1.299544 \n",
      "Batch: 2995. Acc: 0.515958. Loss: 1.341442. Batch_acc: 0.512699. Batch_loss: 1.359845 \n",
      "Batch: 2996. Acc: 0.515966. Loss: 1.341420. Batch_acc: 0.538869. Batch_loss: 1.274568 \n",
      "Batch: 2997. Acc: 0.515969. Loss: 1.341413. Batch_acc: 0.526375. Batch_loss: 1.322020 \n",
      "Batch: 2998. Acc: 0.515975. Loss: 1.341403. Batch_acc: 0.532958. Batch_loss: 1.312378 \n",
      "Batch: 2999. Acc: 0.515978. Loss: 1.341395. Batch_acc: 0.526285. Batch_loss: 1.314840 \n",
      "Batch: 3000. Acc: 0.515971. Loss: 1.341404. Batch_acc: 0.494415. Batch_loss: 1.371436 \n",
      "Batch: 3001. Acc: 0.515982. Loss: 1.341369. Batch_acc: 0.547116. Batch_loss: 1.237310 \n",
      "Batch: 3002. Acc: 0.515989. Loss: 1.341355. Batch_acc: 0.537747. Batch_loss: 1.297500 \n",
      "Batch: 3003. Acc: 0.515994. Loss: 1.341336. Batch_acc: 0.532341. Batch_loss: 1.285448 \n",
      "Batch: 3004. Acc: 0.516002. Loss: 1.341319. Batch_acc: 0.538242. Batch_loss: 1.290376 \n",
      "Batch: 3005. Acc: 0.515997. Loss: 1.341318. Batch_acc: 0.500883. Batch_loss: 1.336703 \n",
      "Batch: 3006. Acc: 0.515999. Loss: 1.341304. Batch_acc: 0.521102. Batch_loss: 1.298543 \n",
      "Batch: 3007. Acc: 0.515997. Loss: 1.341299. Batch_acc: 0.511536. Batch_loss: 1.328822 \n",
      "Batch: 3008. Acc: 0.515997. Loss: 1.341294. Batch_acc: 0.517261. Batch_loss: 1.325298 \n",
      "Batch: 3009. Acc: 0.516008. Loss: 1.341264. Batch_acc: 0.547093. Batch_loss: 1.248658 \n",
      "Batch: 3010. Acc: 0.516011. Loss: 1.341255. Batch_acc: 0.524928. Batch_loss: 1.316018 \n",
      "Batch: 3011. Acc: 0.516015. Loss: 1.341252. Batch_acc: 0.528037. Batch_loss: 1.330690 \n",
      "Batch: 3012. Acc: 0.516024. Loss: 1.341220. Batch_acc: 0.543972. Batch_loss: 1.244978 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.5160237240876918. Loss per char: 1.3412201488410995. Time: 1627220382.3475056\n",
      "Last question is tensor([ 2, 17,  1, 14,  1, 18, 18, 20, 24, 21, 17, 15, 19, 23, 24, 20, 21, 17,\n",
      "        20, 23,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.516022. Loss: 1.341224. Batch_acc: 0.510766. Batch_loss: 1.353732 \n",
      "Batch: 3014. Acc: 0.516034. Loss: 1.341199. Batch_acc: 0.552213. Batch_loss: 1.265800 \n",
      "Batch: 3015. Acc: 0.516032. Loss: 1.341199. Batch_acc: 0.509445. Batch_loss: 1.341872 \n",
      "Batch: 3016. Acc: 0.516030. Loss: 1.341205. Batch_acc: 0.509488. Batch_loss: 1.358931 \n",
      "Batch: 3017. Acc: 0.516028. Loss: 1.341199. Batch_acc: 0.508677. Batch_loss: 1.323469 \n",
      "Batch: 3018. Acc: 0.516031. Loss: 1.341197. Batch_acc: 0.525264. Batch_loss: 1.333360 \n",
      "Batch: 3019. Acc: 0.516026. Loss: 1.341193. Batch_acc: 0.503245. Batch_loss: 1.330777 \n",
      "Batch: 3020. Acc: 0.516029. Loss: 1.341192. Batch_acc: 0.522674. Batch_loss: 1.337273 \n",
      "Batch: 3021. Acc: 0.516022. Loss: 1.341217. Batch_acc: 0.496188. Batch_loss: 1.416981 \n",
      "Batch: 3022. Acc: 0.516023. Loss: 1.341217. Batch_acc: 0.518626. Batch_loss: 1.343220 \n",
      "Batch: 3023. Acc: 0.516027. Loss: 1.341206. Batch_acc: 0.529344. Batch_loss: 1.306760 \n",
      "Batch: 3024. Acc: 0.516029. Loss: 1.341202. Batch_acc: 0.522397. Batch_loss: 1.330520 \n",
      "Batch: 3025. Acc: 0.516034. Loss: 1.341192. Batch_acc: 0.529885. Batch_loss: 1.309157 \n",
      "Batch: 3026. Acc: 0.516037. Loss: 1.341186. Batch_acc: 0.524827. Batch_loss: 1.324764 \n",
      "Batch: 3027. Acc: 0.516041. Loss: 1.341182. Batch_acc: 0.527665. Batch_loss: 1.328540 \n",
      "Batch: 3028. Acc: 0.516039. Loss: 1.341180. Batch_acc: 0.509510. Batch_loss: 1.335135 \n",
      "Batch: 3029. Acc: 0.516044. Loss: 1.341152. Batch_acc: 0.532951. Batch_loss: 1.255383 \n",
      "Batch: 3030. Acc: 0.516059. Loss: 1.341105. Batch_acc: 0.559954. Batch_loss: 1.198311 \n",
      "Batch: 3031. Acc: 0.516054. Loss: 1.341122. Batch_acc: 0.500000. Batch_loss: 1.395809 \n",
      "Batch: 3032. Acc: 0.516059. Loss: 1.341109. Batch_acc: 0.532699. Batch_loss: 1.298591 \n",
      "Batch: 3033. Acc: 0.516061. Loss: 1.341105. Batch_acc: 0.523672. Batch_loss: 1.331329 \n",
      "Batch: 3034. Acc: 0.516071. Loss: 1.341083. Batch_acc: 0.544168. Batch_loss: 1.274293 \n",
      "Batch: 3035. Acc: 0.516077. Loss: 1.341073. Batch_acc: 0.534137. Batch_loss: 1.311179 \n",
      "Batch: 3036. Acc: 0.516087. Loss: 1.341064. Batch_acc: 0.545558. Batch_loss: 1.315057 \n",
      "Batch: 3037. Acc: 0.516088. Loss: 1.341065. Batch_acc: 0.521209. Batch_loss: 1.342541 \n",
      "Batch: 3038. Acc: 0.516089. Loss: 1.341061. Batch_acc: 0.517026. Batch_loss: 1.329070 \n",
      "Batch: 3039. Acc: 0.516090. Loss: 1.341055. Batch_acc: 0.521333. Batch_loss: 1.324298 \n",
      "Batch: 3040. Acc: 0.516096. Loss: 1.341031. Batch_acc: 0.534317. Batch_loss: 1.268759 \n",
      "Batch: 3041. Acc: 0.516095. Loss: 1.341033. Batch_acc: 0.511249. Batch_loss: 1.344750 \n",
      "Batch: 3042. Acc: 0.516092. Loss: 1.341034. Batch_acc: 0.506690. Batch_loss: 1.344887 \n",
      "Batch: 3043. Acc: 0.516092. Loss: 1.341038. Batch_acc: 0.516771. Batch_loss: 1.352070 \n",
      "Batch: 3044. Acc: 0.516096. Loss: 1.341030. Batch_acc: 0.528863. Batch_loss: 1.316792 \n",
      "Batch: 3045. Acc: 0.516105. Loss: 1.340999. Batch_acc: 0.542824. Batch_loss: 1.247966 \n",
      "Batch: 3046. Acc: 0.516108. Loss: 1.340988. Batch_acc: 0.525229. Batch_loss: 1.306464 \n",
      "Batch: 3047. Acc: 0.516110. Loss: 1.340978. Batch_acc: 0.523566. Batch_loss: 1.309624 \n",
      "Batch: 3048. Acc: 0.516116. Loss: 1.340969. Batch_acc: 0.532906. Batch_loss: 1.315978 \n",
      "Batch: 3049. Acc: 0.516122. Loss: 1.340960. Batch_acc: 0.534682. Batch_loss: 1.311200 \n",
      "Batch: 3050. Acc: 0.516121. Loss: 1.340968. Batch_acc: 0.513703. Batch_loss: 1.366192 \n",
      "Batch: 3051. Acc: 0.516128. Loss: 1.340961. Batch_acc: 0.538143. Batch_loss: 1.318958 \n",
      "Batch: 3052. Acc: 0.516132. Loss: 1.340947. Batch_acc: 0.528346. Batch_loss: 1.297228 \n",
      "Batch: 3053. Acc: 0.516130. Loss: 1.340943. Batch_acc: 0.510945. Batch_loss: 1.330136 \n",
      "Batch: 3054. Acc: 0.516126. Loss: 1.340951. Batch_acc: 0.503525. Batch_loss: 1.364686 \n",
      "Batch: 3055. Acc: 0.516131. Loss: 1.340937. Batch_acc: 0.532174. Batch_loss: 1.297213 \n",
      "Batch: 3056. Acc: 0.516134. Loss: 1.340923. Batch_acc: 0.525822. Batch_loss: 1.297989 \n",
      "Batch: 3057. Acc: 0.516130. Loss: 1.340927. Batch_acc: 0.501439. Batch_loss: 1.352235 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3058. Acc: 0.516134. Loss: 1.340909. Batch_acc: 0.530017. Batch_loss: 1.287522 \n",
      "Batch: 3059. Acc: 0.516139. Loss: 1.340894. Batch_acc: 0.529345. Batch_loss: 1.296180 \n",
      "Batch: 3060. Acc: 0.516141. Loss: 1.340898. Batch_acc: 0.522768. Batch_loss: 1.352787 \n",
      "Batch: 3061. Acc: 0.516143. Loss: 1.340893. Batch_acc: 0.521690. Batch_loss: 1.325110 \n",
      "Batch: 3062. Acc: 0.516136. Loss: 1.340911. Batch_acc: 0.495392. Batch_loss: 1.398673 \n",
      "Batch: 3063. Acc: 0.516141. Loss: 1.340895. Batch_acc: 0.533107. Batch_loss: 1.290822 \n",
      "Batch: 3064. Acc: 0.516147. Loss: 1.340880. Batch_acc: 0.532415. Batch_loss: 1.295163 \n",
      "Batch: 3065. Acc: 0.516143. Loss: 1.340886. Batch_acc: 0.504103. Batch_loss: 1.359208 \n",
      "Batch: 3066. Acc: 0.516145. Loss: 1.340882. Batch_acc: 0.522488. Batch_loss: 1.330901 \n",
      "Batch: 3067. Acc: 0.516140. Loss: 1.340887. Batch_acc: 0.500590. Batch_loss: 1.355523 \n",
      "Batch: 3068. Acc: 0.516146. Loss: 1.340858. Batch_acc: 0.535652. Batch_loss: 1.250597 \n",
      "Batch: 3069. Acc: 0.516157. Loss: 1.340827. Batch_acc: 0.548165. Batch_loss: 1.245804 \n",
      "Batch: 3070. Acc: 0.516152. Loss: 1.340838. Batch_acc: 0.500290. Batch_loss: 1.376611 \n",
      "Batch: 3071. Acc: 0.516160. Loss: 1.340820. Batch_acc: 0.542708. Batch_loss: 1.283845 \n",
      "Batch: 3072. Acc: 0.516163. Loss: 1.340809. Batch_acc: 0.524255. Batch_loss: 1.305487 \n",
      "Batch: 3073. Acc: 0.516166. Loss: 1.340797. Batch_acc: 0.526404. Batch_loss: 1.306900 \n",
      "Batch: 3074. Acc: 0.516172. Loss: 1.340777. Batch_acc: 0.532099. Batch_loss: 1.279687 \n",
      "Batch: 3075. Acc: 0.516173. Loss: 1.340769. Batch_acc: 0.522042. Batch_loss: 1.313756 \n",
      "Batch: 3076. Acc: 0.516181. Loss: 1.340750. Batch_acc: 0.540082. Batch_loss: 1.283571 \n",
      "Batch: 3077. Acc: 0.516179. Loss: 1.340764. Batch_acc: 0.510180. Batch_loss: 1.382332 \n",
      "Batch: 3078. Acc: 0.516180. Loss: 1.340757. Batch_acc: 0.517503. Batch_loss: 1.318488 \n",
      "Batch: 3079. Acc: 0.516189. Loss: 1.340723. Batch_acc: 0.546713. Batch_loss: 1.237054 \n",
      "Batch: 3080. Acc: 0.516183. Loss: 1.340745. Batch_acc: 0.497017. Batch_loss: 1.410020 \n",
      "Batch: 3081. Acc: 0.516193. Loss: 1.340725. Batch_acc: 0.545141. Batch_loss: 1.281037 \n",
      "Batch: 3082. Acc: 0.516193. Loss: 1.340724. Batch_acc: 0.517377. Batch_loss: 1.336139 \n",
      "Batch: 3083. Acc: 0.516196. Loss: 1.340718. Batch_acc: 0.525611. Batch_loss: 1.323123 \n",
      "Batch: 3084. Acc: 0.516198. Loss: 1.340719. Batch_acc: 0.522528. Batch_loss: 1.343479 \n",
      "Batch: 3085. Acc: 0.516208. Loss: 1.340694. Batch_acc: 0.546742. Batch_loss: 1.264198 \n",
      "Batch: 3086. Acc: 0.516214. Loss: 1.340676. Batch_acc: 0.533449. Batch_loss: 1.286498 \n",
      "Batch: 3087. Acc: 0.516213. Loss: 1.340677. Batch_acc: 0.514731. Batch_loss: 1.342062 \n",
      "Batch: 3088. Acc: 0.516213. Loss: 1.340668. Batch_acc: 0.514630. Batch_loss: 1.313477 \n",
      "Batch: 3089. Acc: 0.516219. Loss: 1.340643. Batch_acc: 0.536198. Batch_loss: 1.262833 \n",
      "Batch: 3090. Acc: 0.516224. Loss: 1.340634. Batch_acc: 0.529983. Batch_loss: 1.311400 \n",
      "Batch: 3091. Acc: 0.516232. Loss: 1.340612. Batch_acc: 0.541290. Batch_loss: 1.273104 \n",
      "Batch: 3092. Acc: 0.516239. Loss: 1.340590. Batch_acc: 0.538549. Batch_loss: 1.273543 \n",
      "Batch: 3093. Acc: 0.516254. Loss: 1.340558. Batch_acc: 0.563158. Batch_loss: 1.240240 \n",
      "Batch: 3094. Acc: 0.516266. Loss: 1.340531. Batch_acc: 0.550847. Batch_loss: 1.258410 \n",
      "Batch: 3095. Acc: 0.516261. Loss: 1.340549. Batch_acc: 0.502029. Batch_loss: 1.396724 \n",
      "Batch: 3096. Acc: 0.516261. Loss: 1.340547. Batch_acc: 0.517694. Batch_loss: 1.334936 \n",
      "Batch: 3097. Acc: 0.516265. Loss: 1.340532. Batch_acc: 0.526225. Batch_loss: 1.293131 \n",
      "Batch: 3098. Acc: 0.516266. Loss: 1.340527. Batch_acc: 0.519208. Batch_loss: 1.326867 \n",
      "Batch: 3099. Acc: 0.516262. Loss: 1.340530. Batch_acc: 0.506024. Batch_loss: 1.350110 \n",
      "Batch: 3100. Acc: 0.516267. Loss: 1.340520. Batch_acc: 0.532011. Batch_loss: 1.308738 \n",
      "Batch: 3101. Acc: 0.516273. Loss: 1.340508. Batch_acc: 0.533865. Batch_loss: 1.302918 \n",
      "Batch: 3102. Acc: 0.516275. Loss: 1.340508. Batch_acc: 0.522179. Batch_loss: 1.341284 \n",
      "Batch: 3103. Acc: 0.516289. Loss: 1.340478. Batch_acc: 0.558244. Batch_loss: 1.248372 \n",
      "Batch: 3104. Acc: 0.516291. Loss: 1.340476. Batch_acc: 0.521437. Batch_loss: 1.336196 \n",
      "Batch: 3105. Acc: 0.516293. Loss: 1.340467. Batch_acc: 0.523639. Batch_loss: 1.311813 \n",
      "Batch: 3106. Acc: 0.516297. Loss: 1.340452. Batch_acc: 0.529890. Batch_loss: 1.292896 \n",
      "Batch: 3107. Acc: 0.516299. Loss: 1.340446. Batch_acc: 0.521637. Batch_loss: 1.321512 \n",
      "Batch: 3108. Acc: 0.516306. Loss: 1.340428. Batch_acc: 0.540082. Batch_loss: 1.282827 \n",
      "Batch: 3109. Acc: 0.516314. Loss: 1.340406. Batch_acc: 0.541332. Batch_loss: 1.270911 \n",
      "Batch: 3110. Acc: 0.516327. Loss: 1.340371. Batch_acc: 0.556000. Batch_loss: 1.233158 \n",
      "Batch: 3111. Acc: 0.516336. Loss: 1.340354. Batch_acc: 0.542217. Batch_loss: 1.287271 \n",
      "Batch: 3112. Acc: 0.516337. Loss: 1.340359. Batch_acc: 0.520046. Batch_loss: 1.356650 \n",
      "Batch: 3113. Acc: 0.516334. Loss: 1.340360. Batch_acc: 0.508494. Batch_loss: 1.344042 \n",
      "Batch: 3114. Acc: 0.516331. Loss: 1.340368. Batch_acc: 0.507147. Batch_loss: 1.364928 \n",
      "Batch: 3115. Acc: 0.516325. Loss: 1.340382. Batch_acc: 0.495823. Batch_loss: 1.386120 \n",
      "Batch: 3116. Acc: 0.516334. Loss: 1.340359. Batch_acc: 0.545195. Batch_loss: 1.268759 \n",
      "Batch: 3117. Acc: 0.516332. Loss: 1.340358. Batch_acc: 0.508324. Batch_loss: 1.338024 \n",
      "Batch: 3118. Acc: 0.516340. Loss: 1.340329. Batch_acc: 0.542480. Batch_loss: 1.248104 \n",
      "Batch: 3119. Acc: 0.516348. Loss: 1.340309. Batch_acc: 0.539895. Batch_loss: 1.279357 \n",
      "Batch: 3120. Acc: 0.516349. Loss: 1.340314. Batch_acc: 0.520046. Batch_loss: 1.354706 \n",
      "Batch: 3121. Acc: 0.516355. Loss: 1.340292. Batch_acc: 0.536627. Batch_loss: 1.270939 \n",
      "Batch: 3122. Acc: 0.516365. Loss: 1.340260. Batch_acc: 0.545607. Batch_loss: 1.243078 \n",
      "Batch: 3123. Acc: 0.516362. Loss: 1.340259. Batch_acc: 0.506890. Batch_loss: 1.337062 \n",
      "Batch: 3124. Acc: 0.516368. Loss: 1.340244. Batch_acc: 0.533908. Batch_loss: 1.295781 \n",
      "Batch: 3125. Acc: 0.516366. Loss: 1.340245. Batch_acc: 0.511357. Batch_loss: 1.342719 \n",
      "Batch: 3126. Acc: 0.516364. Loss: 1.340254. Batch_acc: 0.508812. Batch_loss: 1.367638 \n",
      "Batch: 3127. Acc: 0.516365. Loss: 1.340244. Batch_acc: 0.522190. Batch_loss: 1.309810 \n",
      "Batch: 3128. Acc: 0.516374. Loss: 1.340214. Batch_acc: 0.542266. Batch_loss: 1.246244 \n",
      "Batch: 3129. Acc: 0.516385. Loss: 1.340188. Batch_acc: 0.551101. Batch_loss: 1.259830 \n",
      "Batch: 3130. Acc: 0.516397. Loss: 1.340160. Batch_acc: 0.552752. Batch_loss: 1.251968 \n",
      "Batch: 3131. Acc: 0.516399. Loss: 1.340155. Batch_acc: 0.522702. Batch_loss: 1.325117 \n",
      "Batch: 3132. Acc: 0.516405. Loss: 1.340139. Batch_acc: 0.535855. Batch_loss: 1.292575 \n",
      "Batch: 3133. Acc: 0.516410. Loss: 1.340133. Batch_acc: 0.530659. Batch_loss: 1.321632 \n",
      "Batch: 3134. Acc: 0.516412. Loss: 1.340118. Batch_acc: 0.522857. Batch_loss: 1.292373 \n",
      "Batch: 3135. Acc: 0.516421. Loss: 1.340100. Batch_acc: 0.545663. Batch_loss: 1.282403 \n",
      "Batch: 3136. Acc: 0.516425. Loss: 1.340086. Batch_acc: 0.527652. Batch_loss: 1.297128 \n",
      "Batch: 3137. Acc: 0.516436. Loss: 1.340056. Batch_acc: 0.549803. Batch_loss: 1.248095 \n",
      "Batch: 3138. Acc: 0.516447. Loss: 1.340023. Batch_acc: 0.553155. Batch_loss: 1.237502 \n",
      "Batch: 3139. Acc: 0.516449. Loss: 1.340021. Batch_acc: 0.520809. Batch_loss: 1.333832 \n",
      "Batch: 3140. Acc: 0.516456. Loss: 1.339998. Batch_acc: 0.538771. Batch_loss: 1.270230 \n",
      "Batch: 3141. Acc: 0.516455. Loss: 1.340009. Batch_acc: 0.512168. Batch_loss: 1.373335 \n",
      "Batch: 3142. Acc: 0.516453. Loss: 1.340017. Batch_acc: 0.512776. Batch_loss: 1.364871 \n",
      "Batch: 3143. Acc: 0.516449. Loss: 1.340021. Batch_acc: 0.502296. Batch_loss: 1.351981 \n",
      "Batch: 3144. Acc: 0.516447. Loss: 1.340029. Batch_acc: 0.510850. Batch_loss: 1.366708 \n",
      "Batch: 3145. Acc: 0.516450. Loss: 1.340023. Batch_acc: 0.524735. Batch_loss: 1.320187 \n",
      "Batch: 3146. Acc: 0.516450. Loss: 1.340022. Batch_acc: 0.517422. Batch_loss: 1.337923 \n",
      "Batch: 3147. Acc: 0.516453. Loss: 1.340011. Batch_acc: 0.527035. Batch_loss: 1.306190 \n",
      "Batch: 3148. Acc: 0.516460. Loss: 1.339987. Batch_acc: 0.536322. Batch_loss: 1.262610 \n",
      "Batch: 3149. Acc: 0.516468. Loss: 1.339962. Batch_acc: 0.540741. Batch_loss: 1.263793 \n",
      "Batch: 3150. Acc: 0.516466. Loss: 1.339965. Batch_acc: 0.511995. Batch_loss: 1.349335 \n",
      "Batch: 3151. Acc: 0.516466. Loss: 1.339958. Batch_acc: 0.517320. Batch_loss: 1.318735 \n",
      "Batch: 3152. Acc: 0.516481. Loss: 1.339925. Batch_acc: 0.560795. Batch_loss: 1.234975 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3153. Acc: 0.516487. Loss: 1.339906. Batch_acc: 0.537407. Batch_loss: 1.282742 \n",
      "Batch: 3154. Acc: 0.516500. Loss: 1.339869. Batch_acc: 0.555619. Batch_loss: 1.223628 \n",
      "Batch: 3155. Acc: 0.516506. Loss: 1.339857. Batch_acc: 0.537522. Batch_loss: 1.300829 \n",
      "Batch: 3156. Acc: 0.516505. Loss: 1.339858. Batch_acc: 0.512980. Batch_loss: 1.344228 \n",
      "Batch: 3157. Acc: 0.516508. Loss: 1.339844. Batch_acc: 0.524930. Batch_loss: 1.294124 \n",
      "Batch: 3158. Acc: 0.516511. Loss: 1.339841. Batch_acc: 0.525058. Batch_loss: 1.332937 \n",
      "Batch: 3159. Acc: 0.516505. Loss: 1.339856. Batch_acc: 0.498851. Batch_loss: 1.385066 \n",
      "Batch: 3160. Acc: 0.516511. Loss: 1.339836. Batch_acc: 0.535755. Batch_loss: 1.278819 \n",
      "Batch: 3161. Acc: 0.516519. Loss: 1.339829. Batch_acc: 0.539436. Batch_loss: 1.316207 \n",
      "Batch: 3162. Acc: 0.516517. Loss: 1.339825. Batch_acc: 0.512293. Batch_loss: 1.328349 \n",
      "Batch: 3163. Acc: 0.516519. Loss: 1.339821. Batch_acc: 0.520979. Batch_loss: 1.328381 \n",
      "Batch: 3164. Acc: 0.516537. Loss: 1.339772. Batch_acc: 0.575618. Batch_loss: 1.181872 \n",
      "Batch: 3165. Acc: 0.516546. Loss: 1.339749. Batch_acc: 0.544515. Batch_loss: 1.267864 \n",
      "Batch: 3166. Acc: 0.516549. Loss: 1.339736. Batch_acc: 0.526765. Batch_loss: 1.298961 \n",
      "Batch: 3167. Acc: 0.516549. Loss: 1.339726. Batch_acc: 0.515309. Batch_loss: 1.309854 \n",
      "Batch: 3168. Acc: 0.516558. Loss: 1.339707. Batch_acc: 0.543330. Batch_loss: 1.277811 \n",
      "Batch: 3169. Acc: 0.516557. Loss: 1.339701. Batch_acc: 0.514748. Batch_loss: 1.321905 \n",
      "Batch: 3170. Acc: 0.516550. Loss: 1.339712. Batch_acc: 0.494851. Batch_loss: 1.372536 \n",
      "Batch: 3171. Acc: 0.516551. Loss: 1.339711. Batch_acc: 0.518052. Batch_loss: 1.337217 \n",
      "Batch: 3172. Acc: 0.516553. Loss: 1.339706. Batch_acc: 0.524217. Batch_loss: 1.324981 \n",
      "Batch: 3173. Acc: 0.516556. Loss: 1.339699. Batch_acc: 0.527335. Batch_loss: 1.316224 \n",
      "Batch: 3174. Acc: 0.516574. Loss: 1.339654. Batch_acc: 0.571670. Batch_loss: 1.201613 \n",
      "Batch: 3175. Acc: 0.516579. Loss: 1.339638. Batch_acc: 0.532565. Batch_loss: 1.289364 \n",
      "Batch: 3176. Acc: 0.516581. Loss: 1.339639. Batch_acc: 0.523998. Batch_loss: 1.342074 \n",
      "Batch: 3177. Acc: 0.516583. Loss: 1.339631. Batch_acc: 0.521071. Batch_loss: 1.313625 \n",
      "Batch: 3178. Acc: 0.516592. Loss: 1.339609. Batch_acc: 0.545663. Batch_loss: 1.269751 \n",
      "Batch: 3179. Acc: 0.516584. Loss: 1.339618. Batch_acc: 0.492546. Batch_loss: 1.369458 \n",
      "Batch: 3180. Acc: 0.516591. Loss: 1.339602. Batch_acc: 0.537059. Batch_loss: 1.286546 \n",
      "Batch: 3181. Acc: 0.516591. Loss: 1.339608. Batch_acc: 0.518430. Batch_loss: 1.358102 \n",
      "Batch: 3182. Acc: 0.516586. Loss: 1.339620. Batch_acc: 0.498264. Batch_loss: 1.379210 \n",
      "Batch: 3183. Acc: 0.516591. Loss: 1.339602. Batch_acc: 0.534019. Batch_loss: 1.283289 \n",
      "Batch: 3184. Acc: 0.516602. Loss: 1.339582. Batch_acc: 0.551032. Batch_loss: 1.275517 \n",
      "Batch: 3185. Acc: 0.516609. Loss: 1.339565. Batch_acc: 0.538680. Batch_loss: 1.286562 \n",
      "Batch: 3186. Acc: 0.516613. Loss: 1.339562. Batch_acc: 0.530337. Batch_loss: 1.328241 \n",
      "Batch: 3187. Acc: 0.516607. Loss: 1.339579. Batch_acc: 0.495921. Batch_loss: 1.396148 \n",
      "Batch: 3188. Acc: 0.516607. Loss: 1.339571. Batch_acc: 0.517301. Batch_loss: 1.314075 \n",
      "Batch: 3189. Acc: 0.516611. Loss: 1.339571. Batch_acc: 0.527252. Batch_loss: 1.339805 \n",
      "Batch: 3190. Acc: 0.516620. Loss: 1.339556. Batch_acc: 0.545560. Batch_loss: 1.291862 \n",
      "Batch: 3191. Acc: 0.516622. Loss: 1.339544. Batch_acc: 0.523783. Batch_loss: 1.300866 \n",
      "Batch: 3192. Acc: 0.516616. Loss: 1.339567. Batch_acc: 0.497345. Batch_loss: 1.413747 \n",
      "Batch: 3193. Acc: 0.516620. Loss: 1.339571. Batch_acc: 0.528563. Batch_loss: 1.353552 \n",
      "Batch: 3194. Acc: 0.516617. Loss: 1.339577. Batch_acc: 0.508323. Batch_loss: 1.360488 \n",
      "Batch: 3195. Acc: 0.516616. Loss: 1.339579. Batch_acc: 0.513671. Batch_loss: 1.344635 \n",
      "Batch: 3196. Acc: 0.516618. Loss: 1.339581. Batch_acc: 0.523216. Batch_loss: 1.346855 \n",
      "Batch: 3197. Acc: 0.516623. Loss: 1.339572. Batch_acc: 0.530079. Batch_loss: 1.310938 \n",
      "Batch: 3198. Acc: 0.516620. Loss: 1.339578. Batch_acc: 0.508751. Batch_loss: 1.359653 \n",
      "Batch: 3199. Acc: 0.516621. Loss: 1.339579. Batch_acc: 0.519954. Batch_loss: 1.341833 \n",
      "Batch: 3200. Acc: 0.516625. Loss: 1.339570. Batch_acc: 0.528940. Batch_loss: 1.310607 \n",
      "Batch: 3201. Acc: 0.516632. Loss: 1.339553. Batch_acc: 0.538810. Batch_loss: 1.286942 \n",
      "Batch: 3202. Acc: 0.516642. Loss: 1.339540. Batch_acc: 0.548082. Batch_loss: 1.299234 \n",
      "Batch: 3203. Acc: 0.516643. Loss: 1.339542. Batch_acc: 0.520182. Batch_loss: 1.343896 \n",
      "Batch: 3204. Acc: 0.516650. Loss: 1.339532. Batch_acc: 0.538689. Batch_loss: 1.306879 \n",
      "Batch: 3205. Acc: 0.516655. Loss: 1.339510. Batch_acc: 0.532203. Batch_loss: 1.271396 \n",
      "Batch: 3206. Acc: 0.516655. Loss: 1.339511. Batch_acc: 0.517878. Batch_loss: 1.343317 \n",
      "Batch: 3207. Acc: 0.516654. Loss: 1.339518. Batch_acc: 0.512894. Batch_loss: 1.359554 \n",
      "Batch: 3208. Acc: 0.516657. Loss: 1.339511. Batch_acc: 0.526844. Batch_loss: 1.316500 \n",
      "Batch: 3209. Acc: 0.516648. Loss: 1.339540. Batch_acc: 0.487682. Batch_loss: 1.431622 \n",
      "Batch: 3210. Acc: 0.516658. Loss: 1.339512. Batch_acc: 0.547739. Batch_loss: 1.251767 \n",
      "Batch: 3211. Acc: 0.516660. Loss: 1.339502. Batch_acc: 0.522676. Batch_loss: 1.308201 \n",
      "Batch: 3212. Acc: 0.516662. Loss: 1.339487. Batch_acc: 0.522662. Batch_loss: 1.292757 \n",
      "Batch: 3213. Acc: 0.516663. Loss: 1.339485. Batch_acc: 0.519242. Batch_loss: 1.331463 \n",
      "Batch: 3214. Acc: 0.516662. Loss: 1.339491. Batch_acc: 0.513921. Batch_loss: 1.358845 \n",
      "Batch: 3215. Acc: 0.516667. Loss: 1.339477. Batch_acc: 0.532276. Batch_loss: 1.294918 \n",
      "Batch: 3216. Acc: 0.516675. Loss: 1.339454. Batch_acc: 0.541550. Batch_loss: 1.269418 \n",
      "Batch: 3217. Acc: 0.516681. Loss: 1.339438. Batch_acc: 0.537892. Batch_loss: 1.286217 \n",
      "Batch: 3218. Acc: 0.516680. Loss: 1.339430. Batch_acc: 0.511023. Batch_loss: 1.315494 \n",
      "Batch: 3219. Acc: 0.516682. Loss: 1.339426. Batch_acc: 0.525913. Batch_loss: 1.325199 \n",
      "Batch: 3220. Acc: 0.516685. Loss: 1.339424. Batch_acc: 0.523810. Batch_loss: 1.332809 \n",
      "Batch: 3221. Acc: 0.516687. Loss: 1.339418. Batch_acc: 0.525985. Batch_loss: 1.321821 \n",
      "Batch: 3222. Acc: 0.516678. Loss: 1.339434. Batch_acc: 0.486136. Batch_loss: 1.390651 \n",
      "Batch: 3223. Acc: 0.516680. Loss: 1.339423. Batch_acc: 0.521984. Batch_loss: 1.305419 \n",
      "Batch: 3224. Acc: 0.516682. Loss: 1.339409. Batch_acc: 0.523343. Batch_loss: 1.295211 \n",
      "Batch: 3225. Acc: 0.516684. Loss: 1.339407. Batch_acc: 0.523478. Batch_loss: 1.331706 \n",
      "Batch: 3226. Acc: 0.516688. Loss: 1.339394. Batch_acc: 0.529820. Batch_loss: 1.298337 \n",
      "Batch: 3227. Acc: 0.516693. Loss: 1.339377. Batch_acc: 0.532710. Batch_loss: 1.283670 \n",
      "Batch: 3228. Acc: 0.516693. Loss: 1.339369. Batch_acc: 0.516110. Batch_loss: 1.312826 \n",
      "Batch: 3229. Acc: 0.516694. Loss: 1.339373. Batch_acc: 0.521348. Batch_loss: 1.351221 \n",
      "Batch: 3230. Acc: 0.516702. Loss: 1.339340. Batch_acc: 0.541183. Batch_loss: 1.231243 \n",
      "Batch: 3231. Acc: 0.516701. Loss: 1.339339. Batch_acc: 0.514857. Batch_loss: 1.338208 \n",
      "Batch: 3232. Acc: 0.516710. Loss: 1.339319. Batch_acc: 0.544092. Batch_loss: 1.272765 \n",
      "Batch: 3233. Acc: 0.516715. Loss: 1.339297. Batch_acc: 0.534780. Batch_loss: 1.272956 \n",
      "Batch: 3234. Acc: 0.516713. Loss: 1.339297. Batch_acc: 0.508435. Batch_loss: 1.339347 \n",
      "Batch: 3235. Acc: 0.516716. Loss: 1.339277. Batch_acc: 0.527762. Batch_loss: 1.273433 \n",
      "Batch: 3236. Acc: 0.516727. Loss: 1.339244. Batch_acc: 0.552879. Batch_loss: 1.230622 \n",
      "Batch: 3237. Acc: 0.516733. Loss: 1.339231. Batch_acc: 0.534602. Batch_loss: 1.295933 \n",
      "Batch: 3238. Acc: 0.516731. Loss: 1.339243. Batch_acc: 0.509025. Batch_loss: 1.379167 \n",
      "Batch: 3239. Acc: 0.516735. Loss: 1.339221. Batch_acc: 0.530761. Batch_loss: 1.269776 \n",
      "Batch: 3240. Acc: 0.516736. Loss: 1.339214. Batch_acc: 0.519681. Batch_loss: 1.318842 \n",
      "Batch: 3241. Acc: 0.516740. Loss: 1.339208. Batch_acc: 0.531323. Batch_loss: 1.319256 \n",
      "Batch: 3242. Acc: 0.516748. Loss: 1.339192. Batch_acc: 0.542314. Batch_loss: 1.287350 \n",
      "Batch: 3243. Acc: 0.516754. Loss: 1.339177. Batch_acc: 0.534923. Batch_loss: 1.291243 \n",
      "Batch: 3244. Acc: 0.516749. Loss: 1.339183. Batch_acc: 0.501167. Batch_loss: 1.359154 \n",
      "Batch: 3245. Acc: 0.516750. Loss: 1.339186. Batch_acc: 0.519048. Batch_loss: 1.348108 \n",
      "Batch: 3246. Acc: 0.516752. Loss: 1.339181. Batch_acc: 0.522688. Batch_loss: 1.324140 \n",
      "Batch: 3247. Acc: 0.516760. Loss: 1.339153. Batch_acc: 0.543829. Batch_loss: 1.245959 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3248. Acc: 0.516761. Loss: 1.339139. Batch_acc: 0.521512. Batch_loss: 1.294920 \n",
      "Batch: 3249. Acc: 0.516766. Loss: 1.339116. Batch_acc: 0.532834. Batch_loss: 1.263018 \n",
      "Batch: 3250. Acc: 0.516775. Loss: 1.339088. Batch_acc: 0.545662. Batch_loss: 1.251052 \n",
      "Batch: 3251. Acc: 0.516776. Loss: 1.339077. Batch_acc: 0.520182. Batch_loss: 1.300700 \n",
      "Batch: 3252. Acc: 0.516786. Loss: 1.339046. Batch_acc: 0.548929. Batch_loss: 1.238590 \n",
      "Batch: 3253. Acc: 0.516788. Loss: 1.339048. Batch_acc: 0.523402. Batch_loss: 1.345033 \n",
      "Batch: 3254. Acc: 0.516793. Loss: 1.339031. Batch_acc: 0.532167. Batch_loss: 1.286401 \n",
      "Batch: 3255. Acc: 0.516795. Loss: 1.339024. Batch_acc: 0.521965. Batch_loss: 1.315201 \n",
      "Batch: 3256. Acc: 0.516798. Loss: 1.339017. Batch_acc: 0.526570. Batch_loss: 1.316668 \n",
      "Batch: 3257. Acc: 0.516807. Loss: 1.338991. Batch_acc: 0.548369. Batch_loss: 1.252976 \n",
      "Batch: 3258. Acc: 0.516804. Loss: 1.338996. Batch_acc: 0.504877. Batch_loss: 1.356918 \n",
      "Batch: 3259. Acc: 0.516810. Loss: 1.338985. Batch_acc: 0.537347. Batch_loss: 1.303495 \n",
      "Batch: 3260. Acc: 0.516811. Loss: 1.338973. Batch_acc: 0.518351. Batch_loss: 1.298666 \n",
      "Batch: 3261. Acc: 0.516818. Loss: 1.338949. Batch_acc: 0.540295. Batch_loss: 1.262295 \n",
      "Batch: 3262. Acc: 0.516820. Loss: 1.338938. Batch_acc: 0.522482. Batch_loss: 1.303874 \n",
      "Batch: 3263. Acc: 0.516825. Loss: 1.338919. Batch_acc: 0.534382. Batch_loss: 1.277555 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.5168249346116012. Loss per char: 1.338919298260117. Time: 1627220587.056544\n",
      "Last question is tensor([ 2, 14, 20,  1, 12,  1, 14, 22, 18, 20, 20, 18, 24, 26, 15, 23, 17, 23,\n",
      "        26, 23,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.516820. Loss: 1.338932. Batch_acc: 0.501171. Batch_loss: 1.381485 \n",
      "Batch: 3265. Acc: 0.516820. Loss: 1.338931. Batch_acc: 0.516590. Batch_loss: 1.335360 \n",
      "Batch: 3266. Acc: 0.516827. Loss: 1.338910. Batch_acc: 0.538111. Batch_loss: 1.270946 \n",
      "Batch: 3267. Acc: 0.516834. Loss: 1.338893. Batch_acc: 0.539205. Batch_loss: 1.284968 \n",
      "Batch: 3268. Acc: 0.516840. Loss: 1.338875. Batch_acc: 0.537209. Batch_loss: 1.278886 \n",
      "Batch: 3269. Acc: 0.516845. Loss: 1.338863. Batch_acc: 0.532370. Batch_loss: 1.300314 \n",
      "Batch: 3270. Acc: 0.516838. Loss: 1.338874. Batch_acc: 0.494991. Batch_loss: 1.373092 \n",
      "Batch: 3271. Acc: 0.516838. Loss: 1.338865. Batch_acc: 0.515398. Batch_loss: 1.311544 \n",
      "Batch: 3272. Acc: 0.516841. Loss: 1.338863. Batch_acc: 0.527536. Batch_loss: 1.330366 \n",
      "Batch: 3273. Acc: 0.516835. Loss: 1.338873. Batch_acc: 0.498544. Batch_loss: 1.372640 \n",
      "Batch: 3274. Acc: 0.516834. Loss: 1.338873. Batch_acc: 0.512821. Batch_loss: 1.338303 \n",
      "Batch: 3275. Acc: 0.516837. Loss: 1.338871. Batch_acc: 0.527305. Batch_loss: 1.333193 \n",
      "Batch: 3276. Acc: 0.516843. Loss: 1.338853. Batch_acc: 0.535510. Batch_loss: 1.279091 \n",
      "Batch: 3277. Acc: 0.516848. Loss: 1.338845. Batch_acc: 0.531952. Batch_loss: 1.314136 \n",
      "Batch: 3278. Acc: 0.516850. Loss: 1.338845. Batch_acc: 0.525099. Batch_loss: 1.336697 \n",
      "Batch: 3279. Acc: 0.516861. Loss: 1.338816. Batch_acc: 0.552708. Batch_loss: 1.243748 \n",
      "Batch: 3280. Acc: 0.516864. Loss: 1.338811. Batch_acc: 0.526346. Batch_loss: 1.321784 \n",
      "Batch: 3281. Acc: 0.516878. Loss: 1.338778. Batch_acc: 0.564645. Batch_loss: 1.231968 \n",
      "Batch: 3282. Acc: 0.516881. Loss: 1.338766. Batch_acc: 0.523755. Batch_loss: 1.299162 \n",
      "Batch: 3283. Acc: 0.516881. Loss: 1.338764. Batch_acc: 0.518995. Batch_loss: 1.332728 \n",
      "Batch: 3284. Acc: 0.516882. Loss: 1.338750. Batch_acc: 0.520093. Batch_loss: 1.292349 \n",
      "Batch: 3285. Acc: 0.516882. Loss: 1.338752. Batch_acc: 0.515784. Batch_loss: 1.344243 \n",
      "Batch: 3286. Acc: 0.516885. Loss: 1.338733. Batch_acc: 0.527762. Batch_loss: 1.275531 \n",
      "Batch: 3287. Acc: 0.516883. Loss: 1.338739. Batch_acc: 0.508216. Batch_loss: 1.359687 \n",
      "Batch: 3288. Acc: 0.516889. Loss: 1.338728. Batch_acc: 0.536517. Batch_loss: 1.301832 \n",
      "Batch: 3289. Acc: 0.516889. Loss: 1.338719. Batch_acc: 0.518182. Batch_loss: 1.311264 \n",
      "Batch: 3290. Acc: 0.516901. Loss: 1.338689. Batch_acc: 0.556306. Batch_loss: 1.240389 \n",
      "Batch: 3291. Acc: 0.516904. Loss: 1.338685. Batch_acc: 0.524852. Batch_loss: 1.328335 \n",
      "Batch: 3292. Acc: 0.516914. Loss: 1.338663. Batch_acc: 0.551967. Batch_loss: 1.263452 \n",
      "Batch: 3293. Acc: 0.516917. Loss: 1.338654. Batch_acc: 0.525264. Batch_loss: 1.308968 \n",
      "Batch: 3294. Acc: 0.516921. Loss: 1.338644. Batch_acc: 0.532705. Batch_loss: 1.304620 \n",
      "Batch: 3295. Acc: 0.516919. Loss: 1.338645. Batch_acc: 0.510502. Batch_loss: 1.342599 \n",
      "Batch: 3296. Acc: 0.516919. Loss: 1.338643. Batch_acc: 0.517065. Batch_loss: 1.329720 \n",
      "Batch: 3297. Acc: 0.516917. Loss: 1.338639. Batch_acc: 0.509804. Batch_loss: 1.327659 \n",
      "Batch: 3298. Acc: 0.516922. Loss: 1.338623. Batch_acc: 0.532258. Batch_loss: 1.283735 \n",
      "Batch: 3299. Acc: 0.516925. Loss: 1.338620. Batch_acc: 0.526964. Batch_loss: 1.326312 \n",
      "Batch: 3300. Acc: 0.516925. Loss: 1.338613. Batch_acc: 0.519495. Batch_loss: 1.315498 \n",
      "Batch: 3301. Acc: 0.516930. Loss: 1.338597. Batch_acc: 0.531196. Batch_loss: 1.288471 \n",
      "Batch: 3302. Acc: 0.516936. Loss: 1.338594. Batch_acc: 0.538728. Batch_loss: 1.327753 \n",
      "Batch: 3303. Acc: 0.516940. Loss: 1.338586. Batch_acc: 0.528149. Batch_loss: 1.310232 \n",
      "Batch: 3304. Acc: 0.516950. Loss: 1.338565. Batch_acc: 0.549971. Batch_loss: 1.271546 \n",
      "Batch: 3305. Acc: 0.516951. Loss: 1.338566. Batch_acc: 0.519653. Batch_loss: 1.340109 \n",
      "Batch: 3306. Acc: 0.516949. Loss: 1.338564. Batch_acc: 0.512983. Batch_loss: 1.332586 \n",
      "Batch: 3307. Acc: 0.516952. Loss: 1.338559. Batch_acc: 0.524957. Batch_loss: 1.321459 \n",
      "Batch: 3308. Acc: 0.516960. Loss: 1.338536. Batch_acc: 0.544253. Batch_loss: 1.264923 \n",
      "Batch: 3309. Acc: 0.516962. Loss: 1.338530. Batch_acc: 0.523945. Batch_loss: 1.318571 \n",
      "Batch: 3310. Acc: 0.516963. Loss: 1.338519. Batch_acc: 0.520906. Batch_loss: 1.301118 \n",
      "Batch: 3311. Acc: 0.516976. Loss: 1.338484. Batch_acc: 0.558074. Batch_loss: 1.223490 \n",
      "Batch: 3312. Acc: 0.516976. Loss: 1.338485. Batch_acc: 0.517857. Batch_loss: 1.340814 \n",
      "Batch: 3313. Acc: 0.516983. Loss: 1.338465. Batch_acc: 0.539451. Batch_loss: 1.274071 \n",
      "Batch: 3314. Acc: 0.516985. Loss: 1.338458. Batch_acc: 0.523699. Batch_loss: 1.312429 \n",
      "Batch: 3315. Acc: 0.516988. Loss: 1.338444. Batch_acc: 0.527936. Batch_loss: 1.293516 \n",
      "Batch: 3316. Acc: 0.516999. Loss: 1.338411. Batch_acc: 0.553337. Batch_loss: 1.231748 \n",
      "Batch: 3317. Acc: 0.517000. Loss: 1.338410. Batch_acc: 0.518582. Batch_loss: 1.333569 \n",
      "Batch: 3318. Acc: 0.517007. Loss: 1.338394. Batch_acc: 0.540295. Batch_loss: 1.284996 \n",
      "Batch: 3319. Acc: 0.517011. Loss: 1.338384. Batch_acc: 0.529104. Batch_loss: 1.305146 \n",
      "Batch: 3320. Acc: 0.517008. Loss: 1.338389. Batch_acc: 0.507736. Batch_loss: 1.356669 \n",
      "Batch: 3321. Acc: 0.517015. Loss: 1.338364. Batch_acc: 0.540927. Batch_loss: 1.256040 \n",
      "Batch: 3322. Acc: 0.517021. Loss: 1.338341. Batch_acc: 0.538550. Batch_loss: 1.261467 \n",
      "Batch: 3323. Acc: 0.517021. Loss: 1.338345. Batch_acc: 0.515887. Batch_loss: 1.352237 \n",
      "Batch: 3324. Acc: 0.517023. Loss: 1.338346. Batch_acc: 0.522145. Batch_loss: 1.340439 \n",
      "Batch: 3325. Acc: 0.517033. Loss: 1.338308. Batch_acc: 0.550658. Batch_loss: 1.212545 \n",
      "Batch: 3326. Acc: 0.517035. Loss: 1.338300. Batch_acc: 0.522805. Batch_loss: 1.311108 \n",
      "Batch: 3327. Acc: 0.517041. Loss: 1.338294. Batch_acc: 0.539397. Batch_loss: 1.317794 \n",
      "Batch: 3328. Acc: 0.517039. Loss: 1.338300. Batch_acc: 0.508855. Batch_loss: 1.360559 \n",
      "Batch: 3329. Acc: 0.517040. Loss: 1.338298. Batch_acc: 0.521338. Batch_loss: 1.330750 \n",
      "Batch: 3330. Acc: 0.517049. Loss: 1.338276. Batch_acc: 0.545817. Batch_loss: 1.266493 \n",
      "Batch: 3331. Acc: 0.517055. Loss: 1.338262. Batch_acc: 0.536332. Batch_loss: 1.289925 \n",
      "Batch: 3332. Acc: 0.517061. Loss: 1.338250. Batch_acc: 0.538818. Batch_loss: 1.299966 \n",
      "Batch: 3333. Acc: 0.517062. Loss: 1.338252. Batch_acc: 0.519744. Batch_loss: 1.342738 \n",
      "Batch: 3334. Acc: 0.517068. Loss: 1.338233. Batch_acc: 0.536274. Batch_loss: 1.276300 \n",
      "Batch: 3335. Acc: 0.517065. Loss: 1.338240. Batch_acc: 0.506993. Batch_loss: 1.360185 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3336. Acc: 0.517063. Loss: 1.338245. Batch_acc: 0.513095. Batch_loss: 1.355788 \n",
      "Batch: 3337. Acc: 0.517062. Loss: 1.338249. Batch_acc: 0.511601. Batch_loss: 1.353483 \n",
      "Batch: 3338. Acc: 0.517062. Loss: 1.338247. Batch_acc: 0.517104. Batch_loss: 1.329919 \n",
      "Batch: 3339. Acc: 0.517063. Loss: 1.338240. Batch_acc: 0.522241. Batch_loss: 1.313956 \n",
      "Batch: 3340. Acc: 0.517063. Loss: 1.338239. Batch_acc: 0.517341. Batch_loss: 1.337813 \n",
      "Batch: 3341. Acc: 0.517072. Loss: 1.338218. Batch_acc: 0.544143. Batch_loss: 1.265490 \n",
      "Batch: 3342. Acc: 0.517073. Loss: 1.338215. Batch_acc: 0.520642. Batch_loss: 1.328599 \n",
      "Batch: 3343. Acc: 0.517080. Loss: 1.338202. Batch_acc: 0.542254. Batch_loss: 1.294069 \n",
      "Batch: 3344. Acc: 0.517081. Loss: 1.338202. Batch_acc: 0.519242. Batch_loss: 1.337592 \n",
      "Batch: 3345. Acc: 0.517086. Loss: 1.338182. Batch_acc: 0.534025. Batch_loss: 1.272657 \n",
      "Batch: 3346. Acc: 0.517098. Loss: 1.338143. Batch_acc: 0.555742. Batch_loss: 1.209596 \n",
      "Batch: 3347. Acc: 0.517097. Loss: 1.338141. Batch_acc: 0.514706. Batch_loss: 1.331335 \n",
      "Batch: 3348. Acc: 0.517104. Loss: 1.338123. Batch_acc: 0.540870. Batch_loss: 1.279043 \n",
      "Batch: 3349. Acc: 0.517109. Loss: 1.338097. Batch_acc: 0.534317. Batch_loss: 1.251316 \n",
      "Batch: 3350. Acc: 0.517106. Loss: 1.338103. Batch_acc: 0.506575. Batch_loss: 1.358906 \n",
      "Batch: 3351. Acc: 0.517110. Loss: 1.338095. Batch_acc: 0.531340. Batch_loss: 1.309048 \n",
      "Batch: 3352. Acc: 0.517123. Loss: 1.338070. Batch_acc: 0.560276. Batch_loss: 1.256607 \n",
      "Batch: 3353. Acc: 0.517130. Loss: 1.338055. Batch_acc: 0.541237. Batch_loss: 1.288330 \n",
      "Batch: 3354. Acc: 0.517132. Loss: 1.338047. Batch_acc: 0.524000. Batch_loss: 1.311198 \n",
      "Batch: 3355. Acc: 0.517131. Loss: 1.338050. Batch_acc: 0.513590. Batch_loss: 1.348166 \n",
      "Batch: 3356. Acc: 0.517140. Loss: 1.338029. Batch_acc: 0.545401. Batch_loss: 1.265730 \n",
      "Batch: 3357. Acc: 0.517142. Loss: 1.338028. Batch_acc: 0.524684. Batch_loss: 1.333501 \n",
      "Batch: 3358. Acc: 0.517144. Loss: 1.338021. Batch_acc: 0.523728. Batch_loss: 1.314286 \n",
      "Batch: 3359. Acc: 0.517139. Loss: 1.338033. Batch_acc: 0.502342. Batch_loss: 1.380257 \n",
      "Batch: 3360. Acc: 0.517148. Loss: 1.338009. Batch_acc: 0.546270. Batch_loss: 1.259925 \n",
      "Batch: 3361. Acc: 0.517152. Loss: 1.338002. Batch_acc: 0.527778. Batch_loss: 1.314907 \n",
      "Batch: 3362. Acc: 0.517153. Loss: 1.338000. Batch_acc: 0.522345. Batch_loss: 1.329068 \n",
      "Batch: 3363. Acc: 0.517156. Loss: 1.337989. Batch_acc: 0.526285. Batch_loss: 1.302985 \n",
      "Batch: 3364. Acc: 0.517159. Loss: 1.337976. Batch_acc: 0.526559. Batch_loss: 1.293290 \n",
      "Batch: 3365. Acc: 0.517156. Loss: 1.337989. Batch_acc: 0.509532. Batch_loss: 1.380396 \n",
      "Batch: 3366. Acc: 0.517153. Loss: 1.337996. Batch_acc: 0.506486. Batch_loss: 1.362716 \n",
      "Batch: 3367. Acc: 0.517150. Loss: 1.338005. Batch_acc: 0.506985. Batch_loss: 1.368749 \n",
      "Batch: 3368. Acc: 0.517155. Loss: 1.337999. Batch_acc: 0.534191. Batch_loss: 1.318408 \n",
      "Batch: 3369. Acc: 0.517155. Loss: 1.338002. Batch_acc: 0.514913. Batch_loss: 1.348184 \n",
      "Batch: 3370. Acc: 0.517153. Loss: 1.338007. Batch_acc: 0.511734. Batch_loss: 1.352724 \n",
      "Batch: 3371. Acc: 0.517155. Loss: 1.337999. Batch_acc: 0.522795. Batch_loss: 1.312135 \n",
      "Batch: 3372. Acc: 0.517163. Loss: 1.337980. Batch_acc: 0.545253. Batch_loss: 1.276858 \n",
      "Batch: 3373. Acc: 0.517163. Loss: 1.337986. Batch_acc: 0.518265. Batch_loss: 1.356135 \n",
      "Batch: 3374. Acc: 0.517166. Loss: 1.337979. Batch_acc: 0.526744. Batch_loss: 1.313861 \n",
      "Batch: 3375. Acc: 0.517172. Loss: 1.337965. Batch_acc: 0.536443. Batch_loss: 1.290622 \n",
      "Batch: 3376. Acc: 0.517176. Loss: 1.337953. Batch_acc: 0.531496. Batch_loss: 1.300378 \n",
      "Batch: 3377. Acc: 0.517175. Loss: 1.337952. Batch_acc: 0.512055. Batch_loss: 1.333620 \n",
      "Batch: 3378. Acc: 0.517182. Loss: 1.337935. Batch_acc: 0.541405. Batch_loss: 1.280673 \n",
      "Batch: 3379. Acc: 0.517186. Loss: 1.337909. Batch_acc: 0.531338. Batch_loss: 1.250519 \n",
      "Batch: 3380. Acc: 0.517191. Loss: 1.337908. Batch_acc: 0.533606. Batch_loss: 1.336502 \n",
      "Batch: 3381. Acc: 0.517192. Loss: 1.337903. Batch_acc: 0.519636. Batch_loss: 1.319988 \n",
      "Batch: 3382. Acc: 0.517196. Loss: 1.337891. Batch_acc: 0.533333. Batch_loss: 1.298130 \n",
      "Batch: 3383. Acc: 0.517198. Loss: 1.337878. Batch_acc: 0.523482. Batch_loss: 1.291373 \n",
      "Batch: 3384. Acc: 0.517208. Loss: 1.337843. Batch_acc: 0.550276. Batch_loss: 1.224665 \n",
      "Batch: 3385. Acc: 0.517219. Loss: 1.337817. Batch_acc: 0.551466. Batch_loss: 1.251894 \n",
      "Batch: 3386. Acc: 0.517219. Loss: 1.337813. Batch_acc: 0.519023. Batch_loss: 1.321745 \n",
      "Batch: 3387. Acc: 0.517220. Loss: 1.337812. Batch_acc: 0.521403. Batch_loss: 1.334559 \n",
      "Batch: 3388. Acc: 0.517222. Loss: 1.337811. Batch_acc: 0.524289. Batch_loss: 1.334141 \n",
      "Batch: 3389. Acc: 0.517231. Loss: 1.337783. Batch_acc: 0.546369. Batch_loss: 1.247780 \n",
      "Batch: 3390. Acc: 0.517233. Loss: 1.337773. Batch_acc: 0.524000. Batch_loss: 1.304001 \n",
      "Batch: 3391. Acc: 0.517233. Loss: 1.337773. Batch_acc: 0.518107. Batch_loss: 1.338528 \n",
      "Batch: 3392. Acc: 0.517240. Loss: 1.337754. Batch_acc: 0.538908. Batch_loss: 1.269822 \n",
      "Batch: 3393. Acc: 0.517244. Loss: 1.337744. Batch_acc: 0.530017. Batch_loss: 1.306699 \n",
      "Batch: 3394. Acc: 0.517244. Loss: 1.337742. Batch_acc: 0.519816. Batch_loss: 1.330392 \n",
      "Batch: 3395. Acc: 0.517256. Loss: 1.337712. Batch_acc: 0.555188. Batch_loss: 1.237760 \n",
      "Batch: 3396. Acc: 0.517258. Loss: 1.337702. Batch_acc: 0.522822. Batch_loss: 1.306007 \n",
      "Batch: 3397. Acc: 0.517258. Loss: 1.337696. Batch_acc: 0.518862. Batch_loss: 1.314736 \n",
      "Batch: 3398. Acc: 0.517262. Loss: 1.337677. Batch_acc: 0.530023. Batch_loss: 1.272594 \n",
      "Batch: 3399. Acc: 0.517266. Loss: 1.337675. Batch_acc: 0.530371. Batch_loss: 1.331997 \n",
      "Batch: 3400. Acc: 0.517266. Loss: 1.337666. Batch_acc: 0.519636. Batch_loss: 1.306658 \n",
      "Batch: 3401. Acc: 0.517272. Loss: 1.337649. Batch_acc: 0.536848. Batch_loss: 1.282913 \n",
      "Batch: 3402. Acc: 0.517285. Loss: 1.337608. Batch_acc: 0.558986. Batch_loss: 1.201015 \n",
      "Batch: 3403. Acc: 0.517292. Loss: 1.337585. Batch_acc: 0.540113. Batch_loss: 1.262128 \n",
      "Batch: 3404. Acc: 0.517298. Loss: 1.337570. Batch_acc: 0.539031. Batch_loss: 1.287634 \n",
      "Batch: 3405. Acc: 0.517296. Loss: 1.337566. Batch_acc: 0.508883. Batch_loss: 1.322355 \n",
      "Batch: 3406. Acc: 0.517297. Loss: 1.337566. Batch_acc: 0.522846. Batch_loss: 1.337883 \n",
      "Batch: 3407. Acc: 0.517299. Loss: 1.337564. Batch_acc: 0.524170. Batch_loss: 1.332870 \n",
      "Batch: 3408. Acc: 0.517307. Loss: 1.337549. Batch_acc: 0.544210. Batch_loss: 1.286639 \n",
      "Batch: 3409. Acc: 0.517308. Loss: 1.337546. Batch_acc: 0.518328. Batch_loss: 1.327424 \n",
      "Batch: 3410. Acc: 0.517306. Loss: 1.337546. Batch_acc: 0.511137. Batch_loss: 1.334975 \n",
      "Batch: 3411. Acc: 0.517301. Loss: 1.337557. Batch_acc: 0.502015. Batch_loss: 1.377055 \n",
      "Batch: 3412. Acc: 0.517305. Loss: 1.337557. Batch_acc: 0.527731. Batch_loss: 1.337717 \n",
      "Batch: 3413. Acc: 0.517301. Loss: 1.337560. Batch_acc: 0.503889. Batch_loss: 1.345939 \n",
      "Batch: 3414. Acc: 0.517300. Loss: 1.337557. Batch_acc: 0.515452. Batch_loss: 1.326458 \n",
      "Batch: 3415. Acc: 0.517305. Loss: 1.337546. Batch_acc: 0.534759. Batch_loss: 1.298792 \n",
      "Batch: 3416. Acc: 0.517314. Loss: 1.337525. Batch_acc: 0.549826. Batch_loss: 1.267365 \n",
      "Batch: 3417. Acc: 0.517315. Loss: 1.337514. Batch_acc: 0.520461. Batch_loss: 1.298009 \n",
      "Batch: 3418. Acc: 0.517315. Loss: 1.337512. Batch_acc: 0.515306. Batch_loss: 1.332672 \n",
      "Batch: 3419. Acc: 0.517316. Loss: 1.337513. Batch_acc: 0.522831. Batch_loss: 1.341292 \n",
      "Batch: 3420. Acc: 0.517323. Loss: 1.337495. Batch_acc: 0.541691. Batch_loss: 1.273201 \n",
      "Batch: 3421. Acc: 0.517322. Loss: 1.337492. Batch_acc: 0.514077. Batch_loss: 1.327796 \n",
      "Batch: 3422. Acc: 0.517321. Loss: 1.337493. Batch_acc: 0.513228. Batch_loss: 1.342929 \n",
      "Batch: 3423. Acc: 0.517326. Loss: 1.337481. Batch_acc: 0.533918. Batch_loss: 1.293936 \n",
      "Batch: 3424. Acc: 0.517327. Loss: 1.337473. Batch_acc: 0.521764. Batch_loss: 1.311379 \n",
      "Batch: 3425. Acc: 0.517329. Loss: 1.337471. Batch_acc: 0.522846. Batch_loss: 1.330338 \n",
      "Batch: 3426. Acc: 0.517333. Loss: 1.337455. Batch_acc: 0.530707. Batch_loss: 1.282668 \n",
      "Batch: 3427. Acc: 0.517344. Loss: 1.337434. Batch_acc: 0.555936. Batch_loss: 1.264300 \n",
      "Batch: 3428. Acc: 0.517349. Loss: 1.337417. Batch_acc: 0.535179. Batch_loss: 1.278659 \n",
      "Batch: 3429. Acc: 0.517353. Loss: 1.337407. Batch_acc: 0.530120. Batch_loss: 1.304709 \n",
      "Batch: 3430. Acc: 0.517361. Loss: 1.337389. Batch_acc: 0.544202. Batch_loss: 1.275711 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3431. Acc: 0.517365. Loss: 1.337371. Batch_acc: 0.531480. Batch_loss: 1.277033 \n",
      "Batch: 3432. Acc: 0.517360. Loss: 1.337380. Batch_acc: 0.498246. Batch_loss: 1.367767 \n",
      "Batch: 3433. Acc: 0.517353. Loss: 1.337388. Batch_acc: 0.495873. Batch_loss: 1.365472 \n",
      "Batch: 3434. Acc: 0.517361. Loss: 1.337364. Batch_acc: 0.541762. Batch_loss: 1.255185 \n",
      "Batch: 3435. Acc: 0.517366. Loss: 1.337349. Batch_acc: 0.536684. Batch_loss: 1.286134 \n",
      "Batch: 3436. Acc: 0.517374. Loss: 1.337329. Batch_acc: 0.545507. Batch_loss: 1.267635 \n",
      "Batch: 3437. Acc: 0.517374. Loss: 1.337328. Batch_acc: 0.517626. Batch_loss: 1.332676 \n",
      "Batch: 3438. Acc: 0.517379. Loss: 1.337313. Batch_acc: 0.533788. Batch_loss: 1.288005 \n",
      "Batch: 3439. Acc: 0.517385. Loss: 1.337302. Batch_acc: 0.536490. Batch_loss: 1.301350 \n",
      "Batch: 3440. Acc: 0.517387. Loss: 1.337292. Batch_acc: 0.525028. Batch_loss: 1.302659 \n",
      "Batch: 3441. Acc: 0.517399. Loss: 1.337264. Batch_acc: 0.555366. Batch_loss: 1.243040 \n",
      "Batch: 3442. Acc: 0.517407. Loss: 1.337243. Batch_acc: 0.545915. Batch_loss: 1.264767 \n",
      "Batch: 3443. Acc: 0.517409. Loss: 1.337237. Batch_acc: 0.525952. Batch_loss: 1.316772 \n",
      "Batch: 3444. Acc: 0.517416. Loss: 1.337220. Batch_acc: 0.540416. Batch_loss: 1.279065 \n",
      "Batch: 3445. Acc: 0.517418. Loss: 1.337211. Batch_acc: 0.522946. Batch_loss: 1.308517 \n",
      "Batch: 3446. Acc: 0.517424. Loss: 1.337186. Batch_acc: 0.539564. Batch_loss: 1.251677 \n",
      "Batch: 3447. Acc: 0.517432. Loss: 1.337161. Batch_acc: 0.543860. Batch_loss: 1.252297 \n",
      "Batch: 3448. Acc: 0.517437. Loss: 1.337143. Batch_acc: 0.533561. Batch_loss: 1.273987 \n",
      "Batch: 3449. Acc: 0.517437. Loss: 1.337136. Batch_acc: 0.519885. Batch_loss: 1.314734 \n",
      "Batch: 3450. Acc: 0.517450. Loss: 1.337105. Batch_acc: 0.557971. Batch_loss: 1.231893 \n",
      "Batch: 3451. Acc: 0.517452. Loss: 1.337094. Batch_acc: 0.525327. Batch_loss: 1.300814 \n",
      "Batch: 3452. Acc: 0.517461. Loss: 1.337071. Batch_acc: 0.548759. Batch_loss: 1.256506 \n",
      "Batch: 3453. Acc: 0.517468. Loss: 1.337046. Batch_acc: 0.541136. Batch_loss: 1.250645 \n",
      "Batch: 3454. Acc: 0.517471. Loss: 1.337034. Batch_acc: 0.530707. Batch_loss: 1.295249 \n",
      "Batch: 3455. Acc: 0.517471. Loss: 1.337035. Batch_acc: 0.514382. Batch_loss: 1.341099 \n",
      "Batch: 3456. Acc: 0.517474. Loss: 1.337021. Batch_acc: 0.527485. Batch_loss: 1.288391 \n",
      "Batch: 3457. Acc: 0.517476. Loss: 1.337011. Batch_acc: 0.525463. Batch_loss: 1.303969 \n",
      "Batch: 3458. Acc: 0.517485. Loss: 1.336986. Batch_acc: 0.548425. Batch_loss: 1.247160 \n",
      "Batch: 3459. Acc: 0.517489. Loss: 1.336969. Batch_acc: 0.533908. Batch_loss: 1.277166 \n",
      "Batch: 3460. Acc: 0.517491. Loss: 1.336960. Batch_acc: 0.524554. Batch_loss: 1.308685 \n",
      "Batch: 3461. Acc: 0.517498. Loss: 1.336942. Batch_acc: 0.539459. Batch_loss: 1.273129 \n",
      "Batch: 3462. Acc: 0.517504. Loss: 1.336926. Batch_acc: 0.540125. Batch_loss: 1.284767 \n",
      "Batch: 3463. Acc: 0.517512. Loss: 1.336907. Batch_acc: 0.543174. Batch_loss: 1.269510 \n",
      "Batch: 3464. Acc: 0.517510. Loss: 1.336909. Batch_acc: 0.512263. Batch_loss: 1.342730 \n",
      "Batch: 3465. Acc: 0.517509. Loss: 1.336908. Batch_acc: 0.513970. Batch_loss: 1.332017 \n",
      "Batch: 3466. Acc: 0.517511. Loss: 1.336909. Batch_acc: 0.524868. Batch_loss: 1.340888 \n",
      "Batch: 3467. Acc: 0.517508. Loss: 1.336912. Batch_acc: 0.504849. Batch_loss: 1.349274 \n",
      "Batch: 3468. Acc: 0.517507. Loss: 1.336918. Batch_acc: 0.513809. Batch_loss: 1.357190 \n",
      "Batch: 3469. Acc: 0.517522. Loss: 1.336871. Batch_acc: 0.572002. Batch_loss: 1.173406 \n",
      "Batch: 3470. Acc: 0.517528. Loss: 1.336859. Batch_acc: 0.536544. Batch_loss: 1.294515 \n",
      "Batch: 3471. Acc: 0.517530. Loss: 1.336851. Batch_acc: 0.526624. Batch_loss: 1.311689 \n",
      "Batch: 3472. Acc: 0.517529. Loss: 1.336858. Batch_acc: 0.512821. Batch_loss: 1.360656 \n",
      "Batch: 3473. Acc: 0.517538. Loss: 1.336843. Batch_acc: 0.549771. Batch_loss: 1.285207 \n",
      "Batch: 3474. Acc: 0.517543. Loss: 1.336830. Batch_acc: 0.533024. Batch_loss: 1.291891 \n",
      "Batch: 3475. Acc: 0.517548. Loss: 1.336820. Batch_acc: 0.537394. Batch_loss: 1.299619 \n",
      "Batch: 3476. Acc: 0.517554. Loss: 1.336814. Batch_acc: 0.535959. Batch_loss: 1.316768 \n",
      "Batch: 3477. Acc: 0.517555. Loss: 1.336813. Batch_acc: 0.522145. Batch_loss: 1.331188 \n",
      "Batch: 3478. Acc: 0.517566. Loss: 1.336787. Batch_acc: 0.555492. Batch_loss: 1.248152 \n",
      "Batch: 3479. Acc: 0.517569. Loss: 1.336784. Batch_acc: 0.527793. Batch_loss: 1.324901 \n",
      "Batch: 3480. Acc: 0.517576. Loss: 1.336762. Batch_acc: 0.542088. Batch_loss: 1.264192 \n",
      "Batch: 3481. Acc: 0.517583. Loss: 1.336743. Batch_acc: 0.540694. Batch_loss: 1.269404 \n",
      "Batch: 3482. Acc: 0.517595. Loss: 1.336702. Batch_acc: 0.559664. Batch_loss: 1.198346 \n",
      "Batch: 3483. Acc: 0.517605. Loss: 1.336679. Batch_acc: 0.550716. Batch_loss: 1.255040 \n",
      "Batch: 3484. Acc: 0.517608. Loss: 1.336675. Batch_acc: 0.528681. Batch_loss: 1.325071 \n",
      "Batch: 3485. Acc: 0.517606. Loss: 1.336676. Batch_acc: 0.510505. Batch_loss: 1.339659 \n",
      "Batch: 3486. Acc: 0.517616. Loss: 1.336649. Batch_acc: 0.552764. Batch_loss: 1.243668 \n",
      "Batch: 3487. Acc: 0.517618. Loss: 1.336643. Batch_acc: 0.524571. Batch_loss: 1.317261 \n",
      "Batch: 3488. Acc: 0.517620. Loss: 1.336641. Batch_acc: 0.525490. Batch_loss: 1.329010 \n",
      "Batch: 3489. Acc: 0.517624. Loss: 1.336630. Batch_acc: 0.530589. Batch_loss: 1.300161 \n",
      "Batch: 3490. Acc: 0.517632. Loss: 1.336604. Batch_acc: 0.545775. Batch_loss: 1.241858 \n",
      "Batch: 3491. Acc: 0.517637. Loss: 1.336588. Batch_acc: 0.533179. Batch_loss: 1.280864 \n",
      "Batch: 3492. Acc: 0.517634. Loss: 1.336586. Batch_acc: 0.508102. Batch_loss: 1.331248 \n",
      "Batch: 3493. Acc: 0.517636. Loss: 1.336578. Batch_acc: 0.525224. Batch_loss: 1.308848 \n",
      "Batch: 3494. Acc: 0.517634. Loss: 1.336579. Batch_acc: 0.511696. Batch_loss: 1.340493 \n",
      "Batch: 3495. Acc: 0.517635. Loss: 1.336576. Batch_acc: 0.520302. Batch_loss: 1.325699 \n",
      "Batch: 3496. Acc: 0.517641. Loss: 1.336564. Batch_acc: 0.538957. Batch_loss: 1.292494 \n",
      "Batch: 3497. Acc: 0.517641. Loss: 1.336553. Batch_acc: 0.518561. Batch_loss: 1.298646 \n",
      "Batch: 3498. Acc: 0.517635. Loss: 1.336570. Batch_acc: 0.495637. Batch_loss: 1.396504 \n",
      "Batch: 3499. Acc: 0.517640. Loss: 1.336562. Batch_acc: 0.535940. Batch_loss: 1.308526 \n",
      "Batch: 3500. Acc: 0.517635. Loss: 1.336576. Batch_acc: 0.500565. Batch_loss: 1.383468 \n",
      "Batch: 3501. Acc: 0.517632. Loss: 1.336576. Batch_acc: 0.506985. Batch_loss: 1.338173 \n",
      "Batch: 3502. Acc: 0.517630. Loss: 1.336577. Batch_acc: 0.509748. Batch_loss: 1.339985 \n",
      "Batch: 3503. Acc: 0.517635. Loss: 1.336559. Batch_acc: 0.533070. Batch_loss: 1.274287 \n",
      "Batch: 3504. Acc: 0.517643. Loss: 1.336539. Batch_acc: 0.546079. Batch_loss: 1.267999 \n",
      "Batch: 3505. Acc: 0.517648. Loss: 1.336524. Batch_acc: 0.535818. Batch_loss: 1.281271 \n",
      "Batch: 3506. Acc: 0.517644. Loss: 1.336540. Batch_acc: 0.503218. Batch_loss: 1.393495 \n",
      "Batch: 3507. Acc: 0.517634. Loss: 1.336562. Batch_acc: 0.482958. Batch_loss: 1.414361 \n",
      "Batch: 3508. Acc: 0.517640. Loss: 1.336545. Batch_acc: 0.537752. Batch_loss: 1.276287 \n",
      "Batch: 3509. Acc: 0.517644. Loss: 1.336534. Batch_acc: 0.532884. Batch_loss: 1.299746 \n",
      "Batch: 3510. Acc: 0.517650. Loss: 1.336522. Batch_acc: 0.538722. Batch_loss: 1.296786 \n",
      "Batch: 3511. Acc: 0.517656. Loss: 1.336499. Batch_acc: 0.537166. Batch_loss: 1.252603 \n",
      "Batch: 3512. Acc: 0.517661. Loss: 1.336482. Batch_acc: 0.534522. Batch_loss: 1.276754 \n",
      "Batch: 3513. Acc: 0.517665. Loss: 1.336471. Batch_acc: 0.532240. Batch_loss: 1.300730 \n",
      "Batch: 3514. Acc: 0.517668. Loss: 1.336464. Batch_acc: 0.527615. Batch_loss: 1.310153 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.5176676175687964. Loss per char: 1.336464005094152. Time: 1627220792.939633\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 18, 17,  1, 78, 74, 79, 86, 84,  1,\n",
      "        14, 19, 24, 21, 23, 18, 22, 21, 26, 21, 21, 24, 24, 22, 23, 32,  3,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.517673. Loss: 1.336441. Batch_acc: 0.534857. Batch_loss: 1.255831 \n",
      "Batch: 3516. Acc: 0.517677. Loss: 1.336422. Batch_acc: 0.533724. Batch_loss: 1.269587 \n",
      "Batch: 3517. Acc: 0.517680. Loss: 1.336419. Batch_acc: 0.529717. Batch_loss: 1.325916 \n",
      "Batch: 3518. Acc: 0.517690. Loss: 1.336390. Batch_acc: 0.549570. Batch_loss: 1.232307 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3519. Acc: 0.517687. Loss: 1.336390. Batch_acc: 0.507205. Batch_loss: 1.336401 \n",
      "Batch: 3520. Acc: 0.517692. Loss: 1.336362. Batch_acc: 0.535794. Batch_loss: 1.241800 \n",
      "Batch: 3521. Acc: 0.517693. Loss: 1.336357. Batch_acc: 0.521490. Batch_loss: 1.320494 \n",
      "Batch: 3522. Acc: 0.517692. Loss: 1.336351. Batch_acc: 0.515186. Batch_loss: 1.315420 \n",
      "Batch: 3523. Acc: 0.517687. Loss: 1.336373. Batch_acc: 0.498853. Batch_loss: 1.410875 \n",
      "Batch: 3524. Acc: 0.517692. Loss: 1.336354. Batch_acc: 0.535447. Batch_loss: 1.270340 \n",
      "Batch: 3525. Acc: 0.517697. Loss: 1.336336. Batch_acc: 0.534247. Batch_loss: 1.273233 \n",
      "Batch: 3526. Acc: 0.517700. Loss: 1.336322. Batch_acc: 0.530600. Batch_loss: 1.288147 \n",
      "Batch: 3527. Acc: 0.517710. Loss: 1.336299. Batch_acc: 0.552661. Batch_loss: 1.254446 \n",
      "Batch: 3528. Acc: 0.517709. Loss: 1.336300. Batch_acc: 0.511926. Batch_loss: 1.339769 \n",
      "Batch: 3529. Acc: 0.517715. Loss: 1.336287. Batch_acc: 0.538594. Batch_loss: 1.290096 \n",
      "Batch: 3530. Acc: 0.517723. Loss: 1.336261. Batch_acc: 0.548127. Batch_loss: 1.246391 \n",
      "Batch: 3531. Acc: 0.517731. Loss: 1.336244. Batch_acc: 0.545091. Batch_loss: 1.274132 \n",
      "Batch: 3532. Acc: 0.517737. Loss: 1.336226. Batch_acc: 0.540082. Batch_loss: 1.272353 \n",
      "Batch: 3533. Acc: 0.517746. Loss: 1.336210. Batch_acc: 0.547836. Batch_loss: 1.281854 \n",
      "Batch: 3534. Acc: 0.517750. Loss: 1.336199. Batch_acc: 0.531579. Batch_loss: 1.296258 \n",
      "Batch: 3535. Acc: 0.517753. Loss: 1.336199. Batch_acc: 0.528173. Batch_loss: 1.337269 \n",
      "Batch: 3536. Acc: 0.517759. Loss: 1.336195. Batch_acc: 0.541130. Batch_loss: 1.321372 \n",
      "Batch: 3537. Acc: 0.517760. Loss: 1.336187. Batch_acc: 0.520628. Batch_loss: 1.306706 \n",
      "Batch: 3538. Acc: 0.517758. Loss: 1.336196. Batch_acc: 0.511331. Batch_loss: 1.369773 \n",
      "Batch: 3539. Acc: 0.517765. Loss: 1.336183. Batch_acc: 0.540154. Batch_loss: 1.290375 \n",
      "Batch: 3540. Acc: 0.517764. Loss: 1.336190. Batch_acc: 0.513002. Batch_loss: 1.363854 \n",
      "Batch: 3541. Acc: 0.517771. Loss: 1.336168. Batch_acc: 0.542344. Batch_loss: 1.260645 \n",
      "Batch: 3542. Acc: 0.517773. Loss: 1.336162. Batch_acc: 0.523699. Batch_loss: 1.314704 \n",
      "Batch: 3543. Acc: 0.517775. Loss: 1.336154. Batch_acc: 0.526163. Batch_loss: 1.306651 \n",
      "Batch: 3544. Acc: 0.517773. Loss: 1.336157. Batch_acc: 0.509703. Batch_loss: 1.346704 \n",
      "Batch: 3545. Acc: 0.517777. Loss: 1.336145. Batch_acc: 0.533963. Batch_loss: 1.292074 \n",
      "Batch: 3546. Acc: 0.517777. Loss: 1.336138. Batch_acc: 0.519443. Batch_loss: 1.311306 \n",
      "Batch: 3547. Acc: 0.517785. Loss: 1.336115. Batch_acc: 0.545040. Batch_loss: 1.253141 \n",
      "Batch: 3548. Acc: 0.517787. Loss: 1.336111. Batch_acc: 0.522879. Batch_loss: 1.324932 \n",
      "Batch: 3549. Acc: 0.517790. Loss: 1.336106. Batch_acc: 0.530277. Batch_loss: 1.318640 \n",
      "Batch: 3550. Acc: 0.517804. Loss: 1.336070. Batch_acc: 0.564830. Batch_loss: 1.211501 \n",
      "Batch: 3551. Acc: 0.517808. Loss: 1.336061. Batch_acc: 0.530114. Batch_loss: 1.306048 \n",
      "Batch: 3552. Acc: 0.517814. Loss: 1.336044. Batch_acc: 0.542072. Batch_loss: 1.274845 \n",
      "Batch: 3553. Acc: 0.517821. Loss: 1.336023. Batch_acc: 0.542609. Batch_loss: 1.261279 \n",
      "Batch: 3554. Acc: 0.517817. Loss: 1.336043. Batch_acc: 0.502075. Batch_loss: 1.409591 \n",
      "Batch: 3555. Acc: 0.517823. Loss: 1.336025. Batch_acc: 0.539718. Batch_loss: 1.270344 \n",
      "Batch: 3556. Acc: 0.517833. Loss: 1.336008. Batch_acc: 0.552752. Batch_loss: 1.276774 \n",
      "Batch: 3557. Acc: 0.517830. Loss: 1.336015. Batch_acc: 0.507937. Batch_loss: 1.363953 \n",
      "Batch: 3558. Acc: 0.517822. Loss: 1.336031. Batch_acc: 0.487819. Batch_loss: 1.393471 \n",
      "Batch: 3559. Acc: 0.517829. Loss: 1.336016. Batch_acc: 0.544202. Batch_loss: 1.281691 \n",
      "Batch: 3560. Acc: 0.517837. Loss: 1.336000. Batch_acc: 0.544772. Batch_loss: 1.277050 \n",
      "Batch: 3561. Acc: 0.517847. Loss: 1.335973. Batch_acc: 0.552616. Batch_loss: 1.242105 \n",
      "Batch: 3562. Acc: 0.517852. Loss: 1.335953. Batch_acc: 0.534750. Batch_loss: 1.263136 \n",
      "Batch: 3563. Acc: 0.517858. Loss: 1.335922. Batch_acc: 0.540984. Batch_loss: 1.228944 \n",
      "Batch: 3564. Acc: 0.517858. Loss: 1.335918. Batch_acc: 0.516477. Batch_loss: 1.319465 \n",
      "Batch: 3565. Acc: 0.517860. Loss: 1.335913. Batch_acc: 0.526894. Batch_loss: 1.320361 \n",
      "Batch: 3566. Acc: 0.517867. Loss: 1.335897. Batch_acc: 0.542480. Batch_loss: 1.276369 \n",
      "Batch: 3567. Acc: 0.517869. Loss: 1.335888. Batch_acc: 0.525354. Batch_loss: 1.304602 \n",
      "Batch: 3568. Acc: 0.517873. Loss: 1.335877. Batch_acc: 0.529412. Batch_loss: 1.297931 \n",
      "Batch: 3569. Acc: 0.517885. Loss: 1.335847. Batch_acc: 0.561283. Batch_loss: 1.227336 \n",
      "Batch: 3570. Acc: 0.517880. Loss: 1.335856. Batch_acc: 0.502353. Batch_loss: 1.370290 \n",
      "Batch: 3571. Acc: 0.517883. Loss: 1.335849. Batch_acc: 0.527397. Batch_loss: 1.310446 \n",
      "Batch: 3572. Acc: 0.517889. Loss: 1.335821. Batch_acc: 0.539540. Batch_loss: 1.237395 \n",
      "Batch: 3573. Acc: 0.517881. Loss: 1.335838. Batch_acc: 0.488427. Batch_loss: 1.397950 \n",
      "Batch: 3574. Acc: 0.517882. Loss: 1.335835. Batch_acc: 0.520833. Batch_loss: 1.326083 \n",
      "Batch: 3575. Acc: 0.517886. Loss: 1.335829. Batch_acc: 0.533053. Batch_loss: 1.314396 \n",
      "Batch: 3576. Acc: 0.517885. Loss: 1.335825. Batch_acc: 0.515203. Batch_loss: 1.322740 \n",
      "Batch: 3577. Acc: 0.517892. Loss: 1.335805. Batch_acc: 0.542711. Batch_loss: 1.263690 \n",
      "Batch: 3578. Acc: 0.517895. Loss: 1.335796. Batch_acc: 0.528412. Batch_loss: 1.302015 \n",
      "Batch: 3579. Acc: 0.517899. Loss: 1.335787. Batch_acc: 0.532716. Batch_loss: 1.305967 \n",
      "Batch: 3580. Acc: 0.517911. Loss: 1.335772. Batch_acc: 0.559351. Batch_loss: 1.281180 \n",
      "Batch: 3581. Acc: 0.517911. Loss: 1.335776. Batch_acc: 0.518453. Batch_loss: 1.348092 \n",
      "Batch: 3582. Acc: 0.517917. Loss: 1.335765. Batch_acc: 0.537720. Batch_loss: 1.299095 \n",
      "Batch: 3583. Acc: 0.517918. Loss: 1.335752. Batch_acc: 0.523032. Batch_loss: 1.288001 \n",
      "Batch: 3584. Acc: 0.517927. Loss: 1.335730. Batch_acc: 0.549255. Batch_loss: 1.256797 \n",
      "Batch: 3585. Acc: 0.517929. Loss: 1.335731. Batch_acc: 0.524294. Batch_loss: 1.337560 \n",
      "Batch: 3586. Acc: 0.517931. Loss: 1.335726. Batch_acc: 0.526932. Batch_loss: 1.320596 \n",
      "Batch: 3587. Acc: 0.517935. Loss: 1.335714. Batch_acc: 0.531090. Batch_loss: 1.292109 \n",
      "Batch: 3588. Acc: 0.517933. Loss: 1.335717. Batch_acc: 0.511312. Batch_loss: 1.344629 \n",
      "Batch: 3589. Acc: 0.517938. Loss: 1.335711. Batch_acc: 0.534364. Batch_loss: 1.315689 \n",
      "Batch: 3590. Acc: 0.517937. Loss: 1.335707. Batch_acc: 0.516752. Batch_loss: 1.322287 \n",
      "Batch: 3591. Acc: 0.517949. Loss: 1.335677. Batch_acc: 0.558320. Batch_loss: 1.232405 \n",
      "Batch: 3592. Acc: 0.517947. Loss: 1.335674. Batch_acc: 0.511098. Batch_loss: 1.324409 \n",
      "Batch: 3593. Acc: 0.517954. Loss: 1.335653. Batch_acc: 0.541176. Batch_loss: 1.260022 \n",
      "Batch: 3594. Acc: 0.517955. Loss: 1.335651. Batch_acc: 0.522910. Batch_loss: 1.328694 \n",
      "Batch: 3595. Acc: 0.517956. Loss: 1.335650. Batch_acc: 0.521086. Batch_loss: 1.331845 \n",
      "Batch: 3596. Acc: 0.517956. Loss: 1.335644. Batch_acc: 0.518775. Batch_loss: 1.316162 \n",
      "Batch: 3597. Acc: 0.517954. Loss: 1.335650. Batch_acc: 0.510526. Batch_loss: 1.357458 \n",
      "Batch: 3598. Acc: 0.517956. Loss: 1.335646. Batch_acc: 0.522727. Batch_loss: 1.319244 \n",
      "Batch: 3599. Acc: 0.517951. Loss: 1.335653. Batch_acc: 0.500869. Batch_loss: 1.361539 \n",
      "Batch: 3600. Acc: 0.517957. Loss: 1.335635. Batch_acc: 0.538247. Batch_loss: 1.272620 \n",
      "Batch: 3601. Acc: 0.517960. Loss: 1.335634. Batch_acc: 0.528684. Batch_loss: 1.332310 \n",
      "Batch: 3602. Acc: 0.517961. Loss: 1.335624. Batch_acc: 0.521240. Batch_loss: 1.300310 \n",
      "Batch: 3603. Acc: 0.517964. Loss: 1.335610. Batch_acc: 0.530190. Batch_loss: 1.285375 \n",
      "Batch: 3604. Acc: 0.517974. Loss: 1.335582. Batch_acc: 0.552408. Batch_loss: 1.236976 \n",
      "Batch: 3605. Acc: 0.517982. Loss: 1.335560. Batch_acc: 0.548350. Batch_loss: 1.256580 \n",
      "Batch: 3606. Acc: 0.517981. Loss: 1.335558. Batch_acc: 0.514431. Batch_loss: 1.327567 \n",
      "Batch: 3607. Acc: 0.517985. Loss: 1.335541. Batch_acc: 0.532230. Batch_loss: 1.275541 \n",
      "Batch: 3608. Acc: 0.517989. Loss: 1.335526. Batch_acc: 0.531073. Batch_loss: 1.281161 \n",
      "Batch: 3609. Acc: 0.517991. Loss: 1.335521. Batch_acc: 0.527389. Batch_loss: 1.316766 \n",
      "Batch: 3610. Acc: 0.517994. Loss: 1.335514. Batch_acc: 0.527902. Batch_loss: 1.310514 \n",
      "Batch: 3611. Acc: 0.517992. Loss: 1.335511. Batch_acc: 0.508803. Batch_loss: 1.326263 \n",
      "Batch: 3612. Acc: 0.517997. Loss: 1.335505. Batch_acc: 0.536082. Batch_loss: 1.312166 \n",
      "Batch: 3613. Acc: 0.517999. Loss: 1.335500. Batch_acc: 0.525253. Batch_loss: 1.318799 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3614. Acc: 0.517996. Loss: 1.335509. Batch_acc: 0.507295. Batch_loss: 1.367720 \n",
      "Batch: 3615. Acc: 0.517995. Loss: 1.335508. Batch_acc: 0.515643. Batch_loss: 1.332787 \n",
      "Batch: 3616. Acc: 0.517999. Loss: 1.335503. Batch_acc: 0.531988. Batch_loss: 1.313849 \n",
      "Batch: 3617. Acc: 0.518000. Loss: 1.335500. Batch_acc: 0.522978. Batch_loss: 1.324682 \n",
      "Batch: 3618. Acc: 0.518004. Loss: 1.335490. Batch_acc: 0.530142. Batch_loss: 1.301002 \n",
      "Batch: 3619. Acc: 0.518007. Loss: 1.335481. Batch_acc: 0.532353. Batch_loss: 1.302417 \n",
      "Batch: 3620. Acc: 0.518005. Loss: 1.335491. Batch_acc: 0.507629. Batch_loss: 1.370681 \n",
      "Batch: 3621. Acc: 0.518008. Loss: 1.335487. Batch_acc: 0.531867. Batch_loss: 1.321527 \n",
      "Batch: 3622. Acc: 0.518013. Loss: 1.335471. Batch_acc: 0.536095. Batch_loss: 1.276253 \n",
      "Batch: 3623. Acc: 0.518015. Loss: 1.335460. Batch_acc: 0.524321. Batch_loss: 1.297324 \n",
      "Batch: 3624. Acc: 0.518017. Loss: 1.335451. Batch_acc: 0.525852. Batch_loss: 1.299316 \n",
      "Batch: 3625. Acc: 0.518017. Loss: 1.335450. Batch_acc: 0.516332. Batch_loss: 1.333541 \n",
      "Batch: 3626. Acc: 0.518025. Loss: 1.335425. Batch_acc: 0.546531. Batch_loss: 1.247027 \n",
      "Batch: 3627. Acc: 0.518027. Loss: 1.335418. Batch_acc: 0.524843. Batch_loss: 1.309421 \n",
      "Batch: 3628. Acc: 0.518033. Loss: 1.335399. Batch_acc: 0.541332. Batch_loss: 1.266740 \n",
      "Batch: 3629. Acc: 0.518034. Loss: 1.335395. Batch_acc: 0.522872. Batch_loss: 1.319401 \n",
      "Batch: 3630. Acc: 0.518045. Loss: 1.335364. Batch_acc: 0.556566. Batch_loss: 1.227097 \n",
      "Batch: 3631. Acc: 0.518050. Loss: 1.335357. Batch_acc: 0.533942. Batch_loss: 1.308770 \n",
      "Batch: 3632. Acc: 0.518051. Loss: 1.335345. Batch_acc: 0.521739. Batch_loss: 1.290037 \n",
      "Batch: 3633. Acc: 0.518057. Loss: 1.335326. Batch_acc: 0.542450. Batch_loss: 1.266924 \n",
      "Batch: 3634. Acc: 0.518062. Loss: 1.335316. Batch_acc: 0.536799. Batch_loss: 1.297967 \n",
      "Batch: 3635. Acc: 0.518065. Loss: 1.335312. Batch_acc: 0.527074. Batch_loss: 1.320661 \n",
      "Batch: 3636. Acc: 0.518065. Loss: 1.335315. Batch_acc: 0.519353. Batch_loss: 1.349015 \n",
      "Batch: 3637. Acc: 0.518070. Loss: 1.335295. Batch_acc: 0.536726. Batch_loss: 1.261582 \n",
      "Batch: 3638. Acc: 0.518074. Loss: 1.335284. Batch_acc: 0.532267. Batch_loss: 1.293818 \n",
      "Batch: 3639. Acc: 0.518074. Loss: 1.335281. Batch_acc: 0.518240. Batch_loss: 1.326751 \n",
      "Batch: 3640. Acc: 0.518080. Loss: 1.335263. Batch_acc: 0.538373. Batch_loss: 1.268490 \n",
      "Batch: 3641. Acc: 0.518082. Loss: 1.335251. Batch_acc: 0.526045. Batch_loss: 1.290370 \n",
      "Batch: 3642. Acc: 0.518084. Loss: 1.335236. Batch_acc: 0.524791. Batch_loss: 1.285691 \n",
      "Batch: 3643. Acc: 0.518090. Loss: 1.335215. Batch_acc: 0.541522. Batch_loss: 1.256336 \n",
      "Batch: 3644. Acc: 0.518088. Loss: 1.335227. Batch_acc: 0.507532. Batch_loss: 1.378838 \n",
      "Batch: 3645. Acc: 0.518083. Loss: 1.335238. Batch_acc: 0.499697. Batch_loss: 1.377462 \n",
      "Batch: 3646. Acc: 0.518087. Loss: 1.335232. Batch_acc: 0.534533. Batch_loss: 1.313134 \n",
      "Batch: 3647. Acc: 0.518091. Loss: 1.335218. Batch_acc: 0.532249. Batch_loss: 1.283068 \n",
      "Batch: 3648. Acc: 0.518093. Loss: 1.335218. Batch_acc: 0.526285. Batch_loss: 1.337760 \n",
      "Batch: 3649. Acc: 0.518097. Loss: 1.335205. Batch_acc: 0.531393. Batch_loss: 1.288768 \n",
      "Batch: 3650. Acc: 0.518098. Loss: 1.335203. Batch_acc: 0.521739. Batch_loss: 1.325533 \n",
      "Batch: 3651. Acc: 0.518098. Loss: 1.335203. Batch_acc: 0.519106. Batch_loss: 1.335903 \n",
      "Batch: 3652. Acc: 0.518102. Loss: 1.335194. Batch_acc: 0.530435. Batch_loss: 1.301844 \n",
      "Batch: 3653. Acc: 0.518104. Loss: 1.335188. Batch_acc: 0.527982. Batch_loss: 1.312956 \n",
      "Batch: 3654. Acc: 0.518105. Loss: 1.335182. Batch_acc: 0.519504. Batch_loss: 1.313673 \n",
      "Batch: 3655. Acc: 0.518113. Loss: 1.335168. Batch_acc: 0.549476. Batch_loss: 1.284717 \n",
      "Batch: 3656. Acc: 0.518119. Loss: 1.335160. Batch_acc: 0.538248. Batch_loss: 1.307407 \n",
      "Batch: 3657. Acc: 0.518120. Loss: 1.335161. Batch_acc: 0.521233. Batch_loss: 1.335447 \n",
      "Batch: 3658. Acc: 0.518123. Loss: 1.335151. Batch_acc: 0.530739. Batch_loss: 1.302107 \n",
      "Batch: 3659. Acc: 0.518124. Loss: 1.335149. Batch_acc: 0.520293. Batch_loss: 1.325893 \n",
      "Batch: 3660. Acc: 0.518134. Loss: 1.335128. Batch_acc: 0.556246. Batch_loss: 1.259861 \n",
      "Batch: 3661. Acc: 0.518142. Loss: 1.335112. Batch_acc: 0.543466. Batch_loss: 1.277545 \n",
      "Batch: 3662. Acc: 0.518148. Loss: 1.335104. Batch_acc: 0.540290. Batch_loss: 1.305600 \n",
      "Batch: 3663. Acc: 0.518154. Loss: 1.335087. Batch_acc: 0.542029. Batch_loss: 1.271849 \n",
      "Batch: 3664. Acc: 0.518158. Loss: 1.335077. Batch_acc: 0.533856. Batch_loss: 1.299319 \n",
      "Batch: 3665. Acc: 0.518162. Loss: 1.335067. Batch_acc: 0.530217. Batch_loss: 1.300168 \n",
      "Batch: 3666. Acc: 0.518158. Loss: 1.335077. Batch_acc: 0.504363. Batch_loss: 1.373852 \n",
      "Batch: 3667. Acc: 0.518155. Loss: 1.335089. Batch_acc: 0.505882. Batch_loss: 1.380211 \n",
      "Batch: 3668. Acc: 0.518156. Loss: 1.335083. Batch_acc: 0.521838. Batch_loss: 1.312797 \n",
      "Batch: 3669. Acc: 0.518155. Loss: 1.335083. Batch_acc: 0.513897. Batch_loss: 1.335652 \n",
      "Batch: 3670. Acc: 0.518152. Loss: 1.335093. Batch_acc: 0.509488. Batch_loss: 1.369426 \n",
      "Batch: 3671. Acc: 0.518153. Loss: 1.335092. Batch_acc: 0.520414. Batch_loss: 1.332230 \n",
      "Batch: 3672. Acc: 0.518155. Loss: 1.335085. Batch_acc: 0.525822. Batch_loss: 1.307240 \n",
      "Batch: 3673. Acc: 0.518158. Loss: 1.335081. Batch_acc: 0.530312. Batch_loss: 1.322570 \n",
      "Batch: 3674. Acc: 0.518164. Loss: 1.335073. Batch_acc: 0.539181. Batch_loss: 1.304075 \n",
      "Batch: 3675. Acc: 0.518174. Loss: 1.335048. Batch_acc: 0.556825. Batch_loss: 1.242969 \n",
      "Batch: 3676. Acc: 0.518178. Loss: 1.335036. Batch_acc: 0.530999. Batch_loss: 1.291515 \n",
      "Batch: 3677. Acc: 0.518177. Loss: 1.335032. Batch_acc: 0.516628. Batch_loss: 1.322320 \n",
      "Batch: 3678. Acc: 0.518176. Loss: 1.335034. Batch_acc: 0.512014. Batch_loss: 1.339250 \n",
      "Batch: 3679. Acc: 0.518179. Loss: 1.335021. Batch_acc: 0.531054. Batch_loss: 1.288586 \n",
      "Batch: 3680. Acc: 0.518182. Loss: 1.335007. Batch_acc: 0.527842. Batch_loss: 1.282328 \n",
      "Batch: 3681. Acc: 0.518191. Loss: 1.334981. Batch_acc: 0.552189. Batch_loss: 1.241677 \n",
      "Batch: 3682. Acc: 0.518199. Loss: 1.334970. Batch_acc: 0.544482. Batch_loss: 1.298509 \n",
      "Batch: 3683. Acc: 0.518204. Loss: 1.334954. Batch_acc: 0.537982. Batch_loss: 1.276618 \n",
      "Batch: 3684. Acc: 0.518202. Loss: 1.334961. Batch_acc: 0.508762. Batch_loss: 1.358643 \n",
      "Batch: 3685. Acc: 0.518207. Loss: 1.334949. Batch_acc: 0.536697. Batch_loss: 1.290440 \n",
      "Batch: 3686. Acc: 0.518210. Loss: 1.334944. Batch_acc: 0.531765. Batch_loss: 1.316772 \n",
      "Batch: 3687. Acc: 0.518212. Loss: 1.334938. Batch_acc: 0.523262. Batch_loss: 1.312077 \n",
      "Batch: 3688. Acc: 0.518218. Loss: 1.334921. Batch_acc: 0.540863. Batch_loss: 1.273173 \n",
      "Batch: 3689. Acc: 0.518218. Loss: 1.334921. Batch_acc: 0.520262. Batch_loss: 1.335022 \n",
      "Batch: 3690. Acc: 0.518228. Loss: 1.334904. Batch_acc: 0.553353. Batch_loss: 1.272906 \n",
      "Batch: 3691. Acc: 0.518236. Loss: 1.334880. Batch_acc: 0.547687. Batch_loss: 1.248049 \n",
      "Batch: 3692. Acc: 0.518240. Loss: 1.334866. Batch_acc: 0.535882. Batch_loss: 1.278736 \n",
      "Batch: 3693. Acc: 0.518247. Loss: 1.334865. Batch_acc: 0.543644. Batch_loss: 1.332145 \n",
      "Batch: 3694. Acc: 0.518250. Loss: 1.334856. Batch_acc: 0.529241. Batch_loss: 1.301883 \n",
      "Batch: 3695. Acc: 0.518253. Loss: 1.334841. Batch_acc: 0.526816. Batch_loss: 1.282119 \n",
      "Batch: 3696. Acc: 0.518259. Loss: 1.334821. Batch_acc: 0.541980. Batch_loss: 1.258692 \n",
      "Batch: 3697. Acc: 0.518265. Loss: 1.334804. Batch_acc: 0.539171. Batch_loss: 1.272148 \n",
      "Batch: 3698. Acc: 0.518271. Loss: 1.334785. Batch_acc: 0.542759. Batch_loss: 1.266627 \n",
      "Batch: 3699. Acc: 0.518276. Loss: 1.334777. Batch_acc: 0.538008. Batch_loss: 1.305148 \n",
      "Batch: 3700. Acc: 0.518278. Loss: 1.334773. Batch_acc: 0.523615. Batch_loss: 1.316875 \n",
      "Batch: 3701. Acc: 0.518281. Loss: 1.334766. Batch_acc: 0.529412. Batch_loss: 1.309231 \n",
      "Batch: 3702. Acc: 0.518285. Loss: 1.334747. Batch_acc: 0.532602. Batch_loss: 1.266146 \n",
      "Batch: 3703. Acc: 0.518293. Loss: 1.334730. Batch_acc: 0.546946. Batch_loss: 1.273163 \n",
      "Batch: 3704. Acc: 0.518301. Loss: 1.334704. Batch_acc: 0.548315. Batch_loss: 1.237931 \n",
      "Batch: 3705. Acc: 0.518306. Loss: 1.334685. Batch_acc: 0.536697. Batch_loss: 1.263749 \n",
      "Batch: 3706. Acc: 0.518312. Loss: 1.334665. Batch_acc: 0.542072. Batch_loss: 1.263229 \n",
      "Batch: 3707. Acc: 0.518320. Loss: 1.334642. Batch_acc: 0.546697. Batch_loss: 1.250385 \n",
      "Batch: 3708. Acc: 0.518331. Loss: 1.334620. Batch_acc: 0.558874. Batch_loss: 1.251062 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3709. Acc: 0.518332. Loss: 1.334611. Batch_acc: 0.521008. Batch_loss: 1.305085 \n",
      "Batch: 3710. Acc: 0.518337. Loss: 1.334603. Batch_acc: 0.536338. Batch_loss: 1.302538 \n",
      "Batch: 3711. Acc: 0.518344. Loss: 1.334584. Batch_acc: 0.545991. Batch_loss: 1.265433 \n",
      "Batch: 3712. Acc: 0.518347. Loss: 1.334574. Batch_acc: 0.530149. Batch_loss: 1.296107 \n",
      "Batch: 3713. Acc: 0.518349. Loss: 1.334567. Batch_acc: 0.526104. Batch_loss: 1.306749 \n",
      "Batch: 3714. Acc: 0.518352. Loss: 1.334558. Batch_acc: 0.529686. Batch_loss: 1.299314 \n",
      "Batch: 3715. Acc: 0.518358. Loss: 1.334546. Batch_acc: 0.539288. Batch_loss: 1.291062 \n",
      "Batch: 3716. Acc: 0.518361. Loss: 1.334534. Batch_acc: 0.531087. Batch_loss: 1.288833 \n",
      "Batch: 3717. Acc: 0.518370. Loss: 1.334512. Batch_acc: 0.552095. Batch_loss: 1.255830 \n",
      "Batch: 3718. Acc: 0.518372. Loss: 1.334517. Batch_acc: 0.523669. Batch_loss: 1.354175 \n",
      "Batch: 3719. Acc: 0.518372. Loss: 1.334515. Batch_acc: 0.519569. Batch_loss: 1.325235 \n",
      "Batch: 3720. Acc: 0.518374. Loss: 1.334513. Batch_acc: 0.524439. Batch_loss: 1.328100 \n",
      "Batch: 3721. Acc: 0.518372. Loss: 1.334519. Batch_acc: 0.510983. Batch_loss: 1.358606 \n",
      "Batch: 3722. Acc: 0.518380. Loss: 1.334496. Batch_acc: 0.547421. Batch_loss: 1.252076 \n",
      "Batch: 3723. Acc: 0.518379. Loss: 1.334494. Batch_acc: 0.516224. Batch_loss: 1.326950 \n",
      "Batch: 3724. Acc: 0.518378. Loss: 1.334494. Batch_acc: 0.513466. Batch_loss: 1.333013 \n",
      "Batch: 3725. Acc: 0.518377. Loss: 1.334494. Batch_acc: 0.512746. Batch_loss: 1.334660 \n",
      "Batch: 3726. Acc: 0.518385. Loss: 1.334466. Batch_acc: 0.549097. Batch_loss: 1.232785 \n",
      "Batch: 3727. Acc: 0.518394. Loss: 1.334455. Batch_acc: 0.552601. Batch_loss: 1.291169 \n",
      "Batch: 3728. Acc: 0.518394. Loss: 1.334455. Batch_acc: 0.516637. Batch_loss: 1.335407 \n",
      "Batch: 3729. Acc: 0.518393. Loss: 1.334453. Batch_acc: 0.517826. Batch_loss: 1.326818 \n",
      "Batch: 3730. Acc: 0.518396. Loss: 1.334450. Batch_acc: 0.527366. Batch_loss: 1.324739 \n",
      "Batch: 3731. Acc: 0.518408. Loss: 1.334413. Batch_acc: 0.561345. Batch_loss: 1.199734 \n",
      "Batch: 3732. Acc: 0.518418. Loss: 1.334384. Batch_acc: 0.559503. Batch_loss: 1.223852 \n",
      "Batch: 3733. Acc: 0.518418. Loss: 1.334389. Batch_acc: 0.518171. Batch_loss: 1.350520 \n",
      "Batch: 3734. Acc: 0.518425. Loss: 1.334371. Batch_acc: 0.543343. Batch_loss: 1.268277 \n",
      "Batch: 3735. Acc: 0.518430. Loss: 1.334360. Batch_acc: 0.538148. Batch_loss: 1.291951 \n",
      "Batch: 3736. Acc: 0.518428. Loss: 1.334355. Batch_acc: 0.510590. Batch_loss: 1.317414 \n",
      "Batch: 3737. Acc: 0.518430. Loss: 1.334352. Batch_acc: 0.523560. Batch_loss: 1.322855 \n",
      "Batch: 3738. Acc: 0.518437. Loss: 1.334331. Batch_acc: 0.546734. Batch_loss: 1.258344 \n",
      "Batch: 3739. Acc: 0.518441. Loss: 1.334324. Batch_acc: 0.530792. Batch_loss: 1.305933 \n",
      "Batch: 3740. Acc: 0.518451. Loss: 1.334299. Batch_acc: 0.558754. Batch_loss: 1.240190 \n",
      "Batch: 3741. Acc: 0.518458. Loss: 1.334282. Batch_acc: 0.543575. Batch_loss: 1.273002 \n",
      "Batch: 3742. Acc: 0.518462. Loss: 1.334274. Batch_acc: 0.532078. Batch_loss: 1.303877 \n",
      "Batch: 3743. Acc: 0.518462. Loss: 1.334270. Batch_acc: 0.521368. Batch_loss: 1.319588 \n",
      "Batch: 3744. Acc: 0.518468. Loss: 1.334263. Batch_acc: 0.538062. Batch_loss: 1.306451 \n",
      "Batch: 3745. Acc: 0.518478. Loss: 1.334236. Batch_acc: 0.557648. Batch_loss: 1.234845 \n",
      "Batch: 3746. Acc: 0.518485. Loss: 1.334221. Batch_acc: 0.544980. Batch_loss: 1.275318 \n",
      "Batch: 3747. Acc: 0.518483. Loss: 1.334221. Batch_acc: 0.511726. Batch_loss: 1.335460 \n",
      "Batch: 3748. Acc: 0.518486. Loss: 1.334211. Batch_acc: 0.529059. Batch_loss: 1.296320 \n",
      "Batch: 3749. Acc: 0.518489. Loss: 1.334199. Batch_acc: 0.528419. Batch_loss: 1.288402 \n",
      "Batch: 3750. Acc: 0.518497. Loss: 1.334183. Batch_acc: 0.549232. Batch_loss: 1.275699 \n",
      "Batch: 3751. Acc: 0.518505. Loss: 1.334164. Batch_acc: 0.549031. Batch_loss: 1.264068 \n",
      "Batch: 3752. Acc: 0.518509. Loss: 1.334155. Batch_acc: 0.533296. Batch_loss: 1.300614 \n",
      "Batch: 3753. Acc: 0.518512. Loss: 1.334147. Batch_acc: 0.527409. Batch_loss: 1.305363 \n",
      "Batch: 3754. Acc: 0.518517. Loss: 1.334127. Batch_acc: 0.537659. Batch_loss: 1.258597 \n",
      "Batch: 3755. Acc: 0.518518. Loss: 1.334123. Batch_acc: 0.522327. Batch_loss: 1.317544 \n",
      "Batch: 3756. Acc: 0.518524. Loss: 1.334108. Batch_acc: 0.541833. Batch_loss: 1.278494 \n",
      "Batch: 3757. Acc: 0.518530. Loss: 1.334091. Batch_acc: 0.541737. Batch_loss: 1.270805 \n",
      "Batch: 3758. Acc: 0.518535. Loss: 1.334076. Batch_acc: 0.536515. Batch_loss: 1.278218 \n",
      "Batch: 3759. Acc: 0.518532. Loss: 1.334077. Batch_acc: 0.507728. Batch_loss: 1.338539 \n",
      "Batch: 3760. Acc: 0.518533. Loss: 1.334069. Batch_acc: 0.519976. Batch_loss: 1.304475 \n",
      "Batch: 3761. Acc: 0.518533. Loss: 1.334060. Batch_acc: 0.520846. Batch_loss: 1.299621 \n",
      "Batch: 3762. Acc: 0.518529. Loss: 1.334069. Batch_acc: 0.502884. Batch_loss: 1.366215 \n",
      "Batch: 3763. Acc: 0.518537. Loss: 1.334046. Batch_acc: 0.549147. Batch_loss: 1.244507 \n",
      "Batch: 3764. Acc: 0.518535. Loss: 1.334048. Batch_acc: 0.509164. Batch_loss: 1.341829 \n",
      "Batch: 3765. Acc: 0.518537. Loss: 1.334038. Batch_acc: 0.527844. Batch_loss: 1.295432 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.5185369373288213. Loss per char: 1.3340378033821718. Time: 1627220992.4235327\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 18, 17, 17, 26, 20, 21, 24, 22,\n",
      "        20, 15, 21, 20,  1, 81, 77, 86, 84,  1, 18, 20, 22, 17, 26, 23, 32,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.518537. Loss: 1.334035. Batch_acc: 0.520161. Batch_loss: 1.322108 \n",
      "Batch: 3767. Acc: 0.518541. Loss: 1.334029. Batch_acc: 0.530460. Batch_loss: 1.311714 \n",
      "Batch: 3768. Acc: 0.518543. Loss: 1.334021. Batch_acc: 0.526285. Batch_loss: 1.304193 \n",
      "Batch: 3769. Acc: 0.518550. Loss: 1.333996. Batch_acc: 0.545151. Batch_loss: 1.242411 \n",
      "Batch: 3770. Acc: 0.518554. Loss: 1.333983. Batch_acc: 0.534911. Batch_loss: 1.283916 \n",
      "Batch: 3771. Acc: 0.518557. Loss: 1.333973. Batch_acc: 0.529745. Batch_loss: 1.295720 \n",
      "Batch: 3772. Acc: 0.518566. Loss: 1.333949. Batch_acc: 0.552954. Batch_loss: 1.247775 \n",
      "Batch: 3773. Acc: 0.518565. Loss: 1.333951. Batch_acc: 0.512421. Batch_loss: 1.340988 \n",
      "Batch: 3774. Acc: 0.518564. Loss: 1.333951. Batch_acc: 0.516894. Batch_loss: 1.334307 \n",
      "Batch: 3775. Acc: 0.518561. Loss: 1.333951. Batch_acc: 0.506636. Batch_loss: 1.333000 \n",
      "Batch: 3776. Acc: 0.518567. Loss: 1.333935. Batch_acc: 0.538287. Batch_loss: 1.273650 \n",
      "Batch: 3777. Acc: 0.518571. Loss: 1.333918. Batch_acc: 0.536543. Batch_loss: 1.269052 \n",
      "Batch: 3778. Acc: 0.518572. Loss: 1.333907. Batch_acc: 0.522831. Batch_loss: 1.295319 \n",
      "Batch: 3779. Acc: 0.518573. Loss: 1.333904. Batch_acc: 0.521408. Batch_loss: 1.320630 \n",
      "Batch: 3780. Acc: 0.518578. Loss: 1.333890. Batch_acc: 0.538551. Batch_loss: 1.279838 \n",
      "Batch: 3781. Acc: 0.518581. Loss: 1.333886. Batch_acc: 0.530470. Batch_loss: 1.321134 \n",
      "Batch: 3782. Acc: 0.518589. Loss: 1.333877. Batch_acc: 0.545091. Batch_loss: 1.299966 \n",
      "Batch: 3783. Acc: 0.518591. Loss: 1.333872. Batch_acc: 0.526587. Batch_loss: 1.312466 \n",
      "Batch: 3784. Acc: 0.518591. Loss: 1.333870. Batch_acc: 0.519132. Batch_loss: 1.326328 \n",
      "Batch: 3785. Acc: 0.518601. Loss: 1.333850. Batch_acc: 0.556701. Batch_loss: 1.259987 \n",
      "Batch: 3786. Acc: 0.518611. Loss: 1.333829. Batch_acc: 0.555302. Batch_loss: 1.253369 \n",
      "Batch: 3787. Acc: 0.518613. Loss: 1.333822. Batch_acc: 0.526134. Batch_loss: 1.308621 \n",
      "Batch: 3788. Acc: 0.518620. Loss: 1.333806. Batch_acc: 0.547301. Batch_loss: 1.271627 \n",
      "Batch: 3789. Acc: 0.518634. Loss: 1.333780. Batch_acc: 0.573178. Batch_loss: 1.233968 \n",
      "Batch: 3790. Acc: 0.518638. Loss: 1.333777. Batch_acc: 0.533060. Batch_loss: 1.322466 \n",
      "Batch: 3791. Acc: 0.518643. Loss: 1.333764. Batch_acc: 0.536700. Batch_loss: 1.283926 \n",
      "Batch: 3792. Acc: 0.518639. Loss: 1.333768. Batch_acc: 0.505178. Batch_loss: 1.349657 \n",
      "Batch: 3793. Acc: 0.518640. Loss: 1.333769. Batch_acc: 0.520821. Batch_loss: 1.335550 \n",
      "Batch: 3794. Acc: 0.518642. Loss: 1.333766. Batch_acc: 0.525552. Batch_loss: 1.325350 \n",
      "Batch: 3795. Acc: 0.518644. Loss: 1.333754. Batch_acc: 0.528722. Batch_loss: 1.284724 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3796. Acc: 0.518651. Loss: 1.333735. Batch_acc: 0.545351. Batch_loss: 1.263585 \n",
      "Batch: 3797. Acc: 0.518658. Loss: 1.333714. Batch_acc: 0.542019. Batch_loss: 1.257216 \n",
      "Batch: 3798. Acc: 0.518665. Loss: 1.333691. Batch_acc: 0.545297. Batch_loss: 1.246119 \n",
      "Batch: 3799. Acc: 0.518665. Loss: 1.333694. Batch_acc: 0.519671. Batch_loss: 1.343867 \n",
      "Batch: 3800. Acc: 0.518670. Loss: 1.333684. Batch_acc: 0.539397. Batch_loss: 1.294144 \n",
      "Batch: 3801. Acc: 0.518672. Loss: 1.333676. Batch_acc: 0.526617. Batch_loss: 1.303557 \n",
      "Batch: 3802. Acc: 0.518679. Loss: 1.333661. Batch_acc: 0.544230. Batch_loss: 1.276846 \n",
      "Batch: 3803. Acc: 0.518682. Loss: 1.333655. Batch_acc: 0.530045. Batch_loss: 1.311269 \n",
      "Batch: 3804. Acc: 0.518684. Loss: 1.333645. Batch_acc: 0.526225. Batch_loss: 1.293239 \n",
      "Batch: 3805. Acc: 0.518681. Loss: 1.333648. Batch_acc: 0.509070. Batch_loss: 1.347174 \n",
      "Batch: 3806. Acc: 0.518679. Loss: 1.333645. Batch_acc: 0.510502. Batch_loss: 1.322280 \n",
      "Batch: 3807. Acc: 0.518689. Loss: 1.333620. Batch_acc: 0.556587. Batch_loss: 1.237974 \n",
      "Batch: 3808. Acc: 0.518687. Loss: 1.333627. Batch_acc: 0.510349. Batch_loss: 1.358792 \n",
      "Batch: 3809. Acc: 0.518687. Loss: 1.333632. Batch_acc: 0.518784. Batch_loss: 1.353547 \n",
      "Batch: 3810. Acc: 0.518691. Loss: 1.333618. Batch_acc: 0.534857. Batch_loss: 1.280273 \n",
      "Batch: 3811. Acc: 0.518700. Loss: 1.333603. Batch_acc: 0.549885. Batch_loss: 1.277886 \n",
      "Batch: 3812. Acc: 0.518710. Loss: 1.333579. Batch_acc: 0.557377. Batch_loss: 1.243370 \n",
      "Batch: 3813. Acc: 0.518718. Loss: 1.333563. Batch_acc: 0.548801. Batch_loss: 1.273986 \n",
      "Batch: 3814. Acc: 0.518725. Loss: 1.333544. Batch_acc: 0.544793. Batch_loss: 1.264821 \n",
      "Batch: 3815. Acc: 0.518729. Loss: 1.333536. Batch_acc: 0.535325. Batch_loss: 1.303386 \n",
      "Batch: 3816. Acc: 0.518726. Loss: 1.333542. Batch_acc: 0.507345. Batch_loss: 1.352957 \n",
      "Batch: 3817. Acc: 0.518726. Loss: 1.333538. Batch_acc: 0.515979. Batch_loss: 1.318223 \n",
      "Batch: 3818. Acc: 0.518731. Loss: 1.333526. Batch_acc: 0.540946. Batch_loss: 1.290371 \n",
      "Batch: 3819. Acc: 0.518740. Loss: 1.333506. Batch_acc: 0.553057. Batch_loss: 1.254185 \n",
      "Batch: 3820. Acc: 0.518740. Loss: 1.333514. Batch_acc: 0.515698. Batch_loss: 1.364558 \n",
      "Batch: 3821. Acc: 0.518741. Loss: 1.333520. Batch_acc: 0.523148. Batch_loss: 1.357767 \n",
      "Batch: 3822. Acc: 0.518749. Loss: 1.333499. Batch_acc: 0.551186. Batch_loss: 1.252404 \n",
      "Batch: 3823. Acc: 0.518755. Loss: 1.333488. Batch_acc: 0.540217. Batch_loss: 1.292722 \n",
      "Batch: 3824. Acc: 0.518755. Loss: 1.333477. Batch_acc: 0.520334. Batch_loss: 1.293925 \n",
      "Batch: 3825. Acc: 0.518766. Loss: 1.333450. Batch_acc: 0.561089. Batch_loss: 1.226131 \n",
      "Batch: 3826. Acc: 0.518777. Loss: 1.333423. Batch_acc: 0.559752. Batch_loss: 1.233938 \n",
      "Batch: 3827. Acc: 0.518785. Loss: 1.333397. Batch_acc: 0.549042. Batch_loss: 1.235568 \n",
      "Batch: 3828. Acc: 0.518784. Loss: 1.333397. Batch_acc: 0.513905. Batch_loss: 1.332573 \n",
      "Batch: 3829. Acc: 0.518789. Loss: 1.333388. Batch_acc: 0.539527. Batch_loss: 1.298834 \n",
      "Batch: 3830. Acc: 0.518791. Loss: 1.333387. Batch_acc: 0.524249. Batch_loss: 1.329372 \n",
      "Batch: 3831. Acc: 0.518796. Loss: 1.333374. Batch_acc: 0.537685. Batch_loss: 1.281832 \n",
      "Batch: 3832. Acc: 0.518799. Loss: 1.333365. Batch_acc: 0.531123. Batch_loss: 1.297942 \n",
      "Batch: 3833. Acc: 0.518804. Loss: 1.333353. Batch_acc: 0.540541. Batch_loss: 1.286405 \n",
      "Batch: 3834. Acc: 0.518803. Loss: 1.333350. Batch_acc: 0.515482. Batch_loss: 1.322424 \n",
      "Batch: 3835. Acc: 0.518802. Loss: 1.333350. Batch_acc: 0.513857. Batch_loss: 1.334175 \n",
      "Batch: 3836. Acc: 0.518802. Loss: 1.333345. Batch_acc: 0.518540. Batch_loss: 1.313012 \n",
      "Batch: 3837. Acc: 0.518800. Loss: 1.333351. Batch_acc: 0.508813. Batch_loss: 1.357183 \n",
      "Batch: 3838. Acc: 0.518805. Loss: 1.333340. Batch_acc: 0.540401. Batch_loss: 1.293175 \n",
      "Batch: 3839. Acc: 0.518808. Loss: 1.333328. Batch_acc: 0.531250. Batch_loss: 1.285741 \n",
      "Batch: 3840. Acc: 0.518809. Loss: 1.333326. Batch_acc: 0.519406. Batch_loss: 1.326666 \n",
      "Batch: 3841. Acc: 0.518808. Loss: 1.333327. Batch_acc: 0.515134. Batch_loss: 1.334287 \n",
      "Batch: 3842. Acc: 0.518809. Loss: 1.333317. Batch_acc: 0.522423. Batch_loss: 1.298067 \n",
      "Batch: 3843. Acc: 0.518816. Loss: 1.333299. Batch_acc: 0.547290. Batch_loss: 1.260276 \n",
      "Batch: 3844. Acc: 0.518817. Loss: 1.333291. Batch_acc: 0.522013. Batch_loss: 1.306450 \n",
      "Batch: 3845. Acc: 0.518824. Loss: 1.333272. Batch_acc: 0.545249. Batch_loss: 1.259133 \n",
      "Batch: 3846. Acc: 0.518819. Loss: 1.333276. Batch_acc: 0.499411. Batch_loss: 1.350446 \n",
      "Batch: 3847. Acc: 0.518822. Loss: 1.333267. Batch_acc: 0.532194. Batch_loss: 1.298142 \n",
      "Batch: 3848. Acc: 0.518818. Loss: 1.333282. Batch_acc: 0.503249. Batch_loss: 1.394252 \n",
      "Batch: 3849. Acc: 0.518822. Loss: 1.333270. Batch_acc: 0.531542. Batch_loss: 1.283974 \n",
      "Batch: 3850. Acc: 0.518828. Loss: 1.333254. Batch_acc: 0.545035. Batch_loss: 1.270582 \n",
      "Batch: 3851. Acc: 0.518834. Loss: 1.333229. Batch_acc: 0.540023. Batch_loss: 1.239291 \n",
      "Batch: 3852. Acc: 0.518840. Loss: 1.333219. Batch_acc: 0.541667. Batch_loss: 1.292126 \n",
      "Batch: 3853. Acc: 0.518849. Loss: 1.333201. Batch_acc: 0.552799. Batch_loss: 1.266295 \n",
      "Batch: 3854. Acc: 0.518848. Loss: 1.333205. Batch_acc: 0.516695. Batch_loss: 1.345439 \n",
      "Batch: 3855. Acc: 0.518841. Loss: 1.333214. Batch_acc: 0.490952. Batch_loss: 1.371813 \n",
      "Batch: 3856. Acc: 0.518840. Loss: 1.333223. Batch_acc: 0.514656. Batch_loss: 1.365920 \n",
      "Batch: 3857. Acc: 0.518845. Loss: 1.333207. Batch_acc: 0.540070. Batch_loss: 1.271278 \n",
      "Batch: 3858. Acc: 0.518845. Loss: 1.333210. Batch_acc: 0.516037. Batch_loss: 1.343469 \n",
      "Batch: 3859. Acc: 0.518851. Loss: 1.333199. Batch_acc: 0.543991. Batch_loss: 1.291660 \n",
      "Batch: 3860. Acc: 0.518856. Loss: 1.333186. Batch_acc: 0.537858. Batch_loss: 1.283016 \n",
      "Batch: 3861. Acc: 0.518858. Loss: 1.333175. Batch_acc: 0.527466. Batch_loss: 1.292955 \n",
      "Batch: 3862. Acc: 0.518862. Loss: 1.333166. Batch_acc: 0.532773. Batch_loss: 1.298750 \n",
      "Batch: 3863. Acc: 0.518863. Loss: 1.333167. Batch_acc: 0.523919. Batch_loss: 1.338885 \n",
      "Batch: 3864. Acc: 0.518866. Loss: 1.333156. Batch_acc: 0.528563. Batch_loss: 1.286938 \n",
      "Batch: 3865. Acc: 0.518865. Loss: 1.333152. Batch_acc: 0.515380. Batch_loss: 1.321096 \n",
      "Batch: 3866. Acc: 0.518867. Loss: 1.333144. Batch_acc: 0.527168. Batch_loss: 1.300808 \n",
      "Batch: 3867. Acc: 0.518870. Loss: 1.333137. Batch_acc: 0.530519. Batch_loss: 1.307403 \n",
      "Batch: 3868. Acc: 0.518871. Loss: 1.333125. Batch_acc: 0.522925. Batch_loss: 1.283698 \n",
      "Batch: 3869. Acc: 0.518876. Loss: 1.333109. Batch_acc: 0.536141. Batch_loss: 1.272155 \n",
      "Batch: 3870. Acc: 0.518881. Loss: 1.333095. Batch_acc: 0.538287. Batch_loss: 1.279124 \n",
      "Batch: 3871. Acc: 0.518880. Loss: 1.333101. Batch_acc: 0.515796. Batch_loss: 1.356037 \n",
      "Batch: 3872. Acc: 0.518873. Loss: 1.333114. Batch_acc: 0.491369. Batch_loss: 1.384503 \n",
      "Batch: 3873. Acc: 0.518874. Loss: 1.333113. Batch_acc: 0.524432. Batch_loss: 1.329033 \n",
      "Batch: 3874. Acc: 0.518882. Loss: 1.333096. Batch_acc: 0.549508. Batch_loss: 1.267342 \n",
      "Batch: 3875. Acc: 0.518876. Loss: 1.333108. Batch_acc: 0.494179. Batch_loss: 1.382216 \n",
      "Batch: 3876. Acc: 0.518875. Loss: 1.333107. Batch_acc: 0.515341. Batch_loss: 1.325837 \n",
      "Batch: 3877. Acc: 0.518883. Loss: 1.333086. Batch_acc: 0.549915. Batch_loss: 1.255921 \n",
      "Batch: 3878. Acc: 0.518890. Loss: 1.333075. Batch_acc: 0.542857. Batch_loss: 1.289783 \n",
      "Batch: 3879. Acc: 0.518899. Loss: 1.333058. Batch_acc: 0.556447. Batch_loss: 1.268164 \n",
      "Batch: 3880. Acc: 0.518900. Loss: 1.333048. Batch_acc: 0.520965. Batch_loss: 1.295519 \n",
      "Batch: 3881. Acc: 0.518907. Loss: 1.333029. Batch_acc: 0.546427. Batch_loss: 1.259598 \n",
      "Batch: 3882. Acc: 0.518912. Loss: 1.333024. Batch_acc: 0.538680. Batch_loss: 1.312315 \n",
      "Batch: 3883. Acc: 0.518916. Loss: 1.333017. Batch_acc: 0.532544. Batch_loss: 1.305688 \n",
      "Batch: 3884. Acc: 0.518920. Loss: 1.333006. Batch_acc: 0.536041. Batch_loss: 1.290561 \n",
      "Batch: 3885. Acc: 0.518920. Loss: 1.333007. Batch_acc: 0.520710. Batch_loss: 1.339789 \n",
      "Batch: 3886. Acc: 0.518924. Loss: 1.332997. Batch_acc: 0.534137. Batch_loss: 1.291711 \n",
      "Batch: 3887. Acc: 0.518924. Loss: 1.332994. Batch_acc: 0.517181. Batch_loss: 1.323680 \n",
      "Batch: 3888. Acc: 0.518920. Loss: 1.333008. Batch_acc: 0.502062. Batch_loss: 1.387451 \n",
      "Batch: 3889. Acc: 0.518924. Loss: 1.332991. Batch_acc: 0.536836. Batch_loss: 1.267662 \n",
      "Batch: 3890. Acc: 0.518930. Loss: 1.332983. Batch_acc: 0.539377. Batch_loss: 1.300090 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3891. Acc: 0.518936. Loss: 1.332967. Batch_acc: 0.544339. Batch_loss: 1.273127 \n",
      "Batch: 3892. Acc: 0.518937. Loss: 1.332965. Batch_acc: 0.523041. Batch_loss: 1.324704 \n",
      "Batch: 3893. Acc: 0.518937. Loss: 1.332965. Batch_acc: 0.516263. Batch_loss: 1.334575 \n",
      "Batch: 3894. Acc: 0.518940. Loss: 1.332957. Batch_acc: 0.531456. Batch_loss: 1.301514 \n",
      "Batch: 3895. Acc: 0.518945. Loss: 1.332934. Batch_acc: 0.537975. Batch_loss: 1.240528 \n",
      "Batch: 3896. Acc: 0.518947. Loss: 1.332930. Batch_acc: 0.526406. Batch_loss: 1.317772 \n",
      "Batch: 3897. Acc: 0.518951. Loss: 1.332906. Batch_acc: 0.537185. Batch_loss: 1.242395 \n",
      "Batch: 3898. Acc: 0.518950. Loss: 1.332912. Batch_acc: 0.515398. Batch_loss: 1.353558 \n",
      "Batch: 3899. Acc: 0.518953. Loss: 1.332900. Batch_acc: 0.530364. Batch_loss: 1.289454 \n",
      "Batch: 3900. Acc: 0.518954. Loss: 1.332898. Batch_acc: 0.520540. Batch_loss: 1.321823 \n",
      "Batch: 3901. Acc: 0.518954. Loss: 1.332896. Batch_acc: 0.519253. Batch_loss: 1.326576 \n",
      "Batch: 3902. Acc: 0.518952. Loss: 1.332897. Batch_acc: 0.510966. Batch_loss: 1.339028 \n",
      "Batch: 3903. Acc: 0.518965. Loss: 1.332868. Batch_acc: 0.569318. Batch_loss: 1.220171 \n",
      "Batch: 3904. Acc: 0.518967. Loss: 1.332858. Batch_acc: 0.526624. Batch_loss: 1.294017 \n",
      "Batch: 3905. Acc: 0.518968. Loss: 1.332856. Batch_acc: 0.524942. Batch_loss: 1.321672 \n",
      "Batch: 3906. Acc: 0.518970. Loss: 1.332841. Batch_acc: 0.524775. Batch_loss: 1.278308 \n",
      "Batch: 3907. Acc: 0.518972. Loss: 1.332825. Batch_acc: 0.527982. Batch_loss: 1.268995 \n",
      "Batch: 3908. Acc: 0.518975. Loss: 1.332824. Batch_acc: 0.528637. Batch_loss: 1.331656 \n",
      "Batch: 3909. Acc: 0.518981. Loss: 1.332805. Batch_acc: 0.542402. Batch_loss: 1.256804 \n",
      "Batch: 3910. Acc: 0.518983. Loss: 1.332796. Batch_acc: 0.527510. Batch_loss: 1.300211 \n",
      "Batch: 3911. Acc: 0.518987. Loss: 1.332784. Batch_acc: 0.536076. Batch_loss: 1.283760 \n",
      "Batch: 3912. Acc: 0.518986. Loss: 1.332777. Batch_acc: 0.515801. Batch_loss: 1.306287 \n",
      "Batch: 3913. Acc: 0.518988. Loss: 1.332770. Batch_acc: 0.524439. Batch_loss: 1.305703 \n",
      "Batch: 3914. Acc: 0.518990. Loss: 1.332758. Batch_acc: 0.527600. Batch_loss: 1.285298 \n",
      "Batch: 3915. Acc: 0.518992. Loss: 1.332753. Batch_acc: 0.525316. Batch_loss: 1.310270 \n",
      "Batch: 3916. Acc: 0.518984. Loss: 1.332765. Batch_acc: 0.488784. Batch_loss: 1.382795 \n",
      "Batch: 3917. Acc: 0.518989. Loss: 1.332744. Batch_acc: 0.539339. Batch_loss: 1.252375 \n",
      "Batch: 3918. Acc: 0.518990. Loss: 1.332737. Batch_acc: 0.523478. Batch_loss: 1.305121 \n",
      "Batch: 3919. Acc: 0.518995. Loss: 1.332727. Batch_acc: 0.535674. Batch_loss: 1.292453 \n",
      "Batch: 3920. Acc: 0.518996. Loss: 1.332717. Batch_acc: 0.525176. Batch_loss: 1.293361 \n",
      "Batch: 3921. Acc: 0.519004. Loss: 1.332696. Batch_acc: 0.547062. Batch_loss: 1.251884 \n",
      "Batch: 3922. Acc: 0.519010. Loss: 1.332684. Batch_acc: 0.543684. Batch_loss: 1.282396 \n",
      "Batch: 3923. Acc: 0.519016. Loss: 1.332666. Batch_acc: 0.544470. Batch_loss: 1.261598 \n",
      "Batch: 3924. Acc: 0.519012. Loss: 1.332674. Batch_acc: 0.501754. Batch_loss: 1.367714 \n",
      "Batch: 3925. Acc: 0.519019. Loss: 1.332659. Batch_acc: 0.548071. Batch_loss: 1.271252 \n",
      "Batch: 3926. Acc: 0.519022. Loss: 1.332651. Batch_acc: 0.529277. Batch_loss: 1.302990 \n",
      "Batch: 3927. Acc: 0.519023. Loss: 1.332649. Batch_acc: 0.523810. Batch_loss: 1.325143 \n",
      "Batch: 3928. Acc: 0.519024. Loss: 1.332646. Batch_acc: 0.522872. Batch_loss: 1.320526 \n",
      "Batch: 3929. Acc: 0.519030. Loss: 1.332636. Batch_acc: 0.540664. Batch_loss: 1.292669 \n",
      "Batch: 3930. Acc: 0.519035. Loss: 1.332622. Batch_acc: 0.541231. Batch_loss: 1.278908 \n",
      "Batch: 3931. Acc: 0.519045. Loss: 1.332605. Batch_acc: 0.555872. Batch_loss: 1.266147 \n",
      "Batch: 3932. Acc: 0.519046. Loss: 1.332605. Batch_acc: 0.525287. Batch_loss: 1.329834 \n",
      "Batch: 3933. Acc: 0.519050. Loss: 1.332594. Batch_acc: 0.534977. Batch_loss: 1.290032 \n",
      "Batch: 3934. Acc: 0.519048. Loss: 1.332594. Batch_acc: 0.510192. Batch_loss: 1.333715 \n",
      "Batch: 3935. Acc: 0.519053. Loss: 1.332585. Batch_acc: 0.539384. Batch_loss: 1.298140 \n",
      "Batch: 3936. Acc: 0.519049. Loss: 1.332584. Batch_acc: 0.503214. Batch_loss: 1.328572 \n",
      "Batch: 3937. Acc: 0.519053. Loss: 1.332570. Batch_acc: 0.533788. Batch_loss: 1.277797 \n",
      "Batch: 3938. Acc: 0.519055. Loss: 1.332570. Batch_acc: 0.526686. Batch_loss: 1.331029 \n",
      "Batch: 3939. Acc: 0.519054. Loss: 1.332564. Batch_acc: 0.516037. Batch_loss: 1.311697 \n",
      "Batch: 3940. Acc: 0.519060. Loss: 1.332544. Batch_acc: 0.542402. Batch_loss: 1.253267 \n",
      "Batch: 3941. Acc: 0.519062. Loss: 1.332534. Batch_acc: 0.525956. Batch_loss: 1.293853 \n",
      "Batch: 3942. Acc: 0.519063. Loss: 1.332530. Batch_acc: 0.524654. Batch_loss: 1.317183 \n",
      "Batch: 3943. Acc: 0.519069. Loss: 1.332518. Batch_acc: 0.540304. Batch_loss: 1.285303 \n",
      "Batch: 3944. Acc: 0.519069. Loss: 1.332512. Batch_acc: 0.521363. Batch_loss: 1.308531 \n",
      "Batch: 3945. Acc: 0.519077. Loss: 1.332486. Batch_acc: 0.550658. Batch_loss: 1.229692 \n",
      "Batch: 3946. Acc: 0.519080. Loss: 1.332484. Batch_acc: 0.530907. Batch_loss: 1.324786 \n",
      "Batch: 3947. Acc: 0.519084. Loss: 1.332477. Batch_acc: 0.533333. Batch_loss: 1.302417 \n",
      "Batch: 3948. Acc: 0.519085. Loss: 1.332473. Batch_acc: 0.521368. Batch_loss: 1.316995 \n",
      "Batch: 3949. Acc: 0.519090. Loss: 1.332463. Batch_acc: 0.542590. Batch_loss: 1.293579 \n",
      "Batch: 3950. Acc: 0.519095. Loss: 1.332451. Batch_acc: 0.538328. Batch_loss: 1.283633 \n",
      "Batch: 3951. Acc: 0.519099. Loss: 1.332443. Batch_acc: 0.533372. Batch_loss: 1.300572 \n",
      "Batch: 3952. Acc: 0.519099. Loss: 1.332441. Batch_acc: 0.519166. Batch_loss: 1.326508 \n",
      "Batch: 3953. Acc: 0.519103. Loss: 1.332431. Batch_acc: 0.537136. Batch_loss: 1.292888 \n",
      "Batch: 3954. Acc: 0.519103. Loss: 1.332432. Batch_acc: 0.516239. Batch_loss: 1.335168 \n",
      "Batch: 3955. Acc: 0.519106. Loss: 1.332420. Batch_acc: 0.533333. Batch_loss: 1.286360 \n",
      "Batch: 3956. Acc: 0.519108. Loss: 1.332417. Batch_acc: 0.526851. Batch_loss: 1.320516 \n",
      "Batch: 3957. Acc: 0.519116. Loss: 1.332409. Batch_acc: 0.549766. Batch_loss: 1.297117 \n",
      "Batch: 3958. Acc: 0.519123. Loss: 1.332398. Batch_acc: 0.546019. Batch_loss: 1.291832 \n",
      "Batch: 3959. Acc: 0.519129. Loss: 1.332383. Batch_acc: 0.544521. Batch_loss: 1.271506 \n",
      "Batch: 3960. Acc: 0.519136. Loss: 1.332366. Batch_acc: 0.544725. Batch_loss: 1.265714 \n",
      "Batch: 3961. Acc: 0.519147. Loss: 1.332341. Batch_acc: 0.562718. Batch_loss: 1.232689 \n",
      "Batch: 3962. Acc: 0.519156. Loss: 1.332318. Batch_acc: 0.556707. Batch_loss: 1.240780 \n",
      "Batch: 3963. Acc: 0.519157. Loss: 1.332313. Batch_acc: 0.522528. Batch_loss: 1.313228 \n",
      "Batch: 3964. Acc: 0.519169. Loss: 1.332283. Batch_acc: 0.565878. Batch_loss: 1.214922 \n",
      "Batch: 3965. Acc: 0.519177. Loss: 1.332262. Batch_acc: 0.551044. Batch_loss: 1.249307 \n",
      "Batch: 3966. Acc: 0.519192. Loss: 1.332233. Batch_acc: 0.576338. Batch_loss: 1.219290 \n",
      "Batch: 3967. Acc: 0.519198. Loss: 1.332217. Batch_acc: 0.545665. Batch_loss: 1.270349 \n",
      "Batch: 3968. Acc: 0.519201. Loss: 1.332215. Batch_acc: 0.528356. Batch_loss: 1.323915 \n",
      "Batch: 3969. Acc: 0.519199. Loss: 1.332223. Batch_acc: 0.515027. Batch_loss: 1.364307 \n",
      "Batch: 3970. Acc: 0.519200. Loss: 1.332222. Batch_acc: 0.522196. Batch_loss: 1.326227 \n",
      "Batch: 3971. Acc: 0.519200. Loss: 1.332219. Batch_acc: 0.517722. Batch_loss: 1.321790 \n",
      "Batch: 3972. Acc: 0.519202. Loss: 1.332215. Batch_acc: 0.528703. Batch_loss: 1.317400 \n",
      "Batch: 3973. Acc: 0.519216. Loss: 1.332186. Batch_acc: 0.571993. Batch_loss: 1.218055 \n",
      "Batch: 3974. Acc: 0.519222. Loss: 1.332174. Batch_acc: 0.542791. Batch_loss: 1.282780 \n",
      "Batch: 3975. Acc: 0.519226. Loss: 1.332162. Batch_acc: 0.537228. Batch_loss: 1.283755 \n",
      "Batch: 3976. Acc: 0.519225. Loss: 1.332167. Batch_acc: 0.515345. Batch_loss: 1.354239 \n",
      "Batch: 3977. Acc: 0.519233. Loss: 1.332156. Batch_acc: 0.547875. Batch_loss: 1.286945 \n",
      "Batch: 3978. Acc: 0.519236. Loss: 1.332149. Batch_acc: 0.532110. Batch_loss: 1.304793 \n",
      "Batch: 3979. Acc: 0.519236. Loss: 1.332150. Batch_acc: 0.521512. Batch_loss: 1.338538 \n",
      "Batch: 3980. Acc: 0.519249. Loss: 1.332123. Batch_acc: 0.567538. Batch_loss: 1.227469 \n",
      "Batch: 3981. Acc: 0.519252. Loss: 1.332118. Batch_acc: 0.529859. Batch_loss: 1.312801 \n",
      "Batch: 3982. Acc: 0.519255. Loss: 1.332110. Batch_acc: 0.533529. Batch_loss: 1.299158 \n",
      "Batch: 3983. Acc: 0.519256. Loss: 1.332111. Batch_acc: 0.522501. Batch_loss: 1.336082 \n",
      "Batch: 3984. Acc: 0.519266. Loss: 1.332082. Batch_acc: 0.560934. Batch_loss: 1.217811 \n",
      "Batch: 3985. Acc: 0.519268. Loss: 1.332084. Batch_acc: 0.526718. Batch_loss: 1.339228 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3986. Acc: 0.519279. Loss: 1.332061. Batch_acc: 0.563867. Batch_loss: 1.241131 \n",
      "Batch: 3987. Acc: 0.519286. Loss: 1.332037. Batch_acc: 0.547226. Batch_loss: 1.231467 \n",
      "Batch: 3988. Acc: 0.519286. Loss: 1.332040. Batch_acc: 0.517775. Batch_loss: 1.344683 \n",
      "Batch: 3989. Acc: 0.519297. Loss: 1.332012. Batch_acc: 0.563140. Batch_loss: 1.224354 \n",
      "Batch: 3990. Acc: 0.519304. Loss: 1.331988. Batch_acc: 0.547474. Batch_loss: 1.239163 \n",
      "Batch: 3991. Acc: 0.519307. Loss: 1.331986. Batch_acc: 0.531452. Batch_loss: 1.320685 \n",
      "Batch: 3992. Acc: 0.519308. Loss: 1.331980. Batch_acc: 0.523194. Batch_loss: 1.310823 \n",
      "Batch: 3993. Acc: 0.519318. Loss: 1.331963. Batch_acc: 0.557414. Batch_loss: 1.264305 \n",
      "Batch: 3994. Acc: 0.519325. Loss: 1.331948. Batch_acc: 0.547674. Batch_loss: 1.272717 \n",
      "Batch: 3995. Acc: 0.519327. Loss: 1.331947. Batch_acc: 0.526286. Batch_loss: 1.325420 \n",
      "Batch: 3996. Acc: 0.519327. Loss: 1.331946. Batch_acc: 0.519819. Batch_loss: 1.329098 \n",
      "Batch: 3997. Acc: 0.519331. Loss: 1.331931. Batch_acc: 0.534078. Batch_loss: 1.271611 \n",
      "Batch: 3998. Acc: 0.519336. Loss: 1.331921. Batch_acc: 0.540493. Batch_loss: 1.290659 \n",
      "Batch: 3999. Acc: 0.519344. Loss: 1.331901. Batch_acc: 0.549605. Batch_loss: 1.252654 \n",
      "Batch: 4000. Acc: 0.519352. Loss: 1.331877. Batch_acc: 0.551839. Batch_loss: 1.238852 \n",
      "Batch: 4001. Acc: 0.519352. Loss: 1.331875. Batch_acc: 0.520000. Batch_loss: 1.326833 \n",
      "Batch: 4002. Acc: 0.519351. Loss: 1.331871. Batch_acc: 0.513680. Batch_loss: 1.315315 \n",
      "Batch: 4003. Acc: 0.519351. Loss: 1.331868. Batch_acc: 0.520461. Batch_loss: 1.319445 \n",
      "Batch: 4004. Acc: 0.519354. Loss: 1.331864. Batch_acc: 0.532565. Batch_loss: 1.317475 \n",
      "Batch: 4005. Acc: 0.519358. Loss: 1.331851. Batch_acc: 0.533333. Batch_loss: 1.278568 \n",
      "Batch: 4006. Acc: 0.519362. Loss: 1.331843. Batch_acc: 0.535510. Batch_loss: 1.299495 \n",
      "Batch: 4007. Acc: 0.519365. Loss: 1.331837. Batch_acc: 0.531842. Batch_loss: 1.306842 \n",
      "Batch: 4008. Acc: 0.519362. Loss: 1.331845. Batch_acc: 0.507839. Batch_loss: 1.363492 \n",
      "Batch: 4009. Acc: 0.519356. Loss: 1.331856. Batch_acc: 0.494467. Batch_loss: 1.374572 \n",
      "Batch: 4010. Acc: 0.519361. Loss: 1.331841. Batch_acc: 0.538159. Batch_loss: 1.274732 \n",
      "Batch: 4011. Acc: 0.519372. Loss: 1.331814. Batch_acc: 0.567190. Batch_loss: 1.220584 \n",
      "Batch: 4012. Acc: 0.519369. Loss: 1.331813. Batch_acc: 0.507058. Batch_loss: 1.329806 \n",
      "Batch: 4013. Acc: 0.519371. Loss: 1.331804. Batch_acc: 0.524695. Batch_loss: 1.296508 \n",
      "Batch: 4014. Acc: 0.519375. Loss: 1.331797. Batch_acc: 0.537939. Batch_loss: 1.302164 \n",
      "Batch: 4015. Acc: 0.519379. Loss: 1.331778. Batch_acc: 0.536082. Batch_loss: 1.257690 \n",
      "Batch: 4016. Acc: 0.519387. Loss: 1.331760. Batch_acc: 0.547579. Batch_loss: 1.260258 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.5193866760410305. Loss per char: 1.3317599906057047. Time: 1627221198.121227\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 24, 26, 21, 20, 17, 24, 18, 25, 18,\n",
      "        17, 24,  1, 14,  1, 14, 23, 21, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.519391. Loss: 1.331749. Batch_acc: 0.536047. Batch_loss: 1.285782 \n",
      "Batch: 4018. Acc: 0.519396. Loss: 1.331744. Batch_acc: 0.539818. Batch_loss: 1.311840 \n",
      "Batch: 4019. Acc: 0.519401. Loss: 1.331740. Batch_acc: 0.540070. Batch_loss: 1.318777 \n",
      "Batch: 4020. Acc: 0.519406. Loss: 1.331723. Batch_acc: 0.539674. Batch_loss: 1.264979 \n",
      "Batch: 4021. Acc: 0.519413. Loss: 1.331707. Batch_acc: 0.548278. Batch_loss: 1.267148 \n",
      "Batch: 4022. Acc: 0.519416. Loss: 1.331694. Batch_acc: 0.530295. Batch_loss: 1.281883 \n",
      "Batch: 4023. Acc: 0.519423. Loss: 1.331674. Batch_acc: 0.547897. Batch_loss: 1.250371 \n",
      "Batch: 4024. Acc: 0.519422. Loss: 1.331668. Batch_acc: 0.513834. Batch_loss: 1.307304 \n",
      "Batch: 4025. Acc: 0.519422. Loss: 1.331658. Batch_acc: 0.520325. Batch_loss: 1.289622 \n",
      "Batch: 4026. Acc: 0.519429. Loss: 1.331640. Batch_acc: 0.548295. Batch_loss: 1.261516 \n",
      "Batch: 4027. Acc: 0.519437. Loss: 1.331626. Batch_acc: 0.551101. Batch_loss: 1.273882 \n",
      "Batch: 4028. Acc: 0.519433. Loss: 1.331626. Batch_acc: 0.501139. Batch_loss: 1.331763 \n",
      "Batch: 4029. Acc: 0.519434. Loss: 1.331622. Batch_acc: 0.525755. Batch_loss: 1.316412 \n",
      "Batch: 4030. Acc: 0.519435. Loss: 1.331621. Batch_acc: 0.520556. Batch_loss: 1.328263 \n",
      "Batch: 4031. Acc: 0.519440. Loss: 1.331609. Batch_acc: 0.541327. Batch_loss: 1.280035 \n",
      "Batch: 4032. Acc: 0.519447. Loss: 1.331594. Batch_acc: 0.548256. Batch_loss: 1.271449 \n",
      "Batch: 4033. Acc: 0.519452. Loss: 1.331579. Batch_acc: 0.537801. Batch_loss: 1.272464 \n",
      "Batch: 4034. Acc: 0.519456. Loss: 1.331567. Batch_acc: 0.538372. Batch_loss: 1.281189 \n",
      "Batch: 4035. Acc: 0.519461. Loss: 1.331549. Batch_acc: 0.540711. Batch_loss: 1.259033 \n",
      "Batch: 4036. Acc: 0.519462. Loss: 1.331542. Batch_acc: 0.523641. Batch_loss: 1.304343 \n",
      "Batch: 4037. Acc: 0.519468. Loss: 1.331524. Batch_acc: 0.543566. Batch_loss: 1.258761 \n",
      "Batch: 4038. Acc: 0.519471. Loss: 1.331525. Batch_acc: 0.527840. Batch_loss: 1.334596 \n",
      "Batch: 4039. Acc: 0.519476. Loss: 1.331515. Batch_acc: 0.539888. Batch_loss: 1.292590 \n",
      "Batch: 4040. Acc: 0.519477. Loss: 1.331509. Batch_acc: 0.525335. Batch_loss: 1.306098 \n",
      "Batch: 4041. Acc: 0.519478. Loss: 1.331501. Batch_acc: 0.523892. Batch_loss: 1.300076 \n",
      "Batch: 4042. Acc: 0.519480. Loss: 1.331503. Batch_acc: 0.526651. Batch_loss: 1.340904 \n",
      "Batch: 4043. Acc: 0.519484. Loss: 1.331496. Batch_acc: 0.535312. Batch_loss: 1.299217 \n",
      "Batch: 4044. Acc: 0.519481. Loss: 1.331502. Batch_acc: 0.509445. Batch_loss: 1.356730 \n",
      "Batch: 4045. Acc: 0.519485. Loss: 1.331493. Batch_acc: 0.532633. Batch_loss: 1.298099 \n",
      "Batch: 4046. Acc: 0.519486. Loss: 1.331492. Batch_acc: 0.525217. Batch_loss: 1.325514 \n",
      "Batch: 4047. Acc: 0.519493. Loss: 1.331484. Batch_acc: 0.547821. Batch_loss: 1.301700 \n",
      "Batch: 4048. Acc: 0.519499. Loss: 1.331469. Batch_acc: 0.541880. Batch_loss: 1.268423 \n",
      "Batch: 4049. Acc: 0.519504. Loss: 1.331456. Batch_acc: 0.541928. Batch_loss: 1.280553 \n",
      "Batch: 4050. Acc: 0.519508. Loss: 1.331449. Batch_acc: 0.535377. Batch_loss: 1.301300 \n",
      "Batch: 4051. Acc: 0.519514. Loss: 1.331433. Batch_acc: 0.541500. Batch_loss: 1.267892 \n",
      "Batch: 4052. Acc: 0.519520. Loss: 1.331416. Batch_acc: 0.545769. Batch_loss: 1.263450 \n",
      "Batch: 4053. Acc: 0.519526. Loss: 1.331404. Batch_acc: 0.543491. Batch_loss: 1.280343 \n",
      "Batch: 4054. Acc: 0.519525. Loss: 1.331400. Batch_acc: 0.513963. Batch_loss: 1.317143 \n",
      "Batch: 4055. Acc: 0.519529. Loss: 1.331392. Batch_acc: 0.536290. Batch_loss: 1.296327 \n",
      "Batch: 4056. Acc: 0.519533. Loss: 1.331376. Batch_acc: 0.537005. Batch_loss: 1.269568 \n",
      "Batch: 4057. Acc: 0.519530. Loss: 1.331376. Batch_acc: 0.508309. Batch_loss: 1.329667 \n",
      "Batch: 4058. Acc: 0.519531. Loss: 1.331368. Batch_acc: 0.523837. Batch_loss: 1.298931 \n",
      "Batch: 4059. Acc: 0.519538. Loss: 1.331352. Batch_acc: 0.546286. Batch_loss: 1.268829 \n",
      "Batch: 4060. Acc: 0.519537. Loss: 1.331353. Batch_acc: 0.515029. Batch_loss: 1.334144 \n",
      "Batch: 4061. Acc: 0.519539. Loss: 1.331349. Batch_acc: 0.527136. Batch_loss: 1.314721 \n",
      "Batch: 4062. Acc: 0.519542. Loss: 1.331343. Batch_acc: 0.533601. Batch_loss: 1.307489 \n",
      "Batch: 4063. Acc: 0.519542. Loss: 1.331344. Batch_acc: 0.517816. Batch_loss: 1.335854 \n",
      "Batch: 4064. Acc: 0.519540. Loss: 1.331350. Batch_acc: 0.510576. Batch_loss: 1.353795 \n",
      "Batch: 4065. Acc: 0.519538. Loss: 1.331356. Batch_acc: 0.512746. Batch_loss: 1.356277 \n",
      "Batch: 4066. Acc: 0.519540. Loss: 1.331343. Batch_acc: 0.528916. Batch_loss: 1.281551 \n",
      "Batch: 4067. Acc: 0.519543. Loss: 1.331332. Batch_acc: 0.528977. Batch_loss: 1.284533 \n",
      "Batch: 4068. Acc: 0.519545. Loss: 1.331329. Batch_acc: 0.528129. Batch_loss: 1.319496 \n",
      "Batch: 4069. Acc: 0.519546. Loss: 1.331330. Batch_acc: 0.524915. Batch_loss: 1.335669 \n",
      "Batch: 4070. Acc: 0.519551. Loss: 1.331313. Batch_acc: 0.539601. Batch_loss: 1.264856 \n",
      "Batch: 4071. Acc: 0.519551. Loss: 1.331312. Batch_acc: 0.518389. Batch_loss: 1.327855 \n",
      "Batch: 4072. Acc: 0.519553. Loss: 1.331307. Batch_acc: 0.527441. Batch_loss: 1.310792 \n",
      "Batch: 4073. Acc: 0.519552. Loss: 1.331301. Batch_acc: 0.517973. Batch_loss: 1.304948 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4074. Acc: 0.519558. Loss: 1.331286. Batch_acc: 0.541290. Batch_loss: 1.271701 \n",
      "Batch: 4075. Acc: 0.519560. Loss: 1.331279. Batch_acc: 0.529482. Batch_loss: 1.298886 \n",
      "Batch: 4076. Acc: 0.519563. Loss: 1.331266. Batch_acc: 0.530541. Batch_loss: 1.279149 \n",
      "Batch: 4077. Acc: 0.519571. Loss: 1.331249. Batch_acc: 0.552662. Batch_loss: 1.260889 \n",
      "Batch: 4078. Acc: 0.519575. Loss: 1.331233. Batch_acc: 0.537697. Batch_loss: 1.266263 \n",
      "Batch: 4079. Acc: 0.519583. Loss: 1.331214. Batch_acc: 0.549488. Batch_loss: 1.255606 \n",
      "Batch: 4080. Acc: 0.519581. Loss: 1.331215. Batch_acc: 0.513783. Batch_loss: 1.332687 \n",
      "Batch: 4081. Acc: 0.519584. Loss: 1.331202. Batch_acc: 0.529649. Batch_loss: 1.277943 \n",
      "Batch: 4082. Acc: 0.519586. Loss: 1.331197. Batch_acc: 0.526735. Batch_loss: 1.312593 \n",
      "Batch: 4083. Acc: 0.519589. Loss: 1.331187. Batch_acc: 0.532014. Batch_loss: 1.290638 \n",
      "Batch: 4084. Acc: 0.519593. Loss: 1.331177. Batch_acc: 0.536572. Batch_loss: 1.289421 \n",
      "Batch: 4085. Acc: 0.519593. Loss: 1.331180. Batch_acc: 0.518754. Batch_loss: 1.343417 \n",
      "Batch: 4086. Acc: 0.519593. Loss: 1.331176. Batch_acc: 0.520138. Batch_loss: 1.317240 \n",
      "Batch: 4087. Acc: 0.519596. Loss: 1.331163. Batch_acc: 0.531831. Batch_loss: 1.279338 \n",
      "Batch: 4088. Acc: 0.519603. Loss: 1.331145. Batch_acc: 0.548571. Batch_loss: 1.256783 \n",
      "Batch: 4089. Acc: 0.519608. Loss: 1.331127. Batch_acc: 0.539859. Batch_loss: 1.254999 \n",
      "Batch: 4090. Acc: 0.519615. Loss: 1.331106. Batch_acc: 0.548658. Batch_loss: 1.249604 \n",
      "Batch: 4091. Acc: 0.519617. Loss: 1.331100. Batch_acc: 0.526932. Batch_loss: 1.303869 \n",
      "Batch: 4092. Acc: 0.519621. Loss: 1.331080. Batch_acc: 0.535195. Batch_loss: 1.247392 \n",
      "Batch: 4093. Acc: 0.519621. Loss: 1.331078. Batch_acc: 0.519534. Batch_loss: 1.323541 \n",
      "Batch: 4094. Acc: 0.519623. Loss: 1.331069. Batch_acc: 0.530928. Batch_loss: 1.296369 \n",
      "Batch: 4095. Acc: 0.519624. Loss: 1.331065. Batch_acc: 0.521258. Batch_loss: 1.314298 \n",
      "Batch: 4096. Acc: 0.519627. Loss: 1.331052. Batch_acc: 0.530968. Batch_loss: 1.278906 \n",
      "Batch: 4097. Acc: 0.519630. Loss: 1.331039. Batch_acc: 0.531077. Batch_loss: 1.278759 \n",
      "Batch: 4098. Acc: 0.519631. Loss: 1.331038. Batch_acc: 0.525424. Batch_loss: 1.325268 \n",
      "Batch: 4099. Acc: 0.519633. Loss: 1.331027. Batch_acc: 0.529243. Batch_loss: 1.289171 \n",
      "Batch: 4100. Acc: 0.519634. Loss: 1.331025. Batch_acc: 0.522569. Batch_loss: 1.320545 \n",
      "Batch: 4101. Acc: 0.519636. Loss: 1.331020. Batch_acc: 0.529176. Batch_loss: 1.311631 \n",
      "Batch: 4102. Acc: 0.519643. Loss: 1.330997. Batch_acc: 0.547159. Batch_loss: 1.234577 \n",
      "Batch: 4103. Acc: 0.519643. Loss: 1.330992. Batch_acc: 0.518129. Batch_loss: 1.309019 \n",
      "Batch: 4104. Acc: 0.519648. Loss: 1.330979. Batch_acc: 0.540870. Batch_loss: 1.276465 \n",
      "Batch: 4105. Acc: 0.519651. Loss: 1.330970. Batch_acc: 0.532726. Batch_loss: 1.296605 \n",
      "Batch: 4106. Acc: 0.519658. Loss: 1.330952. Batch_acc: 0.546750. Batch_loss: 1.258691 \n",
      "Batch: 4107. Acc: 0.519665. Loss: 1.330938. Batch_acc: 0.548169. Batch_loss: 1.272821 \n",
      "Batch: 4108. Acc: 0.519666. Loss: 1.330932. Batch_acc: 0.527011. Batch_loss: 1.308559 \n",
      "Batch: 4109. Acc: 0.519665. Loss: 1.330932. Batch_acc: 0.514253. Batch_loss: 1.329963 \n",
      "Batch: 4110. Acc: 0.519661. Loss: 1.330941. Batch_acc: 0.503687. Batch_loss: 1.366869 \n",
      "Batch: 4111. Acc: 0.519664. Loss: 1.330932. Batch_acc: 0.529794. Batch_loss: 1.293839 \n",
      "Batch: 4112. Acc: 0.519670. Loss: 1.330920. Batch_acc: 0.544876. Batch_loss: 1.279822 \n",
      "Batch: 4113. Acc: 0.519666. Loss: 1.330931. Batch_acc: 0.505787. Batch_loss: 1.377284 \n",
      "Batch: 4114. Acc: 0.519669. Loss: 1.330921. Batch_acc: 0.529073. Batch_loss: 1.289135 \n",
      "Batch: 4115. Acc: 0.519674. Loss: 1.330914. Batch_acc: 0.541866. Batch_loss: 1.300219 \n",
      "Batch: 4116. Acc: 0.519679. Loss: 1.330899. Batch_acc: 0.539773. Batch_loss: 1.271497 \n",
      "Batch: 4117. Acc: 0.519680. Loss: 1.330899. Batch_acc: 0.524628. Batch_loss: 1.331486 \n",
      "Batch: 4118. Acc: 0.519684. Loss: 1.330896. Batch_acc: 0.537176. Batch_loss: 1.315288 \n",
      "Batch: 4119. Acc: 0.519688. Loss: 1.330890. Batch_acc: 0.536348. Batch_loss: 1.306819 \n",
      "Batch: 4120. Acc: 0.519690. Loss: 1.330880. Batch_acc: 0.527357. Batch_loss: 1.291684 \n",
      "Batch: 4121. Acc: 0.519692. Loss: 1.330874. Batch_acc: 0.528769. Batch_loss: 1.305900 \n",
      "Batch: 4122. Acc: 0.519701. Loss: 1.330855. Batch_acc: 0.554854. Batch_loss: 1.251749 \n",
      "Batch: 4123. Acc: 0.519701. Loss: 1.330861. Batch_acc: 0.521264. Batch_loss: 1.354237 \n",
      "Batch: 4124. Acc: 0.519705. Loss: 1.330850. Batch_acc: 0.536806. Batch_loss: 1.288648 \n",
      "Batch: 4125. Acc: 0.519720. Loss: 1.330820. Batch_acc: 0.578002. Batch_loss: 1.209367 \n",
      "Batch: 4126. Acc: 0.519718. Loss: 1.330826. Batch_acc: 0.510157. Batch_loss: 1.354205 \n",
      "Batch: 4127. Acc: 0.519719. Loss: 1.330824. Batch_acc: 0.524515. Batch_loss: 1.325462 \n",
      "Batch: 4128. Acc: 0.519728. Loss: 1.330800. Batch_acc: 0.559409. Batch_loss: 1.233028 \n",
      "Batch: 4129. Acc: 0.519729. Loss: 1.330803. Batch_acc: 0.521209. Batch_loss: 1.340641 \n",
      "Batch: 4130. Acc: 0.519736. Loss: 1.330783. Batch_acc: 0.548963. Batch_loss: 1.250386 \n",
      "Batch: 4131. Acc: 0.519736. Loss: 1.330780. Batch_acc: 0.522114. Batch_loss: 1.315687 \n",
      "Batch: 4132. Acc: 0.519744. Loss: 1.330758. Batch_acc: 0.551685. Batch_loss: 1.242760 \n",
      "Batch: 4133. Acc: 0.519749. Loss: 1.330755. Batch_acc: 0.537472. Batch_loss: 1.316851 \n",
      "Batch: 4134. Acc: 0.519747. Loss: 1.330748. Batch_acc: 0.514384. Batch_loss: 1.300900 \n",
      "Batch: 4135. Acc: 0.519748. Loss: 1.330740. Batch_acc: 0.521816. Batch_loss: 1.297078 \n",
      "Batch: 4136. Acc: 0.519750. Loss: 1.330731. Batch_acc: 0.528696. Batch_loss: 1.294247 \n",
      "Batch: 4137. Acc: 0.519744. Loss: 1.330741. Batch_acc: 0.492694. Batch_loss: 1.371636 \n",
      "Batch: 4138. Acc: 0.519741. Loss: 1.330738. Batch_acc: 0.510029. Batch_loss: 1.320810 \n",
      "Batch: 4139. Acc: 0.519738. Loss: 1.330747. Batch_acc: 0.507306. Batch_loss: 1.368997 \n",
      "Batch: 4140. Acc: 0.519739. Loss: 1.330751. Batch_acc: 0.521889. Batch_loss: 1.347073 \n",
      "Batch: 4141. Acc: 0.519735. Loss: 1.330762. Batch_acc: 0.503452. Batch_loss: 1.376302 \n",
      "Batch: 4142. Acc: 0.519737. Loss: 1.330751. Batch_acc: 0.529748. Batch_loss: 1.284569 \n",
      "Batch: 4143. Acc: 0.519740. Loss: 1.330740. Batch_acc: 0.531268. Batch_loss: 1.285995 \n",
      "Batch: 4144. Acc: 0.519737. Loss: 1.330748. Batch_acc: 0.508782. Batch_loss: 1.364875 \n",
      "Batch: 4145. Acc: 0.519741. Loss: 1.330743. Batch_acc: 0.535138. Batch_loss: 1.306304 \n",
      "Batch: 4146. Acc: 0.519745. Loss: 1.330731. Batch_acc: 0.534642. Batch_loss: 1.281834 \n",
      "Batch: 4147. Acc: 0.519752. Loss: 1.330716. Batch_acc: 0.549488. Batch_loss: 1.270657 \n",
      "Batch: 4148. Acc: 0.519748. Loss: 1.330715. Batch_acc: 0.505214. Batch_loss: 1.326473 \n",
      "Batch: 4149. Acc: 0.519755. Loss: 1.330694. Batch_acc: 0.545615. Batch_loss: 1.242333 \n",
      "Batch: 4150. Acc: 0.519754. Loss: 1.330694. Batch_acc: 0.517262. Batch_loss: 1.331250 \n",
      "Batch: 4151. Acc: 0.519763. Loss: 1.330676. Batch_acc: 0.554736. Batch_loss: 1.254450 \n",
      "Batch: 4152. Acc: 0.519767. Loss: 1.330666. Batch_acc: 0.536077. Batch_loss: 1.290744 \n",
      "Batch: 4153. Acc: 0.519773. Loss: 1.330648. Batch_acc: 0.547592. Batch_loss: 1.256282 \n",
      "Batch: 4154. Acc: 0.519780. Loss: 1.330626. Batch_acc: 0.546775. Batch_loss: 1.239951 \n",
      "Batch: 4155. Acc: 0.519786. Loss: 1.330610. Batch_acc: 0.543539. Batch_loss: 1.266065 \n",
      "Batch: 4156. Acc: 0.519793. Loss: 1.330592. Batch_acc: 0.549247. Batch_loss: 1.254914 \n",
      "Batch: 4157. Acc: 0.519797. Loss: 1.330572. Batch_acc: 0.535274. Batch_loss: 1.249272 \n",
      "Batch: 4158. Acc: 0.519799. Loss: 1.330553. Batch_acc: 0.531250. Batch_loss: 1.255534 \n",
      "Batch: 4159. Acc: 0.519803. Loss: 1.330554. Batch_acc: 0.535447. Batch_loss: 1.332527 \n",
      "Batch: 4160. Acc: 0.519814. Loss: 1.330529. Batch_acc: 0.563152. Batch_loss: 1.225221 \n",
      "Batch: 4161. Acc: 0.519818. Loss: 1.330520. Batch_acc: 0.538857. Batch_loss: 1.295397 \n",
      "Batch: 4162. Acc: 0.519819. Loss: 1.330519. Batch_acc: 0.524735. Batch_loss: 1.324278 \n",
      "Batch: 4163. Acc: 0.519825. Loss: 1.330504. Batch_acc: 0.541039. Batch_loss: 1.272491 \n",
      "Batch: 4164. Acc: 0.519826. Loss: 1.330495. Batch_acc: 0.526678. Batch_loss: 1.290469 \n",
      "Batch: 4165. Acc: 0.519829. Loss: 1.330490. Batch_acc: 0.530329. Batch_loss: 1.311813 \n",
      "Batch: 4166. Acc: 0.519837. Loss: 1.330472. Batch_acc: 0.555035. Batch_loss: 1.253941 \n",
      "Batch: 4167. Acc: 0.519843. Loss: 1.330464. Batch_acc: 0.544799. Batch_loss: 1.293532 \n",
      "Batch: 4168. Acc: 0.519840. Loss: 1.330475. Batch_acc: 0.506603. Batch_loss: 1.378779 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4169. Acc: 0.519842. Loss: 1.330466. Batch_acc: 0.531268. Batch_loss: 1.292192 \n",
      "Batch: 4170. Acc: 0.519847. Loss: 1.330453. Batch_acc: 0.537731. Batch_loss: 1.277895 \n",
      "Batch: 4171. Acc: 0.519848. Loss: 1.330451. Batch_acc: 0.525434. Batch_loss: 1.324855 \n",
      "Batch: 4172. Acc: 0.519850. Loss: 1.330448. Batch_acc: 0.526405. Batch_loss: 1.317447 \n",
      "Batch: 4173. Acc: 0.519850. Loss: 1.330454. Batch_acc: 0.521689. Batch_loss: 1.353812 \n",
      "Batch: 4174. Acc: 0.519854. Loss: 1.330443. Batch_acc: 0.535388. Batch_loss: 1.285193 \n",
      "Batch: 4175. Acc: 0.519862. Loss: 1.330424. Batch_acc: 0.555038. Batch_loss: 1.249284 \n",
      "Batch: 4176. Acc: 0.519867. Loss: 1.330409. Batch_acc: 0.541520. Batch_loss: 1.269343 \n",
      "Batch: 4177. Acc: 0.519872. Loss: 1.330400. Batch_acc: 0.541003. Batch_loss: 1.289632 \n",
      "Batch: 4178. Acc: 0.519876. Loss: 1.330388. Batch_acc: 0.538047. Batch_loss: 1.276743 \n",
      "Batch: 4179. Acc: 0.519872. Loss: 1.330397. Batch_acc: 0.500575. Batch_loss: 1.369788 \n",
      "Batch: 4180. Acc: 0.519877. Loss: 1.330383. Batch_acc: 0.543138. Batch_loss: 1.270421 \n",
      "Batch: 4181. Acc: 0.519881. Loss: 1.330373. Batch_acc: 0.536769. Batch_loss: 1.290689 \n",
      "Batch: 4182. Acc: 0.519882. Loss: 1.330361. Batch_acc: 0.523560. Batch_loss: 1.277848 \n",
      "Batch: 4183. Acc: 0.519888. Loss: 1.330353. Batch_acc: 0.543168. Batch_loss: 1.297879 \n",
      "Batch: 4184. Acc: 0.519892. Loss: 1.330338. Batch_acc: 0.536023. Batch_loss: 1.265708 \n",
      "Batch: 4185. Acc: 0.519895. Loss: 1.330328. Batch_acc: 0.532445. Batch_loss: 1.291288 \n",
      "Batch: 4186. Acc: 0.519892. Loss: 1.330332. Batch_acc: 0.508255. Batch_loss: 1.343694 \n",
      "Batch: 4187. Acc: 0.519899. Loss: 1.330320. Batch_acc: 0.549075. Batch_loss: 1.282138 \n",
      "Batch: 4188. Acc: 0.519897. Loss: 1.330328. Batch_acc: 0.513083. Batch_loss: 1.366071 \n",
      "Batch: 4189. Acc: 0.519899. Loss: 1.330325. Batch_acc: 0.528096. Batch_loss: 1.315050 \n",
      "Batch: 4190. Acc: 0.519901. Loss: 1.330320. Batch_acc: 0.527794. Batch_loss: 1.308341 \n",
      "Batch: 4191. Acc: 0.519906. Loss: 1.330313. Batch_acc: 0.541096. Batch_loss: 1.302339 \n",
      "Batch: 4192. Acc: 0.519903. Loss: 1.330318. Batch_acc: 0.507657. Batch_loss: 1.350065 \n",
      "Batch: 4193. Acc: 0.519903. Loss: 1.330315. Batch_acc: 0.518093. Batch_loss: 1.319088 \n",
      "Batch: 4194. Acc: 0.519907. Loss: 1.330313. Batch_acc: 0.535411. Batch_loss: 1.320333 \n",
      "Batch: 4195. Acc: 0.519912. Loss: 1.330299. Batch_acc: 0.541855. Batch_loss: 1.276250 \n",
      "Batch: 4196. Acc: 0.519916. Loss: 1.330283. Batch_acc: 0.534443. Batch_loss: 1.261482 \n",
      "Batch: 4197. Acc: 0.519918. Loss: 1.330284. Batch_acc: 0.530495. Batch_loss: 1.335778 \n",
      "Batch: 4198. Acc: 0.519921. Loss: 1.330278. Batch_acc: 0.532945. Batch_loss: 1.301717 \n",
      "Batch: 4199. Acc: 0.519925. Loss: 1.330277. Batch_acc: 0.535735. Batch_loss: 1.329439 \n",
      "Batch: 4200. Acc: 0.519924. Loss: 1.330287. Batch_acc: 0.517949. Batch_loss: 1.368994 \n",
      "Batch: 4201. Acc: 0.519932. Loss: 1.330268. Batch_acc: 0.551078. Batch_loss: 1.253437 \n",
      "Batch: 4202. Acc: 0.519932. Loss: 1.330267. Batch_acc: 0.521689. Batch_loss: 1.326437 \n",
      "Batch: 4203. Acc: 0.519938. Loss: 1.330254. Batch_acc: 0.544389. Batch_loss: 1.276665 \n",
      "Batch: 4204. Acc: 0.519945. Loss: 1.330229. Batch_acc: 0.546083. Batch_loss: 1.224990 \n",
      "Batch: 4205. Acc: 0.519947. Loss: 1.330224. Batch_acc: 0.528696. Batch_loss: 1.308160 \n",
      "Batch: 4206. Acc: 0.519952. Loss: 1.330210. Batch_acc: 0.540834. Batch_loss: 1.270576 \n",
      "Batch: 4207. Acc: 0.519959. Loss: 1.330197. Batch_acc: 0.550261. Batch_loss: 1.275959 \n",
      "Batch: 4208. Acc: 0.519971. Loss: 1.330168. Batch_acc: 0.570023. Batch_loss: 1.208073 \n",
      "Batch: 4209. Acc: 0.519973. Loss: 1.330161. Batch_acc: 0.529248. Batch_loss: 1.301221 \n",
      "Batch: 4210. Acc: 0.519977. Loss: 1.330153. Batch_acc: 0.535944. Batch_loss: 1.297139 \n",
      "Batch: 4211. Acc: 0.519978. Loss: 1.330153. Batch_acc: 0.525414. Batch_loss: 1.327583 \n",
      "Batch: 4212. Acc: 0.519983. Loss: 1.330141. Batch_acc: 0.539238. Batch_loss: 1.282354 \n",
      "Batch: 4213. Acc: 0.519989. Loss: 1.330132. Batch_acc: 0.546037. Batch_loss: 1.290660 \n",
      "Batch: 4214. Acc: 0.519998. Loss: 1.330110. Batch_acc: 0.561201. Batch_loss: 1.238528 \n",
      "Batch: 4215. Acc: 0.520004. Loss: 1.330092. Batch_acc: 0.541667. Batch_loss: 1.256467 \n",
      "Batch: 4216. Acc: 0.520009. Loss: 1.330074. Batch_acc: 0.540741. Batch_loss: 1.254441 \n",
      "Batch: 4217. Acc: 0.520014. Loss: 1.330060. Batch_acc: 0.543678. Batch_loss: 1.268854 \n",
      "Batch: 4218. Acc: 0.520022. Loss: 1.330047. Batch_acc: 0.550814. Batch_loss: 1.278710 \n",
      "Batch: 4219. Acc: 0.520026. Loss: 1.330030. Batch_acc: 0.540000. Batch_loss: 1.258586 \n",
      "Batch: 4220. Acc: 0.520032. Loss: 1.330018. Batch_acc: 0.543429. Batch_loss: 1.278623 \n",
      "Batch: 4221. Acc: 0.520033. Loss: 1.330026. Batch_acc: 0.524334. Batch_loss: 1.365163 \n",
      "Batch: 4222. Acc: 0.520035. Loss: 1.330025. Batch_acc: 0.529680. Batch_loss: 1.323399 \n",
      "Batch: 4223. Acc: 0.520043. Loss: 1.330007. Batch_acc: 0.551136. Batch_loss: 1.254646 \n",
      "Batch: 4224. Acc: 0.520052. Loss: 1.329979. Batch_acc: 0.560161. Batch_loss: 1.213958 \n",
      "Batch: 4225. Acc: 0.520060. Loss: 1.329966. Batch_acc: 0.551245. Batch_loss: 1.273366 \n",
      "Batch: 4226. Acc: 0.520058. Loss: 1.329969. Batch_acc: 0.511721. Batch_loss: 1.343510 \n",
      "Batch: 4227. Acc: 0.520071. Loss: 1.329934. Batch_acc: 0.574944. Batch_loss: 1.184039 \n",
      "Batch: 4228. Acc: 0.520075. Loss: 1.329924. Batch_acc: 0.535484. Batch_loss: 1.287646 \n",
      "Batch: 4229. Acc: 0.520080. Loss: 1.329914. Batch_acc: 0.544050. Batch_loss: 1.287933 \n",
      "Batch: 4230. Acc: 0.520082. Loss: 1.329910. Batch_acc: 0.529378. Batch_loss: 1.314411 \n",
      "Batch: 4231. Acc: 0.520091. Loss: 1.329886. Batch_acc: 0.556920. Batch_loss: 1.230161 \n",
      "Batch: 4232. Acc: 0.520095. Loss: 1.329878. Batch_acc: 0.536082. Batch_loss: 1.294922 \n",
      "Batch: 4233. Acc: 0.520100. Loss: 1.329859. Batch_acc: 0.541143. Batch_loss: 1.250553 \n",
      "Batch: 4234. Acc: 0.520105. Loss: 1.329843. Batch_acc: 0.540448. Batch_loss: 1.263992 \n",
      "Batch: 4235. Acc: 0.520114. Loss: 1.329819. Batch_acc: 0.559370. Batch_loss: 1.229675 \n",
      "Batch: 4236. Acc: 0.520116. Loss: 1.329809. Batch_acc: 0.528156. Batch_loss: 1.284913 \n",
      "Batch: 4237. Acc: 0.520119. Loss: 1.329799. Batch_acc: 0.529748. Batch_loss: 1.288428 \n",
      "Batch: 4238. Acc: 0.520115. Loss: 1.329806. Batch_acc: 0.504805. Batch_loss: 1.357916 \n",
      "Batch: 4239. Acc: 0.520115. Loss: 1.329808. Batch_acc: 0.520955. Batch_loss: 1.338922 \n",
      "Batch: 4240. Acc: 0.520115. Loss: 1.329804. Batch_acc: 0.521222. Batch_loss: 1.313882 \n",
      "Batch: 4241. Acc: 0.520122. Loss: 1.329783. Batch_acc: 0.549199. Batch_loss: 1.241500 \n",
      "Batch: 4242. Acc: 0.520123. Loss: 1.329784. Batch_acc: 0.522262. Batch_loss: 1.332869 \n",
      "Batch: 4243. Acc: 0.520134. Loss: 1.329758. Batch_acc: 0.565588. Batch_loss: 1.220482 \n",
      "Batch: 4244. Acc: 0.520139. Loss: 1.329746. Batch_acc: 0.542403. Batch_loss: 1.278915 \n",
      "Batch: 4245. Acc: 0.520144. Loss: 1.329729. Batch_acc: 0.540993. Batch_loss: 1.257153 \n",
      "Batch: 4246. Acc: 0.520148. Loss: 1.329720. Batch_acc: 0.536952. Batch_loss: 1.290991 \n",
      "Batch: 4247. Acc: 0.520154. Loss: 1.329699. Batch_acc: 0.549008. Batch_loss: 1.241406 \n",
      "Batch: 4248. Acc: 0.520154. Loss: 1.329700. Batch_acc: 0.517675. Batch_loss: 1.336880 \n",
      "Batch: 4249. Acc: 0.520153. Loss: 1.329708. Batch_acc: 0.517425. Batch_loss: 1.361866 \n",
      "Batch: 4250. Acc: 0.520161. Loss: 1.329684. Batch_acc: 0.550111. Batch_loss: 1.231307 \n",
      "Batch: 4251. Acc: 0.520162. Loss: 1.329677. Batch_acc: 0.526559. Batch_loss: 1.301781 \n",
      "Batch: 4252. Acc: 0.520164. Loss: 1.329669. Batch_acc: 0.527621. Batch_loss: 1.293812 \n",
      "Batch: 4253. Acc: 0.520168. Loss: 1.329653. Batch_acc: 0.538287. Batch_loss: 1.264564 \n",
      "Batch: 4254. Acc: 0.520176. Loss: 1.329634. Batch_acc: 0.551391. Batch_loss: 1.248989 \n",
      "Batch: 4255. Acc: 0.520173. Loss: 1.329632. Batch_acc: 0.510838. Batch_loss: 1.323177 \n",
      "Batch: 4256. Acc: 0.520180. Loss: 1.329614. Batch_acc: 0.549143. Batch_loss: 1.251511 \n",
      "Batch: 4257. Acc: 0.520185. Loss: 1.329602. Batch_acc: 0.540416. Batch_loss: 1.279681 \n",
      "Batch: 4258. Acc: 0.520189. Loss: 1.329585. Batch_acc: 0.537579. Batch_loss: 1.258163 \n",
      "Batch: 4259. Acc: 0.520190. Loss: 1.329585. Batch_acc: 0.523249. Batch_loss: 1.327816 \n",
      "Batch: 4260. Acc: 0.520196. Loss: 1.329574. Batch_acc: 0.545961. Batch_loss: 1.284425 \n",
      "Batch: 4261. Acc: 0.520205. Loss: 1.329555. Batch_acc: 0.556647. Batch_loss: 1.247006 \n",
      "Batch: 4262. Acc: 0.520208. Loss: 1.329545. Batch_acc: 0.536047. Batch_loss: 1.286542 \n",
      "Batch: 4263. Acc: 0.520209. Loss: 1.329537. Batch_acc: 0.522145. Batch_loss: 1.294766 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4264. Acc: 0.520215. Loss: 1.329519. Batch_acc: 0.545403. Batch_loss: 1.255933 \n",
      "Batch: 4265. Acc: 0.520221. Loss: 1.329510. Batch_acc: 0.547660. Batch_loss: 1.288916 \n",
      "Batch: 4266. Acc: 0.520221. Loss: 1.329514. Batch_acc: 0.517796. Batch_loss: 1.346446 \n",
      "Batch: 4267. Acc: 0.520224. Loss: 1.329507. Batch_acc: 0.534025. Batch_loss: 1.302143 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.5202237952387312. Loss per char: 1.3295073847928274. Time: 1627221403.322695\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 19, 19, 17, 17, 18, 22,\n",
      "        19, 19, 20, 23, 26,  1, 14,  1, 14, 19, 15, 18, 19, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.520226. Loss: 1.329496. Batch_acc: 0.528729. Batch_loss: 1.279830 \n",
      "Batch: 4269. Acc: 0.520228. Loss: 1.329489. Batch_acc: 0.528729. Batch_loss: 1.300435 \n",
      "Batch: 4270. Acc: 0.520233. Loss: 1.329470. Batch_acc: 0.544921. Batch_loss: 1.247389 \n",
      "Batch: 4271. Acc: 0.520238. Loss: 1.329463. Batch_acc: 0.538328. Batch_loss: 1.296026 \n",
      "Batch: 4272. Acc: 0.520238. Loss: 1.329462. Batch_acc: 0.522139. Batch_loss: 1.327401 \n",
      "Batch: 4273. Acc: 0.520248. Loss: 1.329444. Batch_acc: 0.564059. Batch_loss: 1.253265 \n",
      "Batch: 4274. Acc: 0.520248. Loss: 1.329441. Batch_acc: 0.519053. Batch_loss: 1.314787 \n",
      "Batch: 4275. Acc: 0.520248. Loss: 1.329442. Batch_acc: 0.519630. Batch_loss: 1.335449 \n",
      "Batch: 4276. Acc: 0.520251. Loss: 1.329434. Batch_acc: 0.534473. Batch_loss: 1.296522 \n",
      "Batch: 4277. Acc: 0.520258. Loss: 1.329418. Batch_acc: 0.546848. Batch_loss: 1.260000 \n",
      "Batch: 4278. Acc: 0.520260. Loss: 1.329410. Batch_acc: 0.529412. Batch_loss: 1.297147 \n",
      "Batch: 4279. Acc: 0.520266. Loss: 1.329392. Batch_acc: 0.544571. Batch_loss: 1.251861 \n",
      "Batch: 4280. Acc: 0.520272. Loss: 1.329378. Batch_acc: 0.549425. Batch_loss: 1.272350 \n",
      "Batch: 4281. Acc: 0.520273. Loss: 1.329371. Batch_acc: 0.523867. Batch_loss: 1.297374 \n",
      "Batch: 4282. Acc: 0.520278. Loss: 1.329361. Batch_acc: 0.539802. Batch_loss: 1.285245 \n",
      "Batch: 4283. Acc: 0.520279. Loss: 1.329364. Batch_acc: 0.526285. Batch_loss: 1.342844 \n",
      "Batch: 4284. Acc: 0.520283. Loss: 1.329351. Batch_acc: 0.537100. Batch_loss: 1.272201 \n",
      "Batch: 4285. Acc: 0.520289. Loss: 1.329329. Batch_acc: 0.545662. Batch_loss: 1.237017 \n",
      "Batch: 4286. Acc: 0.520285. Loss: 1.329336. Batch_acc: 0.504147. Batch_loss: 1.359124 \n",
      "Batch: 4287. Acc: 0.520295. Loss: 1.329312. Batch_acc: 0.559612. Batch_loss: 1.226556 \n",
      "Batch: 4288. Acc: 0.520295. Loss: 1.329308. Batch_acc: 0.521462. Batch_loss: 1.314519 \n",
      "Batch: 4289. Acc: 0.520298. Loss: 1.329291. Batch_acc: 0.535465. Batch_loss: 1.253879 \n",
      "Batch: 4290. Acc: 0.520297. Loss: 1.329289. Batch_acc: 0.514977. Batch_loss: 1.322500 \n",
      "Batch: 4291. Acc: 0.520299. Loss: 1.329277. Batch_acc: 0.526740. Batch_loss: 1.276059 \n",
      "Batch: 4292. Acc: 0.520305. Loss: 1.329264. Batch_acc: 0.546030. Batch_loss: 1.272075 \n",
      "Batch: 4293. Acc: 0.520309. Loss: 1.329257. Batch_acc: 0.539397. Batch_loss: 1.302078 \n",
      "Batch: 4294. Acc: 0.520316. Loss: 1.329239. Batch_acc: 0.552239. Batch_loss: 1.249648 \n",
      "Batch: 4295. Acc: 0.520324. Loss: 1.329218. Batch_acc: 0.552154. Batch_loss: 1.242100 \n",
      "Batch: 4296. Acc: 0.520326. Loss: 1.329211. Batch_acc: 0.528382. Batch_loss: 1.296925 \n",
      "Batch: 4297. Acc: 0.520327. Loss: 1.329212. Batch_acc: 0.527088. Batch_loss: 1.331920 \n",
      "Batch: 4298. Acc: 0.520327. Loss: 1.329209. Batch_acc: 0.517981. Batch_loss: 1.318085 \n",
      "Batch: 4299. Acc: 0.520323. Loss: 1.329209. Batch_acc: 0.504404. Batch_loss: 1.327973 \n",
      "Batch: 4300. Acc: 0.520326. Loss: 1.329202. Batch_acc: 0.533565. Batch_loss: 1.298252 \n",
      "Batch: 4301. Acc: 0.520327. Loss: 1.329193. Batch_acc: 0.521915. Batch_loss: 1.294324 \n",
      "Batch: 4302. Acc: 0.520332. Loss: 1.329178. Batch_acc: 0.541477. Batch_loss: 1.265392 \n",
      "Batch: 4303. Acc: 0.520333. Loss: 1.329174. Batch_acc: 0.524107. Batch_loss: 1.309315 \n",
      "Batch: 4304. Acc: 0.520335. Loss: 1.329165. Batch_acc: 0.530822. Batch_loss: 1.291430 \n",
      "Batch: 4305. Acc: 0.520337. Loss: 1.329161. Batch_acc: 0.528977. Batch_loss: 1.310959 \n",
      "Batch: 4306. Acc: 0.520345. Loss: 1.329148. Batch_acc: 0.556400. Batch_loss: 1.274550 \n",
      "Batch: 4307. Acc: 0.520352. Loss: 1.329130. Batch_acc: 0.547592. Batch_loss: 1.253859 \n",
      "Batch: 4308. Acc: 0.520356. Loss: 1.329131. Batch_acc: 0.540270. Batch_loss: 1.331559 \n",
      "Batch: 4309. Acc: 0.520361. Loss: 1.329116. Batch_acc: 0.538505. Batch_loss: 1.264927 \n",
      "Batch: 4310. Acc: 0.520365. Loss: 1.329103. Batch_acc: 0.540993. Batch_loss: 1.274360 \n",
      "Batch: 4311. Acc: 0.520373. Loss: 1.329081. Batch_acc: 0.554980. Batch_loss: 1.235472 \n",
      "Batch: 4312. Acc: 0.520381. Loss: 1.329057. Batch_acc: 0.550530. Batch_loss: 1.228801 \n",
      "Batch: 4313. Acc: 0.520392. Loss: 1.329034. Batch_acc: 0.567005. Batch_loss: 1.229875 \n",
      "Batch: 4314. Acc: 0.520394. Loss: 1.329026. Batch_acc: 0.529278. Batch_loss: 1.297949 \n",
      "Batch: 4315. Acc: 0.520391. Loss: 1.329028. Batch_acc: 0.508532. Batch_loss: 1.334836 \n",
      "Batch: 4316. Acc: 0.520390. Loss: 1.329026. Batch_acc: 0.515452. Batch_loss: 1.321280 \n",
      "Batch: 4317. Acc: 0.520392. Loss: 1.329015. Batch_acc: 0.528051. Batch_loss: 1.281722 \n",
      "Batch: 4318. Acc: 0.520397. Loss: 1.329001. Batch_acc: 0.545240. Batch_loss: 1.266171 \n",
      "Batch: 4319. Acc: 0.520400. Loss: 1.328989. Batch_acc: 0.533711. Batch_loss: 1.277817 \n",
      "Batch: 4320. Acc: 0.520410. Loss: 1.328963. Batch_acc: 0.560045. Batch_loss: 1.222455 \n",
      "Batch: 4321. Acc: 0.520409. Loss: 1.328963. Batch_acc: 0.515152. Batch_loss: 1.326390 \n",
      "Batch: 4322. Acc: 0.520406. Loss: 1.328963. Batch_acc: 0.509838. Batch_loss: 1.330233 \n",
      "Batch: 4323. Acc: 0.520409. Loss: 1.328959. Batch_acc: 0.531829. Batch_loss: 1.310111 \n",
      "Batch: 4324. Acc: 0.520414. Loss: 1.328944. Batch_acc: 0.542411. Batch_loss: 1.268516 \n",
      "Batch: 4325. Acc: 0.520419. Loss: 1.328929. Batch_acc: 0.543182. Batch_loss: 1.260822 \n",
      "Batch: 4326. Acc: 0.520418. Loss: 1.328923. Batch_acc: 0.512950. Batch_loss: 1.303954 \n",
      "Batch: 4327. Acc: 0.520412. Loss: 1.328936. Batch_acc: 0.495009. Batch_loss: 1.387309 \n",
      "Batch: 4328. Acc: 0.520411. Loss: 1.328933. Batch_acc: 0.518135. Batch_loss: 1.318481 \n",
      "Batch: 4329. Acc: 0.520414. Loss: 1.328923. Batch_acc: 0.530899. Batch_loss: 1.285624 \n",
      "Batch: 4330. Acc: 0.520416. Loss: 1.328917. Batch_acc: 0.530338. Batch_loss: 1.299621 \n",
      "Batch: 4331. Acc: 0.520418. Loss: 1.328913. Batch_acc: 0.530338. Batch_loss: 1.311569 \n",
      "Batch: 4332. Acc: 0.520424. Loss: 1.328904. Batch_acc: 0.546667. Batch_loss: 1.292440 \n",
      "Batch: 4333. Acc: 0.520424. Loss: 1.328905. Batch_acc: 0.520187. Batch_loss: 1.331300 \n",
      "Batch: 4334. Acc: 0.520428. Loss: 1.328893. Batch_acc: 0.537652. Batch_loss: 1.280427 \n",
      "Batch: 4335. Acc: 0.520432. Loss: 1.328882. Batch_acc: 0.535921. Batch_loss: 1.281079 \n",
      "Batch: 4336. Acc: 0.520430. Loss: 1.328891. Batch_acc: 0.512048. Batch_loss: 1.367036 \n",
      "Batch: 4337. Acc: 0.520438. Loss: 1.328868. Batch_acc: 0.554433. Batch_loss: 1.233222 \n",
      "Batch: 4338. Acc: 0.520446. Loss: 1.328859. Batch_acc: 0.552692. Batch_loss: 1.291281 \n",
      "Batch: 4339. Acc: 0.520449. Loss: 1.328858. Batch_acc: 0.536723. Batch_loss: 1.325166 \n",
      "Batch: 4340. Acc: 0.520454. Loss: 1.328846. Batch_acc: 0.542127. Batch_loss: 1.274809 \n",
      "Batch: 4341. Acc: 0.520457. Loss: 1.328841. Batch_acc: 0.532660. Batch_loss: 1.306759 \n",
      "Batch: 4342. Acc: 0.520464. Loss: 1.328825. Batch_acc: 0.553154. Batch_loss: 1.259341 \n",
      "Batch: 4343. Acc: 0.520470. Loss: 1.328815. Batch_acc: 0.544593. Batch_loss: 1.284945 \n",
      "Batch: 4344. Acc: 0.520475. Loss: 1.328805. Batch_acc: 0.540176. Batch_loss: 1.282634 \n",
      "Batch: 4345. Acc: 0.520480. Loss: 1.328791. Batch_acc: 0.544886. Batch_loss: 1.269722 \n",
      "Batch: 4346. Acc: 0.520487. Loss: 1.328771. Batch_acc: 0.548369. Batch_loss: 1.244118 \n",
      "Batch: 4347. Acc: 0.520491. Loss: 1.328760. Batch_acc: 0.537892. Batch_loss: 1.282602 \n",
      "Batch: 4348. Acc: 0.520490. Loss: 1.328764. Batch_acc: 0.518475. Batch_loss: 1.344887 \n",
      "Batch: 4349. Acc: 0.520492. Loss: 1.328761. Batch_acc: 0.526686. Batch_loss: 1.315712 \n",
      "Batch: 4350. Acc: 0.520495. Loss: 1.328751. Batch_acc: 0.533451. Batch_loss: 1.284650 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4351. Acc: 0.520500. Loss: 1.328737. Batch_acc: 0.543931. Batch_loss: 1.268377 \n",
      "Batch: 4352. Acc: 0.520508. Loss: 1.328716. Batch_acc: 0.554494. Batch_loss: 1.237618 \n",
      "Batch: 4353. Acc: 0.520508. Loss: 1.328703. Batch_acc: 0.520938. Batch_loss: 1.277020 \n",
      "Batch: 4354. Acc: 0.520517. Loss: 1.328684. Batch_acc: 0.556180. Batch_loss: 1.244097 \n",
      "Batch: 4355. Acc: 0.520518. Loss: 1.328680. Batch_acc: 0.525633. Batch_loss: 1.310753 \n",
      "Batch: 4356. Acc: 0.520525. Loss: 1.328665. Batch_acc: 0.550258. Batch_loss: 1.263784 \n",
      "Batch: 4357. Acc: 0.520525. Loss: 1.328660. Batch_acc: 0.521935. Batch_loss: 1.307982 \n",
      "Batch: 4358. Acc: 0.520530. Loss: 1.328648. Batch_acc: 0.543427. Batch_loss: 1.277159 \n",
      "Batch: 4359. Acc: 0.520530. Loss: 1.328647. Batch_acc: 0.521523. Batch_loss: 1.323724 \n",
      "Batch: 4360. Acc: 0.520536. Loss: 1.328632. Batch_acc: 0.546754. Batch_loss: 1.262829 \n",
      "Batch: 4361. Acc: 0.520539. Loss: 1.328621. Batch_acc: 0.532358. Batch_loss: 1.281234 \n",
      "Batch: 4362. Acc: 0.520544. Loss: 1.328610. Batch_acc: 0.541618. Batch_loss: 1.280616 \n",
      "Batch: 4363. Acc: 0.520550. Loss: 1.328600. Batch_acc: 0.549596. Batch_loss: 1.284397 \n",
      "Batch: 4364. Acc: 0.520550. Loss: 1.328599. Batch_acc: 0.519636. Batch_loss: 1.322797 \n",
      "Batch: 4365. Acc: 0.520549. Loss: 1.328600. Batch_acc: 0.516035. Batch_loss: 1.333023 \n",
      "Batch: 4366. Acc: 0.520554. Loss: 1.328575. Batch_acc: 0.542019. Batch_loss: 1.220017 \n",
      "Batch: 4367. Acc: 0.520554. Loss: 1.328565. Batch_acc: 0.521064. Batch_loss: 1.287051 \n",
      "Batch: 4368. Acc: 0.520559. Loss: 1.328554. Batch_acc: 0.541913. Batch_loss: 1.280667 \n",
      "Batch: 4369. Acc: 0.520563. Loss: 1.328544. Batch_acc: 0.537339. Batch_loss: 1.285024 \n",
      "Batch: 4370. Acc: 0.520566. Loss: 1.328543. Batch_acc: 0.532504. Batch_loss: 1.323727 \n",
      "Batch: 4371. Acc: 0.520570. Loss: 1.328533. Batch_acc: 0.540694. Batch_loss: 1.287642 \n",
      "Batch: 4372. Acc: 0.520572. Loss: 1.328529. Batch_acc: 0.527761. Batch_loss: 1.307475 \n",
      "Batch: 4373. Acc: 0.520575. Loss: 1.328515. Batch_acc: 0.535817. Batch_loss: 1.270473 \n",
      "Batch: 4374. Acc: 0.520575. Loss: 1.328510. Batch_acc: 0.519208. Batch_loss: 1.303495 \n",
      "Batch: 4375. Acc: 0.520576. Loss: 1.328511. Batch_acc: 0.524713. Batch_loss: 1.335663 \n",
      "Batch: 4376. Acc: 0.520581. Loss: 1.328500. Batch_acc: 0.543008. Batch_loss: 1.278214 \n",
      "Batch: 4377. Acc: 0.520582. Loss: 1.328497. Batch_acc: 0.523615. Batch_loss: 1.313350 \n",
      "Batch: 4378. Acc: 0.520587. Loss: 1.328477. Batch_acc: 0.543069. Batch_loss: 1.243293 \n",
      "Batch: 4379. Acc: 0.520592. Loss: 1.328464. Batch_acc: 0.542182. Batch_loss: 1.273689 \n",
      "Batch: 4380. Acc: 0.520598. Loss: 1.328454. Batch_acc: 0.545244. Batch_loss: 1.282785 \n",
      "Batch: 4381. Acc: 0.520598. Loss: 1.328458. Batch_acc: 0.520185. Batch_loss: 1.344876 \n",
      "Batch: 4382. Acc: 0.520601. Loss: 1.328455. Batch_acc: 0.536412. Batch_loss: 1.315080 \n",
      "Batch: 4383. Acc: 0.520605. Loss: 1.328442. Batch_acc: 0.535838. Batch_loss: 1.271059 \n",
      "Batch: 4384. Acc: 0.520606. Loss: 1.328433. Batch_acc: 0.528907. Batch_loss: 1.289496 \n",
      "Batch: 4385. Acc: 0.520612. Loss: 1.328415. Batch_acc: 0.544230. Batch_loss: 1.251271 \n",
      "Batch: 4386. Acc: 0.520614. Loss: 1.328409. Batch_acc: 0.531927. Batch_loss: 1.301075 \n",
      "Batch: 4387. Acc: 0.520618. Loss: 1.328403. Batch_acc: 0.536385. Batch_loss: 1.299566 \n",
      "Batch: 4388. Acc: 0.520616. Loss: 1.328405. Batch_acc: 0.515031. Batch_loss: 1.337431 \n",
      "Batch: 4389. Acc: 0.520618. Loss: 1.328393. Batch_acc: 0.525057. Batch_loss: 1.276994 \n",
      "Batch: 4390. Acc: 0.520618. Loss: 1.328387. Batch_acc: 0.520930. Batch_loss: 1.302507 \n",
      "Batch: 4391. Acc: 0.520619. Loss: 1.328389. Batch_acc: 0.527241. Batch_loss: 1.336797 \n",
      "Batch: 4392. Acc: 0.520614. Loss: 1.328398. Batch_acc: 0.496516. Batch_loss: 1.369722 \n",
      "Batch: 4393. Acc: 0.520617. Loss: 1.328386. Batch_acc: 0.537493. Batch_loss: 1.272210 \n",
      "Batch: 4394. Acc: 0.520627. Loss: 1.328361. Batch_acc: 0.563751. Batch_loss: 1.221590 \n",
      "Batch: 4395. Acc: 0.520635. Loss: 1.328338. Batch_acc: 0.553872. Batch_loss: 1.230433 \n",
      "Batch: 4396. Acc: 0.520636. Loss: 1.328337. Batch_acc: 0.526559. Batch_loss: 1.322103 \n",
      "Batch: 4397. Acc: 0.520640. Loss: 1.328323. Batch_acc: 0.535694. Batch_loss: 1.267739 \n",
      "Batch: 4398. Acc: 0.520647. Loss: 1.328308. Batch_acc: 0.550370. Batch_loss: 1.265103 \n",
      "Batch: 4399. Acc: 0.520645. Loss: 1.328310. Batch_acc: 0.514620. Batch_loss: 1.334836 \n",
      "Batch: 4400. Acc: 0.520646. Loss: 1.328311. Batch_acc: 0.525056. Batch_loss: 1.334099 \n",
      "Batch: 4401. Acc: 0.520649. Loss: 1.328305. Batch_acc: 0.533908. Batch_loss: 1.299952 \n",
      "Batch: 4402. Acc: 0.520655. Loss: 1.328288. Batch_acc: 0.544582. Batch_loss: 1.253710 \n",
      "Batch: 4403. Acc: 0.520659. Loss: 1.328277. Batch_acc: 0.540462. Batch_loss: 1.283372 \n",
      "Batch: 4404. Acc: 0.520660. Loss: 1.328275. Batch_acc: 0.521893. Batch_loss: 1.315765 \n",
      "Batch: 4405. Acc: 0.520658. Loss: 1.328280. Batch_acc: 0.512776. Batch_loss: 1.350545 \n",
      "Batch: 4406. Acc: 0.520664. Loss: 1.328273. Batch_acc: 0.546398. Batch_loss: 1.298222 \n",
      "Batch: 4407. Acc: 0.520666. Loss: 1.328261. Batch_acc: 0.531125. Batch_loss: 1.277985 \n",
      "Batch: 4408. Acc: 0.520675. Loss: 1.328236. Batch_acc: 0.559773. Batch_loss: 1.218723 \n",
      "Batch: 4409. Acc: 0.520680. Loss: 1.328221. Batch_acc: 0.539920. Batch_loss: 1.262854 \n",
      "Batch: 4410. Acc: 0.520685. Loss: 1.328213. Batch_acc: 0.544977. Batch_loss: 1.293089 \n",
      "Batch: 4411. Acc: 0.520690. Loss: 1.328201. Batch_acc: 0.541455. Batch_loss: 1.272711 \n",
      "Batch: 4412. Acc: 0.520690. Loss: 1.328198. Batch_acc: 0.522740. Batch_loss: 1.317324 \n",
      "Batch: 4413. Acc: 0.520703. Loss: 1.328167. Batch_acc: 0.576136. Batch_loss: 1.192109 \n",
      "Batch: 4414. Acc: 0.520704. Loss: 1.328169. Batch_acc: 0.523380. Batch_loss: 1.335402 \n",
      "Batch: 4415. Acc: 0.520706. Loss: 1.328166. Batch_acc: 0.530286. Batch_loss: 1.316217 \n",
      "Batch: 4416. Acc: 0.520710. Loss: 1.328155. Batch_acc: 0.537927. Batch_loss: 1.277643 \n",
      "Batch: 4417. Acc: 0.520711. Loss: 1.328152. Batch_acc: 0.528280. Batch_loss: 1.318502 \n",
      "Batch: 4418. Acc: 0.520717. Loss: 1.328134. Batch_acc: 0.546023. Batch_loss: 1.249698 \n",
      "Batch: 4419. Acc: 0.520720. Loss: 1.328125. Batch_acc: 0.532821. Batch_loss: 1.284286 \n",
      "Batch: 4420. Acc: 0.520721. Loss: 1.328120. Batch_acc: 0.525522. Batch_loss: 1.308541 \n",
      "Batch: 4421. Acc: 0.520720. Loss: 1.328119. Batch_acc: 0.518841. Batch_loss: 1.322511 \n",
      "Batch: 4422. Acc: 0.520724. Loss: 1.328102. Batch_acc: 0.538101. Batch_loss: 1.251011 \n",
      "Batch: 4423. Acc: 0.520728. Loss: 1.328096. Batch_acc: 0.536249. Batch_loss: 1.300718 \n",
      "Batch: 4424. Acc: 0.520734. Loss: 1.328076. Batch_acc: 0.546083. Batch_loss: 1.240960 \n",
      "Batch: 4425. Acc: 0.520740. Loss: 1.328066. Batch_acc: 0.549496. Batch_loss: 1.280885 \n",
      "Batch: 4426. Acc: 0.520742. Loss: 1.328055. Batch_acc: 0.530892. Batch_loss: 1.279155 \n",
      "Batch: 4427. Acc: 0.520742. Loss: 1.328058. Batch_acc: 0.518667. Batch_loss: 1.343434 \n",
      "Batch: 4428. Acc: 0.520749. Loss: 1.328036. Batch_acc: 0.553348. Batch_loss: 1.230586 \n",
      "Batch: 4429. Acc: 0.520751. Loss: 1.328030. Batch_acc: 0.530415. Batch_loss: 1.300416 \n",
      "Batch: 4430. Acc: 0.520756. Loss: 1.328016. Batch_acc: 0.540870. Batch_loss: 1.267077 \n",
      "Batch: 4431. Acc: 0.520758. Loss: 1.328013. Batch_acc: 0.530636. Batch_loss: 1.316968 \n",
      "Batch: 4432. Acc: 0.520757. Loss: 1.328017. Batch_acc: 0.517898. Batch_loss: 1.345068 \n",
      "Batch: 4433. Acc: 0.520762. Loss: 1.328001. Batch_acc: 0.542155. Batch_loss: 1.254220 \n",
      "Batch: 4434. Acc: 0.520762. Loss: 1.328000. Batch_acc: 0.520205. Batch_loss: 1.325844 \n",
      "Batch: 4435. Acc: 0.520770. Loss: 1.327978. Batch_acc: 0.555679. Batch_loss: 1.231570 \n",
      "Batch: 4436. Acc: 0.520776. Loss: 1.327964. Batch_acc: 0.546659. Batch_loss: 1.267258 \n",
      "Batch: 4437. Acc: 0.520788. Loss: 1.327930. Batch_acc: 0.575056. Batch_loss: 1.179151 \n",
      "Batch: 4438. Acc: 0.520789. Loss: 1.327929. Batch_acc: 0.524083. Batch_loss: 1.321283 \n",
      "Batch: 4439. Acc: 0.520789. Loss: 1.327932. Batch_acc: 0.519690. Batch_loss: 1.342124 \n",
      "Batch: 4440. Acc: 0.520792. Loss: 1.327920. Batch_acc: 0.533256. Batch_loss: 1.277585 \n",
      "Batch: 4441. Acc: 0.520793. Loss: 1.327914. Batch_acc: 0.524758. Batch_loss: 1.298173 \n",
      "Batch: 4442. Acc: 0.520798. Loss: 1.327903. Batch_acc: 0.544931. Batch_loss: 1.283072 \n",
      "Batch: 4443. Acc: 0.520800. Loss: 1.327900. Batch_acc: 0.530135. Batch_loss: 1.313179 \n",
      "Batch: 4444. Acc: 0.520801. Loss: 1.327895. Batch_acc: 0.525522. Batch_loss: 1.303337 \n",
      "Batch: 4445. Acc: 0.520803. Loss: 1.327889. Batch_acc: 0.530409. Batch_loss: 1.301731 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4446. Acc: 0.520802. Loss: 1.327889. Batch_acc: 0.516464. Batch_loss: 1.327603 \n",
      "Batch: 4447. Acc: 0.520806. Loss: 1.327870. Batch_acc: 0.536836. Batch_loss: 1.243311 \n",
      "Batch: 4448. Acc: 0.520805. Loss: 1.327873. Batch_acc: 0.517202. Batch_loss: 1.342170 \n",
      "Batch: 4449. Acc: 0.520809. Loss: 1.327859. Batch_acc: 0.535795. Batch_loss: 1.267641 \n",
      "Batch: 4450. Acc: 0.520810. Loss: 1.327852. Batch_acc: 0.524868. Batch_loss: 1.293567 \n",
      "Batch: 4451. Acc: 0.520806. Loss: 1.327860. Batch_acc: 0.503505. Batch_loss: 1.364444 \n",
      "Batch: 4452. Acc: 0.520805. Loss: 1.327861. Batch_acc: 0.519366. Batch_loss: 1.334157 \n",
      "Batch: 4453. Acc: 0.520813. Loss: 1.327845. Batch_acc: 0.554204. Batch_loss: 1.258585 \n",
      "Batch: 4454. Acc: 0.520814. Loss: 1.327847. Batch_acc: 0.525539. Batch_loss: 1.335647 \n",
      "Batch: 4455. Acc: 0.520817. Loss: 1.327834. Batch_acc: 0.534130. Batch_loss: 1.272630 \n",
      "Batch: 4456. Acc: 0.520822. Loss: 1.327820. Batch_acc: 0.542776. Batch_loss: 1.263576 \n",
      "Batch: 4457. Acc: 0.520826. Loss: 1.327811. Batch_acc: 0.537435. Batch_loss: 1.287319 \n",
      "Batch: 4458. Acc: 0.520824. Loss: 1.327809. Batch_acc: 0.512629. Batch_loss: 1.321169 \n",
      "Batch: 4459. Acc: 0.520821. Loss: 1.327811. Batch_acc: 0.505651. Batch_loss: 1.335574 \n",
      "Batch: 4460. Acc: 0.520825. Loss: 1.327803. Batch_acc: 0.538287. Batch_loss: 1.295033 \n",
      "Batch: 4461. Acc: 0.520829. Loss: 1.327794. Batch_acc: 0.538902. Batch_loss: 1.286070 \n",
      "Batch: 4462. Acc: 0.520828. Loss: 1.327795. Batch_acc: 0.518065. Batch_loss: 1.330554 \n",
      "Batch: 4463. Acc: 0.520835. Loss: 1.327776. Batch_acc: 0.550485. Batch_loss: 1.246369 \n",
      "Batch: 4464. Acc: 0.520839. Loss: 1.327766. Batch_acc: 0.538022. Batch_loss: 1.281545 \n",
      "Batch: 4465. Acc: 0.520846. Loss: 1.327750. Batch_acc: 0.550857. Batch_loss: 1.257500 \n",
      "Batch: 4466. Acc: 0.520846. Loss: 1.327752. Batch_acc: 0.521425. Batch_loss: 1.336702 \n",
      "Batch: 4467. Acc: 0.520848. Loss: 1.327752. Batch_acc: 0.529651. Batch_loss: 1.328075 \n",
      "Batch: 4468. Acc: 0.520851. Loss: 1.327735. Batch_acc: 0.536348. Batch_loss: 1.253791 \n",
      "Batch: 4469. Acc: 0.520856. Loss: 1.327723. Batch_acc: 0.543478. Batch_loss: 1.272310 \n",
      "Batch: 4470. Acc: 0.520860. Loss: 1.327713. Batch_acc: 0.537703. Batch_loss: 1.286164 \n",
      "Batch: 4471. Acc: 0.520858. Loss: 1.327715. Batch_acc: 0.511945. Batch_loss: 1.336376 \n",
      "Batch: 4472. Acc: 0.520862. Loss: 1.327708. Batch_acc: 0.538462. Batch_loss: 1.296747 \n",
      "Batch: 4473. Acc: 0.520864. Loss: 1.327699. Batch_acc: 0.530435. Batch_loss: 1.285563 \n",
      "Batch: 4474. Acc: 0.520872. Loss: 1.327686. Batch_acc: 0.555242. Batch_loss: 1.269644 \n",
      "Batch: 4475. Acc: 0.520875. Loss: 1.327675. Batch_acc: 0.534659. Batch_loss: 1.279894 \n",
      "Batch: 4476. Acc: 0.520880. Loss: 1.327661. Batch_acc: 0.544109. Batch_loss: 1.263559 \n",
      "Batch: 4477. Acc: 0.520883. Loss: 1.327651. Batch_acc: 0.533565. Batch_loss: 1.283985 \n",
      "Batch: 4478. Acc: 0.520884. Loss: 1.327644. Batch_acc: 0.527346. Batch_loss: 1.295492 \n",
      "Batch: 4479. Acc: 0.520887. Loss: 1.327639. Batch_acc: 0.533599. Batch_loss: 1.306196 \n",
      "Batch: 4480. Acc: 0.520895. Loss: 1.327619. Batch_acc: 0.554732. Batch_loss: 1.238509 \n",
      "Batch: 4481. Acc: 0.520898. Loss: 1.327609. Batch_acc: 0.532948. Batch_loss: 1.281136 \n",
      "Batch: 4482. Acc: 0.520896. Loss: 1.327605. Batch_acc: 0.511424. Batch_loss: 1.308404 \n",
      "Batch: 4483. Acc: 0.520899. Loss: 1.327595. Batch_acc: 0.537919. Batch_loss: 1.280961 \n",
      "Batch: 4484. Acc: 0.520902. Loss: 1.327586. Batch_acc: 0.532437. Batch_loss: 1.286314 \n",
      "Batch: 4485. Acc: 0.520904. Loss: 1.327578. Batch_acc: 0.529619. Batch_loss: 1.292875 \n",
      "Batch: 4486. Acc: 0.520901. Loss: 1.327579. Batch_acc: 0.508149. Batch_loss: 1.334309 \n",
      "Batch: 4487. Acc: 0.520897. Loss: 1.327582. Batch_acc: 0.505463. Batch_loss: 1.338341 \n",
      "Batch: 4488. Acc: 0.520900. Loss: 1.327577. Batch_acc: 0.530871. Batch_loss: 1.305446 \n",
      "Batch: 4489. Acc: 0.520905. Loss: 1.327561. Batch_acc: 0.545665. Batch_loss: 1.256715 \n",
      "Batch: 4490. Acc: 0.520908. Loss: 1.327558. Batch_acc: 0.534620. Batch_loss: 1.313959 \n",
      "Batch: 4491. Acc: 0.520910. Loss: 1.327549. Batch_acc: 0.529514. Batch_loss: 1.284783 \n",
      "Batch: 4492. Acc: 0.520915. Loss: 1.327530. Batch_acc: 0.543860. Batch_loss: 1.243593 \n",
      "Batch: 4493. Acc: 0.520920. Loss: 1.327515. Batch_acc: 0.544041. Batch_loss: 1.258276 \n",
      "Batch: 4494. Acc: 0.520922. Loss: 1.327505. Batch_acc: 0.529651. Batch_loss: 1.281919 \n",
      "Batch: 4495. Acc: 0.520927. Loss: 1.327486. Batch_acc: 0.542890. Batch_loss: 1.241313 \n",
      "Batch: 4496. Acc: 0.520930. Loss: 1.327476. Batch_acc: 0.532191. Batch_loss: 1.281397 \n",
      "Batch: 4497. Acc: 0.520931. Loss: 1.327475. Batch_acc: 0.526466. Batch_loss: 1.322106 \n",
      "Batch: 4498. Acc: 0.520934. Loss: 1.327471. Batch_acc: 0.533569. Batch_loss: 1.312331 \n",
      "Batch: 4499. Acc: 0.520939. Loss: 1.327464. Batch_acc: 0.545508. Batch_loss: 1.292290 \n",
      "Batch: 4500. Acc: 0.520944. Loss: 1.327452. Batch_acc: 0.544482. Batch_loss: 1.276512 \n",
      "Batch: 4501. Acc: 0.520948. Loss: 1.327439. Batch_acc: 0.536348. Batch_loss: 1.270200 \n",
      "Batch: 4502. Acc: 0.520953. Loss: 1.327431. Batch_acc: 0.543084. Batch_loss: 1.290531 \n",
      "Batch: 4503. Acc: 0.520952. Loss: 1.327430. Batch_acc: 0.520140. Batch_loss: 1.325289 \n",
      "Batch: 4504. Acc: 0.520954. Loss: 1.327428. Batch_acc: 0.526471. Batch_loss: 1.316231 \n",
      "Batch: 4505. Acc: 0.520957. Loss: 1.327421. Batch_acc: 0.533952. Batch_loss: 1.295811 \n",
      "Batch: 4506. Acc: 0.520954. Loss: 1.327421. Batch_acc: 0.507532. Batch_loss: 1.325463 \n",
      "Batch: 4507. Acc: 0.520952. Loss: 1.327418. Batch_acc: 0.513905. Batch_loss: 1.316688 \n",
      "Batch: 4508. Acc: 0.520961. Loss: 1.327400. Batch_acc: 0.560907. Batch_loss: 1.247978 \n",
      "Batch: 4509. Acc: 0.520967. Loss: 1.327393. Batch_acc: 0.546498. Batch_loss: 1.296476 \n",
      "Batch: 4510. Acc: 0.520970. Loss: 1.327382. Batch_acc: 0.537763. Batch_loss: 1.274230 \n",
      "Batch: 4511. Acc: 0.520973. Loss: 1.327377. Batch_acc: 0.530733. Batch_loss: 1.306217 \n",
      "Batch: 4512. Acc: 0.520972. Loss: 1.327382. Batch_acc: 0.516393. Batch_loss: 1.350963 \n",
      "Batch: 4513. Acc: 0.520974. Loss: 1.327385. Batch_acc: 0.534144. Batch_loss: 1.342322 \n",
      "Batch: 4514. Acc: 0.520976. Loss: 1.327380. Batch_acc: 0.529210. Batch_loss: 1.304338 \n",
      "Batch: 4515. Acc: 0.520985. Loss: 1.327358. Batch_acc: 0.560022. Batch_loss: 1.231606 \n",
      "Batch: 4516. Acc: 0.520988. Loss: 1.327347. Batch_acc: 0.533333. Batch_loss: 1.275384 \n",
      "Batch: 4517. Acc: 0.520993. Loss: 1.327331. Batch_acc: 0.542108. Batch_loss: 1.258633 \n",
      "Batch: 4518. Acc: 0.520998. Loss: 1.327323. Batch_acc: 0.543890. Batch_loss: 1.288149 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.5209978684421757. Loss per char: 1.3273225437585565. Time: 1627221607.8907819\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 17, 15, 19, 25,\n",
      "         1, 66, 79, 69,  1, 23, 24, 26, 22, 24, 17, 15, 21, 17, 22, 25, 17, 22,\n",
      "        15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.520998. Loss: 1.327311. Batch_acc: 0.523397. Batch_loss: 1.273156 \n",
      "Batch: 4520. Acc: 0.521001. Loss: 1.327309. Batch_acc: 0.532816. Batch_loss: 1.320406 \n",
      "Batch: 4521. Acc: 0.521005. Loss: 1.327302. Batch_acc: 0.539300. Batch_loss: 1.297092 \n",
      "Batch: 4522. Acc: 0.521012. Loss: 1.327289. Batch_acc: 0.550961. Batch_loss: 1.266588 \n",
      "Batch: 4523. Acc: 0.521020. Loss: 1.327277. Batch_acc: 0.557020. Batch_loss: 1.274631 \n",
      "Batch: 4524. Acc: 0.521030. Loss: 1.327257. Batch_acc: 0.569747. Batch_loss: 1.230720 \n",
      "Batch: 4525. Acc: 0.521036. Loss: 1.327240. Batch_acc: 0.550464. Batch_loss: 1.250360 \n",
      "Batch: 4526. Acc: 0.521039. Loss: 1.327236. Batch_acc: 0.533333. Batch_loss: 1.310877 \n",
      "Batch: 4527. Acc: 0.521046. Loss: 1.327215. Batch_acc: 0.553279. Batch_loss: 1.228634 \n",
      "Batch: 4528. Acc: 0.521048. Loss: 1.327214. Batch_acc: 0.527242. Batch_loss: 1.325962 \n",
      "Batch: 4529. Acc: 0.521053. Loss: 1.327201. Batch_acc: 0.545506. Batch_loss: 1.267348 \n",
      "Batch: 4530. Acc: 0.521057. Loss: 1.327201. Batch_acc: 0.537978. Batch_loss: 1.327841 \n",
      "Batch: 4531. Acc: 0.521055. Loss: 1.327215. Batch_acc: 0.513002. Batch_loss: 1.391086 \n",
      "Batch: 4532. Acc: 0.521052. Loss: 1.327219. Batch_acc: 0.508304. Batch_loss: 1.345235 \n",
      "Batch: 4533. Acc: 0.521056. Loss: 1.327212. Batch_acc: 0.535195. Batch_loss: 1.296425 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4534. Acc: 0.521059. Loss: 1.327200. Batch_acc: 0.534726. Batch_loss: 1.275256 \n",
      "Batch: 4535. Acc: 0.521059. Loss: 1.327202. Batch_acc: 0.522042. Batch_loss: 1.333686 \n",
      "Batch: 4536. Acc: 0.521064. Loss: 1.327186. Batch_acc: 0.546801. Batch_loss: 1.254499 \n",
      "Batch: 4537. Acc: 0.521067. Loss: 1.327177. Batch_acc: 0.532324. Batch_loss: 1.282732 \n",
      "Batch: 4538. Acc: 0.521069. Loss: 1.327163. Batch_acc: 0.529686. Batch_loss: 1.263774 \n",
      "Batch: 4539. Acc: 0.521069. Loss: 1.327153. Batch_acc: 0.522857. Batch_loss: 1.284368 \n",
      "Batch: 4540. Acc: 0.521072. Loss: 1.327144. Batch_acc: 0.535838. Batch_loss: 1.282885 \n",
      "Batch: 4541. Acc: 0.521075. Loss: 1.327133. Batch_acc: 0.532876. Batch_loss: 1.278155 \n",
      "Batch: 4542. Acc: 0.521083. Loss: 1.327111. Batch_acc: 0.555876. Batch_loss: 1.227775 \n",
      "Batch: 4543. Acc: 0.521086. Loss: 1.327102. Batch_acc: 0.535411. Batch_loss: 1.288422 \n",
      "Batch: 4544. Acc: 0.521079. Loss: 1.327119. Batch_acc: 0.488889. Batch_loss: 1.406151 \n",
      "Batch: 4545. Acc: 0.521085. Loss: 1.327100. Batch_acc: 0.550758. Batch_loss: 1.236756 \n",
      "Batch: 4546. Acc: 0.521091. Loss: 1.327088. Batch_acc: 0.546034. Batch_loss: 1.273336 \n",
      "Batch: 4547. Acc: 0.521098. Loss: 1.327066. Batch_acc: 0.552018. Batch_loss: 1.226758 \n",
      "Batch: 4548. Acc: 0.521098. Loss: 1.327066. Batch_acc: 0.521487. Batch_loss: 1.331075 \n",
      "Batch: 4549. Acc: 0.521106. Loss: 1.327047. Batch_acc: 0.558046. Batch_loss: 1.236336 \n",
      "Batch: 4550. Acc: 0.521111. Loss: 1.327033. Batch_acc: 0.545505. Batch_loss: 1.267766 \n",
      "Batch: 4551. Acc: 0.521109. Loss: 1.327037. Batch_acc: 0.509554. Batch_loss: 1.345324 \n",
      "Batch: 4552. Acc: 0.521111. Loss: 1.327030. Batch_acc: 0.533032. Batch_loss: 1.297451 \n",
      "Batch: 4553. Acc: 0.521114. Loss: 1.327029. Batch_acc: 0.533528. Batch_loss: 1.322141 \n",
      "Batch: 4554. Acc: 0.521119. Loss: 1.327018. Batch_acc: 0.542316. Batch_loss: 1.279199 \n",
      "Batch: 4555. Acc: 0.521116. Loss: 1.327023. Batch_acc: 0.506166. Batch_loss: 1.346380 \n",
      "Batch: 4556. Acc: 0.521122. Loss: 1.327007. Batch_acc: 0.549451. Batch_loss: 1.254026 \n",
      "Batch: 4557. Acc: 0.521120. Loss: 1.327012. Batch_acc: 0.511226. Batch_loss: 1.352557 \n",
      "Batch: 4558. Acc: 0.521128. Loss: 1.326986. Batch_acc: 0.558553. Batch_loss: 1.207887 \n",
      "Batch: 4559. Acc: 0.521132. Loss: 1.326977. Batch_acc: 0.538015. Batch_loss: 1.287114 \n",
      "Batch: 4560. Acc: 0.521128. Loss: 1.326984. Batch_acc: 0.502342. Batch_loss: 1.357100 \n",
      "Batch: 4561. Acc: 0.521135. Loss: 1.326966. Batch_acc: 0.555620. Batch_loss: 1.242646 \n",
      "Batch: 4562. Acc: 0.521142. Loss: 1.326951. Batch_acc: 0.551127. Batch_loss: 1.261761 \n",
      "Batch: 4563. Acc: 0.521139. Loss: 1.326957. Batch_acc: 0.507683. Batch_loss: 1.354479 \n",
      "Batch: 4564. Acc: 0.521140. Loss: 1.326942. Batch_acc: 0.524460. Batch_loss: 1.256277 \n",
      "Batch: 4565. Acc: 0.521147. Loss: 1.326915. Batch_acc: 0.556125. Batch_loss: 1.205812 \n",
      "Batch: 4566. Acc: 0.521148. Loss: 1.326910. Batch_acc: 0.524334. Batch_loss: 1.305176 \n",
      "Batch: 4567. Acc: 0.521153. Loss: 1.326900. Batch_acc: 0.545775. Batch_loss: 1.279332 \n",
      "Batch: 4568. Acc: 0.521157. Loss: 1.326888. Batch_acc: 0.536642. Batch_loss: 1.273167 \n",
      "Batch: 4569. Acc: 0.521160. Loss: 1.326878. Batch_acc: 0.538724. Batch_loss: 1.279207 \n",
      "Batch: 4570. Acc: 0.521165. Loss: 1.326867. Batch_acc: 0.540359. Batch_loss: 1.280613 \n",
      "Batch: 4571. Acc: 0.521174. Loss: 1.326845. Batch_acc: 0.561058. Batch_loss: 1.225990 \n",
      "Batch: 4572. Acc: 0.521172. Loss: 1.326848. Batch_acc: 0.515188. Batch_loss: 1.343959 \n",
      "Batch: 4573. Acc: 0.521173. Loss: 1.326845. Batch_acc: 0.523397. Batch_loss: 1.309463 \n",
      "Batch: 4574. Acc: 0.521175. Loss: 1.326837. Batch_acc: 0.530114. Batch_loss: 1.293523 \n",
      "Batch: 4575. Acc: 0.521176. Loss: 1.326829. Batch_acc: 0.528005. Batch_loss: 1.287468 \n",
      "Batch: 4576. Acc: 0.521182. Loss: 1.326816. Batch_acc: 0.545297. Batch_loss: 1.267405 \n",
      "Batch: 4577. Acc: 0.521186. Loss: 1.326811. Batch_acc: 0.542759. Batch_loss: 1.305448 \n",
      "Batch: 4578. Acc: 0.521190. Loss: 1.326803. Batch_acc: 0.539683. Batch_loss: 1.290809 \n",
      "Batch: 4579. Acc: 0.521196. Loss: 1.326790. Batch_acc: 0.548894. Batch_loss: 1.264598 \n",
      "Batch: 4580. Acc: 0.521200. Loss: 1.326785. Batch_acc: 0.535553. Batch_loss: 1.304312 \n",
      "Batch: 4581. Acc: 0.521200. Loss: 1.326786. Batch_acc: 0.520761. Batch_loss: 1.331721 \n",
      "Batch: 4582. Acc: 0.521203. Loss: 1.326773. Batch_acc: 0.538068. Batch_loss: 1.268323 \n",
      "Batch: 4583. Acc: 0.521211. Loss: 1.326749. Batch_acc: 0.558059. Batch_loss: 1.215151 \n",
      "Batch: 4584. Acc: 0.521216. Loss: 1.326739. Batch_acc: 0.542314. Batch_loss: 1.284523 \n",
      "Batch: 4585. Acc: 0.521223. Loss: 1.326724. Batch_acc: 0.552480. Batch_loss: 1.254291 \n",
      "Batch: 4586. Acc: 0.521225. Loss: 1.326717. Batch_acc: 0.531286. Batch_loss: 1.296651 \n",
      "Batch: 4587. Acc: 0.521228. Loss: 1.326703. Batch_acc: 0.535918. Batch_loss: 1.262795 \n",
      "Batch: 4588. Acc: 0.521229. Loss: 1.326689. Batch_acc: 0.527378. Batch_loss: 1.260768 \n",
      "Batch: 4589. Acc: 0.521240. Loss: 1.326663. Batch_acc: 0.568259. Batch_loss: 1.208604 \n",
      "Batch: 4590. Acc: 0.521240. Loss: 1.326663. Batch_acc: 0.521127. Batch_loss: 1.327964 \n",
      "Batch: 4591. Acc: 0.521251. Loss: 1.326635. Batch_acc: 0.568681. Batch_loss: 1.203149 \n",
      "Batch: 4592. Acc: 0.521254. Loss: 1.326626. Batch_acc: 0.537592. Batch_loss: 1.286249 \n",
      "Batch: 4593. Acc: 0.521258. Loss: 1.326613. Batch_acc: 0.537507. Batch_loss: 1.267135 \n",
      "Batch: 4594. Acc: 0.521258. Loss: 1.326616. Batch_acc: 0.524289. Batch_loss: 1.342081 \n",
      "Batch: 4595. Acc: 0.521261. Loss: 1.326610. Batch_acc: 0.530864. Batch_loss: 1.298294 \n",
      "Batch: 4596. Acc: 0.521261. Loss: 1.326604. Batch_acc: 0.525247. Batch_loss: 1.303121 \n",
      "Batch: 4597. Acc: 0.521262. Loss: 1.326600. Batch_acc: 0.525143. Batch_loss: 1.305499 \n",
      "Batch: 4598. Acc: 0.521269. Loss: 1.326580. Batch_acc: 0.551140. Batch_loss: 1.235744 \n",
      "Batch: 4599. Acc: 0.521272. Loss: 1.326569. Batch_acc: 0.537887. Batch_loss: 1.272673 \n",
      "Batch: 4600. Acc: 0.521270. Loss: 1.326568. Batch_acc: 0.509380. Batch_loss: 1.321487 \n",
      "Batch: 4601. Acc: 0.521274. Loss: 1.326561. Batch_acc: 0.542029. Batch_loss: 1.297323 \n",
      "Batch: 4602. Acc: 0.521266. Loss: 1.326581. Batch_acc: 0.482290. Batch_loss: 1.417891 \n",
      "Batch: 4603. Acc: 0.521269. Loss: 1.326570. Batch_acc: 0.534805. Batch_loss: 1.279488 \n",
      "Batch: 4604. Acc: 0.521274. Loss: 1.326553. Batch_acc: 0.545352. Batch_loss: 1.249720 \n",
      "Batch: 4605. Acc: 0.521273. Loss: 1.326551. Batch_acc: 0.514302. Batch_loss: 1.318199 \n",
      "Batch: 4606. Acc: 0.521277. Loss: 1.326536. Batch_acc: 0.541040. Batch_loss: 1.256171 \n",
      "Batch: 4607. Acc: 0.521275. Loss: 1.326536. Batch_acc: 0.513234. Batch_loss: 1.325319 \n",
      "Batch: 4608. Acc: 0.521277. Loss: 1.326532. Batch_acc: 0.528334. Batch_loss: 1.310171 \n",
      "Batch: 4609. Acc: 0.521282. Loss: 1.326515. Batch_acc: 0.546545. Batch_loss: 1.247353 \n",
      "Batch: 4610. Acc: 0.521284. Loss: 1.326508. Batch_acc: 0.527499. Batch_loss: 1.295165 \n",
      "Batch: 4611. Acc: 0.521287. Loss: 1.326501. Batch_acc: 0.536401. Batch_loss: 1.290651 \n",
      "Batch: 4612. Acc: 0.521288. Loss: 1.326498. Batch_acc: 0.526494. Batch_loss: 1.316103 \n",
      "Batch: 4613. Acc: 0.521286. Loss: 1.326496. Batch_acc: 0.513279. Batch_loss: 1.316460 \n",
      "Batch: 4614. Acc: 0.521288. Loss: 1.326496. Batch_acc: 0.528037. Batch_loss: 1.325119 \n",
      "Batch: 4615. Acc: 0.521295. Loss: 1.326472. Batch_acc: 0.554489. Batch_loss: 1.216427 \n",
      "Batch: 4616. Acc: 0.521302. Loss: 1.326455. Batch_acc: 0.553846. Batch_loss: 1.250810 \n",
      "Batch: 4617. Acc: 0.521302. Loss: 1.326456. Batch_acc: 0.519129. Batch_loss: 1.330309 \n",
      "Batch: 4618. Acc: 0.521306. Loss: 1.326439. Batch_acc: 0.539966. Batch_loss: 1.252369 \n",
      "Batch: 4619. Acc: 0.521303. Loss: 1.326445. Batch_acc: 0.507357. Batch_loss: 1.354943 \n",
      "Batch: 4620. Acc: 0.521308. Loss: 1.326430. Batch_acc: 0.546380. Batch_loss: 1.253959 \n",
      "Batch: 4621. Acc: 0.521311. Loss: 1.326420. Batch_acc: 0.534665. Batch_loss: 1.282874 \n",
      "Batch: 4622. Acc: 0.521315. Loss: 1.326401. Batch_acc: 0.540603. Batch_loss: 1.237621 \n",
      "Batch: 4623. Acc: 0.521315. Loss: 1.326402. Batch_acc: 0.518052. Batch_loss: 1.330148 \n",
      "Batch: 4624. Acc: 0.521319. Loss: 1.326388. Batch_acc: 0.541714. Batch_loss: 1.263951 \n",
      "Batch: 4625. Acc: 0.521321. Loss: 1.326391. Batch_acc: 0.528077. Batch_loss: 1.338165 \n",
      "Batch: 4626. Acc: 0.521322. Loss: 1.326386. Batch_acc: 0.529477. Batch_loss: 1.302630 \n",
      "Batch: 4627. Acc: 0.521326. Loss: 1.326382. Batch_acc: 0.536932. Batch_loss: 1.307183 \n",
      "Batch: 4628. Acc: 0.521331. Loss: 1.326373. Batch_acc: 0.543849. Batch_loss: 1.286027 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4629. Acc: 0.521328. Loss: 1.326377. Batch_acc: 0.506571. Batch_loss: 1.344281 \n",
      "Batch: 4630. Acc: 0.521329. Loss: 1.326369. Batch_acc: 0.530086. Batch_loss: 1.291002 \n",
      "Batch: 4631. Acc: 0.521332. Loss: 1.326360. Batch_acc: 0.532418. Batch_loss: 1.284354 \n",
      "Batch: 4632. Acc: 0.521338. Loss: 1.326346. Batch_acc: 0.547674. Batch_loss: 1.264092 \n",
      "Batch: 4633. Acc: 0.521340. Loss: 1.326338. Batch_acc: 0.532164. Batch_loss: 1.287554 \n",
      "Batch: 4634. Acc: 0.521345. Loss: 1.326330. Batch_acc: 0.545198. Batch_loss: 1.287760 \n",
      "Batch: 4635. Acc: 0.521344. Loss: 1.326335. Batch_acc: 0.517836. Batch_loss: 1.351285 \n",
      "Batch: 4636. Acc: 0.521344. Loss: 1.326335. Batch_acc: 0.518603. Batch_loss: 1.327903 \n",
      "Batch: 4637. Acc: 0.521349. Loss: 1.326321. Batch_acc: 0.543353. Batch_loss: 1.262502 \n",
      "Batch: 4638. Acc: 0.521349. Loss: 1.326322. Batch_acc: 0.523242. Batch_loss: 1.330138 \n",
      "Batch: 4639. Acc: 0.521349. Loss: 1.326318. Batch_acc: 0.521176. Batch_loss: 1.306866 \n",
      "Batch: 4640. Acc: 0.521355. Loss: 1.326301. Batch_acc: 0.550343. Batch_loss: 1.248782 \n",
      "Batch: 4641. Acc: 0.521358. Loss: 1.326291. Batch_acc: 0.533143. Batch_loss: 1.276835 \n",
      "Batch: 4642. Acc: 0.521362. Loss: 1.326279. Batch_acc: 0.538813. Batch_loss: 1.274284 \n",
      "Batch: 4643. Acc: 0.521365. Loss: 1.326274. Batch_acc: 0.538895. Batch_loss: 1.300991 \n",
      "Batch: 4644. Acc: 0.521365. Loss: 1.326275. Batch_acc: 0.521233. Batch_loss: 1.333490 \n",
      "Batch: 4645. Acc: 0.521371. Loss: 1.326264. Batch_acc: 0.546128. Batch_loss: 1.272747 \n",
      "Batch: 4646. Acc: 0.521369. Loss: 1.326264. Batch_acc: 0.514077. Batch_loss: 1.328253 \n",
      "Batch: 4647. Acc: 0.521369. Loss: 1.326259. Batch_acc: 0.519106. Batch_loss: 1.301010 \n",
      "Batch: 4648. Acc: 0.521373. Loss: 1.326253. Batch_acc: 0.541788. Batch_loss: 1.298433 \n",
      "Batch: 4649. Acc: 0.521379. Loss: 1.326238. Batch_acc: 0.548071. Batch_loss: 1.256403 \n",
      "Batch: 4650. Acc: 0.521382. Loss: 1.326229. Batch_acc: 0.538329. Batch_loss: 1.284293 \n",
      "Batch: 4651. Acc: 0.521385. Loss: 1.326224. Batch_acc: 0.531340. Batch_loss: 1.301925 \n",
      "Batch: 4652. Acc: 0.521382. Loss: 1.326226. Batch_acc: 0.509510. Batch_loss: 1.337536 \n",
      "Batch: 4653. Acc: 0.521387. Loss: 1.326210. Batch_acc: 0.544092. Batch_loss: 1.252367 \n",
      "Batch: 4654. Acc: 0.521388. Loss: 1.326202. Batch_acc: 0.527762. Batch_loss: 1.289464 \n",
      "Batch: 4655. Acc: 0.521388. Loss: 1.326197. Batch_acc: 0.519767. Batch_loss: 1.300338 \n",
      "Batch: 4656. Acc: 0.521389. Loss: 1.326193. Batch_acc: 0.528245. Batch_loss: 1.305339 \n",
      "Batch: 4657. Acc: 0.521390. Loss: 1.326187. Batch_acc: 0.525857. Batch_loss: 1.299636 \n",
      "Batch: 4658. Acc: 0.521391. Loss: 1.326185. Batch_acc: 0.525626. Batch_loss: 1.314994 \n",
      "Batch: 4659. Acc: 0.521396. Loss: 1.326175. Batch_acc: 0.545294. Batch_loss: 1.278755 \n",
      "Batch: 4660. Acc: 0.521403. Loss: 1.326159. Batch_acc: 0.554974. Batch_loss: 1.253050 \n",
      "Batch: 4661. Acc: 0.521405. Loss: 1.326156. Batch_acc: 0.531778. Batch_loss: 1.312839 \n",
      "Batch: 4662. Acc: 0.521406. Loss: 1.326156. Batch_acc: 0.522714. Batch_loss: 1.326426 \n",
      "Batch: 4663. Acc: 0.521412. Loss: 1.326142. Batch_acc: 0.550084. Batch_loss: 1.262565 \n",
      "Batch: 4664. Acc: 0.521416. Loss: 1.326132. Batch_acc: 0.541449. Batch_loss: 1.277585 \n",
      "Batch: 4665. Acc: 0.521411. Loss: 1.326136. Batch_acc: 0.499145. Batch_loss: 1.344735 \n",
      "Batch: 4666. Acc: 0.521417. Loss: 1.326122. Batch_acc: 0.547493. Batch_loss: 1.257027 \n",
      "Batch: 4667. Acc: 0.521415. Loss: 1.326128. Batch_acc: 0.512123. Batch_loss: 1.357286 \n",
      "Batch: 4668. Acc: 0.521426. Loss: 1.326101. Batch_acc: 0.569188. Batch_loss: 1.202770 \n",
      "Batch: 4669. Acc: 0.521430. Loss: 1.326093. Batch_acc: 0.540401. Batch_loss: 1.290985 \n",
      "Batch: 4670. Acc: 0.521431. Loss: 1.326087. Batch_acc: 0.527968. Batch_loss: 1.297174 \n",
      "Batch: 4671. Acc: 0.521436. Loss: 1.326073. Batch_acc: 0.543800. Batch_loss: 1.262163 \n",
      "Batch: 4672. Acc: 0.521440. Loss: 1.326066. Batch_acc: 0.542857. Batch_loss: 1.290603 \n",
      "Batch: 4673. Acc: 0.521447. Loss: 1.326046. Batch_acc: 0.552036. Batch_loss: 1.234528 \n",
      "Batch: 4674. Acc: 0.521449. Loss: 1.326032. Batch_acc: 0.530659. Batch_loss: 1.261168 \n",
      "Batch: 4675. Acc: 0.521454. Loss: 1.326020. Batch_acc: 0.543353. Batch_loss: 1.270645 \n",
      "Batch: 4676. Acc: 0.521462. Loss: 1.325994. Batch_acc: 0.557889. Batch_loss: 1.204134 \n",
      "Batch: 4677. Acc: 0.521465. Loss: 1.325981. Batch_acc: 0.537391. Batch_loss: 1.265038 \n",
      "Batch: 4678. Acc: 0.521466. Loss: 1.325974. Batch_acc: 0.525978. Batch_loss: 1.293780 \n",
      "Batch: 4679. Acc: 0.521470. Loss: 1.325964. Batch_acc: 0.539942. Batch_loss: 1.277527 \n",
      "Batch: 4680. Acc: 0.521475. Loss: 1.325955. Batch_acc: 0.544438. Batch_loss: 1.283163 \n",
      "Batch: 4681. Acc: 0.521475. Loss: 1.325950. Batch_acc: 0.520737. Batch_loss: 1.302938 \n",
      "Batch: 4682. Acc: 0.521476. Loss: 1.325944. Batch_acc: 0.529378. Batch_loss: 1.297885 \n",
      "Batch: 4683. Acc: 0.521476. Loss: 1.325948. Batch_acc: 0.522779. Batch_loss: 1.344164 \n",
      "Batch: 4684. Acc: 0.521487. Loss: 1.325923. Batch_acc: 0.569642. Batch_loss: 1.212593 \n",
      "Batch: 4685. Acc: 0.521489. Loss: 1.325917. Batch_acc: 0.531682. Batch_loss: 1.295298 \n",
      "Batch: 4686. Acc: 0.521495. Loss: 1.325903. Batch_acc: 0.549238. Batch_loss: 1.260613 \n",
      "Batch: 4687. Acc: 0.521496. Loss: 1.325897. Batch_acc: 0.535388. Batch_loss: 1.266445 \n",
      "[Training]  loss: 1.325896715074411, ppl:  3.765560, accuracy: 52.150 %, elapse: 3856972.332ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.2161390402148637,  ppl:  3.37414, accuracy: 56.517 %, elapse: 37708.783ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1128.1681060791016ms\n",
      "[ Epoch: 5 / 8, Run Batch: 23440 / None]\n",
      "Batch: 0. Acc: 0.534223. Loss: 1.278074. Batch_acc: 0.534223. Batch_loss: 1.278074 \n",
      "Batch: 1. Acc: 0.539600. Loss: 1.270115. Batch_acc: 0.544980. Batch_loss: 1.262151 \n",
      "Batch: 2. Acc: 0.540214. Loss: 1.273402. Batch_acc: 0.541408. Batch_loss: 1.279786 \n",
      "Batch: 3. Acc: 0.539600. Loss: 1.277361. Batch_acc: 0.537752. Batch_loss: 1.289275 \n",
      "Batch: 4. Acc: 0.533341. Loss: 1.292251. Batch_acc: 0.508752. Batch_loss: 1.350746 \n",
      "Batch: 5. Acc: 0.536222. Loss: 1.282805. Batch_acc: 0.550600. Batch_loss: 1.235665 \n",
      "Batch: 6. Acc: 0.537915. Loss: 1.276326. Batch_acc: 0.547984. Batch_loss: 1.237781 \n",
      "Batch: 7. Acc: 0.538808. Loss: 1.276228. Batch_acc: 0.544992. Batch_loss: 1.275550 \n",
      "Batch: 8. Acc: 0.540565. Loss: 1.275560. Batch_acc: 0.554545. Batch_loss: 1.270242 \n",
      "Batch: 9. Acc: 0.542183. Loss: 1.272720. Batch_acc: 0.556831. Batch_loss: 1.247018 \n",
      "Batch: 10. Acc: 0.543266. Loss: 1.268879. Batch_acc: 0.553985. Batch_loss: 1.230861 \n",
      "Batch: 11. Acc: 0.543693. Loss: 1.265641. Batch_acc: 0.548315. Batch_loss: 1.230584 \n",
      "Batch: 12. Acc: 0.543989. Loss: 1.265747. Batch_acc: 0.547511. Batch_loss: 1.267002 \n",
      "Batch: 13. Acc: 0.545181. Loss: 1.262522. Batch_acc: 0.560684. Batch_loss: 1.220582 \n",
      "Batch: 14. Acc: 0.542518. Loss: 1.268163. Batch_acc: 0.504888. Batch_loss: 1.347890 \n",
      "Batch: 15. Acc: 0.542529. Loss: 1.268136. Batch_acc: 0.542693. Batch_loss: 1.267727 \n",
      "Batch: 16. Acc: 0.542779. Loss: 1.269517. Batch_acc: 0.546812. Batch_loss: 1.291786 \n",
      "Batch: 17. Acc: 0.541454. Loss: 1.272954. Batch_acc: 0.518710. Batch_loss: 1.331924 \n",
      "Batch: 18. Acc: 0.541903. Loss: 1.271643. Batch_acc: 0.549943. Batch_loss: 1.248183 \n",
      "Batch: 19. Acc: 0.541868. Loss: 1.270696. Batch_acc: 0.541190. Batch_loss: 1.252648 \n",
      "Batch: 20. Acc: 0.541634. Loss: 1.273210. Batch_acc: 0.536909. Batch_loss: 1.324021 \n",
      "Batch: 21. Acc: 0.542161. Loss: 1.271573. Batch_acc: 0.553426. Batch_loss: 1.236604 \n",
      "Batch: 22. Acc: 0.542283. Loss: 1.270727. Batch_acc: 0.544983. Batch_loss: 1.251946 \n",
      "Batch: 23. Acc: 0.542292. Loss: 1.269941. Batch_acc: 0.542499. Batch_loss: 1.251904 \n",
      "Batch: 24. Acc: 0.542008. Loss: 1.270857. Batch_acc: 0.535227. Batch_loss: 1.292708 \n",
      "Batch: 25. Acc: 0.541616. Loss: 1.271593. Batch_acc: 0.531805. Batch_loss: 1.290033 \n",
      "Batch: 26. Acc: 0.542400. Loss: 1.269046. Batch_acc: 0.563006. Batch_loss: 1.202079 \n",
      "Batch: 27. Acc: 0.542064. Loss: 1.269238. Batch_acc: 0.532787. Batch_loss: 1.274545 \n",
      "Batch: 28. Acc: 0.541694. Loss: 1.270110. Batch_acc: 0.531357. Batch_loss: 1.294437 \n",
      "Batch: 29. Acc: 0.541395. Loss: 1.270995. Batch_acc: 0.532468. Batch_loss: 1.297461 \n",
      "Batch: 30. Acc: 0.540636. Loss: 1.272756. Batch_acc: 0.517640. Batch_loss: 1.326133 \n",
      "Batch: 31. Acc: 0.541145. Loss: 1.271978. Batch_acc: 0.556890. Batch_loss: 1.247909 \n",
      "Batch: 32. Acc: 0.541043. Loss: 1.272735. Batch_acc: 0.537806. Batch_loss: 1.296753 \n",
      "Batch: 33. Acc: 0.541782. Loss: 1.270986. Batch_acc: 0.565657. Batch_loss: 1.214436 \n",
      "Batch: 34. Acc: 0.541434. Loss: 1.271222. Batch_acc: 0.529647. Batch_loss: 1.279215 \n",
      "Batch: 35. Acc: 0.540757. Loss: 1.272590. Batch_acc: 0.516964. Batch_loss: 1.320706 \n",
      "Batch: 36. Acc: 0.540315. Loss: 1.273794. Batch_acc: 0.524249. Batch_loss: 1.317536 \n",
      "Batch: 37. Acc: 0.540099. Loss: 1.274416. Batch_acc: 0.532062. Batch_loss: 1.297625 \n",
      "Batch: 38. Acc: 0.539736. Loss: 1.274687. Batch_acc: 0.525671. Batch_loss: 1.285185 \n",
      "Batch: 39. Acc: 0.539677. Loss: 1.274791. Batch_acc: 0.537356. Batch_loss: 1.278841 \n",
      "Batch: 40. Acc: 0.539409. Loss: 1.275616. Batch_acc: 0.528291. Batch_loss: 1.309934 \n",
      "Batch: 41. Acc: 0.538779. Loss: 1.276988. Batch_acc: 0.512522. Batch_loss: 1.334104 \n",
      "Batch: 42. Acc: 0.539222. Loss: 1.275037. Batch_acc: 0.557638. Batch_loss: 1.193915 \n",
      "Batch: 43. Acc: 0.539244. Loss: 1.274965. Batch_acc: 0.540191. Batch_loss: 1.271959 \n",
      "Batch: 44. Acc: 0.538968. Loss: 1.275220. Batch_acc: 0.526682. Batch_loss: 1.286551 \n",
      "Batch: 45. Acc: 0.539028. Loss: 1.275339. Batch_acc: 0.541763. Batch_loss: 1.280784 \n",
      "Batch: 46. Acc: 0.539379. Loss: 1.274370. Batch_acc: 0.555000. Batch_loss: 1.231162 \n",
      "Batch: 47. Acc: 0.539609. Loss: 1.273868. Batch_acc: 0.550490. Batch_loss: 1.250148 \n",
      "Batch: 48. Acc: 0.539215. Loss: 1.275140. Batch_acc: 0.520046. Batch_loss: 1.337032 \n",
      "Batch: 49. Acc: 0.539085. Loss: 1.275195. Batch_acc: 0.532551. Batch_loss: 1.277916 \n",
      "Batch: 50. Acc: 0.538912. Loss: 1.275744. Batch_acc: 0.530197. Batch_loss: 1.303546 \n",
      "Batch: 51. Acc: 0.538401. Loss: 1.277012. Batch_acc: 0.511737. Batch_loss: 1.343128 \n",
      "Batch: 52. Acc: 0.538601. Loss: 1.276168. Batch_acc: 0.548941. Batch_loss: 1.232434 \n",
      "Batch: 53. Acc: 0.538684. Loss: 1.276063. Batch_acc: 0.543174. Batch_loss: 1.270389 \n",
      "Batch: 54. Acc: 0.539250. Loss: 1.275103. Batch_acc: 0.569179. Batch_loss: 1.224332 \n",
      "Batch: 55. Acc: 0.539407. Loss: 1.274832. Batch_acc: 0.548144. Batch_loss: 1.259803 \n",
      "Batch: 56. Acc: 0.538777. Loss: 1.276767. Batch_acc: 0.503448. Batch_loss: 1.385210 \n",
      "Batch: 57. Acc: 0.539167. Loss: 1.275782. Batch_acc: 0.561086. Batch_loss: 1.220450 \n",
      "Batch: 58. Acc: 0.539622. Loss: 1.274897. Batch_acc: 0.565611. Batch_loss: 1.224350 \n",
      "Batch: 59. Acc: 0.539076. Loss: 1.275849. Batch_acc: 0.507345. Batch_loss: 1.331140 \n",
      "Batch: 60. Acc: 0.539262. Loss: 1.275259. Batch_acc: 0.550459. Batch_loss: 1.239872 \n",
      "Batch: 61. Acc: 0.539228. Loss: 1.275735. Batch_acc: 0.537113. Batch_loss: 1.305340 \n",
      "Batch: 62. Acc: 0.539045. Loss: 1.275901. Batch_acc: 0.527536. Batch_loss: 1.286269 \n",
      "Batch: 63. Acc: 0.539305. Loss: 1.275241. Batch_acc: 0.555246. Batch_loss: 1.234804 \n",
      "Batch: 64. Acc: 0.539306. Loss: 1.275243. Batch_acc: 0.539372. Batch_loss: 1.275412 \n",
      "Batch: 65. Acc: 0.539460. Loss: 1.275285. Batch_acc: 0.549457. Batch_loss: 1.278014 \n",
      "Batch: 66. Acc: 0.540053. Loss: 1.273831. Batch_acc: 0.578828. Batch_loss: 1.178605 \n",
      "Batch: 67. Acc: 0.540334. Loss: 1.273579. Batch_acc: 0.559109. Batch_loss: 1.256812 \n",
      "Batch: 68. Acc: 0.540091. Loss: 1.273951. Batch_acc: 0.523563. Batch_loss: 1.299312 \n",
      "Batch: 69. Acc: 0.540444. Loss: 1.273224. Batch_acc: 0.564719. Batch_loss: 1.223102 \n",
      "Batch: 70. Acc: 0.540559. Loss: 1.272680. Batch_acc: 0.548824. Batch_loss: 1.233680 \n",
      "Batch: 71. Acc: 0.540764. Loss: 1.271806. Batch_acc: 0.555427. Batch_loss: 1.209341 \n",
      "Batch: 72. Acc: 0.540665. Loss: 1.272401. Batch_acc: 0.533372. Batch_loss: 1.316126 \n",
      "Batch: 73. Acc: 0.540820. Loss: 1.272371. Batch_acc: 0.552018. Batch_loss: 1.270222 \n",
      "Batch: 74. Acc: 0.540199. Loss: 1.273743. Batch_acc: 0.494259. Batch_loss: 1.375209 \n",
      "Batch: 75. Acc: 0.539934. Loss: 1.274632. Batch_acc: 0.520069. Batch_loss: 1.341242 \n",
      "Batch: 76. Acc: 0.539722. Loss: 1.274851. Batch_acc: 0.523810. Batch_loss: 1.291294 \n",
      "Batch: 77. Acc: 0.539762. Loss: 1.274556. Batch_acc: 0.542776. Batch_loss: 1.252172 \n",
      "Batch: 78. Acc: 0.539904. Loss: 1.273908. Batch_acc: 0.551032. Batch_loss: 1.223402 \n",
      "Batch: 79. Acc: 0.540102. Loss: 1.273456. Batch_acc: 0.555944. Batch_loss: 1.237188 \n",
      "Batch: 80. Acc: 0.539964. Loss: 1.273775. Batch_acc: 0.528868. Batch_loss: 1.299461 \n",
      "Batch: 81. Acc: 0.539786. Loss: 1.274002. Batch_acc: 0.525727. Batch_loss: 1.291899 \n",
      "Batch: 82. Acc: 0.539812. Loss: 1.274083. Batch_acc: 0.542012. Batch_loss: 1.280954 \n",
      "Batch: 83. Acc: 0.539746. Loss: 1.274136. Batch_acc: 0.534325. Batch_loss: 1.278455 \n",
      "Batch: 84. Acc: 0.539812. Loss: 1.274093. Batch_acc: 0.545298. Batch_loss: 1.270546 \n",
      "Batch: 85. Acc: 0.539686. Loss: 1.274033. Batch_acc: 0.529043. Batch_loss: 1.268967 \n",
      "Batch: 86. Acc: 0.539532. Loss: 1.274425. Batch_acc: 0.526069. Batch_loss: 1.308775 \n",
      "Batch: 87. Acc: 0.539809. Loss: 1.273517. Batch_acc: 0.563091. Batch_loss: 1.197052 \n",
      "Batch: 88. Acc: 0.539698. Loss: 1.273977. Batch_acc: 0.529954. Batch_loss: 1.314573 \n",
      "Batch: 89. Acc: 0.539797. Loss: 1.274020. Batch_acc: 0.548423. Batch_loss: 1.277840 \n",
      "Batch: 90. Acc: 0.539690. Loss: 1.274250. Batch_acc: 0.529691. Batch_loss: 1.295605 \n",
      "Batch: 91. Acc: 0.540004. Loss: 1.273458. Batch_acc: 0.568639. Batch_loss: 1.201389 \n",
      "Batch: 92. Acc: 0.539968. Loss: 1.273419. Batch_acc: 0.536682. Batch_loss: 1.269872 \n",
      "Batch: 93. Acc: 0.539991. Loss: 1.273286. Batch_acc: 0.542088. Batch_loss: 1.261247 \n",
      "Batch: 94. Acc: 0.540210. Loss: 1.272888. Batch_acc: 0.560780. Batch_loss: 1.235498 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.540310. Loss: 1.272604. Batch_acc: 0.549971. Batch_loss: 1.245091 \n",
      "Batch: 96. Acc: 0.540149. Loss: 1.273064. Batch_acc: 0.524713. Batch_loss: 1.317235 \n",
      "Batch: 97. Acc: 0.540153. Loss: 1.273061. Batch_acc: 0.540573. Batch_loss: 1.272788 \n",
      "Batch: 98. Acc: 0.539992. Loss: 1.273271. Batch_acc: 0.523782. Batch_loss: 1.294335 \n",
      "Batch: 99. Acc: 0.540201. Loss: 1.272596. Batch_acc: 0.561260. Batch_loss: 1.204707 \n",
      "Batch: 100. Acc: 0.540036. Loss: 1.273310. Batch_acc: 0.523674. Batch_loss: 1.344220 \n",
      "Batch: 101. Acc: 0.539838. Loss: 1.273801. Batch_acc: 0.519653. Batch_loss: 1.323731 \n",
      "Batch: 102. Acc: 0.539882. Loss: 1.273958. Batch_acc: 0.544419. Batch_loss: 1.289795 \n",
      "Batch: 103. Acc: 0.539955. Loss: 1.274006. Batch_acc: 0.547244. Batch_loss: 1.278861 \n",
      "Batch: 104. Acc: 0.539790. Loss: 1.274288. Batch_acc: 0.522300. Batch_loss: 1.304313 \n",
      "Batch: 105. Acc: 0.539433. Loss: 1.275263. Batch_acc: 0.501734. Batch_loss: 1.378282 \n",
      "Batch: 106. Acc: 0.539407. Loss: 1.275425. Batch_acc: 0.536599. Batch_loss: 1.292666 \n",
      "Batch: 107. Acc: 0.539353. Loss: 1.275472. Batch_acc: 0.533599. Batch_loss: 1.280400 \n",
      "Batch: 108. Acc: 0.539273. Loss: 1.275522. Batch_acc: 0.530808. Batch_loss: 1.280909 \n",
      "Batch: 109. Acc: 0.539428. Loss: 1.275252. Batch_acc: 0.556527. Batch_loss: 1.245360 \n",
      "Batch: 110. Acc: 0.539311. Loss: 1.275413. Batch_acc: 0.526285. Batch_loss: 1.293394 \n",
      "Batch: 111. Acc: 0.539386. Loss: 1.275098. Batch_acc: 0.547552. Batch_loss: 1.240833 \n",
      "Batch: 112. Acc: 0.539464. Loss: 1.274882. Batch_acc: 0.548007. Batch_loss: 1.251293 \n",
      "Batch: 113. Acc: 0.539438. Loss: 1.274890. Batch_acc: 0.536544. Batch_loss: 1.275693 \n",
      "Batch: 114. Acc: 0.539458. Loss: 1.274944. Batch_acc: 0.541643. Batch_loss: 1.281104 \n",
      "Batch: 115. Acc: 0.539465. Loss: 1.275053. Batch_acc: 0.540380. Batch_loss: 1.288114 \n",
      "Batch: 116. Acc: 0.539380. Loss: 1.275374. Batch_acc: 0.529167. Batch_loss: 1.313959 \n",
      "Batch: 117. Acc: 0.539479. Loss: 1.274935. Batch_acc: 0.550725. Batch_loss: 1.225077 \n",
      "Batch: 118. Acc: 0.539644. Loss: 1.274520. Batch_acc: 0.559233. Batch_loss: 1.225002 \n",
      "Batch: 119. Acc: 0.539497. Loss: 1.274875. Batch_acc: 0.522235. Batch_loss: 1.316762 \n",
      "Batch: 120. Acc: 0.539334. Loss: 1.275249. Batch_acc: 0.519608. Batch_loss: 1.320339 \n",
      "Batch: 121. Acc: 0.539375. Loss: 1.275269. Batch_acc: 0.544311. Batch_loss: 1.277729 \n",
      "Batch: 122. Acc: 0.539519. Loss: 1.274965. Batch_acc: 0.557085. Batch_loss: 1.237905 \n",
      "Batch: 123. Acc: 0.539693. Loss: 1.274508. Batch_acc: 0.561272. Batch_loss: 1.217926 \n",
      "Batch: 124. Acc: 0.539532. Loss: 1.274863. Batch_acc: 0.519518. Batch_loss: 1.318792 \n",
      "Batch: 125. Acc: 0.539712. Loss: 1.274325. Batch_acc: 0.561829. Batch_loss: 1.208242 \n",
      "Batch: 126. Acc: 0.539713. Loss: 1.274243. Batch_acc: 0.539920. Batch_loss: 1.263965 \n",
      "Batch: 127. Acc: 0.539772. Loss: 1.273914. Batch_acc: 0.547235. Batch_loss: 1.231986 \n",
      "Batch: 128. Acc: 0.539912. Loss: 1.273745. Batch_acc: 0.557703. Batch_loss: 1.252353 \n",
      "Batch: 129. Acc: 0.540050. Loss: 1.273300. Batch_acc: 0.557792. Batch_loss: 1.215761 \n",
      "Batch: 130. Acc: 0.539935. Loss: 1.273632. Batch_acc: 0.524913. Batch_loss: 1.317216 \n",
      "Batch: 131. Acc: 0.539874. Loss: 1.273875. Batch_acc: 0.531915. Batch_loss: 1.305665 \n",
      "Batch: 132. Acc: 0.539852. Loss: 1.274250. Batch_acc: 0.536812. Batch_loss: 1.324264 \n",
      "Batch: 133. Acc: 0.539665. Loss: 1.274765. Batch_acc: 0.514908. Batch_loss: 1.343143 \n",
      "Batch: 134. Acc: 0.539494. Loss: 1.275268. Batch_acc: 0.516628. Batch_loss: 1.342619 \n",
      "Batch: 135. Acc: 0.539571. Loss: 1.275170. Batch_acc: 0.550206. Batch_loss: 1.261590 \n",
      "Batch: 136. Acc: 0.539595. Loss: 1.275134. Batch_acc: 0.542874. Batch_loss: 1.270217 \n",
      "Batch: 137. Acc: 0.539592. Loss: 1.275051. Batch_acc: 0.539205. Batch_loss: 1.263727 \n",
      "Batch: 138. Acc: 0.539605. Loss: 1.274965. Batch_acc: 0.541371. Batch_loss: 1.262761 \n",
      "Batch: 139. Acc: 0.539828. Loss: 1.274578. Batch_acc: 0.571016. Batch_loss: 1.220634 \n",
      "Batch: 140. Acc: 0.539732. Loss: 1.274928. Batch_acc: 0.526163. Batch_loss: 1.324492 \n",
      "Batch: 141. Acc: 0.539647. Loss: 1.275265. Batch_acc: 0.527473. Batch_loss: 1.323056 \n",
      "Batch: 142. Acc: 0.539586. Loss: 1.275309. Batch_acc: 0.531179. Batch_loss: 1.281459 \n",
      "Batch: 143. Acc: 0.539527. Loss: 1.275444. Batch_acc: 0.530828. Batch_loss: 1.295137 \n",
      "Batch: 144. Acc: 0.539367. Loss: 1.275812. Batch_acc: 0.515826. Batch_loss: 1.329994 \n",
      "Batch: 145. Acc: 0.539449. Loss: 1.275632. Batch_acc: 0.551311. Batch_loss: 1.249687 \n",
      "Batch: 146. Acc: 0.539559. Loss: 1.275436. Batch_acc: 0.555815. Batch_loss: 1.246303 \n",
      "Batch: 147. Acc: 0.539564. Loss: 1.275450. Batch_acc: 0.540309. Batch_loss: 1.277463 \n",
      "Batch: 148. Acc: 0.539401. Loss: 1.275526. Batch_acc: 0.515274. Batch_loss: 1.286832 \n",
      "Batch: 149. Acc: 0.539510. Loss: 1.275066. Batch_acc: 0.555306. Batch_loss: 1.208077 \n",
      "Batch: 150. Acc: 0.539531. Loss: 1.275057. Batch_acc: 0.542725. Batch_loss: 1.273768 \n",
      "Batch: 151. Acc: 0.539516. Loss: 1.275084. Batch_acc: 0.537296. Batch_loss: 1.279279 \n",
      "Batch: 152. Acc: 0.539400. Loss: 1.275519. Batch_acc: 0.521118. Batch_loss: 1.343807 \n",
      "Batch: 153. Acc: 0.539418. Loss: 1.275587. Batch_acc: 0.542176. Batch_loss: 1.286239 \n",
      "Batch: 154. Acc: 0.539366. Loss: 1.275900. Batch_acc: 0.531376. Batch_loss: 1.324118 \n",
      "Batch: 155. Acc: 0.539330. Loss: 1.275905. Batch_acc: 0.533531. Batch_loss: 1.276702 \n",
      "Batch: 156. Acc: 0.539466. Loss: 1.275432. Batch_acc: 0.560502. Batch_loss: 1.202147 \n",
      "Batch: 157. Acc: 0.539588. Loss: 1.274991. Batch_acc: 0.558656. Batch_loss: 1.206442 \n",
      "Batch: 158. Acc: 0.539744. Loss: 1.274547. Batch_acc: 0.564339. Batch_loss: 1.204196 \n",
      "Batch: 159. Acc: 0.539647. Loss: 1.274992. Batch_acc: 0.523781. Batch_loss: 1.348119 \n",
      "Batch: 160. Acc: 0.539700. Loss: 1.274727. Batch_acc: 0.548165. Batch_loss: 1.232389 \n",
      "Batch: 161. Acc: 0.539759. Loss: 1.274770. Batch_acc: 0.549528. Batch_loss: 1.281972 \n",
      "Batch: 162. Acc: 0.539724. Loss: 1.274947. Batch_acc: 0.533958. Batch_loss: 1.304024 \n",
      "Batch: 163. Acc: 0.539790. Loss: 1.274818. Batch_acc: 0.550549. Batch_loss: 1.253839 \n",
      "Batch: 164. Acc: 0.539806. Loss: 1.274843. Batch_acc: 0.542344. Batch_loss: 1.278718 \n",
      "Batch: 165. Acc: 0.539735. Loss: 1.275029. Batch_acc: 0.527712. Batch_loss: 1.306562 \n",
      "Batch: 166. Acc: 0.539726. Loss: 1.275079. Batch_acc: 0.538196. Batch_loss: 1.283343 \n",
      "Batch: 167. Acc: 0.539697. Loss: 1.275112. Batch_acc: 0.534747. Batch_loss: 1.280818 \n",
      "Batch: 168. Acc: 0.539656. Loss: 1.275157. Batch_acc: 0.532872. Batch_loss: 1.282718 \n",
      "Batch: 169. Acc: 0.539573. Loss: 1.275372. Batch_acc: 0.525501. Batch_loss: 1.311469 \n",
      "Batch: 170. Acc: 0.539479. Loss: 1.275702. Batch_acc: 0.523104. Batch_loss: 1.333514 \n",
      "Batch: 171. Acc: 0.539449. Loss: 1.275777. Batch_acc: 0.534254. Batch_loss: 1.288612 \n",
      "Batch: 172. Acc: 0.539325. Loss: 1.276335. Batch_acc: 0.517404. Batch_loss: 1.374782 \n",
      "Batch: 173. Acc: 0.539170. Loss: 1.276735. Batch_acc: 0.512557. Batch_loss: 1.345313 \n",
      "Batch: 174. Acc: 0.539218. Loss: 1.276655. Batch_acc: 0.547715. Batch_loss: 1.262767 \n",
      "Batch: 175. Acc: 0.539136. Loss: 1.276814. Batch_acc: 0.525224. Batch_loss: 1.303903 \n",
      "Batch: 176. Acc: 0.539114. Loss: 1.276871. Batch_acc: 0.535088. Batch_loss: 1.286953 \n",
      "Batch: 177. Acc: 0.539050. Loss: 1.277009. Batch_acc: 0.527665. Batch_loss: 1.301804 \n",
      "Batch: 178. Acc: 0.539055. Loss: 1.277136. Batch_acc: 0.539906. Batch_loss: 1.300172 \n",
      "Batch: 179. Acc: 0.538987. Loss: 1.277077. Batch_acc: 0.526593. Batch_loss: 1.266449 \n",
      "Batch: 180. Acc: 0.539023. Loss: 1.277050. Batch_acc: 0.545777. Batch_loss: 1.272029 \n",
      "Batch: 181. Acc: 0.538989. Loss: 1.277107. Batch_acc: 0.532583. Batch_loss: 1.287655 \n",
      "Batch: 182. Acc: 0.539016. Loss: 1.277029. Batch_acc: 0.543840. Batch_loss: 1.262830 \n",
      "Batch: 183. Acc: 0.539027. Loss: 1.276991. Batch_acc: 0.541108. Batch_loss: 1.270119 \n",
      "Batch: 184. Acc: 0.539013. Loss: 1.277012. Batch_acc: 0.536446. Batch_loss: 1.280682 \n",
      "Batch: 185. Acc: 0.538997. Loss: 1.277085. Batch_acc: 0.536047. Batch_loss: 1.290857 \n",
      "Batch: 186. Acc: 0.538915. Loss: 1.277199. Batch_acc: 0.523645. Batch_loss: 1.298447 \n",
      "Batch: 187. Acc: 0.538949. Loss: 1.277055. Batch_acc: 0.545100. Batch_loss: 1.250984 \n",
      "Batch: 188. Acc: 0.539043. Loss: 1.276811. Batch_acc: 0.556243. Batch_loss: 1.232005 \n",
      "Batch: 189. Acc: 0.538932. Loss: 1.276925. Batch_acc: 0.518093. Batch_loss: 1.298313 \n",
      "Batch: 190. Acc: 0.538751. Loss: 1.277325. Batch_acc: 0.504308. Batch_loss: 1.353293 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.538758. Loss: 1.277360. Batch_acc: 0.540158. Batch_loss: 1.283905 \n",
      "Batch: 192. Acc: 0.538700. Loss: 1.277279. Batch_acc: 0.527536. Batch_loss: 1.261551 \n",
      "Batch: 193. Acc: 0.538671. Loss: 1.277170. Batch_acc: 0.533032. Batch_loss: 1.256526 \n",
      "Batch: 194. Acc: 0.538540. Loss: 1.277599. Batch_acc: 0.513203. Batch_loss: 1.360583 \n",
      "Batch: 195. Acc: 0.538534. Loss: 1.277544. Batch_acc: 0.537543. Batch_loss: 1.266926 \n",
      "Batch: 196. Acc: 0.538568. Loss: 1.277545. Batch_acc: 0.545089. Batch_loss: 1.277797 \n",
      "Batch: 197. Acc: 0.538509. Loss: 1.277536. Batch_acc: 0.527004. Batch_loss: 1.275815 \n",
      "Batch: 198. Acc: 0.538425. Loss: 1.277890. Batch_acc: 0.521587. Batch_loss: 1.348924 \n",
      "Batch: 199. Acc: 0.538272. Loss: 1.278172. Batch_acc: 0.507567. Batch_loss: 1.335028 \n",
      "Batch: 200. Acc: 0.538234. Loss: 1.278256. Batch_acc: 0.530636. Batch_loss: 1.295153 \n",
      "Batch: 201. Acc: 0.538195. Loss: 1.278376. Batch_acc: 0.530346. Batch_loss: 1.302110 \n",
      "Batch: 202. Acc: 0.538218. Loss: 1.278314. Batch_acc: 0.542857. Batch_loss: 1.265479 \n",
      "Batch: 203. Acc: 0.538325. Loss: 1.278118. Batch_acc: 0.560300. Batch_loss: 1.238415 \n",
      "Batch: 204. Acc: 0.538307. Loss: 1.278072. Batch_acc: 0.534659. Batch_loss: 1.268695 \n",
      "Batch: 205. Acc: 0.538321. Loss: 1.277994. Batch_acc: 0.541030. Batch_loss: 1.262366 \n",
      "Batch: 206. Acc: 0.538315. Loss: 1.277943. Batch_acc: 0.537037. Batch_loss: 1.267296 \n",
      "Batch: 207. Acc: 0.538341. Loss: 1.277735. Batch_acc: 0.543750. Batch_loss: 1.235149 \n",
      "Batch: 208. Acc: 0.538344. Loss: 1.277735. Batch_acc: 0.538991. Batch_loss: 1.277798 \n",
      "Batch: 209. Acc: 0.538354. Loss: 1.277588. Batch_acc: 0.540509. Batch_loss: 1.246611 \n",
      "Batch: 210. Acc: 0.538304. Loss: 1.277572. Batch_acc: 0.527996. Batch_loss: 1.274438 \n",
      "Batch: 211. Acc: 0.538372. Loss: 1.277201. Batch_acc: 0.552677. Batch_loss: 1.198734 \n",
      "Batch: 212. Acc: 0.538348. Loss: 1.277271. Batch_acc: 0.533255. Batch_loss: 1.292491 \n",
      "Batch: 213. Acc: 0.538396. Loss: 1.277168. Batch_acc: 0.548652. Batch_loss: 1.254797 \n",
      "Batch: 214. Acc: 0.538542. Loss: 1.276860. Batch_acc: 0.569942. Batch_loss: 1.210627 \n",
      "Batch: 215. Acc: 0.538472. Loss: 1.276959. Batch_acc: 0.523620. Batch_loss: 1.298020 \n",
      "Batch: 216. Acc: 0.538307. Loss: 1.277401. Batch_acc: 0.502864. Batch_loss: 1.372532 \n",
      "Batch: 217. Acc: 0.538399. Loss: 1.277075. Batch_acc: 0.558367. Batch_loss: 1.206441 \n",
      "Batch: 218. Acc: 0.538345. Loss: 1.277230. Batch_acc: 0.526500. Batch_loss: 1.311453 \n",
      "Batch: 219. Acc: 0.538276. Loss: 1.277450. Batch_acc: 0.522687. Batch_loss: 1.326665 \n",
      "Batch: 220. Acc: 0.538242. Loss: 1.277513. Batch_acc: 0.530648. Batch_loss: 1.291519 \n",
      "Batch: 221. Acc: 0.538269. Loss: 1.277460. Batch_acc: 0.544289. Batch_loss: 1.265617 \n",
      "Batch: 222. Acc: 0.538333. Loss: 1.277273. Batch_acc: 0.552322. Batch_loss: 1.236899 \n",
      "Batch: 223. Acc: 0.538414. Loss: 1.277040. Batch_acc: 0.555932. Batch_loss: 1.226102 \n",
      "Batch: 224. Acc: 0.538452. Loss: 1.276994. Batch_acc: 0.547181. Batch_loss: 1.266667 \n",
      "Batch: 225. Acc: 0.538415. Loss: 1.276953. Batch_acc: 0.529855. Batch_loss: 1.267696 \n",
      "Batch: 226. Acc: 0.538505. Loss: 1.276625. Batch_acc: 0.558282. Batch_loss: 1.204832 \n",
      "Batch: 227. Acc: 0.538555. Loss: 1.276480. Batch_acc: 0.549631. Batch_loss: 1.244022 \n",
      "Batch: 228. Acc: 0.538562. Loss: 1.276432. Batch_acc: 0.540204. Batch_loss: 1.265608 \n",
      "Batch: 229. Acc: 0.538516. Loss: 1.276583. Batch_acc: 0.528018. Batch_loss: 1.311265 \n",
      "Batch: 230. Acc: 0.538517. Loss: 1.276592. Batch_acc: 0.538643. Batch_loss: 1.278644 \n",
      "Batch: 231. Acc: 0.538486. Loss: 1.276589. Batch_acc: 0.531603. Batch_loss: 1.275957 \n",
      "Batch: 232. Acc: 0.538547. Loss: 1.276585. Batch_acc: 0.552452. Batch_loss: 1.275678 \n",
      "Batch: 233. Acc: 0.538594. Loss: 1.276479. Batch_acc: 0.549519. Batch_loss: 1.252126 \n",
      "Batch: 234. Acc: 0.538484. Loss: 1.276665. Batch_acc: 0.512629. Batch_loss: 1.320085 \n",
      "Batch: 235. Acc: 0.538484. Loss: 1.276699. Batch_acc: 0.538554. Batch_loss: 1.285169 \n",
      "Batch: 236. Acc: 0.538560. Loss: 1.276510. Batch_acc: 0.556653. Batch_loss: 1.231476 \n",
      "Batch: 237. Acc: 0.538674. Loss: 1.276160. Batch_acc: 0.564877. Batch_loss: 1.195583 \n",
      "Batch: 238. Acc: 0.538728. Loss: 1.275871. Batch_acc: 0.551645. Batch_loss: 1.206798 \n",
      "Batch: 239. Acc: 0.538718. Loss: 1.275819. Batch_acc: 0.536503. Batch_loss: 1.263637 \n",
      "Batch: 240. Acc: 0.538633. Loss: 1.275993. Batch_acc: 0.518286. Batch_loss: 1.317403 \n",
      "Batch: 241. Acc: 0.538656. Loss: 1.276034. Batch_acc: 0.544109. Batch_loss: 1.285793 \n",
      "Batch: 242. Acc: 0.538610. Loss: 1.276151. Batch_acc: 0.527441. Batch_loss: 1.304670 \n",
      "Batch: 243. Acc: 0.538563. Loss: 1.276117. Batch_acc: 0.527168. Batch_loss: 1.267914 \n",
      "Batch: 244. Acc: 0.538619. Loss: 1.276033. Batch_acc: 0.552299. Batch_loss: 1.255521 \n",
      "Batch: 245. Acc: 0.538827. Loss: 1.275633. Batch_acc: 0.588732. Batch_loss: 1.179680 \n",
      "Batch: 246. Acc: 0.538802. Loss: 1.275650. Batch_acc: 0.532621. Batch_loss: 1.279548 \n",
      "Batch: 247. Acc: 0.538825. Loss: 1.275705. Batch_acc: 0.544622. Batch_loss: 1.289216 \n",
      "Batch: 248. Acc: 0.538812. Loss: 1.275693. Batch_acc: 0.535613. Batch_loss: 1.272959 \n",
      "Batch: 249. Acc: 0.538855. Loss: 1.275592. Batch_acc: 0.549288. Batch_loss: 1.250688 \n",
      "Batch: 250. Acc: 0.538930. Loss: 1.275395. Batch_acc: 0.557377. Batch_loss: 1.226851 \n",
      "Batch: 251. Acc: 0.538896. Loss: 1.275413. Batch_acc: 0.530348. Batch_loss: 1.280097 \n",
      "Checkpointing on batch: 251. Accuracy: 0.5388963949571394. Loss per char: 1.2754131516368943. Time: 1627222020.721814\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 21, 21, 20, 25, 25, 20, 23,  1, 66, 79, 69,  1, 18,\n",
      "        20, 26, 23, 21, 23, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.538926. Loss: 1.275351. Batch_acc: 0.546439. Batch_loss: 1.259839 \n",
      "Batch: 253. Acc: 0.538845. Loss: 1.275489. Batch_acc: 0.518219. Batch_loss: 1.310656 \n",
      "Batch: 254. Acc: 0.538891. Loss: 1.275436. Batch_acc: 0.550827. Batch_loss: 1.261551 \n",
      "Batch: 255. Acc: 0.538846. Loss: 1.275361. Batch_acc: 0.527590. Batch_loss: 1.256664 \n",
      "Batch: 256. Acc: 0.538941. Loss: 1.275110. Batch_acc: 0.563364. Batch_loss: 1.210764 \n",
      "Batch: 257. Acc: 0.538922. Loss: 1.275182. Batch_acc: 0.534046. Batch_loss: 1.293298 \n",
      "Batch: 258. Acc: 0.538999. Loss: 1.275023. Batch_acc: 0.558508. Batch_loss: 1.234756 \n",
      "Batch: 259. Acc: 0.539010. Loss: 1.274909. Batch_acc: 0.542056. Batch_loss: 1.244676 \n",
      "Batch: 260. Acc: 0.538981. Loss: 1.274986. Batch_acc: 0.531357. Batch_loss: 1.294891 \n",
      "Batch: 261. Acc: 0.538900. Loss: 1.275102. Batch_acc: 0.517523. Batch_loss: 1.305949 \n",
      "Batch: 262. Acc: 0.539000. Loss: 1.274783. Batch_acc: 0.564202. Batch_loss: 1.193895 \n",
      "Batch: 263. Acc: 0.538968. Loss: 1.274803. Batch_acc: 0.530577. Batch_loss: 1.280132 \n",
      "Batch: 264. Acc: 0.539118. Loss: 1.274314. Batch_acc: 0.577678. Batch_loss: 1.148591 \n",
      "Batch: 265. Acc: 0.539101. Loss: 1.274235. Batch_acc: 0.534624. Batch_loss: 1.252629 \n",
      "Batch: 266. Acc: 0.539149. Loss: 1.274128. Batch_acc: 0.551607. Batch_loss: 1.246439 \n",
      "Batch: 267. Acc: 0.539130. Loss: 1.274145. Batch_acc: 0.533874. Batch_loss: 1.278542 \n",
      "Batch: 268. Acc: 0.539216. Loss: 1.273963. Batch_acc: 0.562178. Batch_loss: 1.225482 \n",
      "Batch: 269. Acc: 0.539257. Loss: 1.273831. Batch_acc: 0.550286. Batch_loss: 1.238574 \n",
      "Batch: 270. Acc: 0.539272. Loss: 1.273773. Batch_acc: 0.543330. Batch_loss: 1.258215 \n",
      "Batch: 271. Acc: 0.539350. Loss: 1.273611. Batch_acc: 0.560068. Batch_loss: 1.230433 \n",
      "Batch: 272. Acc: 0.539287. Loss: 1.273687. Batch_acc: 0.521739. Batch_loss: 1.294797 \n",
      "Batch: 273. Acc: 0.539282. Loss: 1.273680. Batch_acc: 0.537879. Batch_loss: 1.271798 \n",
      "Batch: 274. Acc: 0.539280. Loss: 1.273708. Batch_acc: 0.538728. Batch_loss: 1.281425 \n",
      "Batch: 275. Acc: 0.539218. Loss: 1.273916. Batch_acc: 0.521765. Batch_loss: 1.332399 \n",
      "Batch: 276. Acc: 0.539127. Loss: 1.274166. Batch_acc: 0.513921. Batch_loss: 1.343896 \n",
      "Batch: 277. Acc: 0.539170. Loss: 1.273958. Batch_acc: 0.551186. Batch_loss: 1.215891 \n",
      "Batch: 278. Acc: 0.539202. Loss: 1.273925. Batch_acc: 0.547753. Batch_loss: 1.264922 \n",
      "Batch: 279. Acc: 0.539183. Loss: 1.273992. Batch_acc: 0.533947. Batch_loss: 1.292696 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.539189. Loss: 1.274005. Batch_acc: 0.541012. Batch_loss: 1.277739 \n",
      "Batch: 281. Acc: 0.539224. Loss: 1.273918. Batch_acc: 0.548986. Batch_loss: 1.249318 \n",
      "Batch: 282. Acc: 0.539187. Loss: 1.274003. Batch_acc: 0.528436. Batch_loss: 1.298603 \n",
      "Batch: 283. Acc: 0.539192. Loss: 1.274064. Batch_acc: 0.540664. Batch_loss: 1.291417 \n",
      "Batch: 284. Acc: 0.539220. Loss: 1.274072. Batch_acc: 0.547368. Batch_loss: 1.276313 \n",
      "Batch: 285. Acc: 0.539215. Loss: 1.274071. Batch_acc: 0.537853. Batch_loss: 1.273698 \n",
      "Batch: 286. Acc: 0.539234. Loss: 1.274026. Batch_acc: 0.544622. Batch_loss: 1.261201 \n",
      "Batch: 287. Acc: 0.539239. Loss: 1.274096. Batch_acc: 0.540449. Batch_loss: 1.293724 \n",
      "Batch: 288. Acc: 0.539261. Loss: 1.274007. Batch_acc: 0.545773. Batch_loss: 1.248078 \n",
      "Batch: 289. Acc: 0.539283. Loss: 1.273960. Batch_acc: 0.545769. Batch_loss: 1.260277 \n",
      "Batch: 290. Acc: 0.539232. Loss: 1.274086. Batch_acc: 0.523977. Batch_loss: 1.311367 \n",
      "Batch: 291. Acc: 0.539327. Loss: 1.273866. Batch_acc: 0.567285. Batch_loss: 1.209146 \n",
      "Batch: 292. Acc: 0.539345. Loss: 1.273808. Batch_acc: 0.544560. Batch_loss: 1.256807 \n",
      "Batch: 293. Acc: 0.539348. Loss: 1.273830. Batch_acc: 0.540351. Batch_loss: 1.280490 \n",
      "Batch: 294. Acc: 0.539401. Loss: 1.273606. Batch_acc: 0.554917. Batch_loss: 1.207863 \n",
      "Batch: 295. Acc: 0.539440. Loss: 1.273656. Batch_acc: 0.551080. Batch_loss: 1.288474 \n",
      "Batch: 296. Acc: 0.539412. Loss: 1.273696. Batch_acc: 0.531070. Batch_loss: 1.285612 \n",
      "Batch: 297. Acc: 0.539323. Loss: 1.273856. Batch_acc: 0.512938. Batch_loss: 1.321278 \n",
      "Batch: 298. Acc: 0.539315. Loss: 1.273738. Batch_acc: 0.536909. Batch_loss: 1.238612 \n",
      "Batch: 299. Acc: 0.539326. Loss: 1.273701. Batch_acc: 0.542578. Batch_loss: 1.262655 \n",
      "Batch: 300. Acc: 0.539316. Loss: 1.273729. Batch_acc: 0.536640. Batch_loss: 1.281752 \n",
      "Batch: 301. Acc: 0.539323. Loss: 1.273637. Batch_acc: 0.541223. Batch_loss: 1.246864 \n",
      "Batch: 302. Acc: 0.539287. Loss: 1.273765. Batch_acc: 0.528181. Batch_loss: 1.312757 \n",
      "Batch: 303. Acc: 0.539323. Loss: 1.273690. Batch_acc: 0.549972. Batch_loss: 1.251670 \n",
      "Batch: 304. Acc: 0.539324. Loss: 1.273699. Batch_acc: 0.539720. Batch_loss: 1.276418 \n",
      "Batch: 305. Acc: 0.539285. Loss: 1.273761. Batch_acc: 0.527357. Batch_loss: 1.292904 \n",
      "Batch: 306. Acc: 0.539286. Loss: 1.273848. Batch_acc: 0.539618. Batch_loss: 1.300682 \n",
      "Batch: 307. Acc: 0.539229. Loss: 1.273968. Batch_acc: 0.521043. Batch_loss: 1.311893 \n",
      "Batch: 308. Acc: 0.539260. Loss: 1.273862. Batch_acc: 0.548440. Batch_loss: 1.242670 \n",
      "Batch: 309. Acc: 0.539287. Loss: 1.273824. Batch_acc: 0.547511. Batch_loss: 1.262267 \n",
      "Batch: 310. Acc: 0.539366. Loss: 1.273632. Batch_acc: 0.563316. Batch_loss: 1.215077 \n",
      "Batch: 311. Acc: 0.539336. Loss: 1.273683. Batch_acc: 0.530093. Batch_loss: 1.289436 \n",
      "Batch: 312. Acc: 0.539372. Loss: 1.273598. Batch_acc: 0.550640. Batch_loss: 1.246688 \n",
      "Batch: 313. Acc: 0.539347. Loss: 1.273591. Batch_acc: 0.531609. Batch_loss: 1.271500 \n",
      "Batch: 314. Acc: 0.539274. Loss: 1.273728. Batch_acc: 0.515998. Batch_loss: 1.317218 \n",
      "Batch: 315. Acc: 0.539249. Loss: 1.273807. Batch_acc: 0.531395. Batch_loss: 1.298946 \n",
      "Batch: 316. Acc: 0.539200. Loss: 1.273997. Batch_acc: 0.523810. Batch_loss: 1.334017 \n",
      "Batch: 317. Acc: 0.539204. Loss: 1.273943. Batch_acc: 0.540270. Batch_loss: 1.256321 \n",
      "Batch: 318. Acc: 0.539161. Loss: 1.274102. Batch_acc: 0.525354. Batch_loss: 1.326125 \n",
      "Batch: 319. Acc: 0.539099. Loss: 1.274230. Batch_acc: 0.518846. Batch_loss: 1.315829 \n",
      "Batch: 320. Acc: 0.539118. Loss: 1.274139. Batch_acc: 0.544989. Batch_loss: 1.245283 \n",
      "Batch: 321. Acc: 0.539152. Loss: 1.274090. Batch_acc: 0.549943. Batch_loss: 1.258557 \n",
      "Batch: 322. Acc: 0.539152. Loss: 1.274134. Batch_acc: 0.539125. Batch_loss: 1.288285 \n",
      "Batch: 323. Acc: 0.539214. Loss: 1.273895. Batch_acc: 0.558594. Batch_loss: 1.199014 \n",
      "Batch: 324. Acc: 0.539198. Loss: 1.273929. Batch_acc: 0.533963. Batch_loss: 1.285399 \n",
      "Batch: 325. Acc: 0.539165. Loss: 1.274023. Batch_acc: 0.528422. Batch_loss: 1.304739 \n",
      "Batch: 326. Acc: 0.539166. Loss: 1.274038. Batch_acc: 0.539443. Batch_loss: 1.278941 \n",
      "Batch: 327. Acc: 0.539079. Loss: 1.274238. Batch_acc: 0.511287. Batch_loss: 1.338408 \n",
      "Batch: 328. Acc: 0.539001. Loss: 1.274388. Batch_acc: 0.512684. Batch_loss: 1.325036 \n",
      "Batch: 329. Acc: 0.539023. Loss: 1.274384. Batch_acc: 0.545967. Batch_loss: 1.273107 \n",
      "Batch: 330. Acc: 0.539004. Loss: 1.274510. Batch_acc: 0.532948. Batch_loss: 1.316352 \n",
      "Batch: 331. Acc: 0.539061. Loss: 1.274452. Batch_acc: 0.557780. Batch_loss: 1.255085 \n",
      "Batch: 332. Acc: 0.539069. Loss: 1.274425. Batch_acc: 0.541620. Batch_loss: 1.265662 \n",
      "Batch: 333. Acc: 0.539100. Loss: 1.274360. Batch_acc: 0.549344. Batch_loss: 1.253162 \n",
      "Batch: 334. Acc: 0.539123. Loss: 1.274333. Batch_acc: 0.546893. Batch_loss: 1.264821 \n",
      "Batch: 335. Acc: 0.539169. Loss: 1.274263. Batch_acc: 0.554846. Batch_loss: 1.250750 \n",
      "Batch: 336. Acc: 0.539168. Loss: 1.274261. Batch_acc: 0.538687. Batch_loss: 1.273530 \n",
      "Batch: 337. Acc: 0.539146. Loss: 1.274305. Batch_acc: 0.531765. Batch_loss: 1.289662 \n",
      "Batch: 338. Acc: 0.539102. Loss: 1.274382. Batch_acc: 0.524086. Batch_loss: 1.300349 \n",
      "Batch: 339. Acc: 0.539123. Loss: 1.274356. Batch_acc: 0.546034. Batch_loss: 1.265532 \n",
      "Batch: 340. Acc: 0.539030. Loss: 1.274444. Batch_acc: 0.507034. Batch_loss: 1.305208 \n",
      "Batch: 341. Acc: 0.539114. Loss: 1.274291. Batch_acc: 0.567232. Batch_loss: 1.222932 \n",
      "Batch: 342. Acc: 0.539148. Loss: 1.274259. Batch_acc: 0.550575. Batch_loss: 1.263444 \n",
      "Batch: 343. Acc: 0.539112. Loss: 1.274305. Batch_acc: 0.527066. Batch_loss: 1.289926 \n",
      "Batch: 344. Acc: 0.539099. Loss: 1.274277. Batch_acc: 0.534765. Batch_loss: 1.264770 \n",
      "Batch: 345. Acc: 0.539028. Loss: 1.274424. Batch_acc: 0.513970. Batch_loss: 1.325627 \n",
      "Batch: 346. Acc: 0.538990. Loss: 1.274448. Batch_acc: 0.526196. Batch_loss: 1.282829 \n",
      "Batch: 347. Acc: 0.538967. Loss: 1.274558. Batch_acc: 0.530588. Batch_loss: 1.313515 \n",
      "Batch: 348. Acc: 0.538939. Loss: 1.274613. Batch_acc: 0.529309. Batch_loss: 1.293993 \n",
      "Batch: 349. Acc: 0.538977. Loss: 1.274489. Batch_acc: 0.551744. Batch_loss: 1.232177 \n",
      "Batch: 350. Acc: 0.539022. Loss: 1.274372. Batch_acc: 0.554617. Batch_loss: 1.234091 \n",
      "Batch: 351. Acc: 0.539080. Loss: 1.274316. Batch_acc: 0.559489. Batch_loss: 1.254418 \n",
      "Batch: 352. Acc: 0.539053. Loss: 1.274386. Batch_acc: 0.529412. Batch_loss: 1.299408 \n",
      "Batch: 353. Acc: 0.539087. Loss: 1.274254. Batch_acc: 0.550974. Batch_loss: 1.227785 \n",
      "Batch: 354. Acc: 0.539066. Loss: 1.274328. Batch_acc: 0.531878. Batch_loss: 1.300681 \n",
      "Batch: 355. Acc: 0.539061. Loss: 1.274354. Batch_acc: 0.537048. Batch_loss: 1.283436 \n",
      "Batch: 356. Acc: 0.539087. Loss: 1.274294. Batch_acc: 0.548497. Batch_loss: 1.253279 \n",
      "Batch: 357. Acc: 0.539061. Loss: 1.274369. Batch_acc: 0.529446. Batch_loss: 1.301597 \n",
      "Batch: 358. Acc: 0.539052. Loss: 1.274347. Batch_acc: 0.535858. Batch_loss: 1.266276 \n",
      "Batch: 359. Acc: 0.539055. Loss: 1.274408. Batch_acc: 0.540197. Batch_loss: 1.296476 \n",
      "Batch: 360. Acc: 0.539004. Loss: 1.274549. Batch_acc: 0.520282. Batch_loss: 1.326365 \n",
      "Batch: 361. Acc: 0.539014. Loss: 1.274539. Batch_acc: 0.542740. Batch_loss: 1.270956 \n",
      "Batch: 362. Acc: 0.539031. Loss: 1.274391. Batch_acc: 0.545147. Batch_loss: 1.221950 \n",
      "Batch: 363. Acc: 0.539104. Loss: 1.274200. Batch_acc: 0.564946. Batch_loss: 1.205750 \n",
      "Batch: 364. Acc: 0.539072. Loss: 1.274265. Batch_acc: 0.527652. Batch_loss: 1.297608 \n",
      "Batch: 365. Acc: 0.539014. Loss: 1.274409. Batch_acc: 0.517681. Batch_loss: 1.327352 \n",
      "Batch: 366. Acc: 0.539016. Loss: 1.274415. Batch_acc: 0.539966. Batch_loss: 1.276564 \n",
      "Batch: 367. Acc: 0.539040. Loss: 1.274335. Batch_acc: 0.548009. Batch_loss: 1.244542 \n",
      "Batch: 368. Acc: 0.539003. Loss: 1.274484. Batch_acc: 0.525130. Batch_loss: 1.329517 \n",
      "Batch: 369. Acc: 0.539016. Loss: 1.274466. Batch_acc: 0.543779. Batch_loss: 1.267714 \n",
      "Batch: 370. Acc: 0.539070. Loss: 1.274426. Batch_acc: 0.559010. Batch_loss: 1.259439 \n",
      "Batch: 371. Acc: 0.539089. Loss: 1.274417. Batch_acc: 0.546214. Batch_loss: 1.271422 \n",
      "Batch: 372. Acc: 0.539126. Loss: 1.274319. Batch_acc: 0.552874. Batch_loss: 1.237731 \n",
      "Batch: 373. Acc: 0.539145. Loss: 1.274221. Batch_acc: 0.546356. Batch_loss: 1.237115 \n",
      "Batch: 374. Acc: 0.539213. Loss: 1.274111. Batch_acc: 0.563187. Batch_loss: 1.235010 \n",
      "Batch: 375. Acc: 0.539139. Loss: 1.274235. Batch_acc: 0.511945. Batch_loss: 1.320220 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.539191. Loss: 1.274145. Batch_acc: 0.558126. Batch_loss: 1.241017 \n",
      "Batch: 377. Acc: 0.539164. Loss: 1.274154. Batch_acc: 0.529312. Batch_loss: 1.277176 \n",
      "Batch: 378. Acc: 0.539217. Loss: 1.273981. Batch_acc: 0.559042. Batch_loss: 1.209105 \n",
      "Batch: 379. Acc: 0.539226. Loss: 1.273929. Batch_acc: 0.542923. Batch_loss: 1.254319 \n",
      "Batch: 380. Acc: 0.539236. Loss: 1.273946. Batch_acc: 0.543109. Batch_loss: 1.280340 \n",
      "Batch: 381. Acc: 0.539255. Loss: 1.273889. Batch_acc: 0.546392. Batch_loss: 1.252373 \n",
      "Batch: 382. Acc: 0.539275. Loss: 1.273823. Batch_acc: 0.546911. Batch_loss: 1.248681 \n",
      "Batch: 383. Acc: 0.539246. Loss: 1.273947. Batch_acc: 0.527531. Batch_loss: 1.322769 \n",
      "Batch: 384. Acc: 0.539190. Loss: 1.274165. Batch_acc: 0.517241. Batch_loss: 1.360768 \n",
      "Batch: 385. Acc: 0.539162. Loss: 1.274325. Batch_acc: 0.528334. Batch_loss: 1.335722 \n",
      "Batch: 386. Acc: 0.539179. Loss: 1.274259. Batch_acc: 0.545455. Batch_loss: 1.249081 \n",
      "Batch: 387. Acc: 0.539186. Loss: 1.274256. Batch_acc: 0.541976. Batch_loss: 1.272974 \n",
      "Batch: 388. Acc: 0.539145. Loss: 1.274355. Batch_acc: 0.523370. Batch_loss: 1.312950 \n",
      "Batch: 389. Acc: 0.539193. Loss: 1.274290. Batch_acc: 0.557703. Batch_loss: 1.249251 \n",
      "Batch: 390. Acc: 0.539174. Loss: 1.274384. Batch_acc: 0.531521. Batch_loss: 1.311180 \n",
      "Batch: 391. Acc: 0.539184. Loss: 1.274378. Batch_acc: 0.543124. Batch_loss: 1.271962 \n",
      "Batch: 392. Acc: 0.539158. Loss: 1.274364. Batch_acc: 0.529010. Batch_loss: 1.268978 \n",
      "Batch: 393. Acc: 0.539182. Loss: 1.274271. Batch_acc: 0.548280. Batch_loss: 1.239318 \n",
      "Batch: 394. Acc: 0.539213. Loss: 1.274142. Batch_acc: 0.551487. Batch_loss: 1.223264 \n",
      "Batch: 395. Acc: 0.539141. Loss: 1.274401. Batch_acc: 0.510240. Batch_loss: 1.378538 \n",
      "Batch: 396. Acc: 0.539084. Loss: 1.274497. Batch_acc: 0.516835. Batch_loss: 1.311674 \n",
      "Batch: 397. Acc: 0.539109. Loss: 1.274406. Batch_acc: 0.549053. Batch_loss: 1.238332 \n",
      "Batch: 398. Acc: 0.539060. Loss: 1.274560. Batch_acc: 0.519443. Batch_loss: 1.336469 \n",
      "Batch: 399. Acc: 0.539054. Loss: 1.274511. Batch_acc: 0.536818. Batch_loss: 1.255389 \n",
      "Batch: 400. Acc: 0.539047. Loss: 1.274461. Batch_acc: 0.536134. Batch_loss: 1.255113 \n",
      "Batch: 401. Acc: 0.539041. Loss: 1.274505. Batch_acc: 0.536812. Batch_loss: 1.292148 \n",
      "Batch: 402. Acc: 0.539046. Loss: 1.274477. Batch_acc: 0.540873. Batch_loss: 1.263429 \n",
      "Batch: 403. Acc: 0.539049. Loss: 1.274486. Batch_acc: 0.540210. Batch_loss: 1.278315 \n",
      "Batch: 404. Acc: 0.538994. Loss: 1.274607. Batch_acc: 0.516205. Batch_loss: 1.324683 \n",
      "Batch: 405. Acc: 0.539003. Loss: 1.274566. Batch_acc: 0.542823. Batch_loss: 1.257389 \n",
      "Batch: 406. Acc: 0.538988. Loss: 1.274606. Batch_acc: 0.532941. Batch_loss: 1.291293 \n",
      "Batch: 407. Acc: 0.538995. Loss: 1.274604. Batch_acc: 0.541762. Batch_loss: 1.273674 \n",
      "Batch: 408. Acc: 0.538977. Loss: 1.274700. Batch_acc: 0.531682. Batch_loss: 1.314091 \n",
      "Batch: 409. Acc: 0.539006. Loss: 1.274591. Batch_acc: 0.550366. Batch_loss: 1.230806 \n",
      "Batch: 410. Acc: 0.539049. Loss: 1.274464. Batch_acc: 0.556631. Batch_loss: 1.222904 \n",
      "Batch: 411. Acc: 0.539092. Loss: 1.274377. Batch_acc: 0.557035. Batch_loss: 1.238670 \n",
      "Batch: 412. Acc: 0.538990. Loss: 1.274607. Batch_acc: 0.495215. Batch_loss: 1.372966 \n",
      "Batch: 413. Acc: 0.539015. Loss: 1.274489. Batch_acc: 0.548953. Batch_loss: 1.226568 \n",
      "Batch: 414. Acc: 0.539024. Loss: 1.274500. Batch_acc: 0.543138. Batch_loss: 1.279155 \n",
      "Batch: 415. Acc: 0.539028. Loss: 1.274503. Batch_acc: 0.540478. Batch_loss: 1.275828 \n",
      "Batch: 416. Acc: 0.539030. Loss: 1.274458. Batch_acc: 0.539917. Batch_loss: 1.254917 \n",
      "Batch: 417. Acc: 0.539037. Loss: 1.274358. Batch_acc: 0.541903. Batch_loss: 1.233378 \n",
      "Batch: 418. Acc: 0.539028. Loss: 1.274360. Batch_acc: 0.535371. Batch_loss: 1.275395 \n",
      "Batch: 419. Acc: 0.539051. Loss: 1.274294. Batch_acc: 0.548829. Batch_loss: 1.246864 \n",
      "Batch: 420. Acc: 0.539047. Loss: 1.274329. Batch_acc: 0.537026. Batch_loss: 1.289154 \n",
      "Batch: 421. Acc: 0.539080. Loss: 1.274259. Batch_acc: 0.552868. Batch_loss: 1.245392 \n",
      "Batch: 422. Acc: 0.539085. Loss: 1.274215. Batch_acc: 0.541190. Batch_loss: 1.255818 \n",
      "Batch: 423. Acc: 0.539111. Loss: 1.274158. Batch_acc: 0.550206. Batch_loss: 1.249270 \n",
      "Batch: 424. Acc: 0.539126. Loss: 1.274187. Batch_acc: 0.545557. Batch_loss: 1.286381 \n",
      "Batch: 425. Acc: 0.539147. Loss: 1.274133. Batch_acc: 0.547897. Batch_loss: 1.251014 \n",
      "Batch: 426. Acc: 0.539165. Loss: 1.274097. Batch_acc: 0.546999. Batch_loss: 1.258957 \n",
      "Batch: 427. Acc: 0.539176. Loss: 1.274079. Batch_acc: 0.543700. Batch_loss: 1.266513 \n",
      "Batch: 428. Acc: 0.539162. Loss: 1.274162. Batch_acc: 0.533105. Batch_loss: 1.309111 \n",
      "Batch: 429. Acc: 0.539182. Loss: 1.274097. Batch_acc: 0.547826. Batch_loss: 1.246137 \n",
      "Batch: 430. Acc: 0.539191. Loss: 1.274057. Batch_acc: 0.543339. Batch_loss: 1.256634 \n",
      "Batch: 431. Acc: 0.539180. Loss: 1.274070. Batch_acc: 0.534247. Batch_loss: 1.279878 \n",
      "Batch: 432. Acc: 0.539128. Loss: 1.274187. Batch_acc: 0.516541. Batch_loss: 1.324860 \n",
      "Batch: 433. Acc: 0.539149. Loss: 1.274060. Batch_acc: 0.548295. Batch_loss: 1.220067 \n",
      "Batch: 434. Acc: 0.539169. Loss: 1.274000. Batch_acc: 0.547633. Batch_loss: 1.247970 \n",
      "Batch: 435. Acc: 0.539217. Loss: 1.273881. Batch_acc: 0.559954. Batch_loss: 1.222143 \n",
      "Batch: 436. Acc: 0.539175. Loss: 1.273956. Batch_acc: 0.520869. Batch_loss: 1.306654 \n",
      "Batch: 437. Acc: 0.539229. Loss: 1.273756. Batch_acc: 0.563112. Batch_loss: 1.185864 \n",
      "Batch: 438. Acc: 0.539230. Loss: 1.273809. Batch_acc: 0.539459. Batch_loss: 1.296946 \n",
      "Batch: 439. Acc: 0.539221. Loss: 1.273835. Batch_acc: 0.535186. Batch_loss: 1.285474 \n",
      "Batch: 440. Acc: 0.539199. Loss: 1.273902. Batch_acc: 0.529647. Batch_loss: 1.302861 \n",
      "Batch: 441. Acc: 0.539219. Loss: 1.273803. Batch_acc: 0.547753. Batch_loss: 1.231470 \n",
      "Batch: 442. Acc: 0.539208. Loss: 1.273812. Batch_acc: 0.534710. Batch_loss: 1.277689 \n",
      "Batch: 443. Acc: 0.539166. Loss: 1.273885. Batch_acc: 0.520093. Batch_loss: 1.306421 \n",
      "Batch: 444. Acc: 0.539110. Loss: 1.273955. Batch_acc: 0.514401. Batch_loss: 1.305371 \n",
      "Batch: 445. Acc: 0.539083. Loss: 1.274003. Batch_acc: 0.526919. Batch_loss: 1.295261 \n",
      "Batch: 446. Acc: 0.539138. Loss: 1.273889. Batch_acc: 0.563731. Batch_loss: 1.222447 \n",
      "Batch: 447. Acc: 0.539111. Loss: 1.273952. Batch_acc: 0.527346. Batch_loss: 1.302441 \n",
      "Batch: 448. Acc: 0.539061. Loss: 1.274130. Batch_acc: 0.516648. Batch_loss: 1.353511 \n",
      "Batch: 449. Acc: 0.539095. Loss: 1.274034. Batch_acc: 0.554774. Batch_loss: 1.230181 \n",
      "Batch: 450. Acc: 0.539138. Loss: 1.273929. Batch_acc: 0.557671. Batch_loss: 1.227909 \n",
      "Batch: 451. Acc: 0.539165. Loss: 1.273894. Batch_acc: 0.551412. Batch_loss: 1.258498 \n",
      "Batch: 452. Acc: 0.539168. Loss: 1.273885. Batch_acc: 0.540369. Batch_loss: 1.269555 \n",
      "Batch: 453. Acc: 0.539191. Loss: 1.273886. Batch_acc: 0.549383. Batch_loss: 1.274252 \n",
      "Batch: 454. Acc: 0.539203. Loss: 1.273826. Batch_acc: 0.544515. Batch_loss: 1.246742 \n",
      "Batch: 455. Acc: 0.539222. Loss: 1.273749. Batch_acc: 0.547782. Batch_loss: 1.239183 \n",
      "Batch: 456. Acc: 0.539212. Loss: 1.273850. Batch_acc: 0.534522. Batch_loss: 1.319910 \n",
      "Batch: 457. Acc: 0.539204. Loss: 1.273849. Batch_acc: 0.535674. Batch_loss: 1.273563 \n",
      "Batch: 458. Acc: 0.539255. Loss: 1.273724. Batch_acc: 0.563842. Batch_loss: 1.214404 \n",
      "Batch: 459. Acc: 0.539304. Loss: 1.273631. Batch_acc: 0.560598. Batch_loss: 1.232466 \n",
      "Batch: 460. Acc: 0.539332. Loss: 1.273555. Batch_acc: 0.552419. Batch_loss: 1.238219 \n",
      "Batch: 461. Acc: 0.539357. Loss: 1.273499. Batch_acc: 0.550775. Batch_loss: 1.247736 \n",
      "Batch: 462. Acc: 0.539355. Loss: 1.273473. Batch_acc: 0.538462. Batch_loss: 1.261779 \n",
      "Batch: 463. Acc: 0.539362. Loss: 1.273383. Batch_acc: 0.542959. Batch_loss: 1.229980 \n",
      "Batch: 464. Acc: 0.539397. Loss: 1.273307. Batch_acc: 0.555619. Batch_loss: 1.238166 \n",
      "Batch: 465. Acc: 0.539388. Loss: 1.273275. Batch_acc: 0.535274. Batch_loss: 1.258863 \n",
      "Batch: 466. Acc: 0.539345. Loss: 1.273317. Batch_acc: 0.519017. Batch_loss: 1.293243 \n",
      "Batch: 467. Acc: 0.539386. Loss: 1.273210. Batch_acc: 0.558617. Batch_loss: 1.222350 \n",
      "Batch: 468. Acc: 0.539395. Loss: 1.273183. Batch_acc: 0.543849. Batch_loss: 1.260134 \n",
      "Batch: 469. Acc: 0.539422. Loss: 1.273108. Batch_acc: 0.552059. Batch_loss: 1.238063 \n",
      "Batch: 470. Acc: 0.539405. Loss: 1.273126. Batch_acc: 0.531624. Batch_loss: 1.281558 \n",
      "Batch: 471. Acc: 0.539335. Loss: 1.273338. Batch_acc: 0.506087. Batch_loss: 1.373979 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.539373. Loss: 1.273259. Batch_acc: 0.557319. Batch_loss: 1.235095 \n",
      "Batch: 473. Acc: 0.539365. Loss: 1.273239. Batch_acc: 0.535714. Batch_loss: 1.264131 \n",
      "Batch: 474. Acc: 0.539369. Loss: 1.273194. Batch_acc: 0.541430. Batch_loss: 1.251745 \n",
      "Batch: 475. Acc: 0.539386. Loss: 1.273148. Batch_acc: 0.547192. Batch_loss: 1.251354 \n",
      "Batch: 476. Acc: 0.539337. Loss: 1.273270. Batch_acc: 0.515653. Batch_loss: 1.332725 \n",
      "Batch: 477. Acc: 0.539294. Loss: 1.273336. Batch_acc: 0.518775. Batch_loss: 1.304927 \n",
      "Batch: 478. Acc: 0.539312. Loss: 1.273320. Batch_acc: 0.547592. Batch_loss: 1.266053 \n",
      "Batch: 479. Acc: 0.539310. Loss: 1.273295. Batch_acc: 0.538109. Batch_loss: 1.261334 \n",
      "Batch: 480. Acc: 0.539285. Loss: 1.273339. Batch_acc: 0.527294. Batch_loss: 1.294611 \n",
      "Batch: 481. Acc: 0.539293. Loss: 1.273359. Batch_acc: 0.543294. Batch_loss: 1.282749 \n",
      "Batch: 482. Acc: 0.539282. Loss: 1.273421. Batch_acc: 0.533565. Batch_loss: 1.303953 \n",
      "Batch: 483. Acc: 0.539302. Loss: 1.273361. Batch_acc: 0.549476. Batch_loss: 1.243900 \n",
      "Batch: 484. Acc: 0.539363. Loss: 1.273229. Batch_acc: 0.568571. Batch_loss: 1.209861 \n",
      "Batch: 485. Acc: 0.539343. Loss: 1.273274. Batch_acc: 0.529748. Batch_loss: 1.294803 \n",
      "Batch: 486. Acc: 0.539335. Loss: 1.273233. Batch_acc: 0.535406. Batch_loss: 1.253406 \n",
      "Batch: 487. Acc: 0.539338. Loss: 1.273279. Batch_acc: 0.540909. Batch_loss: 1.295279 \n",
      "Batch: 488. Acc: 0.539357. Loss: 1.273227. Batch_acc: 0.548758. Batch_loss: 1.246642 \n",
      "Batch: 489. Acc: 0.539372. Loss: 1.273249. Batch_acc: 0.547148. Batch_loss: 1.284069 \n",
      "Batch: 490. Acc: 0.539347. Loss: 1.273292. Batch_acc: 0.526678. Batch_loss: 1.294219 \n",
      "Batch: 491. Acc: 0.539376. Loss: 1.273236. Batch_acc: 0.553846. Batch_loss: 1.245877 \n",
      "Batch: 492. Acc: 0.539384. Loss: 1.273211. Batch_acc: 0.543217. Batch_loss: 1.261295 \n",
      "Batch: 493. Acc: 0.539397. Loss: 1.273216. Batch_acc: 0.545613. Batch_loss: 1.275496 \n",
      "Batch: 494. Acc: 0.539394. Loss: 1.273277. Batch_acc: 0.537931. Batch_loss: 1.303146 \n",
      "Batch: 495. Acc: 0.539430. Loss: 1.273131. Batch_acc: 0.557239. Batch_loss: 1.202998 \n",
      "Batch: 496. Acc: 0.539404. Loss: 1.273191. Batch_acc: 0.526256. Batch_loss: 1.302465 \n",
      "Batch: 497. Acc: 0.539408. Loss: 1.273203. Batch_acc: 0.541427. Batch_loss: 1.279357 \n",
      "Batch: 498. Acc: 0.539361. Loss: 1.273313. Batch_acc: 0.515543. Batch_loss: 1.329122 \n",
      "Batch: 499. Acc: 0.539320. Loss: 1.273425. Batch_acc: 0.518278. Batch_loss: 1.330512 \n",
      "Batch: 500. Acc: 0.539267. Loss: 1.273500. Batch_acc: 0.512835. Batch_loss: 1.311123 \n",
      "Batch: 501. Acc: 0.539264. Loss: 1.273470. Batch_acc: 0.537935. Batch_loss: 1.258221 \n",
      "Batch: 502. Acc: 0.539289. Loss: 1.273371. Batch_acc: 0.551944. Batch_loss: 1.223474 \n",
      "Checkpointing on batch: 502. Accuracy: 0.5392888215125604. Loss per char: 1.2733713142268013. Time: 1627222226.7902179\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 22, 24, 20, 24, 21, 26, 19,\n",
      "        23, 24, 19, 23, 19,  1, 12,  1, 14, 22, 24, 15,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.539326. Loss: 1.273331. Batch_acc: 0.558193. Batch_loss: 1.252967 \n",
      "Batch: 504. Acc: 0.539308. Loss: 1.273357. Batch_acc: 0.530023. Batch_loss: 1.286216 \n",
      "Batch: 505. Acc: 0.539306. Loss: 1.273357. Batch_acc: 0.538640. Batch_loss: 1.273618 \n",
      "Batch: 506. Acc: 0.539303. Loss: 1.273377. Batch_acc: 0.537653. Batch_loss: 1.283386 \n",
      "Batch: 507. Acc: 0.539337. Loss: 1.273337. Batch_acc: 0.556061. Batch_loss: 1.253473 \n",
      "Batch: 508. Acc: 0.539357. Loss: 1.273299. Batch_acc: 0.549488. Batch_loss: 1.254485 \n",
      "Batch: 509. Acc: 0.539396. Loss: 1.273202. Batch_acc: 0.558890. Batch_loss: 1.224227 \n",
      "Batch: 510. Acc: 0.539381. Loss: 1.273269. Batch_acc: 0.532062. Batch_loss: 1.307930 \n",
      "Batch: 511. Acc: 0.539359. Loss: 1.273265. Batch_acc: 0.528109. Batch_loss: 1.271229 \n",
      "Batch: 512. Acc: 0.539376. Loss: 1.273209. Batch_acc: 0.548000. Batch_loss: 1.244731 \n",
      "Batch: 513. Acc: 0.539368. Loss: 1.273264. Batch_acc: 0.535534. Batch_loss: 1.300290 \n",
      "Batch: 514. Acc: 0.539345. Loss: 1.273267. Batch_acc: 0.527523. Batch_loss: 1.274884 \n",
      "Batch: 515. Acc: 0.539352. Loss: 1.273262. Batch_acc: 0.542553. Batch_loss: 1.270898 \n",
      "Batch: 516. Acc: 0.539356. Loss: 1.273206. Batch_acc: 0.541620. Batch_loss: 1.245193 \n",
      "Batch: 517. Acc: 0.539355. Loss: 1.273233. Batch_acc: 0.538640. Batch_loss: 1.287053 \n",
      "Batch: 518. Acc: 0.539387. Loss: 1.273096. Batch_acc: 0.555743. Batch_loss: 1.203833 \n",
      "Batch: 519. Acc: 0.539410. Loss: 1.273009. Batch_acc: 0.551055. Batch_loss: 1.227942 \n",
      "Batch: 520. Acc: 0.539436. Loss: 1.272971. Batch_acc: 0.552901. Batch_loss: 1.253330 \n",
      "Batch: 521. Acc: 0.539458. Loss: 1.272895. Batch_acc: 0.550950. Batch_loss: 1.233457 \n",
      "Batch: 522. Acc: 0.539486. Loss: 1.272818. Batch_acc: 0.554583. Batch_loss: 1.231757 \n",
      "Batch: 523. Acc: 0.539450. Loss: 1.272937. Batch_acc: 0.520821. Batch_loss: 1.335082 \n",
      "Batch: 524. Acc: 0.539421. Loss: 1.273011. Batch_acc: 0.524217. Batch_loss: 1.311290 \n",
      "Batch: 525. Acc: 0.539496. Loss: 1.272844. Batch_acc: 0.577567. Batch_loss: 1.187858 \n",
      "Batch: 526. Acc: 0.539481. Loss: 1.272896. Batch_acc: 0.531603. Batch_loss: 1.299621 \n",
      "Batch: 527. Acc: 0.539465. Loss: 1.272923. Batch_acc: 0.531144. Batch_loss: 1.287096 \n",
      "Batch: 528. Acc: 0.539431. Loss: 1.273009. Batch_acc: 0.520833. Batch_loss: 1.320017 \n",
      "Batch: 529. Acc: 0.539474. Loss: 1.272950. Batch_acc: 0.561697. Batch_loss: 1.242369 \n",
      "Batch: 530. Acc: 0.539472. Loss: 1.272952. Batch_acc: 0.538462. Batch_loss: 1.273923 \n",
      "Batch: 531. Acc: 0.539488. Loss: 1.272980. Batch_acc: 0.548110. Batch_loss: 1.288041 \n",
      "Batch: 532. Acc: 0.539454. Loss: 1.273103. Batch_acc: 0.520612. Batch_loss: 1.340074 \n",
      "Batch: 533. Acc: 0.539455. Loss: 1.273089. Batch_acc: 0.540150. Batch_loss: 1.265518 \n",
      "Batch: 534. Acc: 0.539499. Loss: 1.272966. Batch_acc: 0.562606. Batch_loss: 1.208175 \n",
      "Batch: 535. Acc: 0.539560. Loss: 1.272826. Batch_acc: 0.571270. Batch_loss: 1.200463 \n",
      "Batch: 536. Acc: 0.539601. Loss: 1.272719. Batch_acc: 0.561265. Batch_loss: 1.216624 \n",
      "Batch: 537. Acc: 0.539561. Loss: 1.272831. Batch_acc: 0.517544. Batch_loss: 1.334206 \n",
      "Batch: 538. Acc: 0.539546. Loss: 1.272832. Batch_acc: 0.531357. Batch_loss: 1.273402 \n",
      "Batch: 539. Acc: 0.539577. Loss: 1.272769. Batch_acc: 0.556310. Batch_loss: 1.239101 \n",
      "Batch: 540. Acc: 0.539585. Loss: 1.272728. Batch_acc: 0.543739. Batch_loss: 1.250496 \n",
      "Batch: 541. Acc: 0.539564. Loss: 1.272775. Batch_acc: 0.528652. Batch_loss: 1.297563 \n",
      "Batch: 542. Acc: 0.539538. Loss: 1.272825. Batch_acc: 0.525576. Batch_loss: 1.299421 \n",
      "Batch: 543. Acc: 0.539507. Loss: 1.272844. Batch_acc: 0.522805. Batch_loss: 1.283030 \n",
      "Batch: 544. Acc: 0.539489. Loss: 1.272889. Batch_acc: 0.529446. Batch_loss: 1.297429 \n",
      "Batch: 545. Acc: 0.539460. Loss: 1.272960. Batch_acc: 0.523419. Batch_loss: 1.312822 \n",
      "Batch: 546. Acc: 0.539442. Loss: 1.273010. Batch_acc: 0.529377. Batch_loss: 1.300763 \n",
      "Batch: 547. Acc: 0.539441. Loss: 1.273019. Batch_acc: 0.539130. Batch_loss: 1.278114 \n",
      "Batch: 548. Acc: 0.539459. Loss: 1.273003. Batch_acc: 0.549223. Batch_loss: 1.264344 \n",
      "Batch: 549. Acc: 0.539447. Loss: 1.273032. Batch_acc: 0.532921. Batch_loss: 1.288154 \n",
      "Batch: 550. Acc: 0.539433. Loss: 1.273079. Batch_acc: 0.531915. Batch_loss: 1.299030 \n",
      "Batch: 551. Acc: 0.539444. Loss: 1.273107. Batch_acc: 0.545611. Batch_loss: 1.288769 \n",
      "Batch: 552. Acc: 0.539469. Loss: 1.273069. Batch_acc: 0.553155. Batch_loss: 1.252381 \n",
      "Batch: 553. Acc: 0.539516. Loss: 1.272992. Batch_acc: 0.564898. Batch_loss: 1.231154 \n",
      "Batch: 554. Acc: 0.539555. Loss: 1.272855. Batch_acc: 0.561213. Batch_loss: 1.196875 \n",
      "Batch: 555. Acc: 0.539549. Loss: 1.272875. Batch_acc: 0.535714. Batch_loss: 1.284431 \n",
      "Batch: 556. Acc: 0.539566. Loss: 1.272878. Batch_acc: 0.549405. Batch_loss: 1.274651 \n",
      "Batch: 557. Acc: 0.539596. Loss: 1.272773. Batch_acc: 0.556322. Batch_loss: 1.214088 \n",
      "Batch: 558. Acc: 0.539586. Loss: 1.272847. Batch_acc: 0.533804. Batch_loss: 1.315147 \n",
      "Batch: 559. Acc: 0.539622. Loss: 1.272739. Batch_acc: 0.560536. Batch_loss: 1.211551 \n",
      "Batch: 560. Acc: 0.539590. Loss: 1.272800. Batch_acc: 0.521152. Batch_loss: 1.307455 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 561. Acc: 0.539558. Loss: 1.272853. Batch_acc: 0.520821. Batch_loss: 1.303213 \n",
      "Batch: 562. Acc: 0.539528. Loss: 1.272864. Batch_acc: 0.522701. Batch_loss: 1.279257 \n",
      "Batch: 563. Acc: 0.539546. Loss: 1.272828. Batch_acc: 0.549766. Batch_loss: 1.252135 \n",
      "Batch: 564. Acc: 0.539567. Loss: 1.272781. Batch_acc: 0.551546. Batch_loss: 1.246240 \n",
      "Batch: 565. Acc: 0.539542. Loss: 1.272877. Batch_acc: 0.525176. Batch_loss: 1.328396 \n",
      "Batch: 566. Acc: 0.539586. Loss: 1.272805. Batch_acc: 0.564220. Batch_loss: 1.232110 \n",
      "Batch: 567. Acc: 0.539562. Loss: 1.272867. Batch_acc: 0.525373. Batch_loss: 1.309204 \n",
      "Batch: 568. Acc: 0.539552. Loss: 1.272895. Batch_acc: 0.534078. Batch_loss: 1.288380 \n",
      "Batch: 569. Acc: 0.539532. Loss: 1.272954. Batch_acc: 0.528161. Batch_loss: 1.306789 \n",
      "Batch: 570. Acc: 0.539541. Loss: 1.272976. Batch_acc: 0.545087. Batch_loss: 1.285383 \n",
      "Batch: 571. Acc: 0.539501. Loss: 1.273121. Batch_acc: 0.516686. Batch_loss: 1.355840 \n",
      "Batch: 572. Acc: 0.539474. Loss: 1.273155. Batch_acc: 0.524025. Batch_loss: 1.292462 \n",
      "Batch: 573. Acc: 0.539450. Loss: 1.273254. Batch_acc: 0.525335. Batch_loss: 1.330974 \n",
      "Batch: 574. Acc: 0.539405. Loss: 1.273325. Batch_acc: 0.513357. Batch_loss: 1.314037 \n",
      "Batch: 575. Acc: 0.539397. Loss: 1.273356. Batch_acc: 0.534977. Batch_loss: 1.291530 \n",
      "Batch: 576. Acc: 0.539381. Loss: 1.273443. Batch_acc: 0.530127. Batch_loss: 1.323737 \n",
      "Batch: 577. Acc: 0.539379. Loss: 1.273437. Batch_acc: 0.538101. Batch_loss: 1.270100 \n",
      "Batch: 578. Acc: 0.539393. Loss: 1.273426. Batch_acc: 0.547429. Batch_loss: 1.267063 \n",
      "Batch: 579. Acc: 0.539428. Loss: 1.273348. Batch_acc: 0.560116. Batch_loss: 1.227597 \n",
      "Batch: 580. Acc: 0.539439. Loss: 1.273313. Batch_acc: 0.545248. Batch_loss: 1.253500 \n",
      "Batch: 581. Acc: 0.539425. Loss: 1.273361. Batch_acc: 0.531432. Batch_loss: 1.301357 \n",
      "Batch: 582. Acc: 0.539444. Loss: 1.273270. Batch_acc: 0.550607. Batch_loss: 1.219994 \n",
      "Batch: 583. Acc: 0.539411. Loss: 1.273355. Batch_acc: 0.519930. Batch_loss: 1.323973 \n",
      "Batch: 584. Acc: 0.539416. Loss: 1.273337. Batch_acc: 0.542286. Batch_loss: 1.262865 \n",
      "Batch: 585. Acc: 0.539400. Loss: 1.273359. Batch_acc: 0.529617. Batch_loss: 1.286222 \n",
      "Batch: 586. Acc: 0.539376. Loss: 1.273467. Batch_acc: 0.525346. Batch_loss: 1.337029 \n",
      "Batch: 587. Acc: 0.539371. Loss: 1.273479. Batch_acc: 0.536786. Batch_loss: 1.280656 \n",
      "Batch: 588. Acc: 0.539335. Loss: 1.273575. Batch_acc: 0.517158. Batch_loss: 1.332887 \n",
      "Batch: 589. Acc: 0.539338. Loss: 1.273588. Batch_acc: 0.540728. Batch_loss: 1.281179 \n",
      "Batch: 590. Acc: 0.539331. Loss: 1.273553. Batch_acc: 0.535172. Batch_loss: 1.253640 \n",
      "Batch: 591. Acc: 0.539333. Loss: 1.273549. Batch_acc: 0.540745. Batch_loss: 1.270736 \n",
      "Batch: 592. Acc: 0.539326. Loss: 1.273577. Batch_acc: 0.534951. Batch_loss: 1.290276 \n",
      "Batch: 593. Acc: 0.539351. Loss: 1.273529. Batch_acc: 0.554039. Batch_loss: 1.245481 \n",
      "Batch: 594. Acc: 0.539433. Loss: 1.273350. Batch_acc: 0.589089. Batch_loss: 1.166306 \n",
      "Batch: 595. Acc: 0.539484. Loss: 1.273246. Batch_acc: 0.569468. Batch_loss: 1.211472 \n",
      "Batch: 596. Acc: 0.539442. Loss: 1.273391. Batch_acc: 0.513937. Batch_loss: 1.360499 \n",
      "Batch: 597. Acc: 0.539481. Loss: 1.273297. Batch_acc: 0.562753. Batch_loss: 1.217218 \n",
      "Batch: 598. Acc: 0.539480. Loss: 1.273266. Batch_acc: 0.539319. Batch_loss: 1.254358 \n",
      "Batch: 599. Acc: 0.539455. Loss: 1.273316. Batch_acc: 0.523865. Batch_loss: 1.303285 \n",
      "Batch: 600. Acc: 0.539481. Loss: 1.273291. Batch_acc: 0.554992. Batch_loss: 1.258561 \n",
      "Batch: 601. Acc: 0.539477. Loss: 1.273302. Batch_acc: 0.536854. Batch_loss: 1.280006 \n",
      "Batch: 602. Acc: 0.539483. Loss: 1.273264. Batch_acc: 0.543416. Batch_loss: 1.250501 \n",
      "Batch: 603. Acc: 0.539479. Loss: 1.273304. Batch_acc: 0.536897. Batch_loss: 1.297411 \n",
      "Batch: 604. Acc: 0.539514. Loss: 1.273183. Batch_acc: 0.560658. Batch_loss: 1.201109 \n",
      "Batch: 605. Acc: 0.539518. Loss: 1.273143. Batch_acc: 0.541520. Batch_loss: 1.248872 \n",
      "Batch: 606. Acc: 0.539492. Loss: 1.273213. Batch_acc: 0.524083. Batch_loss: 1.315221 \n",
      "Batch: 607. Acc: 0.539513. Loss: 1.273198. Batch_acc: 0.551763. Batch_loss: 1.264335 \n",
      "Batch: 608. Acc: 0.539533. Loss: 1.273092. Batch_acc: 0.551986. Batch_loss: 1.207701 \n",
      "Batch: 609. Acc: 0.539519. Loss: 1.273138. Batch_acc: 0.531159. Batch_loss: 1.301765 \n",
      "Batch: 610. Acc: 0.539537. Loss: 1.273101. Batch_acc: 0.550056. Batch_loss: 1.250845 \n",
      "Batch: 611. Acc: 0.539551. Loss: 1.273069. Batch_acc: 0.547860. Batch_loss: 1.254062 \n",
      "Batch: 612. Acc: 0.539564. Loss: 1.273003. Batch_acc: 0.547921. Batch_loss: 1.232483 \n",
      "Batch: 613. Acc: 0.539604. Loss: 1.272918. Batch_acc: 0.563341. Batch_loss: 1.222087 \n",
      "Batch: 614. Acc: 0.539600. Loss: 1.272889. Batch_acc: 0.537262. Batch_loss: 1.254725 \n",
      "Batch: 615. Acc: 0.539655. Loss: 1.272754. Batch_acc: 0.573504. Batch_loss: 1.189116 \n",
      "Batch: 616. Acc: 0.539636. Loss: 1.272802. Batch_acc: 0.528057. Batch_loss: 1.302909 \n",
      "Batch: 617. Acc: 0.539635. Loss: 1.272812. Batch_acc: 0.539027. Batch_loss: 1.279095 \n",
      "Batch: 618. Acc: 0.539633. Loss: 1.272782. Batch_acc: 0.538333. Batch_loss: 1.254690 \n",
      "Batch: 619. Acc: 0.539622. Loss: 1.272843. Batch_acc: 0.532490. Batch_loss: 1.310536 \n",
      "Batch: 620. Acc: 0.539621. Loss: 1.272865. Batch_acc: 0.539249. Batch_loss: 1.286220 \n",
      "Batch: 621. Acc: 0.539596. Loss: 1.272859. Batch_acc: 0.523782. Batch_loss: 1.269662 \n",
      "Batch: 622. Acc: 0.539627. Loss: 1.272769. Batch_acc: 0.559028. Batch_loss: 1.216019 \n",
      "Batch: 623. Acc: 0.539582. Loss: 1.272865. Batch_acc: 0.511424. Batch_loss: 1.333793 \n",
      "Batch: 624. Acc: 0.539600. Loss: 1.272843. Batch_acc: 0.550985. Batch_loss: 1.259063 \n",
      "Batch: 625. Acc: 0.539575. Loss: 1.272858. Batch_acc: 0.523526. Batch_loss: 1.282466 \n",
      "Batch: 626. Acc: 0.539552. Loss: 1.272900. Batch_acc: 0.524730. Batch_loss: 1.299013 \n",
      "Batch: 627. Acc: 0.539541. Loss: 1.272939. Batch_acc: 0.532834. Batch_loss: 1.297593 \n",
      "Batch: 628. Acc: 0.539555. Loss: 1.272953. Batch_acc: 0.548647. Batch_loss: 1.281937 \n",
      "Batch: 629. Acc: 0.539559. Loss: 1.272961. Batch_acc: 0.542088. Batch_loss: 1.277437 \n",
      "Batch: 630. Acc: 0.539568. Loss: 1.272905. Batch_acc: 0.545040. Batch_loss: 1.238150 \n",
      "Batch: 631. Acc: 0.539613. Loss: 1.272800. Batch_acc: 0.567958. Batch_loss: 1.206339 \n",
      "Batch: 632. Acc: 0.539619. Loss: 1.272742. Batch_acc: 0.543787. Batch_loss: 1.235054 \n",
      "Batch: 633. Acc: 0.539602. Loss: 1.272803. Batch_acc: 0.528644. Batch_loss: 1.310694 \n",
      "Batch: 634. Acc: 0.539650. Loss: 1.272722. Batch_acc: 0.570110. Batch_loss: 1.220863 \n",
      "Batch: 635. Acc: 0.539665. Loss: 1.272690. Batch_acc: 0.549769. Batch_loss: 1.252725 \n",
      "Batch: 636. Acc: 0.539653. Loss: 1.272790. Batch_acc: 0.531452. Batch_loss: 1.337888 \n",
      "Batch: 637. Acc: 0.539639. Loss: 1.272846. Batch_acc: 0.531050. Batch_loss: 1.308302 \n",
      "Batch: 638. Acc: 0.539654. Loss: 1.272808. Batch_acc: 0.549031. Batch_loss: 1.249269 \n",
      "Batch: 639. Acc: 0.539669. Loss: 1.272778. Batch_acc: 0.549099. Batch_loss: 1.253172 \n",
      "Batch: 640. Acc: 0.539666. Loss: 1.272763. Batch_acc: 0.537653. Batch_loss: 1.262937 \n",
      "Batch: 641. Acc: 0.539621. Loss: 1.272891. Batch_acc: 0.510638. Batch_loss: 1.355194 \n",
      "Batch: 642. Acc: 0.539615. Loss: 1.272908. Batch_acc: 0.535940. Batch_loss: 1.283527 \n",
      "Batch: 643. Acc: 0.539613. Loss: 1.272918. Batch_acc: 0.538235. Batch_loss: 1.279397 \n",
      "Batch: 644. Acc: 0.539613. Loss: 1.272895. Batch_acc: 0.539645. Batch_loss: 1.258014 \n",
      "Batch: 645. Acc: 0.539567. Loss: 1.272977. Batch_acc: 0.509434. Batch_loss: 1.327358 \n",
      "Batch: 646. Acc: 0.539543. Loss: 1.273054. Batch_acc: 0.523701. Batch_loss: 1.322211 \n",
      "Batch: 647. Acc: 0.539548. Loss: 1.273053. Batch_acc: 0.542890. Batch_loss: 1.272511 \n",
      "Batch: 648. Acc: 0.539543. Loss: 1.273068. Batch_acc: 0.536348. Batch_loss: 1.282868 \n",
      "Batch: 649. Acc: 0.539524. Loss: 1.273121. Batch_acc: 0.527199. Batch_loss: 1.307472 \n",
      "Batch: 650. Acc: 0.539539. Loss: 1.273081. Batch_acc: 0.549794. Batch_loss: 1.246188 \n",
      "Batch: 651. Acc: 0.539554. Loss: 1.273039. Batch_acc: 0.549076. Batch_loss: 1.246043 \n",
      "Batch: 652. Acc: 0.539561. Loss: 1.273045. Batch_acc: 0.544399. Batch_loss: 1.276725 \n",
      "Batch: 653. Acc: 0.539587. Loss: 1.272978. Batch_acc: 0.556382. Batch_loss: 1.229710 \n",
      "Batch: 654. Acc: 0.539550. Loss: 1.273031. Batch_acc: 0.515274. Batch_loss: 1.307783 \n",
      "Batch: 655. Acc: 0.539528. Loss: 1.273095. Batch_acc: 0.525375. Batch_loss: 1.314614 \n",
      "Batch: 656. Acc: 0.539547. Loss: 1.273033. Batch_acc: 0.552126. Batch_loss: 1.232012 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 657. Acc: 0.539549. Loss: 1.273024. Batch_acc: 0.540337. Batch_loss: 1.266855 \n",
      "Batch: 658. Acc: 0.539560. Loss: 1.272988. Batch_acc: 0.547344. Batch_loss: 1.249262 \n",
      "Batch: 659. Acc: 0.539574. Loss: 1.272977. Batch_acc: 0.548115. Batch_loss: 1.266393 \n",
      "Batch: 660. Acc: 0.539609. Loss: 1.272897. Batch_acc: 0.562748. Batch_loss: 1.220553 \n",
      "Batch: 661. Acc: 0.539610. Loss: 1.272860. Batch_acc: 0.540116. Batch_loss: 1.247794 \n",
      "Batch: 662. Acc: 0.539561. Loss: 1.272982. Batch_acc: 0.507946. Batch_loss: 1.352960 \n",
      "Batch: 663. Acc: 0.539527. Loss: 1.273058. Batch_acc: 0.516886. Batch_loss: 1.323532 \n",
      "Batch: 664. Acc: 0.539524. Loss: 1.273085. Batch_acc: 0.537545. Batch_loss: 1.291380 \n",
      "Batch: 665. Acc: 0.539504. Loss: 1.273141. Batch_acc: 0.525985. Batch_loss: 1.310374 \n",
      "Batch: 666. Acc: 0.539483. Loss: 1.273183. Batch_acc: 0.525708. Batch_loss: 1.300776 \n",
      "Batch: 667. Acc: 0.539513. Loss: 1.273072. Batch_acc: 0.558957. Batch_loss: 1.200154 \n",
      "Batch: 668. Acc: 0.539526. Loss: 1.272983. Batch_acc: 0.547984. Batch_loss: 1.214502 \n",
      "Batch: 669. Acc: 0.539534. Loss: 1.273009. Batch_acc: 0.545145. Batch_loss: 1.290013 \n",
      "Batch: 670. Acc: 0.539556. Loss: 1.273009. Batch_acc: 0.553682. Batch_loss: 1.273379 \n",
      "Batch: 671. Acc: 0.539543. Loss: 1.273064. Batch_acc: 0.530528. Batch_loss: 1.310857 \n",
      "Batch: 672. Acc: 0.539556. Loss: 1.273044. Batch_acc: 0.548824. Batch_loss: 1.258915 \n",
      "Batch: 673. Acc: 0.539529. Loss: 1.273109. Batch_acc: 0.520955. Batch_loss: 1.317498 \n",
      "Batch: 674. Acc: 0.539518. Loss: 1.273113. Batch_acc: 0.532078. Batch_loss: 1.276327 \n",
      "Batch: 675. Acc: 0.539554. Loss: 1.273029. Batch_acc: 0.563173. Batch_loss: 1.216631 \n",
      "Batch: 676. Acc: 0.539544. Loss: 1.273098. Batch_acc: 0.532749. Batch_loss: 1.320647 \n",
      "Batch: 677. Acc: 0.539568. Loss: 1.273079. Batch_acc: 0.556061. Batch_loss: 1.260588 \n",
      "Batch: 678. Acc: 0.539541. Loss: 1.273100. Batch_acc: 0.520475. Batch_loss: 1.287685 \n",
      "Batch: 679. Acc: 0.539563. Loss: 1.273065. Batch_acc: 0.553872. Batch_loss: 1.249929 \n",
      "Batch: 680. Acc: 0.539534. Loss: 1.273126. Batch_acc: 0.519839. Batch_loss: 1.314370 \n",
      "Batch: 681. Acc: 0.539552. Loss: 1.273071. Batch_acc: 0.551764. Batch_loss: 1.235565 \n",
      "Batch: 682. Acc: 0.539579. Loss: 1.273007. Batch_acc: 0.557681. Batch_loss: 1.230691 \n",
      "Batch: 683. Acc: 0.539580. Loss: 1.272989. Batch_acc: 0.540698. Batch_loss: 1.259905 \n",
      "Batch: 684. Acc: 0.539611. Loss: 1.272903. Batch_acc: 0.560067. Batch_loss: 1.216384 \n",
      "Batch: 685. Acc: 0.539639. Loss: 1.272812. Batch_acc: 0.558442. Batch_loss: 1.211335 \n",
      "Batch: 686. Acc: 0.539623. Loss: 1.272840. Batch_acc: 0.528513. Batch_loss: 1.292495 \n",
      "Batch: 687. Acc: 0.539616. Loss: 1.272818. Batch_acc: 0.534620. Batch_loss: 1.258038 \n",
      "Batch: 688. Acc: 0.539601. Loss: 1.272878. Batch_acc: 0.529110. Batch_loss: 1.313917 \n",
      "Batch: 689. Acc: 0.539598. Loss: 1.272883. Batch_acc: 0.537522. Batch_loss: 1.276584 \n",
      "Batch: 690. Acc: 0.539594. Loss: 1.272866. Batch_acc: 0.536866. Batch_loss: 1.260743 \n",
      "Batch: 691. Acc: 0.539626. Loss: 1.272768. Batch_acc: 0.561534. Batch_loss: 1.205608 \n",
      "Batch: 692. Acc: 0.539644. Loss: 1.272738. Batch_acc: 0.552359. Batch_loss: 1.251969 \n",
      "Batch: 693. Acc: 0.539669. Loss: 1.272724. Batch_acc: 0.557358. Batch_loss: 1.263212 \n",
      "Batch: 694. Acc: 0.539691. Loss: 1.272661. Batch_acc: 0.554530. Batch_loss: 1.228477 \n",
      "Batch: 695. Acc: 0.539672. Loss: 1.272689. Batch_acc: 0.526590. Batch_loss: 1.292413 \n",
      "Batch: 696. Acc: 0.539621. Loss: 1.272794. Batch_acc: 0.504318. Batch_loss: 1.346066 \n",
      "Batch: 697. Acc: 0.539609. Loss: 1.272778. Batch_acc: 0.531340. Batch_loss: 1.261035 \n",
      "Batch: 698. Acc: 0.539633. Loss: 1.272734. Batch_acc: 0.556593. Batch_loss: 1.242038 \n",
      "Batch: 699. Acc: 0.539614. Loss: 1.272795. Batch_acc: 0.525633. Batch_loss: 1.316450 \n",
      "Batch: 700. Acc: 0.539613. Loss: 1.272766. Batch_acc: 0.539090. Batch_loss: 1.252121 \n",
      "Batch: 701. Acc: 0.539589. Loss: 1.272793. Batch_acc: 0.523468. Batch_loss: 1.290799 \n",
      "Batch: 702. Acc: 0.539599. Loss: 1.272777. Batch_acc: 0.546948. Batch_loss: 1.261506 \n",
      "Batch: 703. Acc: 0.539594. Loss: 1.272814. Batch_acc: 0.535461. Batch_loss: 1.299199 \n",
      "Batch: 704. Acc: 0.539587. Loss: 1.272827. Batch_acc: 0.535119. Batch_loss: 1.282479 \n",
      "Batch: 705. Acc: 0.539565. Loss: 1.272835. Batch_acc: 0.523699. Batch_loss: 1.278919 \n",
      "Batch: 706. Acc: 0.539528. Loss: 1.272903. Batch_acc: 0.512941. Batch_loss: 1.321444 \n",
      "Batch: 707. Acc: 0.539539. Loss: 1.272874. Batch_acc: 0.547278. Batch_loss: 1.252463 \n",
      "Batch: 708. Acc: 0.539550. Loss: 1.272843. Batch_acc: 0.547052. Batch_loss: 1.251443 \n",
      "Batch: 709. Acc: 0.539563. Loss: 1.272780. Batch_acc: 0.549133. Batch_loss: 1.227597 \n",
      "Batch: 710. Acc: 0.539588. Loss: 1.272722. Batch_acc: 0.556948. Batch_loss: 1.232199 \n",
      "Batch: 711. Acc: 0.539600. Loss: 1.272716. Batch_acc: 0.548217. Batch_loss: 1.268605 \n",
      "Batch: 712. Acc: 0.539625. Loss: 1.272645. Batch_acc: 0.557963. Batch_loss: 1.221130 \n",
      "Batch: 713. Acc: 0.539621. Loss: 1.272695. Batch_acc: 0.536458. Batch_loss: 1.308359 \n",
      "Batch: 714. Acc: 0.539577. Loss: 1.272783. Batch_acc: 0.507835. Batch_loss: 1.335915 \n",
      "Batch: 715. Acc: 0.539561. Loss: 1.272869. Batch_acc: 0.527991. Batch_loss: 1.336254 \n",
      "Batch: 716. Acc: 0.539558. Loss: 1.272868. Batch_acc: 0.537768. Batch_loss: 1.272087 \n",
      "Batch: 717. Acc: 0.539585. Loss: 1.272811. Batch_acc: 0.557724. Batch_loss: 1.233308 \n",
      "Batch: 718. Acc: 0.539578. Loss: 1.272854. Batch_acc: 0.534602. Batch_loss: 1.303755 \n",
      "Batch: 719. Acc: 0.539568. Loss: 1.272855. Batch_acc: 0.532452. Batch_loss: 1.273549 \n",
      "Batch: 720. Acc: 0.539573. Loss: 1.272803. Batch_acc: 0.542791. Batch_loss: 1.235315 \n",
      "Batch: 721. Acc: 0.539553. Loss: 1.272849. Batch_acc: 0.525258. Batch_loss: 1.305799 \n",
      "Batch: 722. Acc: 0.539550. Loss: 1.272902. Batch_acc: 0.537709. Batch_loss: 1.311477 \n",
      "Batch: 723. Acc: 0.539561. Loss: 1.272876. Batch_acc: 0.547458. Batch_loss: 1.254067 \n",
      "Batch: 724. Acc: 0.539565. Loss: 1.272899. Batch_acc: 0.541954. Batch_loss: 1.289955 \n",
      "Batch: 725. Acc: 0.539535. Loss: 1.272946. Batch_acc: 0.517837. Batch_loss: 1.306560 \n",
      "Batch: 726. Acc: 0.539561. Loss: 1.272885. Batch_acc: 0.558637. Batch_loss: 1.228645 \n",
      "Batch: 727. Acc: 0.539562. Loss: 1.272877. Batch_acc: 0.540033. Batch_loss: 1.267352 \n",
      "Batch: 728. Acc: 0.539592. Loss: 1.272767. Batch_acc: 0.561998. Batch_loss: 1.192887 \n",
      "Batch: 729. Acc: 0.539581. Loss: 1.272797. Batch_acc: 0.530968. Batch_loss: 1.295372 \n",
      "Batch: 730. Acc: 0.539574. Loss: 1.272822. Batch_acc: 0.534058. Batch_loss: 1.291338 \n",
      "Batch: 731. Acc: 0.539605. Loss: 1.272750. Batch_acc: 0.562644. Batch_loss: 1.220250 \n",
      "Batch: 732. Acc: 0.539605. Loss: 1.272757. Batch_acc: 0.539636. Batch_loss: 1.277501 \n",
      "Batch: 733. Acc: 0.539610. Loss: 1.272750. Batch_acc: 0.543453. Batch_loss: 1.267738 \n",
      "Batch: 734. Acc: 0.539589. Loss: 1.272774. Batch_acc: 0.523672. Batch_loss: 1.290911 \n",
      "Batch: 735. Acc: 0.539582. Loss: 1.272732. Batch_acc: 0.534573. Batch_loss: 1.241224 \n",
      "Batch: 736. Acc: 0.539575. Loss: 1.272740. Batch_acc: 0.534071. Batch_loss: 1.278847 \n",
      "Batch: 737. Acc: 0.539606. Loss: 1.272672. Batch_acc: 0.561841. Batch_loss: 1.224177 \n",
      "Batch: 738. Acc: 0.539644. Loss: 1.272576. Batch_acc: 0.567630. Batch_loss: 1.201436 \n",
      "Batch: 739. Acc: 0.539645. Loss: 1.272586. Batch_acc: 0.540648. Batch_loss: 1.279834 \n",
      "Batch: 740. Acc: 0.539647. Loss: 1.272596. Batch_acc: 0.541116. Batch_loss: 1.279854 \n",
      "Batch: 741. Acc: 0.539640. Loss: 1.272571. Batch_acc: 0.534325. Batch_loss: 1.254080 \n",
      "Batch: 742. Acc: 0.539608. Loss: 1.272641. Batch_acc: 0.516148. Batch_loss: 1.324779 \n",
      "Batch: 743. Acc: 0.539619. Loss: 1.272598. Batch_acc: 0.547786. Batch_loss: 1.240148 \n",
      "Batch: 744. Acc: 0.539656. Loss: 1.272493. Batch_acc: 0.566969. Batch_loss: 1.195695 \n",
      "Batch: 745. Acc: 0.539649. Loss: 1.272513. Batch_acc: 0.534562. Batch_loss: 1.287223 \n",
      "Batch: 746. Acc: 0.539679. Loss: 1.272465. Batch_acc: 0.561139. Batch_loss: 1.237654 \n",
      "Batch: 747. Acc: 0.539691. Loss: 1.272426. Batch_acc: 0.548837. Batch_loss: 1.243314 \n",
      "Batch: 748. Acc: 0.539680. Loss: 1.272426. Batch_acc: 0.531175. Batch_loss: 1.272097 \n",
      "Batch: 749. Acc: 0.539681. Loss: 1.272449. Batch_acc: 0.540365. Batch_loss: 1.290689 \n",
      "Batch: 750. Acc: 0.539673. Loss: 1.272474. Batch_acc: 0.533019. Batch_loss: 1.291502 \n",
      "Batch: 751. Acc: 0.539667. Loss: 1.272485. Batch_acc: 0.535227. Batch_loss: 1.280401 \n",
      "Batch: 752. Acc: 0.539663. Loss: 1.272437. Batch_acc: 0.537110. Batch_loss: 1.236896 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 753. Acc: 0.539692. Loss: 1.272373. Batch_acc: 0.560879. Batch_loss: 1.225579 \n",
      "Checkpointing on batch: 753. Accuracy: 0.5396918292165558. Loss per char: 1.2723733360684126. Time: 1627222431.757679\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 14, 18, 19, 22,\n",
      "        15, 25, 17, 21, 21,  1, 66, 79, 69,  1, 18, 15, 21, 23, 21, 22, 24, 17,\n",
      "        19, 32,  3], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.539663. Loss: 1.272414. Batch_acc: 0.517805. Batch_loss: 1.303499 \n",
      "Batch: 755. Acc: 0.539633. Loss: 1.272501. Batch_acc: 0.516243. Batch_loss: 1.339653 \n",
      "Batch: 756. Acc: 0.539667. Loss: 1.272406. Batch_acc: 0.565143. Batch_loss: 1.201647 \n",
      "Batch: 757. Acc: 0.539664. Loss: 1.272408. Batch_acc: 0.537209. Batch_loss: 1.274037 \n",
      "Batch: 758. Acc: 0.539648. Loss: 1.272435. Batch_acc: 0.527809. Batch_loss: 1.292229 \n",
      "Batch: 759. Acc: 0.539653. Loss: 1.272425. Batch_acc: 0.543578. Batch_loss: 1.264580 \n",
      "Batch: 760. Acc: 0.539646. Loss: 1.272441. Batch_acc: 0.533918. Batch_loss: 1.285479 \n",
      "Batch: 761. Acc: 0.539629. Loss: 1.272492. Batch_acc: 0.527366. Batch_loss: 1.310351 \n",
      "Batch: 762. Acc: 0.539615. Loss: 1.272486. Batch_acc: 0.528981. Batch_loss: 1.268366 \n",
      "Batch: 763. Acc: 0.539619. Loss: 1.272482. Batch_acc: 0.542334. Batch_loss: 1.269477 \n",
      "Batch: 764. Acc: 0.539671. Loss: 1.272349. Batch_acc: 0.579677. Batch_loss: 1.170414 \n",
      "Batch: 765. Acc: 0.539667. Loss: 1.272325. Batch_acc: 0.536342. Batch_loss: 1.253275 \n",
      "Batch: 766. Acc: 0.539672. Loss: 1.272288. Batch_acc: 0.543593. Batch_loss: 1.243495 \n",
      "Batch: 767. Acc: 0.539693. Loss: 1.272230. Batch_acc: 0.556272. Batch_loss: 1.227346 \n",
      "Batch: 768. Acc: 0.539714. Loss: 1.272206. Batch_acc: 0.555492. Batch_loss: 1.253859 \n",
      "Batch: 769. Acc: 0.539754. Loss: 1.272099. Batch_acc: 0.570535. Batch_loss: 1.190416 \n",
      "Batch: 770. Acc: 0.539766. Loss: 1.272060. Batch_acc: 0.548424. Batch_loss: 1.241921 \n",
      "Batch: 771. Acc: 0.539775. Loss: 1.272025. Batch_acc: 0.547411. Batch_loss: 1.245403 \n",
      "Batch: 772. Acc: 0.539781. Loss: 1.272017. Batch_acc: 0.544230. Batch_loss: 1.265748 \n",
      "Batch: 773. Acc: 0.539756. Loss: 1.272066. Batch_acc: 0.519860. Batch_loss: 1.310202 \n",
      "Batch: 774. Acc: 0.539784. Loss: 1.271991. Batch_acc: 0.561543. Batch_loss: 1.214662 \n",
      "Batch: 775. Acc: 0.539769. Loss: 1.272036. Batch_acc: 0.527578. Batch_loss: 1.308523 \n",
      "Batch: 776. Acc: 0.539769. Loss: 1.272034. Batch_acc: 0.540070. Batch_loss: 1.270650 \n",
      "Batch: 777. Acc: 0.539769. Loss: 1.272034. Batch_acc: 0.539288. Batch_loss: 1.271735 \n",
      "Batch: 778. Acc: 0.539759. Loss: 1.272044. Batch_acc: 0.532099. Batch_loss: 1.280236 \n",
      "Batch: 779. Acc: 0.539757. Loss: 1.272029. Batch_acc: 0.538071. Batch_loss: 1.260461 \n",
      "Batch: 780. Acc: 0.539756. Loss: 1.272051. Batch_acc: 0.539532. Batch_loss: 1.288824 \n",
      "Batch: 781. Acc: 0.539752. Loss: 1.272103. Batch_acc: 0.536316. Batch_loss: 1.312716 \n",
      "Batch: 782. Acc: 0.539755. Loss: 1.272063. Batch_acc: 0.542072. Batch_loss: 1.240977 \n",
      "Batch: 783. Acc: 0.539759. Loss: 1.272057. Batch_acc: 0.542450. Batch_loss: 1.267820 \n",
      "Batch: 784. Acc: 0.539731. Loss: 1.272113. Batch_acc: 0.518261. Batch_loss: 1.315721 \n",
      "Batch: 785. Acc: 0.539741. Loss: 1.272091. Batch_acc: 0.546971. Batch_loss: 1.255801 \n",
      "Batch: 786. Acc: 0.539745. Loss: 1.272090. Batch_acc: 0.542824. Batch_loss: 1.270755 \n",
      "Batch: 787. Acc: 0.539738. Loss: 1.272103. Batch_acc: 0.534562. Batch_loss: 1.282917 \n",
      "Batch: 788. Acc: 0.539725. Loss: 1.272120. Batch_acc: 0.529478. Batch_loss: 1.285366 \n",
      "Batch: 789. Acc: 0.539728. Loss: 1.272101. Batch_acc: 0.542402. Batch_loss: 1.256748 \n",
      "Batch: 790. Acc: 0.539723. Loss: 1.272145. Batch_acc: 0.535203. Batch_loss: 1.307358 \n",
      "Batch: 791. Acc: 0.539750. Loss: 1.272066. Batch_acc: 0.560948. Batch_loss: 1.210636 \n",
      "Batch: 792. Acc: 0.539747. Loss: 1.272070. Batch_acc: 0.537110. Batch_loss: 1.274761 \n",
      "Batch: 793. Acc: 0.539767. Loss: 1.272043. Batch_acc: 0.556671. Batch_loss: 1.250620 \n",
      "Batch: 794. Acc: 0.539760. Loss: 1.272054. Batch_acc: 0.533601. Batch_loss: 1.280767 \n",
      "Batch: 795. Acc: 0.539761. Loss: 1.272066. Batch_acc: 0.540810. Batch_loss: 1.281176 \n",
      "Batch: 796. Acc: 0.539743. Loss: 1.272142. Batch_acc: 0.525543. Batch_loss: 1.334197 \n",
      "Batch: 797. Acc: 0.539733. Loss: 1.272125. Batch_acc: 0.531638. Batch_loss: 1.258622 \n",
      "Batch: 798. Acc: 0.539736. Loss: 1.272137. Batch_acc: 0.541928. Batch_loss: 1.281499 \n",
      "Batch: 799. Acc: 0.539749. Loss: 1.272103. Batch_acc: 0.549971. Batch_loss: 1.245023 \n",
      "Batch: 800. Acc: 0.539751. Loss: 1.272103. Batch_acc: 0.541544. Batch_loss: 1.272316 \n",
      "Batch: 801. Acc: 0.539766. Loss: 1.272088. Batch_acc: 0.551977. Batch_loss: 1.259647 \n",
      "Batch: 802. Acc: 0.539774. Loss: 1.272089. Batch_acc: 0.546339. Batch_loss: 1.273307 \n",
      "Batch: 803. Acc: 0.539760. Loss: 1.272130. Batch_acc: 0.528018. Batch_loss: 1.304984 \n",
      "Batch: 804. Acc: 0.539748. Loss: 1.272161. Batch_acc: 0.530000. Batch_loss: 1.297962 \n",
      "Batch: 805. Acc: 0.539743. Loss: 1.272153. Batch_acc: 0.535838. Batch_loss: 1.265518 \n",
      "Batch: 806. Acc: 0.539734. Loss: 1.272176. Batch_acc: 0.532731. Batch_loss: 1.290569 \n",
      "Batch: 807. Acc: 0.539739. Loss: 1.272181. Batch_acc: 0.543651. Batch_loss: 1.275730 \n",
      "Batch: 808. Acc: 0.539746. Loss: 1.272197. Batch_acc: 0.544980. Batch_loss: 1.285229 \n",
      "Batch: 809. Acc: 0.539773. Loss: 1.272139. Batch_acc: 0.561772. Batch_loss: 1.224704 \n",
      "Batch: 810. Acc: 0.539771. Loss: 1.272197. Batch_acc: 0.538815. Batch_loss: 1.318882 \n",
      "Batch: 811. Acc: 0.539771. Loss: 1.272200. Batch_acc: 0.539710. Batch_loss: 1.275337 \n",
      "Batch: 812. Acc: 0.539794. Loss: 1.272177. Batch_acc: 0.557930. Batch_loss: 1.253182 \n",
      "Batch: 813. Acc: 0.539769. Loss: 1.272203. Batch_acc: 0.519106. Batch_loss: 1.294200 \n",
      "Batch: 814. Acc: 0.539755. Loss: 1.272239. Batch_acc: 0.528237. Batch_loss: 1.301408 \n",
      "Batch: 815. Acc: 0.539753. Loss: 1.272244. Batch_acc: 0.538287. Batch_loss: 1.276490 \n",
      "Batch: 816. Acc: 0.539748. Loss: 1.272222. Batch_acc: 0.535077. Batch_loss: 1.253697 \n",
      "Batch: 817. Acc: 0.539772. Loss: 1.272127. Batch_acc: 0.559585. Batch_loss: 1.194068 \n",
      "Batch: 818. Acc: 0.539773. Loss: 1.272097. Batch_acc: 0.540899. Batch_loss: 1.247168 \n",
      "Batch: 819. Acc: 0.539791. Loss: 1.272045. Batch_acc: 0.554354. Batch_loss: 1.230076 \n",
      "Batch: 820. Acc: 0.539784. Loss: 1.272044. Batch_acc: 0.533898. Batch_loss: 1.271343 \n",
      "Batch: 821. Acc: 0.539787. Loss: 1.272039. Batch_acc: 0.542572. Batch_loss: 1.268069 \n",
      "Batch: 822. Acc: 0.539765. Loss: 1.272078. Batch_acc: 0.521864. Batch_loss: 1.304348 \n",
      "Batch: 823. Acc: 0.539780. Loss: 1.272059. Batch_acc: 0.551217. Batch_loss: 1.256439 \n",
      "Batch: 824. Acc: 0.539766. Loss: 1.272095. Batch_acc: 0.529006. Batch_loss: 1.302027 \n",
      "Batch: 825. Acc: 0.539775. Loss: 1.272053. Batch_acc: 0.546902. Batch_loss: 1.237364 \n",
      "Batch: 826. Acc: 0.539765. Loss: 1.272070. Batch_acc: 0.530697. Batch_loss: 1.286704 \n",
      "Batch: 827. Acc: 0.539754. Loss: 1.272088. Batch_acc: 0.531058. Batch_loss: 1.286591 \n",
      "Batch: 828. Acc: 0.539760. Loss: 1.272089. Batch_acc: 0.545296. Batch_loss: 1.272885 \n",
      "Batch: 829. Acc: 0.539778. Loss: 1.272065. Batch_acc: 0.554461. Batch_loss: 1.252179 \n",
      "Batch: 830. Acc: 0.539792. Loss: 1.272039. Batch_acc: 0.551546. Batch_loss: 1.250360 \n",
      "Batch: 831. Acc: 0.539806. Loss: 1.272017. Batch_acc: 0.551289. Batch_loss: 1.253771 \n",
      "Batch: 832. Acc: 0.539801. Loss: 1.272046. Batch_acc: 0.535556. Batch_loss: 1.295377 \n",
      "Batch: 833. Acc: 0.539803. Loss: 1.272057. Batch_acc: 0.542019. Batch_loss: 1.280747 \n",
      "Batch: 834. Acc: 0.539832. Loss: 1.272021. Batch_acc: 0.562921. Batch_loss: 1.243066 \n",
      "Batch: 835. Acc: 0.539830. Loss: 1.272049. Batch_acc: 0.538722. Batch_loss: 1.294741 \n",
      "Batch: 836. Acc: 0.539829. Loss: 1.272041. Batch_acc: 0.538462. Batch_loss: 1.265246 \n",
      "Batch: 837. Acc: 0.539842. Loss: 1.271977. Batch_acc: 0.550881. Batch_loss: 1.219310 \n",
      "Batch: 838. Acc: 0.539845. Loss: 1.271959. Batch_acc: 0.541903. Batch_loss: 1.257499 \n",
      "Batch: 839. Acc: 0.539840. Loss: 1.271943. Batch_acc: 0.535882. Batch_loss: 1.257634 \n",
      "Batch: 840. Acc: 0.539839. Loss: 1.271955. Batch_acc: 0.539352. Batch_loss: 1.282379 \n",
      "Batch: 841. Acc: 0.539849. Loss: 1.271904. Batch_acc: 0.547945. Batch_loss: 1.229230 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 842. Acc: 0.539849. Loss: 1.271881. Batch_acc: 0.539384. Batch_loss: 1.252254 \n",
      "Batch: 843. Acc: 0.539847. Loss: 1.271942. Batch_acc: 0.538192. Batch_loss: 1.324913 \n",
      "Batch: 844. Acc: 0.539829. Loss: 1.271987. Batch_acc: 0.525058. Batch_loss: 1.310250 \n",
      "Batch: 845. Acc: 0.539833. Loss: 1.271988. Batch_acc: 0.542989. Batch_loss: 1.272860 \n",
      "Batch: 846. Acc: 0.539818. Loss: 1.272040. Batch_acc: 0.526718. Batch_loss: 1.317116 \n",
      "Batch: 847. Acc: 0.539822. Loss: 1.272001. Batch_acc: 0.543503. Batch_loss: 1.239181 \n",
      "Batch: 848. Acc: 0.539818. Loss: 1.272020. Batch_acc: 0.536405. Batch_loss: 1.287862 \n",
      "Batch: 849. Acc: 0.539864. Loss: 1.271917. Batch_acc: 0.578437. Batch_loss: 1.185246 \n",
      "Batch: 850. Acc: 0.539861. Loss: 1.271899. Batch_acc: 0.536782. Batch_loss: 1.256594 \n",
      "Batch: 851. Acc: 0.539899. Loss: 1.271830. Batch_acc: 0.572484. Batch_loss: 1.213718 \n",
      "Batch: 852. Acc: 0.539905. Loss: 1.271804. Batch_acc: 0.545024. Batch_loss: 1.249351 \n",
      "Batch: 853. Acc: 0.539960. Loss: 1.271676. Batch_acc: 0.586857. Batch_loss: 1.162902 \n",
      "Batch: 854. Acc: 0.539956. Loss: 1.271690. Batch_acc: 0.536416. Batch_loss: 1.283811 \n",
      "Batch: 855. Acc: 0.539956. Loss: 1.271690. Batch_acc: 0.539863. Batch_loss: 1.271434 \n",
      "Batch: 856. Acc: 0.539939. Loss: 1.271698. Batch_acc: 0.525481. Batch_loss: 1.278326 \n",
      "Batch: 857. Acc: 0.539925. Loss: 1.271721. Batch_acc: 0.527991. Batch_loss: 1.292157 \n",
      "Batch: 858. Acc: 0.539933. Loss: 1.271699. Batch_acc: 0.546518. Batch_loss: 1.252424 \n",
      "Batch: 859. Acc: 0.539958. Loss: 1.271650. Batch_acc: 0.561605. Batch_loss: 1.229803 \n",
      "Batch: 860. Acc: 0.539964. Loss: 1.271644. Batch_acc: 0.545145. Batch_loss: 1.267023 \n",
      "Batch: 861. Acc: 0.539965. Loss: 1.271633. Batch_acc: 0.540309. Batch_loss: 1.262170 \n",
      "Batch: 862. Acc: 0.539952. Loss: 1.271658. Batch_acc: 0.529172. Batch_loss: 1.293132 \n",
      "Batch: 863. Acc: 0.539956. Loss: 1.271662. Batch_acc: 0.542708. Batch_loss: 1.275635 \n",
      "Batch: 864. Acc: 0.539938. Loss: 1.271719. Batch_acc: 0.524786. Batch_loss: 1.320065 \n",
      "Batch: 865. Acc: 0.539944. Loss: 1.271712. Batch_acc: 0.545301. Batch_loss: 1.265940 \n",
      "Batch: 866. Acc: 0.539950. Loss: 1.271677. Batch_acc: 0.545349. Batch_loss: 1.241085 \n",
      "Batch: 867. Acc: 0.539980. Loss: 1.271593. Batch_acc: 0.565070. Batch_loss: 1.199893 \n",
      "Batch: 868. Acc: 0.539983. Loss: 1.271619. Batch_acc: 0.542499. Batch_loss: 1.294238 \n",
      "Batch: 869. Acc: 0.540006. Loss: 1.271569. Batch_acc: 0.560159. Batch_loss: 1.228441 \n",
      "Batch: 870. Acc: 0.540020. Loss: 1.271561. Batch_acc: 0.551919. Batch_loss: 1.264688 \n",
      "Batch: 871. Acc: 0.540008. Loss: 1.271589. Batch_acc: 0.528824. Batch_loss: 1.296535 \n",
      "Batch: 872. Acc: 0.539977. Loss: 1.271615. Batch_acc: 0.513529. Batch_loss: 1.294149 \n",
      "Batch: 873. Acc: 0.539964. Loss: 1.271644. Batch_acc: 0.528356. Batch_loss: 1.297448 \n",
      "Batch: 874. Acc: 0.539962. Loss: 1.271640. Batch_acc: 0.538031. Batch_loss: 1.268528 \n",
      "Batch: 875. Acc: 0.539978. Loss: 1.271631. Batch_acc: 0.553748. Batch_loss: 1.263491 \n",
      "Batch: 876. Acc: 0.539943. Loss: 1.271715. Batch_acc: 0.510227. Batch_loss: 1.344211 \n",
      "Batch: 877. Acc: 0.539940. Loss: 1.271730. Batch_acc: 0.537399. Batch_loss: 1.285478 \n",
      "Batch: 878. Acc: 0.539955. Loss: 1.271658. Batch_acc: 0.552735. Batch_loss: 1.209157 \n",
      "Batch: 879. Acc: 0.539948. Loss: 1.271648. Batch_acc: 0.533746. Batch_loss: 1.262888 \n",
      "Batch: 880. Acc: 0.539951. Loss: 1.271642. Batch_acc: 0.542874. Batch_loss: 1.266310 \n",
      "Batch: 881. Acc: 0.539952. Loss: 1.271650. Batch_acc: 0.540433. Batch_loss: 1.278716 \n",
      "Batch: 882. Acc: 0.539954. Loss: 1.271633. Batch_acc: 0.542029. Batch_loss: 1.257140 \n",
      "Batch: 883. Acc: 0.539944. Loss: 1.271644. Batch_acc: 0.530963. Batch_loss: 1.281222 \n",
      "Batch: 884. Acc: 0.539951. Loss: 1.271636. Batch_acc: 0.545987. Batch_loss: 1.264550 \n",
      "Batch: 885. Acc: 0.539943. Loss: 1.271665. Batch_acc: 0.532754. Batch_loss: 1.296779 \n",
      "Batch: 886. Acc: 0.539934. Loss: 1.271693. Batch_acc: 0.532534. Batch_loss: 1.296827 \n",
      "Batch: 887. Acc: 0.539953. Loss: 1.271649. Batch_acc: 0.556582. Batch_loss: 1.232418 \n",
      "Batch: 888. Acc: 0.539938. Loss: 1.271660. Batch_acc: 0.526943. Batch_loss: 1.281251 \n",
      "Batch: 889. Acc: 0.539955. Loss: 1.271618. Batch_acc: 0.554679. Batch_loss: 1.235216 \n",
      "Batch: 890. Acc: 0.539946. Loss: 1.271657. Batch_acc: 0.532174. Batch_loss: 1.306343 \n",
      "Batch: 891. Acc: 0.539944. Loss: 1.271630. Batch_acc: 0.537763. Batch_loss: 1.247486 \n",
      "Batch: 892. Acc: 0.539966. Loss: 1.271576. Batch_acc: 0.560491. Batch_loss: 1.222891 \n",
      "Batch: 893. Acc: 0.539966. Loss: 1.271589. Batch_acc: 0.539176. Batch_loss: 1.283549 \n",
      "Batch: 894. Acc: 0.539960. Loss: 1.271625. Batch_acc: 0.534949. Batch_loss: 1.302929 \n",
      "Batch: 895. Acc: 0.539998. Loss: 1.271548. Batch_acc: 0.572946. Batch_loss: 1.204855 \n",
      "Batch: 896. Acc: 0.539996. Loss: 1.271604. Batch_acc: 0.538592. Batch_loss: 1.320552 \n",
      "Batch: 897. Acc: 0.539969. Loss: 1.271652. Batch_acc: 0.515868. Batch_loss: 1.314593 \n",
      "Batch: 898. Acc: 0.540014. Loss: 1.271568. Batch_acc: 0.579183. Batch_loss: 1.198795 \n",
      "Batch: 899. Acc: 0.540005. Loss: 1.271573. Batch_acc: 0.531878. Batch_loss: 1.275765 \n",
      "Batch: 900. Acc: 0.540022. Loss: 1.271527. Batch_acc: 0.554378. Batch_loss: 1.231155 \n",
      "Batch: 901. Acc: 0.540009. Loss: 1.271537. Batch_acc: 0.528379. Batch_loss: 1.280475 \n",
      "Batch: 902. Acc: 0.540010. Loss: 1.271525. Batch_acc: 0.540793. Batch_loss: 1.260788 \n",
      "Batch: 903. Acc: 0.540007. Loss: 1.271533. Batch_acc: 0.537442. Batch_loss: 1.279007 \n",
      "Batch: 904. Acc: 0.540024. Loss: 1.271492. Batch_acc: 0.555619. Batch_loss: 1.234288 \n",
      "Batch: 905. Acc: 0.540003. Loss: 1.271547. Batch_acc: 0.520258. Batch_loss: 1.322343 \n",
      "Batch: 906. Acc: 0.540013. Loss: 1.271540. Batch_acc: 0.548718. Batch_loss: 1.265409 \n",
      "Batch: 907. Acc: 0.539984. Loss: 1.271592. Batch_acc: 0.514056. Batch_loss: 1.318934 \n",
      "Batch: 908. Acc: 0.539987. Loss: 1.271581. Batch_acc: 0.542354. Batch_loss: 1.261455 \n",
      "Batch: 909. Acc: 0.540028. Loss: 1.271469. Batch_acc: 0.577250. Batch_loss: 1.171646 \n",
      "Batch: 910. Acc: 0.540017. Loss: 1.271510. Batch_acc: 0.530346. Batch_loss: 1.308309 \n",
      "Batch: 911. Acc: 0.540035. Loss: 1.271459. Batch_acc: 0.555872. Batch_loss: 1.224853 \n",
      "Batch: 912. Acc: 0.540031. Loss: 1.271482. Batch_acc: 0.536673. Batch_loss: 1.293696 \n",
      "Batch: 913. Acc: 0.540039. Loss: 1.271434. Batch_acc: 0.546838. Batch_loss: 1.226833 \n",
      "Batch: 914. Acc: 0.540052. Loss: 1.271391. Batch_acc: 0.552189. Batch_loss: 1.232977 \n",
      "Batch: 915. Acc: 0.540068. Loss: 1.271346. Batch_acc: 0.554203. Batch_loss: 1.229785 \n",
      "Batch: 916. Acc: 0.540084. Loss: 1.271299. Batch_acc: 0.555301. Batch_loss: 1.228249 \n",
      "Batch: 917. Acc: 0.540108. Loss: 1.271223. Batch_acc: 0.561464. Batch_loss: 1.202585 \n",
      "Batch: 918. Acc: 0.540113. Loss: 1.271213. Batch_acc: 0.544824. Batch_loss: 1.261608 \n",
      "Batch: 919. Acc: 0.540142. Loss: 1.271182. Batch_acc: 0.566860. Batch_loss: 1.242685 \n",
      "Batch: 920. Acc: 0.540130. Loss: 1.271230. Batch_acc: 0.529040. Batch_loss: 1.314644 \n",
      "Batch: 921. Acc: 0.540088. Loss: 1.271307. Batch_acc: 0.502027. Batch_loss: 1.343174 \n",
      "Batch: 922. Acc: 0.540075. Loss: 1.271328. Batch_acc: 0.527197. Batch_loss: 1.291221 \n",
      "Batch: 923. Acc: 0.540058. Loss: 1.271375. Batch_acc: 0.523893. Batch_loss: 1.315243 \n",
      "Batch: 924. Acc: 0.540062. Loss: 1.271385. Batch_acc: 0.544168. Batch_loss: 1.280514 \n",
      "Batch: 925. Acc: 0.540052. Loss: 1.271441. Batch_acc: 0.530403. Batch_loss: 1.326096 \n",
      "Batch: 926. Acc: 0.540052. Loss: 1.271424. Batch_acc: 0.540134. Batch_loss: 1.255628 \n",
      "Batch: 927. Acc: 0.540039. Loss: 1.271512. Batch_acc: 0.527518. Batch_loss: 1.355048 \n",
      "Batch: 928. Acc: 0.540025. Loss: 1.271537. Batch_acc: 0.526564. Batch_loss: 1.295474 \n",
      "Batch: 929. Acc: 0.540047. Loss: 1.271487. Batch_acc: 0.560268. Batch_loss: 1.226269 \n",
      "Batch: 930. Acc: 0.540067. Loss: 1.271450. Batch_acc: 0.558221. Batch_loss: 1.236016 \n",
      "Batch: 931. Acc: 0.540090. Loss: 1.271399. Batch_acc: 0.561224. Batch_loss: 1.225349 \n",
      "Batch: 932. Acc: 0.540080. Loss: 1.271419. Batch_acc: 0.530864. Batch_loss: 1.289734 \n",
      "Batch: 933. Acc: 0.540102. Loss: 1.271336. Batch_acc: 0.560477. Batch_loss: 1.195160 \n",
      "Batch: 934. Acc: 0.540107. Loss: 1.271341. Batch_acc: 0.544296. Batch_loss: 1.276019 \n",
      "Batch: 935. Acc: 0.540098. Loss: 1.271379. Batch_acc: 0.532078. Batch_loss: 1.307369 \n",
      "Batch: 936. Acc: 0.540111. Loss: 1.271361. Batch_acc: 0.552309. Batch_loss: 1.254996 \n",
      "Batch: 937. Acc: 0.540126. Loss: 1.271326. Batch_acc: 0.554093. Batch_loss: 1.238442 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 938. Acc: 0.540148. Loss: 1.271278. Batch_acc: 0.561105. Batch_loss: 1.224830 \n",
      "Batch: 939. Acc: 0.540123. Loss: 1.271346. Batch_acc: 0.517222. Batch_loss: 1.335790 \n",
      "Batch: 940. Acc: 0.540113. Loss: 1.271372. Batch_acc: 0.529820. Batch_loss: 1.295624 \n",
      "Batch: 941. Acc: 0.540112. Loss: 1.271363. Batch_acc: 0.539243. Batch_loss: 1.263208 \n",
      "Batch: 942. Acc: 0.540091. Loss: 1.271390. Batch_acc: 0.520571. Batch_loss: 1.296376 \n",
      "Batch: 943. Acc: 0.540086. Loss: 1.271419. Batch_acc: 0.535484. Batch_loss: 1.299518 \n",
      "Batch: 944. Acc: 0.540125. Loss: 1.271333. Batch_acc: 0.577103. Batch_loss: 1.188415 \n",
      "Batch: 945. Acc: 0.540125. Loss: 1.271342. Batch_acc: 0.540587. Batch_loss: 1.280466 \n",
      "Batch: 946. Acc: 0.540113. Loss: 1.271357. Batch_acc: 0.529073. Batch_loss: 1.285547 \n",
      "Batch: 947. Acc: 0.540124. Loss: 1.271348. Batch_acc: 0.550203. Batch_loss: 1.262705 \n",
      "Batch: 948. Acc: 0.540116. Loss: 1.271386. Batch_acc: 0.532445. Batch_loss: 1.307324 \n",
      "Batch: 949. Acc: 0.540145. Loss: 1.271334. Batch_acc: 0.568627. Batch_loss: 1.220823 \n",
      "Batch: 950. Acc: 0.540149. Loss: 1.271331. Batch_acc: 0.543566. Batch_loss: 1.268437 \n",
      "Batch: 951. Acc: 0.540144. Loss: 1.271357. Batch_acc: 0.535673. Batch_loss: 1.295851 \n",
      "Batch: 952. Acc: 0.540169. Loss: 1.271295. Batch_acc: 0.564073. Batch_loss: 1.212922 \n",
      "Batch: 953. Acc: 0.540151. Loss: 1.271322. Batch_acc: 0.523032. Batch_loss: 1.297078 \n",
      "Batch: 954. Acc: 0.540182. Loss: 1.271247. Batch_acc: 0.568528. Batch_loss: 1.201313 \n",
      "Batch: 955. Acc: 0.540162. Loss: 1.271298. Batch_acc: 0.520772. Batch_loss: 1.320780 \n",
      "Batch: 956. Acc: 0.540176. Loss: 1.271233. Batch_acc: 0.553348. Batch_loss: 1.210060 \n",
      "Batch: 957. Acc: 0.540203. Loss: 1.271171. Batch_acc: 0.566998. Batch_loss: 1.210916 \n",
      "Batch: 958. Acc: 0.540208. Loss: 1.271160. Batch_acc: 0.544883. Batch_loss: 1.260596 \n",
      "Batch: 959. Acc: 0.540230. Loss: 1.271099. Batch_acc: 0.561189. Batch_loss: 1.211574 \n",
      "Batch: 960. Acc: 0.540255. Loss: 1.271030. Batch_acc: 0.564407. Batch_loss: 1.205463 \n",
      "Batch: 961. Acc: 0.540262. Loss: 1.271035. Batch_acc: 0.546605. Batch_loss: 1.276062 \n",
      "Batch: 962. Acc: 0.540272. Loss: 1.271038. Batch_acc: 0.550379. Batch_loss: 1.274206 \n",
      "Batch: 963. Acc: 0.540312. Loss: 1.270913. Batch_acc: 0.576902. Batch_loss: 1.154279 \n",
      "Batch: 964. Acc: 0.540284. Loss: 1.270952. Batch_acc: 0.513482. Batch_loss: 1.309922 \n",
      "Batch: 965. Acc: 0.540280. Loss: 1.270918. Batch_acc: 0.535996. Batch_loss: 1.238534 \n",
      "Batch: 966. Acc: 0.540291. Loss: 1.270912. Batch_acc: 0.550708. Batch_loss: 1.265641 \n",
      "Batch: 967. Acc: 0.540300. Loss: 1.270865. Batch_acc: 0.548885. Batch_loss: 1.224987 \n",
      "Batch: 968. Acc: 0.540328. Loss: 1.270814. Batch_acc: 0.567901. Batch_loss: 1.220651 \n",
      "Batch: 969. Acc: 0.540356. Loss: 1.270748. Batch_acc: 0.567476. Batch_loss: 1.208155 \n",
      "Batch: 970. Acc: 0.540350. Loss: 1.270732. Batch_acc: 0.534104. Batch_loss: 1.255420 \n",
      "Batch: 971. Acc: 0.540371. Loss: 1.270662. Batch_acc: 0.561060. Batch_loss: 1.202044 \n",
      "Batch: 972. Acc: 0.540385. Loss: 1.270634. Batch_acc: 0.554210. Batch_loss: 1.243884 \n",
      "Batch: 973. Acc: 0.540380. Loss: 1.270637. Batch_acc: 0.535693. Batch_loss: 1.273483 \n",
      "Batch: 974. Acc: 0.540394. Loss: 1.270648. Batch_acc: 0.554140. Batch_loss: 1.281341 \n",
      "Batch: 975. Acc: 0.540407. Loss: 1.270614. Batch_acc: 0.552865. Batch_loss: 1.236523 \n",
      "Batch: 976. Acc: 0.540401. Loss: 1.270624. Batch_acc: 0.535083. Batch_loss: 1.279909 \n",
      "Batch: 977. Acc: 0.540389. Loss: 1.270661. Batch_acc: 0.528986. Batch_loss: 1.306247 \n",
      "Batch: 978. Acc: 0.540355. Loss: 1.270703. Batch_acc: 0.506873. Batch_loss: 1.311835 \n",
      "Batch: 979. Acc: 0.540384. Loss: 1.270631. Batch_acc: 0.568245. Batch_loss: 1.201811 \n",
      "Batch: 980. Acc: 0.540415. Loss: 1.270565. Batch_acc: 0.569801. Batch_loss: 1.206543 \n",
      "Batch: 981. Acc: 0.540417. Loss: 1.270564. Batch_acc: 0.543138. Batch_loss: 1.269261 \n",
      "Batch: 982. Acc: 0.540402. Loss: 1.270614. Batch_acc: 0.525088. Batch_loss: 1.320893 \n",
      "Batch: 983. Acc: 0.540394. Loss: 1.270662. Batch_acc: 0.532460. Batch_loss: 1.319070 \n",
      "Batch: 984. Acc: 0.540415. Loss: 1.270625. Batch_acc: 0.560632. Batch_loss: 1.235171 \n",
      "Batch: 985. Acc: 0.540426. Loss: 1.270601. Batch_acc: 0.550700. Batch_loss: 1.248071 \n",
      "Batch: 986. Acc: 0.540405. Loss: 1.270651. Batch_acc: 0.519648. Batch_loss: 1.320735 \n",
      "Batch: 987. Acc: 0.540422. Loss: 1.270618. Batch_acc: 0.556117. Batch_loss: 1.238896 \n",
      "Batch: 988. Acc: 0.540424. Loss: 1.270624. Batch_acc: 0.543084. Batch_loss: 1.276033 \n",
      "Batch: 989. Acc: 0.540420. Loss: 1.270632. Batch_acc: 0.535880. Batch_loss: 1.278818 \n",
      "Batch: 990. Acc: 0.540410. Loss: 1.270638. Batch_acc: 0.531144. Batch_loss: 1.276406 \n",
      "Batch: 991. Acc: 0.540432. Loss: 1.270579. Batch_acc: 0.562464. Batch_loss: 1.212234 \n",
      "Batch: 992. Acc: 0.540444. Loss: 1.270555. Batch_acc: 0.551785. Batch_loss: 1.246074 \n",
      "Batch: 993. Acc: 0.540450. Loss: 1.270546. Batch_acc: 0.546573. Batch_loss: 1.261984 \n",
      "Batch: 994. Acc: 0.540439. Loss: 1.270570. Batch_acc: 0.529714. Batch_loss: 1.293767 \n",
      "Batch: 995. Acc: 0.540431. Loss: 1.270567. Batch_acc: 0.532602. Batch_loss: 1.267313 \n",
      "Batch: 996. Acc: 0.540455. Loss: 1.270497. Batch_acc: 0.564767. Batch_loss: 1.201019 \n",
      "Batch: 997. Acc: 0.540462. Loss: 1.270504. Batch_acc: 0.547018. Batch_loss: 1.277276 \n",
      "Batch: 998. Acc: 0.540438. Loss: 1.270568. Batch_acc: 0.515671. Batch_loss: 1.336548 \n",
      "Batch: 999. Acc: 0.540463. Loss: 1.270500. Batch_acc: 0.565094. Batch_loss: 1.203266 \n",
      "Batch: 1000. Acc: 0.540454. Loss: 1.270505. Batch_acc: 0.531469. Batch_loss: 1.275062 \n",
      "Batch: 1001. Acc: 0.540466. Loss: 1.270468. Batch_acc: 0.553279. Batch_loss: 1.233340 \n",
      "Batch: 1002. Acc: 0.540463. Loss: 1.270480. Batch_acc: 0.537016. Batch_loss: 1.282643 \n",
      "Batch: 1003. Acc: 0.540463. Loss: 1.270477. Batch_acc: 0.540495. Batch_loss: 1.267223 \n",
      "Batch: 1004. Acc: 0.540463. Loss: 1.270462. Batch_acc: 0.540464. Batch_loss: 1.255621 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.5404630398076868. Loss per char: 1.2704619946485392. Time: 1627222637.5567687\n",
      "Last question is tensor([ 2, 52, 86, 78,  1, 23, 23, 22, 24, 15, 24, 19,  1, 66, 79, 69,  1, 14,\n",
      "        18, 18, 26, 15, 23, 25, 21, 25, 26, 18, 15,  3,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.540449. Loss: 1.270469. Batch_acc: 0.526614. Batch_loss: 1.277498 \n",
      "Batch: 1006. Acc: 0.540449. Loss: 1.270484. Batch_acc: 0.540433. Batch_loss: 1.285245 \n",
      "Batch: 1007. Acc: 0.540452. Loss: 1.270482. Batch_acc: 0.543161. Batch_loss: 1.268922 \n",
      "Batch: 1008. Acc: 0.540455. Loss: 1.270505. Batch_acc: 0.543728. Batch_loss: 1.293115 \n",
      "Batch: 1009. Acc: 0.540477. Loss: 1.270456. Batch_acc: 0.562536. Batch_loss: 1.221813 \n",
      "Batch: 1010. Acc: 0.540494. Loss: 1.270400. Batch_acc: 0.557882. Batch_loss: 1.213192 \n",
      "Batch: 1011. Acc: 0.540469. Loss: 1.270463. Batch_acc: 0.514775. Batch_loss: 1.335966 \n",
      "Batch: 1012. Acc: 0.540473. Loss: 1.270456. Batch_acc: 0.543870. Batch_loss: 1.263047 \n",
      "Batch: 1013. Acc: 0.540465. Loss: 1.270466. Batch_acc: 0.532239. Batch_loss: 1.280909 \n",
      "Batch: 1014. Acc: 0.540444. Loss: 1.270508. Batch_acc: 0.519208. Batch_loss: 1.313375 \n",
      "Batch: 1015. Acc: 0.540445. Loss: 1.270499. Batch_acc: 0.541375. Batch_loss: 1.261427 \n",
      "Batch: 1016. Acc: 0.540432. Loss: 1.270514. Batch_acc: 0.527011. Batch_loss: 1.285396 \n",
      "Batch: 1017. Acc: 0.540446. Loss: 1.270496. Batch_acc: 0.554540. Batch_loss: 1.252403 \n",
      "Batch: 1018. Acc: 0.540437. Loss: 1.270474. Batch_acc: 0.531624. Batch_loss: 1.248887 \n",
      "Batch: 1019. Acc: 0.540456. Loss: 1.270415. Batch_acc: 0.559745. Batch_loss: 1.209359 \n",
      "Batch: 1020. Acc: 0.540435. Loss: 1.270464. Batch_acc: 0.519298. Batch_loss: 1.321662 \n",
      "Batch: 1021. Acc: 0.540441. Loss: 1.270437. Batch_acc: 0.545918. Batch_loss: 1.243072 \n",
      "Batch: 1022. Acc: 0.540425. Loss: 1.270477. Batch_acc: 0.524664. Batch_loss: 1.310295 \n",
      "Batch: 1023. Acc: 0.540439. Loss: 1.270433. Batch_acc: 0.555172. Batch_loss: 1.225513 \n",
      "Batch: 1024. Acc: 0.540460. Loss: 1.270387. Batch_acc: 0.561323. Batch_loss: 1.223360 \n",
      "Batch: 1025. Acc: 0.540470. Loss: 1.270352. Batch_acc: 0.551020. Batch_loss: 1.234584 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1026. Acc: 0.540475. Loss: 1.270346. Batch_acc: 0.545660. Batch_loss: 1.264186 \n",
      "Batch: 1027. Acc: 0.540465. Loss: 1.270369. Batch_acc: 0.529547. Batch_loss: 1.293475 \n",
      "Batch: 1028. Acc: 0.540458. Loss: 1.270368. Batch_acc: 0.533333. Batch_loss: 1.269037 \n",
      "Batch: 1029. Acc: 0.540445. Loss: 1.270401. Batch_acc: 0.527389. Batch_loss: 1.305042 \n",
      "Batch: 1030. Acc: 0.540441. Loss: 1.270409. Batch_acc: 0.536488. Batch_loss: 1.278616 \n",
      "Batch: 1031. Acc: 0.540460. Loss: 1.270382. Batch_acc: 0.559839. Batch_loss: 1.242861 \n",
      "Batch: 1032. Acc: 0.540442. Loss: 1.270404. Batch_acc: 0.522088. Batch_loss: 1.292933 \n",
      "Batch: 1033. Acc: 0.540438. Loss: 1.270422. Batch_acc: 0.536274. Batch_loss: 1.289151 \n",
      "Batch: 1034. Acc: 0.540425. Loss: 1.270456. Batch_acc: 0.526562. Batch_loss: 1.305920 \n",
      "Batch: 1035. Acc: 0.540444. Loss: 1.270397. Batch_acc: 0.560580. Batch_loss: 1.208619 \n",
      "Batch: 1036. Acc: 0.540430. Loss: 1.270414. Batch_acc: 0.526074. Batch_loss: 1.288319 \n",
      "Batch: 1037. Acc: 0.540431. Loss: 1.270397. Batch_acc: 0.540909. Batch_loss: 1.252549 \n",
      "Batch: 1038. Acc: 0.540461. Loss: 1.270330. Batch_acc: 0.571105. Batch_loss: 1.201878 \n",
      "Batch: 1039. Acc: 0.540453. Loss: 1.270350. Batch_acc: 0.532025. Batch_loss: 1.291573 \n",
      "Batch: 1040. Acc: 0.540472. Loss: 1.270293. Batch_acc: 0.560990. Batch_loss: 1.210946 \n",
      "Batch: 1041. Acc: 0.540509. Loss: 1.270197. Batch_acc: 0.577778. Batch_loss: 1.171442 \n",
      "Batch: 1042. Acc: 0.540525. Loss: 1.270150. Batch_acc: 0.557055. Batch_loss: 1.222604 \n",
      "Batch: 1043. Acc: 0.540548. Loss: 1.270087. Batch_acc: 0.565192. Batch_loss: 1.203490 \n",
      "Batch: 1044. Acc: 0.540563. Loss: 1.270053. Batch_acc: 0.555940. Batch_loss: 1.234400 \n",
      "Batch: 1045. Acc: 0.540540. Loss: 1.270135. Batch_acc: 0.515939. Batch_loss: 1.357923 \n",
      "Batch: 1046. Acc: 0.540573. Loss: 1.270041. Batch_acc: 0.575201. Batch_loss: 1.171533 \n",
      "Batch: 1047. Acc: 0.540563. Loss: 1.270043. Batch_acc: 0.529790. Batch_loss: 1.272222 \n",
      "Batch: 1048. Acc: 0.540554. Loss: 1.270075. Batch_acc: 0.531067. Batch_loss: 1.304709 \n",
      "Batch: 1049. Acc: 0.540545. Loss: 1.270079. Batch_acc: 0.531485. Batch_loss: 1.273608 \n",
      "Batch: 1050. Acc: 0.540527. Loss: 1.270105. Batch_acc: 0.521319. Batch_loss: 1.297829 \n",
      "Batch: 1051. Acc: 0.540531. Loss: 1.270089. Batch_acc: 0.544789. Batch_loss: 1.253549 \n",
      "Batch: 1052. Acc: 0.540565. Loss: 1.270024. Batch_acc: 0.576879. Batch_loss: 1.201122 \n",
      "Batch: 1053. Acc: 0.540581. Loss: 1.270000. Batch_acc: 0.557070. Batch_loss: 1.245223 \n",
      "Batch: 1054. Acc: 0.540601. Loss: 1.269957. Batch_acc: 0.561543. Batch_loss: 1.225056 \n",
      "Batch: 1055. Acc: 0.540585. Loss: 1.270005. Batch_acc: 0.522406. Batch_loss: 1.322107 \n",
      "Batch: 1056. Acc: 0.540594. Loss: 1.269993. Batch_acc: 0.550379. Batch_loss: 1.257360 \n",
      "Batch: 1057. Acc: 0.540617. Loss: 1.269950. Batch_acc: 0.564868. Batch_loss: 1.224267 \n",
      "Batch: 1058. Acc: 0.540601. Loss: 1.269984. Batch_acc: 0.524030. Batch_loss: 1.305986 \n",
      "Batch: 1059. Acc: 0.540610. Loss: 1.269960. Batch_acc: 0.550286. Batch_loss: 1.244729 \n",
      "Batch: 1060. Acc: 0.540635. Loss: 1.269904. Batch_acc: 0.565931. Batch_loss: 1.211903 \n",
      "Batch: 1061. Acc: 0.540622. Loss: 1.269915. Batch_acc: 0.526832. Batch_loss: 1.281818 \n",
      "Batch: 1062. Acc: 0.540606. Loss: 1.269943. Batch_acc: 0.523132. Batch_loss: 1.299563 \n",
      "Batch: 1063. Acc: 0.540638. Loss: 1.269831. Batch_acc: 0.573971. Batch_loss: 1.155006 \n",
      "Batch: 1064. Acc: 0.540647. Loss: 1.269797. Batch_acc: 0.549463. Batch_loss: 1.234086 \n",
      "Batch: 1065. Acc: 0.540641. Loss: 1.269785. Batch_acc: 0.534722. Batch_loss: 1.257060 \n",
      "Batch: 1066. Acc: 0.540635. Loss: 1.269790. Batch_acc: 0.534580. Batch_loss: 1.275728 \n",
      "Batch: 1067. Acc: 0.540639. Loss: 1.269757. Batch_acc: 0.544883. Batch_loss: 1.234120 \n",
      "Batch: 1068. Acc: 0.540646. Loss: 1.269740. Batch_acc: 0.548330. Batch_loss: 1.251388 \n",
      "Batch: 1069. Acc: 0.540655. Loss: 1.269703. Batch_acc: 0.550169. Batch_loss: 1.230845 \n",
      "Batch: 1070. Acc: 0.540650. Loss: 1.269691. Batch_acc: 0.534552. Batch_loss: 1.256989 \n",
      "Batch: 1071. Acc: 0.540641. Loss: 1.269699. Batch_acc: 0.531696. Batch_loss: 1.278705 \n",
      "Batch: 1072. Acc: 0.540649. Loss: 1.269681. Batch_acc: 0.548986. Batch_loss: 1.250192 \n",
      "Batch: 1073. Acc: 0.540666. Loss: 1.269645. Batch_acc: 0.559073. Batch_loss: 1.230970 \n",
      "Batch: 1074. Acc: 0.540676. Loss: 1.269623. Batch_acc: 0.550766. Batch_loss: 1.246842 \n",
      "Batch: 1075. Acc: 0.540672. Loss: 1.269625. Batch_acc: 0.535777. Batch_loss: 1.271184 \n",
      "Batch: 1076. Acc: 0.540686. Loss: 1.269579. Batch_acc: 0.556577. Batch_loss: 1.220912 \n",
      "Batch: 1077. Acc: 0.540698. Loss: 1.269570. Batch_acc: 0.553387. Batch_loss: 1.259820 \n",
      "Batch: 1078. Acc: 0.540705. Loss: 1.269497. Batch_acc: 0.548077. Batch_loss: 1.192181 \n",
      "Batch: 1079. Acc: 0.540709. Loss: 1.269476. Batch_acc: 0.544711. Batch_loss: 1.246197 \n",
      "Batch: 1080. Acc: 0.540724. Loss: 1.269446. Batch_acc: 0.557321. Batch_loss: 1.237262 \n",
      "Batch: 1081. Acc: 0.540730. Loss: 1.269415. Batch_acc: 0.547387. Batch_loss: 1.235650 \n",
      "Batch: 1082. Acc: 0.540735. Loss: 1.269395. Batch_acc: 0.545195. Batch_loss: 1.248601 \n",
      "Batch: 1083. Acc: 0.540749. Loss: 1.269374. Batch_acc: 0.555934. Batch_loss: 1.246354 \n",
      "Batch: 1084. Acc: 0.540766. Loss: 1.269328. Batch_acc: 0.558924. Batch_loss: 1.220362 \n",
      "Batch: 1085. Acc: 0.540768. Loss: 1.269319. Batch_acc: 0.543403. Batch_loss: 1.259027 \n",
      "Batch: 1086. Acc: 0.540775. Loss: 1.269288. Batch_acc: 0.547977. Batch_loss: 1.235253 \n",
      "Batch: 1087. Acc: 0.540779. Loss: 1.269260. Batch_acc: 0.544983. Batch_loss: 1.239091 \n",
      "Batch: 1088. Acc: 0.540767. Loss: 1.269303. Batch_acc: 0.528412. Batch_loss: 1.316854 \n",
      "Batch: 1089. Acc: 0.540770. Loss: 1.269297. Batch_acc: 0.544118. Batch_loss: 1.262747 \n",
      "Batch: 1090. Acc: 0.540770. Loss: 1.269297. Batch_acc: 0.540197. Batch_loss: 1.269355 \n",
      "Batch: 1091. Acc: 0.540774. Loss: 1.269298. Batch_acc: 0.545191. Batch_loss: 1.270777 \n",
      "Batch: 1092. Acc: 0.540783. Loss: 1.269283. Batch_acc: 0.550286. Batch_loss: 1.253301 \n",
      "Batch: 1093. Acc: 0.540784. Loss: 1.269276. Batch_acc: 0.541691. Batch_loss: 1.261621 \n",
      "Batch: 1094. Acc: 0.540779. Loss: 1.269289. Batch_acc: 0.535959. Batch_loss: 1.282740 \n",
      "Batch: 1095. Acc: 0.540751. Loss: 1.269346. Batch_acc: 0.509643. Batch_loss: 1.333422 \n",
      "Batch: 1096. Acc: 0.540749. Loss: 1.269344. Batch_acc: 0.538240. Batch_loss: 1.266684 \n",
      "Batch: 1097. Acc: 0.540727. Loss: 1.269409. Batch_acc: 0.516590. Batch_loss: 1.340498 \n",
      "Batch: 1098. Acc: 0.540722. Loss: 1.269394. Batch_acc: 0.535424. Batch_loss: 1.252958 \n",
      "Batch: 1099. Acc: 0.540709. Loss: 1.269423. Batch_acc: 0.526821. Batch_loss: 1.300429 \n",
      "Batch: 1100. Acc: 0.540706. Loss: 1.269455. Batch_acc: 0.537529. Batch_loss: 1.305135 \n",
      "Batch: 1101. Acc: 0.540719. Loss: 1.269413. Batch_acc: 0.554342. Batch_loss: 1.222875 \n",
      "Batch: 1102. Acc: 0.540717. Loss: 1.269383. Batch_acc: 0.539372. Batch_loss: 1.235740 \n",
      "Batch: 1103. Acc: 0.540736. Loss: 1.269337. Batch_acc: 0.561155. Batch_loss: 1.218695 \n",
      "Batch: 1104. Acc: 0.540735. Loss: 1.269363. Batch_acc: 0.539618. Batch_loss: 1.298922 \n",
      "Batch: 1105. Acc: 0.540740. Loss: 1.269357. Batch_acc: 0.546374. Batch_loss: 1.262418 \n",
      "Batch: 1106. Acc: 0.540753. Loss: 1.269314. Batch_acc: 0.554273. Batch_loss: 1.222051 \n",
      "Batch: 1107. Acc: 0.540770. Loss: 1.269277. Batch_acc: 0.560345. Batch_loss: 1.227430 \n",
      "Batch: 1108. Acc: 0.540775. Loss: 1.269236. Batch_acc: 0.545403. Batch_loss: 1.224365 \n",
      "Batch: 1109. Acc: 0.540785. Loss: 1.269188. Batch_acc: 0.551763. Batch_loss: 1.217534 \n",
      "Batch: 1110. Acc: 0.540783. Loss: 1.269193. Batch_acc: 0.538902. Batch_loss: 1.274354 \n",
      "Batch: 1111. Acc: 0.540769. Loss: 1.269216. Batch_acc: 0.524695. Batch_loss: 1.294962 \n",
      "Batch: 1112. Acc: 0.540765. Loss: 1.269241. Batch_acc: 0.537243. Batch_loss: 1.297885 \n",
      "Batch: 1113. Acc: 0.540790. Loss: 1.269149. Batch_acc: 0.567431. Batch_loss: 1.168735 \n",
      "Batch: 1114. Acc: 0.540777. Loss: 1.269158. Batch_acc: 0.526562. Batch_loss: 1.279454 \n",
      "Batch: 1115. Acc: 0.540763. Loss: 1.269196. Batch_acc: 0.524463. Batch_loss: 1.313816 \n",
      "Batch: 1116. Acc: 0.540760. Loss: 1.269200. Batch_acc: 0.536866. Batch_loss: 1.273086 \n",
      "Batch: 1117. Acc: 0.540774. Loss: 1.269142. Batch_acc: 0.556257. Batch_loss: 1.204947 \n",
      "Batch: 1118. Acc: 0.540781. Loss: 1.269132. Batch_acc: 0.549476. Batch_loss: 1.257429 \n",
      "Batch: 1119. Acc: 0.540786. Loss: 1.269106. Batch_acc: 0.546132. Batch_loss: 1.240410 \n",
      "Batch: 1120. Acc: 0.540806. Loss: 1.269061. Batch_acc: 0.562645. Batch_loss: 1.218013 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1121. Acc: 0.540786. Loss: 1.269100. Batch_acc: 0.518065. Batch_loss: 1.313899 \n",
      "Batch: 1122. Acc: 0.540788. Loss: 1.269091. Batch_acc: 0.542955. Batch_loss: 1.259100 \n",
      "Batch: 1123. Acc: 0.540778. Loss: 1.269081. Batch_acc: 0.530093. Batch_loss: 1.257208 \n",
      "Batch: 1124. Acc: 0.540775. Loss: 1.269073. Batch_acc: 0.537572. Batch_loss: 1.260695 \n",
      "Batch: 1125. Acc: 0.540772. Loss: 1.269104. Batch_acc: 0.537671. Batch_loss: 1.303197 \n",
      "Batch: 1126. Acc: 0.540751. Loss: 1.269176. Batch_acc: 0.516166. Batch_loss: 1.350639 \n",
      "Batch: 1127. Acc: 0.540749. Loss: 1.269183. Batch_acc: 0.539181. Batch_loss: 1.276938 \n",
      "Batch: 1128. Acc: 0.540758. Loss: 1.269166. Batch_acc: 0.551176. Batch_loss: 1.249825 \n",
      "Batch: 1129. Acc: 0.540755. Loss: 1.269178. Batch_acc: 0.536473. Batch_loss: 1.282442 \n",
      "Batch: 1130. Acc: 0.540747. Loss: 1.269190. Batch_acc: 0.532571. Batch_loss: 1.282902 \n",
      "Batch: 1131. Acc: 0.540754. Loss: 1.269169. Batch_acc: 0.547945. Batch_loss: 1.245099 \n",
      "Batch: 1132. Acc: 0.540748. Loss: 1.269171. Batch_acc: 0.534765. Batch_loss: 1.271331 \n",
      "Batch: 1133. Acc: 0.540742. Loss: 1.269186. Batch_acc: 0.533296. Batch_loss: 1.285959 \n",
      "Batch: 1134. Acc: 0.540747. Loss: 1.269145. Batch_acc: 0.546270. Batch_loss: 1.224057 \n",
      "Batch: 1135. Acc: 0.540769. Loss: 1.269063. Batch_acc: 0.566422. Batch_loss: 1.177654 \n",
      "Batch: 1136. Acc: 0.540739. Loss: 1.269107. Batch_acc: 0.505882. Batch_loss: 1.320236 \n",
      "Batch: 1137. Acc: 0.540726. Loss: 1.269166. Batch_acc: 0.525276. Batch_loss: 1.336908 \n",
      "Batch: 1138. Acc: 0.540723. Loss: 1.269159. Batch_acc: 0.537004. Batch_loss: 1.260618 \n",
      "Batch: 1139. Acc: 0.540736. Loss: 1.269128. Batch_acc: 0.555492. Batch_loss: 1.233977 \n",
      "Batch: 1140. Acc: 0.540750. Loss: 1.269104. Batch_acc: 0.557159. Batch_loss: 1.241906 \n",
      "Batch: 1141. Acc: 0.540773. Loss: 1.269033. Batch_acc: 0.566818. Batch_loss: 1.189614 \n",
      "Batch: 1142. Acc: 0.540770. Loss: 1.269035. Batch_acc: 0.537176. Batch_loss: 1.270734 \n",
      "Batch: 1143. Acc: 0.540768. Loss: 1.269018. Batch_acc: 0.538146. Batch_loss: 1.249730 \n",
      "Batch: 1144. Acc: 0.540795. Loss: 1.268940. Batch_acc: 0.571019. Batch_loss: 1.179502 \n",
      "Batch: 1145. Acc: 0.540794. Loss: 1.268949. Batch_acc: 0.539655. Batch_loss: 1.279108 \n",
      "Batch: 1146. Acc: 0.540807. Loss: 1.268918. Batch_acc: 0.555556. Batch_loss: 1.234499 \n",
      "Batch: 1147. Acc: 0.540822. Loss: 1.268885. Batch_acc: 0.558233. Batch_loss: 1.230616 \n",
      "Batch: 1148. Acc: 0.540835. Loss: 1.268829. Batch_acc: 0.555491. Batch_loss: 1.204951 \n",
      "Batch: 1149. Acc: 0.540822. Loss: 1.268847. Batch_acc: 0.526624. Batch_loss: 1.289405 \n",
      "Batch: 1150. Acc: 0.540821. Loss: 1.268890. Batch_acc: 0.539121. Batch_loss: 1.317851 \n",
      "Batch: 1151. Acc: 0.540837. Loss: 1.268869. Batch_acc: 0.558992. Batch_loss: 1.245056 \n",
      "Batch: 1152. Acc: 0.540821. Loss: 1.268898. Batch_acc: 0.523103. Batch_loss: 1.301630 \n",
      "Batch: 1153. Acc: 0.540842. Loss: 1.268862. Batch_acc: 0.564016. Batch_loss: 1.228184 \n",
      "Batch: 1154. Acc: 0.540843. Loss: 1.268877. Batch_acc: 0.542412. Batch_loss: 1.286271 \n",
      "Batch: 1155. Acc: 0.540855. Loss: 1.268855. Batch_acc: 0.555233. Batch_loss: 1.243392 \n",
      "Batch: 1156. Acc: 0.540828. Loss: 1.268912. Batch_acc: 0.508782. Batch_loss: 1.335831 \n",
      "Batch: 1157. Acc: 0.540827. Loss: 1.268931. Batch_acc: 0.539773. Batch_loss: 1.290905 \n",
      "Batch: 1158. Acc: 0.540822. Loss: 1.268918. Batch_acc: 0.534493. Batch_loss: 1.253937 \n",
      "Batch: 1159. Acc: 0.540835. Loss: 1.268888. Batch_acc: 0.555746. Batch_loss: 1.233824 \n",
      "Batch: 1160. Acc: 0.540825. Loss: 1.268907. Batch_acc: 0.529855. Batch_loss: 1.291832 \n",
      "Batch: 1161. Acc: 0.540836. Loss: 1.268877. Batch_acc: 0.553118. Batch_loss: 1.233023 \n",
      "Batch: 1162. Acc: 0.540866. Loss: 1.268814. Batch_acc: 0.574468. Batch_loss: 1.197984 \n",
      "Batch: 1163. Acc: 0.540869. Loss: 1.268801. Batch_acc: 0.545190. Batch_loss: 1.253978 \n",
      "Batch: 1164. Acc: 0.540878. Loss: 1.268781. Batch_acc: 0.551231. Batch_loss: 1.245081 \n",
      "Batch: 1165. Acc: 0.540864. Loss: 1.268836. Batch_acc: 0.523837. Batch_loss: 1.332765 \n",
      "Batch: 1166. Acc: 0.540870. Loss: 1.268814. Batch_acc: 0.548148. Batch_loss: 1.243794 \n",
      "Batch: 1167. Acc: 0.540874. Loss: 1.268802. Batch_acc: 0.545559. Batch_loss: 1.254821 \n",
      "Batch: 1168. Acc: 0.540854. Loss: 1.268857. Batch_acc: 0.517606. Batch_loss: 1.334390 \n",
      "Batch: 1169. Acc: 0.540847. Loss: 1.268867. Batch_acc: 0.531853. Batch_loss: 1.280375 \n",
      "Batch: 1170. Acc: 0.540857. Loss: 1.268828. Batch_acc: 0.553204. Batch_loss: 1.222309 \n",
      "Batch: 1171. Acc: 0.540844. Loss: 1.268853. Batch_acc: 0.524913. Batch_loss: 1.298347 \n",
      "Batch: 1172. Acc: 0.540850. Loss: 1.268844. Batch_acc: 0.548647. Batch_loss: 1.257717 \n",
      "Batch: 1173. Acc: 0.540847. Loss: 1.268860. Batch_acc: 0.536806. Batch_loss: 1.287442 \n",
      "Batch: 1174. Acc: 0.540854. Loss: 1.268823. Batch_acc: 0.549336. Batch_loss: 1.225723 \n",
      "Batch: 1175. Acc: 0.540860. Loss: 1.268844. Batch_acc: 0.547493. Batch_loss: 1.294685 \n",
      "Batch: 1176. Acc: 0.540863. Loss: 1.268835. Batch_acc: 0.544369. Batch_loss: 1.258078 \n",
      "Batch: 1177. Acc: 0.540863. Loss: 1.268824. Batch_acc: 0.541322. Batch_loss: 1.255475 \n",
      "Batch: 1178. Acc: 0.540857. Loss: 1.268849. Batch_acc: 0.533764. Batch_loss: 1.299181 \n",
      "Batch: 1179. Acc: 0.540865. Loss: 1.268842. Batch_acc: 0.550366. Batch_loss: 1.259937 \n",
      "Batch: 1180. Acc: 0.540882. Loss: 1.268812. Batch_acc: 0.561130. Batch_loss: 1.234240 \n",
      "Batch: 1181. Acc: 0.540860. Loss: 1.268874. Batch_acc: 0.513435. Batch_loss: 1.343241 \n",
      "Batch: 1182. Acc: 0.540859. Loss: 1.268860. Batch_acc: 0.540000. Batch_loss: 1.252138 \n",
      "Batch: 1183. Acc: 0.540860. Loss: 1.268837. Batch_acc: 0.542344. Batch_loss: 1.241992 \n",
      "Batch: 1184. Acc: 0.540858. Loss: 1.268834. Batch_acc: 0.538098. Batch_loss: 1.265178 \n",
      "Batch: 1185. Acc: 0.540857. Loss: 1.268854. Batch_acc: 0.539481. Batch_loss: 1.292841 \n",
      "Batch: 1186. Acc: 0.540868. Loss: 1.268832. Batch_acc: 0.554231. Batch_loss: 1.243330 \n",
      "Batch: 1187. Acc: 0.540852. Loss: 1.268865. Batch_acc: 0.521664. Batch_loss: 1.308462 \n",
      "Batch: 1188. Acc: 0.540864. Loss: 1.268815. Batch_acc: 0.555620. Batch_loss: 1.207933 \n",
      "Batch: 1189. Acc: 0.540853. Loss: 1.268855. Batch_acc: 0.527378. Batch_loss: 1.316869 \n",
      "Batch: 1190. Acc: 0.540811. Loss: 1.268936. Batch_acc: 0.490643. Batch_loss: 1.366975 \n",
      "Batch: 1191. Acc: 0.540797. Loss: 1.268960. Batch_acc: 0.524103. Batch_loss: 1.297163 \n",
      "Batch: 1192. Acc: 0.540803. Loss: 1.268971. Batch_acc: 0.547509. Batch_loss: 1.282269 \n",
      "Batch: 1193. Acc: 0.540790. Loss: 1.268994. Batch_acc: 0.525101. Batch_loss: 1.296367 \n",
      "Batch: 1194. Acc: 0.540804. Loss: 1.268947. Batch_acc: 0.557963. Batch_loss: 1.211916 \n",
      "Batch: 1195. Acc: 0.540816. Loss: 1.268906. Batch_acc: 0.555683. Batch_loss: 1.219277 \n",
      "Batch: 1196. Acc: 0.540837. Loss: 1.268862. Batch_acc: 0.565394. Batch_loss: 1.215880 \n",
      "Batch: 1197. Acc: 0.540829. Loss: 1.268881. Batch_acc: 0.532167. Batch_loss: 1.291936 \n",
      "Batch: 1198. Acc: 0.540826. Loss: 1.268877. Batch_acc: 0.536428. Batch_loss: 1.263946 \n",
      "Batch: 1199. Acc: 0.540839. Loss: 1.268831. Batch_acc: 0.556425. Batch_loss: 1.214636 \n",
      "Batch: 1200. Acc: 0.540836. Loss: 1.268843. Batch_acc: 0.537153. Batch_loss: 1.283655 \n",
      "Batch: 1201. Acc: 0.540836. Loss: 1.268854. Batch_acc: 0.541274. Batch_loss: 1.281561 \n",
      "Batch: 1202. Acc: 0.540836. Loss: 1.268819. Batch_acc: 0.540056. Batch_loss: 1.227336 \n",
      "Batch: 1203. Acc: 0.540831. Loss: 1.268819. Batch_acc: 0.535062. Batch_loss: 1.269621 \n",
      "Batch: 1204. Acc: 0.540840. Loss: 1.268790. Batch_acc: 0.551546. Batch_loss: 1.234066 \n",
      "Batch: 1205. Acc: 0.540850. Loss: 1.268752. Batch_acc: 0.553130. Batch_loss: 1.222462 \n",
      "Batch: 1206. Acc: 0.540856. Loss: 1.268712. Batch_acc: 0.547866. Batch_loss: 1.219934 \n",
      "Batch: 1207. Acc: 0.540850. Loss: 1.268730. Batch_acc: 0.533372. Batch_loss: 1.290998 \n",
      "Batch: 1208. Acc: 0.540837. Loss: 1.268740. Batch_acc: 0.525414. Batch_loss: 1.281032 \n",
      "Batch: 1209. Acc: 0.540838. Loss: 1.268745. Batch_acc: 0.542791. Batch_loss: 1.274800 \n",
      "Batch: 1210. Acc: 0.540831. Loss: 1.268772. Batch_acc: 0.531324. Batch_loss: 1.302236 \n",
      "Batch: 1211. Acc: 0.540818. Loss: 1.268789. Batch_acc: 0.525474. Batch_loss: 1.289270 \n",
      "Batch: 1212. Acc: 0.540827. Loss: 1.268778. Batch_acc: 0.550600. Batch_loss: 1.256457 \n",
      "Batch: 1213. Acc: 0.540804. Loss: 1.268843. Batch_acc: 0.513857. Batch_loss: 1.348108 \n",
      "Batch: 1214. Acc: 0.540811. Loss: 1.268793. Batch_acc: 0.548549. Batch_loss: 1.209691 \n",
      "Batch: 1215. Acc: 0.540808. Loss: 1.268809. Batch_acc: 0.537026. Batch_loss: 1.288735 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1216. Acc: 0.540804. Loss: 1.268813. Batch_acc: 0.536348. Batch_loss: 1.272738 \n",
      "Batch: 1217. Acc: 0.540796. Loss: 1.268872. Batch_acc: 0.531125. Batch_loss: 1.340766 \n",
      "Batch: 1218. Acc: 0.540779. Loss: 1.268914. Batch_acc: 0.519429. Batch_loss: 1.319194 \n",
      "Batch: 1219. Acc: 0.540763. Loss: 1.268951. Batch_acc: 0.521465. Batch_loss: 1.314328 \n",
      "Batch: 1220. Acc: 0.540772. Loss: 1.268934. Batch_acc: 0.551744. Batch_loss: 1.248066 \n",
      "Batch: 1221. Acc: 0.540784. Loss: 1.268907. Batch_acc: 0.555367. Batch_loss: 1.237032 \n",
      "Batch: 1222. Acc: 0.540788. Loss: 1.268887. Batch_acc: 0.545455. Batch_loss: 1.243612 \n",
      "Batch: 1223. Acc: 0.540788. Loss: 1.268902. Batch_acc: 0.541740. Batch_loss: 1.287749 \n",
      "Batch: 1224. Acc: 0.540790. Loss: 1.268897. Batch_acc: 0.542461. Batch_loss: 1.262406 \n",
      "Batch: 1225. Acc: 0.540774. Loss: 1.268936. Batch_acc: 0.521240. Batch_loss: 1.317143 \n",
      "Batch: 1226. Acc: 0.540747. Loss: 1.269025. Batch_acc: 0.506555. Batch_loss: 1.381916 \n",
      "Batch: 1227. Acc: 0.540731. Loss: 1.269068. Batch_acc: 0.521209. Batch_loss: 1.322349 \n",
      "Batch: 1228. Acc: 0.540726. Loss: 1.269077. Batch_acc: 0.535017. Batch_loss: 1.280038 \n",
      "Batch: 1229. Acc: 0.540722. Loss: 1.269109. Batch_acc: 0.535267. Batch_loss: 1.307889 \n",
      "Batch: 1230. Acc: 0.540718. Loss: 1.269133. Batch_acc: 0.536358. Batch_loss: 1.298382 \n",
      "Batch: 1231. Acc: 0.540694. Loss: 1.269206. Batch_acc: 0.510369. Batch_loss: 1.359610 \n",
      "Batch: 1232. Acc: 0.540692. Loss: 1.269220. Batch_acc: 0.538248. Batch_loss: 1.285562 \n",
      "Batch: 1233. Acc: 0.540696. Loss: 1.269206. Batch_acc: 0.545612. Batch_loss: 1.252858 \n",
      "Batch: 1234. Acc: 0.540696. Loss: 1.269206. Batch_acc: 0.540711. Batch_loss: 1.269126 \n",
      "Batch: 1235. Acc: 0.540701. Loss: 1.269186. Batch_acc: 0.546767. Batch_loss: 1.244130 \n",
      "Batch: 1236. Acc: 0.540713. Loss: 1.269173. Batch_acc: 0.555942. Batch_loss: 1.252978 \n",
      "Batch: 1237. Acc: 0.540727. Loss: 1.269137. Batch_acc: 0.558523. Batch_loss: 1.225475 \n",
      "Batch: 1238. Acc: 0.540747. Loss: 1.269099. Batch_acc: 0.564424. Batch_loss: 1.221771 \n",
      "Batch: 1239. Acc: 0.540745. Loss: 1.269100. Batch_acc: 0.538766. Batch_loss: 1.269967 \n",
      "Batch: 1240. Acc: 0.540755. Loss: 1.269120. Batch_acc: 0.553276. Batch_loss: 1.293809 \n",
      "Batch: 1241. Acc: 0.540766. Loss: 1.269085. Batch_acc: 0.554062. Batch_loss: 1.227479 \n",
      "Batch: 1242. Acc: 0.540766. Loss: 1.269071. Batch_acc: 0.539965. Batch_loss: 1.251932 \n",
      "Batch: 1243. Acc: 0.540764. Loss: 1.269080. Batch_acc: 0.538866. Batch_loss: 1.280272 \n",
      "Batch: 1244. Acc: 0.540776. Loss: 1.269027. Batch_acc: 0.555811. Batch_loss: 1.202438 \n",
      "Batch: 1245. Acc: 0.540772. Loss: 1.269030. Batch_acc: 0.534979. Batch_loss: 1.272701 \n",
      "Batch: 1246. Acc: 0.540774. Loss: 1.269045. Batch_acc: 0.544186. Batch_loss: 1.288755 \n",
      "Batch: 1247. Acc: 0.540784. Loss: 1.269024. Batch_acc: 0.552392. Batch_loss: 1.242671 \n",
      "Batch: 1248. Acc: 0.540769. Loss: 1.269042. Batch_acc: 0.522241. Batch_loss: 1.291433 \n",
      "Batch: 1249. Acc: 0.540764. Loss: 1.269038. Batch_acc: 0.534562. Batch_loss: 1.264561 \n",
      "Batch: 1250. Acc: 0.540748. Loss: 1.269097. Batch_acc: 0.521062. Batch_loss: 1.342275 \n",
      "Batch: 1251. Acc: 0.540758. Loss: 1.269051. Batch_acc: 0.551977. Batch_loss: 1.213184 \n",
      "Batch: 1252. Acc: 0.540758. Loss: 1.269026. Batch_acc: 0.541190. Batch_loss: 1.237221 \n",
      "Batch: 1253. Acc: 0.540760. Loss: 1.269020. Batch_acc: 0.543002. Batch_loss: 1.262440 \n",
      "Batch: 1254. Acc: 0.540745. Loss: 1.269067. Batch_acc: 0.521383. Batch_loss: 1.328824 \n",
      "Batch: 1255. Acc: 0.540748. Loss: 1.269044. Batch_acc: 0.545455. Batch_loss: 1.240260 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.5407483560163391. Loss per char: 1.2690437795819212. Time: 1627222840.6053505\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 18, 20, 22, 26, 25, 25, 21, 20, 19,\n",
      "        15, 18, 26, 21,  1, 77, 70, 84, 84,  1, 85, 73, 66, 79,  1, 14, 20, 32,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.540734. Loss: 1.269082. Batch_acc: 0.523068. Batch_loss: 1.317826 \n",
      "Batch: 1257. Acc: 0.540743. Loss: 1.269070. Batch_acc: 0.551824. Batch_loss: 1.252938 \n",
      "Batch: 1258. Acc: 0.540747. Loss: 1.269044. Batch_acc: 0.546083. Batch_loss: 1.236610 \n",
      "Batch: 1259. Acc: 0.540732. Loss: 1.269097. Batch_acc: 0.520785. Batch_loss: 1.336101 \n",
      "Batch: 1260. Acc: 0.540750. Loss: 1.269048. Batch_acc: 0.564059. Batch_loss: 1.208299 \n",
      "Batch: 1261. Acc: 0.540754. Loss: 1.269036. Batch_acc: 0.545661. Batch_loss: 1.253646 \n",
      "Batch: 1262. Acc: 0.540773. Loss: 1.268994. Batch_acc: 0.563884. Batch_loss: 1.216722 \n",
      "Batch: 1263. Acc: 0.540796. Loss: 1.268942. Batch_acc: 0.570034. Batch_loss: 1.204196 \n",
      "Batch: 1264. Acc: 0.540794. Loss: 1.268944. Batch_acc: 0.538506. Batch_loss: 1.271549 \n",
      "Batch: 1265. Acc: 0.540768. Loss: 1.268997. Batch_acc: 0.506690. Batch_loss: 1.336422 \n",
      "Batch: 1266. Acc: 0.540764. Loss: 1.269002. Batch_acc: 0.536401. Batch_loss: 1.275055 \n",
      "Batch: 1267. Acc: 0.540780. Loss: 1.268983. Batch_acc: 0.560726. Batch_loss: 1.245809 \n",
      "Batch: 1268. Acc: 0.540792. Loss: 1.268935. Batch_acc: 0.555300. Batch_loss: 1.207562 \n",
      "Batch: 1269. Acc: 0.540800. Loss: 1.268913. Batch_acc: 0.551803. Batch_loss: 1.240545 \n",
      "Batch: 1270. Acc: 0.540788. Loss: 1.268955. Batch_acc: 0.524695. Batch_loss: 1.323028 \n",
      "Batch: 1271. Acc: 0.540782. Loss: 1.268944. Batch_acc: 0.534019. Batch_loss: 1.255823 \n",
      "Batch: 1272. Acc: 0.540785. Loss: 1.268949. Batch_acc: 0.544772. Batch_loss: 1.274477 \n",
      "Batch: 1273. Acc: 0.540776. Loss: 1.269001. Batch_acc: 0.528076. Batch_loss: 1.338863 \n",
      "Batch: 1274. Acc: 0.540782. Loss: 1.268967. Batch_acc: 0.548864. Batch_loss: 1.226115 \n",
      "Batch: 1275. Acc: 0.540780. Loss: 1.268976. Batch_acc: 0.537365. Batch_loss: 1.280060 \n",
      "Batch: 1276. Acc: 0.540766. Loss: 1.269020. Batch_acc: 0.522754. Batch_loss: 1.325699 \n",
      "Batch: 1277. Acc: 0.540765. Loss: 1.269007. Batch_acc: 0.540480. Batch_loss: 1.252431 \n",
      "Batch: 1278. Acc: 0.540775. Loss: 1.268971. Batch_acc: 0.552511. Batch_loss: 1.223397 \n",
      "Batch: 1279. Acc: 0.540768. Loss: 1.269003. Batch_acc: 0.531915. Batch_loss: 1.311368 \n",
      "Batch: 1280. Acc: 0.540765. Loss: 1.269010. Batch_acc: 0.536963. Batch_loss: 1.277542 \n",
      "Batch: 1281. Acc: 0.540767. Loss: 1.269006. Batch_acc: 0.543921. Batch_loss: 1.264325 \n",
      "Batch: 1282. Acc: 0.540773. Loss: 1.268999. Batch_acc: 0.547774. Batch_loss: 1.259109 \n",
      "Batch: 1283. Acc: 0.540767. Loss: 1.269038. Batch_acc: 0.533219. Batch_loss: 1.319594 \n",
      "Batch: 1284. Acc: 0.540751. Loss: 1.269083. Batch_acc: 0.519481. Batch_loss: 1.328494 \n",
      "Batch: 1285. Acc: 0.540763. Loss: 1.269059. Batch_acc: 0.556322. Batch_loss: 1.238377 \n",
      "Batch: 1286. Acc: 0.540773. Loss: 1.269030. Batch_acc: 0.553382. Batch_loss: 1.232933 \n",
      "Batch: 1287. Acc: 0.540775. Loss: 1.269018. Batch_acc: 0.543733. Batch_loss: 1.253470 \n",
      "Batch: 1288. Acc: 0.540801. Loss: 1.268937. Batch_acc: 0.573770. Batch_loss: 1.166214 \n",
      "Batch: 1289. Acc: 0.540794. Loss: 1.268951. Batch_acc: 0.531891. Batch_loss: 1.286852 \n",
      "Batch: 1290. Acc: 0.540786. Loss: 1.268957. Batch_acc: 0.529688. Batch_loss: 1.277220 \n",
      "Batch: 1291. Acc: 0.540797. Loss: 1.268933. Batch_acc: 0.554324. Batch_loss: 1.238460 \n",
      "Batch: 1292. Acc: 0.540782. Loss: 1.268974. Batch_acc: 0.521043. Batch_loss: 1.324498 \n",
      "Batch: 1293. Acc: 0.540776. Loss: 1.268980. Batch_acc: 0.533063. Batch_loss: 1.276501 \n",
      "Batch: 1294. Acc: 0.540775. Loss: 1.268985. Batch_acc: 0.539535. Batch_loss: 1.275469 \n",
      "Batch: 1295. Acc: 0.540776. Loss: 1.268979. Batch_acc: 0.541909. Batch_loss: 1.261175 \n",
      "Batch: 1296. Acc: 0.540766. Loss: 1.268982. Batch_acc: 0.528083. Batch_loss: 1.272444 \n",
      "Batch: 1297. Acc: 0.540772. Loss: 1.268972. Batch_acc: 0.548607. Batch_loss: 1.256583 \n",
      "Batch: 1298. Acc: 0.540807. Loss: 1.268888. Batch_acc: 0.584607. Batch_loss: 1.162212 \n",
      "Batch: 1299. Acc: 0.540796. Loss: 1.268905. Batch_acc: 0.526192. Batch_loss: 1.290241 \n",
      "Batch: 1300. Acc: 0.540793. Loss: 1.268909. Batch_acc: 0.537536. Batch_loss: 1.275231 \n",
      "Batch: 1301. Acc: 0.540788. Loss: 1.268921. Batch_acc: 0.533839. Batch_loss: 1.284537 \n",
      "Batch: 1302. Acc: 0.540811. Loss: 1.268871. Batch_acc: 0.571681. Batch_loss: 1.202171 \n",
      "Batch: 1303. Acc: 0.540808. Loss: 1.268866. Batch_acc: 0.536342. Batch_loss: 1.261430 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1304. Acc: 0.540797. Loss: 1.268896. Batch_acc: 0.526648. Batch_loss: 1.308128 \n",
      "Batch: 1305. Acc: 0.540806. Loss: 1.268875. Batch_acc: 0.552392. Batch_loss: 1.241236 \n",
      "Batch: 1306. Acc: 0.540787. Loss: 1.268910. Batch_acc: 0.515513. Batch_loss: 1.317328 \n",
      "Batch: 1307. Acc: 0.540801. Loss: 1.268859. Batch_acc: 0.558523. Batch_loss: 1.202570 \n",
      "Batch: 1308. Acc: 0.540796. Loss: 1.268873. Batch_acc: 0.534151. Batch_loss: 1.287211 \n",
      "Batch: 1309. Acc: 0.540789. Loss: 1.268872. Batch_acc: 0.532548. Batch_loss: 1.267678 \n",
      "Batch: 1310. Acc: 0.540787. Loss: 1.268897. Batch_acc: 0.537246. Batch_loss: 1.300932 \n",
      "Batch: 1311. Acc: 0.540786. Loss: 1.268901. Batch_acc: 0.540355. Batch_loss: 1.274750 \n",
      "Batch: 1312. Acc: 0.540770. Loss: 1.268956. Batch_acc: 0.519909. Batch_loss: 1.339458 \n",
      "Batch: 1313. Acc: 0.540768. Loss: 1.268966. Batch_acc: 0.537514. Batch_loss: 1.282392 \n",
      "Batch: 1314. Acc: 0.540769. Loss: 1.268975. Batch_acc: 0.543335. Batch_loss: 1.281843 \n",
      "Batch: 1315. Acc: 0.540772. Loss: 1.269000. Batch_acc: 0.543516. Batch_loss: 1.301519 \n",
      "Batch: 1316. Acc: 0.540771. Loss: 1.269016. Batch_acc: 0.540650. Batch_loss: 1.289891 \n",
      "Batch: 1317. Acc: 0.540769. Loss: 1.269010. Batch_acc: 0.536905. Batch_loss: 1.261230 \n",
      "Batch: 1318. Acc: 0.540764. Loss: 1.269030. Batch_acc: 0.535308. Batch_loss: 1.294671 \n",
      "Batch: 1319. Acc: 0.540760. Loss: 1.269037. Batch_acc: 0.534963. Batch_loss: 1.278107 \n",
      "Batch: 1320. Acc: 0.540762. Loss: 1.269016. Batch_acc: 0.543379. Batch_loss: 1.241847 \n",
      "Batch: 1321. Acc: 0.540755. Loss: 1.269024. Batch_acc: 0.531915. Batch_loss: 1.279988 \n",
      "Batch: 1322. Acc: 0.540767. Loss: 1.268993. Batch_acc: 0.555492. Batch_loss: 1.228563 \n",
      "Batch: 1323. Acc: 0.540772. Loss: 1.268967. Batch_acc: 0.547730. Batch_loss: 1.233725 \n",
      "Batch: 1324. Acc: 0.540774. Loss: 1.268954. Batch_acc: 0.543316. Batch_loss: 1.251199 \n",
      "Batch: 1325. Acc: 0.540769. Loss: 1.268964. Batch_acc: 0.535251. Batch_loss: 1.282937 \n",
      "Batch: 1326. Acc: 0.540759. Loss: 1.268993. Batch_acc: 0.526832. Batch_loss: 1.306484 \n",
      "Batch: 1327. Acc: 0.540776. Loss: 1.268959. Batch_acc: 0.563258. Batch_loss: 1.224755 \n",
      "Batch: 1328. Acc: 0.540787. Loss: 1.268942. Batch_acc: 0.555685. Batch_loss: 1.245436 \n",
      "Batch: 1329. Acc: 0.540797. Loss: 1.268900. Batch_acc: 0.554367. Batch_loss: 1.211696 \n",
      "Batch: 1330. Acc: 0.540808. Loss: 1.268876. Batch_acc: 0.556080. Batch_loss: 1.235871 \n",
      "Batch: 1331. Acc: 0.540828. Loss: 1.268844. Batch_acc: 0.568261. Batch_loss: 1.225059 \n",
      "Batch: 1332. Acc: 0.540822. Loss: 1.268846. Batch_acc: 0.532358. Batch_loss: 1.272123 \n",
      "Batch: 1333. Acc: 0.540833. Loss: 1.268801. Batch_acc: 0.556120. Batch_loss: 1.210285 \n",
      "Batch: 1334. Acc: 0.540842. Loss: 1.268787. Batch_acc: 0.551977. Batch_loss: 1.249303 \n",
      "Batch: 1335. Acc: 0.540839. Loss: 1.268791. Batch_acc: 0.536920. Batch_loss: 1.274870 \n",
      "Batch: 1336. Acc: 0.540825. Loss: 1.268835. Batch_acc: 0.521689. Batch_loss: 1.328100 \n",
      "Batch: 1337. Acc: 0.540821. Loss: 1.268835. Batch_acc: 0.536290. Batch_loss: 1.268107 \n",
      "Batch: 1338. Acc: 0.540845. Loss: 1.268765. Batch_acc: 0.572905. Batch_loss: 1.175324 \n",
      "Batch: 1339. Acc: 0.540846. Loss: 1.268757. Batch_acc: 0.541405. Batch_loss: 1.258816 \n",
      "Batch: 1340. Acc: 0.540846. Loss: 1.268729. Batch_acc: 0.540694. Batch_loss: 1.231229 \n",
      "Batch: 1341. Acc: 0.540852. Loss: 1.268697. Batch_acc: 0.549584. Batch_loss: 1.227669 \n",
      "Batch: 1342. Acc: 0.540888. Loss: 1.268619. Batch_acc: 0.588742. Batch_loss: 1.163537 \n",
      "Batch: 1343. Acc: 0.540905. Loss: 1.268576. Batch_acc: 0.563284. Batch_loss: 1.212223 \n",
      "Batch: 1344. Acc: 0.540918. Loss: 1.268545. Batch_acc: 0.558789. Batch_loss: 1.224327 \n",
      "Batch: 1345. Acc: 0.540916. Loss: 1.268554. Batch_acc: 0.538329. Batch_loss: 1.280960 \n",
      "Batch: 1346. Acc: 0.540924. Loss: 1.268513. Batch_acc: 0.551903. Batch_loss: 1.213713 \n",
      "Batch: 1347. Acc: 0.540926. Loss: 1.268500. Batch_acc: 0.542989. Batch_loss: 1.250319 \n",
      "Batch: 1348. Acc: 0.540922. Loss: 1.268530. Batch_acc: 0.535503. Batch_loss: 1.309964 \n",
      "Batch: 1349. Acc: 0.540921. Loss: 1.268506. Batch_acc: 0.539459. Batch_loss: 1.237098 \n",
      "Batch: 1350. Acc: 0.540918. Loss: 1.268507. Batch_acc: 0.537407. Batch_loss: 1.269914 \n",
      "Batch: 1351. Acc: 0.540933. Loss: 1.268476. Batch_acc: 0.560427. Batch_loss: 1.227984 \n",
      "Batch: 1352. Acc: 0.540929. Loss: 1.268492. Batch_acc: 0.535652. Batch_loss: 1.290059 \n",
      "Batch: 1353. Acc: 0.540948. Loss: 1.268444. Batch_acc: 0.567330. Batch_loss: 1.202492 \n",
      "Batch: 1354. Acc: 0.540926. Loss: 1.268508. Batch_acc: 0.511536. Batch_loss: 1.352475 \n",
      "Batch: 1355. Acc: 0.540930. Loss: 1.268523. Batch_acc: 0.546194. Batch_loss: 1.289739 \n",
      "Batch: 1356. Acc: 0.540929. Loss: 1.268513. Batch_acc: 0.539527. Batch_loss: 1.254540 \n",
      "Batch: 1357. Acc: 0.540957. Loss: 1.268456. Batch_acc: 0.578652. Batch_loss: 1.192610 \n",
      "Batch: 1358. Acc: 0.540958. Loss: 1.268452. Batch_acc: 0.542105. Batch_loss: 1.264134 \n",
      "Batch: 1359. Acc: 0.540965. Loss: 1.268444. Batch_acc: 0.550607. Batch_loss: 1.256829 \n",
      "Batch: 1360. Acc: 0.541005. Loss: 1.268351. Batch_acc: 0.594828. Batch_loss: 1.141409 \n",
      "Batch: 1361. Acc: 0.540999. Loss: 1.268354. Batch_acc: 0.533908. Batch_loss: 1.273462 \n",
      "Batch: 1362. Acc: 0.541028. Loss: 1.268291. Batch_acc: 0.579067. Batch_loss: 1.183742 \n",
      "Batch: 1363. Acc: 0.541046. Loss: 1.268255. Batch_acc: 0.565513. Batch_loss: 1.218661 \n",
      "Batch: 1364. Acc: 0.541074. Loss: 1.268185. Batch_acc: 0.578830. Batch_loss: 1.176414 \n",
      "Batch: 1365. Acc: 0.541068. Loss: 1.268187. Batch_acc: 0.532073. Batch_loss: 1.270265 \n",
      "Batch: 1366. Acc: 0.541078. Loss: 1.268153. Batch_acc: 0.555176. Batch_loss: 1.223078 \n",
      "Batch: 1367. Acc: 0.541094. Loss: 1.268120. Batch_acc: 0.561798. Batch_loss: 1.223866 \n",
      "Batch: 1368. Acc: 0.541102. Loss: 1.268096. Batch_acc: 0.553318. Batch_loss: 1.233747 \n",
      "Batch: 1369. Acc: 0.541116. Loss: 1.268054. Batch_acc: 0.560440. Batch_loss: 1.210249 \n",
      "Batch: 1370. Acc: 0.541128. Loss: 1.268030. Batch_acc: 0.557208. Batch_loss: 1.235665 \n",
      "Batch: 1371. Acc: 0.541125. Loss: 1.268033. Batch_acc: 0.536642. Batch_loss: 1.271878 \n",
      "Batch: 1372. Acc: 0.541123. Loss: 1.268044. Batch_acc: 0.538638. Batch_loss: 1.283745 \n",
      "Batch: 1373. Acc: 0.541122. Loss: 1.268034. Batch_acc: 0.539390. Batch_loss: 1.254157 \n",
      "Batch: 1374. Acc: 0.541112. Loss: 1.268050. Batch_acc: 0.527429. Batch_loss: 1.289403 \n",
      "Batch: 1375. Acc: 0.541122. Loss: 1.268020. Batch_acc: 0.554183. Batch_loss: 1.227401 \n",
      "Batch: 1376. Acc: 0.541127. Loss: 1.268017. Batch_acc: 0.548881. Batch_loss: 1.264012 \n",
      "Batch: 1377. Acc: 0.541144. Loss: 1.267951. Batch_acc: 0.563830. Batch_loss: 1.179144 \n",
      "Batch: 1378. Acc: 0.541150. Loss: 1.267923. Batch_acc: 0.549097. Batch_loss: 1.231043 \n",
      "Batch: 1379. Acc: 0.541171. Loss: 1.267875. Batch_acc: 0.569700. Batch_loss: 1.201295 \n",
      "Batch: 1380. Acc: 0.541181. Loss: 1.267834. Batch_acc: 0.554980. Batch_loss: 1.211725 \n",
      "Batch: 1381. Acc: 0.541164. Loss: 1.267874. Batch_acc: 0.517282. Batch_loss: 1.323529 \n",
      "Batch: 1382. Acc: 0.541179. Loss: 1.267847. Batch_acc: 0.562073. Batch_loss: 1.231495 \n",
      "Batch: 1383. Acc: 0.541183. Loss: 1.267836. Batch_acc: 0.547192. Batch_loss: 1.251938 \n",
      "Batch: 1384. Acc: 0.541177. Loss: 1.267850. Batch_acc: 0.532147. Batch_loss: 1.287432 \n",
      "Batch: 1385. Acc: 0.541165. Loss: 1.267874. Batch_acc: 0.524730. Batch_loss: 1.300311 \n",
      "Batch: 1386. Acc: 0.541176. Loss: 1.267837. Batch_acc: 0.556969. Batch_loss: 1.216279 \n",
      "Batch: 1387. Acc: 0.541179. Loss: 1.267826. Batch_acc: 0.545401. Batch_loss: 1.252254 \n",
      "Batch: 1388. Acc: 0.541173. Loss: 1.267832. Batch_acc: 0.532792. Batch_loss: 1.275721 \n",
      "Batch: 1389. Acc: 0.541163. Loss: 1.267839. Batch_acc: 0.527199. Batch_loss: 1.278399 \n",
      "Batch: 1390. Acc: 0.541176. Loss: 1.267807. Batch_acc: 0.558807. Batch_loss: 1.223071 \n",
      "Batch: 1391. Acc: 0.541169. Loss: 1.267808. Batch_acc: 0.531696. Batch_loss: 1.269096 \n",
      "Batch: 1392. Acc: 0.541193. Loss: 1.267762. Batch_acc: 0.574468. Batch_loss: 1.204322 \n",
      "Batch: 1393. Acc: 0.541196. Loss: 1.267755. Batch_acc: 0.546512. Batch_loss: 1.257286 \n",
      "Batch: 1394. Acc: 0.541207. Loss: 1.267717. Batch_acc: 0.555300. Batch_loss: 1.214587 \n",
      "Batch: 1395. Acc: 0.541199. Loss: 1.267739. Batch_acc: 0.531014. Batch_loss: 1.299022 \n",
      "Batch: 1396. Acc: 0.541196. Loss: 1.267739. Batch_acc: 0.537237. Batch_loss: 1.268037 \n",
      "Batch: 1397. Acc: 0.541187. Loss: 1.267778. Batch_acc: 0.526971. Batch_loss: 1.323723 \n",
      "Batch: 1398. Acc: 0.541192. Loss: 1.267772. Batch_acc: 0.548387. Batch_loss: 1.259934 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1399. Acc: 0.541199. Loss: 1.267768. Batch_acc: 0.550963. Batch_loss: 1.261124 \n",
      "Batch: 1400. Acc: 0.541199. Loss: 1.267748. Batch_acc: 0.540694. Batch_loss: 1.240130 \n",
      "Batch: 1401. Acc: 0.541200. Loss: 1.267776. Batch_acc: 0.543953. Batch_loss: 1.308197 \n",
      "Batch: 1402. Acc: 0.541198. Loss: 1.267794. Batch_acc: 0.537714. Batch_loss: 1.293821 \n",
      "Batch: 1403. Acc: 0.541187. Loss: 1.267828. Batch_acc: 0.525543. Batch_loss: 1.316133 \n",
      "Batch: 1404. Acc: 0.541184. Loss: 1.267810. Batch_acc: 0.536514. Batch_loss: 1.242085 \n",
      "Batch: 1405. Acc: 0.541182. Loss: 1.267813. Batch_acc: 0.538153. Batch_loss: 1.272229 \n",
      "Batch: 1406. Acc: 0.541194. Loss: 1.267781. Batch_acc: 0.557341. Batch_loss: 1.223868 \n",
      "Batch: 1407. Acc: 0.541195. Loss: 1.267781. Batch_acc: 0.542745. Batch_loss: 1.268040 \n",
      "Batch: 1408. Acc: 0.541189. Loss: 1.267813. Batch_acc: 0.532297. Batch_loss: 1.314662 \n",
      "Batch: 1409. Acc: 0.541184. Loss: 1.267835. Batch_acc: 0.534552. Batch_loss: 1.298711 \n",
      "Batch: 1410. Acc: 0.541179. Loss: 1.267863. Batch_acc: 0.534325. Batch_loss: 1.306160 \n",
      "Batch: 1411. Acc: 0.541167. Loss: 1.267891. Batch_acc: 0.524221. Batch_loss: 1.308346 \n",
      "Batch: 1412. Acc: 0.541160. Loss: 1.267903. Batch_acc: 0.531178. Batch_loss: 1.284836 \n",
      "Batch: 1413. Acc: 0.541169. Loss: 1.267860. Batch_acc: 0.554524. Batch_loss: 1.206835 \n",
      "Batch: 1414. Acc: 0.541169. Loss: 1.267867. Batch_acc: 0.541108. Batch_loss: 1.278090 \n",
      "Batch: 1415. Acc: 0.541176. Loss: 1.267856. Batch_acc: 0.551195. Batch_loss: 1.252010 \n",
      "Batch: 1416. Acc: 0.541175. Loss: 1.267865. Batch_acc: 0.538687. Batch_loss: 1.281517 \n",
      "Batch: 1417. Acc: 0.541170. Loss: 1.267878. Batch_acc: 0.534710. Batch_loss: 1.286086 \n",
      "Batch: 1418. Acc: 0.541168. Loss: 1.267868. Batch_acc: 0.537757. Batch_loss: 1.253312 \n",
      "Batch: 1419. Acc: 0.541179. Loss: 1.267832. Batch_acc: 0.557737. Batch_loss: 1.215981 \n",
      "Batch: 1420. Acc: 0.541178. Loss: 1.267835. Batch_acc: 0.538912. Batch_loss: 1.272172 \n",
      "Batch: 1421. Acc: 0.541207. Loss: 1.267759. Batch_acc: 0.581696. Batch_loss: 1.163382 \n",
      "Batch: 1422. Acc: 0.541175. Loss: 1.267828. Batch_acc: 0.496301. Batch_loss: 1.364156 \n",
      "Batch: 1423. Acc: 0.541176. Loss: 1.267838. Batch_acc: 0.542283. Batch_loss: 1.283254 \n",
      "Batch: 1424. Acc: 0.541166. Loss: 1.267869. Batch_acc: 0.527043. Batch_loss: 1.311157 \n",
      "Batch: 1425. Acc: 0.541169. Loss: 1.267863. Batch_acc: 0.545299. Batch_loss: 1.259561 \n",
      "Batch: 1426. Acc: 0.541178. Loss: 1.267826. Batch_acc: 0.554974. Batch_loss: 1.213954 \n",
      "Batch: 1427. Acc: 0.541175. Loss: 1.267833. Batch_acc: 0.535880. Batch_loss: 1.278801 \n",
      "Batch: 1428. Acc: 0.541171. Loss: 1.267839. Batch_acc: 0.536232. Batch_loss: 1.276354 \n",
      "Batch: 1429. Acc: 0.541173. Loss: 1.267835. Batch_acc: 0.544000. Batch_loss: 1.262668 \n",
      "Batch: 1430. Acc: 0.541171. Loss: 1.267839. Batch_acc: 0.537536. Batch_loss: 1.272553 \n",
      "Batch: 1431. Acc: 0.541170. Loss: 1.267845. Batch_acc: 0.540223. Batch_loss: 1.276579 \n",
      "Batch: 1432. Acc: 0.541172. Loss: 1.267859. Batch_acc: 0.544044. Batch_loss: 1.287238 \n",
      "Batch: 1433. Acc: 0.541185. Loss: 1.267842. Batch_acc: 0.559400. Batch_loss: 1.243904 \n",
      "Batch: 1434. Acc: 0.541189. Loss: 1.267819. Batch_acc: 0.547592. Batch_loss: 1.235147 \n",
      "Batch: 1435. Acc: 0.541181. Loss: 1.267839. Batch_acc: 0.529241. Batch_loss: 1.297372 \n",
      "Batch: 1436. Acc: 0.541177. Loss: 1.267842. Batch_acc: 0.534422. Batch_loss: 1.272364 \n",
      "Batch: 1437. Acc: 0.541186. Loss: 1.267805. Batch_acc: 0.554971. Batch_loss: 1.213316 \n",
      "Batch: 1438. Acc: 0.541197. Loss: 1.267783. Batch_acc: 0.556120. Batch_loss: 1.236342 \n",
      "Batch: 1439. Acc: 0.541202. Loss: 1.267784. Batch_acc: 0.548837. Batch_loss: 1.270112 \n",
      "Batch: 1440. Acc: 0.541202. Loss: 1.267749. Batch_acc: 0.541954. Batch_loss: 1.217411 \n",
      "Batch: 1441. Acc: 0.541202. Loss: 1.267765. Batch_acc: 0.541390. Batch_loss: 1.290881 \n",
      "Batch: 1442. Acc: 0.541184. Loss: 1.267805. Batch_acc: 0.514420. Batch_loss: 1.327414 \n",
      "Batch: 1443. Acc: 0.541189. Loss: 1.267792. Batch_acc: 0.548442. Batch_loss: 1.249365 \n",
      "Batch: 1444. Acc: 0.541193. Loss: 1.267780. Batch_acc: 0.545824. Batch_loss: 1.250099 \n",
      "Batch: 1445. Acc: 0.541197. Loss: 1.267764. Batch_acc: 0.547953. Batch_loss: 1.245539 \n",
      "Batch: 1446. Acc: 0.541202. Loss: 1.267750. Batch_acc: 0.547509. Batch_loss: 1.247164 \n",
      "Batch: 1447. Acc: 0.541219. Loss: 1.267683. Batch_acc: 0.565616. Batch_loss: 1.171356 \n",
      "Batch: 1448. Acc: 0.541224. Loss: 1.267681. Batch_acc: 0.549214. Batch_loss: 1.264650 \n",
      "Batch: 1449. Acc: 0.541235. Loss: 1.267642. Batch_acc: 0.557217. Batch_loss: 1.211216 \n",
      "Batch: 1450. Acc: 0.541254. Loss: 1.267590. Batch_acc: 0.568272. Batch_loss: 1.192925 \n",
      "Batch: 1451. Acc: 0.541264. Loss: 1.267565. Batch_acc: 0.555817. Batch_loss: 1.230325 \n",
      "Batch: 1452. Acc: 0.541264. Loss: 1.267567. Batch_acc: 0.542007. Batch_loss: 1.270641 \n",
      "Batch: 1453. Acc: 0.541252. Loss: 1.267599. Batch_acc: 0.523243. Batch_loss: 1.313746 \n",
      "Batch: 1454. Acc: 0.541258. Loss: 1.267565. Batch_acc: 0.551020. Batch_loss: 1.217230 \n",
      "Batch: 1455. Acc: 0.541261. Loss: 1.267552. Batch_acc: 0.544715. Batch_loss: 1.248630 \n",
      "Batch: 1456. Acc: 0.541258. Loss: 1.267560. Batch_acc: 0.537296. Batch_loss: 1.278693 \n",
      "Batch: 1457. Acc: 0.541260. Loss: 1.267541. Batch_acc: 0.544233. Batch_loss: 1.241344 \n",
      "Batch: 1458. Acc: 0.541267. Loss: 1.267519. Batch_acc: 0.551763. Batch_loss: 1.235463 \n",
      "Batch: 1459. Acc: 0.541272. Loss: 1.267514. Batch_acc: 0.547564. Batch_loss: 1.260767 \n",
      "Batch: 1460. Acc: 0.541293. Loss: 1.267465. Batch_acc: 0.571348. Batch_loss: 1.196423 \n",
      "Batch: 1461. Acc: 0.541301. Loss: 1.267453. Batch_acc: 0.553470. Batch_loss: 1.251251 \n",
      "Batch: 1462. Acc: 0.541310. Loss: 1.267422. Batch_acc: 0.554031. Batch_loss: 1.222229 \n",
      "Batch: 1463. Acc: 0.541330. Loss: 1.267384. Batch_acc: 0.569899. Batch_loss: 1.213100 \n",
      "Batch: 1464. Acc: 0.541339. Loss: 1.267345. Batch_acc: 0.554926. Batch_loss: 1.209952 \n",
      "Batch: 1465. Acc: 0.541328. Loss: 1.267370. Batch_acc: 0.525217. Batch_loss: 1.305321 \n",
      "Batch: 1466. Acc: 0.541303. Loss: 1.267442. Batch_acc: 0.502398. Batch_loss: 1.377643 \n",
      "Batch: 1467. Acc: 0.541307. Loss: 1.267441. Batch_acc: 0.547591. Batch_loss: 1.265607 \n",
      "Batch: 1468. Acc: 0.541309. Loss: 1.267446. Batch_acc: 0.543667. Batch_loss: 1.274216 \n",
      "Batch: 1469. Acc: 0.541311. Loss: 1.267461. Batch_acc: 0.544921. Batch_loss: 1.290843 \n",
      "Batch: 1470. Acc: 0.541310. Loss: 1.267472. Batch_acc: 0.539747. Batch_loss: 1.283180 \n",
      "Batch: 1471. Acc: 0.541318. Loss: 1.267454. Batch_acc: 0.553204. Batch_loss: 1.240182 \n",
      "Batch: 1472. Acc: 0.541314. Loss: 1.267474. Batch_acc: 0.535113. Batch_loss: 1.296965 \n",
      "Batch: 1473. Acc: 0.541321. Loss: 1.267464. Batch_acc: 0.551724. Batch_loss: 1.252073 \n",
      "Batch: 1474. Acc: 0.541338. Loss: 1.267392. Batch_acc: 0.565834. Batch_loss: 1.163583 \n",
      "Batch: 1475. Acc: 0.541351. Loss: 1.267351. Batch_acc: 0.560408. Batch_loss: 1.207682 \n",
      "Batch: 1476. Acc: 0.541345. Loss: 1.267368. Batch_acc: 0.532992. Batch_loss: 1.291854 \n",
      "Batch: 1477. Acc: 0.541355. Loss: 1.267334. Batch_acc: 0.556897. Batch_loss: 1.217335 \n",
      "Batch: 1478. Acc: 0.541364. Loss: 1.267309. Batch_acc: 0.554322. Batch_loss: 1.229588 \n",
      "Batch: 1479. Acc: 0.541380. Loss: 1.267256. Batch_acc: 0.564841. Batch_loss: 1.189377 \n",
      "Batch: 1480. Acc: 0.541384. Loss: 1.267226. Batch_acc: 0.547577. Batch_loss: 1.222006 \n",
      "Batch: 1481. Acc: 0.541389. Loss: 1.267221. Batch_acc: 0.548387. Batch_loss: 1.259921 \n",
      "Batch: 1482. Acc: 0.541383. Loss: 1.267243. Batch_acc: 0.532014. Batch_loss: 1.299063 \n",
      "Batch: 1483. Acc: 0.541386. Loss: 1.267261. Batch_acc: 0.546974. Batch_loss: 1.294688 \n",
      "Batch: 1484. Acc: 0.541387. Loss: 1.267266. Batch_acc: 0.542506. Batch_loss: 1.274258 \n",
      "Batch: 1485. Acc: 0.541401. Loss: 1.267214. Batch_acc: 0.562393. Batch_loss: 1.191471 \n",
      "Batch: 1486. Acc: 0.541413. Loss: 1.267193. Batch_acc: 0.559371. Batch_loss: 1.235861 \n",
      "Batch: 1487. Acc: 0.541428. Loss: 1.267162. Batch_acc: 0.562606. Batch_loss: 1.221336 \n",
      "Batch: 1488. Acc: 0.541435. Loss: 1.267146. Batch_acc: 0.552023. Batch_loss: 1.243299 \n",
      "Batch: 1489. Acc: 0.541434. Loss: 1.267155. Batch_acc: 0.540750. Batch_loss: 1.280869 \n",
      "Batch: 1490. Acc: 0.541449. Loss: 1.267149. Batch_acc: 0.564132. Batch_loss: 1.257534 \n",
      "Batch: 1491. Acc: 0.541450. Loss: 1.267152. Batch_acc: 0.542323. Batch_loss: 1.272501 \n",
      "Batch: 1492. Acc: 0.541451. Loss: 1.267153. Batch_acc: 0.542245. Batch_loss: 1.267546 \n",
      "Batch: 1493. Acc: 0.541450. Loss: 1.267129. Batch_acc: 0.539977. Batch_loss: 1.231773 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1494. Acc: 0.541457. Loss: 1.267116. Batch_acc: 0.552077. Batch_loss: 1.247571 \n",
      "Batch: 1495. Acc: 0.541451. Loss: 1.267109. Batch_acc: 0.532511. Batch_loss: 1.256900 \n",
      "Batch: 1496. Acc: 0.541463. Loss: 1.267065. Batch_acc: 0.559773. Batch_loss: 1.202894 \n",
      "Batch: 1497. Acc: 0.541485. Loss: 1.266996. Batch_acc: 0.575145. Batch_loss: 1.162172 \n",
      "Batch: 1498. Acc: 0.541484. Loss: 1.267006. Batch_acc: 0.539627. Batch_loss: 1.282147 \n",
      "Batch: 1499. Acc: 0.541489. Loss: 1.267004. Batch_acc: 0.548571. Batch_loss: 1.264302 \n",
      "Batch: 1500. Acc: 0.541491. Loss: 1.267010. Batch_acc: 0.544820. Batch_loss: 1.275793 \n",
      "Batch: 1501. Acc: 0.541493. Loss: 1.266990. Batch_acc: 0.544325. Batch_loss: 1.238629 \n",
      "Batch: 1502. Acc: 0.541495. Loss: 1.266985. Batch_acc: 0.544986. Batch_loss: 1.258437 \n",
      "Batch: 1503. Acc: 0.541504. Loss: 1.266957. Batch_acc: 0.554122. Batch_loss: 1.226308 \n",
      "Batch: 1504. Acc: 0.541510. Loss: 1.266936. Batch_acc: 0.550716. Batch_loss: 1.236060 \n",
      "Batch: 1505. Acc: 0.541516. Loss: 1.266913. Batch_acc: 0.549943. Batch_loss: 1.231554 \n",
      "Batch: 1506. Acc: 0.541513. Loss: 1.266894. Batch_acc: 0.537796. Batch_loss: 1.238667 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.5415133214703123. Loss per char: 1.2668940127400743. Time: 1627223044.9942663\n",
      "Last question is tensor([ 2, 14, 22, 18, 26, 20, 19,  1, 14,  1, 14, 18, 26, 18, 17, 17, 21, 20,\n",
      "        19, 17, 19,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.541507. Loss: 1.266897. Batch_acc: 0.531118. Batch_loss: 1.271979 \n",
      "Batch: 1508. Acc: 0.541497. Loss: 1.266906. Batch_acc: 0.526919. Batch_loss: 1.279610 \n",
      "Batch: 1509. Acc: 0.541499. Loss: 1.266891. Batch_acc: 0.544571. Batch_loss: 1.244519 \n",
      "Batch: 1510. Acc: 0.541511. Loss: 1.266830. Batch_acc: 0.559312. Batch_loss: 1.175066 \n",
      "Batch: 1511. Acc: 0.541505. Loss: 1.266850. Batch_acc: 0.531473. Batch_loss: 1.298423 \n",
      "Batch: 1512. Acc: 0.541504. Loss: 1.266836. Batch_acc: 0.541332. Batch_loss: 1.245512 \n",
      "Batch: 1513. Acc: 0.541507. Loss: 1.266830. Batch_acc: 0.544928. Batch_loss: 1.257784 \n",
      "Batch: 1514. Acc: 0.541516. Loss: 1.266809. Batch_acc: 0.556587. Batch_loss: 1.234656 \n",
      "Batch: 1515. Acc: 0.541514. Loss: 1.266820. Batch_acc: 0.537435. Batch_loss: 1.284063 \n",
      "Batch: 1516. Acc: 0.541512. Loss: 1.266850. Batch_acc: 0.538594. Batch_loss: 1.312009 \n",
      "Batch: 1517. Acc: 0.541531. Loss: 1.266820. Batch_acc: 0.569861. Batch_loss: 1.220565 \n",
      "Batch: 1518. Acc: 0.541531. Loss: 1.266810. Batch_acc: 0.542354. Batch_loss: 1.253063 \n",
      "Batch: 1519. Acc: 0.541535. Loss: 1.266802. Batch_acc: 0.547891. Batch_loss: 1.254406 \n",
      "Batch: 1520. Acc: 0.541527. Loss: 1.266824. Batch_acc: 0.528841. Batch_loss: 1.299695 \n",
      "Batch: 1521. Acc: 0.541533. Loss: 1.266811. Batch_acc: 0.551603. Batch_loss: 1.247347 \n",
      "Batch: 1522. Acc: 0.541526. Loss: 1.266826. Batch_acc: 0.530943. Batch_loss: 1.289779 \n",
      "Batch: 1523. Acc: 0.541506. Loss: 1.266860. Batch_acc: 0.510369. Batch_loss: 1.318904 \n",
      "Batch: 1524. Acc: 0.541508. Loss: 1.266847. Batch_acc: 0.544470. Batch_loss: 1.247006 \n",
      "Batch: 1525. Acc: 0.541529. Loss: 1.266805. Batch_acc: 0.573371. Batch_loss: 1.203819 \n",
      "Batch: 1526. Acc: 0.541530. Loss: 1.266794. Batch_acc: 0.542585. Batch_loss: 1.248555 \n",
      "Batch: 1527. Acc: 0.541540. Loss: 1.266767. Batch_acc: 0.556636. Batch_loss: 1.226764 \n",
      "Batch: 1528. Acc: 0.541560. Loss: 1.266727. Batch_acc: 0.571753. Batch_loss: 1.206300 \n",
      "Batch: 1529. Acc: 0.541562. Loss: 1.266724. Batch_acc: 0.545242. Batch_loss: 1.261539 \n",
      "Batch: 1530. Acc: 0.541568. Loss: 1.266721. Batch_acc: 0.549915. Batch_loss: 1.262931 \n",
      "Batch: 1531. Acc: 0.541561. Loss: 1.266710. Batch_acc: 0.530106. Batch_loss: 1.249359 \n",
      "Batch: 1532. Acc: 0.541577. Loss: 1.266665. Batch_acc: 0.567552. Batch_loss: 1.197358 \n",
      "Batch: 1533. Acc: 0.541584. Loss: 1.266664. Batch_acc: 0.552005. Batch_loss: 1.264036 \n",
      "Batch: 1534. Acc: 0.541589. Loss: 1.266661. Batch_acc: 0.549438. Batch_loss: 1.263202 \n",
      "Batch: 1535. Acc: 0.541587. Loss: 1.266667. Batch_acc: 0.538462. Batch_loss: 1.275287 \n",
      "Batch: 1536. Acc: 0.541607. Loss: 1.266631. Batch_acc: 0.571512. Batch_loss: 1.210199 \n",
      "Batch: 1537. Acc: 0.541599. Loss: 1.266633. Batch_acc: 0.530460. Batch_loss: 1.270442 \n",
      "Batch: 1538. Acc: 0.541587. Loss: 1.266664. Batch_acc: 0.522170. Batch_loss: 1.315644 \n",
      "Batch: 1539. Acc: 0.541601. Loss: 1.266613. Batch_acc: 0.562077. Batch_loss: 1.188635 \n",
      "Batch: 1540. Acc: 0.541583. Loss: 1.266638. Batch_acc: 0.514823. Batch_loss: 1.305050 \n",
      "Batch: 1541. Acc: 0.541601. Loss: 1.266575. Batch_acc: 0.570191. Batch_loss: 1.168494 \n",
      "Batch: 1542. Acc: 0.541594. Loss: 1.266609. Batch_acc: 0.529343. Batch_loss: 1.320046 \n",
      "Batch: 1543. Acc: 0.541597. Loss: 1.266601. Batch_acc: 0.546380. Batch_loss: 1.255283 \n",
      "Batch: 1544. Acc: 0.541601. Loss: 1.266581. Batch_acc: 0.548165. Batch_loss: 1.235747 \n",
      "Batch: 1545. Acc: 0.541596. Loss: 1.266597. Batch_acc: 0.533141. Batch_loss: 1.291688 \n",
      "Batch: 1546. Acc: 0.541616. Loss: 1.266533. Batch_acc: 0.573198. Batch_loss: 1.168861 \n",
      "Batch: 1547. Acc: 0.541632. Loss: 1.266488. Batch_acc: 0.565242. Batch_loss: 1.197705 \n",
      "Batch: 1548. Acc: 0.541621. Loss: 1.266508. Batch_acc: 0.524702. Batch_loss: 1.296571 \n",
      "Batch: 1549. Acc: 0.541623. Loss: 1.266494. Batch_acc: 0.544879. Batch_loss: 1.246031 \n",
      "Batch: 1550. Acc: 0.541632. Loss: 1.266468. Batch_acc: 0.554986. Batch_loss: 1.226364 \n",
      "Batch: 1551. Acc: 0.541641. Loss: 1.266443. Batch_acc: 0.556193. Batch_loss: 1.227454 \n",
      "Batch: 1552. Acc: 0.541638. Loss: 1.266443. Batch_acc: 0.536249. Batch_loss: 1.265873 \n",
      "Batch: 1553. Acc: 0.541652. Loss: 1.266404. Batch_acc: 0.563800. Batch_loss: 1.208434 \n",
      "Batch: 1554. Acc: 0.541653. Loss: 1.266403. Batch_acc: 0.542314. Batch_loss: 1.264658 \n",
      "Batch: 1555. Acc: 0.541655. Loss: 1.266404. Batch_acc: 0.545771. Batch_loss: 1.267189 \n",
      "Batch: 1556. Acc: 0.541641. Loss: 1.266425. Batch_acc: 0.519420. Batch_loss: 1.300475 \n",
      "Batch: 1557. Acc: 0.541653. Loss: 1.266406. Batch_acc: 0.559745. Batch_loss: 1.236130 \n",
      "Batch: 1558. Acc: 0.541649. Loss: 1.266402. Batch_acc: 0.536290. Batch_loss: 1.259164 \n",
      "Batch: 1559. Acc: 0.541645. Loss: 1.266399. Batch_acc: 0.536000. Batch_loss: 1.262504 \n",
      "Batch: 1560. Acc: 0.541639. Loss: 1.266402. Batch_acc: 0.531359. Batch_loss: 1.270428 \n",
      "Batch: 1561. Acc: 0.541647. Loss: 1.266395. Batch_acc: 0.553348. Batch_loss: 1.255629 \n",
      "Batch: 1562. Acc: 0.541671. Loss: 1.266332. Batch_acc: 0.580440. Batch_loss: 1.167686 \n",
      "Batch: 1563. Acc: 0.541676. Loss: 1.266323. Batch_acc: 0.549199. Batch_loss: 1.251966 \n",
      "Batch: 1564. Acc: 0.541686. Loss: 1.266309. Batch_acc: 0.556571. Batch_loss: 1.245289 \n",
      "Batch: 1565. Acc: 0.541686. Loss: 1.266321. Batch_acc: 0.541840. Batch_loss: 1.285000 \n",
      "Batch: 1566. Acc: 0.541700. Loss: 1.266266. Batch_acc: 0.563574. Batch_loss: 1.181028 \n",
      "Batch: 1567. Acc: 0.541697. Loss: 1.266258. Batch_acc: 0.537967. Batch_loss: 1.253634 \n",
      "Batch: 1568. Acc: 0.541709. Loss: 1.266231. Batch_acc: 0.559882. Batch_loss: 1.222117 \n",
      "Batch: 1569. Acc: 0.541696. Loss: 1.266244. Batch_acc: 0.521816. Batch_loss: 1.287751 \n",
      "Batch: 1570. Acc: 0.541720. Loss: 1.266194. Batch_acc: 0.578947. Batch_loss: 1.187436 \n",
      "Batch: 1571. Acc: 0.541733. Loss: 1.266153. Batch_acc: 0.562011. Batch_loss: 1.203943 \n",
      "Batch: 1572. Acc: 0.541759. Loss: 1.266101. Batch_acc: 0.582038. Batch_loss: 1.183109 \n",
      "Batch: 1573. Acc: 0.541772. Loss: 1.266029. Batch_acc: 0.561191. Batch_loss: 1.158846 \n",
      "Batch: 1574. Acc: 0.541759. Loss: 1.266045. Batch_acc: 0.521664. Batch_loss: 1.290486 \n",
      "Batch: 1575. Acc: 0.541773. Loss: 1.265996. Batch_acc: 0.563501. Batch_loss: 1.189125 \n",
      "Batch: 1576. Acc: 0.541781. Loss: 1.265988. Batch_acc: 0.555035. Batch_loss: 1.252934 \n",
      "Batch: 1577. Acc: 0.541805. Loss: 1.265928. Batch_acc: 0.578978. Batch_loss: 1.171963 \n",
      "Batch: 1578. Acc: 0.541813. Loss: 1.265901. Batch_acc: 0.554169. Batch_loss: 1.223219 \n",
      "Batch: 1579. Acc: 0.541814. Loss: 1.265888. Batch_acc: 0.544041. Batch_loss: 1.246382 \n",
      "Batch: 1580. Acc: 0.541832. Loss: 1.265853. Batch_acc: 0.570205. Batch_loss: 1.210781 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1581. Acc: 0.541836. Loss: 1.265848. Batch_acc: 0.548636. Batch_loss: 1.257321 \n",
      "Batch: 1582. Acc: 0.541845. Loss: 1.265809. Batch_acc: 0.555620. Batch_loss: 1.203900 \n",
      "Batch: 1583. Acc: 0.541863. Loss: 1.265778. Batch_acc: 0.569092. Batch_loss: 1.217710 \n",
      "Batch: 1584. Acc: 0.541859. Loss: 1.265771. Batch_acc: 0.535882. Batch_loss: 1.255428 \n",
      "Batch: 1585. Acc: 0.541860. Loss: 1.265765. Batch_acc: 0.542808. Batch_loss: 1.256004 \n",
      "Batch: 1586. Acc: 0.541857. Loss: 1.265752. Batch_acc: 0.537935. Batch_loss: 1.245342 \n",
      "Batch: 1587. Acc: 0.541858. Loss: 1.265741. Batch_acc: 0.543491. Batch_loss: 1.248163 \n",
      "Batch: 1588. Acc: 0.541852. Loss: 1.265761. Batch_acc: 0.532258. Batch_loss: 1.298204 \n",
      "Batch: 1589. Acc: 0.541841. Loss: 1.265786. Batch_acc: 0.524419. Batch_loss: 1.305852 \n",
      "Batch: 1590. Acc: 0.541839. Loss: 1.265769. Batch_acc: 0.537752. Batch_loss: 1.239922 \n",
      "Batch: 1591. Acc: 0.541833. Loss: 1.265798. Batch_acc: 0.531668. Batch_loss: 1.311467 \n",
      "Batch: 1592. Acc: 0.541846. Loss: 1.265761. Batch_acc: 0.563244. Batch_loss: 1.208192 \n",
      "Batch: 1593. Acc: 0.541853. Loss: 1.265749. Batch_acc: 0.553910. Batch_loss: 1.245965 \n",
      "Batch: 1594. Acc: 0.541856. Loss: 1.265742. Batch_acc: 0.545767. Batch_loss: 1.255064 \n",
      "Batch: 1595. Acc: 0.541855. Loss: 1.265732. Batch_acc: 0.539610. Batch_loss: 1.249293 \n",
      "Batch: 1596. Acc: 0.541850. Loss: 1.265744. Batch_acc: 0.534951. Batch_loss: 1.285432 \n",
      "Batch: 1597. Acc: 0.541851. Loss: 1.265730. Batch_acc: 0.543210. Batch_loss: 1.243864 \n",
      "Batch: 1598. Acc: 0.541848. Loss: 1.265725. Batch_acc: 0.537358. Batch_loss: 1.257161 \n",
      "Batch: 1599. Acc: 0.541848. Loss: 1.265718. Batch_acc: 0.541353. Batch_loss: 1.253562 \n",
      "Batch: 1600. Acc: 0.541843. Loss: 1.265740. Batch_acc: 0.534302. Batch_loss: 1.301276 \n",
      "Batch: 1601. Acc: 0.541836. Loss: 1.265772. Batch_acc: 0.529172. Batch_loss: 1.317777 \n",
      "Batch: 1602. Acc: 0.541826. Loss: 1.265800. Batch_acc: 0.525060. Batch_loss: 1.312279 \n",
      "Batch: 1603. Acc: 0.541836. Loss: 1.265781. Batch_acc: 0.558020. Batch_loss: 1.236173 \n",
      "Batch: 1604. Acc: 0.541838. Loss: 1.265780. Batch_acc: 0.545191. Batch_loss: 1.264225 \n",
      "Batch: 1605. Acc: 0.541832. Loss: 1.265811. Batch_acc: 0.532860. Batch_loss: 1.316258 \n",
      "Batch: 1606. Acc: 0.541825. Loss: 1.265827. Batch_acc: 0.530320. Batch_loss: 1.291641 \n",
      "Batch: 1607. Acc: 0.541811. Loss: 1.265858. Batch_acc: 0.519608. Batch_loss: 1.315745 \n",
      "Batch: 1608. Acc: 0.541809. Loss: 1.265833. Batch_acc: 0.538805. Batch_loss: 1.228133 \n",
      "Batch: 1609. Acc: 0.541817. Loss: 1.265835. Batch_acc: 0.554386. Batch_loss: 1.267588 \n",
      "Batch: 1610. Acc: 0.541823. Loss: 1.265840. Batch_acc: 0.551845. Batch_loss: 1.274957 \n",
      "Batch: 1611. Acc: 0.541818. Loss: 1.265870. Batch_acc: 0.532672. Batch_loss: 1.315432 \n",
      "Batch: 1612. Acc: 0.541821. Loss: 1.265880. Batch_acc: 0.546559. Batch_loss: 1.280708 \n",
      "Batch: 1613. Acc: 0.541805. Loss: 1.265923. Batch_acc: 0.515716. Batch_loss: 1.336358 \n",
      "Batch: 1614. Acc: 0.541808. Loss: 1.265910. Batch_acc: 0.547170. Batch_loss: 1.245206 \n",
      "Batch: 1615. Acc: 0.541811. Loss: 1.265892. Batch_acc: 0.546884. Batch_loss: 1.236507 \n",
      "Batch: 1616. Acc: 0.541813. Loss: 1.265891. Batch_acc: 0.544980. Batch_loss: 1.264175 \n",
      "Batch: 1617. Acc: 0.541810. Loss: 1.265897. Batch_acc: 0.537037. Batch_loss: 1.276291 \n",
      "Batch: 1618. Acc: 0.541803. Loss: 1.265913. Batch_acc: 0.529977. Batch_loss: 1.290227 \n",
      "Batch: 1619. Acc: 0.541819. Loss: 1.265868. Batch_acc: 0.568729. Batch_loss: 1.194898 \n",
      "Batch: 1620. Acc: 0.541832. Loss: 1.265840. Batch_acc: 0.562069. Batch_loss: 1.220016 \n",
      "Batch: 1621. Acc: 0.541833. Loss: 1.265822. Batch_acc: 0.544543. Batch_loss: 1.236102 \n",
      "Batch: 1622. Acc: 0.541836. Loss: 1.265821. Batch_acc: 0.545351. Batch_loss: 1.263765 \n",
      "Batch: 1623. Acc: 0.541858. Loss: 1.265771. Batch_acc: 0.577740. Batch_loss: 1.187286 \n",
      "Batch: 1624. Acc: 0.541866. Loss: 1.265749. Batch_acc: 0.553660. Batch_loss: 1.231912 \n",
      "Batch: 1625. Acc: 0.541860. Loss: 1.265741. Batch_acc: 0.531646. Batch_loss: 1.252197 \n",
      "Batch: 1626. Acc: 0.541865. Loss: 1.265738. Batch_acc: 0.549550. Batch_loss: 1.261078 \n",
      "Batch: 1627. Acc: 0.541875. Loss: 1.265695. Batch_acc: 0.558074. Batch_loss: 1.196224 \n",
      "Batch: 1628. Acc: 0.541878. Loss: 1.265687. Batch_acc: 0.546838. Batch_loss: 1.253017 \n",
      "Batch: 1629. Acc: 0.541872. Loss: 1.265692. Batch_acc: 0.533218. Batch_loss: 1.273166 \n",
      "Batch: 1630. Acc: 0.541871. Loss: 1.265696. Batch_acc: 0.539365. Batch_loss: 1.273187 \n",
      "Batch: 1631. Acc: 0.541871. Loss: 1.265698. Batch_acc: 0.541932. Batch_loss: 1.268015 \n",
      "Batch: 1632. Acc: 0.541867. Loss: 1.265731. Batch_acc: 0.535196. Batch_loss: 1.317829 \n",
      "Batch: 1633. Acc: 0.541861. Loss: 1.265742. Batch_acc: 0.532011. Batch_loss: 1.284618 \n",
      "Batch: 1634. Acc: 0.541872. Loss: 1.265716. Batch_acc: 0.560296. Batch_loss: 1.223826 \n",
      "Batch: 1635. Acc: 0.541873. Loss: 1.265729. Batch_acc: 0.543363. Batch_loss: 1.286613 \n",
      "Batch: 1636. Acc: 0.541859. Loss: 1.265747. Batch_acc: 0.518107. Batch_loss: 1.296306 \n",
      "Batch: 1637. Acc: 0.541852. Loss: 1.265742. Batch_acc: 0.531103. Batch_loss: 1.257689 \n",
      "Batch: 1638. Acc: 0.541860. Loss: 1.265729. Batch_acc: 0.555620. Batch_loss: 1.243059 \n",
      "Batch: 1639. Acc: 0.541868. Loss: 1.265706. Batch_acc: 0.553757. Batch_loss: 1.228127 \n",
      "Batch: 1640. Acc: 0.541865. Loss: 1.265714. Batch_acc: 0.537853. Batch_loss: 1.278830 \n",
      "Batch: 1641. Acc: 0.541865. Loss: 1.265706. Batch_acc: 0.540984. Batch_loss: 1.252136 \n",
      "Batch: 1642. Acc: 0.541871. Loss: 1.265698. Batch_acc: 0.552137. Batch_loss: 1.253333 \n",
      "Batch: 1643. Acc: 0.541874. Loss: 1.265699. Batch_acc: 0.546911. Batch_loss: 1.267062 \n",
      "Batch: 1644. Acc: 0.541869. Loss: 1.265700. Batch_acc: 0.532941. Batch_loss: 1.266570 \n",
      "Batch: 1645. Acc: 0.541867. Loss: 1.265724. Batch_acc: 0.538190. Batch_loss: 1.305978 \n",
      "Batch: 1646. Acc: 0.541869. Loss: 1.265721. Batch_acc: 0.546721. Batch_loss: 1.261400 \n",
      "Batch: 1647. Acc: 0.541880. Loss: 1.265686. Batch_acc: 0.559332. Batch_loss: 1.207901 \n",
      "Batch: 1648. Acc: 0.541882. Loss: 1.265679. Batch_acc: 0.544406. Batch_loss: 1.253546 \n",
      "Batch: 1649. Acc: 0.541890. Loss: 1.265644. Batch_acc: 0.555742. Batch_loss: 1.210207 \n",
      "Batch: 1650. Acc: 0.541890. Loss: 1.265656. Batch_acc: 0.540927. Batch_loss: 1.285255 \n",
      "Batch: 1651. Acc: 0.541908. Loss: 1.265610. Batch_acc: 0.571916. Batch_loss: 1.190442 \n",
      "Batch: 1652. Acc: 0.541907. Loss: 1.265630. Batch_acc: 0.540323. Batch_loss: 1.299004 \n",
      "Batch: 1653. Acc: 0.541903. Loss: 1.265633. Batch_acc: 0.534392. Batch_loss: 1.270597 \n",
      "Batch: 1654. Acc: 0.541902. Loss: 1.265627. Batch_acc: 0.540917. Batch_loss: 1.255955 \n",
      "Batch: 1655. Acc: 0.541907. Loss: 1.265623. Batch_acc: 0.550614. Batch_loss: 1.258520 \n",
      "Batch: 1656. Acc: 0.541898. Loss: 1.265652. Batch_acc: 0.527263. Batch_loss: 1.313098 \n",
      "Batch: 1657. Acc: 0.541907. Loss: 1.265637. Batch_acc: 0.557168. Batch_loss: 1.240165 \n",
      "Batch: 1658. Acc: 0.541907. Loss: 1.265640. Batch_acc: 0.541116. Batch_loss: 1.270536 \n",
      "Batch: 1659. Acc: 0.541912. Loss: 1.265639. Batch_acc: 0.551217. Batch_loss: 1.263729 \n",
      "Batch: 1660. Acc: 0.541918. Loss: 1.265636. Batch_acc: 0.551603. Batch_loss: 1.260394 \n",
      "Batch: 1661. Acc: 0.541913. Loss: 1.265632. Batch_acc: 0.533908. Batch_loss: 1.259571 \n",
      "Batch: 1662. Acc: 0.541919. Loss: 1.265623. Batch_acc: 0.550767. Batch_loss: 1.249479 \n",
      "Batch: 1663. Acc: 0.541923. Loss: 1.265640. Batch_acc: 0.549701. Batch_loss: 1.295457 \n",
      "Batch: 1664. Acc: 0.541934. Loss: 1.265606. Batch_acc: 0.559792. Batch_loss: 1.208200 \n",
      "Batch: 1665. Acc: 0.541927. Loss: 1.265626. Batch_acc: 0.530400. Batch_loss: 1.299302 \n",
      "Batch: 1666. Acc: 0.541918. Loss: 1.265638. Batch_acc: 0.526832. Batch_loss: 1.285402 \n",
      "Batch: 1667. Acc: 0.541919. Loss: 1.265631. Batch_acc: 0.543224. Batch_loss: 1.254508 \n",
      "Batch: 1668. Acc: 0.541911. Loss: 1.265655. Batch_acc: 0.529412. Batch_loss: 1.305447 \n",
      "Batch: 1669. Acc: 0.541912. Loss: 1.265649. Batch_acc: 0.542693. Batch_loss: 1.255954 \n",
      "Batch: 1670. Acc: 0.541917. Loss: 1.265631. Batch_acc: 0.551567. Batch_loss: 1.236392 \n",
      "Batch: 1671. Acc: 0.541931. Loss: 1.265591. Batch_acc: 0.564516. Batch_loss: 1.198391 \n",
      "Batch: 1672. Acc: 0.541930. Loss: 1.265586. Batch_acc: 0.541203. Batch_loss: 1.258002 \n",
      "Batch: 1673. Acc: 0.541932. Loss: 1.265590. Batch_acc: 0.544720. Batch_loss: 1.272090 \n",
      "Batch: 1674. Acc: 0.541938. Loss: 1.265577. Batch_acc: 0.550974. Batch_loss: 1.243713 \n",
      "Batch: 1675. Acc: 0.541947. Loss: 1.265565. Batch_acc: 0.558419. Batch_loss: 1.245565 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1676. Acc: 0.541968. Loss: 1.265531. Batch_acc: 0.577987. Batch_loss: 1.207687 \n",
      "Batch: 1677. Acc: 0.541972. Loss: 1.265528. Batch_acc: 0.548313. Batch_loss: 1.260603 \n",
      "Batch: 1678. Acc: 0.541975. Loss: 1.265522. Batch_acc: 0.546999. Batch_loss: 1.255083 \n",
      "Batch: 1679. Acc: 0.541985. Loss: 1.265491. Batch_acc: 0.558523. Batch_loss: 1.213297 \n",
      "Batch: 1680. Acc: 0.541986. Loss: 1.265474. Batch_acc: 0.542412. Batch_loss: 1.238259 \n",
      "Batch: 1681. Acc: 0.541985. Loss: 1.265460. Batch_acc: 0.541691. Batch_loss: 1.240645 \n",
      "Batch: 1682. Acc: 0.541998. Loss: 1.265420. Batch_acc: 0.563073. Batch_loss: 1.199109 \n",
      "Batch: 1683. Acc: 0.542001. Loss: 1.265427. Batch_acc: 0.546492. Batch_loss: 1.277076 \n",
      "Batch: 1684. Acc: 0.542001. Loss: 1.265414. Batch_acc: 0.543253. Batch_loss: 1.243283 \n",
      "Batch: 1685. Acc: 0.542010. Loss: 1.265388. Batch_acc: 0.556261. Batch_loss: 1.221570 \n",
      "Batch: 1686. Acc: 0.542021. Loss: 1.265367. Batch_acc: 0.560562. Batch_loss: 1.229134 \n",
      "Batch: 1687. Acc: 0.542040. Loss: 1.265330. Batch_acc: 0.574686. Batch_loss: 1.202906 \n",
      "Batch: 1688. Acc: 0.542039. Loss: 1.265323. Batch_acc: 0.539720. Batch_loss: 1.253837 \n",
      "Batch: 1689. Acc: 0.542043. Loss: 1.265314. Batch_acc: 0.549240. Batch_loss: 1.249728 \n",
      "Batch: 1690. Acc: 0.542051. Loss: 1.265294. Batch_acc: 0.554556. Batch_loss: 1.233019 \n",
      "Batch: 1691. Acc: 0.542057. Loss: 1.265268. Batch_acc: 0.553179. Batch_loss: 1.220855 \n",
      "Batch: 1692. Acc: 0.542054. Loss: 1.265273. Batch_acc: 0.536332. Batch_loss: 1.273005 \n",
      "Batch: 1693. Acc: 0.542058. Loss: 1.265282. Batch_acc: 0.549425. Batch_loss: 1.281769 \n",
      "Batch: 1694. Acc: 0.542049. Loss: 1.265294. Batch_acc: 0.526740. Batch_loss: 1.284895 \n",
      "Batch: 1695. Acc: 0.542052. Loss: 1.265293. Batch_acc: 0.547052. Batch_loss: 1.263838 \n",
      "Batch: 1696. Acc: 0.542058. Loss: 1.265282. Batch_acc: 0.551804. Batch_loss: 1.247248 \n",
      "Batch: 1697. Acc: 0.542061. Loss: 1.265264. Batch_acc: 0.547392. Batch_loss: 1.235193 \n",
      "Batch: 1698. Acc: 0.542064. Loss: 1.265268. Batch_acc: 0.547181. Batch_loss: 1.271319 \n",
      "Batch: 1699. Acc: 0.542072. Loss: 1.265237. Batch_acc: 0.555180. Batch_loss: 1.214155 \n",
      "Batch: 1700. Acc: 0.542083. Loss: 1.265197. Batch_acc: 0.560903. Batch_loss: 1.194373 \n",
      "Batch: 1701. Acc: 0.542085. Loss: 1.265192. Batch_acc: 0.545980. Batch_loss: 1.256954 \n",
      "Batch: 1702. Acc: 0.542082. Loss: 1.265192. Batch_acc: 0.536198. Batch_loss: 1.265042 \n",
      "Batch: 1703. Acc: 0.542079. Loss: 1.265207. Batch_acc: 0.538022. Batch_loss: 1.290126 \n",
      "Batch: 1704. Acc: 0.542077. Loss: 1.265208. Batch_acc: 0.537703. Batch_loss: 1.268231 \n",
      "Batch: 1705. Acc: 0.542089. Loss: 1.265172. Batch_acc: 0.562851. Batch_loss: 1.204895 \n",
      "Batch: 1706. Acc: 0.542102. Loss: 1.265129. Batch_acc: 0.563700. Batch_loss: 1.190183 \n",
      "Batch: 1707. Acc: 0.542106. Loss: 1.265113. Batch_acc: 0.548643. Batch_loss: 1.239469 \n",
      "Batch: 1708. Acc: 0.542108. Loss: 1.265108. Batch_acc: 0.545660. Batch_loss: 1.255801 \n",
      "Batch: 1709. Acc: 0.542119. Loss: 1.265069. Batch_acc: 0.560452. Batch_loss: 1.199979 \n",
      "Batch: 1710. Acc: 0.542118. Loss: 1.265054. Batch_acc: 0.540925. Batch_loss: 1.237588 \n",
      "Batch: 1711. Acc: 0.542136. Loss: 1.265013. Batch_acc: 0.571829. Batch_loss: 1.196765 \n",
      "Batch: 1712. Acc: 0.542145. Loss: 1.264990. Batch_acc: 0.558669. Batch_loss: 1.225196 \n",
      "Batch: 1713. Acc: 0.542144. Loss: 1.265000. Batch_acc: 0.539503. Batch_loss: 1.282451 \n",
      "Batch: 1714. Acc: 0.542146. Loss: 1.264983. Batch_acc: 0.546598. Batch_loss: 1.236607 \n",
      "Batch: 1715. Acc: 0.542143. Loss: 1.264983. Batch_acc: 0.536215. Batch_loss: 1.264754 \n",
      "Batch: 1716. Acc: 0.542154. Loss: 1.264959. Batch_acc: 0.560484. Batch_loss: 1.222337 \n",
      "Batch: 1717. Acc: 0.542151. Loss: 1.264957. Batch_acc: 0.538106. Batch_loss: 1.261653 \n",
      "Batch: 1718. Acc: 0.542147. Loss: 1.264976. Batch_acc: 0.534762. Batch_loss: 1.299226 \n",
      "Batch: 1719. Acc: 0.542157. Loss: 1.264939. Batch_acc: 0.560091. Batch_loss: 1.201486 \n",
      "Batch: 1720. Acc: 0.542163. Loss: 1.264913. Batch_acc: 0.551412. Batch_loss: 1.221227 \n",
      "Batch: 1721. Acc: 0.542180. Loss: 1.264888. Batch_acc: 0.571510. Batch_loss: 1.222363 \n",
      "Batch: 1722. Acc: 0.542197. Loss: 1.264855. Batch_acc: 0.571348. Batch_loss: 1.209315 \n",
      "Batch: 1723. Acc: 0.542203. Loss: 1.264833. Batch_acc: 0.552392. Batch_loss: 1.226251 \n",
      "Batch: 1724. Acc: 0.542203. Loss: 1.264830. Batch_acc: 0.540946. Batch_loss: 1.261037 \n",
      "Batch: 1725. Acc: 0.542194. Loss: 1.264862. Batch_acc: 0.526678. Batch_loss: 1.318520 \n",
      "Batch: 1726. Acc: 0.542211. Loss: 1.264822. Batch_acc: 0.573373. Batch_loss: 1.194253 \n",
      "Batch: 1727. Acc: 0.542209. Loss: 1.264825. Batch_acc: 0.538684. Batch_loss: 1.269760 \n",
      "Batch: 1728. Acc: 0.542223. Loss: 1.264790. Batch_acc: 0.566897. Batch_loss: 1.204801 \n",
      "Batch: 1729. Acc: 0.542223. Loss: 1.264783. Batch_acc: 0.541023. Batch_loss: 1.252605 \n",
      "Batch: 1730. Acc: 0.542228. Loss: 1.264776. Batch_acc: 0.551282. Batch_loss: 1.253034 \n",
      "Batch: 1731. Acc: 0.542228. Loss: 1.264773. Batch_acc: 0.542690. Batch_loss: 1.259574 \n",
      "Batch: 1732. Acc: 0.542231. Loss: 1.264765. Batch_acc: 0.546433. Batch_loss: 1.250921 \n",
      "Batch: 1733. Acc: 0.542222. Loss: 1.264782. Batch_acc: 0.527114. Batch_loss: 1.295168 \n",
      "Batch: 1734. Acc: 0.542214. Loss: 1.264809. Batch_acc: 0.527491. Batch_loss: 1.311275 \n",
      "Batch: 1735. Acc: 0.542214. Loss: 1.264797. Batch_acc: 0.543353. Batch_loss: 1.244059 \n",
      "Batch: 1736. Acc: 0.542203. Loss: 1.264824. Batch_acc: 0.522050. Batch_loss: 1.313331 \n",
      "Batch: 1737. Acc: 0.542205. Loss: 1.264803. Batch_acc: 0.546083. Batch_loss: 1.227718 \n",
      "Batch: 1738. Acc: 0.542209. Loss: 1.264779. Batch_acc: 0.548974. Batch_loss: 1.222525 \n",
      "Batch: 1739. Acc: 0.542223. Loss: 1.264746. Batch_acc: 0.564946. Batch_loss: 1.208404 \n",
      "Batch: 1740. Acc: 0.542227. Loss: 1.264728. Batch_acc: 0.550396. Batch_loss: 1.232733 \n",
      "Batch: 1741. Acc: 0.542231. Loss: 1.264707. Batch_acc: 0.549199. Batch_loss: 1.229669 \n",
      "Batch: 1742. Acc: 0.542233. Loss: 1.264700. Batch_acc: 0.544977. Batch_loss: 1.252134 \n",
      "Batch: 1743. Acc: 0.542235. Loss: 1.264695. Batch_acc: 0.545558. Batch_loss: 1.255831 \n",
      "Batch: 1744. Acc: 0.542225. Loss: 1.264724. Batch_acc: 0.524897. Batch_loss: 1.315594 \n",
      "Batch: 1745. Acc: 0.542220. Loss: 1.264746. Batch_acc: 0.533937. Batch_loss: 1.302401 \n",
      "Batch: 1746. Acc: 0.542228. Loss: 1.264720. Batch_acc: 0.556395. Batch_loss: 1.219690 \n",
      "Batch: 1747. Acc: 0.542235. Loss: 1.264712. Batch_acc: 0.553927. Batch_loss: 1.250467 \n",
      "Batch: 1748. Acc: 0.542253. Loss: 1.264671. Batch_acc: 0.573770. Batch_loss: 1.191292 \n",
      "Batch: 1749. Acc: 0.542248. Loss: 1.264678. Batch_acc: 0.534602. Batch_loss: 1.276925 \n",
      "Batch: 1750. Acc: 0.542259. Loss: 1.264658. Batch_acc: 0.560721. Batch_loss: 1.229372 \n",
      "Batch: 1751. Acc: 0.542274. Loss: 1.264619. Batch_acc: 0.567915. Batch_loss: 1.197659 \n",
      "Batch: 1752. Acc: 0.542287. Loss: 1.264580. Batch_acc: 0.564692. Batch_loss: 1.197303 \n",
      "Batch: 1753. Acc: 0.542296. Loss: 1.264572. Batch_acc: 0.559096. Batch_loss: 1.250050 \n",
      "Batch: 1754. Acc: 0.542311. Loss: 1.264530. Batch_acc: 0.569525. Batch_loss: 1.190377 \n",
      "Batch: 1755. Acc: 0.542322. Loss: 1.264506. Batch_acc: 0.560990. Batch_loss: 1.221506 \n",
      "Batch: 1756. Acc: 0.542323. Loss: 1.264499. Batch_acc: 0.544664. Batch_loss: 1.252142 \n",
      "Batch: 1757. Acc: 0.542334. Loss: 1.264470. Batch_acc: 0.560198. Batch_loss: 1.215748 \n",
      "Checkpointing on batch: 1757. Accuracy: 0.5423340234739433. Loss per char: 1.2644695478504495. Time: 1627223248.0784733\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 21, 17, 17, 24, 20, 23,  1, 77, 70,\n",
      "        84, 84,  1, 85, 73, 66, 79,  1, 17, 15, 17, 21, 17, 25, 25, 26, 19, 20,\n",
      "        22, 24, 32,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1758. Acc: 0.542348. Loss: 1.264433. Batch_acc: 0.567138. Batch_loss: 1.198601 \n",
      "Batch: 1759. Acc: 0.542343. Loss: 1.264439. Batch_acc: 0.533255. Batch_loss: 1.274910 \n",
      "Batch: 1760. Acc: 0.542345. Loss: 1.264425. Batch_acc: 0.546041. Batch_loss: 1.239828 \n",
      "Batch: 1761. Acc: 0.542357. Loss: 1.264392. Batch_acc: 0.563709. Batch_loss: 1.206712 \n",
      "Batch: 1762. Acc: 0.542352. Loss: 1.264399. Batch_acc: 0.533030. Batch_loss: 1.276894 \n",
      "Batch: 1763. Acc: 0.542352. Loss: 1.264390. Batch_acc: 0.542609. Batch_loss: 1.248429 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1764. Acc: 0.542344. Loss: 1.264391. Batch_acc: 0.528173. Batch_loss: 1.266388 \n",
      "Batch: 1765. Acc: 0.542352. Loss: 1.264367. Batch_acc: 0.557405. Batch_loss: 1.221536 \n",
      "Batch: 1766. Acc: 0.542350. Loss: 1.264361. Batch_acc: 0.538995. Batch_loss: 1.253705 \n",
      "Batch: 1767. Acc: 0.542366. Loss: 1.264328. Batch_acc: 0.569092. Batch_loss: 1.206389 \n",
      "Batch: 1768. Acc: 0.542365. Loss: 1.264325. Batch_acc: 0.540284. Batch_loss: 1.260404 \n",
      "Batch: 1769. Acc: 0.542372. Loss: 1.264315. Batch_acc: 0.554903. Batch_loss: 1.244903 \n",
      "Batch: 1770. Acc: 0.542371. Loss: 1.264306. Batch_acc: 0.540694. Batch_loss: 1.248621 \n",
      "Batch: 1771. Acc: 0.542376. Loss: 1.264283. Batch_acc: 0.552299. Batch_loss: 1.225059 \n",
      "Batch: 1772. Acc: 0.542385. Loss: 1.264263. Batch_acc: 0.557771. Batch_loss: 1.228058 \n",
      "Batch: 1773. Acc: 0.542392. Loss: 1.264253. Batch_acc: 0.555556. Batch_loss: 1.244322 \n",
      "Batch: 1774. Acc: 0.542394. Loss: 1.264255. Batch_acc: 0.546248. Batch_loss: 1.268519 \n",
      "Batch: 1775. Acc: 0.542390. Loss: 1.264253. Batch_acc: 0.535714. Batch_loss: 1.260159 \n",
      "Batch: 1776. Acc: 0.542388. Loss: 1.264255. Batch_acc: 0.538872. Batch_loss: 1.268791 \n",
      "Batch: 1777. Acc: 0.542383. Loss: 1.264258. Batch_acc: 0.532362. Batch_loss: 1.269263 \n",
      "Batch: 1778. Acc: 0.542368. Loss: 1.264285. Batch_acc: 0.516167. Batch_loss: 1.314013 \n",
      "Batch: 1779. Acc: 0.542373. Loss: 1.264274. Batch_acc: 0.550818. Batch_loss: 1.244175 \n",
      "Batch: 1780. Acc: 0.542373. Loss: 1.264280. Batch_acc: 0.542891. Batch_loss: 1.275029 \n",
      "Batch: 1781. Acc: 0.542365. Loss: 1.264313. Batch_acc: 0.526919. Batch_loss: 1.322687 \n",
      "Batch: 1782. Acc: 0.542367. Loss: 1.264313. Batch_acc: 0.546485. Batch_loss: 1.265055 \n",
      "Batch: 1783. Acc: 0.542382. Loss: 1.264278. Batch_acc: 0.568027. Batch_loss: 1.201604 \n",
      "Batch: 1784. Acc: 0.542380. Loss: 1.264281. Batch_acc: 0.539121. Batch_loss: 1.270413 \n",
      "Batch: 1785. Acc: 0.542383. Loss: 1.264283. Batch_acc: 0.548558. Batch_loss: 1.267845 \n",
      "Batch: 1786. Acc: 0.542380. Loss: 1.264274. Batch_acc: 0.537166. Batch_loss: 1.248668 \n",
      "Batch: 1787. Acc: 0.542383. Loss: 1.264274. Batch_acc: 0.547496. Batch_loss: 1.263859 \n",
      "Batch: 1788. Acc: 0.542391. Loss: 1.264256. Batch_acc: 0.556695. Batch_loss: 1.231500 \n",
      "Batch: 1789. Acc: 0.542390. Loss: 1.264260. Batch_acc: 0.539581. Batch_loss: 1.272564 \n",
      "Batch: 1790. Acc: 0.542390. Loss: 1.264258. Batch_acc: 0.542971. Batch_loss: 1.260117 \n",
      "Batch: 1791. Acc: 0.542402. Loss: 1.264225. Batch_acc: 0.563731. Batch_loss: 1.205361 \n",
      "Batch: 1792. Acc: 0.542400. Loss: 1.264206. Batch_acc: 0.538908. Batch_loss: 1.229201 \n",
      "Batch: 1793. Acc: 0.542395. Loss: 1.264231. Batch_acc: 0.534422. Batch_loss: 1.309887 \n",
      "Batch: 1794. Acc: 0.542394. Loss: 1.264233. Batch_acc: 0.540323. Batch_loss: 1.267349 \n",
      "Batch: 1795. Acc: 0.542402. Loss: 1.264217. Batch_acc: 0.556080. Batch_loss: 1.234640 \n",
      "Batch: 1796. Acc: 0.542411. Loss: 1.264175. Batch_acc: 0.559037. Batch_loss: 1.190710 \n",
      "Batch: 1797. Acc: 0.542405. Loss: 1.264196. Batch_acc: 0.530800. Batch_loss: 1.303254 \n",
      "Batch: 1798. Acc: 0.542399. Loss: 1.264205. Batch_acc: 0.532571. Batch_loss: 1.279242 \n",
      "Batch: 1799. Acc: 0.542399. Loss: 1.264194. Batch_acc: 0.541785. Batch_loss: 1.245054 \n",
      "Batch: 1800. Acc: 0.542390. Loss: 1.264218. Batch_acc: 0.525913. Batch_loss: 1.308962 \n",
      "Batch: 1801. Acc: 0.542388. Loss: 1.264228. Batch_acc: 0.538328. Batch_loss: 1.281475 \n",
      "Batch: 1802. Acc: 0.542379. Loss: 1.264236. Batch_acc: 0.526316. Batch_loss: 1.279028 \n",
      "Batch: 1803. Acc: 0.542380. Loss: 1.264225. Batch_acc: 0.544807. Batch_loss: 1.243805 \n",
      "Batch: 1804. Acc: 0.542388. Loss: 1.264205. Batch_acc: 0.557888. Batch_loss: 1.225620 \n",
      "Batch: 1805. Acc: 0.542389. Loss: 1.264196. Batch_acc: 0.544554. Batch_loss: 1.247929 \n",
      "Batch: 1806. Acc: 0.542393. Loss: 1.264183. Batch_acc: 0.548627. Batch_loss: 1.241204 \n",
      "Batch: 1807. Acc: 0.542391. Loss: 1.264189. Batch_acc: 0.538284. Batch_loss: 1.275871 \n",
      "Batch: 1808. Acc: 0.542399. Loss: 1.264150. Batch_acc: 0.557070. Batch_loss: 1.193910 \n",
      "Batch: 1809. Acc: 0.542398. Loss: 1.264136. Batch_acc: 0.540163. Batch_loss: 1.238061 \n",
      "Batch: 1810. Acc: 0.542393. Loss: 1.264136. Batch_acc: 0.533604. Batch_loss: 1.265154 \n",
      "Batch: 1811. Acc: 0.542396. Loss: 1.264107. Batch_acc: 0.548555. Batch_loss: 1.209921 \n",
      "Batch: 1812. Acc: 0.542389. Loss: 1.264124. Batch_acc: 0.528432. Batch_loss: 1.295298 \n",
      "Batch: 1813. Acc: 0.542396. Loss: 1.264103. Batch_acc: 0.556772. Batch_loss: 1.226224 \n",
      "Batch: 1814. Acc: 0.542407. Loss: 1.264071. Batch_acc: 0.560905. Batch_loss: 1.206392 \n",
      "Batch: 1815. Acc: 0.542420. Loss: 1.264037. Batch_acc: 0.566422. Batch_loss: 1.203273 \n",
      "Batch: 1816. Acc: 0.542423. Loss: 1.264013. Batch_acc: 0.548055. Batch_loss: 1.219614 \n",
      "Batch: 1817. Acc: 0.542422. Loss: 1.264025. Batch_acc: 0.540780. Batch_loss: 1.287324 \n",
      "Batch: 1818. Acc: 0.542426. Loss: 1.264009. Batch_acc: 0.549971. Batch_loss: 1.234023 \n",
      "Batch: 1819. Acc: 0.542418. Loss: 1.264015. Batch_acc: 0.526437. Batch_loss: 1.275497 \n",
      "Batch: 1820. Acc: 0.542421. Loss: 1.264004. Batch_acc: 0.548463. Batch_loss: 1.243602 \n",
      "Batch: 1821. Acc: 0.542432. Loss: 1.263979. Batch_acc: 0.562921. Batch_loss: 1.218312 \n",
      "Batch: 1822. Acc: 0.542436. Loss: 1.263964. Batch_acc: 0.549708. Batch_loss: 1.237037 \n",
      "Batch: 1823. Acc: 0.542453. Loss: 1.263914. Batch_acc: 0.572899. Batch_loss: 1.173464 \n",
      "Batch: 1824. Acc: 0.542453. Loss: 1.263909. Batch_acc: 0.542461. Batch_loss: 1.254844 \n",
      "Batch: 1825. Acc: 0.542465. Loss: 1.263875. Batch_acc: 0.564407. Batch_loss: 1.202898 \n",
      "Batch: 1826. Acc: 0.542476. Loss: 1.263854. Batch_acc: 0.560784. Batch_loss: 1.226836 \n",
      "Batch: 1827. Acc: 0.542488. Loss: 1.263816. Batch_acc: 0.565017. Batch_loss: 1.194144 \n",
      "Batch: 1828. Acc: 0.542496. Loss: 1.263781. Batch_acc: 0.557812. Batch_loss: 1.201644 \n",
      "Batch: 1829. Acc: 0.542508. Loss: 1.263761. Batch_acc: 0.563923. Batch_loss: 1.225467 \n",
      "Batch: 1830. Acc: 0.542502. Loss: 1.263795. Batch_acc: 0.531501. Batch_loss: 1.325454 \n",
      "Batch: 1831. Acc: 0.542519. Loss: 1.263748. Batch_acc: 0.572630. Batch_loss: 1.180422 \n",
      "Batch: 1832. Acc: 0.542525. Loss: 1.263742. Batch_acc: 0.553082. Batch_loss: 1.253098 \n",
      "Batch: 1833. Acc: 0.542540. Loss: 1.263703. Batch_acc: 0.569101. Batch_loss: 1.194276 \n",
      "Batch: 1834. Acc: 0.542538. Loss: 1.263701. Batch_acc: 0.538783. Batch_loss: 1.260010 \n",
      "Batch: 1835. Acc: 0.542544. Loss: 1.263693. Batch_acc: 0.555104. Batch_loss: 1.248675 \n",
      "Batch: 1836. Acc: 0.542540. Loss: 1.263713. Batch_acc: 0.535447. Batch_loss: 1.299942 \n",
      "Batch: 1837. Acc: 0.542542. Loss: 1.263706. Batch_acc: 0.545714. Batch_loss: 1.250820 \n",
      "Batch: 1838. Acc: 0.542539. Loss: 1.263728. Batch_acc: 0.536316. Batch_loss: 1.304289 \n",
      "Batch: 1839. Acc: 0.542548. Loss: 1.263708. Batch_acc: 0.558907. Batch_loss: 1.228589 \n",
      "Batch: 1840. Acc: 0.542547. Loss: 1.263708. Batch_acc: 0.541060. Batch_loss: 1.263200 \n",
      "Batch: 1841. Acc: 0.542551. Loss: 1.263712. Batch_acc: 0.549376. Batch_loss: 1.270248 \n",
      "Batch: 1842. Acc: 0.542561. Loss: 1.263684. Batch_acc: 0.560022. Batch_loss: 1.213159 \n",
      "Batch: 1843. Acc: 0.542551. Loss: 1.263694. Batch_acc: 0.524460. Batch_loss: 1.282924 \n",
      "Batch: 1844. Acc: 0.542546. Loss: 1.263717. Batch_acc: 0.533643. Batch_loss: 1.306195 \n",
      "Batch: 1845. Acc: 0.542542. Loss: 1.263722. Batch_acc: 0.535371. Batch_loss: 1.273090 \n",
      "Batch: 1846. Acc: 0.542560. Loss: 1.263695. Batch_acc: 0.575171. Batch_loss: 1.213728 \n",
      "Batch: 1847. Acc: 0.542556. Loss: 1.263701. Batch_acc: 0.535921. Batch_loss: 1.274428 \n",
      "Batch: 1848. Acc: 0.542546. Loss: 1.263714. Batch_acc: 0.523754. Batch_loss: 1.288544 \n",
      "Batch: 1849. Acc: 0.542547. Loss: 1.263715. Batch_acc: 0.543516. Batch_loss: 1.265987 \n",
      "Batch: 1850. Acc: 0.542560. Loss: 1.263694. Batch_acc: 0.566724. Batch_loss: 1.224523 \n",
      "Batch: 1851. Acc: 0.542554. Loss: 1.263700. Batch_acc: 0.531826. Batch_loss: 1.275706 \n",
      "Batch: 1852. Acc: 0.542565. Loss: 1.263684. Batch_acc: 0.562464. Batch_loss: 1.232786 \n",
      "Batch: 1853. Acc: 0.542557. Loss: 1.263710. Batch_acc: 0.528677. Batch_loss: 1.312182 \n",
      "Batch: 1854. Acc: 0.542556. Loss: 1.263715. Batch_acc: 0.539977. Batch_loss: 1.271962 \n",
      "Batch: 1855. Acc: 0.542557. Loss: 1.263705. Batch_acc: 0.544715. Batch_loss: 1.245560 \n",
      "Batch: 1856. Acc: 0.542546. Loss: 1.263736. Batch_acc: 0.522872. Batch_loss: 1.322104 \n",
      "Batch: 1857. Acc: 0.542550. Loss: 1.263711. Batch_acc: 0.549444. Batch_loss: 1.218001 \n",
      "Batch: 1858. Acc: 0.542550. Loss: 1.263711. Batch_acc: 0.542433. Batch_loss: 1.264538 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1859. Acc: 0.542550. Loss: 1.263721. Batch_acc: 0.542596. Batch_loss: 1.282999 \n",
      "Batch: 1860. Acc: 0.542550. Loss: 1.263702. Batch_acc: 0.542461. Batch_loss: 1.227484 \n",
      "Batch: 1861. Acc: 0.542547. Loss: 1.263697. Batch_acc: 0.536655. Batch_loss: 1.254633 \n",
      "Batch: 1862. Acc: 0.542554. Loss: 1.263681. Batch_acc: 0.556268. Batch_loss: 1.233299 \n",
      "Batch: 1863. Acc: 0.542533. Loss: 1.263709. Batch_acc: 0.502633. Batch_loss: 1.317248 \n",
      "Batch: 1864. Acc: 0.542536. Loss: 1.263700. Batch_acc: 0.547351. Batch_loss: 1.246922 \n",
      "Batch: 1865. Acc: 0.542537. Loss: 1.263695. Batch_acc: 0.544457. Batch_loss: 1.254262 \n",
      "Batch: 1866. Acc: 0.542536. Loss: 1.263690. Batch_acc: 0.541217. Batch_loss: 1.255071 \n",
      "Batch: 1867. Acc: 0.542534. Loss: 1.263694. Batch_acc: 0.538995. Batch_loss: 1.269758 \n",
      "Batch: 1868. Acc: 0.542535. Loss: 1.263690. Batch_acc: 0.543991. Batch_loss: 1.256223 \n",
      "Batch: 1869. Acc: 0.542549. Loss: 1.263665. Batch_acc: 0.568593. Batch_loss: 1.216934 \n",
      "Batch: 1870. Acc: 0.542558. Loss: 1.263650. Batch_acc: 0.559332. Batch_loss: 1.234748 \n",
      "Batch: 1871. Acc: 0.542579. Loss: 1.263601. Batch_acc: 0.582157. Batch_loss: 1.174270 \n",
      "Batch: 1872. Acc: 0.542584. Loss: 1.263602. Batch_acc: 0.551804. Batch_loss: 1.265577 \n",
      "Batch: 1873. Acc: 0.542581. Loss: 1.263606. Batch_acc: 0.537195. Batch_loss: 1.270399 \n",
      "Batch: 1874. Acc: 0.542580. Loss: 1.263603. Batch_acc: 0.539638. Batch_loss: 1.258740 \n",
      "Batch: 1875. Acc: 0.542587. Loss: 1.263590. Batch_acc: 0.555366. Batch_loss: 1.239623 \n",
      "Batch: 1876. Acc: 0.542591. Loss: 1.263575. Batch_acc: 0.551445. Batch_loss: 1.234870 \n",
      "Batch: 1877. Acc: 0.542586. Loss: 1.263581. Batch_acc: 0.533486. Batch_loss: 1.274917 \n",
      "Batch: 1878. Acc: 0.542590. Loss: 1.263578. Batch_acc: 0.549482. Batch_loss: 1.257973 \n",
      "Batch: 1879. Acc: 0.542596. Loss: 1.263564. Batch_acc: 0.553291. Batch_loss: 1.236618 \n",
      "Batch: 1880. Acc: 0.542591. Loss: 1.263578. Batch_acc: 0.534513. Batch_loss: 1.291788 \n",
      "Batch: 1881. Acc: 0.542590. Loss: 1.263572. Batch_acc: 0.540634. Batch_loss: 1.251996 \n",
      "Batch: 1882. Acc: 0.542593. Loss: 1.263576. Batch_acc: 0.547786. Batch_loss: 1.270182 \n",
      "Batch: 1883. Acc: 0.542610. Loss: 1.263535. Batch_acc: 0.575687. Batch_loss: 1.186168 \n",
      "Batch: 1884. Acc: 0.542609. Loss: 1.263532. Batch_acc: 0.539638. Batch_loss: 1.258368 \n",
      "Batch: 1885. Acc: 0.542618. Loss: 1.263514. Batch_acc: 0.559449. Batch_loss: 1.228641 \n",
      "Batch: 1886. Acc: 0.542634. Loss: 1.263487. Batch_acc: 0.572050. Batch_loss: 1.216206 \n",
      "Batch: 1887. Acc: 0.542631. Loss: 1.263499. Batch_acc: 0.536866. Batch_loss: 1.284972 \n",
      "Batch: 1888. Acc: 0.542635. Loss: 1.263494. Batch_acc: 0.549943. Batch_loss: 1.254989 \n",
      "Batch: 1889. Acc: 0.542631. Loss: 1.263508. Batch_acc: 0.534911. Batch_loss: 1.289221 \n",
      "Batch: 1890. Acc: 0.542630. Loss: 1.263512. Batch_acc: 0.540243. Batch_loss: 1.270677 \n",
      "Batch: 1891. Acc: 0.542628. Loss: 1.263520. Batch_acc: 0.539090. Batch_loss: 1.279070 \n",
      "Batch: 1892. Acc: 0.542633. Loss: 1.263515. Batch_acc: 0.551603. Batch_loss: 1.253766 \n",
      "Batch: 1893. Acc: 0.542626. Loss: 1.263534. Batch_acc: 0.529446. Batch_loss: 1.300847 \n",
      "Batch: 1894. Acc: 0.542624. Loss: 1.263530. Batch_acc: 0.538732. Batch_loss: 1.256691 \n",
      "Batch: 1895. Acc: 0.542618. Loss: 1.263550. Batch_acc: 0.531624. Batch_loss: 1.300363 \n",
      "Batch: 1896. Acc: 0.542620. Loss: 1.263539. Batch_acc: 0.546145. Batch_loss: 1.243099 \n",
      "Batch: 1897. Acc: 0.542611. Loss: 1.263554. Batch_acc: 0.525656. Batch_loss: 1.291330 \n",
      "Batch: 1898. Acc: 0.542607. Loss: 1.263570. Batch_acc: 0.536281. Batch_loss: 1.294156 \n",
      "Batch: 1899. Acc: 0.542611. Loss: 1.263557. Batch_acc: 0.549346. Batch_loss: 1.236992 \n",
      "Batch: 1900. Acc: 0.542612. Loss: 1.263564. Batch_acc: 0.543870. Batch_loss: 1.276355 \n",
      "Batch: 1901. Acc: 0.542608. Loss: 1.263573. Batch_acc: 0.536190. Batch_loss: 1.282099 \n",
      "Batch: 1902. Acc: 0.542602. Loss: 1.263593. Batch_acc: 0.531465. Batch_loss: 1.300912 \n",
      "Batch: 1903. Acc: 0.542596. Loss: 1.263605. Batch_acc: 0.529723. Batch_loss: 1.287148 \n",
      "Batch: 1904. Acc: 0.542591. Loss: 1.263611. Batch_acc: 0.533410. Batch_loss: 1.273834 \n",
      "Batch: 1905. Acc: 0.542595. Loss: 1.263608. Batch_acc: 0.550392. Batch_loss: 1.258611 \n",
      "Batch: 1906. Acc: 0.542595. Loss: 1.263617. Batch_acc: 0.542019. Batch_loss: 1.279891 \n",
      "Batch: 1907. Acc: 0.542581. Loss: 1.263662. Batch_acc: 0.515434. Batch_loss: 1.350323 \n",
      "Batch: 1908. Acc: 0.542589. Loss: 1.263649. Batch_acc: 0.557593. Batch_loss: 1.239653 \n",
      "Batch: 1909. Acc: 0.542597. Loss: 1.263609. Batch_acc: 0.559293. Batch_loss: 1.187772 \n",
      "Batch: 1910. Acc: 0.542600. Loss: 1.263589. Batch_acc: 0.547673. Batch_loss: 1.226400 \n",
      "Batch: 1911. Acc: 0.542605. Loss: 1.263570. Batch_acc: 0.552860. Batch_loss: 1.226007 \n",
      "Batch: 1912. Acc: 0.542606. Loss: 1.263576. Batch_acc: 0.543491. Batch_loss: 1.276436 \n",
      "Batch: 1913. Acc: 0.542611. Loss: 1.263562. Batch_acc: 0.552601. Batch_loss: 1.235551 \n",
      "Batch: 1914. Acc: 0.542620. Loss: 1.263549. Batch_acc: 0.558824. Batch_loss: 1.238976 \n",
      "Batch: 1915. Acc: 0.542631. Loss: 1.263517. Batch_acc: 0.565217. Batch_loss: 1.201664 \n",
      "Batch: 1916. Acc: 0.542634. Loss: 1.263514. Batch_acc: 0.548182. Batch_loss: 1.258680 \n",
      "Batch: 1917. Acc: 0.542639. Loss: 1.263515. Batch_acc: 0.551543. Batch_loss: 1.265246 \n",
      "Batch: 1918. Acc: 0.542646. Loss: 1.263500. Batch_acc: 0.557111. Batch_loss: 1.236118 \n",
      "Batch: 1919. Acc: 0.542645. Loss: 1.263495. Batch_acc: 0.539497. Batch_loss: 1.252352 \n",
      "Batch: 1920. Acc: 0.542654. Loss: 1.263465. Batch_acc: 0.560862. Batch_loss: 1.204847 \n",
      "Batch: 1921. Acc: 0.542653. Loss: 1.263455. Batch_acc: 0.540634. Batch_loss: 1.244547 \n",
      "Batch: 1922. Acc: 0.542648. Loss: 1.263463. Batch_acc: 0.533411. Batch_loss: 1.279301 \n",
      "Batch: 1923. Acc: 0.542649. Loss: 1.263457. Batch_acc: 0.544186. Batch_loss: 1.251220 \n",
      "Batch: 1924. Acc: 0.542652. Loss: 1.263439. Batch_acc: 0.548518. Batch_loss: 1.228732 \n",
      "Batch: 1925. Acc: 0.542673. Loss: 1.263378. Batch_acc: 0.581880. Batch_loss: 1.149739 \n",
      "Batch: 1926. Acc: 0.542669. Loss: 1.263391. Batch_acc: 0.535179. Batch_loss: 1.287307 \n",
      "Batch: 1927. Acc: 0.542678. Loss: 1.263367. Batch_acc: 0.558857. Batch_loss: 1.216975 \n",
      "Batch: 1928. Acc: 0.542686. Loss: 1.263334. Batch_acc: 0.559255. Batch_loss: 1.202640 \n",
      "Batch: 1929. Acc: 0.542687. Loss: 1.263334. Batch_acc: 0.542959. Batch_loss: 1.261856 \n",
      "Batch: 1930. Acc: 0.542699. Loss: 1.263293. Batch_acc: 0.566893. Batch_loss: 1.185931 \n",
      "Batch: 1931. Acc: 0.542709. Loss: 1.263273. Batch_acc: 0.561785. Batch_loss: 1.225512 \n",
      "Batch: 1932. Acc: 0.542708. Loss: 1.263276. Batch_acc: 0.539906. Batch_loss: 1.267983 \n",
      "Batch: 1933. Acc: 0.542704. Loss: 1.263253. Batch_acc: 0.534790. Batch_loss: 1.218905 \n",
      "Batch: 1934. Acc: 0.542708. Loss: 1.263232. Batch_acc: 0.551900. Batch_loss: 1.223768 \n",
      "Batch: 1935. Acc: 0.542709. Loss: 1.263227. Batch_acc: 0.544664. Batch_loss: 1.252665 \n",
      "Batch: 1936. Acc: 0.542705. Loss: 1.263224. Batch_acc: 0.534065. Batch_loss: 1.258928 \n",
      "Batch: 1937. Acc: 0.542705. Loss: 1.263210. Batch_acc: 0.542343. Batch_loss: 1.235886 \n",
      "Batch: 1938. Acc: 0.542698. Loss: 1.263236. Batch_acc: 0.528969. Batch_loss: 1.313536 \n",
      "Batch: 1939. Acc: 0.542698. Loss: 1.263232. Batch_acc: 0.544023. Batch_loss: 1.254691 \n",
      "Batch: 1940. Acc: 0.542706. Loss: 1.263220. Batch_acc: 0.556990. Batch_loss: 1.239982 \n",
      "Batch: 1941. Acc: 0.542709. Loss: 1.263220. Batch_acc: 0.547633. Batch_loss: 1.264017 \n",
      "Batch: 1942. Acc: 0.542703. Loss: 1.263225. Batch_acc: 0.531915. Batch_loss: 1.273144 \n",
      "Batch: 1943. Acc: 0.542712. Loss: 1.263213. Batch_acc: 0.560877. Batch_loss: 1.239757 \n",
      "Batch: 1944. Acc: 0.542722. Loss: 1.263196. Batch_acc: 0.562390. Batch_loss: 1.230139 \n",
      "Batch: 1945. Acc: 0.542727. Loss: 1.263188. Batch_acc: 0.552026. Batch_loss: 1.247997 \n",
      "Batch: 1946. Acc: 0.542740. Loss: 1.263161. Batch_acc: 0.566705. Batch_loss: 1.210056 \n",
      "Batch: 1947. Acc: 0.542761. Loss: 1.263103. Batch_acc: 0.583574. Batch_loss: 1.150709 \n",
      "Batch: 1948. Acc: 0.542760. Loss: 1.263111. Batch_acc: 0.541383. Batch_loss: 1.277421 \n",
      "Batch: 1949. Acc: 0.542752. Loss: 1.263128. Batch_acc: 0.527082. Batch_loss: 1.297166 \n",
      "Batch: 1950. Acc: 0.542748. Loss: 1.263149. Batch_acc: 0.534937. Batch_loss: 1.304463 \n",
      "Batch: 1951. Acc: 0.542753. Loss: 1.263129. Batch_acc: 0.552632. Batch_loss: 1.224657 \n",
      "Batch: 1952. Acc: 0.542755. Loss: 1.263122. Batch_acc: 0.546328. Batch_loss: 1.250602 \n",
      "Batch: 1953. Acc: 0.542743. Loss: 1.263147. Batch_acc: 0.519814. Batch_loss: 1.312464 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1954. Acc: 0.542759. Loss: 1.263112. Batch_acc: 0.573234. Batch_loss: 1.194196 \n",
      "Batch: 1955. Acc: 0.542755. Loss: 1.263121. Batch_acc: 0.534473. Batch_loss: 1.280404 \n",
      "Batch: 1956. Acc: 0.542766. Loss: 1.263086. Batch_acc: 0.564146. Batch_loss: 1.197532 \n",
      "Batch: 1957. Acc: 0.542759. Loss: 1.263111. Batch_acc: 0.529817. Batch_loss: 1.310457 \n",
      "Batch: 1958. Acc: 0.542757. Loss: 1.263109. Batch_acc: 0.537237. Batch_loss: 1.259392 \n",
      "Batch: 1959. Acc: 0.542760. Loss: 1.263096. Batch_acc: 0.548975. Batch_loss: 1.238262 \n",
      "Batch: 1960. Acc: 0.542763. Loss: 1.263078. Batch_acc: 0.549654. Batch_loss: 1.228472 \n",
      "Batch: 1961. Acc: 0.542774. Loss: 1.263048. Batch_acc: 0.563284. Batch_loss: 1.204115 \n",
      "Batch: 1962. Acc: 0.542789. Loss: 1.263016. Batch_acc: 0.572174. Batch_loss: 1.199441 \n",
      "Batch: 1963. Acc: 0.542792. Loss: 1.262997. Batch_acc: 0.549913. Batch_loss: 1.226937 \n",
      "Batch: 1964. Acc: 0.542800. Loss: 1.262975. Batch_acc: 0.557548. Batch_loss: 1.218482 \n",
      "Batch: 1965. Acc: 0.542777. Loss: 1.263026. Batch_acc: 0.497391. Batch_loss: 1.364269 \n",
      "Batch: 1966. Acc: 0.542779. Loss: 1.263027. Batch_acc: 0.548009. Batch_loss: 1.264221 \n",
      "Batch: 1967. Acc: 0.542781. Loss: 1.263020. Batch_acc: 0.546392. Batch_loss: 1.249208 \n",
      "Batch: 1968. Acc: 0.542786. Loss: 1.263021. Batch_acc: 0.552770. Batch_loss: 1.266884 \n",
      "Batch: 1969. Acc: 0.542771. Loss: 1.263049. Batch_acc: 0.513467. Batch_loss: 1.317684 \n",
      "Batch: 1970. Acc: 0.542773. Loss: 1.263047. Batch_acc: 0.545403. Batch_loss: 1.259112 \n",
      "Batch: 1971. Acc: 0.542777. Loss: 1.263036. Batch_acc: 0.550881. Batch_loss: 1.240689 \n",
      "Batch: 1972. Acc: 0.542786. Loss: 1.263029. Batch_acc: 0.559795. Batch_loss: 1.248871 \n",
      "Batch: 1973. Acc: 0.542778. Loss: 1.263024. Batch_acc: 0.528181. Batch_loss: 1.254381 \n",
      "Batch: 1974. Acc: 0.542777. Loss: 1.263021. Batch_acc: 0.540448. Batch_loss: 1.256815 \n",
      "Batch: 1975. Acc: 0.542795. Loss: 1.262974. Batch_acc: 0.577361. Batch_loss: 1.171057 \n",
      "Batch: 1976. Acc: 0.542795. Loss: 1.262978. Batch_acc: 0.544101. Batch_loss: 1.270383 \n",
      "Batch: 1977. Acc: 0.542805. Loss: 1.262951. Batch_acc: 0.562073. Batch_loss: 1.209960 \n",
      "Batch: 1978. Acc: 0.542813. Loss: 1.262930. Batch_acc: 0.557143. Batch_loss: 1.221752 \n",
      "Batch: 1979. Acc: 0.542830. Loss: 1.262886. Batch_acc: 0.576836. Batch_loss: 1.177537 \n",
      "Batch: 1980. Acc: 0.542847. Loss: 1.262845. Batch_acc: 0.577011. Batch_loss: 1.182341 \n",
      "Batch: 1981. Acc: 0.542859. Loss: 1.262812. Batch_acc: 0.565413. Batch_loss: 1.199177 \n",
      "Batch: 1982. Acc: 0.542849. Loss: 1.262835. Batch_acc: 0.522241. Batch_loss: 1.307977 \n",
      "Batch: 1983. Acc: 0.542836. Loss: 1.262846. Batch_acc: 0.517442. Batch_loss: 1.285270 \n",
      "Batch: 1984. Acc: 0.542841. Loss: 1.262835. Batch_acc: 0.552511. Batch_loss: 1.240875 \n",
      "Batch: 1985. Acc: 0.542820. Loss: 1.262876. Batch_acc: 0.502278. Batch_loss: 1.344395 \n",
      "Batch: 1986. Acc: 0.542830. Loss: 1.262861. Batch_acc: 0.561073. Batch_loss: 1.233225 \n",
      "Batch: 1987. Acc: 0.542835. Loss: 1.262853. Batch_acc: 0.553215. Batch_loss: 1.247712 \n",
      "Batch: 1988. Acc: 0.542830. Loss: 1.262851. Batch_acc: 0.533860. Batch_loss: 1.257181 \n",
      "Batch: 1989. Acc: 0.542822. Loss: 1.262871. Batch_acc: 0.526136. Batch_loss: 1.303624 \n",
      "Batch: 1990. Acc: 0.542828. Loss: 1.262871. Batch_acc: 0.554140. Batch_loss: 1.262691 \n",
      "Batch: 1991. Acc: 0.542840. Loss: 1.262841. Batch_acc: 0.567190. Batch_loss: 1.201418 \n",
      "Batch: 1992. Acc: 0.542831. Loss: 1.262855. Batch_acc: 0.525088. Batch_loss: 1.291307 \n",
      "Batch: 1993. Acc: 0.542842. Loss: 1.262831. Batch_acc: 0.563884. Batch_loss: 1.216297 \n",
      "Batch: 1994. Acc: 0.542842. Loss: 1.262822. Batch_acc: 0.544202. Batch_loss: 1.245137 \n",
      "Batch: 1995. Acc: 0.542850. Loss: 1.262807. Batch_acc: 0.558113. Batch_loss: 1.231894 \n",
      "Batch: 1996. Acc: 0.542857. Loss: 1.262775. Batch_acc: 0.556642. Batch_loss: 1.200374 \n",
      "Batch: 1997. Acc: 0.542857. Loss: 1.262779. Batch_acc: 0.543722. Batch_loss: 1.269676 \n",
      "Batch: 1998. Acc: 0.542867. Loss: 1.262757. Batch_acc: 0.561058. Batch_loss: 1.220597 \n",
      "Batch: 1999. Acc: 0.542880. Loss: 1.262710. Batch_acc: 0.568966. Batch_loss: 1.170534 \n",
      "Batch: 2000. Acc: 0.542881. Loss: 1.262696. Batch_acc: 0.544237. Batch_loss: 1.235733 \n",
      "Batch: 2001. Acc: 0.542885. Loss: 1.262686. Batch_acc: 0.551585. Batch_loss: 1.242366 \n",
      "Batch: 2002. Acc: 0.542888. Loss: 1.262678. Batch_acc: 0.547993. Batch_loss: 1.245527 \n",
      "Batch: 2003. Acc: 0.542877. Loss: 1.262708. Batch_acc: 0.521965. Batch_loss: 1.323042 \n",
      "Batch: 2004. Acc: 0.542877. Loss: 1.262703. Batch_acc: 0.542825. Batch_loss: 1.254024 \n",
      "Batch: 2005. Acc: 0.542874. Loss: 1.262709. Batch_acc: 0.536141. Batch_loss: 1.273286 \n",
      "Batch: 2006. Acc: 0.542876. Loss: 1.262717. Batch_acc: 0.547549. Batch_loss: 1.279027 \n",
      "Batch: 2007. Acc: 0.542873. Loss: 1.262704. Batch_acc: 0.537892. Batch_loss: 1.238545 \n",
      "Batch: 2008. Acc: 0.542880. Loss: 1.262695. Batch_acc: 0.554986. Batch_loss: 1.243057 \n",
      "Checkpointing on batch: 2008. Accuracy: 0.5428795853947761. Loss per char: 1.262694613725498. Time: 1627223442.721721\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 17, 21, 15, 17, 26, 25,  1,\n",
      "        14,  1, 19, 21, 22, 21, 18, 18, 25, 24, 21, 32,  3,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2009. Acc: 0.542883. Loss: 1.262689. Batch_acc: 0.549214. Batch_loss: 1.250606 \n",
      "Batch: 2010. Acc: 0.542876. Loss: 1.262700. Batch_acc: 0.528781. Batch_loss: 1.285821 \n",
      "Batch: 2011. Acc: 0.542870. Loss: 1.262715. Batch_acc: 0.530814. Batch_loss: 1.293246 \n",
      "Batch: 2012. Acc: 0.542869. Loss: 1.262730. Batch_acc: 0.541163. Batch_loss: 1.292522 \n",
      "Batch: 2013. Acc: 0.542873. Loss: 1.262711. Batch_acc: 0.551724. Batch_loss: 1.223534 \n",
      "Batch: 2014. Acc: 0.542872. Loss: 1.262722. Batch_acc: 0.541143. Batch_loss: 1.284496 \n",
      "Batch: 2015. Acc: 0.542875. Loss: 1.262724. Batch_acc: 0.547191. Batch_loss: 1.266972 \n",
      "Batch: 2016. Acc: 0.542882. Loss: 1.262702. Batch_acc: 0.556876. Batch_loss: 1.219836 \n",
      "Batch: 2017. Acc: 0.542878. Loss: 1.262714. Batch_acc: 0.536471. Batch_loss: 1.286976 \n",
      "Batch: 2018. Acc: 0.542868. Loss: 1.262740. Batch_acc: 0.522241. Batch_loss: 1.315395 \n",
      "Batch: 2019. Acc: 0.542867. Loss: 1.262747. Batch_acc: 0.540650. Batch_loss: 1.278181 \n",
      "Batch: 2020. Acc: 0.542874. Loss: 1.262722. Batch_acc: 0.557387. Batch_loss: 1.210078 \n",
      "Batch: 2021. Acc: 0.542886. Loss: 1.262693. Batch_acc: 0.565789. Batch_loss: 1.203411 \n",
      "Batch: 2022. Acc: 0.542880. Loss: 1.262712. Batch_acc: 0.530850. Batch_loss: 1.302108 \n",
      "Batch: 2023. Acc: 0.542883. Loss: 1.262688. Batch_acc: 0.549130. Batch_loss: 1.214777 \n",
      "Batch: 2024. Acc: 0.542878. Loss: 1.262699. Batch_acc: 0.533016. Batch_loss: 1.285897 \n",
      "Batch: 2025. Acc: 0.542873. Loss: 1.262710. Batch_acc: 0.531537. Batch_loss: 1.285593 \n",
      "Batch: 2026. Acc: 0.542876. Loss: 1.262723. Batch_acc: 0.550767. Batch_loss: 1.289392 \n",
      "Batch: 2027. Acc: 0.542868. Loss: 1.262737. Batch_acc: 0.525779. Batch_loss: 1.291196 \n",
      "Batch: 2028. Acc: 0.542866. Loss: 1.262732. Batch_acc: 0.538591. Batch_loss: 1.252771 \n",
      "Batch: 2029. Acc: 0.542880. Loss: 1.262692. Batch_acc: 0.571346. Batch_loss: 1.181718 \n",
      "Batch: 2030. Acc: 0.542893. Loss: 1.262671. Batch_acc: 0.569767. Batch_loss: 1.219297 \n",
      "Batch: 2031. Acc: 0.542906. Loss: 1.262628. Batch_acc: 0.569205. Batch_loss: 1.177122 \n",
      "Batch: 2032. Acc: 0.542902. Loss: 1.262624. Batch_acc: 0.535401. Batch_loss: 1.254729 \n",
      "Batch: 2033. Acc: 0.542886. Loss: 1.262670. Batch_acc: 0.508595. Batch_loss: 1.358475 \n",
      "Batch: 2034. Acc: 0.542882. Loss: 1.262662. Batch_acc: 0.534803. Batch_loss: 1.247404 \n",
      "Batch: 2035. Acc: 0.542882. Loss: 1.262661. Batch_acc: 0.543343. Batch_loss: 1.259776 \n",
      "Batch: 2036. Acc: 0.542886. Loss: 1.262649. Batch_acc: 0.550555. Batch_loss: 1.238868 \n",
      "Batch: 2037. Acc: 0.542896. Loss: 1.262630. Batch_acc: 0.563483. Batch_loss: 1.225115 \n",
      "Batch: 2038. Acc: 0.542902. Loss: 1.262620. Batch_acc: 0.554039. Batch_loss: 1.242099 \n",
      "Batch: 2039. Acc: 0.542904. Loss: 1.262622. Batch_acc: 0.546628. Batch_loss: 1.265609 \n",
      "Batch: 2040. Acc: 0.542900. Loss: 1.262628. Batch_acc: 0.536207. Batch_loss: 1.276669 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2041. Acc: 0.542893. Loss: 1.262652. Batch_acc: 0.526682. Batch_loss: 1.311691 \n",
      "Batch: 2042. Acc: 0.542892. Loss: 1.262648. Batch_acc: 0.542099. Batch_loss: 1.253155 \n",
      "Batch: 2043. Acc: 0.542901. Loss: 1.262636. Batch_acc: 0.560276. Batch_loss: 1.239821 \n",
      "Batch: 2044. Acc: 0.542902. Loss: 1.262628. Batch_acc: 0.544879. Batch_loss: 1.246123 \n",
      "Batch: 2045. Acc: 0.542907. Loss: 1.262619. Batch_acc: 0.553855. Batch_loss: 1.243694 \n",
      "Batch: 2046. Acc: 0.542914. Loss: 1.262599. Batch_acc: 0.557093. Batch_loss: 1.220849 \n",
      "Batch: 2047. Acc: 0.542927. Loss: 1.262569. Batch_acc: 0.569874. Batch_loss: 1.201844 \n",
      "Batch: 2048. Acc: 0.542925. Loss: 1.262573. Batch_acc: 0.538462. Batch_loss: 1.270445 \n",
      "Batch: 2049. Acc: 0.542920. Loss: 1.262591. Batch_acc: 0.532726. Batch_loss: 1.298961 \n",
      "Batch: 2050. Acc: 0.542926. Loss: 1.262578. Batch_acc: 0.554540. Batch_loss: 1.236983 \n",
      "Batch: 2051. Acc: 0.542923. Loss: 1.262581. Batch_acc: 0.538636. Batch_loss: 1.267983 \n",
      "Batch: 2052. Acc: 0.542931. Loss: 1.262557. Batch_acc: 0.558046. Batch_loss: 1.213554 \n",
      "Batch: 2053. Acc: 0.542935. Loss: 1.262546. Batch_acc: 0.552047. Batch_loss: 1.239538 \n",
      "Batch: 2054. Acc: 0.542928. Loss: 1.262544. Batch_acc: 0.527011. Batch_loss: 1.256943 \n",
      "Batch: 2055. Acc: 0.542935. Loss: 1.262511. Batch_acc: 0.558807. Batch_loss: 1.194834 \n",
      "Batch: 2056. Acc: 0.542946. Loss: 1.262486. Batch_acc: 0.565317. Batch_loss: 1.212994 \n",
      "Batch: 2057. Acc: 0.542952. Loss: 1.262460. Batch_acc: 0.553531. Batch_loss: 1.209954 \n",
      "Batch: 2058. Acc: 0.542954. Loss: 1.262444. Batch_acc: 0.548703. Batch_loss: 1.228153 \n",
      "Batch: 2059. Acc: 0.542943. Loss: 1.262453. Batch_acc: 0.519814. Batch_loss: 1.281273 \n",
      "Batch: 2060. Acc: 0.542962. Loss: 1.262406. Batch_acc: 0.580776. Batch_loss: 1.165505 \n",
      "Batch: 2061. Acc: 0.542955. Loss: 1.262409. Batch_acc: 0.529479. Batch_loss: 1.267435 \n",
      "Batch: 2062. Acc: 0.542947. Loss: 1.262412. Batch_acc: 0.526556. Batch_loss: 1.269440 \n",
      "Batch: 2063. Acc: 0.542954. Loss: 1.262397. Batch_acc: 0.557093. Batch_loss: 1.231873 \n",
      "Batch: 2064. Acc: 0.542961. Loss: 1.262383. Batch_acc: 0.557792. Batch_loss: 1.232293 \n",
      "Batch: 2065. Acc: 0.542960. Loss: 1.262393. Batch_acc: 0.539988. Batch_loss: 1.283895 \n",
      "Batch: 2066. Acc: 0.542965. Loss: 1.262383. Batch_acc: 0.554719. Batch_loss: 1.241465 \n",
      "Batch: 2067. Acc: 0.542973. Loss: 1.262356. Batch_acc: 0.559332. Batch_loss: 1.207858 \n",
      "Batch: 2068. Acc: 0.542982. Loss: 1.262345. Batch_acc: 0.561018. Batch_loss: 1.238719 \n",
      "Batch: 2069. Acc: 0.542983. Loss: 1.262343. Batch_acc: 0.545188. Batch_loss: 1.258299 \n",
      "Batch: 2070. Acc: 0.542982. Loss: 1.262338. Batch_acc: 0.541108. Batch_loss: 1.250969 \n",
      "Batch: 2071. Acc: 0.542970. Loss: 1.262362. Batch_acc: 0.518562. Batch_loss: 1.313346 \n",
      "Batch: 2072. Acc: 0.542967. Loss: 1.262363. Batch_acc: 0.536600. Batch_loss: 1.263820 \n",
      "Batch: 2073. Acc: 0.542974. Loss: 1.262344. Batch_acc: 0.555493. Batch_loss: 1.225196 \n",
      "Batch: 2074. Acc: 0.542980. Loss: 1.262326. Batch_acc: 0.556005. Batch_loss: 1.224928 \n",
      "Batch: 2075. Acc: 0.542979. Loss: 1.262330. Batch_acc: 0.541906. Batch_loss: 1.269963 \n",
      "Batch: 2076. Acc: 0.542981. Loss: 1.262329. Batch_acc: 0.547258. Batch_loss: 1.259735 \n",
      "Batch: 2077. Acc: 0.542988. Loss: 1.262305. Batch_acc: 0.557748. Batch_loss: 1.213634 \n",
      "Batch: 2078. Acc: 0.542991. Loss: 1.262289. Batch_acc: 0.548387. Batch_loss: 1.227096 \n",
      "Batch: 2079. Acc: 0.542999. Loss: 1.262279. Batch_acc: 0.558773. Batch_loss: 1.242385 \n",
      "Batch: 2080. Acc: 0.543000. Loss: 1.262263. Batch_acc: 0.544780. Batch_loss: 1.230085 \n",
      "Batch: 2081. Acc: 0.543015. Loss: 1.262229. Batch_acc: 0.574190. Batch_loss: 1.191148 \n",
      "Batch: 2082. Acc: 0.543028. Loss: 1.262198. Batch_acc: 0.570358. Batch_loss: 1.198778 \n",
      "Batch: 2083. Acc: 0.543025. Loss: 1.262189. Batch_acc: 0.537778. Batch_loss: 1.243604 \n",
      "Batch: 2084. Acc: 0.543022. Loss: 1.262216. Batch_acc: 0.534827. Batch_loss: 1.322334 \n",
      "Batch: 2085. Acc: 0.543016. Loss: 1.262233. Batch_acc: 0.531732. Batch_loss: 1.295605 \n",
      "Batch: 2086. Acc: 0.543007. Loss: 1.262240. Batch_acc: 0.524752. Batch_loss: 1.277462 \n",
      "Batch: 2087. Acc: 0.543013. Loss: 1.262237. Batch_acc: 0.554031. Batch_loss: 1.255714 \n",
      "Batch: 2088. Acc: 0.543014. Loss: 1.262237. Batch_acc: 0.545455. Batch_loss: 1.263928 \n",
      "Batch: 2089. Acc: 0.543013. Loss: 1.262240. Batch_acc: 0.541231. Batch_loss: 1.268088 \n",
      "Batch: 2090. Acc: 0.543016. Loss: 1.262246. Batch_acc: 0.548313. Batch_loss: 1.274377 \n",
      "Batch: 2091. Acc: 0.543017. Loss: 1.262246. Batch_acc: 0.544890. Batch_loss: 1.262798 \n",
      "Batch: 2092. Acc: 0.543026. Loss: 1.262238. Batch_acc: 0.561714. Batch_loss: 1.244793 \n",
      "Batch: 2093. Acc: 0.543024. Loss: 1.262244. Batch_acc: 0.538902. Batch_loss: 1.274120 \n",
      "Batch: 2094. Acc: 0.543040. Loss: 1.262200. Batch_acc: 0.577073. Batch_loss: 1.173817 \n",
      "Batch: 2095. Acc: 0.543028. Loss: 1.262203. Batch_acc: 0.517062. Batch_loss: 1.267884 \n",
      "Batch: 2096. Acc: 0.543032. Loss: 1.262193. Batch_acc: 0.551884. Batch_loss: 1.240986 \n",
      "Batch: 2097. Acc: 0.543036. Loss: 1.262186. Batch_acc: 0.550543. Batch_loss: 1.248898 \n",
      "Batch: 2098. Acc: 0.543039. Loss: 1.262179. Batch_acc: 0.548975. Batch_loss: 1.247836 \n",
      "Batch: 2099. Acc: 0.543035. Loss: 1.262181. Batch_acc: 0.535451. Batch_loss: 1.266162 \n",
      "Batch: 2100. Acc: 0.543044. Loss: 1.262163. Batch_acc: 0.561590. Batch_loss: 1.225203 \n",
      "Batch: 2101. Acc: 0.543040. Loss: 1.262174. Batch_acc: 0.535510. Batch_loss: 1.285576 \n",
      "Batch: 2102. Acc: 0.543040. Loss: 1.262167. Batch_acc: 0.542233. Batch_loss: 1.245584 \n",
      "Batch: 2103. Acc: 0.543042. Loss: 1.262157. Batch_acc: 0.548032. Batch_loss: 1.242111 \n",
      "Batch: 2104. Acc: 0.543037. Loss: 1.262165. Batch_acc: 0.531083. Batch_loss: 1.279247 \n",
      "Batch: 2105. Acc: 0.543047. Loss: 1.262149. Batch_acc: 0.563510. Batch_loss: 1.228540 \n",
      "Batch: 2106. Acc: 0.543049. Loss: 1.262164. Batch_acc: 0.547126. Batch_loss: 1.293530 \n",
      "Batch: 2107. Acc: 0.543053. Loss: 1.262163. Batch_acc: 0.552326. Batch_loss: 1.259691 \n",
      "Batch: 2108. Acc: 0.543063. Loss: 1.262154. Batch_acc: 0.563897. Batch_loss: 1.243014 \n",
      "Batch: 2109. Acc: 0.543071. Loss: 1.262147. Batch_acc: 0.561684. Batch_loss: 1.246355 \n",
      "Batch: 2110. Acc: 0.543081. Loss: 1.262132. Batch_acc: 0.563331. Batch_loss: 1.231335 \n",
      "Batch: 2111. Acc: 0.543084. Loss: 1.262130. Batch_acc: 0.549539. Batch_loss: 1.257243 \n",
      "Batch: 2112. Acc: 0.543092. Loss: 1.262107. Batch_acc: 0.559882. Batch_loss: 1.213624 \n",
      "Batch: 2113. Acc: 0.543094. Loss: 1.262093. Batch_acc: 0.547826. Batch_loss: 1.231214 \n",
      "Batch: 2114. Acc: 0.543079. Loss: 1.262115. Batch_acc: 0.511176. Batch_loss: 1.311027 \n",
      "Batch: 2115. Acc: 0.543086. Loss: 1.262095. Batch_acc: 0.557537. Batch_loss: 1.218963 \n",
      "Batch: 2116. Acc: 0.543098. Loss: 1.262045. Batch_acc: 0.568207. Batch_loss: 1.157614 \n",
      "Batch: 2117. Acc: 0.543102. Loss: 1.262067. Batch_acc: 0.550891. Batch_loss: 1.309520 \n",
      "Batch: 2118. Acc: 0.543101. Loss: 1.262072. Batch_acc: 0.540413. Batch_loss: 1.272591 \n",
      "Batch: 2119. Acc: 0.543097. Loss: 1.262081. Batch_acc: 0.536023. Batch_loss: 1.281790 \n",
      "Batch: 2120. Acc: 0.543105. Loss: 1.262077. Batch_acc: 0.558206. Batch_loss: 1.252392 \n",
      "Batch: 2121. Acc: 0.543112. Loss: 1.262055. Batch_acc: 0.558656. Batch_loss: 1.215644 \n",
      "Batch: 2122. Acc: 0.543106. Loss: 1.262077. Batch_acc: 0.529919. Batch_loss: 1.308999 \n",
      "Batch: 2123. Acc: 0.543100. Loss: 1.262087. Batch_acc: 0.530251. Batch_loss: 1.284645 \n",
      "Batch: 2124. Acc: 0.543115. Loss: 1.262028. Batch_acc: 0.575964. Batch_loss: 1.137434 \n",
      "Batch: 2125. Acc: 0.543128. Loss: 1.261996. Batch_acc: 0.571264. Batch_loss: 1.195084 \n",
      "Batch: 2126. Acc: 0.543142. Loss: 1.261962. Batch_acc: 0.571671. Batch_loss: 1.189858 \n",
      "Batch: 2127. Acc: 0.543150. Loss: 1.261944. Batch_acc: 0.560276. Batch_loss: 1.222842 \n",
      "Batch: 2128. Acc: 0.543151. Loss: 1.261938. Batch_acc: 0.545455. Batch_loss: 1.249644 \n",
      "Batch: 2129. Acc: 0.543155. Loss: 1.261931. Batch_acc: 0.550355. Batch_loss: 1.247900 \n",
      "Batch: 2130. Acc: 0.543150. Loss: 1.261942. Batch_acc: 0.533913. Batch_loss: 1.284737 \n",
      "Batch: 2131. Acc: 0.543158. Loss: 1.261915. Batch_acc: 0.558231. Batch_loss: 1.206031 \n",
      "Batch: 2132. Acc: 0.543161. Loss: 1.261913. Batch_acc: 0.551149. Batch_loss: 1.257820 \n",
      "Batch: 2133. Acc: 0.543162. Loss: 1.261914. Batch_acc: 0.545347. Batch_loss: 1.263139 \n",
      "Batch: 2134. Acc: 0.543157. Loss: 1.261929. Batch_acc: 0.532386. Batch_loss: 1.293004 \n",
      "Batch: 2135. Acc: 0.543153. Loss: 1.261916. Batch_acc: 0.534377. Batch_loss: 1.235402 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2136. Acc: 0.543154. Loss: 1.261904. Batch_acc: 0.544382. Batch_loss: 1.237825 \n",
      "Batch: 2137. Acc: 0.543164. Loss: 1.261869. Batch_acc: 0.567200. Batch_loss: 1.183530 \n",
      "Batch: 2138. Acc: 0.543159. Loss: 1.261888. Batch_acc: 0.530491. Batch_loss: 1.303910 \n",
      "Batch: 2139. Acc: 0.543154. Loss: 1.261910. Batch_acc: 0.532295. Batch_loss: 1.309407 \n",
      "Batch: 2140. Acc: 0.543139. Loss: 1.261955. Batch_acc: 0.510700. Batch_loss: 1.359539 \n",
      "Batch: 2141. Acc: 0.543149. Loss: 1.261939. Batch_acc: 0.565020. Batch_loss: 1.227980 \n",
      "Batch: 2142. Acc: 0.543162. Loss: 1.261905. Batch_acc: 0.571261. Batch_loss: 1.187311 \n",
      "Batch: 2143. Acc: 0.543173. Loss: 1.261873. Batch_acc: 0.566059. Batch_loss: 1.193793 \n",
      "Batch: 2144. Acc: 0.543171. Loss: 1.261886. Batch_acc: 0.540012. Batch_loss: 1.289126 \n",
      "Batch: 2145. Acc: 0.543162. Loss: 1.261899. Batch_acc: 0.524277. Batch_loss: 1.291247 \n",
      "Batch: 2146. Acc: 0.543155. Loss: 1.261913. Batch_acc: 0.527604. Batch_loss: 1.290371 \n",
      "Batch: 2147. Acc: 0.543164. Loss: 1.261894. Batch_acc: 0.561927. Batch_loss: 1.221989 \n",
      "Batch: 2148. Acc: 0.543170. Loss: 1.261875. Batch_acc: 0.556856. Batch_loss: 1.221796 \n",
      "Batch: 2149. Acc: 0.543185. Loss: 1.261848. Batch_acc: 0.574383. Batch_loss: 1.205249 \n",
      "Batch: 2150. Acc: 0.543185. Loss: 1.261840. Batch_acc: 0.543253. Batch_loss: 1.244104 \n",
      "Batch: 2151. Acc: 0.543187. Loss: 1.261830. Batch_acc: 0.548643. Batch_loss: 1.240482 \n",
      "Batch: 2152. Acc: 0.543201. Loss: 1.261792. Batch_acc: 0.572313. Batch_loss: 1.182116 \n",
      "Batch: 2153. Acc: 0.543201. Loss: 1.261773. Batch_acc: 0.543099. Batch_loss: 1.222098 \n",
      "Batch: 2154. Acc: 0.543203. Loss: 1.261750. Batch_acc: 0.545861. Batch_loss: 1.213731 \n",
      "Batch: 2155. Acc: 0.543208. Loss: 1.261732. Batch_acc: 0.554598. Batch_loss: 1.222717 \n",
      "Batch: 2156. Acc: 0.543208. Loss: 1.261738. Batch_acc: 0.542857. Batch_loss: 1.273819 \n",
      "Batch: 2157. Acc: 0.543216. Loss: 1.261723. Batch_acc: 0.560316. Batch_loss: 1.229787 \n",
      "Batch: 2158. Acc: 0.543220. Loss: 1.261722. Batch_acc: 0.552265. Batch_loss: 1.260083 \n",
      "Batch: 2159. Acc: 0.543223. Loss: 1.261716. Batch_acc: 0.550029. Batch_loss: 1.248458 \n",
      "Batch: 2160. Acc: 0.543237. Loss: 1.261681. Batch_acc: 0.573438. Batch_loss: 1.187625 \n",
      "Batch: 2161. Acc: 0.543240. Loss: 1.261655. Batch_acc: 0.549801. Batch_loss: 1.206988 \n",
      "Batch: 2162. Acc: 0.543243. Loss: 1.261644. Batch_acc: 0.548555. Batch_loss: 1.237016 \n",
      "Batch: 2163. Acc: 0.543240. Loss: 1.261644. Batch_acc: 0.537365. Batch_loss: 1.262335 \n",
      "Batch: 2164. Acc: 0.543259. Loss: 1.261602. Batch_acc: 0.582726. Batch_loss: 1.173165 \n",
      "Batch: 2165. Acc: 0.543259. Loss: 1.261605. Batch_acc: 0.542824. Batch_loss: 1.266883 \n",
      "Batch: 2166. Acc: 0.543263. Loss: 1.261586. Batch_acc: 0.553022. Batch_loss: 1.221482 \n",
      "Batch: 2167. Acc: 0.543264. Loss: 1.261597. Batch_acc: 0.545559. Batch_loss: 1.285370 \n",
      "Batch: 2168. Acc: 0.543271. Loss: 1.261586. Batch_acc: 0.558358. Batch_loss: 1.237921 \n",
      "Batch: 2169. Acc: 0.543276. Loss: 1.261567. Batch_acc: 0.554980. Batch_loss: 1.218860 \n",
      "Batch: 2170. Acc: 0.543281. Loss: 1.261552. Batch_acc: 0.553551. Batch_loss: 1.229470 \n",
      "Batch: 2171. Acc: 0.543283. Loss: 1.261548. Batch_acc: 0.546545. Batch_loss: 1.253405 \n",
      "Batch: 2172. Acc: 0.543290. Loss: 1.261515. Batch_acc: 0.558219. Batch_loss: 1.189943 \n",
      "Batch: 2173. Acc: 0.543290. Loss: 1.261512. Batch_acc: 0.544092. Batch_loss: 1.256089 \n",
      "Batch: 2174. Acc: 0.543283. Loss: 1.261526. Batch_acc: 0.528479. Batch_loss: 1.292257 \n",
      "Batch: 2175. Acc: 0.543289. Loss: 1.261512. Batch_acc: 0.555366. Batch_loss: 1.230992 \n",
      "Batch: 2176. Acc: 0.543308. Loss: 1.261470. Batch_acc: 0.584960. Batch_loss: 1.170078 \n",
      "Batch: 2177. Acc: 0.543296. Loss: 1.261494. Batch_acc: 0.517280. Batch_loss: 1.312033 \n",
      "Batch: 2178. Acc: 0.543293. Loss: 1.261491. Batch_acc: 0.537296. Batch_loss: 1.255931 \n",
      "Batch: 2179. Acc: 0.543294. Loss: 1.261488. Batch_acc: 0.544701. Batch_loss: 1.255491 \n",
      "Batch: 2180. Acc: 0.543297. Loss: 1.261477. Batch_acc: 0.549631. Batch_loss: 1.237933 \n",
      "Batch: 2181. Acc: 0.543295. Loss: 1.261485. Batch_acc: 0.539954. Batch_loss: 1.277944 \n",
      "Batch: 2182. Acc: 0.543296. Loss: 1.261480. Batch_acc: 0.544237. Batch_loss: 1.249452 \n",
      "Batch: 2183. Acc: 0.543289. Loss: 1.261489. Batch_acc: 0.529212. Batch_loss: 1.281944 \n",
      "Batch: 2184. Acc: 0.543285. Loss: 1.261514. Batch_acc: 0.533295. Batch_loss: 1.315823 \n",
      "Batch: 2185. Acc: 0.543281. Loss: 1.261529. Batch_acc: 0.534453. Batch_loss: 1.294185 \n",
      "Batch: 2186. Acc: 0.543283. Loss: 1.261512. Batch_acc: 0.549560. Batch_loss: 1.224342 \n",
      "Batch: 2187. Acc: 0.543273. Loss: 1.261541. Batch_acc: 0.520666. Batch_loss: 1.325977 \n",
      "Batch: 2188. Acc: 0.543275. Loss: 1.261541. Batch_acc: 0.547018. Batch_loss: 1.260058 \n",
      "Batch: 2189. Acc: 0.543261. Loss: 1.261585. Batch_acc: 0.513514. Batch_loss: 1.357382 \n",
      "Batch: 2190. Acc: 0.543277. Loss: 1.261559. Batch_acc: 0.578035. Batch_loss: 1.204666 \n",
      "Batch: 2191. Acc: 0.543284. Loss: 1.261548. Batch_acc: 0.558907. Batch_loss: 1.238212 \n",
      "Batch: 2192. Acc: 0.543281. Loss: 1.261547. Batch_acc: 0.535088. Batch_loss: 1.259753 \n",
      "Batch: 2193. Acc: 0.543279. Loss: 1.261548. Batch_acc: 0.539813. Batch_loss: 1.263354 \n",
      "Batch: 2194. Acc: 0.543280. Loss: 1.261548. Batch_acc: 0.545507. Batch_loss: 1.260814 \n",
      "Batch: 2195. Acc: 0.543274. Loss: 1.261560. Batch_acc: 0.529654. Batch_loss: 1.288451 \n",
      "Batch: 2196. Acc: 0.543278. Loss: 1.261543. Batch_acc: 0.552499. Batch_loss: 1.225750 \n",
      "Batch: 2197. Acc: 0.543287. Loss: 1.261515. Batch_acc: 0.562321. Batch_loss: 1.201078 \n",
      "Batch: 2198. Acc: 0.543291. Loss: 1.261524. Batch_acc: 0.552018. Batch_loss: 1.280179 \n",
      "Batch: 2199. Acc: 0.543300. Loss: 1.261507. Batch_acc: 0.563533. Batch_loss: 1.224544 \n",
      "Batch: 2200. Acc: 0.543299. Loss: 1.261499. Batch_acc: 0.539747. Batch_loss: 1.244392 \n",
      "Batch: 2201. Acc: 0.543314. Loss: 1.261456. Batch_acc: 0.575723. Batch_loss: 1.167612 \n",
      "Batch: 2202. Acc: 0.543315. Loss: 1.261456. Batch_acc: 0.546893. Batch_loss: 1.261034 \n",
      "Batch: 2203. Acc: 0.543310. Loss: 1.261474. Batch_acc: 0.531142. Batch_loss: 1.300920 \n",
      "Batch: 2204. Acc: 0.543320. Loss: 1.261444. Batch_acc: 0.566454. Batch_loss: 1.195755 \n",
      "Batch: 2205. Acc: 0.543319. Loss: 1.261426. Batch_acc: 0.541954. Batch_loss: 1.221574 \n",
      "Batch: 2206. Acc: 0.543326. Loss: 1.261394. Batch_acc: 0.556730. Batch_loss: 1.193376 \n",
      "Batch: 2207. Acc: 0.543338. Loss: 1.261368. Batch_acc: 0.568782. Batch_loss: 1.205620 \n",
      "Batch: 2208. Acc: 0.543337. Loss: 1.261368. Batch_acc: 0.542412. Batch_loss: 1.261370 \n",
      "Batch: 2209. Acc: 0.543339. Loss: 1.261357. Batch_acc: 0.547429. Batch_loss: 1.235833 \n",
      "Batch: 2210. Acc: 0.543343. Loss: 1.261354. Batch_acc: 0.552616. Batch_loss: 1.254661 \n",
      "Batch: 2211. Acc: 0.543356. Loss: 1.261325. Batch_acc: 0.571668. Batch_loss: 1.201126 \n",
      "Batch: 2212. Acc: 0.543356. Loss: 1.261334. Batch_acc: 0.543280. Batch_loss: 1.280864 \n",
      "Batch: 2213. Acc: 0.543359. Loss: 1.261321. Batch_acc: 0.549457. Batch_loss: 1.231326 \n",
      "Batch: 2214. Acc: 0.543371. Loss: 1.261287. Batch_acc: 0.569599. Batch_loss: 1.188462 \n",
      "Batch: 2215. Acc: 0.543374. Loss: 1.261270. Batch_acc: 0.549913. Batch_loss: 1.223123 \n",
      "Batch: 2216. Acc: 0.543385. Loss: 1.261241. Batch_acc: 0.566312. Batch_loss: 1.199612 \n",
      "Batch: 2217. Acc: 0.543390. Loss: 1.261224. Batch_acc: 0.554810. Batch_loss: 1.225338 \n",
      "Batch: 2218. Acc: 0.543399. Loss: 1.261205. Batch_acc: 0.563198. Batch_loss: 1.217003 \n",
      "Batch: 2219. Acc: 0.543402. Loss: 1.261181. Batch_acc: 0.551149. Batch_loss: 1.208568 \n",
      "Batch: 2220. Acc: 0.543405. Loss: 1.261168. Batch_acc: 0.548066. Batch_loss: 1.230334 \n",
      "Batch: 2221. Acc: 0.543411. Loss: 1.261160. Batch_acc: 0.557579. Batch_loss: 1.243144 \n",
      "Batch: 2222. Acc: 0.543409. Loss: 1.261148. Batch_acc: 0.540445. Batch_loss: 1.236091 \n",
      "Batch: 2223. Acc: 0.543411. Loss: 1.261155. Batch_acc: 0.547619. Batch_loss: 1.275777 \n",
      "Batch: 2224. Acc: 0.543422. Loss: 1.261138. Batch_acc: 0.566382. Batch_loss: 1.223078 \n",
      "Batch: 2225. Acc: 0.543420. Loss: 1.261150. Batch_acc: 0.539540. Batch_loss: 1.287964 \n",
      "Batch: 2226. Acc: 0.543424. Loss: 1.261125. Batch_acc: 0.551585. Batch_loss: 1.205742 \n",
      "Batch: 2227. Acc: 0.543428. Loss: 1.261114. Batch_acc: 0.552054. Batch_loss: 1.236420 \n",
      "Batch: 2228. Acc: 0.543430. Loss: 1.261100. Batch_acc: 0.548824. Batch_loss: 1.228128 \n",
      "Batch: 2229. Acc: 0.543440. Loss: 1.261056. Batch_acc: 0.565418. Batch_loss: 1.163204 \n",
      "Batch: 2230. Acc: 0.543452. Loss: 1.261023. Batch_acc: 0.571429. Batch_loss: 1.188529 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2231. Acc: 0.543459. Loss: 1.260997. Batch_acc: 0.556869. Batch_loss: 1.204497 \n",
      "Batch: 2232. Acc: 0.543451. Loss: 1.261010. Batch_acc: 0.527417. Batch_loss: 1.290171 \n",
      "Batch: 2233. Acc: 0.543451. Loss: 1.261019. Batch_acc: 0.543153. Batch_loss: 1.280789 \n",
      "Batch: 2234. Acc: 0.543435. Loss: 1.261064. Batch_acc: 0.507280. Batch_loss: 1.362268 \n",
      "Batch: 2235. Acc: 0.543441. Loss: 1.261053. Batch_acc: 0.557028. Batch_loss: 1.235793 \n",
      "Batch: 2236. Acc: 0.543446. Loss: 1.261048. Batch_acc: 0.555424. Batch_loss: 1.250930 \n",
      "Batch: 2237. Acc: 0.543452. Loss: 1.261024. Batch_acc: 0.556193. Batch_loss: 1.207341 \n",
      "Batch: 2238. Acc: 0.543440. Loss: 1.261055. Batch_acc: 0.516168. Batch_loss: 1.333332 \n",
      "Batch: 2239. Acc: 0.543450. Loss: 1.261042. Batch_acc: 0.564638. Batch_loss: 1.230580 \n",
      "Batch: 2240. Acc: 0.543455. Loss: 1.261037. Batch_acc: 0.554513. Batch_loss: 1.249463 \n",
      "Batch: 2241. Acc: 0.543465. Loss: 1.261014. Batch_acc: 0.566059. Batch_loss: 1.211187 \n",
      "Batch: 2242. Acc: 0.543466. Loss: 1.260999. Batch_acc: 0.546771. Batch_loss: 1.226767 \n",
      "Batch: 2243. Acc: 0.543477. Loss: 1.260976. Batch_acc: 0.567676. Batch_loss: 1.210056 \n",
      "Batch: 2244. Acc: 0.543478. Loss: 1.260972. Batch_acc: 0.544754. Batch_loss: 1.251854 \n",
      "Batch: 2245. Acc: 0.543479. Loss: 1.260957. Batch_acc: 0.545866. Batch_loss: 1.227612 \n",
      "Batch: 2246. Acc: 0.543480. Loss: 1.260953. Batch_acc: 0.544980. Batch_loss: 1.253777 \n",
      "Batch: 2247. Acc: 0.543482. Loss: 1.260952. Batch_acc: 0.548127. Batch_loss: 1.257055 \n",
      "Batch: 2248. Acc: 0.543484. Loss: 1.260935. Batch_acc: 0.549288. Batch_loss: 1.224554 \n",
      "Batch: 2249. Acc: 0.543481. Loss: 1.260951. Batch_acc: 0.535545. Batch_loss: 1.296275 \n",
      "Batch: 2250. Acc: 0.543492. Loss: 1.260929. Batch_acc: 0.567986. Batch_loss: 1.212636 \n",
      "Batch: 2251. Acc: 0.543509. Loss: 1.260881. Batch_acc: 0.580302. Batch_loss: 1.156122 \n",
      "Batch: 2252. Acc: 0.543509. Loss: 1.260866. Batch_acc: 0.544729. Batch_loss: 1.227120 \n",
      "Batch: 2253. Acc: 0.543513. Loss: 1.260855. Batch_acc: 0.552171. Batch_loss: 1.235885 \n",
      "Batch: 2254. Acc: 0.543506. Loss: 1.260879. Batch_acc: 0.527209. Batch_loss: 1.316654 \n",
      "Batch: 2255. Acc: 0.543498. Loss: 1.260894. Batch_acc: 0.523923. Batch_loss: 1.296433 \n",
      "Batch: 2256. Acc: 0.543496. Loss: 1.260897. Batch_acc: 0.540138. Batch_loss: 1.266793 \n",
      "Batch: 2257. Acc: 0.543491. Loss: 1.260903. Batch_acc: 0.532843. Batch_loss: 1.273248 \n",
      "Batch: 2258. Acc: 0.543484. Loss: 1.260916. Batch_acc: 0.528281. Batch_loss: 1.289866 \n",
      "Batch: 2259. Acc: 0.543483. Loss: 1.260908. Batch_acc: 0.539294. Batch_loss: 1.243941 \n",
      "Checkpointing on batch: 2259. Accuracy: 0.5434825327622071. Loss per char: 1.2609079908303173. Time: 1627223623.4240844\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 22, 23, 19, 18, 22, 22,  1,\n",
      "        14,  1, 14, 17, 15, 18, 22, 17, 19, 22, 25, 18, 25, 15,  3,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2260. Acc: 0.543479. Loss: 1.260912. Batch_acc: 0.535365. Batch_loss: 1.269993 \n",
      "Batch: 2261. Acc: 0.543466. Loss: 1.260937. Batch_acc: 0.514013. Batch_loss: 1.319785 \n",
      "Batch: 2262. Acc: 0.543471. Loss: 1.260915. Batch_acc: 0.554617. Batch_loss: 1.211945 \n",
      "Batch: 2263. Acc: 0.543487. Loss: 1.260879. Batch_acc: 0.578300. Batch_loss: 1.182138 \n",
      "Batch: 2264. Acc: 0.543486. Loss: 1.260889. Batch_acc: 0.540355. Batch_loss: 1.283963 \n",
      "Batch: 2265. Acc: 0.543499. Loss: 1.260857. Batch_acc: 0.572970. Batch_loss: 1.187326 \n",
      "Batch: 2266. Acc: 0.543502. Loss: 1.260846. Batch_acc: 0.550454. Batch_loss: 1.237131 \n",
      "Batch: 2267. Acc: 0.543507. Loss: 1.260827. Batch_acc: 0.554540. Batch_loss: 1.217365 \n",
      "Batch: 2268. Acc: 0.543515. Loss: 1.260820. Batch_acc: 0.562002. Batch_loss: 1.246229 \n",
      "Batch: 2269. Acc: 0.543523. Loss: 1.260805. Batch_acc: 0.561690. Batch_loss: 1.226368 \n",
      "Batch: 2270. Acc: 0.543516. Loss: 1.260816. Batch_acc: 0.527127. Batch_loss: 1.286054 \n",
      "Batch: 2271. Acc: 0.543518. Loss: 1.260811. Batch_acc: 0.547786. Batch_loss: 1.250428 \n",
      "Batch: 2272. Acc: 0.543519. Loss: 1.260811. Batch_acc: 0.546737. Batch_loss: 1.259702 \n",
      "Batch: 2273. Acc: 0.543521. Loss: 1.260815. Batch_acc: 0.546083. Batch_loss: 1.271118 \n",
      "Batch: 2274. Acc: 0.543537. Loss: 1.260767. Batch_acc: 0.579808. Batch_loss: 1.153923 \n",
      "Batch: 2275. Acc: 0.543522. Loss: 1.260798. Batch_acc: 0.509467. Batch_loss: 1.332381 \n",
      "Batch: 2276. Acc: 0.543505. Loss: 1.260831. Batch_acc: 0.503821. Batch_loss: 1.336617 \n",
      "Batch: 2277. Acc: 0.543506. Loss: 1.260827. Batch_acc: 0.546037. Batch_loss: 1.251853 \n",
      "Batch: 2278. Acc: 0.543502. Loss: 1.260830. Batch_acc: 0.533563. Batch_loss: 1.267364 \n",
      "Batch: 2279. Acc: 0.543496. Loss: 1.260846. Batch_acc: 0.531014. Batch_loss: 1.298537 \n",
      "Batch: 2280. Acc: 0.543510. Loss: 1.260820. Batch_acc: 0.574492. Batch_loss: 1.202111 \n",
      "Batch: 2281. Acc: 0.543507. Loss: 1.260825. Batch_acc: 0.535195. Batch_loss: 1.273002 \n",
      "Batch: 2282. Acc: 0.543500. Loss: 1.260848. Batch_acc: 0.528662. Batch_loss: 1.313202 \n",
      "Batch: 2283. Acc: 0.543482. Loss: 1.260896. Batch_acc: 0.501159. Batch_loss: 1.371597 \n",
      "Batch: 2284. Acc: 0.543484. Loss: 1.260900. Batch_acc: 0.548292. Batch_loss: 1.270932 \n",
      "Batch: 2285. Acc: 0.543487. Loss: 1.260904. Batch_acc: 0.550379. Batch_loss: 1.268412 \n",
      "Batch: 2286. Acc: 0.543489. Loss: 1.260897. Batch_acc: 0.548110. Batch_loss: 1.246351 \n",
      "Batch: 2287. Acc: 0.543492. Loss: 1.260897. Batch_acc: 0.549884. Batch_loss: 1.259975 \n",
      "Batch: 2288. Acc: 0.543491. Loss: 1.260897. Batch_acc: 0.541449. Batch_loss: 1.260613 \n",
      "Batch: 2289. Acc: 0.543482. Loss: 1.260905. Batch_acc: 0.522371. Batch_loss: 1.281332 \n",
      "Batch: 2290. Acc: 0.543485. Loss: 1.260900. Batch_acc: 0.550633. Batch_loss: 1.249045 \n",
      "Batch: 2291. Acc: 0.543498. Loss: 1.260857. Batch_acc: 0.574001. Batch_loss: 1.164252 \n",
      "Batch: 2292. Acc: 0.543506. Loss: 1.260845. Batch_acc: 0.560907. Batch_loss: 1.232981 \n",
      "Batch: 2293. Acc: 0.543513. Loss: 1.260823. Batch_acc: 0.559622. Batch_loss: 1.208801 \n",
      "Batch: 2294. Acc: 0.543503. Loss: 1.260852. Batch_acc: 0.520161. Batch_loss: 1.328315 \n",
      "Batch: 2295. Acc: 0.543518. Loss: 1.260814. Batch_acc: 0.578580. Batch_loss: 1.172019 \n",
      "Batch: 2296. Acc: 0.543521. Loss: 1.260798. Batch_acc: 0.551245. Batch_loss: 1.223090 \n",
      "Batch: 2297. Acc: 0.543522. Loss: 1.260807. Batch_acc: 0.545987. Batch_loss: 1.282158 \n",
      "Batch: 2298. Acc: 0.543525. Loss: 1.260793. Batch_acc: 0.548591. Batch_loss: 1.229123 \n",
      "Batch: 2299. Acc: 0.543537. Loss: 1.260768. Batch_acc: 0.572480. Batch_loss: 1.204985 \n",
      "Batch: 2300. Acc: 0.543529. Loss: 1.260794. Batch_acc: 0.523895. Batch_loss: 1.321261 \n",
      "Batch: 2301. Acc: 0.543531. Loss: 1.260792. Batch_acc: 0.548514. Batch_loss: 1.257036 \n",
      "Batch: 2302. Acc: 0.543527. Loss: 1.260813. Batch_acc: 0.534104. Batch_loss: 1.310712 \n",
      "Batch: 2303. Acc: 0.543531. Loss: 1.260805. Batch_acc: 0.552975. Batch_loss: 1.241386 \n",
      "Batch: 2304. Acc: 0.543536. Loss: 1.260794. Batch_acc: 0.553532. Batch_loss: 1.237428 \n",
      "Batch: 2305. Acc: 0.543533. Loss: 1.260794. Batch_acc: 0.536782. Batch_loss: 1.259099 \n",
      "Batch: 2306. Acc: 0.543542. Loss: 1.260766. Batch_acc: 0.564117. Batch_loss: 1.197084 \n",
      "Batch: 2307. Acc: 0.543547. Loss: 1.260747. Batch_acc: 0.554665. Batch_loss: 1.217963 \n",
      "Batch: 2308. Acc: 0.543549. Loss: 1.260732. Batch_acc: 0.549771. Batch_loss: 1.224746 \n",
      "Batch: 2309. Acc: 0.543552. Loss: 1.260731. Batch_acc: 0.549451. Batch_loss: 1.259862 \n",
      "Batch: 2310. Acc: 0.543554. Loss: 1.260724. Batch_acc: 0.548603. Batch_loss: 1.244810 \n",
      "Batch: 2311. Acc: 0.543555. Loss: 1.260732. Batch_acc: 0.546136. Batch_loss: 1.278898 \n",
      "Batch: 2312. Acc: 0.543555. Loss: 1.260736. Batch_acc: 0.543620. Batch_loss: 1.270247 \n",
      "Batch: 2313. Acc: 0.543554. Loss: 1.260737. Batch_acc: 0.540650. Batch_loss: 1.262222 \n",
      "Batch: 2314. Acc: 0.543551. Loss: 1.260746. Batch_acc: 0.537253. Batch_loss: 1.281945 \n",
      "Batch: 2315. Acc: 0.543543. Loss: 1.260763. Batch_acc: 0.522914. Batch_loss: 1.301220 \n",
      "Batch: 2316. Acc: 0.543537. Loss: 1.260777. Batch_acc: 0.531019. Batch_loss: 1.292534 \n",
      "Batch: 2317. Acc: 0.543534. Loss: 1.260779. Batch_acc: 0.535388. Batch_loss: 1.266792 \n",
      "Batch: 2318. Acc: 0.543543. Loss: 1.260745. Batch_acc: 0.565017. Batch_loss: 1.180859 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2319. Acc: 0.543553. Loss: 1.260715. Batch_acc: 0.565463. Batch_loss: 1.193424 \n",
      "Batch: 2320. Acc: 0.543545. Loss: 1.260737. Batch_acc: 0.526072. Batch_loss: 1.312133 \n",
      "Batch: 2321. Acc: 0.543548. Loss: 1.260741. Batch_acc: 0.550432. Batch_loss: 1.269591 \n",
      "Batch: 2322. Acc: 0.543558. Loss: 1.260715. Batch_acc: 0.566705. Batch_loss: 1.199742 \n",
      "Batch: 2323. Acc: 0.543562. Loss: 1.260700. Batch_acc: 0.552647. Batch_loss: 1.224816 \n",
      "Batch: 2324. Acc: 0.543567. Loss: 1.260675. Batch_acc: 0.555620. Batch_loss: 1.203675 \n",
      "Batch: 2325. Acc: 0.543573. Loss: 1.260645. Batch_acc: 0.557461. Batch_loss: 1.190921 \n",
      "Batch: 2326. Acc: 0.543577. Loss: 1.260634. Batch_acc: 0.551843. Batch_loss: 1.234445 \n",
      "Batch: 2327. Acc: 0.543577. Loss: 1.260635. Batch_acc: 0.545297. Batch_loss: 1.262435 \n",
      "Batch: 2328. Acc: 0.543586. Loss: 1.260614. Batch_acc: 0.562710. Batch_loss: 1.212752 \n",
      "Batch: 2329. Acc: 0.543584. Loss: 1.260621. Batch_acc: 0.540138. Batch_loss: 1.277651 \n",
      "Batch: 2330. Acc: 0.543592. Loss: 1.260589. Batch_acc: 0.562354. Batch_loss: 1.185378 \n",
      "Batch: 2331. Acc: 0.543583. Loss: 1.260610. Batch_acc: 0.522440. Batch_loss: 1.309232 \n",
      "Batch: 2332. Acc: 0.543593. Loss: 1.260585. Batch_acc: 0.565072. Batch_loss: 1.205535 \n",
      "Batch: 2333. Acc: 0.543600. Loss: 1.260563. Batch_acc: 0.560114. Batch_loss: 1.207811 \n",
      "Batch: 2334. Acc: 0.543608. Loss: 1.260547. Batch_acc: 0.563063. Batch_loss: 1.225538 \n",
      "Batch: 2335. Acc: 0.543614. Loss: 1.260529. Batch_acc: 0.557078. Batch_loss: 1.217423 \n",
      "Batch: 2336. Acc: 0.543621. Loss: 1.260518. Batch_acc: 0.560255. Batch_loss: 1.236322 \n",
      "Batch: 2337. Acc: 0.543630. Loss: 1.260494. Batch_acc: 0.565473. Batch_loss: 1.201806 \n",
      "Batch: 2338. Acc: 0.543619. Loss: 1.260517. Batch_acc: 0.518135. Batch_loss: 1.313740 \n",
      "Batch: 2339. Acc: 0.543616. Loss: 1.260513. Batch_acc: 0.535203. Batch_loss: 1.252609 \n",
      "Batch: 2340. Acc: 0.543621. Loss: 1.260501. Batch_acc: 0.555682. Batch_loss: 1.231051 \n",
      "Batch: 2341. Acc: 0.543629. Loss: 1.260479. Batch_acc: 0.563112. Batch_loss: 1.210755 \n",
      "Batch: 2342. Acc: 0.543634. Loss: 1.260476. Batch_acc: 0.554572. Batch_loss: 1.252572 \n",
      "Batch: 2343. Acc: 0.543628. Loss: 1.260489. Batch_acc: 0.529786. Batch_loss: 1.292065 \n",
      "Batch: 2344. Acc: 0.543629. Loss: 1.260479. Batch_acc: 0.546573. Batch_loss: 1.235433 \n",
      "Batch: 2345. Acc: 0.543633. Loss: 1.260475. Batch_acc: 0.551704. Batch_loss: 1.250904 \n",
      "Batch: 2346. Acc: 0.543640. Loss: 1.260453. Batch_acc: 0.560658. Batch_loss: 1.210186 \n",
      "Batch: 2347. Acc: 0.543638. Loss: 1.260459. Batch_acc: 0.538018. Batch_loss: 1.274078 \n",
      "Batch: 2348. Acc: 0.543645. Loss: 1.260442. Batch_acc: 0.561114. Batch_loss: 1.221177 \n",
      "Batch: 2349. Acc: 0.543653. Loss: 1.260431. Batch_acc: 0.562209. Batch_loss: 1.233785 \n",
      "Batch: 2350. Acc: 0.543669. Loss: 1.260394. Batch_acc: 0.579571. Batch_loss: 1.175673 \n",
      "Batch: 2351. Acc: 0.543671. Loss: 1.260386. Batch_acc: 0.549464. Batch_loss: 1.240692 \n",
      "Batch: 2352. Acc: 0.543676. Loss: 1.260377. Batch_acc: 0.555430. Batch_loss: 1.239580 \n",
      "Batch: 2353. Acc: 0.543679. Loss: 1.260370. Batch_acc: 0.550265. Batch_loss: 1.243647 \n",
      "Batch: 2354. Acc: 0.543683. Loss: 1.260356. Batch_acc: 0.552921. Batch_loss: 1.226105 \n",
      "Batch: 2355. Acc: 0.543676. Loss: 1.260368. Batch_acc: 0.527939. Batch_loss: 1.290315 \n",
      "Batch: 2356. Acc: 0.543674. Loss: 1.260363. Batch_acc: 0.539221. Batch_loss: 1.249122 \n",
      "Batch: 2357. Acc: 0.543672. Loss: 1.260369. Batch_acc: 0.539294. Batch_loss: 1.273288 \n",
      "Batch: 2358. Acc: 0.543674. Loss: 1.260364. Batch_acc: 0.547756. Batch_loss: 1.248998 \n",
      "Batch: 2359. Acc: 0.543683. Loss: 1.260348. Batch_acc: 0.564339. Batch_loss: 1.221773 \n",
      "Batch: 2360. Acc: 0.543688. Loss: 1.260326. Batch_acc: 0.556636. Batch_loss: 1.209982 \n",
      "Batch: 2361. Acc: 0.543694. Loss: 1.260311. Batch_acc: 0.557432. Batch_loss: 1.224161 \n",
      "Batch: 2362. Acc: 0.543702. Loss: 1.260307. Batch_acc: 0.561668. Batch_loss: 1.252452 \n",
      "Batch: 2363. Acc: 0.543709. Loss: 1.260299. Batch_acc: 0.560345. Batch_loss: 1.240339 \n",
      "Batch: 2364. Acc: 0.543706. Loss: 1.260308. Batch_acc: 0.537874. Batch_loss: 1.282153 \n",
      "Batch: 2365. Acc: 0.543706. Loss: 1.260301. Batch_acc: 0.542578. Batch_loss: 1.243320 \n",
      "Batch: 2366. Acc: 0.543710. Loss: 1.260284. Batch_acc: 0.553095. Batch_loss: 1.220580 \n",
      "Batch: 2367. Acc: 0.543712. Loss: 1.260263. Batch_acc: 0.549476. Batch_loss: 1.211012 \n",
      "Batch: 2368. Acc: 0.543716. Loss: 1.260245. Batch_acc: 0.552982. Batch_loss: 1.217456 \n",
      "Batch: 2369. Acc: 0.543720. Loss: 1.260237. Batch_acc: 0.551471. Batch_loss: 1.240813 \n",
      "Batch: 2370. Acc: 0.543729. Loss: 1.260217. Batch_acc: 0.565598. Batch_loss: 1.211836 \n",
      "Batch: 2371. Acc: 0.543738. Loss: 1.260187. Batch_acc: 0.564452. Batch_loss: 1.190897 \n",
      "Batch: 2372. Acc: 0.543739. Loss: 1.260184. Batch_acc: 0.546989. Batch_loss: 1.251765 \n",
      "Batch: 2373. Acc: 0.543749. Loss: 1.260148. Batch_acc: 0.566312. Batch_loss: 1.178592 \n",
      "Batch: 2374. Acc: 0.543751. Loss: 1.260132. Batch_acc: 0.549304. Batch_loss: 1.220683 \n",
      "Batch: 2375. Acc: 0.543752. Loss: 1.260123. Batch_acc: 0.545824. Batch_loss: 1.238954 \n",
      "Batch: 2376. Acc: 0.543754. Loss: 1.260106. Batch_acc: 0.549344. Batch_loss: 1.219938 \n",
      "Batch: 2377. Acc: 0.543761. Loss: 1.260090. Batch_acc: 0.559792. Batch_loss: 1.222191 \n",
      "Batch: 2378. Acc: 0.543760. Loss: 1.260085. Batch_acc: 0.541264. Batch_loss: 1.249004 \n",
      "Batch: 2379. Acc: 0.543759. Loss: 1.260089. Batch_acc: 0.541667. Batch_loss: 1.268706 \n",
      "Batch: 2380. Acc: 0.543762. Loss: 1.260079. Batch_acc: 0.549913. Batch_loss: 1.236273 \n",
      "Batch: 2381. Acc: 0.543754. Loss: 1.260114. Batch_acc: 0.525852. Batch_loss: 1.345382 \n",
      "Batch: 2382. Acc: 0.543756. Loss: 1.260106. Batch_acc: 0.547660. Batch_loss: 1.241243 \n",
      "Batch: 2383. Acc: 0.543764. Loss: 1.260086. Batch_acc: 0.563251. Batch_loss: 1.211735 \n",
      "Batch: 2384. Acc: 0.543765. Loss: 1.260086. Batch_acc: 0.545401. Batch_loss: 1.260264 \n",
      "Batch: 2385. Acc: 0.543758. Loss: 1.260100. Batch_acc: 0.527682. Batch_loss: 1.294354 \n",
      "Batch: 2386. Acc: 0.543754. Loss: 1.260122. Batch_acc: 0.533711. Batch_loss: 1.313105 \n",
      "Batch: 2387. Acc: 0.543757. Loss: 1.260121. Batch_acc: 0.550374. Batch_loss: 1.257098 \n",
      "Batch: 2388. Acc: 0.543768. Loss: 1.260094. Batch_acc: 0.570693. Batch_loss: 1.196414 \n",
      "Batch: 2389. Acc: 0.543768. Loss: 1.260081. Batch_acc: 0.543921. Batch_loss: 1.227798 \n",
      "Batch: 2390. Acc: 0.543759. Loss: 1.260098. Batch_acc: 0.521562. Batch_loss: 1.301610 \n",
      "Batch: 2391. Acc: 0.543766. Loss: 1.260066. Batch_acc: 0.560446. Batch_loss: 1.182062 \n",
      "Batch: 2392. Acc: 0.543768. Loss: 1.260054. Batch_acc: 0.549943. Batch_loss: 1.231425 \n",
      "Batch: 2393. Acc: 0.543772. Loss: 1.260042. Batch_acc: 0.551906. Batch_loss: 1.230228 \n",
      "Batch: 2394. Acc: 0.543775. Loss: 1.260029. Batch_acc: 0.551078. Batch_loss: 1.228826 \n",
      "Batch: 2395. Acc: 0.543777. Loss: 1.260028. Batch_acc: 0.550231. Batch_loss: 1.258103 \n",
      "Batch: 2396. Acc: 0.543784. Loss: 1.260002. Batch_acc: 0.558723. Batch_loss: 1.198930 \n",
      "Batch: 2397. Acc: 0.543787. Loss: 1.259990. Batch_acc: 0.551103. Batch_loss: 1.229921 \n",
      "Batch: 2398. Acc: 0.543790. Loss: 1.259992. Batch_acc: 0.551887. Batch_loss: 1.266323 \n",
      "Batch: 2399. Acc: 0.543795. Loss: 1.259985. Batch_acc: 0.556527. Batch_loss: 1.241760 \n",
      "Batch: 2400. Acc: 0.543798. Loss: 1.259989. Batch_acc: 0.550929. Batch_loss: 1.269997 \n",
      "Batch: 2401. Acc: 0.543789. Loss: 1.260020. Batch_acc: 0.520604. Batch_loss: 1.335355 \n",
      "Batch: 2402. Acc: 0.543778. Loss: 1.260046. Batch_acc: 0.518349. Batch_loss: 1.321696 \n",
      "Batch: 2403. Acc: 0.543783. Loss: 1.260035. Batch_acc: 0.554861. Batch_loss: 1.233719 \n",
      "Batch: 2404. Acc: 0.543790. Loss: 1.260025. Batch_acc: 0.562140. Batch_loss: 1.236970 \n",
      "Batch: 2405. Acc: 0.543785. Loss: 1.260034. Batch_acc: 0.531829. Batch_loss: 1.281056 \n",
      "Batch: 2406. Acc: 0.543798. Loss: 1.260006. Batch_acc: 0.573854. Batch_loss: 1.193315 \n",
      "Batch: 2407. Acc: 0.543799. Loss: 1.260020. Batch_acc: 0.546064. Batch_loss: 1.292901 \n",
      "Batch: 2408. Acc: 0.543800. Loss: 1.260013. Batch_acc: 0.547083. Batch_loss: 1.244229 \n",
      "Batch: 2409. Acc: 0.543809. Loss: 1.259992. Batch_acc: 0.564087. Batch_loss: 1.207350 \n",
      "Batch: 2410. Acc: 0.543815. Loss: 1.259975. Batch_acc: 0.558478. Batch_loss: 1.219466 \n",
      "Batch: 2411. Acc: 0.543810. Loss: 1.259981. Batch_acc: 0.531579. Batch_loss: 1.274858 \n",
      "Batch: 2412. Acc: 0.543814. Loss: 1.259982. Batch_acc: 0.552392. Batch_loss: 1.263038 \n",
      "Batch: 2413. Acc: 0.543827. Loss: 1.259942. Batch_acc: 0.574758. Batch_loss: 1.164153 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2414. Acc: 0.543826. Loss: 1.259936. Batch_acc: 0.542237. Batch_loss: 1.244938 \n",
      "Batch: 2415. Acc: 0.543826. Loss: 1.259926. Batch_acc: 0.543416. Batch_loss: 1.235942 \n",
      "Batch: 2416. Acc: 0.543828. Loss: 1.259924. Batch_acc: 0.549943. Batch_loss: 1.254925 \n",
      "Batch: 2417. Acc: 0.543828. Loss: 1.259923. Batch_acc: 0.543453. Batch_loss: 1.257257 \n",
      "Batch: 2418. Acc: 0.543833. Loss: 1.259902. Batch_acc: 0.554791. Batch_loss: 1.209987 \n",
      "Batch: 2419. Acc: 0.543837. Loss: 1.259885. Batch_acc: 0.553961. Batch_loss: 1.219958 \n",
      "Batch: 2420. Acc: 0.543832. Loss: 1.259885. Batch_acc: 0.532694. Batch_loss: 1.258589 \n",
      "Batch: 2421. Acc: 0.543834. Loss: 1.259885. Batch_acc: 0.549369. Batch_loss: 1.261206 \n",
      "Batch: 2422. Acc: 0.543838. Loss: 1.259878. Batch_acc: 0.552359. Batch_loss: 1.242840 \n",
      "Batch: 2423. Acc: 0.543841. Loss: 1.259871. Batch_acc: 0.551744. Batch_loss: 1.241941 \n",
      "Batch: 2424. Acc: 0.543852. Loss: 1.259837. Batch_acc: 0.568694. Batch_loss: 1.178172 \n",
      "Batch: 2425. Acc: 0.543863. Loss: 1.259803. Batch_acc: 0.572082. Batch_loss: 1.177496 \n",
      "Batch: 2426. Acc: 0.543863. Loss: 1.259795. Batch_acc: 0.543466. Batch_loss: 1.242237 \n",
      "Batch: 2427. Acc: 0.543857. Loss: 1.259798. Batch_acc: 0.528109. Batch_loss: 1.265384 \n",
      "Batch: 2428. Acc: 0.543864. Loss: 1.259774. Batch_acc: 0.560892. Batch_loss: 1.202260 \n",
      "Batch: 2429. Acc: 0.543875. Loss: 1.259743. Batch_acc: 0.572581. Batch_loss: 1.185838 \n",
      "Batch: 2430. Acc: 0.543879. Loss: 1.259727. Batch_acc: 0.551982. Batch_loss: 1.219901 \n",
      "Batch: 2431. Acc: 0.543879. Loss: 1.259725. Batch_acc: 0.543667. Batch_loss: 1.254130 \n",
      "Batch: 2432. Acc: 0.543879. Loss: 1.259732. Batch_acc: 0.544230. Batch_loss: 1.278357 \n",
      "Batch: 2433. Acc: 0.543892. Loss: 1.259703. Batch_acc: 0.575568. Batch_loss: 1.189373 \n",
      "Batch: 2434. Acc: 0.543891. Loss: 1.259712. Batch_acc: 0.540974. Batch_loss: 1.280537 \n",
      "Batch: 2435. Acc: 0.543897. Loss: 1.259697. Batch_acc: 0.558449. Batch_loss: 1.223552 \n",
      "Batch: 2436. Acc: 0.543898. Loss: 1.259696. Batch_acc: 0.548088. Batch_loss: 1.257192 \n",
      "Batch: 2437. Acc: 0.543909. Loss: 1.259668. Batch_acc: 0.570379. Batch_loss: 1.194255 \n",
      "Batch: 2438. Acc: 0.543908. Loss: 1.259671. Batch_acc: 0.540309. Batch_loss: 1.266556 \n",
      "Batch: 2439. Acc: 0.543912. Loss: 1.259654. Batch_acc: 0.554732. Batch_loss: 1.218511 \n",
      "Batch: 2440. Acc: 0.543914. Loss: 1.259646. Batch_acc: 0.547914. Batch_loss: 1.239943 \n",
      "Batch: 2441. Acc: 0.543917. Loss: 1.259641. Batch_acc: 0.549741. Batch_loss: 1.247906 \n",
      "Batch: 2442. Acc: 0.543917. Loss: 1.259643. Batch_acc: 0.544664. Batch_loss: 1.264497 \n",
      "Batch: 2443. Acc: 0.543924. Loss: 1.259630. Batch_acc: 0.560753. Batch_loss: 1.227066 \n",
      "Batch: 2444. Acc: 0.543923. Loss: 1.259630. Batch_acc: 0.542640. Batch_loss: 1.258994 \n",
      "Batch: 2445. Acc: 0.543925. Loss: 1.259631. Batch_acc: 0.547062. Batch_loss: 1.262563 \n",
      "Batch: 2446. Acc: 0.543934. Loss: 1.259609. Batch_acc: 0.565685. Batch_loss: 1.208326 \n",
      "Batch: 2447. Acc: 0.543944. Loss: 1.259577. Batch_acc: 0.567950. Batch_loss: 1.181577 \n",
      "Batch: 2448. Acc: 0.543950. Loss: 1.259563. Batch_acc: 0.559371. Batch_loss: 1.224275 \n",
      "Batch: 2449. Acc: 0.543948. Loss: 1.259570. Batch_acc: 0.540284. Batch_loss: 1.278123 \n",
      "Batch: 2450. Acc: 0.543951. Loss: 1.259563. Batch_acc: 0.550626. Batch_loss: 1.241332 \n",
      "Batch: 2451. Acc: 0.543960. Loss: 1.259546. Batch_acc: 0.566279. Batch_loss: 1.219128 \n",
      "Batch: 2452. Acc: 0.543966. Loss: 1.259522. Batch_acc: 0.558841. Batch_loss: 1.199352 \n",
      "Batch: 2453. Acc: 0.543956. Loss: 1.259552. Batch_acc: 0.519534. Batch_loss: 1.333664 \n",
      "Batch: 2454. Acc: 0.543955. Loss: 1.259546. Batch_acc: 0.541716. Batch_loss: 1.246254 \n",
      "Batch: 2455. Acc: 0.543945. Loss: 1.259579. Batch_acc: 0.518779. Batch_loss: 1.340034 \n",
      "Batch: 2456. Acc: 0.543945. Loss: 1.259566. Batch_acc: 0.543491. Batch_loss: 1.227232 \n",
      "Batch: 2457. Acc: 0.543942. Loss: 1.259572. Batch_acc: 0.537279. Batch_loss: 1.275856 \n",
      "Batch: 2458. Acc: 0.543952. Loss: 1.259557. Batch_acc: 0.568023. Batch_loss: 1.220751 \n",
      "Batch: 2459. Acc: 0.543956. Loss: 1.259545. Batch_acc: 0.552480. Batch_loss: 1.229669 \n",
      "Batch: 2460. Acc: 0.543960. Loss: 1.259526. Batch_acc: 0.555814. Batch_loss: 1.213977 \n",
      "Batch: 2461. Acc: 0.543965. Loss: 1.259514. Batch_acc: 0.555364. Batch_loss: 1.230664 \n",
      "Batch: 2462. Acc: 0.543965. Loss: 1.259503. Batch_acc: 0.543099. Batch_loss: 1.231205 \n",
      "Batch: 2463. Acc: 0.543976. Loss: 1.259475. Batch_acc: 0.571111. Batch_loss: 1.194472 \n",
      "Batch: 2464. Acc: 0.543981. Loss: 1.259455. Batch_acc: 0.555059. Batch_loss: 1.211105 \n",
      "Batch: 2465. Acc: 0.543982. Loss: 1.259453. Batch_acc: 0.546734. Batch_loss: 1.253494 \n",
      "Batch: 2466. Acc: 0.543993. Loss: 1.259423. Batch_acc: 0.571509. Batch_loss: 1.188479 \n",
      "Batch: 2467. Acc: 0.543999. Loss: 1.259403. Batch_acc: 0.557858. Batch_loss: 1.208302 \n",
      "Batch: 2468. Acc: 0.543987. Loss: 1.259421. Batch_acc: 0.515205. Batch_loss: 1.305593 \n",
      "Batch: 2469. Acc: 0.543987. Loss: 1.259415. Batch_acc: 0.543478. Batch_loss: 1.244113 \n",
      "Batch: 2470. Acc: 0.543981. Loss: 1.259418. Batch_acc: 0.528596. Batch_loss: 1.267988 \n",
      "Batch: 2471. Acc: 0.543985. Loss: 1.259417. Batch_acc: 0.553009. Batch_loss: 1.255463 \n",
      "Batch: 2472. Acc: 0.543981. Loss: 1.259424. Batch_acc: 0.534512. Batch_loss: 1.278273 \n",
      "Batch: 2473. Acc: 0.543987. Loss: 1.259409. Batch_acc: 0.560296. Batch_loss: 1.222112 \n",
      "Batch: 2474. Acc: 0.543983. Loss: 1.259414. Batch_acc: 0.531631. Batch_loss: 1.270551 \n",
      "Batch: 2475. Acc: 0.543984. Loss: 1.259402. Batch_acc: 0.546758. Batch_loss: 1.230687 \n",
      "Batch: 2476. Acc: 0.543990. Loss: 1.259391. Batch_acc: 0.559109. Batch_loss: 1.231186 \n",
      "Batch: 2477. Acc: 0.543997. Loss: 1.259368. Batch_acc: 0.560408. Batch_loss: 1.203401 \n",
      "Batch: 2478. Acc: 0.544005. Loss: 1.259344. Batch_acc: 0.565744. Batch_loss: 1.201922 \n",
      "Batch: 2479. Acc: 0.544005. Loss: 1.259352. Batch_acc: 0.543706. Batch_loss: 1.279201 \n",
      "Batch: 2480. Acc: 0.544012. Loss: 1.259336. Batch_acc: 0.560296. Batch_loss: 1.218802 \n",
      "Batch: 2481. Acc: 0.544023. Loss: 1.259306. Batch_acc: 0.571016. Batch_loss: 1.184533 \n",
      "Batch: 2482. Acc: 0.544028. Loss: 1.259295. Batch_acc: 0.556969. Batch_loss: 1.231833 \n",
      "Batch: 2483. Acc: 0.544032. Loss: 1.259283. Batch_acc: 0.553890. Batch_loss: 1.230771 \n",
      "Batch: 2484. Acc: 0.544041. Loss: 1.259267. Batch_acc: 0.567384. Batch_loss: 1.220342 \n",
      "Batch: 2485. Acc: 0.544041. Loss: 1.259268. Batch_acc: 0.542596. Batch_loss: 1.261798 \n",
      "Batch: 2486. Acc: 0.544050. Loss: 1.259235. Batch_acc: 0.567063. Batch_loss: 1.178293 \n",
      "Batch: 2487. Acc: 0.544057. Loss: 1.259216. Batch_acc: 0.561179. Batch_loss: 1.211694 \n",
      "Batch: 2488. Acc: 0.544063. Loss: 1.259207. Batch_acc: 0.559697. Batch_loss: 1.237996 \n",
      "Batch: 2489. Acc: 0.544071. Loss: 1.259187. Batch_acc: 0.563574. Batch_loss: 1.208591 \n",
      "Batch: 2490. Acc: 0.544074. Loss: 1.259170. Batch_acc: 0.550926. Batch_loss: 1.218214 \n",
      "Batch: 2491. Acc: 0.544069. Loss: 1.259190. Batch_acc: 0.531378. Batch_loss: 1.309087 \n",
      "Batch: 2492. Acc: 0.544071. Loss: 1.259196. Batch_acc: 0.547836. Batch_loss: 1.273441 \n",
      "Batch: 2493. Acc: 0.544077. Loss: 1.259171. Batch_acc: 0.560458. Batch_loss: 1.197907 \n",
      "Batch: 2494. Acc: 0.544089. Loss: 1.259138. Batch_acc: 0.573046. Batch_loss: 1.176943 \n",
      "Batch: 2495. Acc: 0.544094. Loss: 1.259127. Batch_acc: 0.557200. Batch_loss: 1.231993 \n",
      "Batch: 2496. Acc: 0.544103. Loss: 1.259097. Batch_acc: 0.565569. Batch_loss: 1.185356 \n",
      "Batch: 2497. Acc: 0.544100. Loss: 1.259097. Batch_acc: 0.536817. Batch_loss: 1.257533 \n",
      "Batch: 2498. Acc: 0.544106. Loss: 1.259093. Batch_acc: 0.558924. Batch_loss: 1.250918 \n",
      "Batch: 2499. Acc: 0.544111. Loss: 1.259082. Batch_acc: 0.556177. Batch_loss: 1.232016 \n",
      "Batch: 2500. Acc: 0.544107. Loss: 1.259084. Batch_acc: 0.535093. Batch_loss: 1.264104 \n",
      "Batch: 2501. Acc: 0.544119. Loss: 1.259053. Batch_acc: 0.572674. Batch_loss: 1.179669 \n",
      "Batch: 2502. Acc: 0.544123. Loss: 1.259055. Batch_acc: 0.554850. Batch_loss: 1.264391 \n",
      "Batch: 2503. Acc: 0.544132. Loss: 1.259042. Batch_acc: 0.567251. Batch_loss: 1.225648 \n",
      "Batch: 2504. Acc: 0.544124. Loss: 1.259069. Batch_acc: 0.524561. Batch_loss: 1.327143 \n",
      "Batch: 2505. Acc: 0.544120. Loss: 1.259070. Batch_acc: 0.533888. Batch_loss: 1.262532 \n",
      "Batch: 2506. Acc: 0.544120. Loss: 1.259071. Batch_acc: 0.542614. Batch_loss: 1.261265 \n",
      "Batch: 2507. Acc: 0.544119. Loss: 1.259065. Batch_acc: 0.541375. Batch_loss: 1.243380 \n",
      "Batch: 2508. Acc: 0.544130. Loss: 1.259041. Batch_acc: 0.572165. Batch_loss: 1.200229 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2509. Acc: 0.544126. Loss: 1.259056. Batch_acc: 0.535447. Batch_loss: 1.296337 \n",
      "Batch: 2510. Acc: 0.544129. Loss: 1.259063. Batch_acc: 0.549482. Batch_loss: 1.277771 \n",
      "Checkpointing on batch: 2510. Accuracy: 0.544128532361611. Loss per char: 1.2590634264991167. Time: 1627223802.7110438\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 14, 19, 20, 18, 24, 19, 20, 24,\n",
      "        24, 15, 26, 20, 22, 22, 20,  1, 71, 83, 80, 78,  1, 18, 21, 18, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2511. Acc: 0.544127. Loss: 1.259065. Batch_acc: 0.540495. Batch_loss: 1.262714 \n",
      "Batch: 2512. Acc: 0.544122. Loss: 1.259076. Batch_acc: 0.532191. Batch_loss: 1.286969 \n",
      "Batch: 2513. Acc: 0.544138. Loss: 1.259044. Batch_acc: 0.582815. Batch_loss: 1.181871 \n",
      "Batch: 2514. Acc: 0.544149. Loss: 1.259021. Batch_acc: 0.572082. Batch_loss: 1.201549 \n",
      "Batch: 2515. Acc: 0.544138. Loss: 1.259050. Batch_acc: 0.516393. Batch_loss: 1.330896 \n",
      "Batch: 2516. Acc: 0.544139. Loss: 1.259037. Batch_acc: 0.545455. Batch_loss: 1.226349 \n",
      "Batch: 2517. Acc: 0.544133. Loss: 1.259040. Batch_acc: 0.529479. Batch_loss: 1.267244 \n",
      "Batch: 2518. Acc: 0.544137. Loss: 1.259023. Batch_acc: 0.554983. Batch_loss: 1.217236 \n",
      "Batch: 2519. Acc: 0.544139. Loss: 1.259022. Batch_acc: 0.549031. Batch_loss: 1.255614 \n",
      "Batch: 2520. Acc: 0.544149. Loss: 1.258983. Batch_acc: 0.569213. Batch_loss: 1.160821 \n",
      "Batch: 2521. Acc: 0.544147. Loss: 1.258992. Batch_acc: 0.538593. Batch_loss: 1.282195 \n",
      "Batch: 2522. Acc: 0.544146. Loss: 1.258998. Batch_acc: 0.540525. Batch_loss: 1.274478 \n",
      "Batch: 2523. Acc: 0.544146. Loss: 1.258999. Batch_acc: 0.545877. Batch_loss: 1.261402 \n",
      "Batch: 2524. Acc: 0.544142. Loss: 1.259010. Batch_acc: 0.534262. Batch_loss: 1.286617 \n",
      "Batch: 2525. Acc: 0.544142. Loss: 1.259016. Batch_acc: 0.542277. Batch_loss: 1.274298 \n",
      "Batch: 2526. Acc: 0.544147. Loss: 1.259002. Batch_acc: 0.558944. Batch_loss: 1.223521 \n",
      "Batch: 2527. Acc: 0.544153. Loss: 1.258990. Batch_acc: 0.559042. Batch_loss: 1.229227 \n",
      "Batch: 2528. Acc: 0.544156. Loss: 1.258980. Batch_acc: 0.551587. Batch_loss: 1.232349 \n",
      "Batch: 2529. Acc: 0.544157. Loss: 1.258977. Batch_acc: 0.546281. Batch_loss: 1.253107 \n",
      "Batch: 2530. Acc: 0.544158. Loss: 1.258980. Batch_acc: 0.546742. Batch_loss: 1.264499 \n",
      "Batch: 2531. Acc: 0.544166. Loss: 1.258960. Batch_acc: 0.562286. Batch_loss: 1.208875 \n",
      "Batch: 2532. Acc: 0.544172. Loss: 1.258944. Batch_acc: 0.560606. Batch_loss: 1.219545 \n",
      "Batch: 2533. Acc: 0.544177. Loss: 1.258934. Batch_acc: 0.556447. Batch_loss: 1.233092 \n",
      "Batch: 2534. Acc: 0.544175. Loss: 1.258944. Batch_acc: 0.538643. Batch_loss: 1.284008 \n",
      "Batch: 2535. Acc: 0.544169. Loss: 1.258950. Batch_acc: 0.528935. Batch_loss: 1.274799 \n",
      "Batch: 2536. Acc: 0.544162. Loss: 1.258967. Batch_acc: 0.527460. Batch_loss: 1.301268 \n",
      "Batch: 2537. Acc: 0.544168. Loss: 1.258951. Batch_acc: 0.560046. Batch_loss: 1.219174 \n",
      "Batch: 2538. Acc: 0.544179. Loss: 1.258924. Batch_acc: 0.571596. Batch_loss: 1.189781 \n",
      "Batch: 2539. Acc: 0.544181. Loss: 1.258914. Batch_acc: 0.549885. Batch_loss: 1.232553 \n",
      "Batch: 2540. Acc: 0.544177. Loss: 1.258923. Batch_acc: 0.533489. Batch_loss: 1.281479 \n",
      "Batch: 2541. Acc: 0.544187. Loss: 1.258891. Batch_acc: 0.569548. Batch_loss: 1.178358 \n",
      "Batch: 2542. Acc: 0.544186. Loss: 1.258901. Batch_acc: 0.541225. Batch_loss: 1.284152 \n",
      "Batch: 2543. Acc: 0.544180. Loss: 1.258903. Batch_acc: 0.528446. Batch_loss: 1.266347 \n",
      "Batch: 2544. Acc: 0.544183. Loss: 1.258893. Batch_acc: 0.553314. Batch_loss: 1.232345 \n",
      "Batch: 2545. Acc: 0.544190. Loss: 1.258875. Batch_acc: 0.560580. Batch_loss: 1.213055 \n",
      "Batch: 2546. Acc: 0.544186. Loss: 1.258889. Batch_acc: 0.535406. Batch_loss: 1.295503 \n",
      "Batch: 2547. Acc: 0.544180. Loss: 1.258900. Batch_acc: 0.529212. Batch_loss: 1.286082 \n",
      "Batch: 2548. Acc: 0.544179. Loss: 1.258894. Batch_acc: 0.541068. Batch_loss: 1.241863 \n",
      "Batch: 2549. Acc: 0.544174. Loss: 1.258895. Batch_acc: 0.531616. Batch_loss: 1.262594 \n",
      "Batch: 2550. Acc: 0.544181. Loss: 1.258873. Batch_acc: 0.562106. Batch_loss: 1.202548 \n",
      "Batch: 2551. Acc: 0.544185. Loss: 1.258863. Batch_acc: 0.553144. Batch_loss: 1.234083 \n",
      "Batch: 2552. Acc: 0.544177. Loss: 1.258891. Batch_acc: 0.523506. Batch_loss: 1.330220 \n",
      "Batch: 2553. Acc: 0.544185. Loss: 1.258876. Batch_acc: 0.564706. Batch_loss: 1.220582 \n",
      "Batch: 2554. Acc: 0.544185. Loss: 1.258884. Batch_acc: 0.543962. Batch_loss: 1.279929 \n",
      "Batch: 2555. Acc: 0.544189. Loss: 1.258878. Batch_acc: 0.554273. Batch_loss: 1.243014 \n",
      "Batch: 2556. Acc: 0.544186. Loss: 1.258872. Batch_acc: 0.536697. Batch_loss: 1.243544 \n",
      "Batch: 2557. Acc: 0.544189. Loss: 1.258859. Batch_acc: 0.552326. Batch_loss: 1.224967 \n",
      "Batch: 2558. Acc: 0.544190. Loss: 1.258867. Batch_acc: 0.546948. Batch_loss: 1.281186 \n",
      "Batch: 2559. Acc: 0.544195. Loss: 1.258862. Batch_acc: 0.556742. Batch_loss: 1.245168 \n",
      "Batch: 2560. Acc: 0.544203. Loss: 1.258852. Batch_acc: 0.565442. Batch_loss: 1.233008 \n",
      "Batch: 2561. Acc: 0.544200. Loss: 1.258853. Batch_acc: 0.536257. Batch_loss: 1.261913 \n",
      "Batch: 2562. Acc: 0.544210. Loss: 1.258826. Batch_acc: 0.568156. Batch_loss: 1.190275 \n",
      "Batch: 2563. Acc: 0.544206. Loss: 1.258838. Batch_acc: 0.535526. Batch_loss: 1.289768 \n",
      "Batch: 2564. Acc: 0.544214. Loss: 1.258807. Batch_acc: 0.565505. Batch_loss: 1.176389 \n",
      "Batch: 2565. Acc: 0.544214. Loss: 1.258806. Batch_acc: 0.544109. Batch_loss: 1.257156 \n",
      "Batch: 2566. Acc: 0.544213. Loss: 1.258806. Batch_acc: 0.541909. Batch_loss: 1.258592 \n",
      "Batch: 2567. Acc: 0.544222. Loss: 1.258788. Batch_acc: 0.567857. Batch_loss: 1.209375 \n",
      "Batch: 2568. Acc: 0.544229. Loss: 1.258770. Batch_acc: 0.561772. Batch_loss: 1.212490 \n",
      "Batch: 2569. Acc: 0.544237. Loss: 1.258749. Batch_acc: 0.566279. Batch_loss: 1.204733 \n",
      "Batch: 2570. Acc: 0.544249. Loss: 1.258718. Batch_acc: 0.573333. Batch_loss: 1.180453 \n",
      "Batch: 2571. Acc: 0.544250. Loss: 1.258717. Batch_acc: 0.546591. Batch_loss: 1.257807 \n",
      "Batch: 2572. Acc: 0.544251. Loss: 1.258706. Batch_acc: 0.547106. Batch_loss: 1.230541 \n",
      "Batch: 2573. Acc: 0.544254. Loss: 1.258689. Batch_acc: 0.551529. Batch_loss: 1.215552 \n",
      "Batch: 2574. Acc: 0.544258. Loss: 1.258687. Batch_acc: 0.553288. Batch_loss: 1.252328 \n",
      "Batch: 2575. Acc: 0.544266. Loss: 1.258663. Batch_acc: 0.566938. Batch_loss: 1.198087 \n",
      "Batch: 2576. Acc: 0.544269. Loss: 1.258651. Batch_acc: 0.550177. Batch_loss: 1.225388 \n",
      "Batch: 2577. Acc: 0.544272. Loss: 1.258636. Batch_acc: 0.551587. Batch_loss: 1.222154 \n",
      "Batch: 2578. Acc: 0.544268. Loss: 1.258644. Batch_acc: 0.536018. Batch_loss: 1.277479 \n",
      "Batch: 2579. Acc: 0.544275. Loss: 1.258623. Batch_acc: 0.562249. Batch_loss: 1.206090 \n",
      "Batch: 2580. Acc: 0.544271. Loss: 1.258634. Batch_acc: 0.533140. Batch_loss: 1.287638 \n",
      "Batch: 2581. Acc: 0.544281. Loss: 1.258613. Batch_acc: 0.569310. Batch_loss: 1.204936 \n",
      "Batch: 2582. Acc: 0.544287. Loss: 1.258592. Batch_acc: 0.559579. Batch_loss: 1.202600 \n",
      "Batch: 2583. Acc: 0.544284. Loss: 1.258599. Batch_acc: 0.536878. Batch_loss: 1.275923 \n",
      "Batch: 2584. Acc: 0.544284. Loss: 1.258599. Batch_acc: 0.545455. Batch_loss: 1.259637 \n",
      "Batch: 2585. Acc: 0.544281. Loss: 1.258598. Batch_acc: 0.535735. Batch_loss: 1.255839 \n",
      "Batch: 2586. Acc: 0.544287. Loss: 1.258595. Batch_acc: 0.558940. Batch_loss: 1.250550 \n",
      "Batch: 2587. Acc: 0.544283. Loss: 1.258589. Batch_acc: 0.535735. Batch_loss: 1.244323 \n",
      "Batch: 2588. Acc: 0.544292. Loss: 1.258580. Batch_acc: 0.566929. Batch_loss: 1.234538 \n",
      "Batch: 2589. Acc: 0.544295. Loss: 1.258566. Batch_acc: 0.551626. Batch_loss: 1.221720 \n",
      "Batch: 2590. Acc: 0.544301. Loss: 1.258548. Batch_acc: 0.559489. Batch_loss: 1.212350 \n",
      "Batch: 2591. Acc: 0.544300. Loss: 1.258544. Batch_acc: 0.542499. Batch_loss: 1.248708 \n",
      "Batch: 2592. Acc: 0.544302. Loss: 1.258539. Batch_acc: 0.549596. Batch_loss: 1.246000 \n",
      "Batch: 2593. Acc: 0.544311. Loss: 1.258529. Batch_acc: 0.566292. Batch_loss: 1.233599 \n",
      "Batch: 2594. Acc: 0.544316. Loss: 1.258519. Batch_acc: 0.558685. Batch_loss: 1.231723 \n",
      "Batch: 2595. Acc: 0.544323. Loss: 1.258503. Batch_acc: 0.560335. Batch_loss: 1.216913 \n",
      "Batch: 2596. Acc: 0.544328. Loss: 1.258491. Batch_acc: 0.556488. Batch_loss: 1.228656 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2597. Acc: 0.544323. Loss: 1.258502. Batch_acc: 0.532792. Batch_loss: 1.288169 \n",
      "Batch: 2598. Acc: 0.544324. Loss: 1.258501. Batch_acc: 0.546939. Batch_loss: 1.254369 \n",
      "Batch: 2599. Acc: 0.544324. Loss: 1.258499. Batch_acc: 0.544628. Batch_loss: 1.254834 \n",
      "Batch: 2600. Acc: 0.544335. Loss: 1.258465. Batch_acc: 0.571102. Batch_loss: 1.169252 \n",
      "Batch: 2601. Acc: 0.544330. Loss: 1.258479. Batch_acc: 0.532239. Batch_loss: 1.297213 \n",
      "Batch: 2602. Acc: 0.544330. Loss: 1.258465. Batch_acc: 0.544974. Batch_loss: 1.220514 \n",
      "Batch: 2603. Acc: 0.544329. Loss: 1.258452. Batch_acc: 0.542120. Batch_loss: 1.223406 \n",
      "Batch: 2604. Acc: 0.544326. Loss: 1.258455. Batch_acc: 0.534144. Batch_loss: 1.268374 \n",
      "Batch: 2605. Acc: 0.544333. Loss: 1.258427. Batch_acc: 0.563187. Batch_loss: 1.187631 \n",
      "Batch: 2606. Acc: 0.544346. Loss: 1.258388. Batch_acc: 0.576792. Batch_loss: 1.157173 \n",
      "Batch: 2607. Acc: 0.544343. Loss: 1.258391. Batch_acc: 0.537844. Batch_loss: 1.266773 \n",
      "Batch: 2608. Acc: 0.544338. Loss: 1.258404. Batch_acc: 0.529241. Batch_loss: 1.293725 \n",
      "Batch: 2609. Acc: 0.544340. Loss: 1.258406. Batch_acc: 0.551032. Batch_loss: 1.263495 \n",
      "Batch: 2610. Acc: 0.544346. Loss: 1.258386. Batch_acc: 0.561475. Batch_loss: 1.205532 \n",
      "Batch: 2611. Acc: 0.544355. Loss: 1.258369. Batch_acc: 0.566686. Batch_loss: 1.212230 \n",
      "Batch: 2612. Acc: 0.544352. Loss: 1.258379. Batch_acc: 0.535401. Batch_loss: 1.284495 \n",
      "Batch: 2613. Acc: 0.544358. Loss: 1.258357. Batch_acc: 0.560227. Batch_loss: 1.203121 \n",
      "Batch: 2614. Acc: 0.544372. Loss: 1.258327. Batch_acc: 0.582424. Batch_loss: 1.180313 \n",
      "Batch: 2615. Acc: 0.544371. Loss: 1.258332. Batch_acc: 0.540000. Batch_loss: 1.269078 \n",
      "Batch: 2616. Acc: 0.544372. Loss: 1.258326. Batch_acc: 0.546875. Batch_loss: 1.244465 \n",
      "Batch: 2617. Acc: 0.544385. Loss: 1.258297. Batch_acc: 0.578054. Batch_loss: 1.183979 \n",
      "Batch: 2618. Acc: 0.544389. Loss: 1.258286. Batch_acc: 0.555556. Batch_loss: 1.228354 \n",
      "Batch: 2619. Acc: 0.544396. Loss: 1.258275. Batch_acc: 0.563940. Batch_loss: 1.228566 \n",
      "Batch: 2620. Acc: 0.544410. Loss: 1.258240. Batch_acc: 0.579727. Batch_loss: 1.167651 \n",
      "Batch: 2621. Acc: 0.544406. Loss: 1.258255. Batch_acc: 0.533103. Batch_loss: 1.299090 \n",
      "Batch: 2622. Acc: 0.544407. Loss: 1.258248. Batch_acc: 0.548061. Batch_loss: 1.239581 \n",
      "Batch: 2623. Acc: 0.544401. Loss: 1.258266. Batch_acc: 0.527409. Batch_loss: 1.304896 \n",
      "Batch: 2624. Acc: 0.544401. Loss: 1.258266. Batch_acc: 0.545814. Batch_loss: 1.258104 \n",
      "Batch: 2625. Acc: 0.544411. Loss: 1.258248. Batch_acc: 0.569983. Batch_loss: 1.212586 \n",
      "Batch: 2626. Acc: 0.544411. Loss: 1.258244. Batch_acc: 0.544924. Batch_loss: 1.246913 \n",
      "Batch: 2627. Acc: 0.544420. Loss: 1.258217. Batch_acc: 0.568366. Batch_loss: 1.187737 \n",
      "Batch: 2628. Acc: 0.544421. Loss: 1.258213. Batch_acc: 0.545927. Batch_loss: 1.247594 \n",
      "Batch: 2629. Acc: 0.544420. Loss: 1.258222. Batch_acc: 0.541049. Batch_loss: 1.281869 \n",
      "Batch: 2630. Acc: 0.544422. Loss: 1.258214. Batch_acc: 0.550568. Batch_loss: 1.236440 \n",
      "Batch: 2631. Acc: 0.544415. Loss: 1.258235. Batch_acc: 0.527479. Batch_loss: 1.314338 \n",
      "Batch: 2632. Acc: 0.544424. Loss: 1.258217. Batch_acc: 0.566667. Batch_loss: 1.211035 \n",
      "Batch: 2633. Acc: 0.544438. Loss: 1.258190. Batch_acc: 0.580701. Batch_loss: 1.186940 \n",
      "Batch: 2634. Acc: 0.544437. Loss: 1.258193. Batch_acc: 0.542056. Batch_loss: 1.266483 \n",
      "Batch: 2635. Acc: 0.544436. Loss: 1.258195. Batch_acc: 0.542093. Batch_loss: 1.262319 \n",
      "Batch: 2636. Acc: 0.544435. Loss: 1.258202. Batch_acc: 0.541401. Batch_loss: 1.276553 \n",
      "Batch: 2637. Acc: 0.544431. Loss: 1.258203. Batch_acc: 0.535336. Batch_loss: 1.260094 \n",
      "Batch: 2638. Acc: 0.544426. Loss: 1.258218. Batch_acc: 0.529864. Batch_loss: 1.300963 \n",
      "Batch: 2639. Acc: 0.544423. Loss: 1.258221. Batch_acc: 0.535503. Batch_loss: 1.265271 \n",
      "Batch: 2640. Acc: 0.544420. Loss: 1.258226. Batch_acc: 0.537313. Batch_loss: 1.271178 \n",
      "Batch: 2641. Acc: 0.544420. Loss: 1.258231. Batch_acc: 0.544756. Batch_loss: 1.271934 \n",
      "Batch: 2642. Acc: 0.544424. Loss: 1.258215. Batch_acc: 0.555170. Batch_loss: 1.215352 \n",
      "Batch: 2643. Acc: 0.544429. Loss: 1.258205. Batch_acc: 0.556636. Batch_loss: 1.230423 \n",
      "Batch: 2644. Acc: 0.544426. Loss: 1.258206. Batch_acc: 0.536385. Batch_loss: 1.262873 \n",
      "Batch: 2645. Acc: 0.544424. Loss: 1.258204. Batch_acc: 0.540525. Batch_loss: 1.253101 \n",
      "Batch: 2646. Acc: 0.544414. Loss: 1.258234. Batch_acc: 0.515995. Batch_loss: 1.338656 \n",
      "Batch: 2647. Acc: 0.544418. Loss: 1.258220. Batch_acc: 0.554115. Batch_loss: 1.222029 \n",
      "Batch: 2648. Acc: 0.544417. Loss: 1.258226. Batch_acc: 0.543073. Batch_loss: 1.275619 \n",
      "Batch: 2649. Acc: 0.544425. Loss: 1.258206. Batch_acc: 0.565142. Batch_loss: 1.202779 \n",
      "Batch: 2650. Acc: 0.544423. Loss: 1.258211. Batch_acc: 0.538684. Batch_loss: 1.272325 \n",
      "Batch: 2651. Acc: 0.544415. Loss: 1.258224. Batch_acc: 0.523701. Batch_loss: 1.293241 \n",
      "Batch: 2652. Acc: 0.544425. Loss: 1.258201. Batch_acc: 0.572171. Batch_loss: 1.197016 \n",
      "Batch: 2653. Acc: 0.544430. Loss: 1.258189. Batch_acc: 0.558072. Batch_loss: 1.225419 \n",
      "Batch: 2654. Acc: 0.544430. Loss: 1.258201. Batch_acc: 0.543253. Batch_loss: 1.290806 \n",
      "Batch: 2655. Acc: 0.544439. Loss: 1.258172. Batch_acc: 0.568415. Batch_loss: 1.182504 \n",
      "Batch: 2656. Acc: 0.544441. Loss: 1.258175. Batch_acc: 0.548611. Batch_loss: 1.264954 \n",
      "Batch: 2657. Acc: 0.544437. Loss: 1.258189. Batch_acc: 0.533599. Batch_loss: 1.294013 \n",
      "Batch: 2658. Acc: 0.544444. Loss: 1.258160. Batch_acc: 0.563973. Batch_loss: 1.184490 \n",
      "Batch: 2659. Acc: 0.544446. Loss: 1.258155. Batch_acc: 0.550115. Batch_loss: 1.244294 \n",
      "Batch: 2660. Acc: 0.544446. Loss: 1.258153. Batch_acc: 0.544183. Batch_loss: 1.252490 \n",
      "Batch: 2661. Acc: 0.544446. Loss: 1.258153. Batch_acc: 0.543566. Batch_loss: 1.258518 \n",
      "Batch: 2662. Acc: 0.544453. Loss: 1.258137. Batch_acc: 0.564223. Batch_loss: 1.214890 \n",
      "Batch: 2663. Acc: 0.544447. Loss: 1.258149. Batch_acc: 0.527939. Batch_loss: 1.289406 \n",
      "Batch: 2664. Acc: 0.544448. Loss: 1.258148. Batch_acc: 0.547535. Batch_loss: 1.255889 \n",
      "Batch: 2665. Acc: 0.544451. Loss: 1.258139. Batch_acc: 0.551646. Batch_loss: 1.235484 \n",
      "Batch: 2666. Acc: 0.544451. Loss: 1.258141. Batch_acc: 0.544526. Batch_loss: 1.261925 \n",
      "Batch: 2667. Acc: 0.544467. Loss: 1.258099. Batch_acc: 0.586744. Batch_loss: 1.145601 \n",
      "Batch: 2668. Acc: 0.544476. Loss: 1.258074. Batch_acc: 0.568594. Batch_loss: 1.194284 \n",
      "Batch: 2669. Acc: 0.544496. Loss: 1.258028. Batch_acc: 0.596284. Batch_loss: 1.138032 \n",
      "Batch: 2670. Acc: 0.544502. Loss: 1.258005. Batch_acc: 0.560710. Batch_loss: 1.196507 \n",
      "Batch: 2671. Acc: 0.544515. Loss: 1.257972. Batch_acc: 0.579636. Batch_loss: 1.170435 \n",
      "Batch: 2672. Acc: 0.544517. Loss: 1.257961. Batch_acc: 0.549444. Batch_loss: 1.228931 \n",
      "Batch: 2673. Acc: 0.544507. Loss: 1.257981. Batch_acc: 0.516340. Batch_loss: 1.312722 \n",
      "Batch: 2674. Acc: 0.544515. Loss: 1.257968. Batch_acc: 0.567059. Batch_loss: 1.223713 \n",
      "Batch: 2675. Acc: 0.544512. Loss: 1.257970. Batch_acc: 0.537313. Batch_loss: 1.262758 \n",
      "Batch: 2676. Acc: 0.544517. Loss: 1.257960. Batch_acc: 0.556818. Batch_loss: 1.231291 \n",
      "Batch: 2677. Acc: 0.544516. Loss: 1.257965. Batch_acc: 0.541452. Batch_loss: 1.272683 \n",
      "Batch: 2678. Acc: 0.544517. Loss: 1.257978. Batch_acc: 0.547458. Batch_loss: 1.290241 \n",
      "Batch: 2679. Acc: 0.544521. Loss: 1.257982. Batch_acc: 0.555620. Batch_loss: 1.269657 \n",
      "Batch: 2680. Acc: 0.544520. Loss: 1.257975. Batch_acc: 0.542283. Batch_loss: 1.239761 \n",
      "Batch: 2681. Acc: 0.544522. Loss: 1.257973. Batch_acc: 0.548032. Batch_loss: 1.252773 \n",
      "Batch: 2682. Acc: 0.544524. Loss: 1.257966. Batch_acc: 0.550823. Batch_loss: 1.239391 \n",
      "Batch: 2683. Acc: 0.544524. Loss: 1.257962. Batch_acc: 0.545089. Batch_loss: 1.245275 \n",
      "Batch: 2684. Acc: 0.544528. Loss: 1.257953. Batch_acc: 0.553733. Batch_loss: 1.235058 \n",
      "Batch: 2685. Acc: 0.544531. Loss: 1.257947. Batch_acc: 0.552467. Batch_loss: 1.241329 \n",
      "Batch: 2686. Acc: 0.544540. Loss: 1.257927. Batch_acc: 0.569372. Batch_loss: 1.205499 \n",
      "Batch: 2687. Acc: 0.544543. Loss: 1.257924. Batch_acc: 0.552928. Batch_loss: 1.248623 \n",
      "Batch: 2688. Acc: 0.544546. Loss: 1.257909. Batch_acc: 0.551843. Batch_loss: 1.217385 \n",
      "Batch: 2689. Acc: 0.544536. Loss: 1.257931. Batch_acc: 0.518797. Batch_loss: 1.317525 \n",
      "Batch: 2690. Acc: 0.544530. Loss: 1.257950. Batch_acc: 0.527586. Batch_loss: 1.310429 \n",
      "Batch: 2691. Acc: 0.544525. Loss: 1.257967. Batch_acc: 0.531323. Batch_loss: 1.302832 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2692. Acc: 0.544523. Loss: 1.257970. Batch_acc: 0.538550. Batch_loss: 1.266001 \n",
      "Batch: 2693. Acc: 0.544522. Loss: 1.257964. Batch_acc: 0.542019. Batch_loss: 1.243923 \n",
      "Batch: 2694. Acc: 0.544525. Loss: 1.257950. Batch_acc: 0.553276. Batch_loss: 1.219371 \n",
      "Batch: 2695. Acc: 0.544522. Loss: 1.257950. Batch_acc: 0.535113. Batch_loss: 1.258438 \n",
      "Batch: 2696. Acc: 0.544531. Loss: 1.257930. Batch_acc: 0.569868. Batch_loss: 1.204978 \n",
      "Batch: 2697. Acc: 0.544525. Loss: 1.257943. Batch_acc: 0.527262. Batch_loss: 1.291607 \n",
      "Batch: 2698. Acc: 0.544521. Loss: 1.257951. Batch_acc: 0.532891. Batch_loss: 1.280935 \n",
      "Batch: 2699. Acc: 0.544536. Loss: 1.257918. Batch_acc: 0.585664. Batch_loss: 1.167686 \n",
      "Batch: 2700. Acc: 0.544534. Loss: 1.257919. Batch_acc: 0.540650. Batch_loss: 1.261962 \n",
      "Batch: 2701. Acc: 0.544546. Loss: 1.257883. Batch_acc: 0.573734. Batch_loss: 1.163572 \n",
      "Batch: 2702. Acc: 0.544550. Loss: 1.257870. Batch_acc: 0.557839. Batch_loss: 1.220154 \n",
      "Batch: 2703. Acc: 0.544551. Loss: 1.257863. Batch_acc: 0.546812. Batch_loss: 1.240427 \n",
      "Batch: 2704. Acc: 0.544564. Loss: 1.257828. Batch_acc: 0.579093. Batch_loss: 1.166212 \n",
      "Batch: 2705. Acc: 0.544568. Loss: 1.257824. Batch_acc: 0.553792. Batch_loss: 1.245623 \n",
      "Batch: 2706. Acc: 0.544567. Loss: 1.257830. Batch_acc: 0.542690. Batch_loss: 1.275382 \n",
      "Batch: 2707. Acc: 0.544577. Loss: 1.257814. Batch_acc: 0.570524. Batch_loss: 1.213357 \n",
      "Batch: 2708. Acc: 0.544580. Loss: 1.257794. Batch_acc: 0.552975. Batch_loss: 1.204967 \n",
      "Batch: 2709. Acc: 0.544583. Loss: 1.257778. Batch_acc: 0.554279. Batch_loss: 1.216348 \n",
      "Batch: 2710. Acc: 0.544587. Loss: 1.257756. Batch_acc: 0.555492. Batch_loss: 1.198356 \n",
      "Batch: 2711. Acc: 0.544592. Loss: 1.257743. Batch_acc: 0.557208. Batch_loss: 1.220633 \n",
      "Batch: 2712. Acc: 0.544597. Loss: 1.257729. Batch_acc: 0.559060. Batch_loss: 1.219629 \n",
      "Batch: 2713. Acc: 0.544600. Loss: 1.257711. Batch_acc: 0.552708. Batch_loss: 1.210691 \n",
      "Batch: 2714. Acc: 0.544608. Loss: 1.257696. Batch_acc: 0.565090. Batch_loss: 1.213948 \n",
      "Batch: 2715. Acc: 0.544621. Loss: 1.257668. Batch_acc: 0.579669. Batch_loss: 1.183484 \n",
      "Batch: 2716. Acc: 0.544623. Loss: 1.257665. Batch_acc: 0.549425. Batch_loss: 1.248504 \n",
      "Batch: 2717. Acc: 0.544625. Loss: 1.257665. Batch_acc: 0.550088. Batch_loss: 1.259489 \n",
      "Batch: 2718. Acc: 0.544623. Loss: 1.257667. Batch_acc: 0.539610. Batch_loss: 1.261503 \n",
      "Batch: 2719. Acc: 0.544632. Loss: 1.257644. Batch_acc: 0.568739. Batch_loss: 1.196547 \n",
      "Batch: 2720. Acc: 0.544631. Loss: 1.257644. Batch_acc: 0.544027. Batch_loss: 1.256819 \n",
      "Batch: 2721. Acc: 0.544630. Loss: 1.257648. Batch_acc: 0.540398. Batch_loss: 1.270161 \n",
      "Batch: 2722. Acc: 0.544631. Loss: 1.257636. Batch_acc: 0.546238. Batch_loss: 1.225013 \n",
      "Batch: 2723. Acc: 0.544637. Loss: 1.257616. Batch_acc: 0.562572. Batch_loss: 1.201928 \n",
      "Batch: 2724. Acc: 0.544638. Loss: 1.257616. Batch_acc: 0.546099. Batch_loss: 1.259078 \n",
      "Batch: 2725. Acc: 0.544637. Loss: 1.257617. Batch_acc: 0.543981. Batch_loss: 1.259739 \n",
      "Batch: 2726. Acc: 0.544640. Loss: 1.257610. Batch_acc: 0.550963. Batch_loss: 1.237516 \n",
      "Batch: 2727. Acc: 0.544648. Loss: 1.257586. Batch_acc: 0.568379. Batch_loss: 1.193513 \n",
      "Batch: 2728. Acc: 0.544653. Loss: 1.257561. Batch_acc: 0.558046. Batch_loss: 1.188329 \n",
      "Batch: 2729. Acc: 0.544662. Loss: 1.257546. Batch_acc: 0.567224. Batch_loss: 1.218278 \n",
      "Batch: 2730. Acc: 0.544660. Loss: 1.257547. Batch_acc: 0.540793. Batch_loss: 1.257691 \n",
      "Batch: 2731. Acc: 0.544670. Loss: 1.257524. Batch_acc: 0.571348. Batch_loss: 1.197793 \n",
      "Batch: 2732. Acc: 0.544683. Loss: 1.257493. Batch_acc: 0.578258. Batch_loss: 1.172432 \n",
      "Batch: 2733. Acc: 0.544688. Loss: 1.257487. Batch_acc: 0.560721. Batch_loss: 1.241952 \n",
      "Batch: 2734. Acc: 0.544692. Loss: 1.257472. Batch_acc: 0.554140. Batch_loss: 1.216945 \n",
      "Batch: 2735. Acc: 0.544700. Loss: 1.257450. Batch_acc: 0.567291. Batch_loss: 1.197348 \n",
      "Batch: 2736. Acc: 0.544705. Loss: 1.257446. Batch_acc: 0.557274. Batch_loss: 1.246535 \n",
      "Batch: 2737. Acc: 0.544705. Loss: 1.257444. Batch_acc: 0.546087. Batch_loss: 1.252425 \n",
      "Batch: 2738. Acc: 0.544711. Loss: 1.257440. Batch_acc: 0.561877. Batch_loss: 1.244454 \n",
      "Batch: 2739. Acc: 0.544705. Loss: 1.257459. Batch_acc: 0.526796. Batch_loss: 1.310683 \n",
      "Batch: 2740. Acc: 0.544712. Loss: 1.257443. Batch_acc: 0.564236. Batch_loss: 1.212636 \n",
      "Batch: 2741. Acc: 0.544708. Loss: 1.257452. Batch_acc: 0.535047. Batch_loss: 1.281708 \n",
      "Batch: 2742. Acc: 0.544712. Loss: 1.257434. Batch_acc: 0.555236. Batch_loss: 1.209930 \n",
      "Batch: 2743. Acc: 0.544724. Loss: 1.257406. Batch_acc: 0.577120. Batch_loss: 1.180278 \n",
      "Batch: 2744. Acc: 0.544725. Loss: 1.257397. Batch_acc: 0.546659. Batch_loss: 1.232230 \n",
      "Batch: 2745. Acc: 0.544725. Loss: 1.257399. Batch_acc: 0.544332. Batch_loss: 1.263159 \n",
      "Batch: 2746. Acc: 0.544731. Loss: 1.257374. Batch_acc: 0.563198. Batch_loss: 1.187132 \n",
      "Batch: 2747. Acc: 0.544734. Loss: 1.257371. Batch_acc: 0.551684. Batch_loss: 1.248335 \n",
      "Batch: 2748. Acc: 0.544732. Loss: 1.257376. Batch_acc: 0.539221. Batch_loss: 1.270770 \n",
      "Batch: 2749. Acc: 0.544735. Loss: 1.257367. Batch_acc: 0.553073. Batch_loss: 1.233979 \n",
      "Batch: 2750. Acc: 0.544736. Loss: 1.257369. Batch_acc: 0.547213. Batch_loss: 1.262054 \n",
      "Batch: 2751. Acc: 0.544744. Loss: 1.257358. Batch_acc: 0.567324. Batch_loss: 1.229818 \n",
      "Batch: 2752. Acc: 0.544745. Loss: 1.257351. Batch_acc: 0.547362. Batch_loss: 1.237105 \n",
      "Batch: 2753. Acc: 0.544748. Loss: 1.257343. Batch_acc: 0.552961. Batch_loss: 1.236407 \n",
      "Batch: 2754. Acc: 0.544758. Loss: 1.257317. Batch_acc: 0.570621. Batch_loss: 1.185213 \n",
      "Batch: 2755. Acc: 0.544761. Loss: 1.257304. Batch_acc: 0.553167. Batch_loss: 1.222407 \n",
      "Batch: 2756. Acc: 0.544754. Loss: 1.257317. Batch_acc: 0.524941. Batch_loss: 1.294512 \n",
      "Batch: 2757. Acc: 0.544753. Loss: 1.257307. Batch_acc: 0.542791. Batch_loss: 1.228764 \n",
      "Batch: 2758. Acc: 0.544756. Loss: 1.257297. Batch_acc: 0.552948. Batch_loss: 1.229632 \n",
      "Batch: 2759. Acc: 0.544756. Loss: 1.257309. Batch_acc: 0.543789. Batch_loss: 1.291855 \n",
      "Batch: 2760. Acc: 0.544764. Loss: 1.257282. Batch_acc: 0.567536. Batch_loss: 1.180676 \n",
      "Batch: 2761. Acc: 0.544778. Loss: 1.257241. Batch_acc: 0.582014. Batch_loss: 1.148169 \n",
      "Checkpointing on batch: 2761. Accuracy: 0.5447777094405304. Loss per char: 1.2572414735609294. Time: 1627223983.110759\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 19, 23, 26, 15,\n",
      "        17, 18, 20, 26,  1, 66, 79, 69,  1, 19, 22, 17, 25, 23, 15, 21, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 2762. Acc: 0.544790. Loss: 1.257208. Batch_acc: 0.579423. Batch_loss: 1.166476 \n",
      "Batch: 2763. Acc: 0.544797. Loss: 1.257189. Batch_acc: 0.562500. Batch_loss: 1.203601 \n",
      "Batch: 2764. Acc: 0.544801. Loss: 1.257178. Batch_acc: 0.556000. Batch_loss: 1.229396 \n",
      "Batch: 2765. Acc: 0.544804. Loss: 1.257184. Batch_acc: 0.552813. Batch_loss: 1.273607 \n",
      "Batch: 2766. Acc: 0.544814. Loss: 1.257142. Batch_acc: 0.572320. Batch_loss: 1.140574 \n",
      "Batch: 2767. Acc: 0.544809. Loss: 1.257150. Batch_acc: 0.529949. Batch_loss: 1.281282 \n",
      "Batch: 2768. Acc: 0.544806. Loss: 1.257152. Batch_acc: 0.537100. Batch_loss: 1.261267 \n",
      "Batch: 2769. Acc: 0.544806. Loss: 1.257140. Batch_acc: 0.545094. Batch_loss: 1.224234 \n",
      "Batch: 2770. Acc: 0.544820. Loss: 1.257099. Batch_acc: 0.583716. Batch_loss: 1.144933 \n",
      "Batch: 2771. Acc: 0.544820. Loss: 1.257094. Batch_acc: 0.545348. Batch_loss: 1.243044 \n",
      "Batch: 2772. Acc: 0.544815. Loss: 1.257106. Batch_acc: 0.530495. Batch_loss: 1.288987 \n",
      "Batch: 2773. Acc: 0.544815. Loss: 1.257102. Batch_acc: 0.543953. Batch_loss: 1.246266 \n",
      "Batch: 2774. Acc: 0.544819. Loss: 1.257095. Batch_acc: 0.555492. Batch_loss: 1.238470 \n",
      "Batch: 2775. Acc: 0.544815. Loss: 1.257110. Batch_acc: 0.533792. Batch_loss: 1.297797 \n",
      "Batch: 2776. Acc: 0.544821. Loss: 1.257096. Batch_acc: 0.562282. Batch_loss: 1.219081 \n",
      "Batch: 2777. Acc: 0.544820. Loss: 1.257090. Batch_acc: 0.543880. Batch_loss: 1.239834 \n",
      "Batch: 2778. Acc: 0.544820. Loss: 1.257089. Batch_acc: 0.543429. Batch_loss: 1.253350 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2779. Acc: 0.544826. Loss: 1.257078. Batch_acc: 0.561413. Batch_loss: 1.226309 \n",
      "Batch: 2780. Acc: 0.544834. Loss: 1.257058. Batch_acc: 0.565537. Batch_loss: 1.204777 \n",
      "Batch: 2781. Acc: 0.544837. Loss: 1.257043. Batch_acc: 0.554679. Batch_loss: 1.215451 \n",
      "Batch: 2782. Acc: 0.544838. Loss: 1.257043. Batch_acc: 0.547764. Batch_loss: 1.256840 \n",
      "Batch: 2783. Acc: 0.544846. Loss: 1.257024. Batch_acc: 0.566474. Batch_loss: 1.202976 \n",
      "Batch: 2784. Acc: 0.544845. Loss: 1.257027. Batch_acc: 0.542283. Batch_loss: 1.267131 \n",
      "Batch: 2785. Acc: 0.544848. Loss: 1.257011. Batch_acc: 0.553499. Batch_loss: 1.212059 \n",
      "Batch: 2786. Acc: 0.544853. Loss: 1.257000. Batch_acc: 0.559078. Batch_loss: 1.226325 \n",
      "Batch: 2787. Acc: 0.544855. Loss: 1.256994. Batch_acc: 0.549271. Batch_loss: 1.238442 \n",
      "Batch: 2788. Acc: 0.544866. Loss: 1.256969. Batch_acc: 0.574408. Batch_loss: 1.190480 \n",
      "Batch: 2789. Acc: 0.544876. Loss: 1.256947. Batch_acc: 0.573596. Batch_loss: 1.194768 \n",
      "Batch: 2790. Acc: 0.544879. Loss: 1.256929. Batch_acc: 0.553899. Batch_loss: 1.207241 \n",
      "Batch: 2791. Acc: 0.544890. Loss: 1.256899. Batch_acc: 0.572707. Batch_loss: 1.177779 \n",
      "Batch: 2792. Acc: 0.544889. Loss: 1.256896. Batch_acc: 0.542431. Batch_loss: 1.248055 \n",
      "Batch: 2793. Acc: 0.544895. Loss: 1.256879. Batch_acc: 0.561373. Batch_loss: 1.209265 \n",
      "Batch: 2794. Acc: 0.544894. Loss: 1.256874. Batch_acc: 0.543159. Batch_loss: 1.240577 \n",
      "Batch: 2795. Acc: 0.544892. Loss: 1.256880. Batch_acc: 0.539664. Batch_loss: 1.273098 \n",
      "Batch: 2796. Acc: 0.544902. Loss: 1.256865. Batch_acc: 0.571592. Batch_loss: 1.217306 \n",
      "Batch: 2797. Acc: 0.544900. Loss: 1.256867. Batch_acc: 0.539176. Batch_loss: 1.261410 \n",
      "Batch: 2798. Acc: 0.544905. Loss: 1.256859. Batch_acc: 0.558300. Batch_loss: 1.235144 \n",
      "Batch: 2799. Acc: 0.544909. Loss: 1.256852. Batch_acc: 0.558300. Batch_loss: 1.237226 \n",
      "Batch: 2800. Acc: 0.544918. Loss: 1.256833. Batch_acc: 0.567645. Batch_loss: 1.202598 \n",
      "Batch: 2801. Acc: 0.544909. Loss: 1.256852. Batch_acc: 0.521687. Batch_loss: 1.311620 \n",
      "Batch: 2802. Acc: 0.544920. Loss: 1.256831. Batch_acc: 0.573789. Batch_loss: 1.199942 \n",
      "Batch: 2803. Acc: 0.544921. Loss: 1.256839. Batch_acc: 0.548110. Batch_loss: 1.277977 \n",
      "Batch: 2804. Acc: 0.544921. Loss: 1.256834. Batch_acc: 0.544413. Batch_loss: 1.243089 \n",
      "Batch: 2805. Acc: 0.544933. Loss: 1.256799. Batch_acc: 0.577285. Batch_loss: 1.163234 \n",
      "Batch: 2806. Acc: 0.544945. Loss: 1.256765. Batch_acc: 0.580311. Batch_loss: 1.160190 \n",
      "Batch: 2807. Acc: 0.544941. Loss: 1.256777. Batch_acc: 0.531050. Batch_loss: 1.292511 \n",
      "Batch: 2808. Acc: 0.544951. Loss: 1.256750. Batch_acc: 0.574107. Batch_loss: 1.178351 \n",
      "Batch: 2809. Acc: 0.544954. Loss: 1.256738. Batch_acc: 0.554245. Batch_loss: 1.222853 \n",
      "Batch: 2810. Acc: 0.544965. Loss: 1.256710. Batch_acc: 0.574958. Batch_loss: 1.179506 \n",
      "Batch: 2811. Acc: 0.544966. Loss: 1.256704. Batch_acc: 0.548290. Batch_loss: 1.239399 \n",
      "Batch: 2812. Acc: 0.544962. Loss: 1.256714. Batch_acc: 0.532634. Batch_loss: 1.283547 \n",
      "Batch: 2813. Acc: 0.544962. Loss: 1.256702. Batch_acc: 0.545714. Batch_loss: 1.225201 \n",
      "Batch: 2814. Acc: 0.544964. Loss: 1.256705. Batch_acc: 0.551665. Batch_loss: 1.265518 \n",
      "Batch: 2815. Acc: 0.544955. Loss: 1.256721. Batch_acc: 0.518819. Batch_loss: 1.301990 \n",
      "Batch: 2816. Acc: 0.544964. Loss: 1.256705. Batch_acc: 0.571016. Batch_loss: 1.210459 \n",
      "Batch: 2817. Acc: 0.544968. Loss: 1.256697. Batch_acc: 0.553933. Batch_loss: 1.233264 \n",
      "Batch: 2818. Acc: 0.544974. Loss: 1.256671. Batch_acc: 0.562429. Batch_loss: 1.184717 \n",
      "Batch: 2819. Acc: 0.544975. Loss: 1.256662. Batch_acc: 0.548182. Batch_loss: 1.232851 \n",
      "Batch: 2820. Acc: 0.544978. Loss: 1.256658. Batch_acc: 0.552130. Batch_loss: 1.243721 \n",
      "Batch: 2821. Acc: 0.544971. Loss: 1.256671. Batch_acc: 0.525172. Batch_loss: 1.294691 \n",
      "Batch: 2822. Acc: 0.544970. Loss: 1.256667. Batch_acc: 0.543968. Batch_loss: 1.246401 \n",
      "Batch: 2823. Acc: 0.544969. Loss: 1.256670. Batch_acc: 0.541143. Batch_loss: 1.265034 \n",
      "Batch: 2824. Acc: 0.544979. Loss: 1.256647. Batch_acc: 0.573034. Batch_loss: 1.192246 \n",
      "Batch: 2825. Acc: 0.544974. Loss: 1.256659. Batch_acc: 0.531376. Batch_loss: 1.289563 \n",
      "Batch: 2826. Acc: 0.544973. Loss: 1.256657. Batch_acc: 0.540416. Batch_loss: 1.250708 \n",
      "Batch: 2827. Acc: 0.544977. Loss: 1.256645. Batch_acc: 0.556707. Batch_loss: 1.223840 \n",
      "Batch: 2828. Acc: 0.544975. Loss: 1.256640. Batch_acc: 0.539466. Batch_loss: 1.243389 \n",
      "Batch: 2829. Acc: 0.544982. Loss: 1.256619. Batch_acc: 0.566572. Batch_loss: 1.198332 \n",
      "Batch: 2830. Acc: 0.544987. Loss: 1.256610. Batch_acc: 0.559046. Batch_loss: 1.228740 \n",
      "Batch: 2831. Acc: 0.544993. Loss: 1.256592. Batch_acc: 0.559524. Batch_loss: 1.208955 \n",
      "Batch: 2832. Acc: 0.544994. Loss: 1.256589. Batch_acc: 0.547993. Batch_loss: 1.246382 \n",
      "Batch: 2833. Acc: 0.544988. Loss: 1.256592. Batch_acc: 0.529513. Batch_loss: 1.264696 \n",
      "Batch: 2834. Acc: 0.545000. Loss: 1.256552. Batch_acc: 0.579702. Batch_loss: 1.145477 \n",
      "Batch: 2835. Acc: 0.545002. Loss: 1.256552. Batch_acc: 0.550231. Batch_loss: 1.255793 \n",
      "Batch: 2836. Acc: 0.544994. Loss: 1.256569. Batch_acc: 0.522371. Batch_loss: 1.305540 \n",
      "Batch: 2837. Acc: 0.544992. Loss: 1.256572. Batch_acc: 0.536842. Batch_loss: 1.265584 \n",
      "Batch: 2838. Acc: 0.545006. Loss: 1.256551. Batch_acc: 0.587413. Batch_loss: 1.195999 \n",
      "Batch: 2839. Acc: 0.545006. Loss: 1.256557. Batch_acc: 0.544023. Batch_loss: 1.271837 \n",
      "Batch: 2840. Acc: 0.545010. Loss: 1.256547. Batch_acc: 0.555359. Batch_loss: 1.229146 \n",
      "Batch: 2841. Acc: 0.545012. Loss: 1.256543. Batch_acc: 0.550708. Batch_loss: 1.243641 \n",
      "Batch: 2842. Acc: 0.545021. Loss: 1.256514. Batch_acc: 0.570304. Batch_loss: 1.177986 \n",
      "Batch: 2843. Acc: 0.545017. Loss: 1.256521. Batch_acc: 0.535132. Batch_loss: 1.273939 \n",
      "Batch: 2844. Acc: 0.545013. Loss: 1.256533. Batch_acc: 0.533879. Batch_loss: 1.291329 \n",
      "Batch: 2845. Acc: 0.545013. Loss: 1.256528. Batch_acc: 0.543217. Batch_loss: 1.242182 \n",
      "Batch: 2846. Acc: 0.545015. Loss: 1.256514. Batch_acc: 0.553179. Batch_loss: 1.218623 \n",
      "Batch: 2847. Acc: 0.545018. Loss: 1.256504. Batch_acc: 0.551326. Batch_loss: 1.228292 \n",
      "Batch: 2848. Acc: 0.545022. Loss: 1.256484. Batch_acc: 0.558501. Batch_loss: 1.197878 \n",
      "Batch: 2849. Acc: 0.545020. Loss: 1.256491. Batch_acc: 0.537960. Batch_loss: 1.278014 \n",
      "Batch: 2850. Acc: 0.545021. Loss: 1.256487. Batch_acc: 0.548652. Batch_loss: 1.244901 \n",
      "Batch: 2851. Acc: 0.545015. Loss: 1.256497. Batch_acc: 0.528103. Batch_loss: 1.284251 \n",
      "Batch: 2852. Acc: 0.545015. Loss: 1.256494. Batch_acc: 0.543239. Batch_loss: 1.248072 \n",
      "Batch: 2853. Acc: 0.545028. Loss: 1.256463. Batch_acc: 0.581488. Batch_loss: 1.170070 \n",
      "Batch: 2854. Acc: 0.545019. Loss: 1.256478. Batch_acc: 0.518957. Batch_loss: 1.298761 \n",
      "Batch: 2855. Acc: 0.545020. Loss: 1.256471. Batch_acc: 0.549451. Batch_loss: 1.238732 \n",
      "Batch: 2856. Acc: 0.545025. Loss: 1.256456. Batch_acc: 0.556695. Batch_loss: 1.212825 \n",
      "Batch: 2857. Acc: 0.545030. Loss: 1.256451. Batch_acc: 0.560852. Batch_loss: 1.242149 \n",
      "Batch: 2858. Acc: 0.545032. Loss: 1.256453. Batch_acc: 0.550203. Batch_loss: 1.261358 \n",
      "Batch: 2859. Acc: 0.545037. Loss: 1.256437. Batch_acc: 0.559078. Batch_loss: 1.212207 \n",
      "Batch: 2860. Acc: 0.545041. Loss: 1.256423. Batch_acc: 0.557442. Batch_loss: 1.216903 \n",
      "Batch: 2861. Acc: 0.545042. Loss: 1.256419. Batch_acc: 0.548220. Batch_loss: 1.244272 \n",
      "Batch: 2862. Acc: 0.545041. Loss: 1.256421. Batch_acc: 0.541231. Batch_loss: 1.261861 \n",
      "Batch: 2863. Acc: 0.545029. Loss: 1.256444. Batch_acc: 0.509195. Batch_loss: 1.324062 \n",
      "Batch: 2864. Acc: 0.545032. Loss: 1.256434. Batch_acc: 0.554252. Batch_loss: 1.227472 \n",
      "Batch: 2865. Acc: 0.545037. Loss: 1.256421. Batch_acc: 0.561060. Batch_loss: 1.218022 \n",
      "Batch: 2866. Acc: 0.545042. Loss: 1.256410. Batch_acc: 0.557901. Batch_loss: 1.225476 \n",
      "Batch: 2867. Acc: 0.545035. Loss: 1.256422. Batch_acc: 0.526080. Batch_loss: 1.288699 \n",
      "Batch: 2868. Acc: 0.545032. Loss: 1.256427. Batch_acc: 0.535336. Batch_loss: 1.272224 \n",
      "Batch: 2869. Acc: 0.545029. Loss: 1.256421. Batch_acc: 0.536443. Batch_loss: 1.238283 \n",
      "Batch: 2870. Acc: 0.545029. Loss: 1.256418. Batch_acc: 0.546659. Batch_loss: 1.248350 \n",
      "Batch: 2871. Acc: 0.545034. Loss: 1.256404. Batch_acc: 0.557517. Batch_loss: 1.215909 \n",
      "Batch: 2872. Acc: 0.545035. Loss: 1.256406. Batch_acc: 0.547387. Batch_loss: 1.263035 \n",
      "Batch: 2873. Acc: 0.545033. Loss: 1.256402. Batch_acc: 0.540461. Batch_loss: 1.243595 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2874. Acc: 0.545033. Loss: 1.256399. Batch_acc: 0.545562. Batch_loss: 1.247402 \n",
      "Batch: 2875. Acc: 0.545040. Loss: 1.256374. Batch_acc: 0.564607. Batch_loss: 1.186684 \n",
      "Batch: 2876. Acc: 0.545048. Loss: 1.256361. Batch_acc: 0.566723. Batch_loss: 1.219772 \n",
      "Batch: 2877. Acc: 0.545041. Loss: 1.256384. Batch_acc: 0.526464. Batch_loss: 1.319882 \n",
      "Batch: 2878. Acc: 0.545031. Loss: 1.256403. Batch_acc: 0.516167. Batch_loss: 1.314192 \n",
      "Batch: 2879. Acc: 0.545035. Loss: 1.256397. Batch_acc: 0.554896. Batch_loss: 1.237739 \n",
      "Batch: 2880. Acc: 0.545038. Loss: 1.256391. Batch_acc: 0.555814. Batch_loss: 1.239168 \n",
      "Batch: 2881. Acc: 0.545031. Loss: 1.256418. Batch_acc: 0.524656. Batch_loss: 1.334672 \n",
      "Batch: 2882. Acc: 0.545034. Loss: 1.256408. Batch_acc: 0.551289. Batch_loss: 1.226182 \n",
      "Batch: 2883. Acc: 0.545044. Loss: 1.256387. Batch_acc: 0.575311. Batch_loss: 1.197290 \n",
      "Batch: 2884. Acc: 0.545036. Loss: 1.256398. Batch_acc: 0.522650. Batch_loss: 1.287103 \n",
      "Batch: 2885. Acc: 0.545041. Loss: 1.256387. Batch_acc: 0.557191. Batch_loss: 1.225416 \n",
      "Batch: 2886. Acc: 0.545038. Loss: 1.256397. Batch_acc: 0.538593. Batch_loss: 1.285912 \n",
      "Batch: 2887. Acc: 0.545039. Loss: 1.256392. Batch_acc: 0.547381. Batch_loss: 1.239876 \n",
      "Batch: 2888. Acc: 0.545045. Loss: 1.256372. Batch_acc: 0.562925. Batch_loss: 1.199520 \n",
      "Batch: 2889. Acc: 0.545045. Loss: 1.256371. Batch_acc: 0.543188. Batch_loss: 1.255695 \n",
      "Batch: 2890. Acc: 0.545048. Loss: 1.256352. Batch_acc: 0.554715. Batch_loss: 1.200917 \n",
      "Batch: 2891. Acc: 0.545060. Loss: 1.256317. Batch_acc: 0.578887. Batch_loss: 1.153214 \n",
      "Batch: 2892. Acc: 0.545059. Loss: 1.256310. Batch_acc: 0.542197. Batch_loss: 1.238002 \n",
      "Batch: 2893. Acc: 0.545062. Loss: 1.256298. Batch_acc: 0.554724. Batch_loss: 1.219615 \n",
      "Batch: 2894. Acc: 0.545058. Loss: 1.256296. Batch_acc: 0.532945. Batch_loss: 1.251400 \n",
      "Batch: 2895. Acc: 0.545064. Loss: 1.256272. Batch_acc: 0.562137. Batch_loss: 1.187454 \n",
      "Batch: 2896. Acc: 0.545071. Loss: 1.256253. Batch_acc: 0.565192. Batch_loss: 1.197801 \n",
      "Batch: 2897. Acc: 0.545071. Loss: 1.256259. Batch_acc: 0.546750. Batch_loss: 1.273268 \n",
      "Batch: 2898. Acc: 0.545073. Loss: 1.256247. Batch_acc: 0.549508. Batch_loss: 1.223246 \n",
      "Batch: 2899. Acc: 0.545086. Loss: 1.256209. Batch_acc: 0.583194. Batch_loss: 1.149192 \n",
      "Batch: 2900. Acc: 0.545090. Loss: 1.256190. Batch_acc: 0.555024. Batch_loss: 1.198529 \n",
      "Batch: 2901. Acc: 0.545097. Loss: 1.256171. Batch_acc: 0.567130. Batch_loss: 1.200363 \n",
      "Batch: 2902. Acc: 0.545094. Loss: 1.256182. Batch_acc: 0.536232. Batch_loss: 1.289114 \n",
      "Batch: 2903. Acc: 0.545102. Loss: 1.256158. Batch_acc: 0.568091. Batch_loss: 1.186431 \n",
      "Batch: 2904. Acc: 0.545109. Loss: 1.256135. Batch_acc: 0.564758. Batch_loss: 1.190732 \n",
      "Batch: 2905. Acc: 0.545115. Loss: 1.256118. Batch_acc: 0.561588. Batch_loss: 1.206525 \n",
      "Batch: 2906. Acc: 0.545119. Loss: 1.256098. Batch_acc: 0.558396. Batch_loss: 1.197636 \n",
      "Batch: 2907. Acc: 0.545125. Loss: 1.256078. Batch_acc: 0.562428. Batch_loss: 1.197794 \n",
      "Batch: 2908. Acc: 0.545139. Loss: 1.256040. Batch_acc: 0.584580. Batch_loss: 1.146012 \n",
      "Batch: 2909. Acc: 0.545141. Loss: 1.256029. Batch_acc: 0.550392. Batch_loss: 1.224749 \n",
      "Batch: 2910. Acc: 0.545147. Loss: 1.256011. Batch_acc: 0.564414. Batch_loss: 1.203923 \n",
      "Batch: 2911. Acc: 0.545157. Loss: 1.255985. Batch_acc: 0.574179. Batch_loss: 1.181296 \n",
      "Batch: 2912. Acc: 0.545159. Loss: 1.255989. Batch_acc: 0.550536. Batch_loss: 1.265806 \n",
      "Batch: 2913. Acc: 0.545163. Loss: 1.255980. Batch_acc: 0.555877. Batch_loss: 1.231096 \n",
      "Batch: 2914. Acc: 0.545169. Loss: 1.255958. Batch_acc: 0.561714. Batch_loss: 1.191720 \n",
      "Batch: 2915. Acc: 0.545175. Loss: 1.255935. Batch_acc: 0.564894. Batch_loss: 1.188453 \n",
      "Batch: 2916. Acc: 0.545179. Loss: 1.255923. Batch_acc: 0.556128. Batch_loss: 1.222318 \n",
      "Batch: 2917. Acc: 0.545180. Loss: 1.255923. Batch_acc: 0.548131. Batch_loss: 1.256003 \n",
      "Batch: 2918. Acc: 0.545184. Loss: 1.255918. Batch_acc: 0.556125. Batch_loss: 1.242252 \n",
      "Batch: 2919. Acc: 0.545186. Loss: 1.255918. Batch_acc: 0.552273. Batch_loss: 1.254483 \n",
      "Batch: 2920. Acc: 0.545185. Loss: 1.255908. Batch_acc: 0.541903. Batch_loss: 1.228644 \n",
      "Batch: 2921. Acc: 0.545192. Loss: 1.255906. Batch_acc: 0.564014. Batch_loss: 1.249575 \n",
      "Batch: 2922. Acc: 0.545190. Loss: 1.255909. Batch_acc: 0.540787. Batch_loss: 1.262383 \n",
      "Batch: 2923. Acc: 0.545190. Loss: 1.255896. Batch_acc: 0.544260. Batch_loss: 1.220655 \n",
      "Batch: 2924. Acc: 0.545184. Loss: 1.255907. Batch_acc: 0.528488. Batch_loss: 1.287368 \n",
      "Batch: 2925. Acc: 0.545176. Loss: 1.255922. Batch_acc: 0.521053. Batch_loss: 1.300804 \n",
      "Batch: 2926. Acc: 0.545186. Loss: 1.255897. Batch_acc: 0.575029. Batch_loss: 1.183979 \n",
      "Batch: 2927. Acc: 0.545199. Loss: 1.255875. Batch_acc: 0.580427. Batch_loss: 1.190685 \n",
      "Batch: 2928. Acc: 0.545203. Loss: 1.255866. Batch_acc: 0.557925. Batch_loss: 1.229308 \n",
      "Batch: 2929. Acc: 0.545212. Loss: 1.255846. Batch_acc: 0.570458. Batch_loss: 1.198811 \n",
      "Batch: 2930. Acc: 0.545222. Loss: 1.255827. Batch_acc: 0.575946. Batch_loss: 1.201665 \n",
      "Batch: 2931. Acc: 0.545235. Loss: 1.255797. Batch_acc: 0.583480. Batch_loss: 1.165348 \n",
      "Batch: 2932. Acc: 0.545244. Loss: 1.255777. Batch_acc: 0.570191. Batch_loss: 1.198923 \n",
      "Batch: 2933. Acc: 0.545249. Loss: 1.255763. Batch_acc: 0.560879. Batch_loss: 1.214778 \n",
      "Batch: 2934. Acc: 0.545260. Loss: 1.255732. Batch_acc: 0.575913. Batch_loss: 1.163957 \n",
      "Batch: 2935. Acc: 0.545262. Loss: 1.255732. Batch_acc: 0.551479. Batch_loss: 1.256014 \n",
      "Batch: 2936. Acc: 0.545260. Loss: 1.255735. Batch_acc: 0.541290. Batch_loss: 1.264211 \n",
      "Batch: 2937. Acc: 0.545261. Loss: 1.255739. Batch_acc: 0.546458. Batch_loss: 1.269472 \n",
      "Batch: 2938. Acc: 0.545256. Loss: 1.255751. Batch_acc: 0.531741. Batch_loss: 1.290824 \n",
      "Batch: 2939. Acc: 0.545267. Loss: 1.255728. Batch_acc: 0.576223. Batch_loss: 1.187392 \n",
      "Batch: 2940. Acc: 0.545276. Loss: 1.255707. Batch_acc: 0.572235. Batch_loss: 1.196686 \n",
      "Batch: 2941. Acc: 0.545276. Loss: 1.255686. Batch_acc: 0.543440. Batch_loss: 1.191629 \n",
      "Batch: 2942. Acc: 0.545285. Loss: 1.255661. Batch_acc: 0.572794. Batch_loss: 1.185269 \n",
      "Batch: 2943. Acc: 0.545280. Loss: 1.255679. Batch_acc: 0.529851. Batch_loss: 1.307656 \n",
      "Batch: 2944. Acc: 0.545288. Loss: 1.255665. Batch_acc: 0.567831. Batch_loss: 1.216601 \n",
      "Batch: 2945. Acc: 0.545288. Loss: 1.255657. Batch_acc: 0.546857. Batch_loss: 1.231076 \n",
      "Batch: 2946. Acc: 0.545293. Loss: 1.255644. Batch_acc: 0.558532. Batch_loss: 1.218238 \n",
      "Batch: 2947. Acc: 0.545297. Loss: 1.255638. Batch_acc: 0.558411. Batch_loss: 1.234934 \n",
      "Batch: 2948. Acc: 0.545306. Loss: 1.255619. Batch_acc: 0.570768. Batch_loss: 1.200982 \n",
      "Batch: 2949. Acc: 0.545306. Loss: 1.255617. Batch_acc: 0.545139. Batch_loss: 1.248412 \n",
      "Batch: 2950. Acc: 0.545312. Loss: 1.255604. Batch_acc: 0.564618. Batch_loss: 1.217728 \n",
      "Batch: 2951. Acc: 0.545315. Loss: 1.255591. Batch_acc: 0.554054. Batch_loss: 1.218351 \n",
      "Batch: 2952. Acc: 0.545319. Loss: 1.255590. Batch_acc: 0.558059. Batch_loss: 1.252254 \n",
      "Batch: 2953. Acc: 0.545327. Loss: 1.255566. Batch_acc: 0.569356. Batch_loss: 1.184489 \n",
      "Batch: 2954. Acc: 0.545331. Loss: 1.255547. Batch_acc: 0.556268. Batch_loss: 1.196760 \n",
      "Batch: 2955. Acc: 0.545331. Loss: 1.255540. Batch_acc: 0.544084. Batch_loss: 1.235705 \n",
      "Batch: 2956. Acc: 0.545336. Loss: 1.255522. Batch_acc: 0.560807. Batch_loss: 1.200344 \n",
      "Batch: 2957. Acc: 0.545329. Loss: 1.255531. Batch_acc: 0.526316. Batch_loss: 1.282444 \n",
      "Batch: 2958. Acc: 0.545326. Loss: 1.255531. Batch_acc: 0.536458. Batch_loss: 1.256850 \n",
      "Batch: 2959. Acc: 0.545330. Loss: 1.255515. Batch_acc: 0.555621. Batch_loss: 1.205039 \n",
      "Batch: 2960. Acc: 0.545326. Loss: 1.255512. Batch_acc: 0.535068. Batch_loss: 1.248500 \n",
      "Batch: 2961. Acc: 0.545338. Loss: 1.255489. Batch_acc: 0.579128. Batch_loss: 1.186846 \n",
      "Batch: 2962. Acc: 0.545339. Loss: 1.255484. Batch_acc: 0.550313. Batch_loss: 1.240845 \n",
      "Batch: 2963. Acc: 0.545338. Loss: 1.255481. Batch_acc: 0.541572. Batch_loss: 1.247881 \n",
      "Batch: 2964. Acc: 0.545334. Loss: 1.255487. Batch_acc: 0.533721. Batch_loss: 1.272268 \n",
      "Batch: 2965. Acc: 0.545338. Loss: 1.255461. Batch_acc: 0.556452. Batch_loss: 1.177495 \n",
      "Batch: 2966. Acc: 0.545350. Loss: 1.255435. Batch_acc: 0.581182. Batch_loss: 1.178168 \n",
      "Batch: 2967. Acc: 0.545351. Loss: 1.255427. Batch_acc: 0.547977. Batch_loss: 1.233146 \n",
      "Batch: 2968. Acc: 0.545356. Loss: 1.255398. Batch_acc: 0.561644. Batch_loss: 1.168253 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 2969. Acc: 0.545357. Loss: 1.255395. Batch_acc: 0.547093. Batch_loss: 1.247211 \n",
      "Batch: 2970. Acc: 0.545358. Loss: 1.255386. Batch_acc: 0.547313. Batch_loss: 1.228898 \n",
      "Batch: 2971. Acc: 0.545362. Loss: 1.255373. Batch_acc: 0.559361. Batch_loss: 1.216627 \n",
      "Batch: 2972. Acc: 0.545363. Loss: 1.255364. Batch_acc: 0.547192. Batch_loss: 1.230206 \n",
      "Batch: 2973. Acc: 0.545368. Loss: 1.255349. Batch_acc: 0.560658. Batch_loss: 1.211471 \n",
      "Batch: 2974. Acc: 0.545360. Loss: 1.255361. Batch_acc: 0.521143. Batch_loss: 1.290797 \n",
      "Batch: 2975. Acc: 0.545361. Loss: 1.255360. Batch_acc: 0.547059. Batch_loss: 1.250998 \n",
      "Batch: 2976. Acc: 0.545354. Loss: 1.255372. Batch_acc: 0.526316. Batch_loss: 1.292039 \n",
      "Batch: 2977. Acc: 0.545352. Loss: 1.255373. Batch_acc: 0.538995. Batch_loss: 1.259130 \n",
      "Batch: 2978. Acc: 0.545361. Loss: 1.255350. Batch_acc: 0.570290. Batch_loss: 1.186259 \n",
      "Batch: 2979. Acc: 0.545366. Loss: 1.255340. Batch_acc: 0.562140. Batch_loss: 1.225702 \n",
      "Batch: 2980. Acc: 0.545370. Loss: 1.255334. Batch_acc: 0.556512. Batch_loss: 1.238199 \n",
      "Batch: 2981. Acc: 0.545376. Loss: 1.255315. Batch_acc: 0.563533. Batch_loss: 1.199353 \n",
      "Batch: 2982. Acc: 0.545374. Loss: 1.255322. Batch_acc: 0.538895. Batch_loss: 1.276146 \n",
      "Batch: 2983. Acc: 0.545375. Loss: 1.255318. Batch_acc: 0.547437. Batch_loss: 1.241971 \n",
      "Batch: 2984. Acc: 0.545379. Loss: 1.255304. Batch_acc: 0.557889. Batch_loss: 1.214130 \n",
      "Batch: 2985. Acc: 0.545375. Loss: 1.255315. Batch_acc: 0.534620. Batch_loss: 1.286933 \n",
      "Batch: 2986. Acc: 0.545384. Loss: 1.255297. Batch_acc: 0.570602. Batch_loss: 1.202551 \n",
      "Batch: 2987. Acc: 0.545395. Loss: 1.255266. Batch_acc: 0.580738. Batch_loss: 1.160772 \n",
      "Batch: 2988. Acc: 0.545393. Loss: 1.255271. Batch_acc: 0.536428. Batch_loss: 1.271428 \n",
      "Batch: 2989. Acc: 0.545393. Loss: 1.255260. Batch_acc: 0.547811. Batch_loss: 1.223828 \n",
      "Batch: 2990. Acc: 0.545397. Loss: 1.255259. Batch_acc: 0.555620. Batch_loss: 1.251015 \n",
      "Batch: 2991. Acc: 0.545394. Loss: 1.255257. Batch_acc: 0.537622. Batch_loss: 1.249822 \n",
      "Batch: 2992. Acc: 0.545401. Loss: 1.255242. Batch_acc: 0.565116. Batch_loss: 1.210998 \n",
      "Batch: 2993. Acc: 0.545411. Loss: 1.255217. Batch_acc: 0.577960. Batch_loss: 1.177394 \n",
      "Batch: 2994. Acc: 0.545410. Loss: 1.255217. Batch_acc: 0.542012. Batch_loss: 1.254774 \n",
      "Batch: 2995. Acc: 0.545414. Loss: 1.255211. Batch_acc: 0.556395. Batch_loss: 1.236281 \n",
      "Batch: 2996. Acc: 0.545421. Loss: 1.255197. Batch_acc: 0.567742. Batch_loss: 1.213530 \n",
      "Batch: 2997. Acc: 0.545428. Loss: 1.255192. Batch_acc: 0.565192. Batch_loss: 1.238537 \n",
      "Batch: 2998. Acc: 0.545430. Loss: 1.255187. Batch_acc: 0.553908. Batch_loss: 1.240752 \n",
      "Batch: 2999. Acc: 0.545435. Loss: 1.255175. Batch_acc: 0.558300. Batch_loss: 1.220223 \n",
      "Batch: 3000. Acc: 0.545436. Loss: 1.255167. Batch_acc: 0.549249. Batch_loss: 1.231271 \n",
      "Batch: 3001. Acc: 0.545443. Loss: 1.255150. Batch_acc: 0.565045. Batch_loss: 1.205265 \n",
      "Batch: 3002. Acc: 0.545444. Loss: 1.255146. Batch_acc: 0.550175. Batch_loss: 1.243584 \n",
      "Batch: 3003. Acc: 0.545445. Loss: 1.255136. Batch_acc: 0.546136. Batch_loss: 1.224663 \n",
      "Batch: 3004. Acc: 0.545448. Loss: 1.255131. Batch_acc: 0.555242. Batch_loss: 1.240212 \n",
      "Batch: 3005. Acc: 0.545449. Loss: 1.255131. Batch_acc: 0.549523. Batch_loss: 1.255282 \n",
      "Batch: 3006. Acc: 0.545450. Loss: 1.255126. Batch_acc: 0.548998. Batch_loss: 1.241295 \n",
      "Batch: 3007. Acc: 0.545455. Loss: 1.255112. Batch_acc: 0.558314. Batch_loss: 1.211706 \n",
      "Batch: 3008. Acc: 0.545461. Loss: 1.255093. Batch_acc: 0.563698. Batch_loss: 1.198833 \n",
      "Batch: 3009. Acc: 0.545473. Loss: 1.255063. Batch_acc: 0.581911. Batch_loss: 1.168091 \n",
      "Batch: 3010. Acc: 0.545480. Loss: 1.255044. Batch_acc: 0.564699. Batch_loss: 1.198403 \n",
      "Batch: 3011. Acc: 0.545487. Loss: 1.255018. Batch_acc: 0.568754. Batch_loss: 1.174903 \n",
      "Batch: 3012. Acc: 0.545487. Loss: 1.255006. Batch_acc: 0.545769. Batch_loss: 1.217171 \n",
      "Checkpointing on batch: 3012. Accuracy: 0.54548722732464. Loss per char: 1.255005668186165. Time: 1627224164.2438645\n",
      "Last question is tensor([ 2, 49, 86, 85,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 24, 22, 17, 15,\n",
      "        26, 25, 25, 23, 19, 25, 22, 20, 26, 22, 24,  1, 66, 79, 69,  1, 14, 17,\n",
      "        15, 21, 15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3013. Acc: 0.545485. Loss: 1.255003. Batch_acc: 0.539044. Batch_loss: 1.245460 \n",
      "Batch: 3014. Acc: 0.545482. Loss: 1.255005. Batch_acc: 0.537243. Batch_loss: 1.261988 \n",
      "Batch: 3015. Acc: 0.545476. Loss: 1.255030. Batch_acc: 0.524255. Batch_loss: 1.332452 \n",
      "Batch: 3016. Acc: 0.545476. Loss: 1.255022. Batch_acc: 0.546464. Batch_loss: 1.229232 \n",
      "Batch: 3017. Acc: 0.545477. Loss: 1.255011. Batch_acc: 0.548105. Batch_loss: 1.223495 \n",
      "Batch: 3018. Acc: 0.545483. Loss: 1.254989. Batch_acc: 0.564174. Batch_loss: 1.190862 \n",
      "Batch: 3019. Acc: 0.545485. Loss: 1.254988. Batch_acc: 0.552525. Batch_loss: 1.251770 \n",
      "Batch: 3020. Acc: 0.545489. Loss: 1.254974. Batch_acc: 0.557950. Batch_loss: 1.212288 \n",
      "Batch: 3021. Acc: 0.545492. Loss: 1.254968. Batch_acc: 0.553069. Batch_loss: 1.235592 \n",
      "Batch: 3022. Acc: 0.545478. Loss: 1.255003. Batch_acc: 0.501799. Batch_loss: 1.366552 \n",
      "Batch: 3023. Acc: 0.545486. Loss: 1.254975. Batch_acc: 0.568284. Batch_loss: 1.170561 \n",
      "Batch: 3024. Acc: 0.545482. Loss: 1.254981. Batch_acc: 0.533255. Batch_loss: 1.274428 \n",
      "Batch: 3025. Acc: 0.545481. Loss: 1.254980. Batch_acc: 0.541909. Batch_loss: 1.251128 \n",
      "Batch: 3026. Acc: 0.545485. Loss: 1.254957. Batch_acc: 0.558501. Batch_loss: 1.186525 \n",
      "Batch: 3027. Acc: 0.545495. Loss: 1.254930. Batch_acc: 0.576081. Batch_loss: 1.174067 \n",
      "Batch: 3028. Acc: 0.545499. Loss: 1.254915. Batch_acc: 0.557847. Batch_loss: 1.210660 \n",
      "Batch: 3029. Acc: 0.545491. Loss: 1.254939. Batch_acc: 0.519084. Batch_loss: 1.326950 \n",
      "Batch: 3030. Acc: 0.545496. Loss: 1.254920. Batch_acc: 0.562392. Batch_loss: 1.199861 \n",
      "Batch: 3031. Acc: 0.545496. Loss: 1.254922. Batch_acc: 0.543224. Batch_loss: 1.258487 \n",
      "Batch: 3032. Acc: 0.545490. Loss: 1.254938. Batch_acc: 0.528964. Batch_loss: 1.306680 \n",
      "Batch: 3033. Acc: 0.545496. Loss: 1.254931. Batch_acc: 0.561393. Batch_loss: 1.232209 \n",
      "Batch: 3034. Acc: 0.545497. Loss: 1.254930. Batch_acc: 0.549110. Batch_loss: 1.252551 \n",
      "Batch: 3035. Acc: 0.545495. Loss: 1.254944. Batch_acc: 0.538506. Batch_loss: 1.296105 \n",
      "Batch: 3036. Acc: 0.545499. Loss: 1.254926. Batch_acc: 0.559456. Batch_loss: 1.203612 \n",
      "Batch: 3037. Acc: 0.545495. Loss: 1.254941. Batch_acc: 0.532286. Batch_loss: 1.299028 \n",
      "Batch: 3038. Acc: 0.545507. Loss: 1.254910. Batch_acc: 0.583479. Batch_loss: 1.159691 \n",
      "Batch: 3039. Acc: 0.545509. Loss: 1.254898. Batch_acc: 0.551543. Batch_loss: 1.219018 \n",
      "Batch: 3040. Acc: 0.545509. Loss: 1.254887. Batch_acc: 0.546296. Batch_loss: 1.222271 \n",
      "Batch: 3041. Acc: 0.545501. Loss: 1.254903. Batch_acc: 0.519119. Batch_loss: 1.301208 \n",
      "Batch: 3042. Acc: 0.545510. Loss: 1.254875. Batch_acc: 0.573086. Batch_loss: 1.170818 \n",
      "Batch: 3043. Acc: 0.545509. Loss: 1.254882. Batch_acc: 0.541497. Batch_loss: 1.277345 \n",
      "Batch: 3044. Acc: 0.545509. Loss: 1.254883. Batch_acc: 0.546019. Batch_loss: 1.256853 \n",
      "Batch: 3045. Acc: 0.545508. Loss: 1.254874. Batch_acc: 0.541814. Batch_loss: 1.224953 \n",
      "Batch: 3046. Acc: 0.545510. Loss: 1.254872. Batch_acc: 0.552359. Batch_loss: 1.250772 \n",
      "Batch: 3047. Acc: 0.545507. Loss: 1.254868. Batch_acc: 0.536405. Batch_loss: 1.241628 \n",
      "Batch: 3048. Acc: 0.545509. Loss: 1.254864. Batch_acc: 0.552204. Batch_loss: 1.243976 \n",
      "Batch: 3049. Acc: 0.545516. Loss: 1.254842. Batch_acc: 0.568696. Batch_loss: 1.187408 \n",
      "Batch: 3050. Acc: 0.545518. Loss: 1.254840. Batch_acc: 0.549912. Batch_loss: 1.247172 \n",
      "Batch: 3051. Acc: 0.545525. Loss: 1.254833. Batch_acc: 0.565812. Batch_loss: 1.232799 \n",
      "Batch: 3052. Acc: 0.545520. Loss: 1.254840. Batch_acc: 0.530850. Batch_loss: 1.277082 \n",
      "Batch: 3053. Acc: 0.545527. Loss: 1.254819. Batch_acc: 0.568403. Batch_loss: 1.190969 \n",
      "Batch: 3054. Acc: 0.545523. Loss: 1.254831. Batch_acc: 0.532324. Batch_loss: 1.292521 \n",
      "Batch: 3055. Acc: 0.545524. Loss: 1.254831. Batch_acc: 0.549623. Batch_loss: 1.255123 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3056. Acc: 0.545531. Loss: 1.254808. Batch_acc: 0.566762. Batch_loss: 1.185089 \n",
      "Batch: 3057. Acc: 0.545532. Loss: 1.254801. Batch_acc: 0.547836. Batch_loss: 1.234360 \n",
      "Batch: 3058. Acc: 0.545535. Loss: 1.254799. Batch_acc: 0.553551. Batch_loss: 1.247273 \n",
      "Batch: 3059. Acc: 0.545530. Loss: 1.254807. Batch_acc: 0.531161. Batch_loss: 1.279506 \n",
      "Batch: 3060. Acc: 0.545532. Loss: 1.254799. Batch_acc: 0.550261. Batch_loss: 1.229565 \n",
      "Batch: 3061. Acc: 0.545531. Loss: 1.254800. Batch_acc: 0.542776. Batch_loss: 1.258126 \n",
      "Batch: 3062. Acc: 0.545528. Loss: 1.254802. Batch_acc: 0.535756. Batch_loss: 1.260504 \n",
      "Batch: 3063. Acc: 0.545536. Loss: 1.254781. Batch_acc: 0.571104. Batch_loss: 1.190767 \n",
      "Batch: 3064. Acc: 0.545533. Loss: 1.254777. Batch_acc: 0.536726. Batch_loss: 1.242555 \n",
      "Batch: 3065. Acc: 0.545533. Loss: 1.254772. Batch_acc: 0.544245. Batch_loss: 1.240436 \n",
      "Batch: 3066. Acc: 0.545540. Loss: 1.254754. Batch_acc: 0.566783. Batch_loss: 1.199254 \n",
      "Batch: 3067. Acc: 0.545538. Loss: 1.254755. Batch_acc: 0.540899. Batch_loss: 1.258407 \n",
      "Batch: 3068. Acc: 0.545541. Loss: 1.254744. Batch_acc: 0.553767. Batch_loss: 1.221322 \n",
      "Batch: 3069. Acc: 0.545545. Loss: 1.254740. Batch_acc: 0.557415. Batch_loss: 1.240147 \n",
      "Batch: 3070. Acc: 0.545542. Loss: 1.254737. Batch_acc: 0.538062. Batch_loss: 1.246738 \n",
      "Batch: 3071. Acc: 0.545545. Loss: 1.254727. Batch_acc: 0.553864. Batch_loss: 1.223919 \n",
      "Batch: 3072. Acc: 0.545550. Loss: 1.254717. Batch_acc: 0.559380. Batch_loss: 1.224072 \n",
      "Batch: 3073. Acc: 0.545557. Loss: 1.254700. Batch_acc: 0.567568. Batch_loss: 1.205558 \n",
      "Batch: 3074. Acc: 0.545555. Loss: 1.254701. Batch_acc: 0.540919. Batch_loss: 1.257915 \n",
      "Batch: 3075. Acc: 0.545552. Loss: 1.254707. Batch_acc: 0.535406. Batch_loss: 1.271680 \n",
      "Batch: 3076. Acc: 0.545549. Loss: 1.254718. Batch_acc: 0.536756. Batch_loss: 1.287543 \n",
      "Batch: 3077. Acc: 0.545546. Loss: 1.254725. Batch_acc: 0.536599. Batch_loss: 1.277276 \n",
      "Batch: 3078. Acc: 0.545546. Loss: 1.254728. Batch_acc: 0.543343. Batch_loss: 1.264070 \n",
      "Batch: 3079. Acc: 0.545540. Loss: 1.254737. Batch_acc: 0.527378. Batch_loss: 1.281816 \n",
      "Batch: 3080. Acc: 0.545544. Loss: 1.254731. Batch_acc: 0.558250. Batch_loss: 1.235419 \n",
      "Batch: 3081. Acc: 0.545551. Loss: 1.254709. Batch_acc: 0.566382. Batch_loss: 1.190002 \n",
      "Batch: 3082. Acc: 0.545544. Loss: 1.254714. Batch_acc: 0.526223. Batch_loss: 1.268712 \n",
      "Batch: 3083. Acc: 0.545550. Loss: 1.254706. Batch_acc: 0.562390. Batch_loss: 1.229108 \n",
      "Batch: 3084. Acc: 0.545544. Loss: 1.254707. Batch_acc: 0.528149. Batch_loss: 1.257920 \n",
      "Batch: 3085. Acc: 0.545550. Loss: 1.254694. Batch_acc: 0.563446. Batch_loss: 1.215876 \n",
      "Batch: 3086. Acc: 0.545551. Loss: 1.254692. Batch_acc: 0.547771. Batch_loss: 1.248393 \n",
      "Batch: 3087. Acc: 0.545552. Loss: 1.254687. Batch_acc: 0.549688. Batch_loss: 1.239116 \n",
      "Batch: 3088. Acc: 0.545547. Loss: 1.254702. Batch_acc: 0.531250. Batch_loss: 1.303348 \n",
      "Batch: 3089. Acc: 0.545552. Loss: 1.254686. Batch_acc: 0.560624. Batch_loss: 1.202188 \n",
      "Batch: 3090. Acc: 0.545552. Loss: 1.254685. Batch_acc: 0.545300. Batch_loss: 1.252319 \n",
      "Batch: 3091. Acc: 0.545558. Loss: 1.254671. Batch_acc: 0.562714. Batch_loss: 1.212387 \n",
      "Batch: 3092. Acc: 0.545567. Loss: 1.254652. Batch_acc: 0.574843. Batch_loss: 1.198009 \n",
      "Batch: 3093. Acc: 0.545578. Loss: 1.254628. Batch_acc: 0.576597. Batch_loss: 1.181070 \n",
      "Batch: 3094. Acc: 0.545583. Loss: 1.254613. Batch_acc: 0.563786. Batch_loss: 1.207640 \n",
      "Batch: 3095. Acc: 0.545589. Loss: 1.254596. Batch_acc: 0.563770. Batch_loss: 1.202709 \n",
      "Batch: 3096. Acc: 0.545593. Loss: 1.254584. Batch_acc: 0.558085. Batch_loss: 1.215802 \n",
      "Batch: 3097. Acc: 0.545597. Loss: 1.254569. Batch_acc: 0.557889. Batch_loss: 1.208612 \n",
      "Batch: 3098. Acc: 0.545598. Loss: 1.254572. Batch_acc: 0.548387. Batch_loss: 1.265578 \n",
      "Batch: 3099. Acc: 0.545597. Loss: 1.254576. Batch_acc: 0.542955. Batch_loss: 1.266549 \n",
      "Batch: 3100. Acc: 0.545604. Loss: 1.254561. Batch_acc: 0.567251. Batch_loss: 1.207636 \n",
      "Batch: 3101. Acc: 0.545616. Loss: 1.254525. Batch_acc: 0.580178. Batch_loss: 1.145040 \n",
      "Batch: 3102. Acc: 0.545623. Loss: 1.254506. Batch_acc: 0.568169. Batch_loss: 1.197479 \n",
      "Batch: 3103. Acc: 0.545634. Loss: 1.254492. Batch_acc: 0.578196. Batch_loss: 1.211949 \n",
      "Batch: 3104. Acc: 0.545642. Loss: 1.254465. Batch_acc: 0.571755. Batch_loss: 1.169849 \n",
      "Batch: 3105. Acc: 0.545648. Loss: 1.254452. Batch_acc: 0.562209. Batch_loss: 1.214345 \n",
      "Batch: 3106. Acc: 0.545648. Loss: 1.254444. Batch_acc: 0.547028. Batch_loss: 1.229363 \n",
      "Batch: 3107. Acc: 0.545658. Loss: 1.254425. Batch_acc: 0.576771. Batch_loss: 1.196250 \n",
      "Batch: 3108. Acc: 0.545662. Loss: 1.254413. Batch_acc: 0.557083. Batch_loss: 1.215667 \n",
      "Batch: 3109. Acc: 0.545665. Loss: 1.254404. Batch_acc: 0.555556. Batch_loss: 1.227324 \n",
      "Batch: 3110. Acc: 0.545667. Loss: 1.254401. Batch_acc: 0.553477. Batch_loss: 1.244703 \n",
      "Batch: 3111. Acc: 0.545669. Loss: 1.254402. Batch_acc: 0.550454. Batch_loss: 1.258336 \n",
      "Batch: 3112. Acc: 0.545675. Loss: 1.254381. Batch_acc: 0.563413. Batch_loss: 1.185786 \n",
      "Batch: 3113. Acc: 0.545675. Loss: 1.254382. Batch_acc: 0.547496. Batch_loss: 1.258066 \n",
      "Batch: 3114. Acc: 0.545675. Loss: 1.254386. Batch_acc: 0.544734. Batch_loss: 1.265740 \n",
      "Batch: 3115. Acc: 0.545677. Loss: 1.254380. Batch_acc: 0.553154. Batch_loss: 1.236843 \n",
      "Batch: 3116. Acc: 0.545678. Loss: 1.254385. Batch_acc: 0.547374. Batch_loss: 1.269753 \n",
      "Batch: 3117. Acc: 0.545681. Loss: 1.254375. Batch_acc: 0.556246. Batch_loss: 1.222534 \n",
      "Batch: 3118. Acc: 0.545690. Loss: 1.254351. Batch_acc: 0.572299. Batch_loss: 1.182311 \n",
      "Batch: 3119. Acc: 0.545688. Loss: 1.254346. Batch_acc: 0.540416. Batch_loss: 1.241282 \n",
      "Batch: 3120. Acc: 0.545688. Loss: 1.254350. Batch_acc: 0.543376. Batch_loss: 1.265087 \n",
      "Batch: 3121. Acc: 0.545695. Loss: 1.254330. Batch_acc: 0.567644. Batch_loss: 1.193873 \n",
      "Batch: 3122. Acc: 0.545699. Loss: 1.254323. Batch_acc: 0.560335. Batch_loss: 1.230954 \n",
      "Batch: 3123. Acc: 0.545697. Loss: 1.254334. Batch_acc: 0.538507. Batch_loss: 1.291125 \n",
      "Batch: 3124. Acc: 0.545699. Loss: 1.254333. Batch_acc: 0.551186. Batch_loss: 1.248815 \n",
      "Batch: 3125. Acc: 0.545695. Loss: 1.254346. Batch_acc: 0.532646. Batch_loss: 1.295070 \n",
      "Batch: 3126. Acc: 0.545699. Loss: 1.254330. Batch_acc: 0.558486. Batch_loss: 1.206089 \n",
      "Batch: 3127. Acc: 0.545712. Loss: 1.254301. Batch_acc: 0.587042. Batch_loss: 1.164616 \n",
      "Batch: 3128. Acc: 0.545716. Loss: 1.254297. Batch_acc: 0.557771. Batch_loss: 1.240977 \n",
      "Batch: 3129. Acc: 0.545720. Loss: 1.254287. Batch_acc: 0.558434. Batch_loss: 1.223498 \n",
      "Batch: 3130. Acc: 0.545716. Loss: 1.254299. Batch_acc: 0.533453. Batch_loss: 1.294583 \n",
      "Batch: 3131. Acc: 0.545711. Loss: 1.254312. Batch_acc: 0.529752. Batch_loss: 1.292984 \n",
      "Batch: 3132. Acc: 0.545713. Loss: 1.254306. Batch_acc: 0.552005. Batch_loss: 1.236450 \n",
      "Batch: 3133. Acc: 0.545728. Loss: 1.254270. Batch_acc: 0.592401. Batch_loss: 1.140937 \n",
      "Batch: 3134. Acc: 0.545731. Loss: 1.254259. Batch_acc: 0.556466. Batch_loss: 1.219472 \n",
      "Batch: 3135. Acc: 0.545736. Loss: 1.254242. Batch_acc: 0.558723. Batch_loss: 1.202069 \n",
      "Batch: 3136. Acc: 0.545737. Loss: 1.254236. Batch_acc: 0.550437. Batch_loss: 1.233649 \n",
      "Batch: 3137. Acc: 0.545745. Loss: 1.254211. Batch_acc: 0.571023. Batch_loss: 1.177035 \n",
      "Batch: 3138. Acc: 0.545745. Loss: 1.254211. Batch_acc: 0.545930. Batch_loss: 1.255638 \n",
      "Batch: 3139. Acc: 0.545748. Loss: 1.254211. Batch_acc: 0.553633. Batch_loss: 1.253150 \n",
      "Batch: 3140. Acc: 0.545746. Loss: 1.254206. Batch_acc: 0.539607. Batch_loss: 1.238245 \n",
      "Batch: 3141. Acc: 0.545751. Loss: 1.254193. Batch_acc: 0.562204. Batch_loss: 1.212595 \n",
      "Batch: 3142. Acc: 0.545758. Loss: 1.254176. Batch_acc: 0.568445. Batch_loss: 1.200044 \n",
      "Batch: 3143. Acc: 0.545758. Loss: 1.254174. Batch_acc: 0.545250. Batch_loss: 1.249481 \n",
      "Batch: 3144. Acc: 0.545771. Loss: 1.254138. Batch_acc: 0.585023. Batch_loss: 1.141576 \n",
      "Batch: 3145. Acc: 0.545780. Loss: 1.254121. Batch_acc: 0.574385. Batch_loss: 1.201859 \n",
      "Batch: 3146. Acc: 0.545777. Loss: 1.254134. Batch_acc: 0.534753. Batch_loss: 1.295002 \n",
      "Batch: 3147. Acc: 0.545772. Loss: 1.254148. Batch_acc: 0.530268. Batch_loss: 1.298841 \n",
      "Batch: 3148. Acc: 0.545780. Loss: 1.254125. Batch_acc: 0.570687. Batch_loss: 1.179854 \n",
      "Batch: 3149. Acc: 0.545783. Loss: 1.254117. Batch_acc: 0.554926. Batch_loss: 1.231809 \n",
      "Batch: 3150. Acc: 0.545786. Loss: 1.254104. Batch_acc: 0.557681. Batch_loss: 1.211568 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3151. Acc: 0.545791. Loss: 1.254085. Batch_acc: 0.559195. Batch_loss: 1.196344 \n",
      "Batch: 3152. Acc: 0.545789. Loss: 1.254095. Batch_acc: 0.540163. Batch_loss: 1.285098 \n",
      "Batch: 3153. Acc: 0.545799. Loss: 1.254073. Batch_acc: 0.577140. Batch_loss: 1.185117 \n",
      "Batch: 3154. Acc: 0.545799. Loss: 1.254061. Batch_acc: 0.545141. Batch_loss: 1.216760 \n",
      "Batch: 3155. Acc: 0.545805. Loss: 1.254049. Batch_acc: 0.564442. Batch_loss: 1.218092 \n",
      "Batch: 3156. Acc: 0.545812. Loss: 1.254035. Batch_acc: 0.570110. Batch_loss: 1.207989 \n",
      "Batch: 3157. Acc: 0.545818. Loss: 1.254022. Batch_acc: 0.562144. Batch_loss: 1.212399 \n",
      "Batch: 3158. Acc: 0.545812. Loss: 1.254035. Batch_acc: 0.526347. Batch_loss: 1.297473 \n",
      "Batch: 3159. Acc: 0.545817. Loss: 1.254024. Batch_acc: 0.562251. Batch_loss: 1.218663 \n",
      "Batch: 3160. Acc: 0.545823. Loss: 1.254003. Batch_acc: 0.564117. Batch_loss: 1.187967 \n",
      "Batch: 3161. Acc: 0.545826. Loss: 1.254001. Batch_acc: 0.555490. Batch_loss: 1.247245 \n",
      "Batch: 3162. Acc: 0.545831. Loss: 1.253993. Batch_acc: 0.562356. Batch_loss: 1.228551 \n",
      "Batch: 3163. Acc: 0.545821. Loss: 1.254009. Batch_acc: 0.515312. Batch_loss: 1.307173 \n",
      "Batch: 3164. Acc: 0.545823. Loss: 1.254002. Batch_acc: 0.550784. Batch_loss: 1.231519 \n",
      "Batch: 3165. Acc: 0.545827. Loss: 1.253994. Batch_acc: 0.557715. Batch_loss: 1.227173 \n",
      "Batch: 3166. Acc: 0.545824. Loss: 1.253996. Batch_acc: 0.537616. Batch_loss: 1.262410 \n",
      "Batch: 3167. Acc: 0.545828. Loss: 1.253985. Batch_acc: 0.556998. Batch_loss: 1.219908 \n",
      "Batch: 3168. Acc: 0.545825. Loss: 1.253989. Batch_acc: 0.538895. Batch_loss: 1.264831 \n",
      "Batch: 3169. Acc: 0.545825. Loss: 1.253992. Batch_acc: 0.545613. Batch_loss: 1.264504 \n",
      "Batch: 3170. Acc: 0.545830. Loss: 1.253974. Batch_acc: 0.561302. Batch_loss: 1.195423 \n",
      "Batch: 3171. Acc: 0.545834. Loss: 1.253959. Batch_acc: 0.558907. Batch_loss: 1.207119 \n",
      "Batch: 3172. Acc: 0.545832. Loss: 1.253960. Batch_acc: 0.537313. Batch_loss: 1.256324 \n",
      "Batch: 3173. Acc: 0.545836. Loss: 1.253944. Batch_acc: 0.560879. Batch_loss: 1.205952 \n",
      "Batch: 3174. Acc: 0.545844. Loss: 1.253932. Batch_acc: 0.567950. Batch_loss: 1.214149 \n",
      "Batch: 3175. Acc: 0.545848. Loss: 1.253919. Batch_acc: 0.560159. Batch_loss: 1.215820 \n",
      "Batch: 3176. Acc: 0.545850. Loss: 1.253910. Batch_acc: 0.552846. Batch_loss: 1.223557 \n",
      "Batch: 3177. Acc: 0.545851. Loss: 1.253902. Batch_acc: 0.546705. Batch_loss: 1.230228 \n",
      "Batch: 3178. Acc: 0.545851. Loss: 1.253903. Batch_acc: 0.546291. Batch_loss: 1.255627 \n",
      "Batch: 3179. Acc: 0.545863. Loss: 1.253876. Batch_acc: 0.583193. Batch_loss: 1.171169 \n",
      "Batch: 3180. Acc: 0.545870. Loss: 1.253871. Batch_acc: 0.568143. Batch_loss: 1.237355 \n",
      "Batch: 3181. Acc: 0.545875. Loss: 1.253866. Batch_acc: 0.562608. Batch_loss: 1.237674 \n",
      "Batch: 3182. Acc: 0.545878. Loss: 1.253855. Batch_acc: 0.553933. Batch_loss: 1.219194 \n",
      "Batch: 3183. Acc: 0.545880. Loss: 1.253863. Batch_acc: 0.552023. Batch_loss: 1.281096 \n",
      "Batch: 3184. Acc: 0.545880. Loss: 1.253858. Batch_acc: 0.547441. Batch_loss: 1.237213 \n",
      "Batch: 3185. Acc: 0.545882. Loss: 1.253847. Batch_acc: 0.553167. Batch_loss: 1.217203 \n",
      "Batch: 3186. Acc: 0.545890. Loss: 1.253825. Batch_acc: 0.569468. Batch_loss: 1.184980 \n",
      "Batch: 3187. Acc: 0.545897. Loss: 1.253810. Batch_acc: 0.569880. Batch_loss: 1.206214 \n",
      "Batch: 3188. Acc: 0.545898. Loss: 1.253805. Batch_acc: 0.546697. Batch_loss: 1.236732 \n",
      "Batch: 3189. Acc: 0.545905. Loss: 1.253798. Batch_acc: 0.568354. Batch_loss: 1.233915 \n",
      "Batch: 3190. Acc: 0.545905. Loss: 1.253798. Batch_acc: 0.547674. Batch_loss: 1.252794 \n",
      "Batch: 3191. Acc: 0.545906. Loss: 1.253792. Batch_acc: 0.549120. Batch_loss: 1.235397 \n",
      "Batch: 3192. Acc: 0.545909. Loss: 1.253785. Batch_acc: 0.554802. Batch_loss: 1.230110 \n",
      "Batch: 3193. Acc: 0.545909. Loss: 1.253788. Batch_acc: 0.545037. Batch_loss: 1.264791 \n",
      "Batch: 3194. Acc: 0.545917. Loss: 1.253773. Batch_acc: 0.572426. Batch_loss: 1.206538 \n",
      "Batch: 3195. Acc: 0.545919. Loss: 1.253767. Batch_acc: 0.553191. Batch_loss: 1.232637 \n",
      "Batch: 3196. Acc: 0.545930. Loss: 1.253736. Batch_acc: 0.581143. Batch_loss: 1.155096 \n",
      "Batch: 3197. Acc: 0.545934. Loss: 1.253734. Batch_acc: 0.557452. Batch_loss: 1.246176 \n",
      "Batch: 3198. Acc: 0.545938. Loss: 1.253718. Batch_acc: 0.558419. Batch_loss: 1.203404 \n",
      "Batch: 3199. Acc: 0.545941. Loss: 1.253706. Batch_acc: 0.556064. Batch_loss: 1.215740 \n",
      "Batch: 3200. Acc: 0.545947. Loss: 1.253692. Batch_acc: 0.563812. Batch_loss: 1.209452 \n",
      "Batch: 3201. Acc: 0.545953. Loss: 1.253674. Batch_acc: 0.566647. Batch_loss: 1.195292 \n",
      "Batch: 3202. Acc: 0.545966. Loss: 1.253650. Batch_acc: 0.588640. Batch_loss: 1.178947 \n",
      "Batch: 3203. Acc: 0.545971. Loss: 1.253645. Batch_acc: 0.559741. Batch_loss: 1.236292 \n",
      "Batch: 3204. Acc: 0.545981. Loss: 1.253622. Batch_acc: 0.577314. Batch_loss: 1.180123 \n",
      "Batch: 3205. Acc: 0.545984. Loss: 1.253610. Batch_acc: 0.558258. Batch_loss: 1.218626 \n",
      "Batch: 3206. Acc: 0.545988. Loss: 1.253607. Batch_acc: 0.558206. Batch_loss: 1.242896 \n",
      "Batch: 3207. Acc: 0.545995. Loss: 1.253581. Batch_acc: 0.567384. Batch_loss: 1.170357 \n",
      "Batch: 3208. Acc: 0.545999. Loss: 1.253570. Batch_acc: 0.557028. Batch_loss: 1.218279 \n",
      "Batch: 3209. Acc: 0.546005. Loss: 1.253557. Batch_acc: 0.567678. Batch_loss: 1.213374 \n",
      "Batch: 3210. Acc: 0.546013. Loss: 1.253539. Batch_acc: 0.569748. Batch_loss: 1.194912 \n",
      "Batch: 3211. Acc: 0.546016. Loss: 1.253538. Batch_acc: 0.555492. Batch_loss: 1.251924 \n",
      "Batch: 3212. Acc: 0.546019. Loss: 1.253529. Batch_acc: 0.556977. Batch_loss: 1.224965 \n",
      "Batch: 3213. Acc: 0.546015. Loss: 1.253544. Batch_acc: 0.531866. Batch_loss: 1.300754 \n",
      "Batch: 3214. Acc: 0.546015. Loss: 1.253536. Batch_acc: 0.547437. Batch_loss: 1.227307 \n",
      "Batch: 3215. Acc: 0.546016. Loss: 1.253534. Batch_acc: 0.549971. Batch_loss: 1.248775 \n",
      "Batch: 3216. Acc: 0.546023. Loss: 1.253512. Batch_acc: 0.568078. Batch_loss: 1.181349 \n",
      "Batch: 3217. Acc: 0.546026. Loss: 1.253504. Batch_acc: 0.555682. Batch_loss: 1.229001 \n",
      "Batch: 3218. Acc: 0.546031. Loss: 1.253490. Batch_acc: 0.559628. Batch_loss: 1.206833 \n",
      "Batch: 3219. Acc: 0.546039. Loss: 1.253468. Batch_acc: 0.573598. Batch_loss: 1.181598 \n",
      "Batch: 3220. Acc: 0.546046. Loss: 1.253453. Batch_acc: 0.568594. Batch_loss: 1.207483 \n",
      "Batch: 3221. Acc: 0.546048. Loss: 1.253450. Batch_acc: 0.551260. Batch_loss: 1.242263 \n",
      "Batch: 3222. Acc: 0.546035. Loss: 1.253480. Batch_acc: 0.503550. Batch_loss: 1.352520 \n",
      "Batch: 3223. Acc: 0.546032. Loss: 1.253478. Batch_acc: 0.535777. Batch_loss: 1.248451 \n",
      "Batch: 3224. Acc: 0.546031. Loss: 1.253485. Batch_acc: 0.543717. Batch_loss: 1.273685 \n",
      "Batch: 3225. Acc: 0.546030. Loss: 1.253493. Batch_acc: 0.543717. Batch_loss: 1.282274 \n",
      "Batch: 3226. Acc: 0.546040. Loss: 1.253468. Batch_acc: 0.578018. Batch_loss: 1.173435 \n",
      "Batch: 3227. Acc: 0.546044. Loss: 1.253458. Batch_acc: 0.559042. Batch_loss: 1.219757 \n",
      "Batch: 3228. Acc: 0.546048. Loss: 1.253447. Batch_acc: 0.557725. Batch_loss: 1.219186 \n",
      "Batch: 3229. Acc: 0.546051. Loss: 1.253444. Batch_acc: 0.556779. Batch_loss: 1.242011 \n",
      "Batch: 3230. Acc: 0.546053. Loss: 1.253439. Batch_acc: 0.550549. Batch_loss: 1.237970 \n",
      "Batch: 3231. Acc: 0.546057. Loss: 1.253429. Batch_acc: 0.561019. Batch_loss: 1.220843 \n",
      "Batch: 3232. Acc: 0.546060. Loss: 1.253418. Batch_acc: 0.554472. Batch_loss: 1.216401 \n",
      "Batch: 3233. Acc: 0.546065. Loss: 1.253392. Batch_acc: 0.561856. Batch_loss: 1.170686 \n",
      "Batch: 3234. Acc: 0.546073. Loss: 1.253379. Batch_acc: 0.571105. Batch_loss: 1.210678 \n",
      "Batch: 3235. Acc: 0.546077. Loss: 1.253368. Batch_acc: 0.560251. Batch_loss: 1.218089 \n",
      "Batch: 3236. Acc: 0.546084. Loss: 1.253353. Batch_acc: 0.568064. Batch_loss: 1.205143 \n",
      "Batch: 3237. Acc: 0.546085. Loss: 1.253349. Batch_acc: 0.551354. Batch_loss: 1.240323 \n",
      "Batch: 3238. Acc: 0.546086. Loss: 1.253346. Batch_acc: 0.549412. Batch_loss: 1.245618 \n",
      "Batch: 3239. Acc: 0.546088. Loss: 1.253338. Batch_acc: 0.552813. Batch_loss: 1.225784 \n",
      "Batch: 3240. Acc: 0.546089. Loss: 1.253329. Batch_acc: 0.549255. Batch_loss: 1.226022 \n",
      "Batch: 3241. Acc: 0.546091. Loss: 1.253322. Batch_acc: 0.552204. Batch_loss: 1.228506 \n",
      "Batch: 3242. Acc: 0.546095. Loss: 1.253319. Batch_acc: 0.559312. Batch_loss: 1.243355 \n",
      "Batch: 3243. Acc: 0.546098. Loss: 1.253308. Batch_acc: 0.554588. Batch_loss: 1.218270 \n",
      "Batch: 3244. Acc: 0.546103. Loss: 1.253291. Batch_acc: 0.564193. Batch_loss: 1.198621 \n",
      "Batch: 3245. Acc: 0.546112. Loss: 1.253271. Batch_acc: 0.575221. Batch_loss: 1.186057 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3246. Acc: 0.546113. Loss: 1.253277. Batch_acc: 0.548122. Batch_loss: 1.273824 \n",
      "Batch: 3247. Acc: 0.546121. Loss: 1.253254. Batch_acc: 0.571348. Batch_loss: 1.179443 \n",
      "Batch: 3248. Acc: 0.546127. Loss: 1.253231. Batch_acc: 0.566406. Batch_loss: 1.179089 \n",
      "Batch: 3249. Acc: 0.546129. Loss: 1.253220. Batch_acc: 0.552514. Batch_loss: 1.220801 \n",
      "Batch: 3250. Acc: 0.546137. Loss: 1.253219. Batch_acc: 0.570618. Batch_loss: 1.246922 \n",
      "Batch: 3251. Acc: 0.546139. Loss: 1.253217. Batch_acc: 0.554472. Batch_loss: 1.248782 \n",
      "Batch: 3252. Acc: 0.546140. Loss: 1.253210. Batch_acc: 0.547137. Batch_loss: 1.230467 \n",
      "Batch: 3253. Acc: 0.546140. Loss: 1.253214. Batch_acc: 0.546697. Batch_loss: 1.266199 \n",
      "Batch: 3254. Acc: 0.546145. Loss: 1.253191. Batch_acc: 0.562676. Batch_loss: 1.180607 \n",
      "Batch: 3255. Acc: 0.546149. Loss: 1.253173. Batch_acc: 0.558192. Batch_loss: 1.194283 \n",
      "Batch: 3256. Acc: 0.546151. Loss: 1.253172. Batch_acc: 0.551971. Batch_loss: 1.248389 \n",
      "Batch: 3257. Acc: 0.546157. Loss: 1.253157. Batch_acc: 0.567894. Batch_loss: 1.205598 \n",
      "Batch: 3258. Acc: 0.546146. Loss: 1.253185. Batch_acc: 0.509390. Batch_loss: 1.344900 \n",
      "Batch: 3259. Acc: 0.546146. Loss: 1.253190. Batch_acc: 0.546189. Batch_loss: 1.270950 \n",
      "Batch: 3260. Acc: 0.546152. Loss: 1.253174. Batch_acc: 0.563647. Batch_loss: 1.202678 \n",
      "Batch: 3261. Acc: 0.546154. Loss: 1.253168. Batch_acc: 0.555428. Batch_loss: 1.232846 \n",
      "Batch: 3262. Acc: 0.546163. Loss: 1.253142. Batch_acc: 0.572313. Batch_loss: 1.169666 \n",
      "Batch: 3263. Acc: 0.546170. Loss: 1.253127. Batch_acc: 0.570335. Batch_loss: 1.202024 \n",
      "Checkpointing on batch: 3263. Accuracy: 0.5461698465499379. Loss per char: 1.253126727457211. Time: 1627224344.864365\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 23,  1, 71, 83, 80, 78,  1, 14,\n",
      "        24, 25, 22, 21, 23, 21, 26, 19, 17, 25, 21, 19, 15,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3264. Acc: 0.546177. Loss: 1.253110. Batch_acc: 0.568312. Batch_loss: 1.197855 \n",
      "Batch: 3265. Acc: 0.546172. Loss: 1.253122. Batch_acc: 0.529930. Batch_loss: 1.293558 \n",
      "Batch: 3266. Acc: 0.546176. Loss: 1.253108. Batch_acc: 0.558756. Batch_loss: 1.208586 \n",
      "Batch: 3267. Acc: 0.546173. Loss: 1.253114. Batch_acc: 0.538462. Batch_loss: 1.271438 \n",
      "Batch: 3268. Acc: 0.546175. Loss: 1.253109. Batch_acc: 0.550708. Batch_loss: 1.237936 \n",
      "Batch: 3269. Acc: 0.546174. Loss: 1.253110. Batch_acc: 0.543972. Batch_loss: 1.256092 \n",
      "Batch: 3270. Acc: 0.546174. Loss: 1.253116. Batch_acc: 0.547801. Batch_loss: 1.271425 \n",
      "Batch: 3271. Acc: 0.546172. Loss: 1.253118. Batch_acc: 0.536374. Batch_loss: 1.260096 \n",
      "Batch: 3272. Acc: 0.546177. Loss: 1.253102. Batch_acc: 0.563562. Batch_loss: 1.200405 \n",
      "Batch: 3273. Acc: 0.546187. Loss: 1.253075. Batch_acc: 0.578369. Batch_loss: 1.165623 \n",
      "Batch: 3274. Acc: 0.546192. Loss: 1.253059. Batch_acc: 0.565389. Batch_loss: 1.200024 \n",
      "Batch: 3275. Acc: 0.546204. Loss: 1.253034. Batch_acc: 0.584198. Batch_loss: 1.170021 \n",
      "Batch: 3276. Acc: 0.546203. Loss: 1.253039. Batch_acc: 0.543153. Batch_loss: 1.270404 \n",
      "Batch: 3277. Acc: 0.546208. Loss: 1.253026. Batch_acc: 0.562500. Batch_loss: 1.212877 \n",
      "Batch: 3278. Acc: 0.546211. Loss: 1.253017. Batch_acc: 0.554857. Batch_loss: 1.222963 \n",
      "Batch: 3279. Acc: 0.546212. Loss: 1.253017. Batch_acc: 0.548986. Batch_loss: 1.253712 \n",
      "Batch: 3280. Acc: 0.546217. Loss: 1.253008. Batch_acc: 0.563523. Batch_loss: 1.222437 \n",
      "Batch: 3281. Acc: 0.546217. Loss: 1.253008. Batch_acc: 0.547028. Batch_loss: 1.254203 \n",
      "Batch: 3282. Acc: 0.546222. Loss: 1.252990. Batch_acc: 0.561621. Batch_loss: 1.195675 \n",
      "Batch: 3283. Acc: 0.546226. Loss: 1.252984. Batch_acc: 0.559664. Batch_loss: 1.233672 \n",
      "Batch: 3284. Acc: 0.546232. Loss: 1.252964. Batch_acc: 0.565290. Batch_loss: 1.187258 \n",
      "Batch: 3285. Acc: 0.546236. Loss: 1.252952. Batch_acc: 0.559389. Batch_loss: 1.213864 \n",
      "Batch: 3286. Acc: 0.546238. Loss: 1.252948. Batch_acc: 0.552995. Batch_loss: 1.239368 \n",
      "Batch: 3287. Acc: 0.546242. Loss: 1.252935. Batch_acc: 0.557070. Batch_loss: 1.211971 \n",
      "Batch: 3288. Acc: 0.546235. Loss: 1.252945. Batch_acc: 0.523918. Batch_loss: 1.286930 \n",
      "Batch: 3289. Acc: 0.546237. Loss: 1.252946. Batch_acc: 0.554508. Batch_loss: 1.256557 \n",
      "Batch: 3290. Acc: 0.546242. Loss: 1.252929. Batch_acc: 0.560364. Batch_loss: 1.195504 \n",
      "Batch: 3291. Acc: 0.546240. Loss: 1.252927. Batch_acc: 0.539085. Batch_loss: 1.247362 \n",
      "Batch: 3292. Acc: 0.546240. Loss: 1.252935. Batch_acc: 0.547730. Batch_loss: 1.278378 \n",
      "Batch: 3293. Acc: 0.546247. Loss: 1.252911. Batch_acc: 0.567811. Batch_loss: 1.176057 \n",
      "Batch: 3294. Acc: 0.546247. Loss: 1.252910. Batch_acc: 0.548444. Batch_loss: 1.250674 \n",
      "Batch: 3295. Acc: 0.546248. Loss: 1.252902. Batch_acc: 0.548647. Batch_loss: 1.227255 \n",
      "Batch: 3296. Acc: 0.546246. Loss: 1.252911. Batch_acc: 0.538905. Batch_loss: 1.281566 \n",
      "Batch: 3297. Acc: 0.546246. Loss: 1.252915. Batch_acc: 0.548144. Batch_loss: 1.265647 \n",
      "Batch: 3298. Acc: 0.546249. Loss: 1.252915. Batch_acc: 0.553666. Batch_loss: 1.252196 \n",
      "Batch: 3299. Acc: 0.546254. Loss: 1.252899. Batch_acc: 0.565242. Batch_loss: 1.202144 \n",
      "Batch: 3300. Acc: 0.546260. Loss: 1.252883. Batch_acc: 0.563574. Batch_loss: 1.200190 \n",
      "Batch: 3301. Acc: 0.546262. Loss: 1.252873. Batch_acc: 0.552692. Batch_loss: 1.218171 \n",
      "Batch: 3302. Acc: 0.546265. Loss: 1.252869. Batch_acc: 0.559233. Batch_loss: 1.239453 \n",
      "Batch: 3303. Acc: 0.546276. Loss: 1.252834. Batch_acc: 0.579476. Batch_loss: 1.140438 \n",
      "Batch: 3304. Acc: 0.546274. Loss: 1.252832. Batch_acc: 0.540176. Batch_loss: 1.246458 \n",
      "Batch: 3305. Acc: 0.546275. Loss: 1.252824. Batch_acc: 0.550562. Batch_loss: 1.227025 \n",
      "Batch: 3306. Acc: 0.546284. Loss: 1.252805. Batch_acc: 0.573678. Batch_loss: 1.190907 \n",
      "Batch: 3307. Acc: 0.546290. Loss: 1.252790. Batch_acc: 0.568481. Batch_loss: 1.203045 \n",
      "Batch: 3308. Acc: 0.546294. Loss: 1.252773. Batch_acc: 0.559042. Batch_loss: 1.198065 \n",
      "Batch: 3309. Acc: 0.546297. Loss: 1.252764. Batch_acc: 0.553633. Batch_loss: 1.222897 \n",
      "Batch: 3310. Acc: 0.546294. Loss: 1.252761. Batch_acc: 0.538192. Batch_loss: 1.241549 \n",
      "Batch: 3311. Acc: 0.546303. Loss: 1.252738. Batch_acc: 0.573348. Batch_loss: 1.179596 \n",
      "Batch: 3312. Acc: 0.546304. Loss: 1.252730. Batch_acc: 0.551508. Batch_loss: 1.225075 \n",
      "Batch: 3313. Acc: 0.546314. Loss: 1.252700. Batch_acc: 0.580082. Batch_loss: 1.153455 \n",
      "Batch: 3314. Acc: 0.546322. Loss: 1.252684. Batch_acc: 0.570862. Batch_loss: 1.200517 \n",
      "Batch: 3315. Acc: 0.546328. Loss: 1.252666. Batch_acc: 0.566741. Batch_loss: 1.193582 \n",
      "Batch: 3316. Acc: 0.546326. Loss: 1.252666. Batch_acc: 0.538068. Batch_loss: 1.254537 \n",
      "Batch: 3317. Acc: 0.546329. Loss: 1.252655. Batch_acc: 0.557854. Batch_loss: 1.216149 \n",
      "Batch: 3318. Acc: 0.546326. Loss: 1.252654. Batch_acc: 0.536215. Batch_loss: 1.250169 \n",
      "Batch: 3319. Acc: 0.546329. Loss: 1.252652. Batch_acc: 0.555427. Batch_loss: 1.246048 \n",
      "Batch: 3320. Acc: 0.546327. Loss: 1.252648. Batch_acc: 0.540369. Batch_loss: 1.238979 \n",
      "Batch: 3321. Acc: 0.546334. Loss: 1.252632. Batch_acc: 0.568583. Batch_loss: 1.198864 \n",
      "Batch: 3322. Acc: 0.546331. Loss: 1.252639. Batch_acc: 0.538286. Batch_loss: 1.276330 \n",
      "Batch: 3323. Acc: 0.546334. Loss: 1.252630. Batch_acc: 0.556000. Batch_loss: 1.224411 \n",
      "Batch: 3324. Acc: 0.546340. Loss: 1.252620. Batch_acc: 0.565217. Batch_loss: 1.219945 \n",
      "Batch: 3325. Acc: 0.546343. Loss: 1.252615. Batch_acc: 0.555236. Batch_loss: 1.235350 \n",
      "Batch: 3326. Acc: 0.546342. Loss: 1.252618. Batch_acc: 0.544653. Batch_loss: 1.263162 \n",
      "Batch: 3327. Acc: 0.546339. Loss: 1.252625. Batch_acc: 0.535406. Batch_loss: 1.274383 \n",
      "Batch: 3328. Acc: 0.546339. Loss: 1.252615. Batch_acc: 0.547429. Batch_loss: 1.219482 \n",
      "Batch: 3329. Acc: 0.546334. Loss: 1.252633. Batch_acc: 0.529678. Batch_loss: 1.312942 \n",
      "Batch: 3330. Acc: 0.546342. Loss: 1.252620. Batch_acc: 0.571260. Batch_loss: 1.208856 \n",
      "Batch: 3331. Acc: 0.546345. Loss: 1.252611. Batch_acc: 0.558206. Batch_loss: 1.221443 \n",
      "Batch: 3332. Acc: 0.546355. Loss: 1.252580. Batch_acc: 0.579685. Batch_loss: 1.148991 \n",
      "Batch: 3333. Acc: 0.546365. Loss: 1.252557. Batch_acc: 0.579310. Batch_loss: 1.175793 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3334. Acc: 0.546370. Loss: 1.252548. Batch_acc: 0.563452. Batch_loss: 1.222857 \n",
      "Batch: 3335. Acc: 0.546378. Loss: 1.252527. Batch_acc: 0.572982. Batch_loss: 1.182756 \n",
      "Batch: 3336. Acc: 0.546376. Loss: 1.252526. Batch_acc: 0.538416. Batch_loss: 1.248600 \n",
      "Batch: 3337. Acc: 0.546385. Loss: 1.252500. Batch_acc: 0.575531. Batch_loss: 1.166830 \n",
      "Batch: 3338. Acc: 0.546381. Loss: 1.252510. Batch_acc: 0.534924. Batch_loss: 1.284959 \n",
      "Batch: 3339. Acc: 0.546394. Loss: 1.252488. Batch_acc: 0.586920. Batch_loss: 1.181670 \n",
      "Batch: 3340. Acc: 0.546387. Loss: 1.252501. Batch_acc: 0.522741. Batch_loss: 1.295249 \n",
      "Batch: 3341. Acc: 0.546397. Loss: 1.252466. Batch_acc: 0.580296. Batch_loss: 1.136811 \n",
      "Batch: 3342. Acc: 0.546399. Loss: 1.252476. Batch_acc: 0.551603. Batch_loss: 1.286293 \n",
      "Batch: 3343. Acc: 0.546400. Loss: 1.252471. Batch_acc: 0.550234. Batch_loss: 1.237671 \n",
      "Batch: 3344. Acc: 0.546404. Loss: 1.252453. Batch_acc: 0.560624. Batch_loss: 1.191230 \n",
      "Batch: 3345. Acc: 0.546411. Loss: 1.252433. Batch_acc: 0.571264. Batch_loss: 1.185166 \n",
      "Batch: 3346. Acc: 0.546413. Loss: 1.252423. Batch_acc: 0.551826. Batch_loss: 1.217166 \n",
      "Batch: 3347. Acc: 0.546420. Loss: 1.252401. Batch_acc: 0.569826. Batch_loss: 1.181928 \n",
      "Batch: 3348. Acc: 0.546425. Loss: 1.252392. Batch_acc: 0.564282. Batch_loss: 1.220621 \n",
      "Batch: 3349. Acc: 0.546429. Loss: 1.252383. Batch_acc: 0.557803. Batch_loss: 1.221683 \n",
      "Batch: 3350. Acc: 0.546435. Loss: 1.252372. Batch_acc: 0.568041. Batch_loss: 1.219222 \n",
      "Batch: 3351. Acc: 0.546437. Loss: 1.252365. Batch_acc: 0.552230. Batch_loss: 1.227210 \n",
      "Batch: 3352. Acc: 0.546436. Loss: 1.252366. Batch_acc: 0.541909. Batch_loss: 1.255637 \n",
      "Batch: 3353. Acc: 0.546435. Loss: 1.252368. Batch_acc: 0.543552. Batch_loss: 1.261105 \n",
      "Batch: 3354. Acc: 0.546436. Loss: 1.252361. Batch_acc: 0.551685. Batch_loss: 1.228083 \n",
      "Batch: 3355. Acc: 0.546442. Loss: 1.252351. Batch_acc: 0.563762. Batch_loss: 1.217469 \n",
      "Batch: 3356. Acc: 0.546437. Loss: 1.252359. Batch_acc: 0.528589. Batch_loss: 1.283146 \n",
      "Batch: 3357. Acc: 0.546435. Loss: 1.252367. Batch_acc: 0.539589. Batch_loss: 1.278538 \n",
      "Batch: 3358. Acc: 0.546427. Loss: 1.252375. Batch_acc: 0.521889. Batch_loss: 1.278185 \n",
      "Batch: 3359. Acc: 0.546429. Loss: 1.252369. Batch_acc: 0.553167. Batch_loss: 1.232864 \n",
      "Batch: 3360. Acc: 0.546435. Loss: 1.252357. Batch_acc: 0.565621. Batch_loss: 1.210110 \n",
      "Batch: 3361. Acc: 0.546442. Loss: 1.252336. Batch_acc: 0.570370. Batch_loss: 1.184123 \n",
      "Batch: 3362. Acc: 0.546454. Loss: 1.252309. Batch_acc: 0.585591. Batch_loss: 1.161160 \n",
      "Batch: 3363. Acc: 0.546466. Loss: 1.252278. Batch_acc: 0.586458. Batch_loss: 1.149987 \n",
      "Batch: 3364. Acc: 0.546469. Loss: 1.252272. Batch_acc: 0.556199. Batch_loss: 1.233392 \n",
      "Batch: 3365. Acc: 0.546470. Loss: 1.252269. Batch_acc: 0.548997. Batch_loss: 1.243036 \n",
      "Batch: 3366. Acc: 0.546473. Loss: 1.252272. Batch_acc: 0.556512. Batch_loss: 1.260280 \n",
      "Batch: 3367. Acc: 0.546472. Loss: 1.252268. Batch_acc: 0.546238. Batch_loss: 1.238349 \n",
      "Batch: 3368. Acc: 0.546484. Loss: 1.252239. Batch_acc: 0.586744. Batch_loss: 1.153813 \n",
      "Batch: 3369. Acc: 0.546489. Loss: 1.252231. Batch_acc: 0.562114. Batch_loss: 1.227187 \n",
      "Batch: 3370. Acc: 0.546485. Loss: 1.252237. Batch_acc: 0.532025. Batch_loss: 1.272826 \n",
      "Batch: 3371. Acc: 0.546482. Loss: 1.252245. Batch_acc: 0.535301. Batch_loss: 1.277802 \n",
      "Batch: 3372. Acc: 0.546483. Loss: 1.252245. Batch_acc: 0.551606. Batch_loss: 1.254700 \n",
      "Batch: 3373. Acc: 0.546479. Loss: 1.252249. Batch_acc: 0.533447. Batch_loss: 1.264364 \n",
      "Batch: 3374. Acc: 0.546480. Loss: 1.252253. Batch_acc: 0.549650. Batch_loss: 1.265854 \n",
      "Batch: 3375. Acc: 0.546488. Loss: 1.252229. Batch_acc: 0.573723. Batch_loss: 1.170841 \n",
      "Batch: 3376. Acc: 0.546495. Loss: 1.252203. Batch_acc: 0.568707. Batch_loss: 1.163706 \n",
      "Batch: 3377. Acc: 0.546495. Loss: 1.252190. Batch_acc: 0.545877. Batch_loss: 1.209899 \n",
      "Batch: 3378. Acc: 0.546498. Loss: 1.252181. Batch_acc: 0.558605. Batch_loss: 1.220365 \n",
      "Batch: 3379. Acc: 0.546500. Loss: 1.252179. Batch_acc: 0.552047. Batch_loss: 1.246238 \n",
      "Batch: 3380. Acc: 0.546503. Loss: 1.252168. Batch_acc: 0.557222. Batch_loss: 1.217627 \n",
      "Batch: 3381. Acc: 0.546512. Loss: 1.252148. Batch_acc: 0.576988. Batch_loss: 1.183323 \n",
      "Batch: 3382. Acc: 0.546512. Loss: 1.252156. Batch_acc: 0.544484. Batch_loss: 1.280799 \n",
      "Batch: 3383. Acc: 0.546510. Loss: 1.252172. Batch_acc: 0.541021. Batch_loss: 1.306540 \n",
      "Batch: 3384. Acc: 0.546508. Loss: 1.252178. Batch_acc: 0.538505. Batch_loss: 1.273697 \n",
      "Batch: 3385. Acc: 0.546511. Loss: 1.252179. Batch_acc: 0.558672. Batch_loss: 1.255338 \n",
      "Batch: 3386. Acc: 0.546513. Loss: 1.252166. Batch_acc: 0.553291. Batch_loss: 1.206098 \n",
      "Batch: 3387. Acc: 0.546517. Loss: 1.252162. Batch_acc: 0.558621. Batch_loss: 1.239357 \n",
      "Batch: 3388. Acc: 0.546516. Loss: 1.252156. Batch_acc: 0.545040. Batch_loss: 1.232553 \n",
      "Batch: 3389. Acc: 0.546518. Loss: 1.252146. Batch_acc: 0.553571. Batch_loss: 1.218237 \n",
      "Batch: 3390. Acc: 0.546527. Loss: 1.252127. Batch_acc: 0.574171. Batch_loss: 1.185717 \n",
      "Batch: 3391. Acc: 0.546536. Loss: 1.252111. Batch_acc: 0.579279. Batch_loss: 1.198509 \n",
      "Batch: 3392. Acc: 0.546545. Loss: 1.252096. Batch_acc: 0.576945. Batch_loss: 1.200713 \n",
      "Batch: 3393. Acc: 0.546548. Loss: 1.252082. Batch_acc: 0.556064. Batch_loss: 1.205635 \n",
      "Batch: 3394. Acc: 0.546558. Loss: 1.252058. Batch_acc: 0.579439. Batch_loss: 1.170410 \n",
      "Batch: 3395. Acc: 0.546560. Loss: 1.252049. Batch_acc: 0.556061. Batch_loss: 1.220271 \n",
      "Batch: 3396. Acc: 0.546565. Loss: 1.252043. Batch_acc: 0.562315. Batch_loss: 1.231587 \n",
      "Batch: 3397. Acc: 0.546571. Loss: 1.252030. Batch_acc: 0.567598. Batch_loss: 1.209362 \n",
      "Batch: 3398. Acc: 0.546572. Loss: 1.252038. Batch_acc: 0.547897. Batch_loss: 1.279300 \n",
      "Batch: 3399. Acc: 0.546577. Loss: 1.252031. Batch_acc: 0.567112. Batch_loss: 1.226136 \n",
      "Batch: 3400. Acc: 0.546575. Loss: 1.252042. Batch_acc: 0.537090. Batch_loss: 1.289670 \n",
      "Batch: 3401. Acc: 0.546567. Loss: 1.252059. Batch_acc: 0.519648. Batch_loss: 1.311532 \n",
      "Batch: 3402. Acc: 0.546567. Loss: 1.252053. Batch_acc: 0.548165. Batch_loss: 1.230550 \n",
      "Batch: 3403. Acc: 0.546569. Loss: 1.252053. Batch_acc: 0.550496. Batch_loss: 1.252597 \n",
      "Batch: 3404. Acc: 0.546575. Loss: 1.252045. Batch_acc: 0.569134. Batch_loss: 1.224270 \n",
      "Batch: 3405. Acc: 0.546570. Loss: 1.252058. Batch_acc: 0.528969. Batch_loss: 1.297339 \n",
      "Batch: 3406. Acc: 0.546575. Loss: 1.252046. Batch_acc: 0.562674. Batch_loss: 1.213238 \n",
      "Batch: 3407. Acc: 0.546585. Loss: 1.252019. Batch_acc: 0.582081. Batch_loss: 1.158880 \n",
      "Batch: 3408. Acc: 0.546581. Loss: 1.252029. Batch_acc: 0.530178. Batch_loss: 1.288872 \n",
      "Batch: 3409. Acc: 0.546583. Loss: 1.252020. Batch_acc: 0.555556. Batch_loss: 1.220134 \n",
      "Batch: 3410. Acc: 0.546585. Loss: 1.252022. Batch_acc: 0.551429. Batch_loss: 1.258006 \n",
      "Batch: 3411. Acc: 0.546595. Loss: 1.252001. Batch_acc: 0.581315. Batch_loss: 1.181824 \n",
      "Batch: 3412. Acc: 0.546605. Loss: 1.251983. Batch_acc: 0.582468. Batch_loss: 1.187913 \n",
      "Batch: 3413. Acc: 0.546603. Loss: 1.251994. Batch_acc: 0.539436. Batch_loss: 1.291230 \n",
      "Batch: 3414. Acc: 0.546613. Loss: 1.251968. Batch_acc: 0.578798. Batch_loss: 1.163324 \n",
      "Batch: 3415. Acc: 0.546620. Loss: 1.251948. Batch_acc: 0.569892. Batch_loss: 1.186070 \n",
      "Batch: 3416. Acc: 0.546618. Loss: 1.251952. Batch_acc: 0.541237. Batch_loss: 1.265182 \n",
      "Batch: 3417. Acc: 0.546622. Loss: 1.251945. Batch_acc: 0.558508. Batch_loss: 1.227051 \n",
      "Batch: 3418. Acc: 0.546622. Loss: 1.251935. Batch_acc: 0.546821. Batch_loss: 1.219097 \n",
      "Batch: 3419. Acc: 0.546626. Loss: 1.251919. Batch_acc: 0.562606. Batch_loss: 1.196245 \n",
      "Batch: 3420. Acc: 0.546626. Loss: 1.251921. Batch_acc: 0.544521. Batch_loss: 1.260755 \n",
      "Batch: 3421. Acc: 0.546628. Loss: 1.251917. Batch_acc: 0.553392. Batch_loss: 1.237810 \n",
      "Batch: 3422. Acc: 0.546631. Loss: 1.251911. Batch_acc: 0.557127. Batch_loss: 1.232608 \n",
      "Batch: 3423. Acc: 0.546629. Loss: 1.251917. Batch_acc: 0.540323. Batch_loss: 1.269634 \n",
      "Batch: 3424. Acc: 0.546629. Loss: 1.251914. Batch_acc: 0.545872. Batch_loss: 1.241992 \n",
      "Batch: 3425. Acc: 0.546632. Loss: 1.251898. Batch_acc: 0.557368. Batch_loss: 1.197392 \n",
      "Batch: 3426. Acc: 0.546630. Loss: 1.251899. Batch_acc: 0.538682. Batch_loss: 1.255728 \n",
      "Batch: 3427. Acc: 0.546627. Loss: 1.251905. Batch_acc: 0.535967. Batch_loss: 1.271094 \n",
      "Batch: 3428. Acc: 0.546631. Loss: 1.251896. Batch_acc: 0.561785. Batch_loss: 1.222944 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3429. Acc: 0.546635. Loss: 1.251885. Batch_acc: 0.562137. Batch_loss: 1.212147 \n",
      "Batch: 3430. Acc: 0.546640. Loss: 1.251871. Batch_acc: 0.563107. Batch_loss: 1.206250 \n",
      "Batch: 3431. Acc: 0.546645. Loss: 1.251856. Batch_acc: 0.563574. Batch_loss: 1.200599 \n",
      "Batch: 3432. Acc: 0.546648. Loss: 1.251843. Batch_acc: 0.554378. Batch_loss: 1.208958 \n",
      "Batch: 3433. Acc: 0.546646. Loss: 1.251859. Batch_acc: 0.541472. Batch_loss: 1.306660 \n",
      "Batch: 3434. Acc: 0.546640. Loss: 1.251867. Batch_acc: 0.526316. Batch_loss: 1.278073 \n",
      "Batch: 3435. Acc: 0.546648. Loss: 1.251848. Batch_acc: 0.573123. Batch_loss: 1.186710 \n",
      "Batch: 3436. Acc: 0.546644. Loss: 1.251853. Batch_acc: 0.533981. Batch_loss: 1.269710 \n",
      "Batch: 3437. Acc: 0.546641. Loss: 1.251856. Batch_acc: 0.536306. Batch_loss: 1.262388 \n",
      "Batch: 3438. Acc: 0.546639. Loss: 1.251862. Batch_acc: 0.540243. Batch_loss: 1.271504 \n",
      "Batch: 3439. Acc: 0.546643. Loss: 1.251849. Batch_acc: 0.560414. Batch_loss: 1.208883 \n",
      "Batch: 3440. Acc: 0.546651. Loss: 1.251841. Batch_acc: 0.572162. Batch_loss: 1.223928 \n",
      "Batch: 3441. Acc: 0.546658. Loss: 1.251821. Batch_acc: 0.571021. Batch_loss: 1.183236 \n",
      "Batch: 3442. Acc: 0.546664. Loss: 1.251807. Batch_acc: 0.568129. Batch_loss: 1.205376 \n",
      "Batch: 3443. Acc: 0.546672. Loss: 1.251793. Batch_acc: 0.573157. Batch_loss: 1.202698 \n",
      "Batch: 3444. Acc: 0.546674. Loss: 1.251791. Batch_acc: 0.555493. Batch_loss: 1.246295 \n",
      "Batch: 3445. Acc: 0.546679. Loss: 1.251780. Batch_acc: 0.561804. Batch_loss: 1.210096 \n",
      "Batch: 3446. Acc: 0.546684. Loss: 1.251762. Batch_acc: 0.563574. Batch_loss: 1.190732 \n",
      "Batch: 3447. Acc: 0.546691. Loss: 1.251746. Batch_acc: 0.571910. Batch_loss: 1.197496 \n",
      "Batch: 3448. Acc: 0.546694. Loss: 1.251733. Batch_acc: 0.555942. Batch_loss: 1.209149 \n",
      "Batch: 3449. Acc: 0.546692. Loss: 1.251739. Batch_acc: 0.541332. Batch_loss: 1.272562 \n",
      "Batch: 3450. Acc: 0.546692. Loss: 1.251740. Batch_acc: 0.547126. Batch_loss: 1.253971 \n",
      "Batch: 3451. Acc: 0.546688. Loss: 1.251742. Batch_acc: 0.532194. Batch_loss: 1.257318 \n",
      "Batch: 3452. Acc: 0.546690. Loss: 1.251731. Batch_acc: 0.552586. Batch_loss: 1.212717 \n",
      "Batch: 3453. Acc: 0.546696. Loss: 1.251717. Batch_acc: 0.566531. Batch_loss: 1.206032 \n",
      "Batch: 3454. Acc: 0.546698. Loss: 1.251708. Batch_acc: 0.555749. Batch_loss: 1.220178 \n",
      "Batch: 3455. Acc: 0.546697. Loss: 1.251714. Batch_acc: 0.541691. Batch_loss: 1.271558 \n",
      "Batch: 3456. Acc: 0.546694. Loss: 1.251721. Batch_acc: 0.537463. Batch_loss: 1.276327 \n",
      "Batch: 3457. Acc: 0.546697. Loss: 1.251712. Batch_acc: 0.556582. Batch_loss: 1.220832 \n",
      "Batch: 3458. Acc: 0.546702. Loss: 1.251697. Batch_acc: 0.565116. Batch_loss: 1.198819 \n",
      "Batch: 3459. Acc: 0.546710. Loss: 1.251676. Batch_acc: 0.572717. Batch_loss: 1.182536 \n",
      "Batch: 3460. Acc: 0.546717. Loss: 1.251661. Batch_acc: 0.569533. Batch_loss: 1.196328 \n",
      "Batch: 3461. Acc: 0.546719. Loss: 1.251653. Batch_acc: 0.555303. Batch_loss: 1.227414 \n",
      "Batch: 3462. Acc: 0.546719. Loss: 1.251646. Batch_acc: 0.548161. Batch_loss: 1.224517 \n",
      "Batch: 3463. Acc: 0.546713. Loss: 1.251663. Batch_acc: 0.521998. Batch_loss: 1.313605 \n",
      "Batch: 3464. Acc: 0.546713. Loss: 1.251650. Batch_acc: 0.549229. Batch_loss: 1.205649 \n",
      "Batch: 3465. Acc: 0.546716. Loss: 1.251640. Batch_acc: 0.557847. Batch_loss: 1.217703 \n",
      "Batch: 3466. Acc: 0.546718. Loss: 1.251630. Batch_acc: 0.550640. Batch_loss: 1.214353 \n",
      "Batch: 3467. Acc: 0.546721. Loss: 1.251618. Batch_acc: 0.560000. Batch_loss: 1.209265 \n",
      "Batch: 3468. Acc: 0.546722. Loss: 1.251614. Batch_acc: 0.548444. Batch_loss: 1.239908 \n",
      "Batch: 3469. Acc: 0.546724. Loss: 1.251603. Batch_acc: 0.553105. Batch_loss: 1.212506 \n",
      "Batch: 3470. Acc: 0.546719. Loss: 1.251621. Batch_acc: 0.531157. Batch_loss: 1.314570 \n",
      "Batch: 3471. Acc: 0.546717. Loss: 1.251616. Batch_acc: 0.540276. Batch_loss: 1.235684 \n",
      "Batch: 3472. Acc: 0.546722. Loss: 1.251604. Batch_acc: 0.562967. Batch_loss: 1.211227 \n",
      "Batch: 3473. Acc: 0.546718. Loss: 1.251609. Batch_acc: 0.531268. Batch_loss: 1.266762 \n",
      "Batch: 3474. Acc: 0.546720. Loss: 1.251604. Batch_acc: 0.554920. Batch_loss: 1.235693 \n",
      "Batch: 3475. Acc: 0.546727. Loss: 1.251586. Batch_acc: 0.569106. Batch_loss: 1.188556 \n",
      "Batch: 3476. Acc: 0.546726. Loss: 1.251592. Batch_acc: 0.545035. Batch_loss: 1.273071 \n",
      "Batch: 3477. Acc: 0.546727. Loss: 1.251589. Batch_acc: 0.551685. Batch_loss: 1.241725 \n",
      "Batch: 3478. Acc: 0.546724. Loss: 1.251591. Batch_acc: 0.532851. Batch_loss: 1.257715 \n",
      "Batch: 3479. Acc: 0.546725. Loss: 1.251587. Batch_acc: 0.549858. Batch_loss: 1.238565 \n",
      "Batch: 3480. Acc: 0.546730. Loss: 1.251575. Batch_acc: 0.565737. Batch_loss: 1.208537 \n",
      "Batch: 3481. Acc: 0.546733. Loss: 1.251556. Batch_acc: 0.557078. Batch_loss: 1.185527 \n",
      "Batch: 3482. Acc: 0.546728. Loss: 1.251567. Batch_acc: 0.527337. Batch_loss: 1.291097 \n",
      "Batch: 3483. Acc: 0.546732. Loss: 1.251560. Batch_acc: 0.563372. Batch_loss: 1.228227 \n",
      "Batch: 3484. Acc: 0.546737. Loss: 1.251551. Batch_acc: 0.561219. Batch_loss: 1.220647 \n",
      "Batch: 3485. Acc: 0.546738. Loss: 1.251543. Batch_acc: 0.552617. Batch_loss: 1.222742 \n",
      "Batch: 3486. Acc: 0.546749. Loss: 1.251516. Batch_acc: 0.584430. Batch_loss: 1.159410 \n",
      "Batch: 3487. Acc: 0.546752. Loss: 1.251505. Batch_acc: 0.555046. Batch_loss: 1.213587 \n",
      "Batch: 3488. Acc: 0.546749. Loss: 1.251511. Batch_acc: 0.536974. Batch_loss: 1.272917 \n",
      "Batch: 3489. Acc: 0.546747. Loss: 1.251504. Batch_acc: 0.541886. Batch_loss: 1.224603 \n",
      "Batch: 3490. Acc: 0.546755. Loss: 1.251488. Batch_acc: 0.571998. Batch_loss: 1.195507 \n",
      "Batch: 3491. Acc: 0.546755. Loss: 1.251488. Batch_acc: 0.546248. Batch_loss: 1.253307 \n",
      "Batch: 3492. Acc: 0.546763. Loss: 1.251471. Batch_acc: 0.574201. Batch_loss: 1.191678 \n",
      "Batch: 3493. Acc: 0.546765. Loss: 1.251460. Batch_acc: 0.554292. Batch_loss: 1.214525 \n",
      "Batch: 3494. Acc: 0.546770. Loss: 1.251446. Batch_acc: 0.563636. Batch_loss: 1.202447 \n",
      "Batch: 3495. Acc: 0.546773. Loss: 1.251437. Batch_acc: 0.558140. Batch_loss: 1.220514 \n",
      "Batch: 3496. Acc: 0.546781. Loss: 1.251406. Batch_acc: 0.576608. Batch_loss: 1.140500 \n",
      "Batch: 3497. Acc: 0.546783. Loss: 1.251406. Batch_acc: 0.553415. Batch_loss: 1.250618 \n",
      "Batch: 3498. Acc: 0.546784. Loss: 1.251403. Batch_acc: 0.551080. Batch_loss: 1.241423 \n",
      "Batch: 3499. Acc: 0.546785. Loss: 1.251398. Batch_acc: 0.550699. Batch_loss: 1.235365 \n",
      "Batch: 3500. Acc: 0.546789. Loss: 1.251389. Batch_acc: 0.559322. Batch_loss: 1.218807 \n",
      "Batch: 3501. Acc: 0.546792. Loss: 1.251369. Batch_acc: 0.556766. Batch_loss: 1.181549 \n",
      "Batch: 3502. Acc: 0.546802. Loss: 1.251348. Batch_acc: 0.581002. Batch_loss: 1.176776 \n",
      "Batch: 3503. Acc: 0.546802. Loss: 1.251348. Batch_acc: 0.547244. Batch_loss: 1.253241 \n",
      "Batch: 3504. Acc: 0.546802. Loss: 1.251347. Batch_acc: 0.548788. Batch_loss: 1.247368 \n",
      "Batch: 3505. Acc: 0.546807. Loss: 1.251328. Batch_acc: 0.564118. Batch_loss: 1.181051 \n",
      "Batch: 3506. Acc: 0.546819. Loss: 1.251286. Batch_acc: 0.587709. Batch_loss: 1.109471 \n",
      "Batch: 3507. Acc: 0.546821. Loss: 1.251269. Batch_acc: 0.553204. Batch_loss: 1.192288 \n",
      "Batch: 3508. Acc: 0.546822. Loss: 1.251260. Batch_acc: 0.551977. Batch_loss: 1.219564 \n",
      "Batch: 3509. Acc: 0.546826. Loss: 1.251256. Batch_acc: 0.557648. Batch_loss: 1.235869 \n",
      "Batch: 3510. Acc: 0.546829. Loss: 1.251242. Batch_acc: 0.558924. Batch_loss: 1.203522 \n",
      "Batch: 3511. Acc: 0.546831. Loss: 1.251226. Batch_acc: 0.553846. Batch_loss: 1.195533 \n",
      "Batch: 3512. Acc: 0.546824. Loss: 1.251249. Batch_acc: 0.521965. Batch_loss: 1.332841 \n",
      "Batch: 3513. Acc: 0.546824. Loss: 1.251236. Batch_acc: 0.545821. Batch_loss: 1.204116 \n",
      "Batch: 3514. Acc: 0.546829. Loss: 1.251226. Batch_acc: 0.564535. Batch_loss: 1.217131 \n",
      "Checkpointing on batch: 3514. Accuracy: 0.5468286702396747. Loss per char: 1.25122595020946. Time: 1627224525.105966\n",
      "Last question is tensor([ 2, 14, 18, 18, 23, 17, 25, 21, 18, 22, 21, 25, 22, 19,  1, 14,  1, 22,\n",
      "         3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3515. Acc: 0.546833. Loss: 1.251211. Batch_acc: 0.562027. Batch_loss: 1.198842 \n",
      "Batch: 3516. Acc: 0.546827. Loss: 1.251223. Batch_acc: 0.525694. Batch_loss: 1.294795 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3517. Acc: 0.546827. Loss: 1.251222. Batch_acc: 0.547619. Batch_loss: 1.245378 \n",
      "Batch: 3518. Acc: 0.546821. Loss: 1.251238. Batch_acc: 0.524277. Batch_loss: 1.307500 \n",
      "Batch: 3519. Acc: 0.546822. Loss: 1.251238. Batch_acc: 0.552256. Batch_loss: 1.253233 \n",
      "Batch: 3520. Acc: 0.546825. Loss: 1.251227. Batch_acc: 0.556475. Batch_loss: 1.209587 \n",
      "Batch: 3521. Acc: 0.546829. Loss: 1.251209. Batch_acc: 0.560000. Batch_loss: 1.186828 \n",
      "Batch: 3522. Acc: 0.546825. Loss: 1.251216. Batch_acc: 0.532609. Batch_loss: 1.277192 \n",
      "Batch: 3523. Acc: 0.546816. Loss: 1.251232. Batch_acc: 0.515927. Batch_loss: 1.307824 \n",
      "Batch: 3524. Acc: 0.546817. Loss: 1.251232. Batch_acc: 0.551977. Batch_loss: 1.249349 \n",
      "Batch: 3525. Acc: 0.546821. Loss: 1.251225. Batch_acc: 0.559283. Batch_loss: 1.228653 \n",
      "Batch: 3526. Acc: 0.546824. Loss: 1.251214. Batch_acc: 0.556754. Batch_loss: 1.211316 \n",
      "Batch: 3527. Acc: 0.546824. Loss: 1.251212. Batch_acc: 0.548002. Batch_loss: 1.245708 \n",
      "Batch: 3528. Acc: 0.546825. Loss: 1.251211. Batch_acc: 0.551683. Batch_loss: 1.244712 \n",
      "Batch: 3529. Acc: 0.546830. Loss: 1.251202. Batch_acc: 0.563594. Batch_loss: 1.221115 \n",
      "Batch: 3530. Acc: 0.546833. Loss: 1.251196. Batch_acc: 0.556653. Batch_loss: 1.229220 \n",
      "Batch: 3531. Acc: 0.546834. Loss: 1.251191. Batch_acc: 0.549735. Batch_loss: 1.233522 \n",
      "Batch: 3532. Acc: 0.546845. Loss: 1.251162. Batch_acc: 0.586052. Batch_loss: 1.150172 \n",
      "Batch: 3533. Acc: 0.546854. Loss: 1.251139. Batch_acc: 0.577254. Batch_loss: 1.170627 \n",
      "Batch: 3534. Acc: 0.546852. Loss: 1.251143. Batch_acc: 0.541928. Batch_loss: 1.263334 \n",
      "Batch: 3535. Acc: 0.546852. Loss: 1.251143. Batch_acc: 0.544386. Batch_loss: 1.251954 \n",
      "Batch: 3536. Acc: 0.546852. Loss: 1.251136. Batch_acc: 0.549744. Batch_loss: 1.227606 \n",
      "Batch: 3537. Acc: 0.546854. Loss: 1.251127. Batch_acc: 0.552841. Batch_loss: 1.220706 \n",
      "Batch: 3538. Acc: 0.546857. Loss: 1.251122. Batch_acc: 0.558543. Batch_loss: 1.233047 \n",
      "Batch: 3539. Acc: 0.546854. Loss: 1.251134. Batch_acc: 0.534750. Batch_loss: 1.292876 \n",
      "Batch: 3540. Acc: 0.546854. Loss: 1.251134. Batch_acc: 0.546087. Batch_loss: 1.251083 \n",
      "Batch: 3541. Acc: 0.546857. Loss: 1.251126. Batch_acc: 0.559078. Batch_loss: 1.222045 \n",
      "Batch: 3542. Acc: 0.546859. Loss: 1.251121. Batch_acc: 0.551646. Batch_loss: 1.235363 \n",
      "Batch: 3543. Acc: 0.546856. Loss: 1.251124. Batch_acc: 0.538143. Batch_loss: 1.260365 \n",
      "Batch: 3544. Acc: 0.546861. Loss: 1.251112. Batch_acc: 0.563265. Batch_loss: 1.210432 \n",
      "Batch: 3545. Acc: 0.546864. Loss: 1.251101. Batch_acc: 0.559264. Batch_loss: 1.209090 \n",
      "Batch: 3546. Acc: 0.546868. Loss: 1.251091. Batch_acc: 0.561283. Batch_loss: 1.216147 \n",
      "Batch: 3547. Acc: 0.546868. Loss: 1.251088. Batch_acc: 0.546911. Batch_loss: 1.241720 \n",
      "Batch: 3548. Acc: 0.546870. Loss: 1.251082. Batch_acc: 0.551564. Batch_loss: 1.230905 \n",
      "Batch: 3549. Acc: 0.546877. Loss: 1.251056. Batch_acc: 0.572669. Batch_loss: 1.158288 \n",
      "Batch: 3550. Acc: 0.546879. Loss: 1.251053. Batch_acc: 0.552408. Batch_loss: 1.237975 \n",
      "Batch: 3551. Acc: 0.546878. Loss: 1.251060. Batch_acc: 0.543210. Batch_loss: 1.276018 \n",
      "Batch: 3552. Acc: 0.546879. Loss: 1.251050. Batch_acc: 0.550808. Batch_loss: 1.215327 \n",
      "Batch: 3553. Acc: 0.546875. Loss: 1.251049. Batch_acc: 0.533682. Batch_loss: 1.250354 \n",
      "Batch: 3554. Acc: 0.546879. Loss: 1.251040. Batch_acc: 0.560204. Batch_loss: 1.217471 \n",
      "Batch: 3555. Acc: 0.546887. Loss: 1.251020. Batch_acc: 0.577449. Batch_loss: 1.182253 \n",
      "Batch: 3556. Acc: 0.546885. Loss: 1.251020. Batch_acc: 0.537090. Batch_loss: 1.248756 \n",
      "Batch: 3557. Acc: 0.546889. Loss: 1.251013. Batch_acc: 0.560847. Batch_loss: 1.228664 \n",
      "Batch: 3558. Acc: 0.546892. Loss: 1.251009. Batch_acc: 0.559530. Batch_loss: 1.234965 \n",
      "Batch: 3559. Acc: 0.546900. Loss: 1.250980. Batch_acc: 0.576389. Batch_loss: 1.148300 \n",
      "Batch: 3560. Acc: 0.546902. Loss: 1.250976. Batch_acc: 0.554147. Batch_loss: 1.234593 \n",
      "Batch: 3561. Acc: 0.546912. Loss: 1.250955. Batch_acc: 0.579596. Batch_loss: 1.181191 \n",
      "Batch: 3562. Acc: 0.546909. Loss: 1.250957. Batch_acc: 0.537529. Batch_loss: 1.255726 \n",
      "Batch: 3563. Acc: 0.546912. Loss: 1.250949. Batch_acc: 0.556199. Batch_loss: 1.221578 \n",
      "Batch: 3564. Acc: 0.546909. Loss: 1.250957. Batch_acc: 0.537844. Batch_loss: 1.280227 \n",
      "Batch: 3565. Acc: 0.546910. Loss: 1.250960. Batch_acc: 0.547689. Batch_loss: 1.262405 \n",
      "Batch: 3566. Acc: 0.546908. Loss: 1.250969. Batch_acc: 0.541449. Batch_loss: 1.284777 \n",
      "Batch: 3567. Acc: 0.546910. Loss: 1.250960. Batch_acc: 0.555109. Batch_loss: 1.218544 \n",
      "Batch: 3568. Acc: 0.546901. Loss: 1.250974. Batch_acc: 0.514501. Batch_loss: 1.301614 \n",
      "Batch: 3569. Acc: 0.546910. Loss: 1.250952. Batch_acc: 0.579007. Batch_loss: 1.170351 \n",
      "Batch: 3570. Acc: 0.546911. Loss: 1.250945. Batch_acc: 0.549658. Batch_loss: 1.226955 \n",
      "Batch: 3571. Acc: 0.546916. Loss: 1.250935. Batch_acc: 0.565466. Batch_loss: 1.217454 \n",
      "Batch: 3572. Acc: 0.546917. Loss: 1.250933. Batch_acc: 0.548627. Batch_loss: 1.241958 \n",
      "Batch: 3573. Acc: 0.546920. Loss: 1.250922. Batch_acc: 0.556522. Batch_loss: 1.211531 \n",
      "Batch: 3574. Acc: 0.546925. Loss: 1.250900. Batch_acc: 0.568221. Batch_loss: 1.172207 \n",
      "Batch: 3575. Acc: 0.546937. Loss: 1.250872. Batch_acc: 0.587653. Batch_loss: 1.151322 \n",
      "Batch: 3576. Acc: 0.546936. Loss: 1.250875. Batch_acc: 0.544643. Batch_loss: 1.261409 \n",
      "Batch: 3577. Acc: 0.546941. Loss: 1.250862. Batch_acc: 0.563284. Batch_loss: 1.205196 \n",
      "Batch: 3578. Acc: 0.546943. Loss: 1.250850. Batch_acc: 0.555295. Batch_loss: 1.207583 \n",
      "Batch: 3579. Acc: 0.546950. Loss: 1.250823. Batch_acc: 0.571748. Batch_loss: 1.156508 \n",
      "Batch: 3580. Acc: 0.546953. Loss: 1.250814. Batch_acc: 0.555492. Batch_loss: 1.219218 \n",
      "Batch: 3581. Acc: 0.546957. Loss: 1.250800. Batch_acc: 0.561283. Batch_loss: 1.200121 \n",
      "Batch: 3582. Acc: 0.546960. Loss: 1.250794. Batch_acc: 0.557839. Batch_loss: 1.226752 \n",
      "Batch: 3583. Acc: 0.546960. Loss: 1.250788. Batch_acc: 0.549913. Batch_loss: 1.229748 \n",
      "Batch: 3584. Acc: 0.546964. Loss: 1.250789. Batch_acc: 0.559524. Batch_loss: 1.255639 \n",
      "Batch: 3585. Acc: 0.546966. Loss: 1.250785. Batch_acc: 0.556002. Batch_loss: 1.234311 \n",
      "Batch: 3586. Acc: 0.546971. Loss: 1.250774. Batch_acc: 0.562428. Batch_loss: 1.212873 \n",
      "Batch: 3587. Acc: 0.546973. Loss: 1.250772. Batch_acc: 0.553582. Batch_loss: 1.244949 \n",
      "Batch: 3588. Acc: 0.546980. Loss: 1.250754. Batch_acc: 0.574726. Batch_loss: 1.184556 \n",
      "Batch: 3589. Acc: 0.546988. Loss: 1.250735. Batch_acc: 0.575115. Batch_loss: 1.183538 \n",
      "Batch: 3590. Acc: 0.546991. Loss: 1.250728. Batch_acc: 0.555556. Batch_loss: 1.225360 \n",
      "Batch: 3591. Acc: 0.546998. Loss: 1.250700. Batch_acc: 0.571922. Batch_loss: 1.149442 \n",
      "Batch: 3592. Acc: 0.547004. Loss: 1.250678. Batch_acc: 0.569861. Batch_loss: 1.174404 \n",
      "Batch: 3593. Acc: 0.547005. Loss: 1.250677. Batch_acc: 0.549915. Batch_loss: 1.246606 \n",
      "Batch: 3594. Acc: 0.547009. Loss: 1.250664. Batch_acc: 0.561172. Batch_loss: 1.204400 \n",
      "Batch: 3595. Acc: 0.547013. Loss: 1.250648. Batch_acc: 0.563689. Batch_loss: 1.193242 \n",
      "Batch: 3596. Acc: 0.547017. Loss: 1.250639. Batch_acc: 0.559770. Batch_loss: 1.217045 \n",
      "Batch: 3597. Acc: 0.547021. Loss: 1.250633. Batch_acc: 0.562874. Batch_loss: 1.228660 \n",
      "Batch: 3598. Acc: 0.547023. Loss: 1.250622. Batch_acc: 0.555102. Batch_loss: 1.210985 \n",
      "Batch: 3599. Acc: 0.547025. Loss: 1.250623. Batch_acc: 0.551922. Batch_loss: 1.252646 \n",
      "Batch: 3600. Acc: 0.547028. Loss: 1.250616. Batch_acc: 0.557481. Batch_loss: 1.224466 \n",
      "Batch: 3601. Acc: 0.547031. Loss: 1.250606. Batch_acc: 0.558059. Batch_loss: 1.215758 \n",
      "Batch: 3602. Acc: 0.547029. Loss: 1.250607. Batch_acc: 0.541596. Batch_loss: 1.254478 \n",
      "Batch: 3603. Acc: 0.547035. Loss: 1.250587. Batch_acc: 0.568739. Batch_loss: 1.179790 \n",
      "Batch: 3604. Acc: 0.547041. Loss: 1.250576. Batch_acc: 0.569143. Batch_loss: 1.209591 \n",
      "Batch: 3605. Acc: 0.547036. Loss: 1.250581. Batch_acc: 0.527453. Batch_loss: 1.267812 \n",
      "Batch: 3606. Acc: 0.547048. Loss: 1.250552. Batch_acc: 0.588636. Batch_loss: 1.149892 \n",
      "Batch: 3607. Acc: 0.547052. Loss: 1.250549. Batch_acc: 0.564573. Batch_loss: 1.238773 \n",
      "Batch: 3608. Acc: 0.547052. Loss: 1.250548. Batch_acc: 0.546746. Batch_loss: 1.244562 \n",
      "Batch: 3609. Acc: 0.547053. Loss: 1.250550. Batch_acc: 0.547984. Batch_loss: 1.261162 \n",
      "Batch: 3610. Acc: 0.547056. Loss: 1.250537. Batch_acc: 0.558675. Batch_loss: 1.202326 \n",
      "Batch: 3611. Acc: 0.547056. Loss: 1.250537. Batch_acc: 0.546705. Batch_loss: 1.251848 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3612. Acc: 0.547065. Loss: 1.250514. Batch_acc: 0.579402. Batch_loss: 1.165157 \n",
      "Batch: 3613. Acc: 0.547061. Loss: 1.250521. Batch_acc: 0.533645. Batch_loss: 1.279211 \n",
      "Batch: 3614. Acc: 0.547057. Loss: 1.250529. Batch_acc: 0.533483. Batch_loss: 1.279035 \n",
      "Batch: 3615. Acc: 0.547057. Loss: 1.250526. Batch_acc: 0.547673. Batch_loss: 1.239944 \n",
      "Batch: 3616. Acc: 0.547058. Loss: 1.250522. Batch_acc: 0.550379. Batch_loss: 1.233340 \n",
      "Batch: 3617. Acc: 0.547056. Loss: 1.250535. Batch_acc: 0.539481. Batch_loss: 1.297380 \n",
      "Batch: 3618. Acc: 0.547063. Loss: 1.250511. Batch_acc: 0.571429. Batch_loss: 1.166454 \n",
      "Batch: 3619. Acc: 0.547061. Loss: 1.250507. Batch_acc: 0.540634. Batch_loss: 1.234666 \n",
      "Batch: 3620. Acc: 0.547064. Loss: 1.250502. Batch_acc: 0.555684. Batch_loss: 1.233407 \n",
      "Batch: 3621. Acc: 0.547068. Loss: 1.250491. Batch_acc: 0.560513. Batch_loss: 1.210966 \n",
      "Batch: 3622. Acc: 0.547076. Loss: 1.250474. Batch_acc: 0.578613. Batch_loss: 1.191251 \n",
      "Batch: 3623. Acc: 0.547077. Loss: 1.250464. Batch_acc: 0.551101. Batch_loss: 1.214235 \n",
      "Batch: 3624. Acc: 0.547077. Loss: 1.250463. Batch_acc: 0.545082. Batch_loss: 1.244474 \n",
      "Batch: 3625. Acc: 0.547077. Loss: 1.250470. Batch_acc: 0.545936. Batch_loss: 1.279605 \n",
      "Batch: 3626. Acc: 0.547086. Loss: 1.250447. Batch_acc: 0.580496. Batch_loss: 1.164089 \n",
      "Batch: 3627. Acc: 0.547077. Loss: 1.250469. Batch_acc: 0.515476. Batch_loss: 1.334607 \n",
      "Batch: 3628. Acc: 0.547079. Loss: 1.250462. Batch_acc: 0.554257. Batch_loss: 1.224804 \n",
      "Batch: 3629. Acc: 0.547075. Loss: 1.250472. Batch_acc: 0.529959. Batch_loss: 1.289334 \n",
      "Batch: 3630. Acc: 0.547078. Loss: 1.250461. Batch_acc: 0.558206. Batch_loss: 1.209049 \n",
      "Batch: 3631. Acc: 0.547081. Loss: 1.250449. Batch_acc: 0.559579. Batch_loss: 1.207265 \n",
      "Batch: 3632. Acc: 0.547092. Loss: 1.250424. Batch_acc: 0.586188. Batch_loss: 1.161362 \n",
      "Batch: 3633. Acc: 0.547098. Loss: 1.250409. Batch_acc: 0.569204. Batch_loss: 1.195092 \n",
      "Batch: 3634. Acc: 0.547101. Loss: 1.250401. Batch_acc: 0.557815. Batch_loss: 1.220970 \n",
      "Batch: 3635. Acc: 0.547100. Loss: 1.250406. Batch_acc: 0.544057. Batch_loss: 1.270656 \n",
      "Batch: 3636. Acc: 0.547104. Loss: 1.250393. Batch_acc: 0.560091. Batch_loss: 1.203834 \n",
      "Batch: 3637. Acc: 0.547112. Loss: 1.250376. Batch_acc: 0.575406. Batch_loss: 1.189065 \n",
      "Batch: 3638. Acc: 0.547115. Loss: 1.250361. Batch_acc: 0.560571. Batch_loss: 1.194747 \n",
      "Batch: 3639. Acc: 0.547119. Loss: 1.250350. Batch_acc: 0.559908. Batch_loss: 1.211332 \n",
      "Batch: 3640. Acc: 0.547126. Loss: 1.250330. Batch_acc: 0.571910. Batch_loss: 1.176619 \n",
      "Batch: 3641. Acc: 0.547124. Loss: 1.250330. Batch_acc: 0.540387. Batch_loss: 1.250122 \n",
      "Batch: 3642. Acc: 0.547131. Loss: 1.250319. Batch_acc: 0.570535. Batch_loss: 1.211762 \n",
      "Batch: 3643. Acc: 0.547130. Loss: 1.250310. Batch_acc: 0.546994. Batch_loss: 1.219122 \n",
      "Batch: 3644. Acc: 0.547133. Loss: 1.250304. Batch_acc: 0.556730. Batch_loss: 1.228772 \n",
      "Batch: 3645. Acc: 0.547138. Loss: 1.250287. Batch_acc: 0.563709. Batch_loss: 1.187042 \n",
      "Batch: 3646. Acc: 0.547134. Loss: 1.250285. Batch_acc: 0.533136. Batch_loss: 1.243428 \n",
      "Batch: 3647. Acc: 0.547137. Loss: 1.250276. Batch_acc: 0.556845. Batch_loss: 1.216254 \n",
      "Batch: 3648. Acc: 0.547142. Loss: 1.250262. Batch_acc: 0.567506. Batch_loss: 1.201510 \n",
      "Batch: 3649. Acc: 0.547152. Loss: 1.250236. Batch_acc: 0.583238. Batch_loss: 1.154411 \n",
      "Batch: 3650. Acc: 0.547157. Loss: 1.250219. Batch_acc: 0.565931. Batch_loss: 1.191196 \n",
      "Batch: 3651. Acc: 0.547161. Loss: 1.250217. Batch_acc: 0.560022. Batch_loss: 1.242944 \n",
      "Batch: 3652. Acc: 0.547162. Loss: 1.250216. Batch_acc: 0.551526. Batch_loss: 1.243865 \n",
      "Batch: 3653. Acc: 0.547161. Loss: 1.250215. Batch_acc: 0.543118. Batch_loss: 1.247147 \n",
      "Batch: 3654. Acc: 0.547175. Loss: 1.250175. Batch_acc: 0.594944. Batch_loss: 1.109256 \n",
      "Batch: 3655. Acc: 0.547179. Loss: 1.250166. Batch_acc: 0.563615. Batch_loss: 1.214520 \n",
      "Batch: 3656. Acc: 0.547187. Loss: 1.250141. Batch_acc: 0.575723. Batch_loss: 1.160323 \n",
      "Batch: 3657. Acc: 0.547185. Loss: 1.250141. Batch_acc: 0.539090. Batch_loss: 1.250817 \n",
      "Batch: 3658. Acc: 0.547184. Loss: 1.250141. Batch_acc: 0.543326. Batch_loss: 1.249458 \n",
      "Batch: 3659. Acc: 0.547184. Loss: 1.250147. Batch_acc: 0.547687. Batch_loss: 1.271084 \n",
      "Batch: 3660. Acc: 0.547189. Loss: 1.250131. Batch_acc: 0.567114. Batch_loss: 1.195251 \n",
      "Batch: 3661. Acc: 0.547190. Loss: 1.250133. Batch_acc: 0.549008. Batch_loss: 1.255995 \n",
      "Batch: 3662. Acc: 0.547194. Loss: 1.250120. Batch_acc: 0.562899. Batch_loss: 1.200304 \n",
      "Batch: 3663. Acc: 0.547196. Loss: 1.250108. Batch_acc: 0.553035. Batch_loss: 1.207323 \n",
      "Batch: 3664. Acc: 0.547192. Loss: 1.250104. Batch_acc: 0.534364. Batch_loss: 1.237524 \n",
      "Batch: 3665. Acc: 0.547189. Loss: 1.250109. Batch_acc: 0.534844. Batch_loss: 1.267744 \n",
      "Batch: 3666. Acc: 0.547194. Loss: 1.250097. Batch_acc: 0.565167. Batch_loss: 1.204643 \n",
      "Batch: 3667. Acc: 0.547189. Loss: 1.250115. Batch_acc: 0.528504. Batch_loss: 1.319454 \n",
      "Batch: 3668. Acc: 0.547189. Loss: 1.250112. Batch_acc: 0.549911. Batch_loss: 1.236533 \n",
      "Batch: 3669. Acc: 0.547186. Loss: 1.250123. Batch_acc: 0.532830. Batch_loss: 1.292771 \n",
      "Batch: 3670. Acc: 0.547181. Loss: 1.250128. Batch_acc: 0.530380. Batch_loss: 1.266459 \n",
      "Batch: 3671. Acc: 0.547188. Loss: 1.250105. Batch_acc: 0.571038. Batch_loss: 1.173154 \n",
      "Batch: 3672. Acc: 0.547193. Loss: 1.250093. Batch_acc: 0.565533. Batch_loss: 1.205225 \n",
      "Batch: 3673. Acc: 0.547198. Loss: 1.250091. Batch_acc: 0.567016. Batch_loss: 1.244096 \n",
      "Batch: 3674. Acc: 0.547200. Loss: 1.250088. Batch_acc: 0.552189. Batch_loss: 1.238156 \n",
      "Batch: 3675. Acc: 0.547194. Loss: 1.250094. Batch_acc: 0.528051. Batch_loss: 1.273680 \n",
      "Batch: 3676. Acc: 0.547199. Loss: 1.250071. Batch_acc: 0.562951. Batch_loss: 1.166599 \n",
      "Batch: 3677. Acc: 0.547194. Loss: 1.250081. Batch_acc: 0.528083. Batch_loss: 1.286662 \n",
      "Batch: 3678. Acc: 0.547195. Loss: 1.250077. Batch_acc: 0.551055. Batch_loss: 1.237444 \n",
      "Batch: 3679. Acc: 0.547200. Loss: 1.250063. Batch_acc: 0.566724. Batch_loss: 1.198096 \n",
      "Batch: 3680. Acc: 0.547205. Loss: 1.250053. Batch_acc: 0.564379. Batch_loss: 1.213220 \n",
      "Batch: 3681. Acc: 0.547209. Loss: 1.250045. Batch_acc: 0.563112. Batch_loss: 1.222306 \n",
      "Batch: 3682. Acc: 0.547208. Loss: 1.250050. Batch_acc: 0.543620. Batch_loss: 1.265832 \n",
      "Batch: 3683. Acc: 0.547209. Loss: 1.250055. Batch_acc: 0.548903. Batch_loss: 1.269705 \n",
      "Batch: 3684. Acc: 0.547209. Loss: 1.250047. Batch_acc: 0.547083. Batch_loss: 1.222231 \n",
      "Batch: 3685. Acc: 0.547212. Loss: 1.250039. Batch_acc: 0.560389. Batch_loss: 1.221097 \n",
      "Batch: 3686. Acc: 0.547212. Loss: 1.250037. Batch_acc: 0.544711. Batch_loss: 1.242534 \n",
      "Batch: 3687. Acc: 0.547220. Loss: 1.250014. Batch_acc: 0.576204. Batch_loss: 1.165905 \n",
      "Batch: 3688. Acc: 0.547228. Loss: 1.249991. Batch_acc: 0.576923. Batch_loss: 1.166022 \n",
      "Batch: 3689. Acc: 0.547237. Loss: 1.249971. Batch_acc: 0.579181. Batch_loss: 1.179645 \n",
      "Batch: 3690. Acc: 0.547238. Loss: 1.249963. Batch_acc: 0.551163. Batch_loss: 1.218051 \n",
      "Batch: 3691. Acc: 0.547240. Loss: 1.249952. Batch_acc: 0.555993. Batch_loss: 1.211408 \n",
      "Batch: 3692. Acc: 0.547244. Loss: 1.249946. Batch_acc: 0.561404. Batch_loss: 1.226080 \n",
      "Batch: 3693. Acc: 0.547245. Loss: 1.249940. Batch_acc: 0.551627. Batch_loss: 1.230111 \n",
      "Batch: 3694. Acc: 0.547248. Loss: 1.249934. Batch_acc: 0.559091. Batch_loss: 1.226255 \n",
      "Batch: 3695. Acc: 0.547247. Loss: 1.249935. Batch_acc: 0.540365. Batch_loss: 1.255820 \n",
      "Batch: 3696. Acc: 0.547249. Loss: 1.249935. Batch_acc: 0.556492. Batch_loss: 1.249270 \n",
      "Batch: 3697. Acc: 0.547244. Loss: 1.249943. Batch_acc: 0.528930. Batch_loss: 1.281504 \n",
      "Batch: 3698. Acc: 0.547245. Loss: 1.249944. Batch_acc: 0.550410. Batch_loss: 1.252531 \n",
      "Batch: 3699. Acc: 0.547250. Loss: 1.249936. Batch_acc: 0.564174. Batch_loss: 1.222116 \n",
      "Batch: 3700. Acc: 0.547256. Loss: 1.249917. Batch_acc: 0.569801. Batch_loss: 1.177756 \n",
      "Batch: 3701. Acc: 0.547261. Loss: 1.249902. Batch_acc: 0.566998. Batch_loss: 1.193283 \n",
      "Batch: 3702. Acc: 0.547259. Loss: 1.249907. Batch_acc: 0.540129. Batch_loss: 1.268877 \n",
      "Batch: 3703. Acc: 0.547265. Loss: 1.249898. Batch_acc: 0.568439. Batch_loss: 1.219479 \n",
      "Batch: 3704. Acc: 0.547268. Loss: 1.249888. Batch_acc: 0.556243. Batch_loss: 1.211226 \n",
      "Batch: 3705. Acc: 0.547274. Loss: 1.249878. Batch_acc: 0.569444. Batch_loss: 1.214136 \n",
      "Batch: 3706. Acc: 0.547276. Loss: 1.249871. Batch_acc: 0.557151. Batch_loss: 1.224730 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3707. Acc: 0.547279. Loss: 1.249861. Batch_acc: 0.558405. Batch_loss: 1.213110 \n",
      "Batch: 3708. Acc: 0.547280. Loss: 1.249861. Batch_acc: 0.549913. Batch_loss: 1.248247 \n",
      "Batch: 3709. Acc: 0.547287. Loss: 1.249842. Batch_acc: 0.570946. Batch_loss: 1.181582 \n",
      "Batch: 3710. Acc: 0.547294. Loss: 1.249830. Batch_acc: 0.573837. Batch_loss: 1.203016 \n",
      "Batch: 3711. Acc: 0.547297. Loss: 1.249826. Batch_acc: 0.561310. Batch_loss: 1.234793 \n",
      "Batch: 3712. Acc: 0.547302. Loss: 1.249816. Batch_acc: 0.563405. Batch_loss: 1.213655 \n",
      "Batch: 3713. Acc: 0.547311. Loss: 1.249788. Batch_acc: 0.579911. Batch_loss: 1.149044 \n",
      "Batch: 3714. Acc: 0.547308. Loss: 1.249790. Batch_acc: 0.535401. Batch_loss: 1.259575 \n",
      "Batch: 3715. Acc: 0.547307. Loss: 1.249791. Batch_acc: 0.543651. Batch_loss: 1.253681 \n",
      "Batch: 3716. Acc: 0.547305. Loss: 1.249792. Batch_acc: 0.542034. Batch_loss: 1.251739 \n",
      "Batch: 3717. Acc: 0.547304. Loss: 1.249795. Batch_acc: 0.541691. Batch_loss: 1.260408 \n",
      "Batch: 3718. Acc: 0.547308. Loss: 1.249783. Batch_acc: 0.564162. Batch_loss: 1.205441 \n",
      "Batch: 3719. Acc: 0.547318. Loss: 1.249765. Batch_acc: 0.584019. Batch_loss: 1.181221 \n",
      "Batch: 3720. Acc: 0.547323. Loss: 1.249749. Batch_acc: 0.567536. Batch_loss: 1.188738 \n",
      "Batch: 3721. Acc: 0.547331. Loss: 1.249729. Batch_acc: 0.574758. Batch_loss: 1.175881 \n",
      "Batch: 3722. Acc: 0.547335. Loss: 1.249716. Batch_acc: 0.562820. Batch_loss: 1.202312 \n",
      "Batch: 3723. Acc: 0.547331. Loss: 1.249723. Batch_acc: 0.532286. Batch_loss: 1.276035 \n",
      "Batch: 3724. Acc: 0.547333. Loss: 1.249714. Batch_acc: 0.553944. Batch_loss: 1.216694 \n",
      "Batch: 3725. Acc: 0.547336. Loss: 1.249704. Batch_acc: 0.560000. Batch_loss: 1.214426 \n",
      "Batch: 3726. Acc: 0.547340. Loss: 1.249693. Batch_acc: 0.562137. Batch_loss: 1.207921 \n",
      "Batch: 3727. Acc: 0.547348. Loss: 1.249672. Batch_acc: 0.576050. Batch_loss: 1.173885 \n",
      "Batch: 3728. Acc: 0.547361. Loss: 1.249639. Batch_acc: 0.597506. Batch_loss: 1.125084 \n",
      "Batch: 3729. Acc: 0.547368. Loss: 1.249627. Batch_acc: 0.569721. Batch_loss: 1.206931 \n",
      "Batch: 3730. Acc: 0.547373. Loss: 1.249616. Batch_acc: 0.568169. Batch_loss: 1.210365 \n",
      "Batch: 3731. Acc: 0.547375. Loss: 1.249609. Batch_acc: 0.553603. Batch_loss: 1.223229 \n",
      "Batch: 3732. Acc: 0.547378. Loss: 1.249597. Batch_acc: 0.557735. Batch_loss: 1.207135 \n",
      "Batch: 3733. Acc: 0.547379. Loss: 1.249597. Batch_acc: 0.551222. Batch_loss: 1.247869 \n",
      "Batch: 3734. Acc: 0.547382. Loss: 1.249591. Batch_acc: 0.560517. Batch_loss: 1.225390 \n",
      "Batch: 3735. Acc: 0.547385. Loss: 1.249577. Batch_acc: 0.559073. Batch_loss: 1.198717 \n",
      "Batch: 3736. Acc: 0.547390. Loss: 1.249566. Batch_acc: 0.565015. Batch_loss: 1.209158 \n",
      "Batch: 3737. Acc: 0.547398. Loss: 1.249545. Batch_acc: 0.576836. Batch_loss: 1.171941 \n",
      "Batch: 3738. Acc: 0.547396. Loss: 1.249548. Batch_acc: 0.539130. Batch_loss: 1.261835 \n",
      "Batch: 3739. Acc: 0.547400. Loss: 1.249534. Batch_acc: 0.561823. Batch_loss: 1.197175 \n",
      "Batch: 3740. Acc: 0.547400. Loss: 1.249534. Batch_acc: 0.549799. Batch_loss: 1.247557 \n",
      "Batch: 3741. Acc: 0.547398. Loss: 1.249541. Batch_acc: 0.539828. Batch_loss: 1.277938 \n",
      "Batch: 3742. Acc: 0.547392. Loss: 1.249551. Batch_acc: 0.522176. Batch_loss: 1.286350 \n",
      "Batch: 3743. Acc: 0.547383. Loss: 1.249570. Batch_acc: 0.513514. Batch_loss: 1.320777 \n",
      "Batch: 3744. Acc: 0.547385. Loss: 1.249561. Batch_acc: 0.555301. Batch_loss: 1.215787 \n",
      "Batch: 3745. Acc: 0.547383. Loss: 1.249566. Batch_acc: 0.538773. Batch_loss: 1.269613 \n",
      "Batch: 3746. Acc: 0.547383. Loss: 1.249570. Batch_acc: 0.547424. Batch_loss: 1.263451 \n",
      "Batch: 3747. Acc: 0.547381. Loss: 1.249574. Batch_acc: 0.540509. Batch_loss: 1.266508 \n",
      "Batch: 3748. Acc: 0.547373. Loss: 1.249590. Batch_acc: 0.517805. Batch_loss: 1.309987 \n",
      "Batch: 3749. Acc: 0.547371. Loss: 1.249592. Batch_acc: 0.538111. Batch_loss: 1.258738 \n",
      "Batch: 3750. Acc: 0.547369. Loss: 1.249606. Batch_acc: 0.543084. Batch_loss: 1.300043 \n",
      "Batch: 3751. Acc: 0.547372. Loss: 1.249596. Batch_acc: 0.557501. Batch_loss: 1.212499 \n",
      "Batch: 3752. Acc: 0.547377. Loss: 1.249588. Batch_acc: 0.565873. Batch_loss: 1.218667 \n",
      "Batch: 3753. Acc: 0.547379. Loss: 1.249589. Batch_acc: 0.556005. Batch_loss: 1.254296 \n",
      "Batch: 3754. Acc: 0.547378. Loss: 1.249592. Batch_acc: 0.543919. Batch_loss: 1.257248 \n",
      "Batch: 3755. Acc: 0.547372. Loss: 1.249607. Batch_acc: 0.523729. Batch_loss: 1.306064 \n",
      "Batch: 3756. Acc: 0.547373. Loss: 1.249605. Batch_acc: 0.552256. Batch_loss: 1.241492 \n",
      "Batch: 3757. Acc: 0.547377. Loss: 1.249597. Batch_acc: 0.560961. Batch_loss: 1.218710 \n",
      "Batch: 3758. Acc: 0.547388. Loss: 1.249565. Batch_acc: 0.589205. Batch_loss: 1.133077 \n",
      "Batch: 3759. Acc: 0.547391. Loss: 1.249557. Batch_acc: 0.556779. Batch_loss: 1.217784 \n",
      "Batch: 3760. Acc: 0.547391. Loss: 1.249557. Batch_acc: 0.547786. Batch_loss: 1.250860 \n",
      "Batch: 3761. Acc: 0.547391. Loss: 1.249557. Batch_acc: 0.547368. Batch_loss: 1.250221 \n",
      "Batch: 3762. Acc: 0.547392. Loss: 1.249556. Batch_acc: 0.551069. Batch_loss: 1.244111 \n",
      "Batch: 3763. Acc: 0.547390. Loss: 1.249567. Batch_acc: 0.543058. Batch_loss: 1.292622 \n",
      "Batch: 3764. Acc: 0.547394. Loss: 1.249556. Batch_acc: 0.561353. Batch_loss: 1.207027 \n",
      "Batch: 3765. Acc: 0.547391. Loss: 1.249559. Batch_acc: 0.534262. Batch_loss: 1.260934 \n",
      "Checkpointing on batch: 3765. Accuracy: 0.5473906986548702. Loss per char: 1.249558839533748. Time: 1627224704.6678295\n",
      "Last question is tensor([ 2, 52, 86, 67, 85, 83, 66, 68, 85,  1, 14, 18, 19, 24, 23, 21, 19, 25,\n",
      "        21,  1, 71, 83, 80, 78,  1, 14, 19, 20, 21, 22, 21, 21, 15,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 3766. Acc: 0.547399. Loss: 1.249542. Batch_acc: 0.579851. Batch_loss: 1.184793 \n",
      "Batch: 3767. Acc: 0.547403. Loss: 1.249530. Batch_acc: 0.561242. Batch_loss: 1.205522 \n",
      "Batch: 3768. Acc: 0.547407. Loss: 1.249520. Batch_acc: 0.562249. Batch_loss: 1.212235 \n",
      "Batch: 3769. Acc: 0.547413. Loss: 1.249500. Batch_acc: 0.571185. Batch_loss: 1.174973 \n",
      "Batch: 3770. Acc: 0.547414. Loss: 1.249497. Batch_acc: 0.550974. Batch_loss: 1.240486 \n",
      "Batch: 3771. Acc: 0.547414. Loss: 1.249494. Batch_acc: 0.547703. Batch_loss: 1.234229 \n",
      "Batch: 3772. Acc: 0.547418. Loss: 1.249484. Batch_acc: 0.560046. Batch_loss: 1.212550 \n",
      "Batch: 3773. Acc: 0.547424. Loss: 1.249469. Batch_acc: 0.571186. Batch_loss: 1.195929 \n",
      "Batch: 3774. Acc: 0.547427. Loss: 1.249452. Batch_acc: 0.559091. Batch_loss: 1.186809 \n",
      "Batch: 3775. Acc: 0.547432. Loss: 1.249441. Batch_acc: 0.564580. Batch_loss: 1.205831 \n",
      "Batch: 3776. Acc: 0.547439. Loss: 1.249417. Batch_acc: 0.573968. Batch_loss: 1.161894 \n",
      "Batch: 3777. Acc: 0.547445. Loss: 1.249407. Batch_acc: 0.569323. Batch_loss: 1.210629 \n",
      "Batch: 3778. Acc: 0.547449. Loss: 1.249392. Batch_acc: 0.563615. Batch_loss: 1.194436 \n",
      "Batch: 3779. Acc: 0.547454. Loss: 1.249381. Batch_acc: 0.564799. Batch_loss: 1.207064 \n",
      "Batch: 3780. Acc: 0.547455. Loss: 1.249374. Batch_acc: 0.551626. Batch_loss: 1.225525 \n",
      "Batch: 3781. Acc: 0.547455. Loss: 1.249373. Batch_acc: 0.547674. Batch_loss: 1.243587 \n",
      "Batch: 3782. Acc: 0.547456. Loss: 1.249377. Batch_acc: 0.549369. Batch_loss: 1.265723 \n",
      "Batch: 3783. Acc: 0.547462. Loss: 1.249359. Batch_acc: 0.572323. Batch_loss: 1.180932 \n",
      "Batch: 3784. Acc: 0.547466. Loss: 1.249352. Batch_acc: 0.560731. Batch_loss: 1.224160 \n",
      "Batch: 3785. Acc: 0.547469. Loss: 1.249335. Batch_acc: 0.559006. Batch_loss: 1.184090 \n",
      "Batch: 3786. Acc: 0.547462. Loss: 1.249353. Batch_acc: 0.519435. Batch_loss: 1.319816 \n",
      "Batch: 3787. Acc: 0.547467. Loss: 1.249344. Batch_acc: 0.567552. Batch_loss: 1.216200 \n",
      "Batch: 3788. Acc: 0.547468. Loss: 1.249349. Batch_acc: 0.550682. Batch_loss: 1.268354 \n",
      "Batch: 3789. Acc: 0.547469. Loss: 1.249345. Batch_acc: 0.552316. Batch_loss: 1.235138 \n",
      "Batch: 3790. Acc: 0.547466. Loss: 1.249347. Batch_acc: 0.537486. Batch_loss: 1.254583 \n",
      "Batch: 3791. Acc: 0.547469. Loss: 1.249339. Batch_acc: 0.557901. Batch_loss: 1.220044 \n",
      "Batch: 3792. Acc: 0.547470. Loss: 1.249341. Batch_acc: 0.550974. Batch_loss: 1.257524 \n",
      "Batch: 3793. Acc: 0.547470. Loss: 1.249346. Batch_acc: 0.547159. Batch_loss: 1.268565 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3794. Acc: 0.547468. Loss: 1.249348. Batch_acc: 0.537956. Batch_loss: 1.258484 \n",
      "Batch: 3795. Acc: 0.547470. Loss: 1.249340. Batch_acc: 0.556856. Batch_loss: 1.219808 \n",
      "Batch: 3796. Acc: 0.547472. Loss: 1.249338. Batch_acc: 0.555366. Batch_loss: 1.242073 \n",
      "Batch: 3797. Acc: 0.547476. Loss: 1.249332. Batch_acc: 0.560807. Batch_loss: 1.223551 \n",
      "Batch: 3798. Acc: 0.547475. Loss: 1.249334. Batch_acc: 0.545882. Batch_loss: 1.259134 \n",
      "Batch: 3799. Acc: 0.547478. Loss: 1.249330. Batch_acc: 0.557377. Batch_loss: 1.233083 \n",
      "Batch: 3800. Acc: 0.547480. Loss: 1.249330. Batch_acc: 0.553656. Batch_loss: 1.250250 \n",
      "Batch: 3801. Acc: 0.547481. Loss: 1.249325. Batch_acc: 0.554252. Batch_loss: 1.228779 \n",
      "Batch: 3802. Acc: 0.547487. Loss: 1.249308. Batch_acc: 0.568605. Batch_loss: 1.186182 \n",
      "Batch: 3803. Acc: 0.547482. Loss: 1.249318. Batch_acc: 0.528696. Batch_loss: 1.290232 \n",
      "Batch: 3804. Acc: 0.547487. Loss: 1.249305. Batch_acc: 0.566377. Batch_loss: 1.199327 \n",
      "Batch: 3805. Acc: 0.547489. Loss: 1.249294. Batch_acc: 0.553267. Batch_loss: 1.203189 \n",
      "Batch: 3806. Acc: 0.547486. Loss: 1.249301. Batch_acc: 0.536148. Batch_loss: 1.277780 \n",
      "Batch: 3807. Acc: 0.547488. Loss: 1.249289. Batch_acc: 0.558754. Batch_loss: 1.201704 \n",
      "Batch: 3808. Acc: 0.547492. Loss: 1.249283. Batch_acc: 0.559795. Batch_loss: 1.229011 \n",
      "Batch: 3809. Acc: 0.547500. Loss: 1.249276. Batch_acc: 0.577537. Batch_loss: 1.221474 \n",
      "Batch: 3810. Acc: 0.547494. Loss: 1.249288. Batch_acc: 0.526869. Batch_loss: 1.294310 \n",
      "Batch: 3811. Acc: 0.547496. Loss: 1.249282. Batch_acc: 0.552678. Batch_loss: 1.228868 \n",
      "Batch: 3812. Acc: 0.547493. Loss: 1.249282. Batch_acc: 0.537757. Batch_loss: 1.247447 \n",
      "Batch: 3813. Acc: 0.547492. Loss: 1.249281. Batch_acc: 0.544715. Batch_loss: 1.244332 \n",
      "Batch: 3814. Acc: 0.547496. Loss: 1.249274. Batch_acc: 0.560520. Batch_loss: 1.225257 \n",
      "Batch: 3815. Acc: 0.547496. Loss: 1.249268. Batch_acc: 0.548894. Batch_loss: 1.225969 \n",
      "Batch: 3816. Acc: 0.547504. Loss: 1.249246. Batch_acc: 0.575910. Batch_loss: 1.166151 \n",
      "Batch: 3817. Acc: 0.547502. Loss: 1.249248. Batch_acc: 0.538417. Batch_loss: 1.257138 \n",
      "Batch: 3818. Acc: 0.547504. Loss: 1.249237. Batch_acc: 0.558275. Batch_loss: 1.208832 \n",
      "Batch: 3819. Acc: 0.547508. Loss: 1.249227. Batch_acc: 0.562571. Batch_loss: 1.210784 \n",
      "Batch: 3820. Acc: 0.547510. Loss: 1.249227. Batch_acc: 0.555426. Batch_loss: 1.248660 \n",
      "Batch: 3821. Acc: 0.547512. Loss: 1.249207. Batch_acc: 0.555300. Batch_loss: 1.171938 \n",
      "Batch: 3822. Acc: 0.547515. Loss: 1.249191. Batch_acc: 0.556689. Batch_loss: 1.188568 \n",
      "Batch: 3823. Acc: 0.547514. Loss: 1.249191. Batch_acc: 0.545507. Batch_loss: 1.248927 \n",
      "Batch: 3824. Acc: 0.547514. Loss: 1.249189. Batch_acc: 0.547038. Batch_loss: 1.242589 \n",
      "Batch: 3825. Acc: 0.547525. Loss: 1.249161. Batch_acc: 0.589143. Batch_loss: 1.143918 \n",
      "Batch: 3826. Acc: 0.547523. Loss: 1.249168. Batch_acc: 0.537839. Batch_loss: 1.275392 \n",
      "Batch: 3827. Acc: 0.547530. Loss: 1.249153. Batch_acc: 0.574719. Batch_loss: 1.190499 \n",
      "Batch: 3828. Acc: 0.547537. Loss: 1.249137. Batch_acc: 0.574383. Batch_loss: 1.190220 \n",
      "Batch: 3829. Acc: 0.547543. Loss: 1.249122. Batch_acc: 0.569899. Batch_loss: 1.188665 \n",
      "Batch: 3830. Acc: 0.547539. Loss: 1.249133. Batch_acc: 0.533728. Batch_loss: 1.291635 \n",
      "Batch: 3831. Acc: 0.547545. Loss: 1.249122. Batch_acc: 0.569517. Batch_loss: 1.206541 \n",
      "Batch: 3832. Acc: 0.547543. Loss: 1.249135. Batch_acc: 0.540571. Batch_loss: 1.300879 \n",
      "Batch: 3833. Acc: 0.547547. Loss: 1.249132. Batch_acc: 0.562607. Batch_loss: 1.236400 \n",
      "Batch: 3834. Acc: 0.547548. Loss: 1.249128. Batch_acc: 0.553079. Batch_loss: 1.235302 \n",
      "Batch: 3835. Acc: 0.547551. Loss: 1.249115. Batch_acc: 0.558275. Batch_loss: 1.197547 \n",
      "Batch: 3836. Acc: 0.547555. Loss: 1.249100. Batch_acc: 0.561159. Batch_loss: 1.191423 \n",
      "Batch: 3837. Acc: 0.547558. Loss: 1.249089. Batch_acc: 0.559476. Batch_loss: 1.208307 \n",
      "Batch: 3838. Acc: 0.547563. Loss: 1.249068. Batch_acc: 0.568828. Batch_loss: 1.165947 \n",
      "Batch: 3839. Acc: 0.547572. Loss: 1.249044. Batch_acc: 0.579841. Batch_loss: 1.159085 \n",
      "Batch: 3840. Acc: 0.547579. Loss: 1.249025. Batch_acc: 0.575190. Batch_loss: 1.177300 \n",
      "Batch: 3841. Acc: 0.547585. Loss: 1.249013. Batch_acc: 0.572394. Batch_loss: 1.200747 \n",
      "Batch: 3842. Acc: 0.547584. Loss: 1.249011. Batch_acc: 0.542690. Batch_loss: 1.242779 \n",
      "Batch: 3843. Acc: 0.547584. Loss: 1.249009. Batch_acc: 0.545507. Batch_loss: 1.242640 \n",
      "Batch: 3844. Acc: 0.547587. Loss: 1.249003. Batch_acc: 0.558738. Batch_loss: 1.223976 \n",
      "Batch: 3845. Acc: 0.547589. Loss: 1.249000. Batch_acc: 0.556322. Batch_loss: 1.238224 \n",
      "Batch: 3846. Acc: 0.547590. Loss: 1.248993. Batch_acc: 0.553022. Batch_loss: 1.223594 \n",
      "Batch: 3847. Acc: 0.547586. Loss: 1.249006. Batch_acc: 0.532374. Batch_loss: 1.299776 \n",
      "Batch: 3848. Acc: 0.547590. Loss: 1.248990. Batch_acc: 0.561189. Batch_loss: 1.185915 \n",
      "Batch: 3849. Acc: 0.547584. Loss: 1.249003. Batch_acc: 0.526042. Batch_loss: 1.298156 \n",
      "Batch: 3850. Acc: 0.547586. Loss: 1.248996. Batch_acc: 0.552499. Batch_loss: 1.222663 \n",
      "Batch: 3851. Acc: 0.547587. Loss: 1.248995. Batch_acc: 0.553653. Batch_loss: 1.247062 \n",
      "Batch: 3852. Acc: 0.547588. Loss: 1.248993. Batch_acc: 0.550028. Batch_loss: 1.241924 \n",
      "Batch: 3853. Acc: 0.547591. Loss: 1.248993. Batch_acc: 0.560947. Batch_loss: 1.249715 \n",
      "Batch: 3854. Acc: 0.547597. Loss: 1.248980. Batch_acc: 0.571346. Batch_loss: 1.198761 \n",
      "Batch: 3855. Acc: 0.547607. Loss: 1.248955. Batch_acc: 0.582717. Batch_loss: 1.153032 \n",
      "Batch: 3856. Acc: 0.547607. Loss: 1.248954. Batch_acc: 0.548975. Batch_loss: 1.242478 \n",
      "Batch: 3857. Acc: 0.547616. Loss: 1.248926. Batch_acc: 0.583097. Batch_loss: 1.142819 \n",
      "Batch: 3858. Acc: 0.547617. Loss: 1.248924. Batch_acc: 0.551103. Batch_loss: 1.243014 \n",
      "Batch: 3859. Acc: 0.547622. Loss: 1.248915. Batch_acc: 0.563698. Batch_loss: 1.214643 \n",
      "Batch: 3860. Acc: 0.547624. Loss: 1.248916. Batch_acc: 0.557368. Batch_loss: 1.250744 \n",
      "Batch: 3861. Acc: 0.547622. Loss: 1.248911. Batch_acc: 0.539909. Batch_loss: 1.232775 \n",
      "Batch: 3862. Acc: 0.547626. Loss: 1.248899. Batch_acc: 0.562570. Batch_loss: 1.202838 \n",
      "Batch: 3863. Acc: 0.547626. Loss: 1.248896. Batch_acc: 0.548260. Batch_loss: 1.236129 \n",
      "Batch: 3864. Acc: 0.547628. Loss: 1.248892. Batch_acc: 0.555938. Batch_loss: 1.235796 \n",
      "Batch: 3865. Acc: 0.547624. Loss: 1.248903. Batch_acc: 0.530277. Batch_loss: 1.288006 \n",
      "Batch: 3866. Acc: 0.547623. Loss: 1.248906. Batch_acc: 0.543261. Batch_loss: 1.264076 \n",
      "Batch: 3867. Acc: 0.547622. Loss: 1.248907. Batch_acc: 0.546079. Batch_loss: 1.250762 \n",
      "Batch: 3868. Acc: 0.547626. Loss: 1.248887. Batch_acc: 0.562069. Batch_loss: 1.173461 \n",
      "Batch: 3869. Acc: 0.547632. Loss: 1.248875. Batch_acc: 0.569484. Batch_loss: 1.201763 \n",
      "Batch: 3870. Acc: 0.547636. Loss: 1.248860. Batch_acc: 0.562358. Batch_loss: 1.191542 \n",
      "Batch: 3871. Acc: 0.547639. Loss: 1.248851. Batch_acc: 0.561485. Batch_loss: 1.215225 \n",
      "Batch: 3872. Acc: 0.547641. Loss: 1.248837. Batch_acc: 0.556551. Batch_loss: 1.195377 \n",
      "Batch: 3873. Acc: 0.547649. Loss: 1.248815. Batch_acc: 0.577143. Batch_loss: 1.163226 \n",
      "Batch: 3874. Acc: 0.547651. Loss: 1.248813. Batch_acc: 0.555111. Batch_loss: 1.239705 \n",
      "Batch: 3875. Acc: 0.547657. Loss: 1.248800. Batch_acc: 0.569161. Batch_loss: 1.201942 \n",
      "Batch: 3876. Acc: 0.547660. Loss: 1.248794. Batch_acc: 0.559517. Batch_loss: 1.224183 \n",
      "Batch: 3877. Acc: 0.547666. Loss: 1.248780. Batch_acc: 0.571930. Batch_loss: 1.193493 \n",
      "Batch: 3878. Acc: 0.547669. Loss: 1.248774. Batch_acc: 0.557703. Batch_loss: 1.226685 \n",
      "Batch: 3879. Acc: 0.547669. Loss: 1.248773. Batch_acc: 0.549076. Batch_loss: 1.243417 \n",
      "Batch: 3880. Acc: 0.547673. Loss: 1.248767. Batch_acc: 0.562178. Batch_loss: 1.224948 \n",
      "Batch: 3881. Acc: 0.547671. Loss: 1.248768. Batch_acc: 0.542093. Batch_loss: 1.252929 \n",
      "Batch: 3882. Acc: 0.547671. Loss: 1.248762. Batch_acc: 0.547687. Batch_loss: 1.226755 \n",
      "Batch: 3883. Acc: 0.547669. Loss: 1.248771. Batch_acc: 0.539031. Batch_loss: 1.281612 \n",
      "Batch: 3884. Acc: 0.547675. Loss: 1.248753. Batch_acc: 0.569335. Batch_loss: 1.181990 \n",
      "Batch: 3885. Acc: 0.547676. Loss: 1.248750. Batch_acc: 0.554854. Batch_loss: 1.237102 \n",
      "Batch: 3886. Acc: 0.547678. Loss: 1.248745. Batch_acc: 0.554238. Batch_loss: 1.229165 \n",
      "Batch: 3887. Acc: 0.547683. Loss: 1.248735. Batch_acc: 0.565639. Batch_loss: 1.209688 \n",
      "Batch: 3888. Acc: 0.547686. Loss: 1.248726. Batch_acc: 0.559188. Batch_loss: 1.212423 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3889. Acc: 0.547686. Loss: 1.248724. Batch_acc: 0.548538. Batch_loss: 1.243806 \n",
      "Batch: 3890. Acc: 0.547690. Loss: 1.248712. Batch_acc: 0.561932. Batch_loss: 1.202244 \n",
      "Batch: 3891. Acc: 0.547693. Loss: 1.248707. Batch_acc: 0.558960. Batch_loss: 1.228018 \n",
      "Batch: 3892. Acc: 0.547693. Loss: 1.248714. Batch_acc: 0.549166. Batch_loss: 1.277819 \n",
      "Batch: 3893. Acc: 0.547702. Loss: 1.248693. Batch_acc: 0.581355. Batch_loss: 1.166090 \n",
      "Batch: 3894. Acc: 0.547710. Loss: 1.248668. Batch_acc: 0.578354. Batch_loss: 1.153748 \n",
      "Batch: 3895. Acc: 0.547712. Loss: 1.248664. Batch_acc: 0.555751. Batch_loss: 1.232709 \n",
      "Batch: 3896. Acc: 0.547718. Loss: 1.248645. Batch_acc: 0.573072. Batch_loss: 1.174369 \n",
      "Batch: 3897. Acc: 0.547721. Loss: 1.248644. Batch_acc: 0.558891. Batch_loss: 1.243444 \n",
      "Batch: 3898. Acc: 0.547720. Loss: 1.248647. Batch_acc: 0.542254. Batch_loss: 1.259230 \n",
      "Batch: 3899. Acc: 0.547726. Loss: 1.248629. Batch_acc: 0.571510. Batch_loss: 1.181185 \n",
      "Batch: 3900. Acc: 0.547727. Loss: 1.248625. Batch_acc: 0.552927. Batch_loss: 1.230516 \n",
      "Batch: 3901. Acc: 0.547733. Loss: 1.248608. Batch_acc: 0.571754. Batch_loss: 1.182591 \n",
      "Batch: 3902. Acc: 0.547735. Loss: 1.248604. Batch_acc: 0.553253. Batch_loss: 1.234001 \n",
      "Batch: 3903. Acc: 0.547735. Loss: 1.248595. Batch_acc: 0.549575. Batch_loss: 1.212864 \n",
      "Batch: 3904. Acc: 0.547738. Loss: 1.248579. Batch_acc: 0.558789. Batch_loss: 1.188278 \n",
      "Batch: 3905. Acc: 0.547747. Loss: 1.248556. Batch_acc: 0.582628. Batch_loss: 1.158710 \n",
      "Batch: 3906. Acc: 0.547750. Loss: 1.248551. Batch_acc: 0.558352. Batch_loss: 1.230954 \n",
      "Batch: 3907. Acc: 0.547755. Loss: 1.248541. Batch_acc: 0.566038. Batch_loss: 1.207475 \n",
      "Batch: 3908. Acc: 0.547753. Loss: 1.248540. Batch_acc: 0.539909. Batch_loss: 1.244827 \n",
      "Batch: 3909. Acc: 0.547755. Loss: 1.248533. Batch_acc: 0.558789. Batch_loss: 1.222501 \n",
      "Batch: 3910. Acc: 0.547755. Loss: 1.248537. Batch_acc: 0.548311. Batch_loss: 1.263849 \n",
      "Batch: 3911. Acc: 0.547759. Loss: 1.248525. Batch_acc: 0.559504. Batch_loss: 1.203251 \n",
      "Batch: 3912. Acc: 0.547763. Loss: 1.248507. Batch_acc: 0.565506. Batch_loss: 1.179787 \n",
      "Batch: 3913. Acc: 0.547764. Loss: 1.248503. Batch_acc: 0.550253. Batch_loss: 1.235276 \n",
      "Batch: 3914. Acc: 0.547761. Loss: 1.248511. Batch_acc: 0.537015. Batch_loss: 1.278125 \n",
      "Batch: 3915. Acc: 0.547753. Loss: 1.248517. Batch_acc: 0.513639. Batch_loss: 1.274359 \n",
      "Batch: 3916. Acc: 0.547760. Loss: 1.248500. Batch_acc: 0.577332. Batch_loss: 1.177478 \n",
      "Batch: 3917. Acc: 0.547764. Loss: 1.248491. Batch_acc: 0.561955. Batch_loss: 1.213227 \n",
      "Batch: 3918. Acc: 0.547763. Loss: 1.248489. Batch_acc: 0.545029. Batch_loss: 1.239633 \n",
      "Batch: 3919. Acc: 0.547766. Loss: 1.248480. Batch_acc: 0.560947. Batch_loss: 1.213996 \n",
      "Batch: 3920. Acc: 0.547768. Loss: 1.248478. Batch_acc: 0.553022. Batch_loss: 1.242897 \n",
      "Batch: 3921. Acc: 0.547776. Loss: 1.248458. Batch_acc: 0.581211. Batch_loss: 1.168737 \n",
      "Batch: 3922. Acc: 0.547772. Loss: 1.248471. Batch_acc: 0.531231. Batch_loss: 1.301268 \n",
      "Batch: 3923. Acc: 0.547776. Loss: 1.248462. Batch_acc: 0.561073. Batch_loss: 1.215765 \n",
      "Batch: 3924. Acc: 0.547777. Loss: 1.248458. Batch_acc: 0.554736. Batch_loss: 1.232978 \n",
      "Batch: 3925. Acc: 0.547782. Loss: 1.248443. Batch_acc: 0.564939. Batch_loss: 1.188951 \n",
      "Batch: 3926. Acc: 0.547778. Loss: 1.248448. Batch_acc: 0.532801. Batch_loss: 1.264813 \n",
      "Batch: 3927. Acc: 0.547786. Loss: 1.248427. Batch_acc: 0.579875. Batch_loss: 1.170060 \n",
      "Batch: 3928. Acc: 0.547780. Loss: 1.248443. Batch_acc: 0.522768. Batch_loss: 1.312738 \n",
      "Batch: 3929. Acc: 0.547774. Loss: 1.248453. Batch_acc: 0.523669. Batch_loss: 1.289797 \n",
      "Batch: 3930. Acc: 0.547776. Loss: 1.248459. Batch_acc: 0.555749. Batch_loss: 1.271818 \n",
      "Batch: 3931. Acc: 0.547780. Loss: 1.248450. Batch_acc: 0.563842. Batch_loss: 1.211020 \n",
      "Batch: 3932. Acc: 0.547787. Loss: 1.248429. Batch_acc: 0.575740. Batch_loss: 1.167746 \n",
      "Batch: 3933. Acc: 0.547785. Loss: 1.248432. Batch_acc: 0.539384. Batch_loss: 1.260019 \n",
      "Batch: 3934. Acc: 0.547783. Loss: 1.248438. Batch_acc: 0.539874. Batch_loss: 1.271385 \n",
      "Batch: 3935. Acc: 0.547789. Loss: 1.248429. Batch_acc: 0.571347. Batch_loss: 1.215829 \n",
      "Batch: 3936. Acc: 0.547792. Loss: 1.248417. Batch_acc: 0.559510. Batch_loss: 1.199367 \n",
      "Batch: 3937. Acc: 0.547797. Loss: 1.248400. Batch_acc: 0.566783. Batch_loss: 1.179407 \n",
      "Batch: 3938. Acc: 0.547802. Loss: 1.248388. Batch_acc: 0.570262. Batch_loss: 1.200897 \n",
      "Batch: 3939. Acc: 0.547805. Loss: 1.248378. Batch_acc: 0.558100. Batch_loss: 1.210223 \n",
      "Batch: 3940. Acc: 0.547810. Loss: 1.248363. Batch_acc: 0.568458. Batch_loss: 1.187264 \n",
      "Batch: 3941. Acc: 0.547811. Loss: 1.248363. Batch_acc: 0.549494. Batch_loss: 1.248362 \n",
      "Batch: 3942. Acc: 0.547815. Loss: 1.248356. Batch_acc: 0.564058. Batch_loss: 1.221123 \n",
      "Batch: 3943. Acc: 0.547813. Loss: 1.248361. Batch_acc: 0.539306. Batch_loss: 1.270336 \n",
      "Batch: 3944. Acc: 0.547815. Loss: 1.248352. Batch_acc: 0.556120. Batch_loss: 1.213379 \n",
      "Batch: 3945. Acc: 0.547814. Loss: 1.248353. Batch_acc: 0.543035. Batch_loss: 1.251642 \n",
      "Batch: 3946. Acc: 0.547828. Loss: 1.248314. Batch_acc: 0.603495. Batch_loss: 1.102730 \n",
      "Batch: 3947. Acc: 0.547834. Loss: 1.248292. Batch_acc: 0.570136. Batch_loss: 1.159592 \n",
      "Batch: 3948. Acc: 0.547839. Loss: 1.248275. Batch_acc: 0.568156. Batch_loss: 1.183295 \n",
      "Batch: 3949. Acc: 0.547844. Loss: 1.248262. Batch_acc: 0.565634. Batch_loss: 1.196629 \n",
      "Batch: 3950. Acc: 0.547842. Loss: 1.248255. Batch_acc: 0.542088. Batch_loss: 1.221509 \n",
      "Batch: 3951. Acc: 0.547848. Loss: 1.248242. Batch_acc: 0.567720. Batch_loss: 1.198596 \n",
      "Batch: 3952. Acc: 0.547845. Loss: 1.248239. Batch_acc: 0.538776. Batch_loss: 1.237836 \n",
      "Batch: 3953. Acc: 0.547853. Loss: 1.248220. Batch_acc: 0.578045. Batch_loss: 1.174096 \n",
      "Batch: 3954. Acc: 0.547847. Loss: 1.248229. Batch_acc: 0.524155. Batch_loss: 1.283702 \n",
      "Batch: 3955. Acc: 0.547851. Loss: 1.248222. Batch_acc: 0.561196. Batch_loss: 1.219894 \n",
      "Batch: 3956. Acc: 0.547852. Loss: 1.248219. Batch_acc: 0.552692. Batch_loss: 1.239002 \n",
      "Batch: 3957. Acc: 0.547850. Loss: 1.248225. Batch_acc: 0.538092. Batch_loss: 1.270347 \n",
      "Batch: 3958. Acc: 0.547847. Loss: 1.248227. Batch_acc: 0.537796. Batch_loss: 1.257356 \n",
      "Batch: 3959. Acc: 0.547840. Loss: 1.248243. Batch_acc: 0.518187. Batch_loss: 1.316004 \n",
      "Batch: 3960. Acc: 0.547837. Loss: 1.248245. Batch_acc: 0.538282. Batch_loss: 1.255290 \n",
      "Batch: 3961. Acc: 0.547840. Loss: 1.248237. Batch_acc: 0.557527. Batch_loss: 1.215001 \n",
      "Batch: 3962. Acc: 0.547844. Loss: 1.248223. Batch_acc: 0.565751. Batch_loss: 1.193939 \n",
      "Batch: 3963. Acc: 0.547843. Loss: 1.248224. Batch_acc: 0.543376. Batch_loss: 1.249428 \n",
      "Batch: 3964. Acc: 0.547841. Loss: 1.248235. Batch_acc: 0.536716. Batch_loss: 1.293309 \n",
      "Batch: 3965. Acc: 0.547841. Loss: 1.248231. Batch_acc: 0.549470. Batch_loss: 1.234156 \n",
      "Batch: 3966. Acc: 0.547851. Loss: 1.248200. Batch_acc: 0.585829. Batch_loss: 1.124668 \n",
      "Batch: 3967. Acc: 0.547852. Loss: 1.248193. Batch_acc: 0.554196. Batch_loss: 1.220262 \n",
      "Batch: 3968. Acc: 0.547860. Loss: 1.248168. Batch_acc: 0.579096. Batch_loss: 1.152206 \n",
      "Batch: 3969. Acc: 0.547860. Loss: 1.248170. Batch_acc: 0.548148. Batch_loss: 1.254106 \n",
      "Batch: 3970. Acc: 0.547864. Loss: 1.248159. Batch_acc: 0.561605. Batch_loss: 1.203282 \n",
      "Batch: 3971. Acc: 0.547869. Loss: 1.248140. Batch_acc: 0.568051. Batch_loss: 1.175573 \n",
      "Batch: 3972. Acc: 0.547868. Loss: 1.248137. Batch_acc: 0.546651. Batch_loss: 1.233244 \n",
      "Batch: 3973. Acc: 0.547875. Loss: 1.248124. Batch_acc: 0.574601. Batch_loss: 1.198674 \n",
      "Batch: 3974. Acc: 0.547880. Loss: 1.248121. Batch_acc: 0.565292. Batch_loss: 1.236373 \n",
      "Batch: 3975. Acc: 0.547888. Loss: 1.248092. Batch_acc: 0.581692. Batch_loss: 1.133677 \n",
      "Batch: 3976. Acc: 0.547890. Loss: 1.248084. Batch_acc: 0.557202. Batch_loss: 1.212228 \n",
      "Batch: 3977. Acc: 0.547890. Loss: 1.248079. Batch_acc: 0.545147. Batch_loss: 1.229474 \n",
      "Batch: 3978. Acc: 0.547892. Loss: 1.248079. Batch_acc: 0.555431. Batch_loss: 1.247727 \n",
      "Batch: 3979. Acc: 0.547886. Loss: 1.248096. Batch_acc: 0.526080. Batch_loss: 1.314073 \n",
      "Batch: 3980. Acc: 0.547895. Loss: 1.248076. Batch_acc: 0.582014. Batch_loss: 1.170909 \n",
      "Batch: 3981. Acc: 0.547901. Loss: 1.248060. Batch_acc: 0.573389. Batch_loss: 1.180346 \n",
      "Batch: 3982. Acc: 0.547904. Loss: 1.248055. Batch_acc: 0.559601. Batch_loss: 1.226748 \n",
      "Batch: 3983. Acc: 0.547906. Loss: 1.248051. Batch_acc: 0.557349. Batch_loss: 1.234025 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 3984. Acc: 0.547912. Loss: 1.248039. Batch_acc: 0.570755. Batch_loss: 1.197888 \n",
      "Batch: 3985. Acc: 0.547916. Loss: 1.248024. Batch_acc: 0.563927. Batch_loss: 1.187997 \n",
      "Batch: 3986. Acc: 0.547915. Loss: 1.248027. Batch_acc: 0.546302. Batch_loss: 1.261293 \n",
      "Batch: 3987. Acc: 0.547913. Loss: 1.248026. Batch_acc: 0.539823. Batch_loss: 1.245126 \n",
      "Batch: 3988. Acc: 0.547921. Loss: 1.248013. Batch_acc: 0.577790. Batch_loss: 1.196027 \n",
      "Batch: 3989. Acc: 0.547922. Loss: 1.248010. Batch_acc: 0.550143. Batch_loss: 1.237708 \n",
      "Batch: 3990. Acc: 0.547926. Loss: 1.247999. Batch_acc: 0.565887. Batch_loss: 1.202393 \n",
      "Batch: 3991. Acc: 0.547930. Loss: 1.247983. Batch_acc: 0.564563. Batch_loss: 1.185608 \n",
      "Batch: 3992. Acc: 0.547936. Loss: 1.247968. Batch_acc: 0.569186. Batch_loss: 1.185336 \n",
      "Batch: 3993. Acc: 0.547940. Loss: 1.247955. Batch_acc: 0.565931. Batch_loss: 1.199551 \n",
      "Batch: 3994. Acc: 0.547948. Loss: 1.247935. Batch_acc: 0.581967. Batch_loss: 1.166965 \n",
      "Batch: 3995. Acc: 0.547953. Loss: 1.247928. Batch_acc: 0.565015. Batch_loss: 1.219618 \n",
      "Batch: 3996. Acc: 0.547955. Loss: 1.247923. Batch_acc: 0.557593. Batch_loss: 1.228160 \n",
      "Batch: 3997. Acc: 0.547966. Loss: 1.247895. Batch_acc: 0.592425. Batch_loss: 1.134321 \n",
      "Batch: 3998. Acc: 0.547968. Loss: 1.247884. Batch_acc: 0.555749. Batch_loss: 1.206731 \n",
      "Batch: 3999. Acc: 0.547975. Loss: 1.247859. Batch_acc: 0.575257. Batch_loss: 1.148510 \n",
      "Batch: 4000. Acc: 0.547979. Loss: 1.247855. Batch_acc: 0.563762. Batch_loss: 1.230141 \n",
      "Batch: 4001. Acc: 0.547981. Loss: 1.247851. Batch_acc: 0.557020. Batch_loss: 1.231381 \n",
      "Batch: 4002. Acc: 0.547981. Loss: 1.247848. Batch_acc: 0.547181. Batch_loss: 1.236428 \n",
      "Batch: 4003. Acc: 0.547979. Loss: 1.247846. Batch_acc: 0.540993. Batch_loss: 1.242086 \n",
      "Batch: 4004. Acc: 0.547991. Loss: 1.247814. Batch_acc: 0.592045. Batch_loss: 1.121217 \n",
      "Batch: 4005. Acc: 0.547995. Loss: 1.247809. Batch_acc: 0.565294. Batch_loss: 1.224962 \n",
      "Batch: 4006. Acc: 0.547995. Loss: 1.247807. Batch_acc: 0.549859. Batch_loss: 1.241680 \n",
      "Batch: 4007. Acc: 0.547996. Loss: 1.247799. Batch_acc: 0.551564. Batch_loss: 1.215231 \n",
      "Batch: 4008. Acc: 0.547999. Loss: 1.247791. Batch_acc: 0.558594. Batch_loss: 1.214099 \n",
      "Batch: 4009. Acc: 0.548000. Loss: 1.247781. Batch_acc: 0.552222. Batch_loss: 1.207870 \n",
      "Batch: 4010. Acc: 0.548002. Loss: 1.247767. Batch_acc: 0.557552. Batch_loss: 1.196385 \n",
      "Batch: 4011. Acc: 0.548008. Loss: 1.247755. Batch_acc: 0.569186. Batch_loss: 1.196939 \n",
      "Batch: 4012. Acc: 0.548012. Loss: 1.247741. Batch_acc: 0.566761. Batch_loss: 1.192838 \n",
      "Batch: 4013. Acc: 0.548018. Loss: 1.247720. Batch_acc: 0.570370. Batch_loss: 1.164444 \n",
      "Batch: 4014. Acc: 0.548014. Loss: 1.247730. Batch_acc: 0.533019. Batch_loss: 1.287731 \n",
      "Batch: 4015. Acc: 0.548011. Loss: 1.247745. Batch_acc: 0.532506. Batch_loss: 1.309686 \n",
      "Batch: 4016. Acc: 0.548014. Loss: 1.247737. Batch_acc: 0.562018. Batch_loss: 1.214897 \n",
      "Checkpointing on batch: 4016. Accuracy: 0.54801401939424. Loss per char: 1.247736839689977. Time: 1627224885.7661085\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 84, 85, 66,\n",
      "        79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 18, 17, 24, 17, 25,  1,\n",
      "        66, 79, 69,  1, 23, 22, 26, 18, 15, 20, 18, 20, 32,  3,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4017. Acc: 0.548022. Loss: 1.247716. Batch_acc: 0.580254. Batch_loss: 1.165085 \n",
      "Batch: 4018. Acc: 0.548028. Loss: 1.247701. Batch_acc: 0.571592. Batch_loss: 1.186640 \n",
      "Batch: 4019. Acc: 0.548033. Loss: 1.247696. Batch_acc: 0.567190. Batch_loss: 1.225391 \n",
      "Batch: 4020. Acc: 0.548033. Loss: 1.247698. Batch_acc: 0.550867. Batch_loss: 1.256993 \n",
      "Batch: 4021. Acc: 0.548035. Loss: 1.247692. Batch_acc: 0.555229. Batch_loss: 1.223170 \n",
      "Batch: 4022. Acc: 0.548039. Loss: 1.247682. Batch_acc: 0.565267. Batch_loss: 1.207465 \n",
      "Batch: 4023. Acc: 0.548042. Loss: 1.247671. Batch_acc: 0.556772. Batch_loss: 1.205462 \n",
      "Batch: 4024. Acc: 0.548054. Loss: 1.247637. Batch_acc: 0.595864. Batch_loss: 1.111706 \n",
      "Batch: 4025. Acc: 0.548064. Loss: 1.247613. Batch_acc: 0.589072. Batch_loss: 1.154217 \n",
      "Batch: 4026. Acc: 0.548067. Loss: 1.247598. Batch_acc: 0.558806. Batch_loss: 1.186621 \n",
      "Batch: 4027. Acc: 0.548070. Loss: 1.247589. Batch_acc: 0.562607. Batch_loss: 1.210561 \n",
      "Batch: 4028. Acc: 0.548078. Loss: 1.247572. Batch_acc: 0.576988. Batch_loss: 1.180996 \n",
      "Batch: 4029. Acc: 0.548083. Loss: 1.247557. Batch_acc: 0.570451. Batch_loss: 1.185098 \n",
      "Batch: 4030. Acc: 0.548085. Loss: 1.247552. Batch_acc: 0.554217. Batch_loss: 1.230643 \n",
      "Batch: 4031. Acc: 0.548090. Loss: 1.247540. Batch_acc: 0.567708. Batch_loss: 1.198738 \n",
      "Batch: 4032. Acc: 0.548090. Loss: 1.247537. Batch_acc: 0.548975. Batch_loss: 1.235724 \n",
      "Batch: 4033. Acc: 0.548092. Loss: 1.247531. Batch_acc: 0.556075. Batch_loss: 1.220503 \n",
      "Batch: 4034. Acc: 0.548098. Loss: 1.247513. Batch_acc: 0.573587. Batch_loss: 1.179540 \n",
      "Batch: 4035. Acc: 0.548101. Loss: 1.247507. Batch_acc: 0.559420. Batch_loss: 1.221286 \n",
      "Batch: 4036. Acc: 0.548101. Loss: 1.247502. Batch_acc: 0.549796. Batch_loss: 1.225897 \n",
      "Batch: 4037. Acc: 0.548104. Loss: 1.247496. Batch_acc: 0.556754. Batch_loss: 1.224160 \n",
      "Batch: 4038. Acc: 0.548103. Loss: 1.247494. Batch_acc: 0.547320. Batch_loss: 1.241117 \n",
      "Batch: 4039. Acc: 0.548113. Loss: 1.247467. Batch_acc: 0.584607. Batch_loss: 1.139168 \n",
      "Batch: 4040. Acc: 0.548114. Loss: 1.247461. Batch_acc: 0.551664. Batch_loss: 1.224657 \n",
      "Batch: 4041. Acc: 0.548120. Loss: 1.247445. Batch_acc: 0.574201. Batch_loss: 1.180860 \n",
      "Batch: 4042. Acc: 0.548117. Loss: 1.247454. Batch_acc: 0.535406. Batch_loss: 1.285114 \n",
      "Batch: 4043. Acc: 0.548115. Loss: 1.247460. Batch_acc: 0.541546. Batch_loss: 1.272316 \n",
      "Batch: 4044. Acc: 0.548117. Loss: 1.247454. Batch_acc: 0.554305. Batch_loss: 1.223768 \n",
      "Batch: 4045. Acc: 0.548118. Loss: 1.247448. Batch_acc: 0.554279. Batch_loss: 1.220837 \n",
      "Batch: 4046. Acc: 0.548120. Loss: 1.247448. Batch_acc: 0.553043. Batch_loss: 1.249532 \n",
      "Batch: 4047. Acc: 0.548117. Loss: 1.247446. Batch_acc: 0.536528. Batch_loss: 1.238902 \n",
      "Batch: 4048. Acc: 0.548111. Loss: 1.247453. Batch_acc: 0.525671. Batch_loss: 1.276015 \n",
      "Batch: 4049. Acc: 0.548113. Loss: 1.247451. Batch_acc: 0.553376. Batch_loss: 1.240454 \n",
      "Batch: 4050. Acc: 0.548114. Loss: 1.247444. Batch_acc: 0.554210. Batch_loss: 1.218130 \n",
      "Batch: 4051. Acc: 0.548118. Loss: 1.247434. Batch_acc: 0.562073. Batch_loss: 1.208007 \n",
      "Batch: 4052. Acc: 0.548115. Loss: 1.247440. Batch_acc: 0.536697. Batch_loss: 1.269963 \n",
      "Batch: 4053. Acc: 0.548111. Loss: 1.247457. Batch_acc: 0.531178. Batch_loss: 1.315799 \n",
      "Batch: 4054. Acc: 0.548104. Loss: 1.247461. Batch_acc: 0.521458. Batch_loss: 1.265533 \n",
      "Batch: 4055. Acc: 0.548110. Loss: 1.247450. Batch_acc: 0.572645. Batch_loss: 1.201878 \n",
      "Batch: 4056. Acc: 0.548106. Loss: 1.247452. Batch_acc: 0.531014. Batch_loss: 1.258047 \n",
      "Batch: 4057. Acc: 0.548105. Loss: 1.247455. Batch_acc: 0.543711. Batch_loss: 1.259452 \n",
      "Batch: 4058. Acc: 0.548106. Loss: 1.247447. Batch_acc: 0.553974. Batch_loss: 1.213120 \n",
      "Batch: 4059. Acc: 0.548117. Loss: 1.247418. Batch_acc: 0.590778. Batch_loss: 1.131278 \n",
      "Batch: 4060. Acc: 0.548118. Loss: 1.247412. Batch_acc: 0.554070. Batch_loss: 1.221887 \n",
      "Batch: 4061. Acc: 0.548130. Loss: 1.247387. Batch_acc: 0.595009. Batch_loss: 1.146259 \n",
      "Batch: 4062. Acc: 0.548142. Loss: 1.247358. Batch_acc: 0.597246. Batch_loss: 1.130614 \n",
      "Batch: 4063. Acc: 0.548148. Loss: 1.247341. Batch_acc: 0.572941. Batch_loss: 1.174961 \n",
      "Batch: 4064. Acc: 0.548156. Loss: 1.247319. Batch_acc: 0.581192. Batch_loss: 1.157247 \n",
      "Batch: 4065. Acc: 0.548151. Loss: 1.247322. Batch_acc: 0.526438. Batch_loss: 1.261732 \n",
      "Batch: 4066. Acc: 0.548154. Loss: 1.247305. Batch_acc: 0.559420. Batch_loss: 1.175825 \n",
      "Batch: 4067. Acc: 0.548157. Loss: 1.247298. Batch_acc: 0.561675. Batch_loss: 1.219454 \n",
      "Batch: 4068. Acc: 0.548165. Loss: 1.247276. Batch_acc: 0.581225. Batch_loss: 1.159545 \n",
      "Batch: 4069. Acc: 0.548175. Loss: 1.247249. Batch_acc: 0.588102. Batch_loss: 1.139480 \n",
      "Batch: 4070. Acc: 0.548183. Loss: 1.247225. Batch_acc: 0.581104. Batch_loss: 1.151412 \n",
      "Batch: 4071. Acc: 0.548178. Loss: 1.247238. Batch_acc: 0.525176. Batch_loss: 1.301013 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4072. Acc: 0.548181. Loss: 1.247232. Batch_acc: 0.561473. Batch_loss: 1.220697 \n",
      "Batch: 4073. Acc: 0.548189. Loss: 1.247215. Batch_acc: 0.579036. Batch_loss: 1.182076 \n",
      "Batch: 4074. Acc: 0.548189. Loss: 1.247210. Batch_acc: 0.549854. Batch_loss: 1.224894 \n",
      "Batch: 4075. Acc: 0.548195. Loss: 1.247192. Batch_acc: 0.572743. Batch_loss: 1.173329 \n",
      "Batch: 4076. Acc: 0.548193. Loss: 1.247198. Batch_acc: 0.538106. Batch_loss: 1.273656 \n",
      "Batch: 4077. Acc: 0.548197. Loss: 1.247186. Batch_acc: 0.563970. Batch_loss: 1.199036 \n",
      "Batch: 4078. Acc: 0.548194. Loss: 1.247201. Batch_acc: 0.538065. Batch_loss: 1.308206 \n",
      "Batch: 4079. Acc: 0.548197. Loss: 1.247195. Batch_acc: 0.558101. Batch_loss: 1.220377 \n",
      "Batch: 4080. Acc: 0.548192. Loss: 1.247207. Batch_acc: 0.529717. Batch_loss: 1.296313 \n",
      "Batch: 4081. Acc: 0.548194. Loss: 1.247202. Batch_acc: 0.556330. Batch_loss: 1.229837 \n",
      "Batch: 4082. Acc: 0.548198. Loss: 1.247193. Batch_acc: 0.562925. Batch_loss: 1.209723 \n",
      "Batch: 4083. Acc: 0.548205. Loss: 1.247170. Batch_acc: 0.577169. Batch_loss: 1.151415 \n",
      "Batch: 4084. Acc: 0.548211. Loss: 1.247158. Batch_acc: 0.572342. Batch_loss: 1.196305 \n",
      "Batch: 4085. Acc: 0.548216. Loss: 1.247147. Batch_acc: 0.568594. Batch_loss: 1.205536 \n",
      "Batch: 4086. Acc: 0.548221. Loss: 1.247132. Batch_acc: 0.570290. Batch_loss: 1.186351 \n",
      "Batch: 4087. Acc: 0.548228. Loss: 1.247123. Batch_acc: 0.574915. Batch_loss: 1.208510 \n",
      "Batch: 4088. Acc: 0.548230. Loss: 1.247109. Batch_acc: 0.558495. Batch_loss: 1.188609 \n",
      "Batch: 4089. Acc: 0.548231. Loss: 1.247104. Batch_acc: 0.549771. Batch_loss: 1.227721 \n",
      "Batch: 4090. Acc: 0.548230. Loss: 1.247101. Batch_acc: 0.546433. Batch_loss: 1.234055 \n",
      "Batch: 4091. Acc: 0.548233. Loss: 1.247091. Batch_acc: 0.558167. Batch_loss: 1.206725 \n",
      "Batch: 4092. Acc: 0.548234. Loss: 1.247092. Batch_acc: 0.553676. Batch_loss: 1.250866 \n",
      "Batch: 4093. Acc: 0.548243. Loss: 1.247066. Batch_acc: 0.587755. Batch_loss: 1.138921 \n",
      "Batch: 4094. Acc: 0.548245. Loss: 1.247061. Batch_acc: 0.552879. Batch_loss: 1.227236 \n",
      "Batch: 4095. Acc: 0.548245. Loss: 1.247059. Batch_acc: 0.551867. Batch_loss: 1.238055 \n",
      "Batch: 4096. Acc: 0.548250. Loss: 1.247045. Batch_acc: 0.565521. Batch_loss: 1.188771 \n",
      "Batch: 4097. Acc: 0.548253. Loss: 1.247027. Batch_acc: 0.562679. Batch_loss: 1.173208 \n",
      "Batch: 4098. Acc: 0.548260. Loss: 1.247010. Batch_acc: 0.574854. Batch_loss: 1.177970 \n",
      "Batch: 4099. Acc: 0.548261. Loss: 1.247001. Batch_acc: 0.554133. Batch_loss: 1.207495 \n",
      "Batch: 4100. Acc: 0.548258. Loss: 1.247011. Batch_acc: 0.534750. Batch_loss: 1.289553 \n",
      "Batch: 4101. Acc: 0.548260. Loss: 1.247007. Batch_acc: 0.558219. Batch_loss: 1.230679 \n",
      "Batch: 4102. Acc: 0.548261. Loss: 1.247009. Batch_acc: 0.550600. Batch_loss: 1.256276 \n",
      "Batch: 4103. Acc: 0.548261. Loss: 1.247004. Batch_acc: 0.550320. Batch_loss: 1.224390 \n",
      "Batch: 4104. Acc: 0.548265. Loss: 1.246998. Batch_acc: 0.563265. Batch_loss: 1.221263 \n",
      "Batch: 4105. Acc: 0.548271. Loss: 1.246982. Batch_acc: 0.573090. Batch_loss: 1.182945 \n",
      "Batch: 4106. Acc: 0.548271. Loss: 1.246978. Batch_acc: 0.549826. Batch_loss: 1.233061 \n",
      "Batch: 4107. Acc: 0.548275. Loss: 1.246967. Batch_acc: 0.563073. Batch_loss: 1.202008 \n",
      "Batch: 4108. Acc: 0.548281. Loss: 1.246952. Batch_acc: 0.570634. Batch_loss: 1.185304 \n",
      "Batch: 4109. Acc: 0.548284. Loss: 1.246945. Batch_acc: 0.560502. Batch_loss: 1.220969 \n",
      "Batch: 4110. Acc: 0.548284. Loss: 1.246947. Batch_acc: 0.550808. Batch_loss: 1.256043 \n",
      "Batch: 4111. Acc: 0.548290. Loss: 1.246924. Batch_acc: 0.569905. Batch_loss: 1.153196 \n",
      "Batch: 4112. Acc: 0.548291. Loss: 1.246918. Batch_acc: 0.552018. Batch_loss: 1.222270 \n",
      "Batch: 4113. Acc: 0.548292. Loss: 1.246909. Batch_acc: 0.552799. Batch_loss: 1.208572 \n",
      "Batch: 4114. Acc: 0.548299. Loss: 1.246890. Batch_acc: 0.579067. Batch_loss: 1.168719 \n",
      "Batch: 4115. Acc: 0.548299. Loss: 1.246883. Batch_acc: 0.549419. Batch_loss: 1.220975 \n",
      "Batch: 4116. Acc: 0.548298. Loss: 1.246882. Batch_acc: 0.541040. Batch_loss: 1.240387 \n",
      "Batch: 4117. Acc: 0.548302. Loss: 1.246872. Batch_acc: 0.565217. Batch_loss: 1.207151 \n",
      "Batch: 4118. Acc: 0.548302. Loss: 1.246865. Batch_acc: 0.548424. Batch_loss: 1.216184 \n",
      "Batch: 4119. Acc: 0.548302. Loss: 1.246863. Batch_acc: 0.548332. Batch_loss: 1.240264 \n",
      "Batch: 4120. Acc: 0.548305. Loss: 1.246856. Batch_acc: 0.559177. Batch_loss: 1.218809 \n",
      "Batch: 4121. Acc: 0.548306. Loss: 1.246850. Batch_acc: 0.553969. Batch_loss: 1.221549 \n",
      "Batch: 4122. Acc: 0.548314. Loss: 1.246829. Batch_acc: 0.581435. Batch_loss: 1.159227 \n",
      "Batch: 4123. Acc: 0.548317. Loss: 1.246822. Batch_acc: 0.561629. Batch_loss: 1.222243 \n",
      "Batch: 4124. Acc: 0.548322. Loss: 1.246814. Batch_acc: 0.567396. Batch_loss: 1.211493 \n",
      "Batch: 4125. Acc: 0.548324. Loss: 1.246799. Batch_acc: 0.556306. Batch_loss: 1.187980 \n",
      "Batch: 4126. Acc: 0.548325. Loss: 1.246791. Batch_acc: 0.554217. Batch_loss: 1.213665 \n",
      "Batch: 4127. Acc: 0.548328. Loss: 1.246778. Batch_acc: 0.558723. Batch_loss: 1.194427 \n",
      "Batch: 4128. Acc: 0.548327. Loss: 1.246779. Batch_acc: 0.543210. Batch_loss: 1.251018 \n",
      "Batch: 4129. Acc: 0.548329. Loss: 1.246777. Batch_acc: 0.558373. Batch_loss: 1.236892 \n",
      "Batch: 4130. Acc: 0.548328. Loss: 1.246773. Batch_acc: 0.542343. Batch_loss: 1.229706 \n",
      "Batch: 4131. Acc: 0.548336. Loss: 1.246755. Batch_acc: 0.580990. Batch_loss: 1.173319 \n",
      "Batch: 4132. Acc: 0.548332. Loss: 1.246760. Batch_acc: 0.531103. Batch_loss: 1.269550 \n",
      "Batch: 4133. Acc: 0.548331. Loss: 1.246753. Batch_acc: 0.544326. Batch_loss: 1.214971 \n",
      "Batch: 4134. Acc: 0.548329. Loss: 1.246749. Batch_acc: 0.540191. Batch_loss: 1.231171 \n",
      "Batch: 4135. Acc: 0.548333. Loss: 1.246742. Batch_acc: 0.564205. Batch_loss: 1.219799 \n",
      "Batch: 4136. Acc: 0.548334. Loss: 1.246740. Batch_acc: 0.553792. Batch_loss: 1.239130 \n",
      "Batch: 4137. Acc: 0.548333. Loss: 1.246741. Batch_acc: 0.544633. Batch_loss: 1.247014 \n",
      "Batch: 4138. Acc: 0.548338. Loss: 1.246723. Batch_acc: 0.568458. Batch_loss: 1.175731 \n",
      "Batch: 4139. Acc: 0.548339. Loss: 1.246727. Batch_acc: 0.552955. Batch_loss: 1.261007 \n",
      "Batch: 4140. Acc: 0.548344. Loss: 1.246713. Batch_acc: 0.570928. Batch_loss: 1.187992 \n",
      "Batch: 4141. Acc: 0.548346. Loss: 1.246711. Batch_acc: 0.554196. Batch_loss: 1.240394 \n",
      "Batch: 4142. Acc: 0.548345. Loss: 1.246705. Batch_acc: 0.547181. Batch_loss: 1.221744 \n",
      "Batch: 4143. Acc: 0.548344. Loss: 1.246707. Batch_acc: 0.542939. Batch_loss: 1.251630 \n",
      "Batch: 4144. Acc: 0.548351. Loss: 1.246688. Batch_acc: 0.575601. Batch_loss: 1.171303 \n",
      "Batch: 4145. Acc: 0.548356. Loss: 1.246675. Batch_acc: 0.570083. Batch_loss: 1.194612 \n",
      "Batch: 4146. Acc: 0.548353. Loss: 1.246685. Batch_acc: 0.536920. Batch_loss: 1.288039 \n",
      "Batch: 4147. Acc: 0.548357. Loss: 1.246674. Batch_acc: 0.564161. Batch_loss: 1.202471 \n",
      "Batch: 4148. Acc: 0.548355. Loss: 1.246681. Batch_acc: 0.540176. Batch_loss: 1.275524 \n",
      "Batch: 4149. Acc: 0.548361. Loss: 1.246673. Batch_acc: 0.573001. Batch_loss: 1.213780 \n",
      "Batch: 4150. Acc: 0.548364. Loss: 1.246661. Batch_acc: 0.561998. Batch_loss: 1.197454 \n",
      "Batch: 4151. Acc: 0.548366. Loss: 1.246654. Batch_acc: 0.556642. Batch_loss: 1.215255 \n",
      "Batch: 4152. Acc: 0.548373. Loss: 1.246641. Batch_acc: 0.576018. Batch_loss: 1.193861 \n",
      "Batch: 4153. Acc: 0.548380. Loss: 1.246625. Batch_acc: 0.575740. Batch_loss: 1.179645 \n",
      "Batch: 4154. Acc: 0.548378. Loss: 1.246627. Batch_acc: 0.541741. Batch_loss: 1.256562 \n",
      "Batch: 4155. Acc: 0.548379. Loss: 1.246626. Batch_acc: 0.551959. Batch_loss: 1.239951 \n",
      "Batch: 4156. Acc: 0.548381. Loss: 1.246614. Batch_acc: 0.557512. Batch_loss: 1.198201 \n",
      "Batch: 4157. Acc: 0.548385. Loss: 1.246598. Batch_acc: 0.565169. Batch_loss: 1.182998 \n",
      "Batch: 4158. Acc: 0.548390. Loss: 1.246586. Batch_acc: 0.567894. Batch_loss: 1.195532 \n",
      "Batch: 4159. Acc: 0.548389. Loss: 1.246591. Batch_acc: 0.544266. Batch_loss: 1.266330 \n",
      "Batch: 4160. Acc: 0.548390. Loss: 1.246579. Batch_acc: 0.552909. Batch_loss: 1.200317 \n",
      "Batch: 4161. Acc: 0.548390. Loss: 1.246581. Batch_acc: 0.546644. Batch_loss: 1.255384 \n",
      "Batch: 4162. Acc: 0.548386. Loss: 1.246586. Batch_acc: 0.531473. Batch_loss: 1.265095 \n",
      "Batch: 4163. Acc: 0.548384. Loss: 1.246591. Batch_acc: 0.539543. Batch_loss: 1.268116 \n",
      "Batch: 4164. Acc: 0.548387. Loss: 1.246579. Batch_acc: 0.560414. Batch_loss: 1.198516 \n",
      "Batch: 4165. Acc: 0.548387. Loss: 1.246572. Batch_acc: 0.549943. Batch_loss: 1.215605 \n",
      "Batch: 4166. Acc: 0.548385. Loss: 1.246578. Batch_acc: 0.538150. Batch_loss: 1.275591 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4167. Acc: 0.548387. Loss: 1.246574. Batch_acc: 0.559361. Batch_loss: 1.227435 \n",
      "Batch: 4168. Acc: 0.548388. Loss: 1.246566. Batch_acc: 0.550716. Batch_loss: 1.212876 \n",
      "Batch: 4169. Acc: 0.548389. Loss: 1.246560. Batch_acc: 0.551231. Batch_loss: 1.223415 \n",
      "Batch: 4170. Acc: 0.548391. Loss: 1.246560. Batch_acc: 0.558707. Batch_loss: 1.248080 \n",
      "Batch: 4171. Acc: 0.548392. Loss: 1.246565. Batch_acc: 0.550775. Batch_loss: 1.264560 \n",
      "Batch: 4172. Acc: 0.548397. Loss: 1.246556. Batch_acc: 0.571598. Batch_loss: 1.210206 \n",
      "Batch: 4173. Acc: 0.548395. Loss: 1.246560. Batch_acc: 0.540493. Batch_loss: 1.262415 \n",
      "Batch: 4174. Acc: 0.548400. Loss: 1.246542. Batch_acc: 0.566402. Batch_loss: 1.170799 \n",
      "Batch: 4175. Acc: 0.548404. Loss: 1.246531. Batch_acc: 0.565291. Batch_loss: 1.204506 \n",
      "Batch: 4176. Acc: 0.548411. Loss: 1.246518. Batch_acc: 0.579686. Batch_loss: 1.191375 \n",
      "Batch: 4177. Acc: 0.548408. Loss: 1.246520. Batch_acc: 0.535354. Batch_loss: 1.254695 \n",
      "Batch: 4178. Acc: 0.548416. Loss: 1.246494. Batch_acc: 0.581609. Batch_loss: 1.139467 \n",
      "Batch: 4179. Acc: 0.548418. Loss: 1.246491. Batch_acc: 0.554329. Batch_loss: 1.232485 \n",
      "Batch: 4180. Acc: 0.548419. Loss: 1.246493. Batch_acc: 0.555116. Batch_loss: 1.255617 \n",
      "Batch: 4181. Acc: 0.548425. Loss: 1.246481. Batch_acc: 0.571671. Batch_loss: 1.195740 \n",
      "Batch: 4182. Acc: 0.548428. Loss: 1.246475. Batch_acc: 0.561159. Batch_loss: 1.221982 \n",
      "Batch: 4183. Acc: 0.548436. Loss: 1.246452. Batch_acc: 0.582564. Batch_loss: 1.150771 \n",
      "Batch: 4184. Acc: 0.548441. Loss: 1.246442. Batch_acc: 0.567644. Batch_loss: 1.203134 \n",
      "Batch: 4185. Acc: 0.548440. Loss: 1.246443. Batch_acc: 0.543605. Batch_loss: 1.253732 \n",
      "Batch: 4186. Acc: 0.548444. Loss: 1.246428. Batch_acc: 0.566647. Batch_loss: 1.182823 \n",
      "Batch: 4187. Acc: 0.548454. Loss: 1.246408. Batch_acc: 0.588812. Batch_loss: 1.160858 \n",
      "Batch: 4188. Acc: 0.548455. Loss: 1.246405. Batch_acc: 0.556196. Batch_loss: 1.234411 \n",
      "Batch: 4189. Acc: 0.548457. Loss: 1.246397. Batch_acc: 0.553676. Batch_loss: 1.211837 \n",
      "Batch: 4190. Acc: 0.548461. Loss: 1.246387. Batch_acc: 0.565268. Batch_loss: 1.206407 \n",
      "Batch: 4191. Acc: 0.548462. Loss: 1.246378. Batch_acc: 0.555809. Batch_loss: 1.209079 \n",
      "Batch: 4192. Acc: 0.548465. Loss: 1.246375. Batch_acc: 0.558633. Batch_loss: 1.233807 \n",
      "Batch: 4193. Acc: 0.548464. Loss: 1.246377. Batch_acc: 0.546291. Batch_loss: 1.251614 \n",
      "Batch: 4194. Acc: 0.548470. Loss: 1.246363. Batch_acc: 0.570362. Batch_loss: 1.189725 \n",
      "Batch: 4195. Acc: 0.548463. Loss: 1.246377. Batch_acc: 0.521233. Batch_loss: 1.304437 \n",
      "Batch: 4196. Acc: 0.548463. Loss: 1.246373. Batch_acc: 0.550143. Batch_loss: 1.230856 \n",
      "Batch: 4197. Acc: 0.548466. Loss: 1.246359. Batch_acc: 0.558324. Batch_loss: 1.187427 \n",
      "Batch: 4198. Acc: 0.548473. Loss: 1.246344. Batch_acc: 0.578369. Batch_loss: 1.181710 \n",
      "Batch: 4199. Acc: 0.548473. Loss: 1.246338. Batch_acc: 0.550691. Batch_loss: 1.223260 \n",
      "Batch: 4200. Acc: 0.548480. Loss: 1.246319. Batch_acc: 0.575741. Batch_loss: 1.168034 \n",
      "Batch: 4201. Acc: 0.548492. Loss: 1.246295. Batch_acc: 0.596045. Batch_loss: 1.145834 \n",
      "Batch: 4202. Acc: 0.548494. Loss: 1.246286. Batch_acc: 0.556314. Batch_loss: 1.209948 \n",
      "Batch: 4203. Acc: 0.548499. Loss: 1.246276. Batch_acc: 0.573086. Batch_loss: 1.205799 \n",
      "Batch: 4204. Acc: 0.548504. Loss: 1.246261. Batch_acc: 0.566553. Batch_loss: 1.183706 \n",
      "Batch: 4205. Acc: 0.548508. Loss: 1.246249. Batch_acc: 0.567112. Batch_loss: 1.195523 \n",
      "Batch: 4206. Acc: 0.548515. Loss: 1.246233. Batch_acc: 0.576377. Batch_loss: 1.179886 \n",
      "Batch: 4207. Acc: 0.548519. Loss: 1.246222. Batch_acc: 0.565510. Batch_loss: 1.199587 \n",
      "Batch: 4208. Acc: 0.548525. Loss: 1.246206. Batch_acc: 0.573184. Batch_loss: 1.182909 \n",
      "Batch: 4209. Acc: 0.548524. Loss: 1.246206. Batch_acc: 0.545612. Batch_loss: 1.246036 \n",
      "Batch: 4210. Acc: 0.548529. Loss: 1.246191. Batch_acc: 0.570029. Batch_loss: 1.179867 \n",
      "Batch: 4211. Acc: 0.548527. Loss: 1.246200. Batch_acc: 0.540383. Batch_loss: 1.287768 \n",
      "Batch: 4212. Acc: 0.548522. Loss: 1.246209. Batch_acc: 0.524055. Batch_loss: 1.283916 \n",
      "Batch: 4213. Acc: 0.548520. Loss: 1.246215. Batch_acc: 0.539977. Batch_loss: 1.268710 \n",
      "Batch: 4214. Acc: 0.548523. Loss: 1.246211. Batch_acc: 0.562392. Batch_loss: 1.228956 \n",
      "Batch: 4215. Acc: 0.548531. Loss: 1.246196. Batch_acc: 0.582320. Batch_loss: 1.187733 \n",
      "Batch: 4216. Acc: 0.548531. Loss: 1.246190. Batch_acc: 0.546492. Batch_loss: 1.221533 \n",
      "Batch: 4217. Acc: 0.548542. Loss: 1.246159. Batch_acc: 0.592945. Batch_loss: 1.115950 \n",
      "Batch: 4218. Acc: 0.548545. Loss: 1.246144. Batch_acc: 0.562857. Batch_loss: 1.186025 \n",
      "Batch: 4219. Acc: 0.548551. Loss: 1.246125. Batch_acc: 0.572009. Batch_loss: 1.165224 \n",
      "Batch: 4220. Acc: 0.548554. Loss: 1.246120. Batch_acc: 0.564269. Batch_loss: 1.223752 \n",
      "Batch: 4221. Acc: 0.548563. Loss: 1.246096. Batch_acc: 0.587376. Batch_loss: 1.143350 \n",
      "Batch: 4222. Acc: 0.548564. Loss: 1.246093. Batch_acc: 0.553695. Batch_loss: 1.234974 \n",
      "Batch: 4223. Acc: 0.548569. Loss: 1.246084. Batch_acc: 0.566893. Batch_loss: 1.208753 \n",
      "Batch: 4224. Acc: 0.548572. Loss: 1.246074. Batch_acc: 0.561772. Batch_loss: 1.199874 \n",
      "Batch: 4225. Acc: 0.548572. Loss: 1.246076. Batch_acc: 0.551008. Batch_loss: 1.254671 \n",
      "Batch: 4226. Acc: 0.548576. Loss: 1.246072. Batch_acc: 0.563348. Batch_loss: 1.230129 \n",
      "Batch: 4227. Acc: 0.548571. Loss: 1.246082. Batch_acc: 0.525982. Batch_loss: 1.288259 \n",
      "Batch: 4228. Acc: 0.548576. Loss: 1.246063. Batch_acc: 0.569115. Batch_loss: 1.166889 \n",
      "Batch: 4229. Acc: 0.548578. Loss: 1.246051. Batch_acc: 0.558841. Batch_loss: 1.193460 \n",
      "Batch: 4230. Acc: 0.548577. Loss: 1.246047. Batch_acc: 0.546041. Batch_loss: 1.231536 \n",
      "Batch: 4231. Acc: 0.548581. Loss: 1.246030. Batch_acc: 0.564414. Batch_loss: 1.171405 \n",
      "Batch: 4232. Acc: 0.548583. Loss: 1.246026. Batch_acc: 0.558140. Batch_loss: 1.228437 \n",
      "Batch: 4233. Acc: 0.548591. Loss: 1.246009. Batch_acc: 0.580996. Batch_loss: 1.176692 \n",
      "Batch: 4234. Acc: 0.548591. Loss: 1.246004. Batch_acc: 0.549451. Batch_loss: 1.223776 \n",
      "Batch: 4235. Acc: 0.548589. Loss: 1.246003. Batch_acc: 0.539053. Batch_loss: 1.243486 \n",
      "Batch: 4236. Acc: 0.548592. Loss: 1.245999. Batch_acc: 0.560748. Batch_loss: 1.225704 \n",
      "Batch: 4237. Acc: 0.548595. Loss: 1.245991. Batch_acc: 0.561659. Batch_loss: 1.213327 \n",
      "Batch: 4238. Acc: 0.548600. Loss: 1.245976. Batch_acc: 0.570598. Batch_loss: 1.183397 \n",
      "Batch: 4239. Acc: 0.548603. Loss: 1.245974. Batch_acc: 0.562950. Batch_loss: 1.234644 \n",
      "Batch: 4240. Acc: 0.548613. Loss: 1.245952. Batch_acc: 0.587130. Batch_loss: 1.153951 \n",
      "Batch: 4241. Acc: 0.548611. Loss: 1.245959. Batch_acc: 0.541120. Batch_loss: 1.278922 \n",
      "Batch: 4242. Acc: 0.548616. Loss: 1.245941. Batch_acc: 0.569620. Batch_loss: 1.169122 \n",
      "Batch: 4243. Acc: 0.548621. Loss: 1.245925. Batch_acc: 0.571511. Batch_loss: 1.175415 \n",
      "Batch: 4244. Acc: 0.548622. Loss: 1.245922. Batch_acc: 0.551903. Batch_loss: 1.234928 \n",
      "Batch: 4245. Acc: 0.548628. Loss: 1.245910. Batch_acc: 0.574640. Batch_loss: 1.196548 \n",
      "Batch: 4246. Acc: 0.548634. Loss: 1.245900. Batch_acc: 0.574235. Batch_loss: 1.203467 \n",
      "Batch: 4247. Acc: 0.548637. Loss: 1.245902. Batch_acc: 0.561454. Batch_loss: 1.252578 \n",
      "Batch: 4248. Acc: 0.548641. Loss: 1.245895. Batch_acc: 0.563854. Batch_loss: 1.215634 \n",
      "Batch: 4249. Acc: 0.548641. Loss: 1.245894. Batch_acc: 0.550454. Batch_loss: 1.242711 \n",
      "Batch: 4250. Acc: 0.548648. Loss: 1.245877. Batch_acc: 0.579067. Batch_loss: 1.173945 \n",
      "Batch: 4251. Acc: 0.548646. Loss: 1.245880. Batch_acc: 0.536390. Batch_loss: 1.258231 \n",
      "Batch: 4252. Acc: 0.548646. Loss: 1.245882. Batch_acc: 0.550000. Batch_loss: 1.254441 \n",
      "Batch: 4253. Acc: 0.548645. Loss: 1.245889. Batch_acc: 0.547093. Batch_loss: 1.275320 \n",
      "Batch: 4254. Acc: 0.548639. Loss: 1.245904. Batch_acc: 0.522241. Batch_loss: 1.312404 \n",
      "Batch: 4255. Acc: 0.548639. Loss: 1.245910. Batch_acc: 0.548615. Batch_loss: 1.269312 \n",
      "Batch: 4256. Acc: 0.548638. Loss: 1.245920. Batch_acc: 0.544118. Batch_loss: 1.291284 \n",
      "Batch: 4257. Acc: 0.548634. Loss: 1.245928. Batch_acc: 0.530400. Batch_loss: 1.278199 \n",
      "Batch: 4258. Acc: 0.548637. Loss: 1.245920. Batch_acc: 0.561993. Batch_loss: 1.212961 \n",
      "Batch: 4259. Acc: 0.548633. Loss: 1.245925. Batch_acc: 0.532945. Batch_loss: 1.266595 \n",
      "Batch: 4260. Acc: 0.548640. Loss: 1.245908. Batch_acc: 0.575878. Batch_loss: 1.176620 \n",
      "Batch: 4261. Acc: 0.548646. Loss: 1.245898. Batch_acc: 0.573205. Batch_loss: 1.202587 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4262. Acc: 0.548650. Loss: 1.245889. Batch_acc: 0.564249. Batch_loss: 1.209194 \n",
      "Batch: 4263. Acc: 0.548652. Loss: 1.245880. Batch_acc: 0.561189. Batch_loss: 1.207978 \n",
      "Batch: 4264. Acc: 0.548651. Loss: 1.245881. Batch_acc: 0.542294. Batch_loss: 1.249247 \n",
      "Batch: 4265. Acc: 0.548656. Loss: 1.245867. Batch_acc: 0.568897. Batch_loss: 1.187573 \n",
      "Batch: 4266. Acc: 0.548665. Loss: 1.245845. Batch_acc: 0.586599. Batch_loss: 1.152956 \n",
      "Batch: 4267. Acc: 0.548667. Loss: 1.245834. Batch_acc: 0.559571. Batch_loss: 1.198157 \n",
      "Checkpointing on batch: 4267. Accuracy: 0.5486673336658895. Loss per char: 1.2458339142893586. Time: 1627225066.1704044\n",
      "Last question is tensor([ 2, 36, 66, 77, 68, 86, 77, 66, 85, 70,  1, 14, 17, 15, 18, 17, 25, 18,\n",
      "        23, 22, 22,  1, 12,  1, 14, 18, 24, 26, 23, 15, 23, 23, 21, 23, 15,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4268. Acc: 0.548670. Loss: 1.245823. Batch_acc: 0.558036. Batch_loss: 1.200714 \n",
      "Batch: 4269. Acc: 0.548674. Loss: 1.245809. Batch_acc: 0.566761. Batch_loss: 1.188670 \n",
      "Batch: 4270. Acc: 0.548685. Loss: 1.245782. Batch_acc: 0.596273. Batch_loss: 1.131552 \n",
      "Batch: 4271. Acc: 0.548688. Loss: 1.245775. Batch_acc: 0.558621. Batch_loss: 1.213411 \n",
      "Batch: 4272. Acc: 0.548689. Loss: 1.245770. Batch_acc: 0.555747. Batch_loss: 1.227619 \n",
      "Batch: 4273. Acc: 0.548688. Loss: 1.245771. Batch_acc: 0.542002. Batch_loss: 1.249295 \n",
      "Batch: 4274. Acc: 0.548696. Loss: 1.245756. Batch_acc: 0.584454. Batch_loss: 1.180867 \n",
      "Batch: 4275. Acc: 0.548697. Loss: 1.245751. Batch_acc: 0.555491. Batch_loss: 1.222331 \n",
      "Batch: 4276. Acc: 0.548705. Loss: 1.245735. Batch_acc: 0.579162. Batch_loss: 1.177860 \n",
      "Batch: 4277. Acc: 0.548710. Loss: 1.245729. Batch_acc: 0.570768. Batch_loss: 1.219592 \n",
      "Batch: 4278. Acc: 0.548710. Loss: 1.245726. Batch_acc: 0.551311. Batch_loss: 1.233747 \n",
      "Batch: 4279. Acc: 0.548713. Loss: 1.245717. Batch_acc: 0.560117. Batch_loss: 1.205724 \n",
      "Batch: 4280. Acc: 0.548711. Loss: 1.245721. Batch_acc: 0.538416. Batch_loss: 1.262623 \n",
      "Batch: 4281. Acc: 0.548711. Loss: 1.245714. Batch_acc: 0.549650. Batch_loss: 1.215878 \n",
      "Batch: 4282. Acc: 0.548716. Loss: 1.245708. Batch_acc: 0.569781. Batch_loss: 1.218041 \n",
      "Batch: 4283. Acc: 0.548718. Loss: 1.245700. Batch_acc: 0.557028. Batch_loss: 1.214443 \n",
      "Batch: 4284. Acc: 0.548723. Loss: 1.245686. Batch_acc: 0.573616. Batch_loss: 1.182161 \n",
      "Batch: 4285. Acc: 0.548724. Loss: 1.245679. Batch_acc: 0.551091. Batch_loss: 1.216167 \n",
      "Batch: 4286. Acc: 0.548729. Loss: 1.245659. Batch_acc: 0.569592. Batch_loss: 1.162597 \n",
      "Batch: 4287. Acc: 0.548738. Loss: 1.245628. Batch_acc: 0.589744. Batch_loss: 1.115318 \n",
      "Batch: 4288. Acc: 0.548738. Loss: 1.245631. Batch_acc: 0.547522. Batch_loss: 1.257192 \n",
      "Batch: 4289. Acc: 0.548738. Loss: 1.245625. Batch_acc: 0.546269. Batch_loss: 1.219312 \n",
      "Batch: 4290. Acc: 0.548740. Loss: 1.245619. Batch_acc: 0.558891. Batch_loss: 1.218136 \n",
      "Batch: 4291. Acc: 0.548740. Loss: 1.245614. Batch_acc: 0.549271. Batch_loss: 1.226951 \n",
      "Batch: 4292. Acc: 0.548738. Loss: 1.245616. Batch_acc: 0.538946. Batch_loss: 1.251022 \n",
      "Batch: 4293. Acc: 0.548738. Loss: 1.245609. Batch_acc: 0.550427. Batch_loss: 1.218904 \n",
      "Batch: 4294. Acc: 0.548739. Loss: 1.245609. Batch_acc: 0.551402. Batch_loss: 1.245638 \n",
      "Batch: 4295. Acc: 0.548737. Loss: 1.245613. Batch_acc: 0.539049. Batch_loss: 1.261805 \n",
      "Batch: 4296. Acc: 0.548735. Loss: 1.245616. Batch_acc: 0.543339. Batch_loss: 1.259050 \n",
      "Batch: 4297. Acc: 0.548737. Loss: 1.245608. Batch_acc: 0.554108. Batch_loss: 1.212943 \n",
      "Batch: 4298. Acc: 0.548739. Loss: 1.245602. Batch_acc: 0.560320. Batch_loss: 1.218169 \n",
      "Batch: 4299. Acc: 0.548738. Loss: 1.245605. Batch_acc: 0.540993. Batch_loss: 1.259647 \n",
      "Batch: 4300. Acc: 0.548741. Loss: 1.245593. Batch_acc: 0.565043. Batch_loss: 1.193803 \n",
      "Batch: 4301. Acc: 0.548746. Loss: 1.245580. Batch_acc: 0.569389. Batch_loss: 1.191207 \n",
      "Batch: 4302. Acc: 0.548751. Loss: 1.245561. Batch_acc: 0.568616. Batch_loss: 1.164873 \n",
      "Batch: 4303. Acc: 0.548757. Loss: 1.245544. Batch_acc: 0.574074. Batch_loss: 1.170541 \n",
      "Batch: 4304. Acc: 0.548764. Loss: 1.245522. Batch_acc: 0.579932. Batch_loss: 1.151654 \n",
      "Batch: 4305. Acc: 0.548763. Loss: 1.245519. Batch_acc: 0.545559. Batch_loss: 1.235379 \n",
      "Batch: 4306. Acc: 0.548768. Loss: 1.245509. Batch_acc: 0.567845. Batch_loss: 1.200191 \n",
      "Batch: 4307. Acc: 0.548767. Loss: 1.245512. Batch_acc: 0.544986. Batch_loss: 1.258761 \n",
      "Batch: 4308. Acc: 0.548767. Loss: 1.245515. Batch_acc: 0.549799. Batch_loss: 1.258175 \n",
      "Batch: 4309. Acc: 0.548772. Loss: 1.245511. Batch_acc: 0.570698. Batch_loss: 1.228015 \n",
      "Batch: 4310. Acc: 0.548771. Loss: 1.245511. Batch_acc: 0.540927. Batch_loss: 1.245349 \n",
      "Batch: 4311. Acc: 0.548766. Loss: 1.245520. Batch_acc: 0.531178. Batch_loss: 1.287503 \n",
      "Batch: 4312. Acc: 0.548774. Loss: 1.245499. Batch_acc: 0.579818. Batch_loss: 1.156388 \n",
      "Batch: 4313. Acc: 0.548770. Loss: 1.245508. Batch_acc: 0.530778. Batch_loss: 1.280886 \n",
      "Batch: 4314. Acc: 0.548774. Loss: 1.245495. Batch_acc: 0.567063. Batch_loss: 1.192547 \n",
      "Batch: 4315. Acc: 0.548782. Loss: 1.245476. Batch_acc: 0.581158. Batch_loss: 1.162395 \n",
      "Batch: 4316. Acc: 0.548780. Loss: 1.245479. Batch_acc: 0.542480. Batch_loss: 1.259972 \n",
      "Batch: 4317. Acc: 0.548780. Loss: 1.245485. Batch_acc: 0.548780. Batch_loss: 1.271047 \n",
      "Batch: 4318. Acc: 0.548784. Loss: 1.245481. Batch_acc: 0.566929. Batch_loss: 1.227377 \n",
      "Batch: 4319. Acc: 0.548779. Loss: 1.245491. Batch_acc: 0.526863. Batch_loss: 1.290864 \n",
      "Batch: 4320. Acc: 0.548787. Loss: 1.245469. Batch_acc: 0.579885. Batch_loss: 1.150085 \n",
      "Batch: 4321. Acc: 0.548790. Loss: 1.245460. Batch_acc: 0.562315. Batch_loss: 1.204814 \n",
      "Batch: 4322. Acc: 0.548792. Loss: 1.245456. Batch_acc: 0.557396. Batch_loss: 1.230796 \n",
      "Batch: 4323. Acc: 0.548792. Loss: 1.245456. Batch_acc: 0.550286. Batch_loss: 1.242067 \n",
      "Batch: 4324. Acc: 0.548795. Loss: 1.245450. Batch_acc: 0.562832. Batch_loss: 1.219859 \n",
      "Batch: 4325. Acc: 0.548798. Loss: 1.245436. Batch_acc: 0.560022. Batch_loss: 1.186363 \n",
      "Batch: 4326. Acc: 0.548802. Loss: 1.245429. Batch_acc: 0.568102. Batch_loss: 1.216945 \n",
      "Batch: 4327. Acc: 0.548811. Loss: 1.245407. Batch_acc: 0.585755. Batch_loss: 1.148234 \n",
      "Batch: 4328. Acc: 0.548815. Loss: 1.245397. Batch_acc: 0.565267. Batch_loss: 1.205132 \n",
      "Batch: 4329. Acc: 0.548814. Loss: 1.245391. Batch_acc: 0.545828. Batch_loss: 1.216270 \n",
      "Batch: 4330. Acc: 0.548813. Loss: 1.245390. Batch_acc: 0.544296. Batch_loss: 1.242936 \n",
      "Batch: 4331. Acc: 0.548814. Loss: 1.245382. Batch_acc: 0.552213. Batch_loss: 1.212898 \n",
      "Batch: 4332. Acc: 0.548809. Loss: 1.245395. Batch_acc: 0.527695. Batch_loss: 1.302762 \n",
      "Batch: 4333. Acc: 0.548819. Loss: 1.245368. Batch_acc: 0.592936. Batch_loss: 1.127947 \n",
      "Batch: 4334. Acc: 0.548823. Loss: 1.245355. Batch_acc: 0.563636. Batch_loss: 1.188616 \n",
      "Batch: 4335. Acc: 0.548826. Loss: 1.245344. Batch_acc: 0.564534. Batch_loss: 1.199772 \n",
      "Batch: 4336. Acc: 0.548823. Loss: 1.245353. Batch_acc: 0.533178. Batch_loss: 1.282378 \n",
      "Batch: 4337. Acc: 0.548823. Loss: 1.245347. Batch_acc: 0.550891. Batch_loss: 1.220751 \n",
      "Batch: 4338. Acc: 0.548826. Loss: 1.245334. Batch_acc: 0.561675. Batch_loss: 1.189871 \n",
      "Batch: 4339. Acc: 0.548826. Loss: 1.245338. Batch_acc: 0.549971. Batch_loss: 1.261072 \n",
      "Batch: 4340. Acc: 0.548827. Loss: 1.245329. Batch_acc: 0.551684. Batch_loss: 1.207211 \n",
      "Batch: 4341. Acc: 0.548830. Loss: 1.245320. Batch_acc: 0.560834. Batch_loss: 1.206710 \n",
      "Batch: 4342. Acc: 0.548833. Loss: 1.245313. Batch_acc: 0.562428. Batch_loss: 1.214055 \n",
      "Batch: 4343. Acc: 0.548833. Loss: 1.245309. Batch_acc: 0.551168. Batch_loss: 1.229561 \n",
      "Batch: 4344. Acc: 0.548834. Loss: 1.245313. Batch_acc: 0.552723. Batch_loss: 1.262470 \n",
      "Batch: 4345. Acc: 0.548834. Loss: 1.245303. Batch_acc: 0.547235. Batch_loss: 1.201501 \n",
      "Batch: 4346. Acc: 0.548836. Loss: 1.245299. Batch_acc: 0.555620. Batch_loss: 1.226458 \n",
      "Batch: 4347. Acc: 0.548843. Loss: 1.245276. Batch_acc: 0.581798. Batch_loss: 1.150433 \n",
      "Batch: 4348. Acc: 0.548843. Loss: 1.245276. Batch_acc: 0.548824. Batch_loss: 1.242152 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4349. Acc: 0.548847. Loss: 1.245266. Batch_acc: 0.563405. Batch_loss: 1.200723 \n",
      "Batch: 4350. Acc: 0.548852. Loss: 1.245249. Batch_acc: 0.573053. Batch_loss: 1.172550 \n",
      "Batch: 4351. Acc: 0.548856. Loss: 1.245235. Batch_acc: 0.565072. Batch_loss: 1.189227 \n",
      "Batch: 4352. Acc: 0.548858. Loss: 1.245234. Batch_acc: 0.556143. Batch_loss: 1.237882 \n",
      "Batch: 4353. Acc: 0.548859. Loss: 1.245229. Batch_acc: 0.554266. Batch_loss: 1.224735 \n",
      "Batch: 4354. Acc: 0.548860. Loss: 1.245221. Batch_acc: 0.551784. Batch_loss: 1.209591 \n",
      "Batch: 4355. Acc: 0.548860. Loss: 1.245215. Batch_acc: 0.549826. Batch_loss: 1.219921 \n",
      "Batch: 4356. Acc: 0.548866. Loss: 1.245198. Batch_acc: 0.576701. Batch_loss: 1.168979 \n",
      "Batch: 4357. Acc: 0.548870. Loss: 1.245184. Batch_acc: 0.562963. Batch_loss: 1.184304 \n",
      "Batch: 4358. Acc: 0.548872. Loss: 1.245182. Batch_acc: 0.561343. Batch_loss: 1.237877 \n",
      "Batch: 4359. Acc: 0.548880. Loss: 1.245166. Batch_acc: 0.581798. Batch_loss: 1.176971 \n",
      "Batch: 4360. Acc: 0.548879. Loss: 1.245165. Batch_acc: 0.544048. Batch_loss: 1.239859 \n",
      "Batch: 4361. Acc: 0.548883. Loss: 1.245161. Batch_acc: 0.563957. Batch_loss: 1.228699 \n",
      "Batch: 4362. Acc: 0.548886. Loss: 1.245153. Batch_acc: 0.563700. Batch_loss: 1.212250 \n",
      "Batch: 4363. Acc: 0.548884. Loss: 1.245155. Batch_acc: 0.538726. Batch_loss: 1.252369 \n",
      "Batch: 4364. Acc: 0.548883. Loss: 1.245154. Batch_acc: 0.546955. Batch_loss: 1.243105 \n",
      "Batch: 4365. Acc: 0.548887. Loss: 1.245146. Batch_acc: 0.566857. Batch_loss: 1.210545 \n",
      "Batch: 4366. Acc: 0.548891. Loss: 1.245136. Batch_acc: 0.564525. Batch_loss: 1.200517 \n",
      "Batch: 4367. Acc: 0.548893. Loss: 1.245123. Batch_acc: 0.556977. Batch_loss: 1.185227 \n",
      "Batch: 4368. Acc: 0.548894. Loss: 1.245120. Batch_acc: 0.555744. Batch_loss: 1.233750 \n",
      "Batch: 4369. Acc: 0.548898. Loss: 1.245112. Batch_acc: 0.563288. Batch_loss: 1.211846 \n",
      "Batch: 4370. Acc: 0.548900. Loss: 1.245103. Batch_acc: 0.556193. Batch_loss: 1.207840 \n",
      "Batch: 4371. Acc: 0.548904. Loss: 1.245099. Batch_acc: 0.566572. Batch_loss: 1.225446 \n",
      "Batch: 4372. Acc: 0.548904. Loss: 1.245098. Batch_acc: 0.552187. Batch_loss: 1.242091 \n",
      "Batch: 4373. Acc: 0.548905. Loss: 1.245089. Batch_acc: 0.550895. Batch_loss: 1.204420 \n",
      "Batch: 4374. Acc: 0.548905. Loss: 1.245094. Batch_acc: 0.548518. Batch_loss: 1.269892 \n",
      "Batch: 4375. Acc: 0.548909. Loss: 1.245095. Batch_acc: 0.568259. Batch_loss: 1.248173 \n",
      "Batch: 4376. Acc: 0.548909. Loss: 1.245096. Batch_acc: 0.548780. Batch_loss: 1.250669 \n",
      "Batch: 4377. Acc: 0.548919. Loss: 1.245078. Batch_acc: 0.592364. Batch_loss: 1.165587 \n",
      "Batch: 4378. Acc: 0.548919. Loss: 1.245079. Batch_acc: 0.546697. Batch_loss: 1.250882 \n",
      "Batch: 4379. Acc: 0.548918. Loss: 1.245085. Batch_acc: 0.545507. Batch_loss: 1.273563 \n",
      "Batch: 4380. Acc: 0.548924. Loss: 1.245070. Batch_acc: 0.577259. Batch_loss: 1.176563 \n",
      "Batch: 4381. Acc: 0.548928. Loss: 1.245059. Batch_acc: 0.564692. Batch_loss: 1.196188 \n",
      "Batch: 4382. Acc: 0.548930. Loss: 1.245051. Batch_acc: 0.557942. Batch_loss: 1.210408 \n",
      "Batch: 4383. Acc: 0.548929. Loss: 1.245050. Batch_acc: 0.545350. Batch_loss: 1.241537 \n",
      "Batch: 4384. Acc: 0.548938. Loss: 1.245029. Batch_acc: 0.584949. Batch_loss: 1.152058 \n",
      "Batch: 4385. Acc: 0.548934. Loss: 1.245040. Batch_acc: 0.531842. Batch_loss: 1.293768 \n",
      "Batch: 4386. Acc: 0.548939. Loss: 1.245024. Batch_acc: 0.571588. Batch_loss: 1.176332 \n",
      "Batch: 4387. Acc: 0.548939. Loss: 1.245016. Batch_acc: 0.550793. Batch_loss: 1.209534 \n",
      "Batch: 4388. Acc: 0.548951. Loss: 1.244983. Batch_acc: 0.598612. Batch_loss: 1.101591 \n",
      "Batch: 4389. Acc: 0.548958. Loss: 1.244963. Batch_acc: 0.580377. Batch_loss: 1.159054 \n",
      "Batch: 4390. Acc: 0.548960. Loss: 1.244962. Batch_acc: 0.555109. Batch_loss: 1.239946 \n",
      "Batch: 4391. Acc: 0.548965. Loss: 1.244950. Batch_acc: 0.570855. Batch_loss: 1.195272 \n",
      "Batch: 4392. Acc: 0.548965. Loss: 1.244954. Batch_acc: 0.552961. Batch_loss: 1.258883 \n",
      "Batch: 4393. Acc: 0.548965. Loss: 1.244954. Batch_acc: 0.545455. Batch_loss: 1.245385 \n",
      "Batch: 4394. Acc: 0.548968. Loss: 1.244943. Batch_acc: 0.564294. Batch_loss: 1.199857 \n",
      "Batch: 4395. Acc: 0.548973. Loss: 1.244929. Batch_acc: 0.571512. Batch_loss: 1.179339 \n",
      "Batch: 4396. Acc: 0.548979. Loss: 1.244915. Batch_acc: 0.573410. Batch_loss: 1.184443 \n",
      "Batch: 4397. Acc: 0.548979. Loss: 1.244914. Batch_acc: 0.550793. Batch_loss: 1.240389 \n",
      "Batch: 4398. Acc: 0.548977. Loss: 1.244918. Batch_acc: 0.541375. Batch_loss: 1.262163 \n",
      "Batch: 4399. Acc: 0.548979. Loss: 1.244918. Batch_acc: 0.553899. Batch_loss: 1.244134 \n",
      "Batch: 4400. Acc: 0.548979. Loss: 1.244914. Batch_acc: 0.551424. Batch_loss: 1.226875 \n",
      "Batch: 4401. Acc: 0.548984. Loss: 1.244902. Batch_acc: 0.571098. Batch_loss: 1.193224 \n",
      "Batch: 4402. Acc: 0.548979. Loss: 1.244909. Batch_acc: 0.527746. Batch_loss: 1.277084 \n",
      "Batch: 4403. Acc: 0.548975. Loss: 1.244910. Batch_acc: 0.531087. Batch_loss: 1.250510 \n",
      "Batch: 4404. Acc: 0.548976. Loss: 1.244915. Batch_acc: 0.552496. Batch_loss: 1.265627 \n",
      "Batch: 4405. Acc: 0.548974. Loss: 1.244918. Batch_acc: 0.540587. Batch_loss: 1.258012 \n",
      "Batch: 4406. Acc: 0.548975. Loss: 1.244914. Batch_acc: 0.550700. Batch_loss: 1.227281 \n",
      "Batch: 4407. Acc: 0.548979. Loss: 1.244895. Batch_acc: 0.567181. Batch_loss: 1.163377 \n",
      "Batch: 4408. Acc: 0.548982. Loss: 1.244890. Batch_acc: 0.563112. Batch_loss: 1.222468 \n",
      "Batch: 4409. Acc: 0.548990. Loss: 1.244871. Batch_acc: 0.584641. Batch_loss: 1.159837 \n",
      "Batch: 4410. Acc: 0.548998. Loss: 1.244849. Batch_acc: 0.582192. Batch_loss: 1.150399 \n",
      "Batch: 4411. Acc: 0.549008. Loss: 1.244824. Batch_acc: 0.592150. Batch_loss: 1.137849 \n",
      "Batch: 4412. Acc: 0.549008. Loss: 1.244829. Batch_acc: 0.548002. Batch_loss: 1.266863 \n",
      "Batch: 4413. Acc: 0.549009. Loss: 1.244826. Batch_acc: 0.555809. Batch_loss: 1.230037 \n",
      "Batch: 4414. Acc: 0.549011. Loss: 1.244815. Batch_acc: 0.557339. Batch_loss: 1.198041 \n",
      "Batch: 4415. Acc: 0.549016. Loss: 1.244804. Batch_acc: 0.569635. Batch_loss: 1.196894 \n",
      "Batch: 4416. Acc: 0.549020. Loss: 1.244800. Batch_acc: 0.566147. Batch_loss: 1.224091 \n",
      "Batch: 4417. Acc: 0.549018. Loss: 1.244808. Batch_acc: 0.539881. Batch_loss: 1.283310 \n",
      "Batch: 4418. Acc: 0.549021. Loss: 1.244793. Batch_acc: 0.565996. Batch_loss: 1.181632 \n",
      "Batch: 4419. Acc: 0.549024. Loss: 1.244788. Batch_acc: 0.561817. Batch_loss: 1.219523 \n",
      "Batch: 4420. Acc: 0.549025. Loss: 1.244790. Batch_acc: 0.549824. Batch_loss: 1.256254 \n",
      "Batch: 4421. Acc: 0.549029. Loss: 1.244781. Batch_acc: 0.569905. Batch_loss: 1.203876 \n",
      "Batch: 4422. Acc: 0.549032. Loss: 1.244773. Batch_acc: 0.560340. Batch_loss: 1.210790 \n",
      "Batch: 4423. Acc: 0.549034. Loss: 1.244771. Batch_acc: 0.559571. Batch_loss: 1.236126 \n",
      "Batch: 4424. Acc: 0.549050. Loss: 1.244733. Batch_acc: 0.617057. Batch_loss: 1.080418 \n",
      "Batch: 4425. Acc: 0.549054. Loss: 1.244721. Batch_acc: 0.565541. Batch_loss: 1.194331 \n",
      "Batch: 4426. Acc: 0.549056. Loss: 1.244711. Batch_acc: 0.555743. Batch_loss: 1.199659 \n",
      "Batch: 4427. Acc: 0.549058. Loss: 1.244706. Batch_acc: 0.558553. Batch_loss: 1.224177 \n",
      "Batch: 4428. Acc: 0.549063. Loss: 1.244694. Batch_acc: 0.572832. Batch_loss: 1.191680 \n",
      "Batch: 4429. Acc: 0.549069. Loss: 1.244685. Batch_acc: 0.573761. Batch_loss: 1.202246 \n",
      "Batch: 4430. Acc: 0.549076. Loss: 1.244668. Batch_acc: 0.580460. Batch_loss: 1.171772 \n",
      "Batch: 4431. Acc: 0.549082. Loss: 1.244650. Batch_acc: 0.578045. Batch_loss: 1.165547 \n",
      "Batch: 4432. Acc: 0.549086. Loss: 1.244637. Batch_acc: 0.564265. Batch_loss: 1.184064 \n",
      "Batch: 4433. Acc: 0.549083. Loss: 1.244638. Batch_acc: 0.537237. Batch_loss: 1.248459 \n",
      "Batch: 4434. Acc: 0.549084. Loss: 1.244632. Batch_acc: 0.555489. Batch_loss: 1.221102 \n",
      "Batch: 4435. Acc: 0.549083. Loss: 1.244630. Batch_acc: 0.544612. Batch_loss: 1.231983 \n",
      "Batch: 4436. Acc: 0.549083. Loss: 1.244631. Batch_acc: 0.547851. Batch_loss: 1.250911 \n",
      "Batch: 4437. Acc: 0.549085. Loss: 1.244625. Batch_acc: 0.557396. Batch_loss: 1.218567 \n",
      "Batch: 4438. Acc: 0.549087. Loss: 1.244619. Batch_acc: 0.559649. Batch_loss: 1.216559 \n",
      "Batch: 4439. Acc: 0.549090. Loss: 1.244618. Batch_acc: 0.561444. Batch_loss: 1.239559 \n",
      "Batch: 4440. Acc: 0.549089. Loss: 1.244621. Batch_acc: 0.545924. Batch_loss: 1.256994 \n",
      "Batch: 4441. Acc: 0.549087. Loss: 1.244620. Batch_acc: 0.538373. Batch_loss: 1.241743 \n",
      "Batch: 4442. Acc: 0.549089. Loss: 1.244615. Batch_acc: 0.556303. Batch_loss: 1.221665 \n",
      "Batch: 4443. Acc: 0.549084. Loss: 1.244620. Batch_acc: 0.530364. Batch_loss: 1.268909 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4444. Acc: 0.549090. Loss: 1.244609. Batch_acc: 0.573106. Batch_loss: 1.193512 \n",
      "Batch: 4445. Acc: 0.549102. Loss: 1.244583. Batch_acc: 0.605384. Batch_loss: 1.128475 \n",
      "Batch: 4446. Acc: 0.549104. Loss: 1.244581. Batch_acc: 0.554147. Batch_loss: 1.237251 \n",
      "Batch: 4447. Acc: 0.549107. Loss: 1.244574. Batch_acc: 0.566458. Batch_loss: 1.216295 \n",
      "Batch: 4448. Acc: 0.549107. Loss: 1.244567. Batch_acc: 0.547203. Batch_loss: 1.212474 \n",
      "Batch: 4449. Acc: 0.549109. Loss: 1.244559. Batch_acc: 0.560164. Batch_loss: 1.206648 \n",
      "Batch: 4450. Acc: 0.549114. Loss: 1.244547. Batch_acc: 0.570012. Batch_loss: 1.191019 \n",
      "Batch: 4451. Acc: 0.549112. Loss: 1.244559. Batch_acc: 0.538153. Batch_loss: 1.297459 \n",
      "Batch: 4452. Acc: 0.549111. Loss: 1.244559. Batch_acc: 0.545771. Batch_loss: 1.243279 \n",
      "Batch: 4453. Acc: 0.549111. Loss: 1.244557. Batch_acc: 0.550937. Batch_loss: 1.238422 \n",
      "Batch: 4454. Acc: 0.549116. Loss: 1.244550. Batch_acc: 0.568627. Batch_loss: 1.209701 \n",
      "Batch: 4455. Acc: 0.549112. Loss: 1.244559. Batch_acc: 0.533295. Batch_loss: 1.288192 \n",
      "Batch: 4456. Acc: 0.549115. Loss: 1.244557. Batch_acc: 0.561753. Batch_loss: 1.233923 \n",
      "Batch: 4457. Acc: 0.549119. Loss: 1.244541. Batch_acc: 0.565564. Batch_loss: 1.174777 \n",
      "Batch: 4458. Acc: 0.549125. Loss: 1.244521. Batch_acc: 0.578251. Batch_loss: 1.156269 \n",
      "Batch: 4459. Acc: 0.549127. Loss: 1.244517. Batch_acc: 0.555866. Batch_loss: 1.226766 \n",
      "Batch: 4460. Acc: 0.549132. Loss: 1.244500. Batch_acc: 0.574127. Batch_loss: 1.168805 \n",
      "Batch: 4461. Acc: 0.549129. Loss: 1.244501. Batch_acc: 0.534753. Batch_loss: 1.248657 \n",
      "Batch: 4462. Acc: 0.549134. Loss: 1.244488. Batch_acc: 0.570760. Batch_loss: 1.184357 \n",
      "Batch: 4463. Acc: 0.549140. Loss: 1.244478. Batch_acc: 0.575397. Batch_loss: 1.200107 \n",
      "Batch: 4464. Acc: 0.549138. Loss: 1.244481. Batch_acc: 0.541051. Batch_loss: 1.257427 \n",
      "Batch: 4465. Acc: 0.549139. Loss: 1.244467. Batch_acc: 0.553364. Batch_loss: 1.185284 \n",
      "Batch: 4466. Acc: 0.549139. Loss: 1.244471. Batch_acc: 0.548071. Batch_loss: 1.259981 \n",
      "Batch: 4467. Acc: 0.549146. Loss: 1.244458. Batch_acc: 0.582176. Batch_loss: 1.188099 \n",
      "Batch: 4468. Acc: 0.549150. Loss: 1.244444. Batch_acc: 0.568366. Batch_loss: 1.179617 \n",
      "Batch: 4469. Acc: 0.549153. Loss: 1.244435. Batch_acc: 0.560092. Batch_loss: 1.204918 \n",
      "Batch: 4470. Acc: 0.549146. Loss: 1.244450. Batch_acc: 0.515826. Batch_loss: 1.311126 \n",
      "Batch: 4471. Acc: 0.549146. Loss: 1.244449. Batch_acc: 0.551172. Batch_loss: 1.240900 \n",
      "Batch: 4472. Acc: 0.549148. Loss: 1.244442. Batch_acc: 0.557159. Batch_loss: 1.214044 \n",
      "Batch: 4473. Acc: 0.549146. Loss: 1.244439. Batch_acc: 0.540230. Batch_loss: 1.230308 \n",
      "Batch: 4474. Acc: 0.549144. Loss: 1.244438. Batch_acc: 0.542266. Batch_loss: 1.240718 \n",
      "Batch: 4475. Acc: 0.549145. Loss: 1.244431. Batch_acc: 0.552342. Batch_loss: 1.214212 \n",
      "Batch: 4476. Acc: 0.549151. Loss: 1.244411. Batch_acc: 0.575792. Batch_loss: 1.155209 \n",
      "Batch: 4477. Acc: 0.549154. Loss: 1.244405. Batch_acc: 0.560364. Batch_loss: 1.216117 \n",
      "Batch: 4478. Acc: 0.549161. Loss: 1.244382. Batch_acc: 0.584829. Batch_loss: 1.140142 \n",
      "Batch: 4479. Acc: 0.549158. Loss: 1.244388. Batch_acc: 0.531903. Batch_loss: 1.270790 \n",
      "Batch: 4480. Acc: 0.549154. Loss: 1.244396. Batch_acc: 0.533255. Batch_loss: 1.283989 \n",
      "Batch: 4481. Acc: 0.549161. Loss: 1.244379. Batch_acc: 0.577425. Batch_loss: 1.170132 \n",
      "Batch: 4482. Acc: 0.549162. Loss: 1.244376. Batch_acc: 0.556452. Batch_loss: 1.230427 \n",
      "Batch: 4483. Acc: 0.549158. Loss: 1.244384. Batch_acc: 0.531250. Batch_loss: 1.278219 \n",
      "Batch: 4484. Acc: 0.549157. Loss: 1.244383. Batch_acc: 0.544776. Batch_loss: 1.242364 \n",
      "Batch: 4485. Acc: 0.549157. Loss: 1.244383. Batch_acc: 0.550000. Batch_loss: 1.241435 \n",
      "Batch: 4486. Acc: 0.549155. Loss: 1.244381. Batch_acc: 0.536471. Batch_loss: 1.238477 \n",
      "Batch: 4487. Acc: 0.549158. Loss: 1.244365. Batch_acc: 0.564903. Batch_loss: 1.173927 \n",
      "Batch: 4488. Acc: 0.549161. Loss: 1.244356. Batch_acc: 0.562137. Batch_loss: 1.201694 \n",
      "Batch: 4489. Acc: 0.549167. Loss: 1.244342. Batch_acc: 0.575072. Batch_loss: 1.180362 \n",
      "Batch: 4490. Acc: 0.549164. Loss: 1.244347. Batch_acc: 0.534097. Batch_loss: 1.267957 \n",
      "Batch: 4491. Acc: 0.549162. Loss: 1.244355. Batch_acc: 0.540418. Batch_loss: 1.280600 \n",
      "Batch: 4492. Acc: 0.549156. Loss: 1.244366. Batch_acc: 0.524000. Batch_loss: 1.294064 \n",
      "Batch: 4493. Acc: 0.549160. Loss: 1.244355. Batch_acc: 0.565292. Batch_loss: 1.195065 \n",
      "Batch: 4494. Acc: 0.549156. Loss: 1.244359. Batch_acc: 0.535088. Batch_loss: 1.260752 \n",
      "Batch: 4495. Acc: 0.549159. Loss: 1.244347. Batch_acc: 0.559585. Batch_loss: 1.190728 \n",
      "Batch: 4496. Acc: 0.549164. Loss: 1.244331. Batch_acc: 0.572989. Batch_loss: 1.174935 \n",
      "Batch: 4497. Acc: 0.549165. Loss: 1.244330. Batch_acc: 0.555102. Batch_loss: 1.237095 \n",
      "Batch: 4498. Acc: 0.549167. Loss: 1.244324. Batch_acc: 0.558153. Batch_loss: 1.217672 \n",
      "Batch: 4499. Acc: 0.549170. Loss: 1.244314. Batch_acc: 0.561383. Batch_loss: 1.200575 \n",
      "Batch: 4500. Acc: 0.549176. Loss: 1.244298. Batch_acc: 0.573630. Batch_loss: 1.172925 \n",
      "Batch: 4501. Acc: 0.549175. Loss: 1.244294. Batch_acc: 0.544992. Batch_loss: 1.226583 \n",
      "Batch: 4502. Acc: 0.549175. Loss: 1.244295. Batch_acc: 0.552239. Batch_loss: 1.246010 \n",
      "Batch: 4503. Acc: 0.549187. Loss: 1.244269. Batch_acc: 0.598985. Batch_loss: 1.129878 \n",
      "Batch: 4504. Acc: 0.549184. Loss: 1.244282. Batch_acc: 0.536471. Batch_loss: 1.304252 \n",
      "Batch: 4505. Acc: 0.549181. Loss: 1.244281. Batch_acc: 0.536009. Batch_loss: 1.241500 \n",
      "Batch: 4506. Acc: 0.549183. Loss: 1.244274. Batch_acc: 0.559628. Batch_loss: 1.213805 \n",
      "Batch: 4507. Acc: 0.549183. Loss: 1.244270. Batch_acc: 0.549854. Batch_loss: 1.225245 \n",
      "Batch: 4508. Acc: 0.549182. Loss: 1.244271. Batch_acc: 0.544230. Batch_loss: 1.248438 \n",
      "Batch: 4509. Acc: 0.549180. Loss: 1.244275. Batch_acc: 0.537883. Batch_loss: 1.260529 \n",
      "Batch: 4510. Acc: 0.549185. Loss: 1.244256. Batch_acc: 0.573521. Batch_loss: 1.163411 \n",
      "Batch: 4511. Acc: 0.549192. Loss: 1.244241. Batch_acc: 0.580045. Batch_loss: 1.178191 \n",
      "Batch: 4512. Acc: 0.549194. Loss: 1.244233. Batch_acc: 0.557225. Batch_loss: 1.207094 \n",
      "Batch: 4513. Acc: 0.549200. Loss: 1.244216. Batch_acc: 0.576196. Batch_loss: 1.167450 \n",
      "Batch: 4514. Acc: 0.549205. Loss: 1.244195. Batch_acc: 0.571262. Batch_loss: 1.149813 \n",
      "Batch: 4515. Acc: 0.549202. Loss: 1.244197. Batch_acc: 0.534065. Batch_loss: 1.255197 \n",
      "Batch: 4516. Acc: 0.549206. Loss: 1.244186. Batch_acc: 0.567087. Batch_loss: 1.193245 \n",
      "Batch: 4517. Acc: 0.549207. Loss: 1.244184. Batch_acc: 0.553437. Batch_loss: 1.234590 \n",
      "Batch: 4518. Acc: 0.549210. Loss: 1.244175. Batch_acc: 0.563910. Batch_loss: 1.203733 \n",
      "Checkpointing on batch: 4518. Accuracy: 0.5492099283146274. Loss per char: 1.2441750989572815. Time: 1627225245.140227\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 22, 15, 22,  1,\n",
      "        66, 79, 69,  1, 14, 22, 15, 22, 22, 22, 22, 21, 26, 24, 18, 26, 19, 18,\n",
      "        32,  3,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 4519. Acc: 0.549210. Loss: 1.244169. Batch_acc: 0.550000. Batch_loss: 1.215370 \n",
      "Batch: 4520. Acc: 0.549208. Loss: 1.244173. Batch_acc: 0.537442. Batch_loss: 1.264130 \n",
      "Batch: 4521. Acc: 0.549205. Loss: 1.244177. Batch_acc: 0.538726. Batch_loss: 1.261137 \n",
      "Batch: 4522. Acc: 0.549208. Loss: 1.244176. Batch_acc: 0.559591. Batch_loss: 1.238553 \n",
      "Batch: 4523. Acc: 0.549214. Loss: 1.244161. Batch_acc: 0.578397. Batch_loss: 1.178576 \n",
      "Batch: 4524. Acc: 0.549217. Loss: 1.244153. Batch_acc: 0.561424. Batch_loss: 1.207983 \n",
      "Batch: 4525. Acc: 0.549217. Loss: 1.244149. Batch_acc: 0.551986. Batch_loss: 1.224962 \n",
      "Batch: 4526. Acc: 0.549222. Loss: 1.244136. Batch_acc: 0.571345. Batch_loss: 1.183444 \n",
      "Batch: 4527. Acc: 0.549222. Loss: 1.244129. Batch_acc: 0.550891. Batch_loss: 1.213308 \n",
      "Batch: 4528. Acc: 0.549219. Loss: 1.244141. Batch_acc: 0.535227. Batch_loss: 1.295860 \n",
      "Batch: 4529. Acc: 0.549223. Loss: 1.244127. Batch_acc: 0.566781. Batch_loss: 1.183803 \n",
      "Batch: 4530. Acc: 0.549227. Loss: 1.244115. Batch_acc: 0.568143. Batch_loss: 1.189287 \n",
      "Batch: 4531. Acc: 0.549226. Loss: 1.244126. Batch_acc: 0.541716. Batch_loss: 1.292259 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4532. Acc: 0.549228. Loss: 1.244117. Batch_acc: 0.558206. Batch_loss: 1.205682 \n",
      "Batch: 4533. Acc: 0.549229. Loss: 1.244108. Batch_acc: 0.556507. Batch_loss: 1.202022 \n",
      "Batch: 4534. Acc: 0.549233. Loss: 1.244098. Batch_acc: 0.564311. Batch_loss: 1.202174 \n",
      "Batch: 4535. Acc: 0.549238. Loss: 1.244084. Batch_acc: 0.573948. Batch_loss: 1.180181 \n",
      "Batch: 4536. Acc: 0.549233. Loss: 1.244101. Batch_acc: 0.525394. Batch_loss: 1.322762 \n",
      "Batch: 4537. Acc: 0.549236. Loss: 1.244090. Batch_acc: 0.564591. Batch_loss: 1.193979 \n",
      "Batch: 4538. Acc: 0.549235. Loss: 1.244094. Batch_acc: 0.542645. Batch_loss: 1.261824 \n",
      "Batch: 4539. Acc: 0.549235. Loss: 1.244093. Batch_acc: 0.551333. Batch_loss: 1.239341 \n",
      "Batch: 4540. Acc: 0.549236. Loss: 1.244084. Batch_acc: 0.554354. Batch_loss: 1.204833 \n",
      "Batch: 4541. Acc: 0.549239. Loss: 1.244076. Batch_acc: 0.562716. Batch_loss: 1.204686 \n",
      "Batch: 4542. Acc: 0.549242. Loss: 1.244068. Batch_acc: 0.561965. Batch_loss: 1.208591 \n",
      "Batch: 4543. Acc: 0.549251. Loss: 1.244045. Batch_acc: 0.587409. Batch_loss: 1.143047 \n",
      "Batch: 4544. Acc: 0.549262. Loss: 1.244014. Batch_acc: 0.599554. Batch_loss: 1.107593 \n",
      "Batch: 4545. Acc: 0.549270. Loss: 1.244004. Batch_acc: 0.582664. Batch_loss: 1.199842 \n",
      "Batch: 4546. Acc: 0.549273. Loss: 1.243996. Batch_acc: 0.562322. Batch_loss: 1.205981 \n",
      "Batch: 4547. Acc: 0.549272. Loss: 1.243994. Batch_acc: 0.547875. Batch_loss: 1.233991 \n",
      "Batch: 4548. Acc: 0.549278. Loss: 1.243977. Batch_acc: 0.575705. Batch_loss: 1.168245 \n",
      "Batch: 4549. Acc: 0.549278. Loss: 1.243973. Batch_acc: 0.547605. Batch_loss: 1.223352 \n",
      "Batch: 4550. Acc: 0.549279. Loss: 1.243973. Batch_acc: 0.555239. Batch_loss: 1.244967 \n",
      "Batch: 4551. Acc: 0.549290. Loss: 1.243944. Batch_acc: 0.599186. Batch_loss: 1.111439 \n",
      "Batch: 4552. Acc: 0.549297. Loss: 1.243928. Batch_acc: 0.581278. Batch_loss: 1.173224 \n",
      "Batch: 4553. Acc: 0.549303. Loss: 1.243912. Batch_acc: 0.577408. Batch_loss: 1.173202 \n",
      "Batch: 4554. Acc: 0.549306. Loss: 1.243907. Batch_acc: 0.563152. Batch_loss: 1.217312 \n",
      "Batch: 4555. Acc: 0.549306. Loss: 1.243900. Batch_acc: 0.548203. Batch_loss: 1.213872 \n",
      "Batch: 4556. Acc: 0.549309. Loss: 1.243886. Batch_acc: 0.563045. Batch_loss: 1.177441 \n",
      "Batch: 4557. Acc: 0.549316. Loss: 1.243870. Batch_acc: 0.582184. Batch_loss: 1.171309 \n",
      "Batch: 4558. Acc: 0.549314. Loss: 1.243868. Batch_acc: 0.540909. Batch_loss: 1.234621 \n",
      "Batch: 4559. Acc: 0.549313. Loss: 1.243870. Batch_acc: 0.543540. Batch_loss: 1.256702 \n",
      "Batch: 4560. Acc: 0.549311. Loss: 1.243866. Batch_acc: 0.541875. Batch_loss: 1.226531 \n",
      "Batch: 4561. Acc: 0.549308. Loss: 1.243876. Batch_acc: 0.534183. Batch_loss: 1.287644 \n",
      "Batch: 4562. Acc: 0.549307. Loss: 1.243880. Batch_acc: 0.544032. Batch_loss: 1.264088 \n",
      "Batch: 4563. Acc: 0.549306. Loss: 1.243889. Batch_acc: 0.545670. Batch_loss: 1.284150 \n",
      "Batch: 4564. Acc: 0.549307. Loss: 1.243887. Batch_acc: 0.554530. Batch_loss: 1.235173 \n",
      "Batch: 4565. Acc: 0.549310. Loss: 1.243884. Batch_acc: 0.562536. Batch_loss: 1.229536 \n",
      "Batch: 4566. Acc: 0.549311. Loss: 1.243877. Batch_acc: 0.553714. Batch_loss: 1.211800 \n",
      "Batch: 4567. Acc: 0.549313. Loss: 1.243876. Batch_acc: 0.558649. Batch_loss: 1.238346 \n",
      "Batch: 4568. Acc: 0.549313. Loss: 1.243878. Batch_acc: 0.550469. Batch_loss: 1.253813 \n",
      "Batch: 4569. Acc: 0.549315. Loss: 1.243874. Batch_acc: 0.554416. Batch_loss: 1.224398 \n",
      "Batch: 4570. Acc: 0.549312. Loss: 1.243875. Batch_acc: 0.539645. Batch_loss: 1.249571 \n",
      "Batch: 4571. Acc: 0.549308. Loss: 1.243879. Batch_acc: 0.530612. Batch_loss: 1.263083 \n",
      "Batch: 4572. Acc: 0.549305. Loss: 1.243892. Batch_acc: 0.533643. Batch_loss: 1.303052 \n",
      "Batch: 4573. Acc: 0.549309. Loss: 1.243886. Batch_acc: 0.567275. Batch_loss: 1.220230 \n",
      "Batch: 4574. Acc: 0.549308. Loss: 1.243894. Batch_acc: 0.546275. Batch_loss: 1.275467 \n",
      "Batch: 4575. Acc: 0.549303. Loss: 1.243903. Batch_acc: 0.523256. Batch_loss: 1.288662 \n",
      "Batch: 4576. Acc: 0.549298. Loss: 1.243912. Batch_acc: 0.528103. Batch_loss: 1.282665 \n",
      "Batch: 4577. Acc: 0.549302. Loss: 1.243900. Batch_acc: 0.566514. Batch_loss: 1.189065 \n",
      "Batch: 4578. Acc: 0.549304. Loss: 1.243895. Batch_acc: 0.558396. Batch_loss: 1.222322 \n",
      "Batch: 4579. Acc: 0.549306. Loss: 1.243890. Batch_acc: 0.557013. Batch_loss: 1.220037 \n",
      "Batch: 4580. Acc: 0.549311. Loss: 1.243871. Batch_acc: 0.572002. Batch_loss: 1.159283 \n",
      "Batch: 4581. Acc: 0.549315. Loss: 1.243859. Batch_acc: 0.570930. Batch_loss: 1.188468 \n",
      "Batch: 4582. Acc: 0.549316. Loss: 1.243857. Batch_acc: 0.551424. Batch_loss: 1.234940 \n",
      "Batch: 4583. Acc: 0.549319. Loss: 1.243853. Batch_acc: 0.562572. Batch_loss: 1.226631 \n",
      "Batch: 4584. Acc: 0.549320. Loss: 1.243848. Batch_acc: 0.557704. Batch_loss: 1.220725 \n",
      "Batch: 4585. Acc: 0.549323. Loss: 1.243840. Batch_acc: 0.561485. Batch_loss: 1.205360 \n",
      "Batch: 4586. Acc: 0.549324. Loss: 1.243834. Batch_acc: 0.556409. Batch_loss: 1.213930 \n",
      "Batch: 4587. Acc: 0.549324. Loss: 1.243831. Batch_acc: 0.544907. Batch_loss: 1.232006 \n",
      "Batch: 4588. Acc: 0.549328. Loss: 1.243820. Batch_acc: 0.570763. Batch_loss: 1.190306 \n",
      "Batch: 4589. Acc: 0.549339. Loss: 1.243793. Batch_acc: 0.600000. Batch_loss: 1.119148 \n",
      "Batch: 4590. Acc: 0.549340. Loss: 1.243791. Batch_acc: 0.553936. Batch_loss: 1.231674 \n",
      "Batch: 4591. Acc: 0.549342. Loss: 1.243787. Batch_acc: 0.558113. Batch_loss: 1.226512 \n",
      "Batch: 4592. Acc: 0.549342. Loss: 1.243785. Batch_acc: 0.550961. Batch_loss: 1.235645 \n",
      "Batch: 4593. Acc: 0.549345. Loss: 1.243782. Batch_acc: 0.562906. Batch_loss: 1.230382 \n",
      "Batch: 4594. Acc: 0.549339. Loss: 1.243794. Batch_acc: 0.523121. Batch_loss: 1.296242 \n",
      "Batch: 4595. Acc: 0.549338. Loss: 1.243792. Batch_acc: 0.544658. Batch_loss: 1.235046 \n",
      "Batch: 4596. Acc: 0.549341. Loss: 1.243780. Batch_acc: 0.560117. Batch_loss: 1.189641 \n",
      "Batch: 4597. Acc: 0.549343. Loss: 1.243780. Batch_acc: 0.557501. Batch_loss: 1.241874 \n",
      "Batch: 4598. Acc: 0.549343. Loss: 1.243780. Batch_acc: 0.553541. Batch_loss: 1.242971 \n",
      "Batch: 4599. Acc: 0.549346. Loss: 1.243773. Batch_acc: 0.560350. Batch_loss: 1.215526 \n",
      "Batch: 4600. Acc: 0.549351. Loss: 1.243765. Batch_acc: 0.573607. Batch_loss: 1.205407 \n",
      "Batch: 4601. Acc: 0.549352. Loss: 1.243765. Batch_acc: 0.554519. Batch_loss: 1.240534 \n",
      "Batch: 4602. Acc: 0.549351. Loss: 1.243766. Batch_acc: 0.545032. Batch_loss: 1.249162 \n",
      "Batch: 4603. Acc: 0.549351. Loss: 1.243759. Batch_acc: 0.546439. Batch_loss: 1.214609 \n",
      "Batch: 4604. Acc: 0.549352. Loss: 1.243753. Batch_acc: 0.555056. Batch_loss: 1.213802 \n",
      "Batch: 4605. Acc: 0.549351. Loss: 1.243745. Batch_acc: 0.547578. Batch_loss: 1.207682 \n",
      "Batch: 4606. Acc: 0.549352. Loss: 1.243744. Batch_acc: 0.551228. Batch_loss: 1.238827 \n",
      "Batch: 4607. Acc: 0.549357. Loss: 1.243736. Batch_acc: 0.574640. Batch_loss: 1.207620 \n",
      "Batch: 4608. Acc: 0.549353. Loss: 1.243740. Batch_acc: 0.527357. Batch_loss: 1.263039 \n",
      "Batch: 4609. Acc: 0.549351. Loss: 1.243737. Batch_acc: 0.542775. Batch_loss: 1.230012 \n",
      "Batch: 4610. Acc: 0.549351. Loss: 1.243735. Batch_acc: 0.551068. Batch_loss: 1.235094 \n",
      "Batch: 4611. Acc: 0.549358. Loss: 1.243719. Batch_acc: 0.579342. Batch_loss: 1.168083 \n",
      "Batch: 4612. Acc: 0.549358. Loss: 1.243716. Batch_acc: 0.551289. Batch_loss: 1.231554 \n",
      "Batch: 4613. Acc: 0.549360. Loss: 1.243714. Batch_acc: 0.557110. Batch_loss: 1.234239 \n",
      "Batch: 4614. Acc: 0.549362. Loss: 1.243709. Batch_acc: 0.556257. Batch_loss: 1.218445 \n",
      "Batch: 4615. Acc: 0.549368. Loss: 1.243695. Batch_acc: 0.576966. Batch_loss: 1.180977 \n",
      "Batch: 4616. Acc: 0.549371. Loss: 1.243685. Batch_acc: 0.565774. Batch_loss: 1.197696 \n",
      "Batch: 4617. Acc: 0.549367. Loss: 1.243696. Batch_acc: 0.527863. Batch_loss: 1.297471 \n",
      "Batch: 4618. Acc: 0.549369. Loss: 1.243695. Batch_acc: 0.561556. Batch_loss: 1.238830 \n",
      "Batch: 4619. Acc: 0.549375. Loss: 1.243680. Batch_acc: 0.573454. Batch_loss: 1.174977 \n",
      "Batch: 4620. Acc: 0.549382. Loss: 1.243661. Batch_acc: 0.581995. Batch_loss: 1.157315 \n",
      "Batch: 4621. Acc: 0.549384. Loss: 1.243656. Batch_acc: 0.560414. Batch_loss: 1.218998 \n",
      "Batch: 4622. Acc: 0.549381. Loss: 1.243658. Batch_acc: 0.535227. Batch_loss: 1.255634 \n",
      "Batch: 4623. Acc: 0.549383. Loss: 1.243655. Batch_acc: 0.560114. Batch_loss: 1.227283 \n",
      "Batch: 4624. Acc: 0.549384. Loss: 1.243642. Batch_acc: 0.552339. Batch_loss: 1.185106 \n",
      "Batch: 4625. Acc: 0.549382. Loss: 1.243643. Batch_acc: 0.539282. Batch_loss: 1.249922 \n",
      "Batch: 4626. Acc: 0.549389. Loss: 1.243626. Batch_acc: 0.583001. Batch_loss: 1.164551 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 4627. Acc: 0.549389. Loss: 1.243632. Batch_acc: 0.548929. Batch_loss: 1.271770 \n",
      "Batch: 4628. Acc: 0.549381. Loss: 1.243647. Batch_acc: 0.510180. Batch_loss: 1.315826 \n",
      "Batch: 4629. Acc: 0.549382. Loss: 1.243642. Batch_acc: 0.555294. Batch_loss: 1.217129 \n",
      "Batch: 4630. Acc: 0.549389. Loss: 1.243628. Batch_acc: 0.579686. Batch_loss: 1.181370 \n",
      "Batch: 4631. Acc: 0.549382. Loss: 1.243645. Batch_acc: 0.516110. Batch_loss: 1.325776 \n",
      "Batch: 4632. Acc: 0.549379. Loss: 1.243644. Batch_acc: 0.535032. Batch_loss: 1.238371 \n",
      "Batch: 4633. Acc: 0.549379. Loss: 1.243643. Batch_acc: 0.549885. Batch_loss: 1.239809 \n",
      "Batch: 4634. Acc: 0.549382. Loss: 1.243630. Batch_acc: 0.567147. Batch_loss: 1.181655 \n",
      "Batch: 4635. Acc: 0.549388. Loss: 1.243611. Batch_acc: 0.574541. Batch_loss: 1.158054 \n",
      "Batch: 4636. Acc: 0.549394. Loss: 1.243598. Batch_acc: 0.576081. Batch_loss: 1.184130 \n",
      "Batch: 4637. Acc: 0.549399. Loss: 1.243583. Batch_acc: 0.571429. Batch_loss: 1.172534 \n",
      "Batch: 4638. Acc: 0.549401. Loss: 1.243572. Batch_acc: 0.559456. Batch_loss: 1.194733 \n",
      "Batch: 4639. Acc: 0.549406. Loss: 1.243560. Batch_acc: 0.572379. Batch_loss: 1.189536 \n",
      "Batch: 4640. Acc: 0.549407. Loss: 1.243550. Batch_acc: 0.555556. Batch_loss: 1.197826 \n",
      "Batch: 4641. Acc: 0.549407. Loss: 1.243548. Batch_acc: 0.547846. Batch_loss: 1.234342 \n",
      "Batch: 4642. Acc: 0.549410. Loss: 1.243536. Batch_acc: 0.565758. Batch_loss: 1.183117 \n",
      "Batch: 4643. Acc: 0.549411. Loss: 1.243529. Batch_acc: 0.554070. Batch_loss: 1.210752 \n",
      "Batch: 4644. Acc: 0.549411. Loss: 1.243525. Batch_acc: 0.547564. Batch_loss: 1.224101 \n",
      "Batch: 4645. Acc: 0.549413. Loss: 1.243515. Batch_acc: 0.560742. Batch_loss: 1.201531 \n",
      "Batch: 4646. Acc: 0.549411. Loss: 1.243521. Batch_acc: 0.539130. Batch_loss: 1.268784 \n",
      "Batch: 4647. Acc: 0.549413. Loss: 1.243510. Batch_acc: 0.556199. Batch_loss: 1.194393 \n",
      "Batch: 4648. Acc: 0.549413. Loss: 1.243504. Batch_acc: 0.551626. Batch_loss: 1.215004 \n",
      "Batch: 4649. Acc: 0.549420. Loss: 1.243485. Batch_acc: 0.579808. Batch_loss: 1.158511 \n",
      "Batch: 4650. Acc: 0.549424. Loss: 1.243473. Batch_acc: 0.570120. Batch_loss: 1.187114 \n",
      "Batch: 4651. Acc: 0.549425. Loss: 1.243467. Batch_acc: 0.554085. Batch_loss: 1.215954 \n",
      "Batch: 4652. Acc: 0.549430. Loss: 1.243453. Batch_acc: 0.571024. Batch_loss: 1.180375 \n",
      "Batch: 4653. Acc: 0.549434. Loss: 1.243439. Batch_acc: 0.569813. Batch_loss: 1.176984 \n",
      "Batch: 4654. Acc: 0.549433. Loss: 1.243435. Batch_acc: 0.544780. Batch_loss: 1.227450 \n",
      "Batch: 4655. Acc: 0.549434. Loss: 1.243435. Batch_acc: 0.552901. Batch_loss: 1.241527 \n",
      "Batch: 4656. Acc: 0.549442. Loss: 1.243416. Batch_acc: 0.583287. Batch_loss: 1.158287 \n",
      "Batch: 4657. Acc: 0.549441. Loss: 1.243411. Batch_acc: 0.545401. Batch_loss: 1.219409 \n",
      "Batch: 4658. Acc: 0.549446. Loss: 1.243398. Batch_acc: 0.574598. Batch_loss: 1.185446 \n",
      "Batch: 4659. Acc: 0.549451. Loss: 1.243384. Batch_acc: 0.569405. Batch_loss: 1.178819 \n",
      "Batch: 4660. Acc: 0.549457. Loss: 1.243370. Batch_acc: 0.580403. Batch_loss: 1.174132 \n",
      "Batch: 4661. Acc: 0.549462. Loss: 1.243361. Batch_acc: 0.572581. Batch_loss: 1.203221 \n",
      "Batch: 4662. Acc: 0.549471. Loss: 1.243340. Batch_acc: 0.591063. Batch_loss: 1.149560 \n",
      "Batch: 4663. Acc: 0.549469. Loss: 1.243346. Batch_acc: 0.538062. Batch_loss: 1.270889 \n",
      "Batch: 4664. Acc: 0.549472. Loss: 1.243341. Batch_acc: 0.561353. Batch_loss: 1.219751 \n",
      "Batch: 4665. Acc: 0.549478. Loss: 1.243326. Batch_acc: 0.579513. Batch_loss: 1.173640 \n",
      "Batch: 4666. Acc: 0.549480. Loss: 1.243318. Batch_acc: 0.557827. Batch_loss: 1.205683 \n",
      "Batch: 4667. Acc: 0.549482. Loss: 1.243317. Batch_acc: 0.558517. Batch_loss: 1.238066 \n",
      "Batch: 4668. Acc: 0.549482. Loss: 1.243308. Batch_acc: 0.551919. Batch_loss: 1.201968 \n",
      "Batch: 4669. Acc: 0.549483. Loss: 1.243298. Batch_acc: 0.553695. Batch_loss: 1.195215 \n",
      "Batch: 4670. Acc: 0.549485. Loss: 1.243285. Batch_acc: 0.559908. Batch_loss: 1.181551 \n",
      "Batch: 4671. Acc: 0.549481. Loss: 1.243300. Batch_acc: 0.528790. Batch_loss: 1.318567 \n",
      "Batch: 4672. Acc: 0.549485. Loss: 1.243292. Batch_acc: 0.569045. Batch_loss: 1.204557 \n",
      "Batch: 4673. Acc: 0.549481. Loss: 1.243299. Batch_acc: 0.530241. Batch_loss: 1.278311 \n",
      "Batch: 4674. Acc: 0.549483. Loss: 1.243291. Batch_acc: 0.559233. Batch_loss: 1.204456 \n",
      "Batch: 4675. Acc: 0.549489. Loss: 1.243275. Batch_acc: 0.577259. Batch_loss: 1.164930 \n",
      "Batch: 4676. Acc: 0.549492. Loss: 1.243266. Batch_acc: 0.563700. Batch_loss: 1.202899 \n",
      "Batch: 4677. Acc: 0.549492. Loss: 1.243259. Batch_acc: 0.549321. Batch_loss: 1.211142 \n",
      "Batch: 4678. Acc: 0.549494. Loss: 1.243257. Batch_acc: 0.556072. Batch_loss: 1.229784 \n",
      "Batch: 4679. Acc: 0.549493. Loss: 1.243257. Batch_acc: 0.548499. Batch_loss: 1.244677 \n",
      "Batch: 4680. Acc: 0.549494. Loss: 1.243252. Batch_acc: 0.552827. Batch_loss: 1.218670 \n",
      "Batch: 4681. Acc: 0.549495. Loss: 1.243245. Batch_acc: 0.553069. Batch_loss: 1.213078 \n",
      "Batch: 4682. Acc: 0.549498. Loss: 1.243236. Batch_acc: 0.566572. Batch_loss: 1.202801 \n",
      "Batch: 4683. Acc: 0.549501. Loss: 1.243226. Batch_acc: 0.559752. Batch_loss: 1.194126 \n",
      "Batch: 4684. Acc: 0.549506. Loss: 1.243209. Batch_acc: 0.574887. Batch_loss: 1.166724 \n",
      "Batch: 4685. Acc: 0.549511. Loss: 1.243190. Batch_acc: 0.572316. Batch_loss: 1.155853 \n",
      "Batch: 4686. Acc: 0.549515. Loss: 1.243183. Batch_acc: 0.566589. Batch_loss: 1.208006 \n",
      "Batch: 4687. Acc: 0.549514. Loss: 1.243184. Batch_acc: 0.537559. Batch_loss: 1.253079 \n",
      "[Training]  loss: 1.2431835914202707, ppl:  3.466632, accuracy: 54.951 %, elapse: 3583402.606ms\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "                                                                                             \r"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[interpolate]  loss: 1.1629543230186625,  ppl:  3.19937, accuracy: 58.333 %, elapse: 35641.791ms\n",
      "Building checkpoint..\n",
      "Save checkpoint time: 1205.8935165405273ms\n",
      "[ Epoch: 6 / 8, Run Batch: 28128 / None]\n",
      "Batch: 0. Acc: 0.569476. Loss: 1.210290. Batch_acc: 0.569476. Batch_loss: 1.210290 \n",
      "Batch: 1. Acc: 0.565674. Loss: 1.205622. Batch_acc: 0.561899. Batch_loss: 1.200989 \n",
      "Batch: 2. Acc: 0.562811. Loss: 1.220387. Batch_acc: 0.556865. Batch_loss: 1.251056 \n",
      "Batch: 3. Acc: 0.562304. Loss: 1.218990. Batch_acc: 0.560811. Batch_loss: 1.214882 \n",
      "Batch: 4. Acc: 0.558739. Loss: 1.228426. Batch_acc: 0.544296. Batch_loss: 1.266665 \n",
      "Batch: 5. Acc: 0.559889. Loss: 1.221076. Batch_acc: 0.565668. Batch_loss: 1.184131 \n",
      "Batch: 6. Acc: 0.560725. Loss: 1.215304. Batch_acc: 0.565797. Batch_loss: 1.180304 \n",
      "Batch: 7. Acc: 0.559047. Loss: 1.215963. Batch_acc: 0.547374. Batch_loss: 1.220544 \n",
      "Batch: 8. Acc: 0.560367. Loss: 1.212407. Batch_acc: 0.570781. Batch_loss: 1.184344 \n",
      "Batch: 9. Acc: 0.561583. Loss: 1.208483. Batch_acc: 0.572489. Batch_loss: 1.173309 \n",
      "Batch: 10. Acc: 0.560589. Loss: 1.208078. Batch_acc: 0.550410. Batch_loss: 1.203940 \n",
      "Batch: 11. Acc: 0.561182. Loss: 1.207896. Batch_acc: 0.567836. Batch_loss: 1.205854 \n",
      "Batch: 12. Acc: 0.563020. Loss: 1.203718. Batch_acc: 0.585480. Batch_loss: 1.152654 \n",
      "Batch: 13. Acc: 0.562933. Loss: 1.203552. Batch_acc: 0.561841. Batch_loss: 1.201474 \n",
      "Batch: 14. Acc: 0.563074. Loss: 1.202915. Batch_acc: 0.565020. Batch_loss: 1.194106 \n",
      "Batch: 15. Acc: 0.562617. Loss: 1.203953. Batch_acc: 0.555621. Batch_loss: 1.219834 \n",
      "Batch: 16. Acc: 0.562032. Loss: 1.204415. Batch_acc: 0.552398. Batch_loss: 1.212031 \n",
      "Batch: 17. Acc: 0.560671. Loss: 1.208221. Batch_acc: 0.537253. Batch_loss: 1.273671 \n",
      "Batch: 18. Acc: 0.559921. Loss: 1.210068. Batch_acc: 0.546350. Batch_loss: 1.243523 \n",
      "Batch: 19. Acc: 0.560008. Loss: 1.208944. Batch_acc: 0.561644. Batch_loss: 1.187771 \n",
      "Batch: 20. Acc: 0.559242. Loss: 1.210508. Batch_acc: 0.543644. Batch_loss: 1.242336 \n",
      "Batch: 21. Acc: 0.558809. Loss: 1.211389. Batch_acc: 0.549741. Batch_loss: 1.229853 \n",
      "Batch: 22. Acc: 0.559558. Loss: 1.210262. Batch_acc: 0.576625. Batch_loss: 1.184613 \n",
      "Batch: 23. Acc: 0.559139. Loss: 1.212196. Batch_acc: 0.549067. Batch_loss: 1.258603 \n",
      "Batch: 24. Acc: 0.559299. Loss: 1.211883. Batch_acc: 0.563198. Batch_loss: 1.204239 \n",
      "Batch: 25. Acc: 0.559801. Loss: 1.211723. Batch_acc: 0.571906. Batch_loss: 1.207860 \n",
      "Batch: 26. Acc: 0.560178. Loss: 1.210538. Batch_acc: 0.570093. Batch_loss: 1.179394 \n",
      "Batch: 27. Acc: 0.560102. Loss: 1.210787. Batch_acc: 0.558001. Batch_loss: 1.217695 \n",
      "Batch: 28. Acc: 0.561077. Loss: 1.208216. Batch_acc: 0.587934. Batch_loss: 1.137374 \n",
      "Batch: 29. Acc: 0.560860. Loss: 1.208467. Batch_acc: 0.554524. Batch_loss: 1.215790 \n",
      "Batch: 30. Acc: 0.560858. Loss: 1.208311. Batch_acc: 0.560822. Batch_loss: 1.203692 \n",
      "Batch: 31. Acc: 0.560856. Loss: 1.208317. Batch_acc: 0.560795. Batch_loss: 1.208485 \n",
      "Batch: 32. Acc: 0.561284. Loss: 1.207596. Batch_acc: 0.575087. Batch_loss: 1.184356 \n",
      "Batch: 33. Acc: 0.561178. Loss: 1.207806. Batch_acc: 0.557590. Batch_loss: 1.214894 \n",
      "Batch: 34. Acc: 0.561274. Loss: 1.208231. Batch_acc: 0.564622. Batch_loss: 1.223095 \n",
      "Batch: 35. Acc: 0.561134. Loss: 1.207956. Batch_acc: 0.556203. Batch_loss: 1.198272 \n",
      "Batch: 36. Acc: 0.561736. Loss: 1.206719. Batch_acc: 0.583238. Batch_loss: 1.162568 \n",
      "Batch: 37. Acc: 0.561250. Loss: 1.207961. Batch_acc: 0.543478. Batch_loss: 1.253370 \n",
      "Batch: 38. Acc: 0.561936. Loss: 1.206767. Batch_acc: 0.587664. Batch_loss: 1.161979 \n",
      "Batch: 39. Acc: 0.561450. Loss: 1.208122. Batch_acc: 0.542323. Batch_loss: 1.261466 \n",
      "Batch: 40. Acc: 0.561344. Loss: 1.208895. Batch_acc: 0.557143. Batch_loss: 1.239474 \n",
      "Batch: 41. Acc: 0.560993. Loss: 1.209503. Batch_acc: 0.546946. Batch_loss: 1.233873 \n",
      "Batch: 42. Acc: 0.560132. Loss: 1.211323. Batch_acc: 0.524646. Batch_loss: 1.286273 \n",
      "Batch: 43. Acc: 0.560862. Loss: 1.209647. Batch_acc: 0.591446. Batch_loss: 1.139414 \n",
      "Batch: 44. Acc: 0.561143. Loss: 1.208788. Batch_acc: 0.573198. Batch_loss: 1.171914 \n",
      "Batch: 45. Acc: 0.560751. Loss: 1.209789. Batch_acc: 0.543266. Batch_loss: 1.254568 \n",
      "Batch: 46. Acc: 0.560329. Loss: 1.210544. Batch_acc: 0.541290. Batch_loss: 1.244583 \n",
      "Batch: 47. Acc: 0.560293. Loss: 1.210450. Batch_acc: 0.558625. Batch_loss: 1.206130 \n",
      "Batch: 48. Acc: 0.559992. Loss: 1.211231. Batch_acc: 0.545662. Batch_loss: 1.248366 \n",
      "Batch: 49. Acc: 0.559517. Loss: 1.211887. Batch_acc: 0.536723. Batch_loss: 1.243413 \n",
      "Batch: 50. Acc: 0.559405. Loss: 1.211802. Batch_acc: 0.553646. Batch_loss: 1.207417 \n",
      "Batch: 51. Acc: 0.559216. Loss: 1.212391. Batch_acc: 0.549476. Batch_loss: 1.242718 \n",
      "Batch: 52. Acc: 0.559286. Loss: 1.212590. Batch_acc: 0.562891. Batch_loss: 1.222831 \n",
      "Batch: 53. Acc: 0.559822. Loss: 1.211655. Batch_acc: 0.588824. Batch_loss: 1.161063 \n",
      "Batch: 54. Acc: 0.560127. Loss: 1.210798. Batch_acc: 0.576166. Batch_loss: 1.165655 \n",
      "Batch: 55. Acc: 0.559641. Loss: 1.211823. Batch_acc: 0.532754. Batch_loss: 1.268535 \n",
      "Batch: 56. Acc: 0.559539. Loss: 1.212385. Batch_acc: 0.553924. Batch_loss: 1.243232 \n",
      "Batch: 57. Acc: 0.559321. Loss: 1.212980. Batch_acc: 0.546682. Batch_loss: 1.247557 \n",
      "Batch: 58. Acc: 0.559767. Loss: 1.212139. Batch_acc: 0.586066. Batch_loss: 1.162566 \n",
      "Batch: 59. Acc: 0.560067. Loss: 1.211964. Batch_acc: 0.577791. Batch_loss: 1.201595 \n",
      "Batch: 60. Acc: 0.560107. Loss: 1.211865. Batch_acc: 0.562500. Batch_loss: 1.206049 \n",
      "Batch: 61. Acc: 0.560209. Loss: 1.211686. Batch_acc: 0.566306. Batch_loss: 1.200869 \n",
      "Batch: 62. Acc: 0.560112. Loss: 1.211307. Batch_acc: 0.554147. Batch_loss: 1.187810 \n",
      "Batch: 63. Acc: 0.560113. Loss: 1.211041. Batch_acc: 0.560180. Batch_loss: 1.194698 \n",
      "Batch: 64. Acc: 0.560414. Loss: 1.210494. Batch_acc: 0.580094. Batch_loss: 1.174682 \n",
      "Batch: 65. Acc: 0.560219. Loss: 1.211414. Batch_acc: 0.547767. Batch_loss: 1.270096 \n",
      "Batch: 66. Acc: 0.560345. Loss: 1.210553. Batch_acc: 0.568639. Batch_loss: 1.153877 \n",
      "Batch: 67. Acc: 0.560384. Loss: 1.210970. Batch_acc: 0.563045. Batch_loss: 1.239200 \n",
      "Batch: 68. Acc: 0.560226. Loss: 1.211028. Batch_acc: 0.549631. Batch_loss: 1.214870 \n",
      "Batch: 69. Acc: 0.559978. Loss: 1.211177. Batch_acc: 0.542262. Batch_loss: 1.221848 \n",
      "Batch: 70. Acc: 0.560013. Loss: 1.211629. Batch_acc: 0.562464. Batch_loss: 1.242930 \n",
      "Batch: 71. Acc: 0.559923. Loss: 1.211627. Batch_acc: 0.553415. Batch_loss: 1.211489 \n",
      "Batch: 72. Acc: 0.559626. Loss: 1.212687. Batch_acc: 0.537967. Batch_loss: 1.290012 \n",
      "Batch: 73. Acc: 0.559662. Loss: 1.212643. Batch_acc: 0.562284. Batch_loss: 1.209471 \n",
      "Batch: 74. Acc: 0.559264. Loss: 1.213644. Batch_acc: 0.529919. Batch_loss: 1.287605 \n",
      "Batch: 75. Acc: 0.559061. Loss: 1.213863. Batch_acc: 0.543414. Batch_loss: 1.230653 \n",
      "Batch: 76. Acc: 0.559152. Loss: 1.213247. Batch_acc: 0.566016. Batch_loss: 1.166640 \n",
      "Batch: 77. Acc: 0.559229. Loss: 1.213229. Batch_acc: 0.565045. Batch_loss: 1.211866 \n",
      "Batch: 78. Acc: 0.559331. Loss: 1.212708. Batch_acc: 0.567039. Batch_loss: 1.173303 \n",
      "Batch: 79. Acc: 0.559478. Loss: 1.212291. Batch_acc: 0.570864. Batch_loss: 1.180023 \n",
      "Batch: 80. Acc: 0.559262. Loss: 1.213103. Batch_acc: 0.541740. Batch_loss: 1.278946 \n",
      "Batch: 81. Acc: 0.559170. Loss: 1.213471. Batch_acc: 0.551704. Batch_loss: 1.243350 \n",
      "Batch: 82. Acc: 0.558999. Loss: 1.214217. Batch_acc: 0.544872. Batch_loss: 1.276155 \n",
      "Batch: 83. Acc: 0.559091. Loss: 1.214106. Batch_acc: 0.566572. Batch_loss: 1.205015 \n",
      "Batch: 84. Acc: 0.559155. Loss: 1.213935. Batch_acc: 0.564563. Batch_loss: 1.199489 \n",
      "Batch: 85. Acc: 0.559298. Loss: 1.213841. Batch_acc: 0.571511. Batch_loss: 1.205835 \n",
      "Batch: 86. Acc: 0.559341. Loss: 1.213691. Batch_acc: 0.562918. Batch_loss: 1.201243 \n",
      "Batch: 87. Acc: 0.559439. Loss: 1.213312. Batch_acc: 0.567688. Batch_loss: 1.181395 \n",
      "Batch: 88. Acc: 0.559528. Loss: 1.213147. Batch_acc: 0.567442. Batch_loss: 1.198421 \n",
      "Batch: 89. Acc: 0.559327. Loss: 1.213493. Batch_acc: 0.541427. Batch_loss: 1.244352 \n",
      "Batch: 90. Acc: 0.559195. Loss: 1.213684. Batch_acc: 0.547246. Batch_loss: 1.230920 \n",
      "Batch: 91. Acc: 0.559261. Loss: 1.213590. Batch_acc: 0.565396. Batch_loss: 1.204938 \n",
      "Batch: 92. Acc: 0.559158. Loss: 1.213791. Batch_acc: 0.549714. Batch_loss: 1.232092 \n",
      "Batch: 93. Acc: 0.559363. Loss: 1.213369. Batch_acc: 0.579041. Batch_loss: 1.173042 \n",
      "Batch: 94. Acc: 0.559396. Loss: 1.213403. Batch_acc: 0.562428. Batch_loss: 1.216528 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 95. Acc: 0.559361. Loss: 1.213564. Batch_acc: 0.555950. Batch_loss: 1.229369 \n",
      "Batch: 96. Acc: 0.559377. Loss: 1.213553. Batch_acc: 0.560890. Batch_loss: 1.212439 \n",
      "Batch: 97. Acc: 0.559294. Loss: 1.213484. Batch_acc: 0.551348. Batch_loss: 1.206810 \n",
      "Batch: 98. Acc: 0.559158. Loss: 1.213832. Batch_acc: 0.545614. Batch_loss: 1.248477 \n",
      "Batch: 99. Acc: 0.559197. Loss: 1.213788. Batch_acc: 0.562963. Batch_loss: 1.209471 \n",
      "Batch: 100. Acc: 0.559095. Loss: 1.213909. Batch_acc: 0.548907. Batch_loss: 1.225980 \n",
      "Batch: 101. Acc: 0.558972. Loss: 1.214066. Batch_acc: 0.546936. Batch_loss: 1.229539 \n",
      "Batch: 102. Acc: 0.558953. Loss: 1.214110. Batch_acc: 0.557055. Batch_loss: 1.218458 \n",
      "Batch: 103. Acc: 0.559062. Loss: 1.213751. Batch_acc: 0.569983. Batch_loss: 1.177721 \n",
      "Batch: 104. Acc: 0.559072. Loss: 1.213796. Batch_acc: 0.560116. Batch_loss: 1.218459 \n",
      "Batch: 105. Acc: 0.559233. Loss: 1.213604. Batch_acc: 0.576232. Batch_loss: 1.193349 \n",
      "Batch: 106. Acc: 0.559210. Loss: 1.213576. Batch_acc: 0.556725. Batch_loss: 1.210564 \n",
      "Batch: 107. Acc: 0.559164. Loss: 1.213721. Batch_acc: 0.554279. Batch_loss: 1.229164 \n",
      "Batch: 108. Acc: 0.559350. Loss: 1.213312. Batch_acc: 0.579526. Batch_loss: 1.168975 \n",
      "Batch: 109. Acc: 0.559233. Loss: 1.213613. Batch_acc: 0.546787. Batch_loss: 1.245748 \n",
      "Batch: 110. Acc: 0.559278. Loss: 1.213541. Batch_acc: 0.564147. Batch_loss: 1.205649 \n",
      "Batch: 111. Acc: 0.559250. Loss: 1.213828. Batch_acc: 0.556147. Batch_loss: 1.246483 \n",
      "Batch: 112. Acc: 0.559291. Loss: 1.213881. Batch_acc: 0.563770. Batch_loss: 1.219753 \n",
      "Batch: 113. Acc: 0.559248. Loss: 1.214147. Batch_acc: 0.554238. Batch_loss: 1.245079 \n",
      "Batch: 114. Acc: 0.559095. Loss: 1.214513. Batch_acc: 0.542088. Batch_loss: 1.255090 \n",
      "Batch: 115. Acc: 0.559067. Loss: 1.214535. Batch_acc: 0.555811. Batch_loss: 1.217071 \n",
      "Batch: 116. Acc: 0.558902. Loss: 1.214908. Batch_acc: 0.539747. Batch_loss: 1.258203 \n",
      "Batch: 117. Acc: 0.558742. Loss: 1.215440. Batch_acc: 0.538977. Batch_loss: 1.281235 \n",
      "Batch: 118. Acc: 0.558648. Loss: 1.215720. Batch_acc: 0.547687. Batch_loss: 1.248509 \n",
      "Batch: 119. Acc: 0.558715. Loss: 1.215661. Batch_acc: 0.566516. Batch_loss: 1.208770 \n",
      "Batch: 120. Acc: 0.558730. Loss: 1.215665. Batch_acc: 0.560458. Batch_loss: 1.216140 \n",
      "Batch: 121. Acc: 0.559069. Loss: 1.214663. Batch_acc: 0.600000. Batch_loss: 1.093763 \n",
      "Batch: 122. Acc: 0.559103. Loss: 1.214714. Batch_acc: 0.563244. Batch_loss: 1.220803 \n",
      "Batch: 123. Acc: 0.559054. Loss: 1.214922. Batch_acc: 0.552788. Batch_loss: 1.241303 \n",
      "Batch: 124. Acc: 0.558977. Loss: 1.215124. Batch_acc: 0.549575. Batch_loss: 1.239766 \n",
      "Batch: 125. Acc: 0.558876. Loss: 1.215235. Batch_acc: 0.545940. Batch_loss: 1.229451 \n",
      "Batch: 126. Acc: 0.558815. Loss: 1.215384. Batch_acc: 0.550948. Batch_loss: 1.234656 \n",
      "Batch: 127. Acc: 0.558935. Loss: 1.214976. Batch_acc: 0.574160. Batch_loss: 1.162902 \n",
      "Batch: 128. Acc: 0.559162. Loss: 1.214345. Batch_acc: 0.587834. Batch_loss: 1.134720 \n",
      "Batch: 129. Acc: 0.559331. Loss: 1.214035. Batch_acc: 0.581089. Batch_loss: 1.174271 \n",
      "Batch: 130. Acc: 0.559333. Loss: 1.214236. Batch_acc: 0.559606. Batch_loss: 1.240426 \n",
      "Batch: 131. Acc: 0.559185. Loss: 1.214561. Batch_acc: 0.540080. Batch_loss: 1.256551 \n",
      "Batch: 132. Acc: 0.559183. Loss: 1.214697. Batch_acc: 0.558840. Batch_loss: 1.232454 \n",
      "Batch: 133. Acc: 0.559146. Loss: 1.214861. Batch_acc: 0.554203. Batch_loss: 1.236795 \n",
      "Batch: 134. Acc: 0.559101. Loss: 1.214876. Batch_acc: 0.553030. Batch_loss: 1.216949 \n",
      "Batch: 135. Acc: 0.559032. Loss: 1.214888. Batch_acc: 0.549830. Batch_loss: 1.216417 \n",
      "Batch: 136. Acc: 0.559278. Loss: 1.214019. Batch_acc: 0.592466. Batch_loss: 1.096892 \n",
      "Batch: 137. Acc: 0.559493. Loss: 1.213568. Batch_acc: 0.588673. Batch_loss: 1.152232 \n",
      "Batch: 138. Acc: 0.559621. Loss: 1.213186. Batch_acc: 0.577367. Batch_loss: 1.160286 \n",
      "Batch: 139. Acc: 0.559556. Loss: 1.213282. Batch_acc: 0.550658. Batch_loss: 1.226562 \n",
      "Batch: 140. Acc: 0.559443. Loss: 1.213565. Batch_acc: 0.543210. Batch_loss: 1.254102 \n",
      "Batch: 141. Acc: 0.559480. Loss: 1.213494. Batch_acc: 0.564788. Batch_loss: 1.203294 \n",
      "Batch: 142. Acc: 0.559387. Loss: 1.213838. Batch_acc: 0.546136. Batch_loss: 1.262727 \n",
      "Batch: 143. Acc: 0.559351. Loss: 1.213752. Batch_acc: 0.554147. Batch_loss: 1.201550 \n",
      "Batch: 144. Acc: 0.559371. Loss: 1.213781. Batch_acc: 0.562463. Batch_loss: 1.218078 \n",
      "Batch: 145. Acc: 0.559372. Loss: 1.213742. Batch_acc: 0.559504. Batch_loss: 1.208205 \n",
      "Batch: 146. Acc: 0.559568. Loss: 1.213197. Batch_acc: 0.587409. Batch_loss: 1.135528 \n",
      "Batch: 147. Acc: 0.559757. Loss: 1.212818. Batch_acc: 0.587429. Batch_loss: 1.157579 \n",
      "Batch: 148. Acc: 0.559535. Loss: 1.213344. Batch_acc: 0.524848. Batch_loss: 1.295214 \n",
      "Batch: 149. Acc: 0.559641. Loss: 1.213044. Batch_acc: 0.575548. Batch_loss: 1.168320 \n",
      "Batch: 150. Acc: 0.559602. Loss: 1.213105. Batch_acc: 0.553529. Batch_loss: 1.222364 \n",
      "Batch: 151. Acc: 0.559718. Loss: 1.212775. Batch_acc: 0.577010. Batch_loss: 1.163846 \n",
      "Batch: 152. Acc: 0.559688. Loss: 1.212724. Batch_acc: 0.554896. Batch_loss: 1.204750 \n",
      "Batch: 153. Acc: 0.559632. Loss: 1.213081. Batch_acc: 0.550961. Batch_loss: 1.268275 \n",
      "Batch: 154. Acc: 0.559604. Loss: 1.213187. Batch_acc: 0.555294. Batch_loss: 1.229831 \n",
      "Batch: 155. Acc: 0.559707. Loss: 1.213016. Batch_acc: 0.575723. Batch_loss: 1.186468 \n",
      "Batch: 156. Acc: 0.559635. Loss: 1.213197. Batch_acc: 0.548179. Batch_loss: 1.242048 \n",
      "Batch: 157. Acc: 0.559605. Loss: 1.213224. Batch_acc: 0.554787. Batch_loss: 1.217459 \n",
      "Batch: 158. Acc: 0.559597. Loss: 1.213437. Batch_acc: 0.558411. Batch_loss: 1.247507 \n",
      "Batch: 159. Acc: 0.559615. Loss: 1.213435. Batch_acc: 0.562500. Batch_loss: 1.213024 \n",
      "Batch: 160. Acc: 0.559561. Loss: 1.213479. Batch_acc: 0.550793. Batch_loss: 1.220722 \n",
      "Batch: 161. Acc: 0.559632. Loss: 1.213151. Batch_acc: 0.570857. Batch_loss: 1.160749 \n",
      "Batch: 162. Acc: 0.559557. Loss: 1.213286. Batch_acc: 0.547399. Batch_loss: 1.235311 \n",
      "Batch: 163. Acc: 0.559439. Loss: 1.213650. Batch_acc: 0.540035. Batch_loss: 1.273819 \n",
      "Batch: 164. Acc: 0.559358. Loss: 1.213811. Batch_acc: 0.546275. Batch_loss: 1.239595 \n",
      "Batch: 165. Acc: 0.559303. Loss: 1.214017. Batch_acc: 0.550117. Batch_loss: 1.248324 \n",
      "Batch: 166. Acc: 0.559296. Loss: 1.214125. Batch_acc: 0.558207. Batch_loss: 1.232202 \n",
      "Batch: 167. Acc: 0.559310. Loss: 1.214062. Batch_acc: 0.561588. Batch_loss: 1.203563 \n",
      "Batch: 168. Acc: 0.559311. Loss: 1.214126. Batch_acc: 0.559585. Batch_loss: 1.224802 \n",
      "Batch: 169. Acc: 0.559350. Loss: 1.214120. Batch_acc: 0.566038. Batch_loss: 1.213085 \n",
      "Batch: 170. Acc: 0.559407. Loss: 1.214002. Batch_acc: 0.568839. Batch_loss: 1.194327 \n",
      "Batch: 171. Acc: 0.559364. Loss: 1.213972. Batch_acc: 0.552023. Batch_loss: 1.208705 \n",
      "Batch: 172. Acc: 0.559284. Loss: 1.213976. Batch_acc: 0.545455. Batch_loss: 1.214818 \n",
      "Batch: 173. Acc: 0.559261. Loss: 1.213956. Batch_acc: 0.555302. Batch_loss: 1.210549 \n",
      "Batch: 174. Acc: 0.559067. Loss: 1.214503. Batch_acc: 0.525000. Batch_loss: 1.310368 \n",
      "Batch: 175. Acc: 0.559211. Loss: 1.214256. Batch_acc: 0.583754. Batch_loss: 1.172243 \n",
      "Batch: 176. Acc: 0.559069. Loss: 1.214616. Batch_acc: 0.533174. Batch_loss: 1.280371 \n",
      "Batch: 177. Acc: 0.558970. Loss: 1.214751. Batch_acc: 0.541379. Batch_loss: 1.238569 \n",
      "Batch: 178. Acc: 0.558987. Loss: 1.214598. Batch_acc: 0.562175. Batch_loss: 1.187326 \n",
      "Batch: 179. Acc: 0.558883. Loss: 1.214826. Batch_acc: 0.540556. Batch_loss: 1.254836 \n",
      "Batch: 180. Acc: 0.558982. Loss: 1.214423. Batch_acc: 0.576111. Batch_loss: 1.144596 \n",
      "Batch: 181. Acc: 0.558866. Loss: 1.214776. Batch_acc: 0.537609. Batch_loss: 1.279313 \n",
      "Batch: 182. Acc: 0.558782. Loss: 1.214949. Batch_acc: 0.543810. Batch_loss: 1.245828 \n",
      "Batch: 183. Acc: 0.558842. Loss: 1.214699. Batch_acc: 0.569707. Batch_loss: 1.169262 \n",
      "Batch: 184. Acc: 0.558928. Loss: 1.214475. Batch_acc: 0.574812. Batch_loss: 1.173202 \n",
      "Batch: 185. Acc: 0.559016. Loss: 1.214245. Batch_acc: 0.574887. Batch_loss: 1.172586 \n",
      "Batch: 186. Acc: 0.558971. Loss: 1.214407. Batch_acc: 0.550581. Batch_loss: 1.244894 \n",
      "Batch: 187. Acc: 0.559093. Loss: 1.214241. Batch_acc: 0.582398. Batch_loss: 1.182320 \n",
      "Batch: 188. Acc: 0.559014. Loss: 1.214400. Batch_acc: 0.544582. Batch_loss: 1.243627 \n",
      "Batch: 189. Acc: 0.559164. Loss: 1.214048. Batch_acc: 0.586496. Batch_loss: 1.149668 \n",
      "Batch: 190. Acc: 0.559076. Loss: 1.214100. Batch_acc: 0.542776. Batch_loss: 1.223817 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 191. Acc: 0.559040. Loss: 1.214135. Batch_acc: 0.552119. Batch_loss: 1.220784 \n",
      "Batch: 192. Acc: 0.559166. Loss: 1.213805. Batch_acc: 0.583873. Batch_loss: 1.149223 \n",
      "Batch: 193. Acc: 0.559280. Loss: 1.213533. Batch_acc: 0.581221. Batch_loss: 1.160992 \n",
      "Batch: 194. Acc: 0.559235. Loss: 1.213621. Batch_acc: 0.550575. Batch_loss: 1.230644 \n",
      "Batch: 195. Acc: 0.559312. Loss: 1.213300. Batch_acc: 0.574212. Batch_loss: 1.151086 \n",
      "Batch: 196. Acc: 0.559276. Loss: 1.213292. Batch_acc: 0.552392. Batch_loss: 1.211628 \n",
      "Batch: 197. Acc: 0.559180. Loss: 1.213512. Batch_acc: 0.540023. Batch_loss: 1.257138 \n",
      "Batch: 198. Acc: 0.559233. Loss: 1.213337. Batch_acc: 0.569635. Batch_loss: 1.179044 \n",
      "Batch: 199. Acc: 0.559320. Loss: 1.213086. Batch_acc: 0.576444. Batch_loss: 1.163996 \n",
      "Batch: 200. Acc: 0.559328. Loss: 1.213107. Batch_acc: 0.560961. Batch_loss: 1.217496 \n",
      "Batch: 201. Acc: 0.559455. Loss: 1.212796. Batch_acc: 0.584563. Batch_loss: 1.151154 \n",
      "Batch: 202. Acc: 0.559570. Loss: 1.212520. Batch_acc: 0.582386. Batch_loss: 1.157510 \n",
      "Batch: 203. Acc: 0.559661. Loss: 1.212352. Batch_acc: 0.577816. Batch_loss: 1.178868 \n",
      "Batch: 204. Acc: 0.559684. Loss: 1.212355. Batch_acc: 0.564498. Batch_loss: 1.213040 \n",
      "Batch: 205. Acc: 0.559587. Loss: 1.212670. Batch_acc: 0.539610. Batch_loss: 1.277039 \n",
      "Batch: 206. Acc: 0.559624. Loss: 1.212475. Batch_acc: 0.567198. Batch_loss: 1.172794 \n",
      "Batch: 207. Acc: 0.559662. Loss: 1.212337. Batch_acc: 0.567476. Batch_loss: 1.184271 \n",
      "Batch: 208. Acc: 0.559772. Loss: 1.212168. Batch_acc: 0.582424. Batch_loss: 1.177213 \n",
      "Batch: 209. Acc: 0.559807. Loss: 1.212140. Batch_acc: 0.567285. Batch_loss: 1.206190 \n",
      "Batch: 210. Acc: 0.559838. Loss: 1.212181. Batch_acc: 0.566210. Batch_loss: 1.220642 \n",
      "Batch: 211. Acc: 0.559841. Loss: 1.212102. Batch_acc: 0.560484. Batch_loss: 1.195537 \n",
      "Batch: 212. Acc: 0.559866. Loss: 1.212024. Batch_acc: 0.565118. Batch_loss: 1.195495 \n",
      "Batch: 213. Acc: 0.559867. Loss: 1.212062. Batch_acc: 0.560161. Batch_loss: 1.220072 \n",
      "Batch: 214. Acc: 0.559870. Loss: 1.212117. Batch_acc: 0.560536. Batch_loss: 1.224039 \n",
      "Batch: 215. Acc: 0.559960. Loss: 1.211839. Batch_acc: 0.578858. Batch_loss: 1.153136 \n",
      "Batch: 216. Acc: 0.559968. Loss: 1.211785. Batch_acc: 0.561856. Batch_loss: 1.200349 \n",
      "Batch: 217. Acc: 0.560007. Loss: 1.211772. Batch_acc: 0.568651. Batch_loss: 1.208731 \n",
      "Batch: 218. Acc: 0.560011. Loss: 1.211712. Batch_acc: 0.560875. Batch_loss: 1.198281 \n",
      "Batch: 219. Acc: 0.559959. Loss: 1.211823. Batch_acc: 0.548627. Batch_loss: 1.236098 \n",
      "Batch: 220. Acc: 0.559954. Loss: 1.211952. Batch_acc: 0.558772. Batch_loss: 1.240364 \n",
      "Batch: 221. Acc: 0.559944. Loss: 1.211963. Batch_acc: 0.557847. Batch_loss: 1.214360 \n",
      "Batch: 222. Acc: 0.559968. Loss: 1.212003. Batch_acc: 0.565095. Batch_loss: 1.220636 \n",
      "Batch: 223. Acc: 0.559967. Loss: 1.211927. Batch_acc: 0.559863. Batch_loss: 1.195255 \n",
      "Batch: 224. Acc: 0.560022. Loss: 1.211883. Batch_acc: 0.572345. Batch_loss: 1.201977 \n",
      "Batch: 225. Acc: 0.559922. Loss: 1.212253. Batch_acc: 0.536972. Batch_loss: 1.297056 \n",
      "Batch: 226. Acc: 0.559927. Loss: 1.212255. Batch_acc: 0.561102. Batch_loss: 1.212669 \n",
      "Batch: 227. Acc: 0.559931. Loss: 1.212256. Batch_acc: 0.560850. Batch_loss: 1.212385 \n",
      "Batch: 228. Acc: 0.560023. Loss: 1.212115. Batch_acc: 0.580357. Batch_loss: 1.181018 \n",
      "Batch: 229. Acc: 0.560089. Loss: 1.211861. Batch_acc: 0.575014. Batch_loss: 1.154160 \n",
      "Batch: 230. Acc: 0.560078. Loss: 1.211951. Batch_acc: 0.557586. Batch_loss: 1.231970 \n",
      "Batch: 231. Acc: 0.560155. Loss: 1.211758. Batch_acc: 0.578271. Batch_loss: 1.166527 \n",
      "Batch: 232. Acc: 0.560170. Loss: 1.211832. Batch_acc: 0.563711. Batch_loss: 1.229396 \n",
      "Batch: 233. Acc: 0.560048. Loss: 1.212152. Batch_acc: 0.532322. Batch_loss: 1.284806 \n",
      "Batch: 234. Acc: 0.559995. Loss: 1.212122. Batch_acc: 0.547633. Batch_loss: 1.205265 \n",
      "Batch: 235. Acc: 0.559889. Loss: 1.212358. Batch_acc: 0.535388. Batch_loss: 1.267296 \n",
      "Batch: 236. Acc: 0.559837. Loss: 1.212530. Batch_acc: 0.547578. Batch_loss: 1.252697 \n",
      "Batch: 237. Acc: 0.559822. Loss: 1.212498. Batch_acc: 0.556330. Batch_loss: 1.204873 \n",
      "Batch: 238. Acc: 0.559761. Loss: 1.212742. Batch_acc: 0.544924. Batch_loss: 1.271557 \n",
      "Batch: 239. Acc: 0.559715. Loss: 1.212880. Batch_acc: 0.548975. Batch_loss: 1.245389 \n",
      "Batch: 240. Acc: 0.559609. Loss: 1.213179. Batch_acc: 0.533174. Batch_loss: 1.287778 \n",
      "Batch: 241. Acc: 0.559682. Loss: 1.213020. Batch_acc: 0.576989. Batch_loss: 1.175051 \n",
      "Batch: 242. Acc: 0.559824. Loss: 1.212741. Batch_acc: 0.594161. Batch_loss: 1.145497 \n",
      "Batch: 243. Acc: 0.559802. Loss: 1.212734. Batch_acc: 0.554484. Batch_loss: 1.211162 \n",
      "Batch: 244. Acc: 0.559819. Loss: 1.212782. Batch_acc: 0.564044. Batch_loss: 1.224462 \n",
      "Batch: 245. Acc: 0.560052. Loss: 1.212150. Batch_acc: 0.615730. Batch_loss: 1.061065 \n",
      "Batch: 246. Acc: 0.559988. Loss: 1.212379. Batch_acc: 0.543660. Batch_loss: 1.270893 \n",
      "Batch: 247. Acc: 0.560043. Loss: 1.212325. Batch_acc: 0.573487. Batch_loss: 1.198882 \n",
      "Batch: 248. Acc: 0.559939. Loss: 1.212516. Batch_acc: 0.533800. Batch_loss: 1.260520 \n",
      "Batch: 249. Acc: 0.560009. Loss: 1.212415. Batch_acc: 0.577408. Batch_loss: 1.187302 \n",
      "Batch: 250. Acc: 0.560138. Loss: 1.212074. Batch_acc: 0.591779. Batch_loss: 1.128739 \n",
      "Batch: 251. Acc: 0.560211. Loss: 1.211835. Batch_acc: 0.577940. Batch_loss: 1.153228 \n",
      "Checkpointing on batch: 251. Accuracy: 0.5602105604664499. Loss per char: 1.2118350257733301. Time: 1627225616.2609172\n",
      "Last question is tensor([ 2, 34, 69, 69,  1, 85, 80, 72, 70, 85, 73, 70, 83,  1, 14, 21, 26, 21,\n",
      "        21, 24, 15, 25, 19, 17, 17, 24,  1, 66, 79, 69,  1, 14, 22, 24, 18, 18,\n",
      "        15,  3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790650\n",
      "Batch: 252. Acc: 0.560188. Loss: 1.211993. Batch_acc: 0.554380. Batch_loss: 1.252650 \n",
      "Batch: 253. Acc: 0.560185. Loss: 1.211819. Batch_acc: 0.559292. Batch_loss: 1.166713 \n",
      "Batch: 254. Acc: 0.560113. Loss: 1.211875. Batch_acc: 0.541569. Batch_loss: 1.226444 \n",
      "Batch: 255. Acc: 0.560021. Loss: 1.212091. Batch_acc: 0.536543. Batch_loss: 1.267383 \n",
      "Batch: 256. Acc: 0.560039. Loss: 1.212033. Batch_acc: 0.564826. Batch_loss: 1.196585 \n",
      "Batch: 257. Acc: 0.560138. Loss: 1.211786. Batch_acc: 0.585747. Batch_loss: 1.148098 \n",
      "Batch: 258. Acc: 0.560159. Loss: 1.211747. Batch_acc: 0.565469. Batch_loss: 1.201531 \n",
      "Batch: 259. Acc: 0.560127. Loss: 1.211909. Batch_acc: 0.551704. Batch_loss: 1.254598 \n",
      "Batch: 260. Acc: 0.560244. Loss: 1.211624. Batch_acc: 0.590778. Batch_loss: 1.137697 \n",
      "Batch: 261. Acc: 0.560323. Loss: 1.211419. Batch_acc: 0.580831. Batch_loss: 1.157729 \n",
      "Batch: 262. Acc: 0.560365. Loss: 1.211297. Batch_acc: 0.571188. Batch_loss: 1.180024 \n",
      "Batch: 263. Acc: 0.560352. Loss: 1.211271. Batch_acc: 0.556818. Batch_loss: 1.204645 \n",
      "Batch: 264. Acc: 0.560447. Loss: 1.210968. Batch_acc: 0.585366. Batch_loss: 1.132193 \n",
      "Batch: 265. Acc: 0.560446. Loss: 1.210996. Batch_acc: 0.560047. Batch_loss: 1.218477 \n",
      "Batch: 266. Acc: 0.560471. Loss: 1.210999. Batch_acc: 0.567207. Batch_loss: 1.211851 \n",
      "Batch: 267. Acc: 0.560438. Loss: 1.211033. Batch_acc: 0.551505. Batch_loss: 1.220230 \n",
      "Batch: 268. Acc: 0.560451. Loss: 1.211034. Batch_acc: 0.564087. Batch_loss: 1.211241 \n",
      "Batch: 269. Acc: 0.560460. Loss: 1.210996. Batch_acc: 0.562963. Batch_loss: 1.201004 \n",
      "Batch: 270. Acc: 0.560472. Loss: 1.210989. Batch_acc: 0.563657. Batch_loss: 1.209067 \n",
      "Batch: 271. Acc: 0.560451. Loss: 1.211018. Batch_acc: 0.554923. Batch_loss: 1.218629 \n",
      "Batch: 272. Acc: 0.560385. Loss: 1.211149. Batch_acc: 0.542793. Batch_loss: 1.246028 \n",
      "Batch: 273. Acc: 0.560352. Loss: 1.211246. Batch_acc: 0.551253. Batch_loss: 1.237415 \n",
      "Batch: 274. Acc: 0.560300. Loss: 1.211462. Batch_acc: 0.545882. Batch_loss: 1.272004 \n",
      "Batch: 275. Acc: 0.560258. Loss: 1.211491. Batch_acc: 0.548885. Batch_loss: 1.219368 \n",
      "Batch: 276. Acc: 0.560201. Loss: 1.211647. Batch_acc: 0.544005. Batch_loss: 1.255807 \n",
      "Batch: 277. Acc: 0.560173. Loss: 1.211615. Batch_acc: 0.552542. Batch_loss: 1.202916 \n",
      "Batch: 278. Acc: 0.560223. Loss: 1.211455. Batch_acc: 0.573864. Batch_loss: 1.167652 \n",
      "Batch: 279. Acc: 0.560235. Loss: 1.211386. Batch_acc: 0.563533. Batch_loss: 1.192330 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 280. Acc: 0.560290. Loss: 1.211256. Batch_acc: 0.576132. Batch_loss: 1.174077 \n",
      "Batch: 281. Acc: 0.560269. Loss: 1.211306. Batch_acc: 0.554478. Batch_loss: 1.225235 \n",
      "Batch: 282. Acc: 0.560307. Loss: 1.211130. Batch_acc: 0.570701. Batch_loss: 1.162297 \n",
      "Batch: 283. Acc: 0.560289. Loss: 1.211284. Batch_acc: 0.555164. Batch_loss: 1.255590 \n",
      "Batch: 284. Acc: 0.560274. Loss: 1.211322. Batch_acc: 0.555877. Batch_loss: 1.222175 \n",
      "Batch: 285. Acc: 0.560285. Loss: 1.211423. Batch_acc: 0.563529. Batch_loss: 1.241039 \n",
      "Batch: 286. Acc: 0.560332. Loss: 1.211345. Batch_acc: 0.574205. Batch_loss: 1.188375 \n",
      "Batch: 287. Acc: 0.560253. Loss: 1.211522. Batch_acc: 0.537305. Batch_loss: 1.262626 \n",
      "Batch: 288. Acc: 0.560247. Loss: 1.211549. Batch_acc: 0.558480. Batch_loss: 1.219496 \n",
      "Batch: 289. Acc: 0.560201. Loss: 1.211609. Batch_acc: 0.547116. Batch_loss: 1.228658 \n",
      "Batch: 290. Acc: 0.560181. Loss: 1.211543. Batch_acc: 0.554348. Batch_loss: 1.192568 \n",
      "Batch: 291. Acc: 0.560163. Loss: 1.211573. Batch_acc: 0.555109. Batch_loss: 1.220165 \n",
      "Batch: 292. Acc: 0.560265. Loss: 1.211239. Batch_acc: 0.590116. Batch_loss: 1.112972 \n",
      "Batch: 293. Acc: 0.560313. Loss: 1.211112. Batch_acc: 0.574157. Batch_loss: 1.174884 \n",
      "Batch: 294. Acc: 0.560386. Loss: 1.210968. Batch_acc: 0.581977. Batch_loss: 1.168139 \n",
      "Batch: 295. Acc: 0.560362. Loss: 1.211012. Batch_acc: 0.553142. Batch_loss: 1.224163 \n",
      "Batch: 296. Acc: 0.560368. Loss: 1.210984. Batch_acc: 0.562106. Batch_loss: 1.202928 \n",
      "Batch: 297. Acc: 0.560376. Loss: 1.210895. Batch_acc: 0.562929. Batch_loss: 1.184467 \n",
      "Batch: 298. Acc: 0.560314. Loss: 1.211056. Batch_acc: 0.542045. Batch_loss: 1.258524 \n",
      "Batch: 299. Acc: 0.560248. Loss: 1.211172. Batch_acc: 0.540587. Batch_loss: 1.245697 \n",
      "Batch: 300. Acc: 0.560372. Loss: 1.210815. Batch_acc: 0.595628. Batch_loss: 1.109239 \n",
      "Batch: 301. Acc: 0.560356. Loss: 1.210852. Batch_acc: 0.555298. Batch_loss: 1.222081 \n",
      "Batch: 302. Acc: 0.560362. Loss: 1.210790. Batch_acc: 0.562215. Batch_loss: 1.192178 \n",
      "Batch: 303. Acc: 0.560268. Loss: 1.210968. Batch_acc: 0.531952. Batch_loss: 1.264795 \n",
      "Batch: 304. Acc: 0.560254. Loss: 1.211073. Batch_acc: 0.555940. Batch_loss: 1.243166 \n",
      "Batch: 305. Acc: 0.560266. Loss: 1.211031. Batch_acc: 0.563884. Batch_loss: 1.198349 \n",
      "Batch: 306. Acc: 0.560226. Loss: 1.211224. Batch_acc: 0.548071. Batch_loss: 1.270260 \n",
      "Batch: 307. Acc: 0.560106. Loss: 1.211497. Batch_acc: 0.521765. Batch_loss: 1.298350 \n",
      "Batch: 308. Acc: 0.560080. Loss: 1.211524. Batch_acc: 0.552204. Batch_loss: 1.220033 \n",
      "Batch: 309. Acc: 0.560044. Loss: 1.211626. Batch_acc: 0.548885. Batch_loss: 1.242667 \n",
      "Batch: 310. Acc: 0.560077. Loss: 1.211498. Batch_acc: 0.570120. Batch_loss: 1.172025 \n",
      "Batch: 311. Acc: 0.560105. Loss: 1.211417. Batch_acc: 0.568672. Batch_loss: 1.186873 \n",
      "Batch: 312. Acc: 0.560162. Loss: 1.211270. Batch_acc: 0.577778. Batch_loss: 1.165823 \n",
      "Batch: 313. Acc: 0.560119. Loss: 1.211400. Batch_acc: 0.546713. Batch_loss: 1.252208 \n",
      "Batch: 314. Acc: 0.560177. Loss: 1.211111. Batch_acc: 0.578223. Batch_loss: 1.120842 \n",
      "Batch: 315. Acc: 0.560130. Loss: 1.211219. Batch_acc: 0.545348. Batch_loss: 1.245711 \n",
      "Batch: 316. Acc: 0.560156. Loss: 1.211135. Batch_acc: 0.568182. Batch_loss: 1.184339 \n",
      "Batch: 317. Acc: 0.560123. Loss: 1.211197. Batch_acc: 0.549654. Batch_loss: 1.230615 \n",
      "Batch: 318. Acc: 0.560089. Loss: 1.211269. Batch_acc: 0.549539. Batch_loss: 1.234199 \n",
      "Batch: 319. Acc: 0.560145. Loss: 1.211100. Batch_acc: 0.577378. Batch_loss: 1.158455 \n",
      "Batch: 320. Acc: 0.560095. Loss: 1.211256. Batch_acc: 0.543808. Batch_loss: 1.261846 \n",
      "Batch: 321. Acc: 0.560167. Loss: 1.211112. Batch_acc: 0.583721. Batch_loss: 1.164556 \n",
      "Batch: 322. Acc: 0.560188. Loss: 1.211020. Batch_acc: 0.567164. Batch_loss: 1.180378 \n",
      "Batch: 323. Acc: 0.560144. Loss: 1.211130. Batch_acc: 0.545769. Batch_loss: 1.246727 \n",
      "Batch: 324. Acc: 0.560156. Loss: 1.211140. Batch_acc: 0.564014. Batch_loss: 1.214125 \n",
      "Batch: 325. Acc: 0.560224. Loss: 1.210992. Batch_acc: 0.582200. Batch_loss: 1.163775 \n",
      "Batch: 326. Acc: 0.560221. Loss: 1.210935. Batch_acc: 0.559303. Batch_loss: 1.192748 \n",
      "Batch: 327. Acc: 0.560270. Loss: 1.210887. Batch_acc: 0.575982. Batch_loss: 1.195299 \n",
      "Batch: 328. Acc: 0.560285. Loss: 1.210780. Batch_acc: 0.565242. Batch_loss: 1.176329 \n",
      "Batch: 329. Acc: 0.560285. Loss: 1.210833. Batch_acc: 0.560093. Batch_loss: 1.228266 \n",
      "Batch: 330. Acc: 0.560265. Loss: 1.210850. Batch_acc: 0.553623. Batch_loss: 1.216672 \n",
      "Batch: 331. Acc: 0.560289. Loss: 1.210723. Batch_acc: 0.568391. Batch_loss: 1.168632 \n",
      "Batch: 332. Acc: 0.560269. Loss: 1.210797. Batch_acc: 0.553404. Batch_loss: 1.236039 \n",
      "Batch: 333. Acc: 0.560332. Loss: 1.210668. Batch_acc: 0.581275. Batch_loss: 1.167741 \n",
      "Batch: 334. Acc: 0.560391. Loss: 1.210492. Batch_acc: 0.579694. Batch_loss: 1.152442 \n",
      "Batch: 335. Acc: 0.560470. Loss: 1.210359. Batch_acc: 0.586919. Batch_loss: 1.166058 \n",
      "Batch: 336. Acc: 0.560479. Loss: 1.210357. Batch_acc: 0.563348. Batch_loss: 1.209675 \n",
      "Batch: 337. Acc: 0.560450. Loss: 1.210347. Batch_acc: 0.550555. Batch_loss: 1.207073 \n",
      "Batch: 338. Acc: 0.560437. Loss: 1.210312. Batch_acc: 0.556064. Batch_loss: 1.198305 \n",
      "Batch: 339. Acc: 0.560389. Loss: 1.210421. Batch_acc: 0.544126. Batch_loss: 1.248113 \n",
      "Batch: 340. Acc: 0.560386. Loss: 1.210388. Batch_acc: 0.559078. Batch_loss: 1.199189 \n",
      "Batch: 341. Acc: 0.560506. Loss: 1.210139. Batch_acc: 0.600907. Batch_loss: 1.126524 \n",
      "Batch: 342. Acc: 0.560536. Loss: 1.210054. Batch_acc: 0.570693. Batch_loss: 1.181265 \n",
      "Batch: 343. Acc: 0.560650. Loss: 1.209755. Batch_acc: 0.598762. Batch_loss: 1.109572 \n",
      "Batch: 344. Acc: 0.560669. Loss: 1.209760. Batch_acc: 0.567368. Batch_loss: 1.211247 \n",
      "Batch: 345. Acc: 0.560608. Loss: 1.209875. Batch_acc: 0.539090. Batch_loss: 1.250267 \n",
      "Batch: 346. Acc: 0.560678. Loss: 1.209690. Batch_acc: 0.585057. Batch_loss: 1.145763 \n",
      "Batch: 347. Acc: 0.560677. Loss: 1.209628. Batch_acc: 0.560159. Batch_loss: 1.188366 \n",
      "Batch: 348. Acc: 0.560731. Loss: 1.209476. Batch_acc: 0.579338. Batch_loss: 1.156882 \n",
      "Batch: 349. Acc: 0.560789. Loss: 1.209355. Batch_acc: 0.580903. Batch_loss: 1.167571 \n",
      "Batch: 350. Acc: 0.560792. Loss: 1.209354. Batch_acc: 0.562103. Batch_loss: 1.208826 \n",
      "Batch: 351. Acc: 0.560780. Loss: 1.209428. Batch_acc: 0.556287. Batch_loss: 1.236655 \n",
      "Batch: 352. Acc: 0.560830. Loss: 1.209258. Batch_acc: 0.578169. Batch_loss: 1.150026 \n",
      "Batch: 353. Acc: 0.560828. Loss: 1.209232. Batch_acc: 0.560114. Batch_loss: 1.200089 \n",
      "Batch: 354. Acc: 0.560779. Loss: 1.209274. Batch_acc: 0.542823. Batch_loss: 1.224650 \n",
      "Batch: 355. Acc: 0.560767. Loss: 1.209307. Batch_acc: 0.556647. Batch_loss: 1.221085 \n",
      "Batch: 356. Acc: 0.560773. Loss: 1.209256. Batch_acc: 0.562997. Batch_loss: 1.191265 \n",
      "Batch: 357. Acc: 0.560818. Loss: 1.209156. Batch_acc: 0.576726. Batch_loss: 1.173851 \n",
      "Batch: 358. Acc: 0.560915. Loss: 1.208939. Batch_acc: 0.595103. Batch_loss: 1.132043 \n",
      "Batch: 359. Acc: 0.560921. Loss: 1.208947. Batch_acc: 0.563164. Batch_loss: 1.212038 \n",
      "Batch: 360. Acc: 0.560913. Loss: 1.209016. Batch_acc: 0.557895. Batch_loss: 1.234131 \n",
      "Batch: 361. Acc: 0.560869. Loss: 1.209140. Batch_acc: 0.545248. Batch_loss: 1.253360 \n",
      "Batch: 362. Acc: 0.560851. Loss: 1.209164. Batch_acc: 0.554189. Batch_loss: 1.217974 \n",
      "Batch: 363. Acc: 0.560938. Loss: 1.208945. Batch_acc: 0.591058. Batch_loss: 1.133772 \n",
      "Batch: 364. Acc: 0.561041. Loss: 1.208681. Batch_acc: 0.598604. Batch_loss: 1.111813 \n",
      "Batch: 365. Acc: 0.561048. Loss: 1.208633. Batch_acc: 0.563698. Batch_loss: 1.191245 \n",
      "Batch: 366. Acc: 0.561066. Loss: 1.208627. Batch_acc: 0.567708. Batch_loss: 1.206362 \n",
      "Batch: 367. Acc: 0.561082. Loss: 1.208565. Batch_acc: 0.567028. Batch_loss: 1.186051 \n",
      "Batch: 368. Acc: 0.561059. Loss: 1.208587. Batch_acc: 0.552265. Batch_loss: 1.216698 \n",
      "Batch: 369. Acc: 0.561092. Loss: 1.208530. Batch_acc: 0.573703. Batch_loss: 1.187181 \n",
      "Batch: 370. Acc: 0.561164. Loss: 1.208281. Batch_acc: 0.587995. Batch_loss: 1.115085 \n",
      "Batch: 371. Acc: 0.561176. Loss: 1.208217. Batch_acc: 0.565728. Batch_loss: 1.183803 \n",
      "Batch: 372. Acc: 0.561106. Loss: 1.208444. Batch_acc: 0.535179. Batch_loss: 1.293025 \n",
      "Batch: 373. Acc: 0.561041. Loss: 1.208520. Batch_acc: 0.536528. Batch_loss: 1.237449 \n",
      "Batch: 374. Acc: 0.561010. Loss: 1.208562. Batch_acc: 0.549425. Batch_loss: 1.224303 \n",
      "Batch: 375. Acc: 0.560950. Loss: 1.208735. Batch_acc: 0.538593. Batch_loss: 1.273147 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 376. Acc: 0.561012. Loss: 1.208520. Batch_acc: 0.584250. Batch_loss: 1.127259 \n",
      "Batch: 377. Acc: 0.560988. Loss: 1.208574. Batch_acc: 0.551845. Batch_loss: 1.229220 \n",
      "Batch: 378. Acc: 0.560963. Loss: 1.208594. Batch_acc: 0.551783. Batch_loss: 1.215817 \n",
      "Batch: 379. Acc: 0.560926. Loss: 1.208594. Batch_acc: 0.547062. Batch_loss: 1.208694 \n",
      "Batch: 380. Acc: 0.560953. Loss: 1.208524. Batch_acc: 0.571264. Batch_loss: 1.181802 \n",
      "Batch: 381. Acc: 0.560955. Loss: 1.208469. Batch_acc: 0.561353. Batch_loss: 1.187814 \n",
      "Batch: 382. Acc: 0.560926. Loss: 1.208560. Batch_acc: 0.549735. Batch_loss: 1.244078 \n",
      "Batch: 383. Acc: 0.560898. Loss: 1.208645. Batch_acc: 0.550029. Batch_loss: 1.241778 \n",
      "Batch: 384. Acc: 0.560946. Loss: 1.208541. Batch_acc: 0.579592. Batch_loss: 1.168041 \n",
      "Batch: 385. Acc: 0.560932. Loss: 1.208632. Batch_acc: 0.555491. Batch_loss: 1.243610 \n",
      "Batch: 386. Acc: 0.560959. Loss: 1.208587. Batch_acc: 0.571346. Batch_loss: 1.191411 \n",
      "Batch: 387. Acc: 0.560937. Loss: 1.208627. Batch_acc: 0.552370. Batch_loss: 1.224348 \n",
      "Batch: 388. Acc: 0.560891. Loss: 1.208701. Batch_acc: 0.542383. Batch_loss: 1.238199 \n",
      "Batch: 389. Acc: 0.561003. Loss: 1.208441. Batch_acc: 0.603966. Batch_loss: 1.108882 \n",
      "Batch: 390. Acc: 0.561009. Loss: 1.208383. Batch_acc: 0.563284. Batch_loss: 1.185871 \n",
      "Batch: 391. Acc: 0.560991. Loss: 1.208422. Batch_acc: 0.554210. Batch_loss: 1.223778 \n",
      "Batch: 392. Acc: 0.561026. Loss: 1.208425. Batch_acc: 0.575179. Batch_loss: 1.209702 \n",
      "Batch: 393. Acc: 0.561032. Loss: 1.208417. Batch_acc: 0.563339. Batch_loss: 1.205412 \n",
      "Batch: 394. Acc: 0.561027. Loss: 1.208413. Batch_acc: 0.559104. Batch_loss: 1.206727 \n",
      "Batch: 395. Acc: 0.561008. Loss: 1.208540. Batch_acc: 0.553643. Batch_loss: 1.258337 \n",
      "Batch: 396. Acc: 0.560976. Loss: 1.208539. Batch_acc: 0.548122. Batch_loss: 1.208432 \n",
      "Batch: 397. Acc: 0.560938. Loss: 1.208613. Batch_acc: 0.545817. Batch_loss: 1.237373 \n",
      "Batch: 398. Acc: 0.560965. Loss: 1.208525. Batch_acc: 0.571765. Batch_loss: 1.172788 \n",
      "Batch: 399. Acc: 0.560949. Loss: 1.208552. Batch_acc: 0.554787. Batch_loss: 1.219572 \n",
      "Batch: 400. Acc: 0.560998. Loss: 1.208394. Batch_acc: 0.580275. Batch_loss: 1.145409 \n",
      "Batch: 401. Acc: 0.561069. Loss: 1.208191. Batch_acc: 0.589582. Batch_loss: 1.127268 \n",
      "Batch: 402. Acc: 0.561043. Loss: 1.208227. Batch_acc: 0.550691. Batch_loss: 1.222597 \n",
      "Batch: 403. Acc: 0.561045. Loss: 1.208218. Batch_acc: 0.561683. Batch_loss: 1.204609 \n",
      "Batch: 404. Acc: 0.561082. Loss: 1.208169. Batch_acc: 0.576000. Batch_loss: 1.188692 \n",
      "Batch: 405. Acc: 0.561104. Loss: 1.208162. Batch_acc: 0.570160. Batch_loss: 1.205066 \n",
      "Batch: 406. Acc: 0.561160. Loss: 1.208026. Batch_acc: 0.583569. Batch_loss: 1.153918 \n",
      "Batch: 407. Acc: 0.561192. Loss: 1.207936. Batch_acc: 0.574042. Batch_loss: 1.171713 \n",
      "Batch: 408. Acc: 0.561177. Loss: 1.207931. Batch_acc: 0.555300. Batch_loss: 1.205677 \n",
      "Batch: 409. Acc: 0.561142. Loss: 1.207997. Batch_acc: 0.546518. Batch_loss: 1.235466 \n",
      "Batch: 410. Acc: 0.561080. Loss: 1.208177. Batch_acc: 0.535591. Batch_loss: 1.281827 \n",
      "Batch: 411. Acc: 0.561092. Loss: 1.208097. Batch_acc: 0.566244. Batch_loss: 1.175105 \n",
      "Batch: 412. Acc: 0.561115. Loss: 1.208063. Batch_acc: 0.570349. Batch_loss: 1.194002 \n",
      "Batch: 413. Acc: 0.561176. Loss: 1.207845. Batch_acc: 0.586168. Batch_loss: 1.119057 \n",
      "Batch: 414. Acc: 0.561216. Loss: 1.207782. Batch_acc: 0.578378. Batch_loss: 1.180488 \n",
      "Batch: 415. Acc: 0.561211. Loss: 1.207878. Batch_acc: 0.559400. Batch_loss: 1.247950 \n",
      "Batch: 416. Acc: 0.561254. Loss: 1.207809. Batch_acc: 0.578856. Batch_loss: 1.178904 \n",
      "Batch: 417. Acc: 0.561221. Loss: 1.207867. Batch_acc: 0.547660. Batch_loss: 1.232424 \n",
      "Batch: 418. Acc: 0.561223. Loss: 1.207826. Batch_acc: 0.561778. Batch_loss: 1.190665 \n",
      "Batch: 419. Acc: 0.561223. Loss: 1.207801. Batch_acc: 0.561414. Batch_loss: 1.197012 \n",
      "Batch: 420. Acc: 0.561223. Loss: 1.207774. Batch_acc: 0.561102. Batch_loss: 1.196606 \n",
      "Batch: 421. Acc: 0.561182. Loss: 1.207865. Batch_acc: 0.543768. Batch_loss: 1.246351 \n",
      "Batch: 422. Acc: 0.561200. Loss: 1.207847. Batch_acc: 0.568976. Batch_loss: 1.200000 \n",
      "Batch: 423. Acc: 0.561222. Loss: 1.207777. Batch_acc: 0.570768. Batch_loss: 1.178262 \n",
      "Batch: 424. Acc: 0.561246. Loss: 1.207751. Batch_acc: 0.571511. Batch_loss: 1.196644 \n",
      "Batch: 425. Acc: 0.561230. Loss: 1.207779. Batch_acc: 0.554118. Batch_loss: 1.219862 \n",
      "Batch: 426. Acc: 0.561243. Loss: 1.207655. Batch_acc: 0.567034. Batch_loss: 1.154391 \n",
      "Batch: 427. Acc: 0.561282. Loss: 1.207568. Batch_acc: 0.577441. Batch_loss: 1.171371 \n",
      "Batch: 428. Acc: 0.561310. Loss: 1.207512. Batch_acc: 0.573066. Batch_loss: 1.183891 \n",
      "Batch: 429. Acc: 0.561324. Loss: 1.207499. Batch_acc: 0.567164. Batch_loss: 1.202009 \n",
      "Batch: 430. Acc: 0.561353. Loss: 1.207444. Batch_acc: 0.573789. Batch_loss: 1.184084 \n",
      "Batch: 431. Acc: 0.561382. Loss: 1.207388. Batch_acc: 0.573596. Batch_loss: 1.183601 \n",
      "Batch: 432. Acc: 0.561363. Loss: 1.207465. Batch_acc: 0.553253. Batch_loss: 1.240741 \n",
      "Batch: 433. Acc: 0.561365. Loss: 1.207512. Batch_acc: 0.562319. Batch_loss: 1.227840 \n",
      "Batch: 434. Acc: 0.561420. Loss: 1.207376. Batch_acc: 0.584809. Batch_loss: 1.148923 \n",
      "Batch: 435. Acc: 0.561419. Loss: 1.207405. Batch_acc: 0.561230. Batch_loss: 1.220358 \n",
      "Batch: 436. Acc: 0.561464. Loss: 1.207298. Batch_acc: 0.580920. Batch_loss: 1.161170 \n",
      "Batch: 437. Acc: 0.561467. Loss: 1.207261. Batch_acc: 0.562755. Batch_loss: 1.190811 \n",
      "Batch: 438. Acc: 0.561500. Loss: 1.207226. Batch_acc: 0.576061. Batch_loss: 1.191809 \n",
      "Batch: 439. Acc: 0.561532. Loss: 1.207159. Batch_acc: 0.576261. Batch_loss: 1.176674 \n",
      "Batch: 440. Acc: 0.561428. Loss: 1.207381. Batch_acc: 0.513723. Batch_loss: 1.308440 \n",
      "Batch: 441. Acc: 0.561373. Loss: 1.207527. Batch_acc: 0.536657. Batch_loss: 1.272967 \n",
      "Batch: 442. Acc: 0.561377. Loss: 1.207516. Batch_acc: 0.563124. Batch_loss: 1.202569 \n",
      "Batch: 443. Acc: 0.561466. Loss: 1.207258. Batch_acc: 0.600453. Batch_loss: 1.095069 \n",
      "Batch: 444. Acc: 0.561510. Loss: 1.207089. Batch_acc: 0.580701. Batch_loss: 1.132588 \n",
      "Batch: 445. Acc: 0.561565. Loss: 1.206919. Batch_acc: 0.586207. Batch_loss: 1.131171 \n",
      "Batch: 446. Acc: 0.561549. Loss: 1.206959. Batch_acc: 0.554467. Batch_loss: 1.224704 \n",
      "Batch: 447. Acc: 0.561558. Loss: 1.206964. Batch_acc: 0.565593. Batch_loss: 1.209552 \n",
      "Batch: 448. Acc: 0.561571. Loss: 1.207005. Batch_acc: 0.567105. Batch_loss: 1.224952 \n",
      "Batch: 449. Acc: 0.561547. Loss: 1.207036. Batch_acc: 0.551068. Batch_loss: 1.221100 \n",
      "Batch: 450. Acc: 0.561574. Loss: 1.207035. Batch_acc: 0.573123. Batch_loss: 1.206497 \n",
      "Batch: 451. Acc: 0.561631. Loss: 1.206905. Batch_acc: 0.587529. Batch_loss: 1.148832 \n",
      "Batch: 452. Acc: 0.561671. Loss: 1.206795. Batch_acc: 0.579216. Batch_loss: 1.157778 \n",
      "Batch: 453. Acc: 0.561675. Loss: 1.206752. Batch_acc: 0.563805. Batch_loss: 1.187077 \n",
      "Batch: 454. Acc: 0.561653. Loss: 1.206784. Batch_acc: 0.551546. Batch_loss: 1.221265 \n",
      "Batch: 455. Acc: 0.561617. Loss: 1.206884. Batch_acc: 0.545350. Batch_loss: 1.252355 \n",
      "Batch: 456. Acc: 0.561626. Loss: 1.206905. Batch_acc: 0.565574. Batch_loss: 1.216255 \n",
      "Batch: 457. Acc: 0.561634. Loss: 1.206847. Batch_acc: 0.565439. Batch_loss: 1.181005 \n",
      "Batch: 458. Acc: 0.561621. Loss: 1.206867. Batch_acc: 0.555295. Batch_loss: 1.216325 \n",
      "Batch: 459. Acc: 0.561676. Loss: 1.206710. Batch_acc: 0.586957. Batch_loss: 1.135028 \n",
      "Batch: 460. Acc: 0.561695. Loss: 1.206666. Batch_acc: 0.570229. Batch_loss: 1.186975 \n",
      "Batch: 461. Acc: 0.561702. Loss: 1.206651. Batch_acc: 0.564794. Batch_loss: 1.199909 \n",
      "Batch: 462. Acc: 0.561737. Loss: 1.206566. Batch_acc: 0.578271. Batch_loss: 1.166840 \n",
      "Batch: 463. Acc: 0.561789. Loss: 1.206442. Batch_acc: 0.586268. Batch_loss: 1.147651 \n",
      "Batch: 464. Acc: 0.561790. Loss: 1.206482. Batch_acc: 0.562249. Batch_loss: 1.225142 \n",
      "Batch: 465. Acc: 0.561808. Loss: 1.206500. Batch_acc: 0.570215. Batch_loss: 1.214725 \n",
      "Batch: 466. Acc: 0.561810. Loss: 1.206482. Batch_acc: 0.562536. Batch_loss: 1.198078 \n",
      "Batch: 467. Acc: 0.561842. Loss: 1.206404. Batch_acc: 0.577332. Batch_loss: 1.168962 \n",
      "Batch: 468. Acc: 0.561819. Loss: 1.206399. Batch_acc: 0.550833. Batch_loss: 1.203807 \n",
      "Batch: 469. Acc: 0.561816. Loss: 1.206435. Batch_acc: 0.560517. Batch_loss: 1.223764 \n",
      "Batch: 470. Acc: 0.561736. Loss: 1.206660. Batch_acc: 0.523533. Batch_loss: 1.313617 \n",
      "Batch: 471. Acc: 0.561773. Loss: 1.206574. Batch_acc: 0.579157. Batch_loss: 1.166264 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 472. Acc: 0.561787. Loss: 1.206529. Batch_acc: 0.568581. Batch_loss: 1.184816 \n",
      "Batch: 473. Acc: 0.561779. Loss: 1.206531. Batch_acc: 0.558152. Batch_loss: 1.207496 \n",
      "Batch: 474. Acc: 0.561809. Loss: 1.206467. Batch_acc: 0.575964. Batch_loss: 1.176576 \n",
      "Batch: 475. Acc: 0.561821. Loss: 1.206484. Batch_acc: 0.567122. Batch_loss: 1.214417 \n",
      "Batch: 476. Acc: 0.561790. Loss: 1.206560. Batch_acc: 0.547192. Batch_loss: 1.243006 \n",
      "Batch: 477. Acc: 0.561768. Loss: 1.206606. Batch_acc: 0.551091. Batch_loss: 1.228574 \n",
      "Batch: 478. Acc: 0.561750. Loss: 1.206595. Batch_acc: 0.553314. Batch_loss: 1.201436 \n",
      "Batch: 479. Acc: 0.561766. Loss: 1.206551. Batch_acc: 0.569598. Batch_loss: 1.185203 \n",
      "Batch: 480. Acc: 0.561825. Loss: 1.206412. Batch_acc: 0.589788. Batch_loss: 1.139876 \n",
      "Batch: 481. Acc: 0.561808. Loss: 1.206466. Batch_acc: 0.553666. Batch_loss: 1.233096 \n",
      "Batch: 482. Acc: 0.561766. Loss: 1.206575. Batch_acc: 0.542067. Batch_loss: 1.257738 \n",
      "Batch: 483. Acc: 0.561747. Loss: 1.206613. Batch_acc: 0.552540. Batch_loss: 1.225110 \n",
      "Batch: 484. Acc: 0.561736. Loss: 1.206662. Batch_acc: 0.556210. Batch_loss: 1.231059 \n",
      "Batch: 485. Acc: 0.561688. Loss: 1.206795. Batch_acc: 0.538373. Batch_loss: 1.271516 \n",
      "Batch: 486. Acc: 0.561640. Loss: 1.206864. Batch_acc: 0.537225. Batch_loss: 1.241337 \n",
      "Batch: 487. Acc: 0.561628. Loss: 1.206896. Batch_acc: 0.555882. Batch_loss: 1.222932 \n",
      "Batch: 488. Acc: 0.561600. Loss: 1.206978. Batch_acc: 0.547619. Batch_loss: 1.248236 \n",
      "Batch: 489. Acc: 0.561576. Loss: 1.207050. Batch_acc: 0.549830. Batch_loss: 1.241720 \n",
      "Batch: 490. Acc: 0.561617. Loss: 1.206930. Batch_acc: 0.581408. Batch_loss: 1.149183 \n",
      "Batch: 491. Acc: 0.561642. Loss: 1.206809. Batch_acc: 0.573837. Batch_loss: 1.146788 \n",
      "Batch: 492. Acc: 0.561620. Loss: 1.206861. Batch_acc: 0.550784. Batch_loss: 1.232977 \n",
      "Batch: 493. Acc: 0.561618. Loss: 1.206797. Batch_acc: 0.560395. Batch_loss: 1.174954 \n",
      "Batch: 494. Acc: 0.561645. Loss: 1.206800. Batch_acc: 0.575510. Batch_loss: 1.208408 \n",
      "Batch: 495. Acc: 0.561670. Loss: 1.206730. Batch_acc: 0.573835. Batch_loss: 1.173012 \n",
      "Batch: 496. Acc: 0.561675. Loss: 1.206698. Batch_acc: 0.564162. Batch_loss: 1.190690 \n",
      "Batch: 497. Acc: 0.561728. Loss: 1.206555. Batch_acc: 0.587699. Batch_loss: 1.136033 \n",
      "Batch: 498. Acc: 0.561705. Loss: 1.206613. Batch_acc: 0.550343. Batch_loss: 1.235408 \n",
      "Batch: 499. Acc: 0.561714. Loss: 1.206523. Batch_acc: 0.566189. Batch_loss: 1.161902 \n",
      "Batch: 500. Acc: 0.561720. Loss: 1.206481. Batch_acc: 0.564599. Batch_loss: 1.185506 \n",
      "Batch: 501. Acc: 0.561746. Loss: 1.206448. Batch_acc: 0.574263. Batch_loss: 1.190238 \n",
      "Batch: 502. Acc: 0.561730. Loss: 1.206456. Batch_acc: 0.554162. Batch_loss: 1.210611 \n",
      "Checkpointing on batch: 502. Accuracy: 0.561730353577757. Loss per char: 1.206456055451482. Time: 1627225796.037779\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 18, 22, 17, 26, 25, 23, 25, 18,\n",
      "        25,  1, 78, 74, 79, 86, 84,  1, 14, 18, 24, 19, 15, 17, 18, 26, 32,  3,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 503. Acc: 0.561810. Loss: 1.206265. Batch_acc: 0.600902. Batch_loss: 1.112394 \n",
      "Batch: 504. Acc: 0.561842. Loss: 1.206127. Batch_acc: 0.577940. Batch_loss: 1.137789 \n",
      "Batch: 505. Acc: 0.561852. Loss: 1.206106. Batch_acc: 0.566762. Batch_loss: 1.195669 \n",
      "Batch: 506. Acc: 0.561853. Loss: 1.206049. Batch_acc: 0.562322. Batch_loss: 1.177502 \n",
      "Batch: 507. Acc: 0.561881. Loss: 1.205988. Batch_acc: 0.575986. Batch_loss: 1.174902 \n",
      "Batch: 508. Acc: 0.561867. Loss: 1.205989. Batch_acc: 0.554787. Batch_loss: 1.206448 \n",
      "Batch: 509. Acc: 0.561802. Loss: 1.206111. Batch_acc: 0.529040. Batch_loss: 1.268419 \n",
      "Batch: 510. Acc: 0.561766. Loss: 1.206140. Batch_acc: 0.543253. Batch_loss: 1.220828 \n",
      "Batch: 511. Acc: 0.561768. Loss: 1.206140. Batch_acc: 0.562570. Batch_loss: 1.205877 \n",
      "Batch: 512. Acc: 0.561761. Loss: 1.206216. Batch_acc: 0.558153. Batch_loss: 1.245963 \n",
      "Batch: 513. Acc: 0.561762. Loss: 1.206233. Batch_acc: 0.562392. Batch_loss: 1.214682 \n",
      "Batch: 514. Acc: 0.561753. Loss: 1.206203. Batch_acc: 0.557274. Batch_loss: 1.191342 \n",
      "Batch: 515. Acc: 0.561742. Loss: 1.206243. Batch_acc: 0.556059. Batch_loss: 1.226486 \n",
      "Batch: 516. Acc: 0.561754. Loss: 1.206247. Batch_acc: 0.567676. Batch_loss: 1.208312 \n",
      "Batch: 517. Acc: 0.561741. Loss: 1.206297. Batch_acc: 0.555097. Batch_loss: 1.232653 \n",
      "Batch: 518. Acc: 0.561763. Loss: 1.206245. Batch_acc: 0.573241. Batch_loss: 1.179161 \n",
      "Batch: 519. Acc: 0.561771. Loss: 1.206216. Batch_acc: 0.565737. Batch_loss: 1.191334 \n",
      "Batch: 520. Acc: 0.561733. Loss: 1.206375. Batch_acc: 0.541493. Batch_loss: 1.292208 \n",
      "Batch: 521. Acc: 0.561717. Loss: 1.206420. Batch_acc: 0.553130. Batch_loss: 1.229692 \n",
      "Batch: 522. Acc: 0.561673. Loss: 1.206534. Batch_acc: 0.538506. Batch_loss: 1.266540 \n",
      "Batch: 523. Acc: 0.561678. Loss: 1.206555. Batch_acc: 0.564622. Batch_loss: 1.217978 \n",
      "Batch: 524. Acc: 0.561705. Loss: 1.206503. Batch_acc: 0.575671. Batch_loss: 1.179484 \n",
      "Batch: 525. Acc: 0.561709. Loss: 1.206513. Batch_acc: 0.563510. Batch_loss: 1.211679 \n",
      "Batch: 526. Acc: 0.561691. Loss: 1.206544. Batch_acc: 0.552540. Batch_loss: 1.223012 \n",
      "Batch: 527. Acc: 0.561714. Loss: 1.206473. Batch_acc: 0.573252. Batch_loss: 1.170673 \n",
      "Batch: 528. Acc: 0.561741. Loss: 1.206422. Batch_acc: 0.575654. Batch_loss: 1.179639 \n",
      "Batch: 529. Acc: 0.561697. Loss: 1.206510. Batch_acc: 0.537641. Batch_loss: 1.254509 \n",
      "Batch: 530. Acc: 0.561680. Loss: 1.206562. Batch_acc: 0.552586. Batch_loss: 1.234455 \n",
      "Batch: 531. Acc: 0.561699. Loss: 1.206517. Batch_acc: 0.571674. Batch_loss: 1.182694 \n",
      "Batch: 532. Acc: 0.561731. Loss: 1.206462. Batch_acc: 0.578503. Batch_loss: 1.177832 \n",
      "Batch: 533. Acc: 0.561716. Loss: 1.206483. Batch_acc: 0.553477. Batch_loss: 1.217555 \n",
      "Batch: 534. Acc: 0.561680. Loss: 1.206520. Batch_acc: 0.542640. Batch_loss: 1.226691 \n",
      "Batch: 535. Acc: 0.561661. Loss: 1.206524. Batch_acc: 0.551320. Batch_loss: 1.208817 \n",
      "Batch: 536. Acc: 0.561695. Loss: 1.206467. Batch_acc: 0.579603. Batch_loss: 1.176229 \n",
      "Batch: 537. Acc: 0.561725. Loss: 1.206425. Batch_acc: 0.577576. Batch_loss: 1.184381 \n",
      "Batch: 538. Acc: 0.561738. Loss: 1.206389. Batch_acc: 0.568627. Batch_loss: 1.186798 \n",
      "Batch: 539. Acc: 0.561782. Loss: 1.206264. Batch_acc: 0.585408. Batch_loss: 1.138957 \n",
      "Batch: 540. Acc: 0.561814. Loss: 1.206218. Batch_acc: 0.578857. Batch_loss: 1.181684 \n",
      "Batch: 541. Acc: 0.561832. Loss: 1.206191. Batch_acc: 0.572009. Batch_loss: 1.191478 \n",
      "Batch: 542. Acc: 0.561848. Loss: 1.206192. Batch_acc: 0.570191. Batch_loss: 1.206431 \n",
      "Batch: 543. Acc: 0.561834. Loss: 1.206183. Batch_acc: 0.554438. Batch_loss: 1.201269 \n",
      "Batch: 544. Acc: 0.561820. Loss: 1.206200. Batch_acc: 0.553985. Batch_loss: 1.215361 \n",
      "Batch: 545. Acc: 0.561834. Loss: 1.206156. Batch_acc: 0.569577. Batch_loss: 1.182614 \n",
      "Batch: 546. Acc: 0.561797. Loss: 1.206259. Batch_acc: 0.540541. Batch_loss: 1.264683 \n",
      "Batch: 547. Acc: 0.561795. Loss: 1.206229. Batch_acc: 0.560764. Batch_loss: 1.189828 \n",
      "Batch: 548. Acc: 0.561819. Loss: 1.206158. Batch_acc: 0.574661. Batch_loss: 1.167812 \n",
      "Batch: 549. Acc: 0.561776. Loss: 1.206206. Batch_acc: 0.537697. Batch_loss: 1.233153 \n",
      "Batch: 550. Acc: 0.561771. Loss: 1.206210. Batch_acc: 0.559312. Batch_loss: 1.208430 \n",
      "Batch: 551. Acc: 0.561786. Loss: 1.206186. Batch_acc: 0.570082. Batch_loss: 1.192706 \n",
      "Batch: 552. Acc: 0.561783. Loss: 1.206177. Batch_acc: 0.560231. Batch_loss: 1.201102 \n",
      "Batch: 553. Acc: 0.561774. Loss: 1.206162. Batch_acc: 0.556845. Batch_loss: 1.198095 \n",
      "Batch: 554. Acc: 0.561752. Loss: 1.206181. Batch_acc: 0.549887. Batch_loss: 1.216363 \n",
      "Batch: 555. Acc: 0.561770. Loss: 1.206165. Batch_acc: 0.571510. Batch_loss: 1.197458 \n",
      "Batch: 556. Acc: 0.561788. Loss: 1.206152. Batch_acc: 0.571751. Batch_loss: 1.198742 \n",
      "Batch: 557. Acc: 0.561762. Loss: 1.206228. Batch_acc: 0.546920. Batch_loss: 1.248590 \n",
      "Batch: 558. Acc: 0.561766. Loss: 1.206233. Batch_acc: 0.564117. Batch_loss: 1.209109 \n",
      "Batch: 559. Acc: 0.561790. Loss: 1.206194. Batch_acc: 0.574552. Batch_loss: 1.185179 \n",
      "Batch: 560. Acc: 0.561831. Loss: 1.206117. Batch_acc: 0.584873. Batch_loss: 1.162764 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 561. Acc: 0.561842. Loss: 1.206040. Batch_acc: 0.568427. Batch_loss: 1.163180 \n",
      "Batch: 562. Acc: 0.561872. Loss: 1.205933. Batch_acc: 0.578613. Batch_loss: 1.145750 \n",
      "Batch: 563. Acc: 0.561821. Loss: 1.206031. Batch_acc: 0.533295. Batch_loss: 1.260580 \n",
      "Batch: 564. Acc: 0.561841. Loss: 1.206002. Batch_acc: 0.572630. Batch_loss: 1.190073 \n",
      "Batch: 565. Acc: 0.561801. Loss: 1.206094. Batch_acc: 0.539130. Batch_loss: 1.258604 \n",
      "Batch: 566. Acc: 0.561845. Loss: 1.206012. Batch_acc: 0.586130. Batch_loss: 1.161025 \n",
      "Batch: 567. Acc: 0.561841. Loss: 1.206052. Batch_acc: 0.559495. Batch_loss: 1.229433 \n",
      "Batch: 568. Acc: 0.561867. Loss: 1.205980. Batch_acc: 0.576726. Batch_loss: 1.165493 \n",
      "Batch: 569. Acc: 0.561865. Loss: 1.205961. Batch_acc: 0.560364. Batch_loss: 1.195478 \n",
      "Batch: 570. Acc: 0.561875. Loss: 1.205947. Batch_acc: 0.567723. Batch_loss: 1.198020 \n",
      "Batch: 571. Acc: 0.561828. Loss: 1.206032. Batch_acc: 0.534884. Batch_loss: 1.254842 \n",
      "Batch: 572. Acc: 0.561820. Loss: 1.205994. Batch_acc: 0.557405. Batch_loss: 1.184386 \n",
      "Batch: 573. Acc: 0.561800. Loss: 1.206029. Batch_acc: 0.550228. Batch_loss: 1.226089 \n",
      "Batch: 574. Acc: 0.561803. Loss: 1.206044. Batch_acc: 0.563277. Batch_loss: 1.214342 \n",
      "Batch: 575. Acc: 0.561804. Loss: 1.206073. Batch_acc: 0.562464. Batch_loss: 1.222747 \n",
      "Batch: 576. Acc: 0.561829. Loss: 1.206027. Batch_acc: 0.576587. Batch_loss: 1.178987 \n",
      "Batch: 577. Acc: 0.561799. Loss: 1.206083. Batch_acc: 0.544843. Batch_loss: 1.237818 \n",
      "Batch: 578. Acc: 0.561823. Loss: 1.206015. Batch_acc: 0.575296. Batch_loss: 1.167310 \n",
      "Batch: 579. Acc: 0.561781. Loss: 1.206079. Batch_acc: 0.537190. Batch_loss: 1.243999 \n",
      "Batch: 580. Acc: 0.561795. Loss: 1.206045. Batch_acc: 0.569468. Batch_loss: 1.186547 \n",
      "Batch: 581. Acc: 0.561823. Loss: 1.205978. Batch_acc: 0.578334. Batch_loss: 1.166455 \n",
      "Batch: 582. Acc: 0.561819. Loss: 1.205977. Batch_acc: 0.559954. Batch_loss: 1.205426 \n",
      "Batch: 583. Acc: 0.561807. Loss: 1.205979. Batch_acc: 0.554540. Batch_loss: 1.207145 \n",
      "Batch: 584. Acc: 0.561815. Loss: 1.205950. Batch_acc: 0.566143. Batch_loss: 1.189580 \n",
      "Batch: 585. Acc: 0.561885. Loss: 1.205764. Batch_acc: 0.601562. Batch_loss: 1.100467 \n",
      "Batch: 586. Acc: 0.561941. Loss: 1.205677. Batch_acc: 0.593836. Batch_loss: 1.156889 \n",
      "Batch: 587. Acc: 0.561977. Loss: 1.205543. Batch_acc: 0.582949. Batch_loss: 1.127031 \n",
      "Batch: 588. Acc: 0.561978. Loss: 1.205539. Batch_acc: 0.562181. Batch_loss: 1.202817 \n",
      "Batch: 589. Acc: 0.562002. Loss: 1.205456. Batch_acc: 0.576174. Batch_loss: 1.157160 \n",
      "Batch: 590. Acc: 0.561977. Loss: 1.205532. Batch_acc: 0.547356. Batch_loss: 1.250496 \n",
      "Batch: 591. Acc: 0.562009. Loss: 1.205472. Batch_acc: 0.580590. Batch_loss: 1.170578 \n",
      "Batch: 592. Acc: 0.562035. Loss: 1.205438. Batch_acc: 0.577531. Batch_loss: 1.185235 \n",
      "Batch: 593. Acc: 0.562018. Loss: 1.205494. Batch_acc: 0.551683. Batch_loss: 1.239619 \n",
      "Batch: 594. Acc: 0.562027. Loss: 1.205465. Batch_acc: 0.567308. Batch_loss: 1.188489 \n",
      "Batch: 595. Acc: 0.562013. Loss: 1.205473. Batch_acc: 0.553510. Batch_loss: 1.209817 \n",
      "Batch: 596. Acc: 0.561975. Loss: 1.205578. Batch_acc: 0.540345. Batch_loss: 1.266155 \n",
      "Batch: 597. Acc: 0.561904. Loss: 1.205763. Batch_acc: 0.518562. Batch_loss: 1.319092 \n",
      "Batch: 598. Acc: 0.561889. Loss: 1.205758. Batch_acc: 0.552784. Batch_loss: 1.202389 \n",
      "Batch: 599. Acc: 0.561890. Loss: 1.205781. Batch_acc: 0.562242. Batch_loss: 1.219913 \n",
      "Batch: 600. Acc: 0.561863. Loss: 1.205858. Batch_acc: 0.545663. Batch_loss: 1.251849 \n",
      "Batch: 601. Acc: 0.561884. Loss: 1.205851. Batch_acc: 0.575058. Batch_loss: 1.201887 \n",
      "Batch: 602. Acc: 0.561881. Loss: 1.205832. Batch_acc: 0.560023. Batch_loss: 1.194617 \n",
      "Batch: 603. Acc: 0.561890. Loss: 1.205838. Batch_acc: 0.567458. Batch_loss: 1.209389 \n",
      "Batch: 604. Acc: 0.561893. Loss: 1.205799. Batch_acc: 0.563501. Batch_loss: 1.182205 \n",
      "Batch: 605. Acc: 0.561902. Loss: 1.205753. Batch_acc: 0.567181. Batch_loss: 1.178336 \n",
      "Batch: 606. Acc: 0.561897. Loss: 1.205781. Batch_acc: 0.558669. Batch_loss: 1.222740 \n",
      "Batch: 607. Acc: 0.561883. Loss: 1.205799. Batch_acc: 0.553846. Batch_loss: 1.216955 \n",
      "Batch: 608. Acc: 0.561886. Loss: 1.205777. Batch_acc: 0.563372. Batch_loss: 1.192395 \n",
      "Batch: 609. Acc: 0.561845. Loss: 1.205873. Batch_acc: 0.537005. Batch_loss: 1.264376 \n",
      "Batch: 610. Acc: 0.561849. Loss: 1.205865. Batch_acc: 0.564191. Batch_loss: 1.200921 \n",
      "Batch: 611. Acc: 0.561810. Loss: 1.205994. Batch_acc: 0.538373. Batch_loss: 1.285269 \n",
      "Batch: 612. Acc: 0.561860. Loss: 1.205858. Batch_acc: 0.591518. Batch_loss: 1.125127 \n",
      "Batch: 613. Acc: 0.561875. Loss: 1.205803. Batch_acc: 0.570771. Batch_loss: 1.172046 \n",
      "Batch: 614. Acc: 0.561856. Loss: 1.205841. Batch_acc: 0.550118. Batch_loss: 1.229525 \n",
      "Batch: 615. Acc: 0.561839. Loss: 1.205882. Batch_acc: 0.551159. Batch_loss: 1.230478 \n",
      "Batch: 616. Acc: 0.561823. Loss: 1.205933. Batch_acc: 0.552316. Batch_loss: 1.237084 \n",
      "Batch: 617. Acc: 0.561813. Loss: 1.205970. Batch_acc: 0.555365. Batch_loss: 1.228564 \n",
      "Batch: 618. Acc: 0.561807. Loss: 1.205949. Batch_acc: 0.558548. Batch_loss: 1.193183 \n",
      "Batch: 619. Acc: 0.561823. Loss: 1.205902. Batch_acc: 0.571842. Batch_loss: 1.176711 \n",
      "Batch: 620. Acc: 0.561823. Loss: 1.205930. Batch_acc: 0.561393. Batch_loss: 1.222758 \n",
      "Batch: 621. Acc: 0.561873. Loss: 1.205824. Batch_acc: 0.593915. Batch_loss: 1.139352 \n",
      "Batch: 622. Acc: 0.561867. Loss: 1.205821. Batch_acc: 0.557579. Batch_loss: 1.203805 \n",
      "Batch: 623. Acc: 0.561834. Loss: 1.205903. Batch_acc: 0.542135. Batch_loss: 1.255607 \n",
      "Batch: 624. Acc: 0.561848. Loss: 1.205899. Batch_acc: 0.570051. Batch_loss: 1.203492 \n",
      "Batch: 625. Acc: 0.561868. Loss: 1.205906. Batch_acc: 0.574505. Batch_loss: 1.210524 \n",
      "Batch: 626. Acc: 0.561891. Loss: 1.205913. Batch_acc: 0.576766. Batch_loss: 1.210295 \n",
      "Batch: 627. Acc: 0.561906. Loss: 1.205911. Batch_acc: 0.571858. Batch_loss: 1.204377 \n",
      "Batch: 628. Acc: 0.561894. Loss: 1.205956. Batch_acc: 0.553899. Batch_loss: 1.234361 \n",
      "Batch: 629. Acc: 0.561915. Loss: 1.205890. Batch_acc: 0.575342. Batch_loss: 1.164343 \n",
      "Batch: 630. Acc: 0.561918. Loss: 1.205888. Batch_acc: 0.563986. Batch_loss: 1.205051 \n",
      "Batch: 631. Acc: 0.561929. Loss: 1.205898. Batch_acc: 0.568362. Batch_loss: 1.212128 \n",
      "Batch: 632. Acc: 0.561955. Loss: 1.205832. Batch_acc: 0.578437. Batch_loss: 1.164541 \n",
      "Batch: 633. Acc: 0.561939. Loss: 1.205843. Batch_acc: 0.551505. Batch_loss: 1.212592 \n",
      "Batch: 634. Acc: 0.561957. Loss: 1.205817. Batch_acc: 0.573333. Batch_loss: 1.189431 \n",
      "Batch: 635. Acc: 0.561954. Loss: 1.205807. Batch_acc: 0.560091. Batch_loss: 1.199361 \n",
      "Batch: 636. Acc: 0.561999. Loss: 1.205745. Batch_acc: 0.590751. Batch_loss: 1.166063 \n",
      "Batch: 637. Acc: 0.562023. Loss: 1.205653. Batch_acc: 0.577765. Batch_loss: 1.146957 \n",
      "Batch: 638. Acc: 0.562032. Loss: 1.205583. Batch_acc: 0.567537. Batch_loss: 1.161963 \n",
      "Batch: 639. Acc: 0.562053. Loss: 1.205548. Batch_acc: 0.575548. Batch_loss: 1.182783 \n",
      "Batch: 640. Acc: 0.562085. Loss: 1.205440. Batch_acc: 0.581808. Batch_loss: 1.139070 \n",
      "Batch: 641. Acc: 0.562072. Loss: 1.205425. Batch_acc: 0.553757. Batch_loss: 1.195887 \n",
      "Batch: 642. Acc: 0.562075. Loss: 1.205407. Batch_acc: 0.563817. Batch_loss: 1.193233 \n",
      "Batch: 643. Acc: 0.562079. Loss: 1.205376. Batch_acc: 0.565115. Batch_loss: 1.185095 \n",
      "Batch: 644. Acc: 0.562105. Loss: 1.205336. Batch_acc: 0.578470. Batch_loss: 1.179799 \n",
      "Batch: 645. Acc: 0.562120. Loss: 1.205313. Batch_acc: 0.571753. Batch_loss: 1.190728 \n",
      "Batch: 646. Acc: 0.562106. Loss: 1.205345. Batch_acc: 0.552752. Batch_loss: 1.226444 \n",
      "Batch: 647. Acc: 0.562136. Loss: 1.205273. Batch_acc: 0.581892. Batch_loss: 1.158607 \n",
      "Batch: 648. Acc: 0.562109. Loss: 1.205331. Batch_acc: 0.544464. Batch_loss: 1.242803 \n",
      "Batch: 649. Acc: 0.562131. Loss: 1.205274. Batch_acc: 0.576125. Batch_loss: 1.167895 \n",
      "Batch: 650. Acc: 0.562131. Loss: 1.205290. Batch_acc: 0.562212. Batch_loss: 1.215866 \n",
      "Batch: 651. Acc: 0.562149. Loss: 1.205244. Batch_acc: 0.574171. Batch_loss: 1.175013 \n",
      "Batch: 652. Acc: 0.562156. Loss: 1.205231. Batch_acc: 0.566571. Batch_loss: 1.196461 \n",
      "Batch: 653. Acc: 0.562175. Loss: 1.205197. Batch_acc: 0.574679. Batch_loss: 1.182482 \n",
      "Batch: 654. Acc: 0.562189. Loss: 1.205129. Batch_acc: 0.571588. Batch_loss: 1.162043 \n",
      "Batch: 655. Acc: 0.562221. Loss: 1.205089. Batch_acc: 0.582717. Batch_loss: 1.179307 \n",
      "Batch: 656. Acc: 0.562223. Loss: 1.205062. Batch_acc: 0.563615. Batch_loss: 1.187303 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 657. Acc: 0.562290. Loss: 1.204967. Batch_acc: 0.605174. Batch_loss: 1.144104 \n",
      "Batch: 658. Acc: 0.562299. Loss: 1.204937. Batch_acc: 0.568354. Batch_loss: 1.184806 \n",
      "Batch: 659. Acc: 0.562323. Loss: 1.204882. Batch_acc: 0.578107. Batch_loss: 1.168908 \n",
      "Batch: 660. Acc: 0.562336. Loss: 1.204862. Batch_acc: 0.570833. Batch_loss: 1.191290 \n",
      "Batch: 661. Acc: 0.562317. Loss: 1.204936. Batch_acc: 0.549885. Batch_loss: 1.254204 \n",
      "Batch: 662. Acc: 0.562354. Loss: 1.204840. Batch_acc: 0.586659. Batch_loss: 1.141833 \n",
      "Batch: 663. Acc: 0.562338. Loss: 1.204861. Batch_acc: 0.551282. Batch_loss: 1.218579 \n",
      "Batch: 664. Acc: 0.562361. Loss: 1.204802. Batch_acc: 0.578278. Batch_loss: 1.165700 \n",
      "Batch: 665. Acc: 0.562355. Loss: 1.204792. Batch_acc: 0.557895. Batch_loss: 1.197869 \n",
      "Batch: 666. Acc: 0.562354. Loss: 1.204751. Batch_acc: 0.561660. Batch_loss: 1.176836 \n",
      "Batch: 667. Acc: 0.562363. Loss: 1.204742. Batch_acc: 0.568493. Batch_loss: 1.198852 \n",
      "Batch: 668. Acc: 0.562344. Loss: 1.204788. Batch_acc: 0.549741. Batch_loss: 1.235588 \n",
      "Batch: 669. Acc: 0.562334. Loss: 1.204821. Batch_acc: 0.555620. Batch_loss: 1.227466 \n",
      "Batch: 670. Acc: 0.562316. Loss: 1.204860. Batch_acc: 0.549913. Batch_loss: 1.230777 \n",
      "Batch: 671. Acc: 0.562292. Loss: 1.204928. Batch_acc: 0.546307. Batch_loss: 1.251539 \n",
      "Batch: 672. Acc: 0.562284. Loss: 1.204949. Batch_acc: 0.556701. Batch_loss: 1.219006 \n",
      "Batch: 673. Acc: 0.562299. Loss: 1.204892. Batch_acc: 0.572067. Batch_loss: 1.167522 \n",
      "Batch: 674. Acc: 0.562311. Loss: 1.204847. Batch_acc: 0.570181. Batch_loss: 1.173951 \n",
      "Batch: 675. Acc: 0.562308. Loss: 1.204880. Batch_acc: 0.560571. Batch_loss: 1.227446 \n",
      "Batch: 676. Acc: 0.562289. Loss: 1.204923. Batch_acc: 0.549680. Batch_loss: 1.233652 \n",
      "Batch: 677. Acc: 0.562283. Loss: 1.204933. Batch_acc: 0.557870. Batch_loss: 1.212098 \n",
      "Batch: 678. Acc: 0.562281. Loss: 1.204938. Batch_acc: 0.561184. Batch_loss: 1.208023 \n",
      "Batch: 679. Acc: 0.562270. Loss: 1.204980. Batch_acc: 0.554732. Batch_loss: 1.233517 \n",
      "Batch: 680. Acc: 0.562268. Loss: 1.205015. Batch_acc: 0.561091. Batch_loss: 1.229262 \n",
      "Batch: 681. Acc: 0.562263. Loss: 1.205003. Batch_acc: 0.558807. Batch_loss: 1.196870 \n",
      "Batch: 682. Acc: 0.562237. Loss: 1.205115. Batch_acc: 0.543995. Batch_loss: 1.284124 \n",
      "Batch: 683. Acc: 0.562240. Loss: 1.205083. Batch_acc: 0.563720. Batch_loss: 1.183473 \n",
      "Batch: 684. Acc: 0.562281. Loss: 1.204996. Batch_acc: 0.590155. Batch_loss: 1.145660 \n",
      "Batch: 685. Acc: 0.562265. Loss: 1.205009. Batch_acc: 0.551705. Batch_loss: 1.213590 \n",
      "Batch: 686. Acc: 0.562273. Loss: 1.204946. Batch_acc: 0.567950. Batch_loss: 1.162888 \n",
      "Batch: 687. Acc: 0.562302. Loss: 1.204890. Batch_acc: 0.581911. Batch_loss: 1.166553 \n",
      "Batch: 688. Acc: 0.562277. Loss: 1.204927. Batch_acc: 0.544601. Batch_loss: 1.231120 \n",
      "Batch: 689. Acc: 0.562272. Loss: 1.204922. Batch_acc: 0.558942. Batch_loss: 1.201301 \n",
      "Batch: 690. Acc: 0.562254. Loss: 1.204970. Batch_acc: 0.549741. Batch_loss: 1.238153 \n",
      "Batch: 691. Acc: 0.562251. Loss: 1.204956. Batch_acc: 0.560276. Batch_loss: 1.194960 \n",
      "Batch: 692. Acc: 0.562276. Loss: 1.204871. Batch_acc: 0.578977. Batch_loss: 1.148563 \n",
      "Batch: 693. Acc: 0.562287. Loss: 1.204880. Batch_acc: 0.569994. Batch_loss: 1.211258 \n",
      "Batch: 694. Acc: 0.562310. Loss: 1.204822. Batch_acc: 0.577940. Batch_loss: 1.165375 \n",
      "Batch: 695. Acc: 0.562290. Loss: 1.204882. Batch_acc: 0.547703. Batch_loss: 1.247635 \n",
      "Batch: 696. Acc: 0.562322. Loss: 1.204802. Batch_acc: 0.584895. Batch_loss: 1.149815 \n",
      "Batch: 697. Acc: 0.562330. Loss: 1.204767. Batch_acc: 0.567324. Batch_loss: 1.180622 \n",
      "Batch: 698. Acc: 0.562358. Loss: 1.204725. Batch_acc: 0.581111. Batch_loss: 1.176711 \n",
      "Batch: 699. Acc: 0.562341. Loss: 1.204794. Batch_acc: 0.550775. Batch_loss: 1.252449 \n",
      "Batch: 700. Acc: 0.562331. Loss: 1.204814. Batch_acc: 0.555743. Batch_loss: 1.219086 \n",
      "Batch: 701. Acc: 0.562293. Loss: 1.204878. Batch_acc: 0.534816. Batch_loss: 1.250500 \n",
      "Batch: 702. Acc: 0.562341. Loss: 1.204747. Batch_acc: 0.596220. Batch_loss: 1.112757 \n",
      "Batch: 703. Acc: 0.562331. Loss: 1.204762. Batch_acc: 0.555038. Batch_loss: 1.215569 \n",
      "Batch: 704. Acc: 0.562332. Loss: 1.204781. Batch_acc: 0.562826. Batch_loss: 1.218259 \n",
      "Batch: 705. Acc: 0.562343. Loss: 1.204763. Batch_acc: 0.570531. Batch_loss: 1.191899 \n",
      "Batch: 706. Acc: 0.562348. Loss: 1.204734. Batch_acc: 0.565521. Batch_loss: 1.184083 \n",
      "Batch: 707. Acc: 0.562340. Loss: 1.204762. Batch_acc: 0.556766. Batch_loss: 1.224807 \n",
      "Batch: 708. Acc: 0.562332. Loss: 1.204789. Batch_acc: 0.556532. Batch_loss: 1.224101 \n",
      "Batch: 709. Acc: 0.562321. Loss: 1.204812. Batch_acc: 0.554651. Batch_loss: 1.220977 \n",
      "Batch: 710. Acc: 0.562306. Loss: 1.204824. Batch_acc: 0.551505. Batch_loss: 1.213927 \n",
      "Batch: 711. Acc: 0.562283. Loss: 1.204890. Batch_acc: 0.545455. Batch_loss: 1.252352 \n",
      "Batch: 712. Acc: 0.562287. Loss: 1.204859. Batch_acc: 0.565143. Batch_loss: 1.183074 \n",
      "Batch: 713. Acc: 0.562314. Loss: 1.204795. Batch_acc: 0.581197. Batch_loss: 1.159656 \n",
      "Batch: 714. Acc: 0.562304. Loss: 1.204819. Batch_acc: 0.555107. Batch_loss: 1.221895 \n",
      "Batch: 715. Acc: 0.562337. Loss: 1.204743. Batch_acc: 0.586345. Batch_loss: 1.150702 \n",
      "Batch: 716. Acc: 0.562374. Loss: 1.204682. Batch_acc: 0.588611. Batch_loss: 1.160435 \n",
      "Batch: 717. Acc: 0.562392. Loss: 1.204647. Batch_acc: 0.575972. Batch_loss: 1.178793 \n",
      "Batch: 718. Acc: 0.562374. Loss: 1.204679. Batch_acc: 0.549771. Batch_loss: 1.227886 \n",
      "Batch: 719. Acc: 0.562409. Loss: 1.204595. Batch_acc: 0.587182. Batch_loss: 1.144092 \n",
      "Batch: 720. Acc: 0.562417. Loss: 1.204539. Batch_acc: 0.567972. Batch_loss: 1.164149 \n",
      "Batch: 721. Acc: 0.562414. Loss: 1.204534. Batch_acc: 0.560580. Batch_loss: 1.200546 \n",
      "Batch: 722. Acc: 0.562419. Loss: 1.204507. Batch_acc: 0.565751. Batch_loss: 1.184898 \n",
      "Batch: 723. Acc: 0.562419. Loss: 1.204521. Batch_acc: 0.562967. Batch_loss: 1.214929 \n",
      "Batch: 724. Acc: 0.562442. Loss: 1.204486. Batch_acc: 0.578829. Batch_loss: 1.179743 \n",
      "Batch: 725. Acc: 0.562428. Loss: 1.204512. Batch_acc: 0.552028. Batch_loss: 1.223615 \n",
      "Batch: 726. Acc: 0.562464. Loss: 1.204423. Batch_acc: 0.588168. Batch_loss: 1.139581 \n",
      "Batch: 727. Acc: 0.562410. Loss: 1.204561. Batch_acc: 0.521635. Batch_loss: 1.309826 \n",
      "Batch: 728. Acc: 0.562436. Loss: 1.204491. Batch_acc: 0.580882. Batch_loss: 1.154334 \n",
      "Batch: 729. Acc: 0.562413. Loss: 1.204536. Batch_acc: 0.546473. Batch_loss: 1.236021 \n",
      "Batch: 730. Acc: 0.562424. Loss: 1.204519. Batch_acc: 0.569849. Batch_loss: 1.192093 \n",
      "Batch: 731. Acc: 0.562454. Loss: 1.204443. Batch_acc: 0.583844. Batch_loss: 1.151094 \n",
      "Batch: 732. Acc: 0.562445. Loss: 1.204450. Batch_acc: 0.555684. Batch_loss: 1.209214 \n",
      "Batch: 733. Acc: 0.562426. Loss: 1.204480. Batch_acc: 0.548312. Batch_loss: 1.227235 \n",
      "Batch: 734. Acc: 0.562411. Loss: 1.204515. Batch_acc: 0.551364. Batch_loss: 1.230170 \n",
      "Batch: 735. Acc: 0.562440. Loss: 1.204442. Batch_acc: 0.584005. Batch_loss: 1.150445 \n",
      "Batch: 736. Acc: 0.562450. Loss: 1.204349. Batch_acc: 0.569787. Batch_loss: 1.136558 \n",
      "Batch: 737. Acc: 0.562458. Loss: 1.204284. Batch_acc: 0.568144. Batch_loss: 1.157121 \n",
      "Batch: 738. Acc: 0.562443. Loss: 1.204291. Batch_acc: 0.550912. Batch_loss: 1.209743 \n",
      "Batch: 739. Acc: 0.562462. Loss: 1.204221. Batch_acc: 0.576879. Batch_loss: 1.153458 \n",
      "Batch: 740. Acc: 0.562464. Loss: 1.204199. Batch_acc: 0.563626. Batch_loss: 1.187458 \n",
      "Batch: 741. Acc: 0.562455. Loss: 1.204210. Batch_acc: 0.556069. Batch_loss: 1.212080 \n",
      "Batch: 742. Acc: 0.562444. Loss: 1.204185. Batch_acc: 0.554210. Batch_loss: 1.186169 \n",
      "Batch: 743. Acc: 0.562446. Loss: 1.204212. Batch_acc: 0.563731. Batch_loss: 1.223938 \n",
      "Batch: 744. Acc: 0.562481. Loss: 1.204168. Batch_acc: 0.587612. Batch_loss: 1.172998 \n",
      "Batch: 745. Acc: 0.562508. Loss: 1.204113. Batch_acc: 0.582897. Batch_loss: 1.162218 \n",
      "Batch: 746. Acc: 0.562509. Loss: 1.204122. Batch_acc: 0.563510. Batch_loss: 1.210916 \n",
      "Batch: 747. Acc: 0.562521. Loss: 1.204112. Batch_acc: 0.571346. Batch_loss: 1.196590 \n",
      "Batch: 748. Acc: 0.562503. Loss: 1.204137. Batch_acc: 0.549351. Batch_loss: 1.222304 \n",
      "Batch: 749. Acc: 0.562501. Loss: 1.204156. Batch_acc: 0.560850. Batch_loss: 1.218563 \n",
      "Batch: 750. Acc: 0.562518. Loss: 1.204114. Batch_acc: 0.575231. Batch_loss: 1.172529 \n",
      "Batch: 751. Acc: 0.562540. Loss: 1.204030. Batch_acc: 0.579310. Batch_loss: 1.141385 \n",
      "Batch: 752. Acc: 0.562519. Loss: 1.204089. Batch_acc: 0.546830. Batch_loss: 1.248769 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 753. Acc: 0.562537. Loss: 1.204074. Batch_acc: 0.575880. Batch_loss: 1.192454 \n",
      "Checkpointing on batch: 753. Accuracy: 0.5625371308487291. Loss per char: 1.2040738884888784. Time: 1627225975.3106933\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 20, 22, 18, 21, 21, 22, 21, 19, 26,\n",
      "        23, 24, 19, 15, 21, 23, 25,  1, 12,  1, 14, 17, 15, 19, 32,  3,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 754. Acc: 0.562557. Loss: 1.204002. Batch_acc: 0.577440. Batch_loss: 1.149200 \n",
      "Batch: 755. Acc: 0.562553. Loss: 1.204004. Batch_acc: 0.559882. Batch_loss: 1.205568 \n",
      "Batch: 756. Acc: 0.562559. Loss: 1.204003. Batch_acc: 0.567241. Batch_loss: 1.202883 \n",
      "Batch: 757. Acc: 0.562556. Loss: 1.204001. Batch_acc: 0.560116. Batch_loss: 1.202307 \n",
      "Batch: 758. Acc: 0.562589. Loss: 1.203879. Batch_acc: 0.587861. Batch_loss: 1.111302 \n",
      "Batch: 759. Acc: 0.562580. Loss: 1.203878. Batch_acc: 0.555431. Batch_loss: 1.203364 \n",
      "Batch: 760. Acc: 0.562566. Loss: 1.203875. Batch_acc: 0.552282. Batch_loss: 1.201376 \n",
      "Batch: 761. Acc: 0.562564. Loss: 1.203930. Batch_acc: 0.560753. Batch_loss: 1.245402 \n",
      "Batch: 762. Acc: 0.562571. Loss: 1.203917. Batch_acc: 0.567922. Batch_loss: 1.194165 \n",
      "Batch: 763. Acc: 0.562545. Loss: 1.203938. Batch_acc: 0.542676. Batch_loss: 1.219941 \n",
      "Batch: 764. Acc: 0.562538. Loss: 1.203925. Batch_acc: 0.557359. Batch_loss: 1.194149 \n",
      "Batch: 765. Acc: 0.562531. Loss: 1.203933. Batch_acc: 0.557583. Batch_loss: 1.210470 \n",
      "Batch: 766. Acc: 0.562512. Loss: 1.203987. Batch_acc: 0.547836. Batch_loss: 1.244585 \n",
      "Batch: 767. Acc: 0.562502. Loss: 1.204011. Batch_acc: 0.555239. Batch_loss: 1.222102 \n",
      "Batch: 768. Acc: 0.562524. Loss: 1.203951. Batch_acc: 0.578588. Batch_loss: 1.158555 \n",
      "Batch: 769. Acc: 0.562520. Loss: 1.203928. Batch_acc: 0.559654. Batch_loss: 1.186090 \n",
      "Batch: 770. Acc: 0.562497. Loss: 1.203970. Batch_acc: 0.545248. Batch_loss: 1.235964 \n",
      "Batch: 771. Acc: 0.562499. Loss: 1.203973. Batch_acc: 0.564117. Batch_loss: 1.205944 \n",
      "Batch: 772. Acc: 0.562504. Loss: 1.203937. Batch_acc: 0.565887. Batch_loss: 1.176557 \n",
      "Batch: 773. Acc: 0.562510. Loss: 1.203943. Batch_acc: 0.567708. Batch_loss: 1.208606 \n",
      "Batch: 774. Acc: 0.562516. Loss: 1.203917. Batch_acc: 0.567313. Batch_loss: 1.183686 \n",
      "Batch: 775. Acc: 0.562497. Loss: 1.203964. Batch_acc: 0.547756. Batch_loss: 1.240518 \n",
      "Batch: 776. Acc: 0.562471. Loss: 1.204003. Batch_acc: 0.541950. Batch_loss: 1.233380 \n",
      "Batch: 777. Acc: 0.562468. Loss: 1.204047. Batch_acc: 0.560070. Batch_loss: 1.238758 \n",
      "Batch: 778. Acc: 0.562464. Loss: 1.204040. Batch_acc: 0.559906. Batch_loss: 1.198264 \n",
      "Batch: 779. Acc: 0.562463. Loss: 1.204055. Batch_acc: 0.561143. Batch_loss: 1.215952 \n",
      "Batch: 780. Acc: 0.562448. Loss: 1.204095. Batch_acc: 0.551200. Batch_loss: 1.235290 \n",
      "Batch: 781. Acc: 0.562427. Loss: 1.204143. Batch_acc: 0.545615. Batch_loss: 1.242432 \n",
      "Batch: 782. Acc: 0.562402. Loss: 1.204214. Batch_acc: 0.542565. Batch_loss: 1.259056 \n",
      "Batch: 783. Acc: 0.562434. Loss: 1.204140. Batch_acc: 0.587346. Batch_loss: 1.147975 \n",
      "Batch: 784. Acc: 0.562415. Loss: 1.204155. Batch_acc: 0.547605. Batch_loss: 1.216175 \n",
      "Batch: 785. Acc: 0.562422. Loss: 1.204166. Batch_acc: 0.567583. Batch_loss: 1.212572 \n",
      "Batch: 786. Acc: 0.562407. Loss: 1.204189. Batch_acc: 0.549910. Batch_loss: 1.222837 \n",
      "Batch: 787. Acc: 0.562428. Loss: 1.204151. Batch_acc: 0.579727. Batch_loss: 1.173581 \n",
      "Batch: 788. Acc: 0.562424. Loss: 1.204166. Batch_acc: 0.559618. Batch_loss: 1.215611 \n",
      "Batch: 789. Acc: 0.562450. Loss: 1.204120. Batch_acc: 0.582804. Batch_loss: 1.168017 \n",
      "Batch: 790. Acc: 0.562464. Loss: 1.204088. Batch_acc: 0.573178. Batch_loss: 1.177958 \n",
      "Batch: 791. Acc: 0.562467. Loss: 1.204073. Batch_acc: 0.565043. Batch_loss: 1.192678 \n",
      "Batch: 792. Acc: 0.562469. Loss: 1.204061. Batch_acc: 0.563751. Batch_loss: 1.194577 \n",
      "Batch: 793. Acc: 0.562498. Loss: 1.203999. Batch_acc: 0.585489. Batch_loss: 1.155784 \n",
      "Batch: 794. Acc: 0.562505. Loss: 1.203971. Batch_acc: 0.567615. Batch_loss: 1.181342 \n",
      "Batch: 795. Acc: 0.562496. Loss: 1.203949. Batch_acc: 0.555491. Batch_loss: 1.186776 \n",
      "Batch: 796. Acc: 0.562525. Loss: 1.203859. Batch_acc: 0.585297. Batch_loss: 1.134317 \n",
      "Batch: 797. Acc: 0.562536. Loss: 1.203845. Batch_acc: 0.571512. Batch_loss: 1.192223 \n",
      "Batch: 798. Acc: 0.562537. Loss: 1.203832. Batch_acc: 0.562860. Batch_loss: 1.193195 \n",
      "Batch: 799. Acc: 0.562535. Loss: 1.203816. Batch_acc: 0.560822. Batch_loss: 1.191491 \n",
      "Batch: 800. Acc: 0.562511. Loss: 1.203873. Batch_acc: 0.543275. Batch_loss: 1.249695 \n",
      "Batch: 801. Acc: 0.562503. Loss: 1.203892. Batch_acc: 0.556064. Batch_loss: 1.219585 \n",
      "Batch: 802. Acc: 0.562516. Loss: 1.203845. Batch_acc: 0.573143. Batch_loss: 1.166575 \n",
      "Batch: 803. Acc: 0.562543. Loss: 1.203787. Batch_acc: 0.583620. Batch_loss: 1.156737 \n",
      "Batch: 804. Acc: 0.562517. Loss: 1.203831. Batch_acc: 0.541880. Batch_loss: 1.239361 \n",
      "Batch: 805. Acc: 0.562494. Loss: 1.203917. Batch_acc: 0.543757. Batch_loss: 1.273940 \n",
      "Batch: 806. Acc: 0.562471. Loss: 1.203926. Batch_acc: 0.544399. Batch_loss: 1.211604 \n",
      "Batch: 807. Acc: 0.562492. Loss: 1.203851. Batch_acc: 0.578680. Batch_loss: 1.144508 \n",
      "Batch: 808. Acc: 0.562504. Loss: 1.203819. Batch_acc: 0.572434. Batch_loss: 1.177133 \n",
      "Batch: 809. Acc: 0.562492. Loss: 1.203841. Batch_acc: 0.552677. Batch_loss: 1.221421 \n",
      "Batch: 810. Acc: 0.562492. Loss: 1.203830. Batch_acc: 0.562682. Batch_loss: 1.194787 \n",
      "Batch: 811. Acc: 0.562471. Loss: 1.203906. Batch_acc: 0.545186. Batch_loss: 1.267403 \n",
      "Batch: 812. Acc: 0.562486. Loss: 1.203863. Batch_acc: 0.574336. Batch_loss: 1.169291 \n",
      "Batch: 813. Acc: 0.562497. Loss: 1.203827. Batch_acc: 0.571265. Batch_loss: 1.174685 \n",
      "Batch: 814. Acc: 0.562503. Loss: 1.203832. Batch_acc: 0.567647. Batch_loss: 1.208181 \n",
      "Batch: 815. Acc: 0.562496. Loss: 1.203807. Batch_acc: 0.557222. Batch_loss: 1.184572 \n",
      "Batch: 816. Acc: 0.562475. Loss: 1.203876. Batch_acc: 0.545091. Batch_loss: 1.259749 \n",
      "Batch: 817. Acc: 0.562505. Loss: 1.203808. Batch_acc: 0.587302. Batch_loss: 1.146452 \n",
      "Batch: 818. Acc: 0.562512. Loss: 1.203800. Batch_acc: 0.568091. Batch_loss: 1.197296 \n",
      "Batch: 819. Acc: 0.562527. Loss: 1.203800. Batch_acc: 0.575439. Batch_loss: 1.204481 \n",
      "Batch: 820. Acc: 0.562513. Loss: 1.203824. Batch_acc: 0.551056. Batch_loss: 1.223868 \n",
      "Batch: 821. Acc: 0.562504. Loss: 1.203844. Batch_acc: 0.554502. Batch_loss: 1.220118 \n",
      "Batch: 822. Acc: 0.562471. Loss: 1.203935. Batch_acc: 0.535611. Batch_loss: 1.279458 \n",
      "Batch: 823. Acc: 0.562463. Loss: 1.203956. Batch_acc: 0.555806. Batch_loss: 1.220736 \n",
      "Batch: 824. Acc: 0.562451. Loss: 1.203962. Batch_acc: 0.552538. Batch_loss: 1.209050 \n",
      "Batch: 825. Acc: 0.562456. Loss: 1.203932. Batch_acc: 0.566627. Batch_loss: 1.178697 \n",
      "Batch: 826. Acc: 0.562440. Loss: 1.203983. Batch_acc: 0.548774. Batch_loss: 1.245609 \n",
      "Batch: 827. Acc: 0.562450. Loss: 1.203935. Batch_acc: 0.571346. Batch_loss: 1.164006 \n",
      "Batch: 828. Acc: 0.562430. Loss: 1.204015. Batch_acc: 0.545719. Batch_loss: 1.271071 \n",
      "Batch: 829. Acc: 0.562424. Loss: 1.204053. Batch_acc: 0.556969. Batch_loss: 1.236163 \n",
      "Batch: 830. Acc: 0.562448. Loss: 1.204025. Batch_acc: 0.582235. Batch_loss: 1.180788 \n",
      "Batch: 831. Acc: 0.562450. Loss: 1.204008. Batch_acc: 0.564088. Batch_loss: 1.189390 \n",
      "Batch: 832. Acc: 0.562477. Loss: 1.203967. Batch_acc: 0.584917. Batch_loss: 1.170095 \n",
      "Batch: 833. Acc: 0.562466. Loss: 1.203983. Batch_acc: 0.553705. Batch_loss: 1.216914 \n",
      "Batch: 834. Acc: 0.562476. Loss: 1.203931. Batch_acc: 0.570768. Batch_loss: 1.160752 \n",
      "Batch: 835. Acc: 0.562486. Loss: 1.203937. Batch_acc: 0.570942. Batch_loss: 1.208882 \n",
      "Batch: 836. Acc: 0.562480. Loss: 1.203968. Batch_acc: 0.556918. Batch_loss: 1.229912 \n",
      "Batch: 837. Acc: 0.562452. Loss: 1.204035. Batch_acc: 0.538640. Batch_loss: 1.261197 \n",
      "Batch: 838. Acc: 0.562471. Loss: 1.204004. Batch_acc: 0.578947. Batch_loss: 1.177912 \n",
      "Batch: 839. Acc: 0.562466. Loss: 1.203997. Batch_acc: 0.557792. Batch_loss: 1.197962 \n",
      "Batch: 840. Acc: 0.562485. Loss: 1.203942. Batch_acc: 0.578857. Batch_loss: 1.157710 \n",
      "Batch: 841. Acc: 0.562504. Loss: 1.203895. Batch_acc: 0.577728. Batch_loss: 1.165793 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 842. Acc: 0.562494. Loss: 1.203942. Batch_acc: 0.554196. Batch_loss: 1.243783 \n",
      "Batch: 843. Acc: 0.562509. Loss: 1.203920. Batch_acc: 0.575461. Batch_loss: 1.184965 \n",
      "Batch: 844. Acc: 0.562497. Loss: 1.203972. Batch_acc: 0.552419. Batch_loss: 1.248159 \n",
      "Batch: 845. Acc: 0.562499. Loss: 1.204003. Batch_acc: 0.563501. Batch_loss: 1.229990 \n",
      "Batch: 846. Acc: 0.562496. Loss: 1.204006. Batch_acc: 0.560589. Batch_loss: 1.206412 \n",
      "Batch: 847. Acc: 0.562499. Loss: 1.203996. Batch_acc: 0.564767. Batch_loss: 1.195179 \n",
      "Batch: 848. Acc: 0.562497. Loss: 1.204000. Batch_acc: 0.560520. Batch_loss: 1.207587 \n",
      "Batch: 849. Acc: 0.562491. Loss: 1.204017. Batch_acc: 0.557769. Batch_loss: 1.218415 \n",
      "Batch: 850. Acc: 0.562506. Loss: 1.203976. Batch_acc: 0.575334. Batch_loss: 1.168869 \n",
      "Batch: 851. Acc: 0.562464. Loss: 1.204080. Batch_acc: 0.527541. Batch_loss: 1.290978 \n",
      "Batch: 852. Acc: 0.562491. Loss: 1.204012. Batch_acc: 0.584809. Batch_loss: 1.146860 \n",
      "Batch: 853. Acc: 0.562518. Loss: 1.203922. Batch_acc: 0.585642. Batch_loss: 1.128650 \n",
      "Batch: 854. Acc: 0.562520. Loss: 1.203912. Batch_acc: 0.563786. Batch_loss: 1.195280 \n",
      "Batch: 855. Acc: 0.562529. Loss: 1.203862. Batch_acc: 0.570215. Batch_loss: 1.161284 \n",
      "Batch: 856. Acc: 0.562521. Loss: 1.203872. Batch_acc: 0.555745. Batch_loss: 1.212908 \n",
      "Batch: 857. Acc: 0.562521. Loss: 1.203853. Batch_acc: 0.562319. Batch_loss: 1.186928 \n",
      "Batch: 858. Acc: 0.562535. Loss: 1.203848. Batch_acc: 0.574925. Batch_loss: 1.199545 \n",
      "Batch: 859. Acc: 0.562538. Loss: 1.203815. Batch_acc: 0.565217. Batch_loss: 1.176663 \n",
      "Batch: 860. Acc: 0.562570. Loss: 1.203746. Batch_acc: 0.589497. Batch_loss: 1.145041 \n",
      "Batch: 861. Acc: 0.562565. Loss: 1.203794. Batch_acc: 0.558247. Batch_loss: 1.245477 \n",
      "Batch: 862. Acc: 0.562586. Loss: 1.203753. Batch_acc: 0.580719. Batch_loss: 1.168755 \n",
      "Batch: 863. Acc: 0.562556. Loss: 1.203820. Batch_acc: 0.536878. Batch_loss: 1.261409 \n",
      "Batch: 864. Acc: 0.562573. Loss: 1.203793. Batch_acc: 0.577075. Batch_loss: 1.180634 \n",
      "Batch: 865. Acc: 0.562576. Loss: 1.203774. Batch_acc: 0.564719. Batch_loss: 1.187983 \n",
      "Batch: 866. Acc: 0.562584. Loss: 1.203734. Batch_acc: 0.570023. Batch_loss: 1.168491 \n",
      "Batch: 867. Acc: 0.562585. Loss: 1.203736. Batch_acc: 0.563720. Batch_loss: 1.205270 \n",
      "Batch: 868. Acc: 0.562600. Loss: 1.203712. Batch_acc: 0.574971. Batch_loss: 1.183125 \n",
      "Batch: 869. Acc: 0.562568. Loss: 1.203794. Batch_acc: 0.534884. Batch_loss: 1.276046 \n",
      "Batch: 870. Acc: 0.562558. Loss: 1.203848. Batch_acc: 0.553353. Batch_loss: 1.251405 \n",
      "Batch: 871. Acc: 0.562578. Loss: 1.203783. Batch_acc: 0.580645. Batch_loss: 1.147010 \n",
      "Batch: 872. Acc: 0.562577. Loss: 1.203760. Batch_acc: 0.561534. Batch_loss: 1.183571 \n",
      "Batch: 873. Acc: 0.562557. Loss: 1.203798. Batch_acc: 0.545506. Batch_loss: 1.237059 \n",
      "Batch: 874. Acc: 0.562528. Loss: 1.203892. Batch_acc: 0.536342. Batch_loss: 1.286686 \n",
      "Batch: 875. Acc: 0.562532. Loss: 1.203889. Batch_acc: 0.566238. Batch_loss: 1.201862 \n",
      "Batch: 876. Acc: 0.562543. Loss: 1.203859. Batch_acc: 0.571348. Batch_loss: 1.177595 \n",
      "Batch: 877. Acc: 0.562557. Loss: 1.203822. Batch_acc: 0.575327. Batch_loss: 1.172390 \n",
      "Batch: 878. Acc: 0.562545. Loss: 1.203832. Batch_acc: 0.551626. Batch_loss: 1.211896 \n",
      "Batch: 879. Acc: 0.562564. Loss: 1.203778. Batch_acc: 0.579099. Batch_loss: 1.156869 \n",
      "Batch: 880. Acc: 0.562545. Loss: 1.203829. Batch_acc: 0.546223. Batch_loss: 1.247251 \n",
      "Batch: 881. Acc: 0.562561. Loss: 1.203776. Batch_acc: 0.576531. Batch_loss: 1.157862 \n",
      "Batch: 882. Acc: 0.562566. Loss: 1.203751. Batch_acc: 0.567492. Batch_loss: 1.182428 \n",
      "Batch: 883. Acc: 0.562580. Loss: 1.203723. Batch_acc: 0.574263. Batch_loss: 1.179114 \n",
      "Batch: 884. Acc: 0.562588. Loss: 1.203704. Batch_acc: 0.569966. Batch_loss: 1.187317 \n",
      "Batch: 885. Acc: 0.562621. Loss: 1.203642. Batch_acc: 0.590780. Batch_loss: 1.149489 \n",
      "Batch: 886. Acc: 0.562589. Loss: 1.203743. Batch_acc: 0.534151. Batch_loss: 1.294605 \n",
      "Batch: 887. Acc: 0.562615. Loss: 1.203663. Batch_acc: 0.585906. Batch_loss: 1.131357 \n",
      "Batch: 888. Acc: 0.562616. Loss: 1.203660. Batch_acc: 0.563667. Batch_loss: 1.201478 \n",
      "Batch: 889. Acc: 0.562593. Loss: 1.203712. Batch_acc: 0.541618. Batch_loss: 1.249807 \n",
      "Batch: 890. Acc: 0.562579. Loss: 1.203739. Batch_acc: 0.550115. Batch_loss: 1.227850 \n",
      "Batch: 891. Acc: 0.562562. Loss: 1.203756. Batch_acc: 0.547564. Batch_loss: 1.219058 \n",
      "Batch: 892. Acc: 0.562550. Loss: 1.203801. Batch_acc: 0.552065. Batch_loss: 1.244264 \n",
      "Batch: 893. Acc: 0.562563. Loss: 1.203757. Batch_acc: 0.573978. Batch_loss: 1.164477 \n",
      "Batch: 894. Acc: 0.562574. Loss: 1.203728. Batch_acc: 0.572320. Batch_loss: 1.178305 \n",
      "Batch: 895. Acc: 0.562572. Loss: 1.203729. Batch_acc: 0.560528. Batch_loss: 1.205080 \n",
      "Batch: 896. Acc: 0.562597. Loss: 1.203674. Batch_acc: 0.584755. Batch_loss: 1.154358 \n",
      "Batch: 897. Acc: 0.562606. Loss: 1.203658. Batch_acc: 0.570693. Batch_loss: 1.189783 \n",
      "Batch: 898. Acc: 0.562590. Loss: 1.203686. Batch_acc: 0.548253. Batch_loss: 1.229630 \n",
      "Batch: 899. Acc: 0.562576. Loss: 1.203714. Batch_acc: 0.549476. Batch_loss: 1.229020 \n",
      "Batch: 900. Acc: 0.562589. Loss: 1.203668. Batch_acc: 0.573579. Batch_loss: 1.163326 \n",
      "Batch: 901. Acc: 0.562598. Loss: 1.203655. Batch_acc: 0.571343. Batch_loss: 1.191948 \n",
      "Batch: 902. Acc: 0.562600. Loss: 1.203647. Batch_acc: 0.564841. Batch_loss: 1.196024 \n",
      "Batch: 903. Acc: 0.562604. Loss: 1.203657. Batch_acc: 0.565859. Batch_loss: 1.212986 \n",
      "Batch: 904. Acc: 0.562620. Loss: 1.203624. Batch_acc: 0.576836. Batch_loss: 1.174274 \n",
      "Batch: 905. Acc: 0.562632. Loss: 1.203587. Batch_acc: 0.573402. Batch_loss: 1.169901 \n",
      "Batch: 906. Acc: 0.562624. Loss: 1.203605. Batch_acc: 0.555938. Batch_loss: 1.219962 \n",
      "Batch: 907. Acc: 0.562662. Loss: 1.203534. Batch_acc: 0.597312. Batch_loss: 1.138029 \n",
      "Batch: 908. Acc: 0.562663. Loss: 1.203537. Batch_acc: 0.563298. Batch_loss: 1.206979 \n",
      "Batch: 909. Acc: 0.562677. Loss: 1.203503. Batch_acc: 0.575272. Batch_loss: 1.172259 \n",
      "Batch: 910. Acc: 0.562690. Loss: 1.203461. Batch_acc: 0.575175. Batch_loss: 1.164705 \n",
      "Batch: 911. Acc: 0.562670. Loss: 1.203502. Batch_acc: 0.544451. Batch_loss: 1.241608 \n",
      "Batch: 912. Acc: 0.562704. Loss: 1.203412. Batch_acc: 0.592890. Batch_loss: 1.121750 \n",
      "Batch: 913. Acc: 0.562742. Loss: 1.203310. Batch_acc: 0.597285. Batch_loss: 1.111462 \n",
      "Batch: 914. Acc: 0.562753. Loss: 1.203282. Batch_acc: 0.572743. Batch_loss: 1.177448 \n",
      "Batch: 915. Acc: 0.562762. Loss: 1.203242. Batch_acc: 0.570864. Batch_loss: 1.167998 \n",
      "Batch: 916. Acc: 0.562787. Loss: 1.203169. Batch_acc: 0.585755. Batch_loss: 1.136283 \n",
      "Batch: 917. Acc: 0.562780. Loss: 1.203220. Batch_acc: 0.556002. Batch_loss: 1.250385 \n",
      "Batch: 918. Acc: 0.562774. Loss: 1.203250. Batch_acc: 0.557614. Batch_loss: 1.230703 \n",
      "Batch: 919. Acc: 0.562780. Loss: 1.203234. Batch_acc: 0.567873. Batch_loss: 1.189041 \n",
      "Batch: 920. Acc: 0.562794. Loss: 1.203182. Batch_acc: 0.575413. Batch_loss: 1.155918 \n",
      "Batch: 921. Acc: 0.562800. Loss: 1.203151. Batch_acc: 0.568143. Batch_loss: 1.174127 \n",
      "Batch: 922. Acc: 0.562791. Loss: 1.203149. Batch_acc: 0.555056. Batch_loss: 1.201517 \n",
      "Batch: 923. Acc: 0.562804. Loss: 1.203109. Batch_acc: 0.574929. Batch_loss: 1.167101 \n",
      "Batch: 924. Acc: 0.562799. Loss: 1.203129. Batch_acc: 0.557792. Batch_loss: 1.220864 \n",
      "Batch: 925. Acc: 0.562801. Loss: 1.203104. Batch_acc: 0.564189. Batch_loss: 1.180708 \n",
      "Batch: 926. Acc: 0.562844. Loss: 1.203013. Batch_acc: 0.602144. Batch_loss: 1.120690 \n",
      "Batch: 927. Acc: 0.562841. Loss: 1.203012. Batch_acc: 0.560345. Batch_loss: 1.201707 \n",
      "Batch: 928. Acc: 0.562826. Loss: 1.203042. Batch_acc: 0.548872. Batch_loss: 1.230771 \n",
      "Batch: 929. Acc: 0.562810. Loss: 1.203076. Batch_acc: 0.548182. Batch_loss: 1.235301 \n",
      "Batch: 930. Acc: 0.562811. Loss: 1.203069. Batch_acc: 0.563298. Batch_loss: 1.196477 \n",
      "Batch: 931. Acc: 0.562809. Loss: 1.203069. Batch_acc: 0.560822. Batch_loss: 1.202580 \n",
      "Batch: 932. Acc: 0.562827. Loss: 1.203049. Batch_acc: 0.579338. Batch_loss: 1.185030 \n",
      "Batch: 933. Acc: 0.562824. Loss: 1.203051. Batch_acc: 0.560325. Batch_loss: 1.204700 \n",
      "Batch: 934. Acc: 0.562835. Loss: 1.203030. Batch_acc: 0.572821. Batch_loss: 1.183464 \n",
      "Batch: 935. Acc: 0.562831. Loss: 1.203051. Batch_acc: 0.559165. Batch_loss: 1.222684 \n",
      "Batch: 936. Acc: 0.562850. Loss: 1.203007. Batch_acc: 0.580758. Batch_loss: 1.161186 \n",
      "Batch: 937. Acc: 0.562862. Loss: 1.202978. Batch_acc: 0.574223. Batch_loss: 1.175915 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 938. Acc: 0.562857. Loss: 1.203004. Batch_acc: 0.558449. Batch_loss: 1.228128 \n",
      "Batch: 939. Acc: 0.562889. Loss: 1.202930. Batch_acc: 0.592255. Batch_loss: 1.134070 \n",
      "Batch: 940. Acc: 0.562891. Loss: 1.202914. Batch_acc: 0.565421. Batch_loss: 1.187041 \n",
      "Batch: 941. Acc: 0.562907. Loss: 1.202882. Batch_acc: 0.576945. Batch_loss: 1.173455 \n",
      "Batch: 942. Acc: 0.562906. Loss: 1.202854. Batch_acc: 0.561965. Batch_loss: 1.176411 \n",
      "Batch: 943. Acc: 0.562922. Loss: 1.202823. Batch_acc: 0.578169. Batch_loss: 1.174015 \n",
      "Batch: 944. Acc: 0.562914. Loss: 1.202853. Batch_acc: 0.555492. Batch_loss: 1.230952 \n",
      "Batch: 945. Acc: 0.562889. Loss: 1.202925. Batch_acc: 0.539359. Batch_loss: 1.271896 \n",
      "Batch: 946. Acc: 0.562870. Loss: 1.202984. Batch_acc: 0.544451. Batch_loss: 1.259980 \n",
      "Batch: 947. Acc: 0.562862. Loss: 1.203009. Batch_acc: 0.554968. Batch_loss: 1.226506 \n",
      "Batch: 948. Acc: 0.562863. Loss: 1.203014. Batch_acc: 0.564162. Batch_loss: 1.208234 \n",
      "Batch: 949. Acc: 0.562867. Loss: 1.203004. Batch_acc: 0.566189. Batch_loss: 1.193065 \n",
      "Batch: 950. Acc: 0.562884. Loss: 1.202981. Batch_acc: 0.578887. Batch_loss: 1.181385 \n",
      "Batch: 951. Acc: 0.562887. Loss: 1.202972. Batch_acc: 0.565774. Batch_loss: 1.194246 \n",
      "Batch: 952. Acc: 0.562877. Loss: 1.203027. Batch_acc: 0.553592. Batch_loss: 1.255330 \n",
      "Batch: 953. Acc: 0.562871. Loss: 1.203015. Batch_acc: 0.556897. Batch_loss: 1.191469 \n",
      "Batch: 954. Acc: 0.562893. Loss: 1.202933. Batch_acc: 0.583569. Batch_loss: 1.125319 \n",
      "Batch: 955. Acc: 0.562901. Loss: 1.202924. Batch_acc: 0.571106. Batch_loss: 1.194913 \n",
      "Batch: 956. Acc: 0.562893. Loss: 1.202945. Batch_acc: 0.554386. Batch_loss: 1.223849 \n",
      "Batch: 957. Acc: 0.562891. Loss: 1.202918. Batch_acc: 0.561254. Batch_loss: 1.176695 \n",
      "Batch: 958. Acc: 0.562898. Loss: 1.202913. Batch_acc: 0.569714. Batch_loss: 1.198794 \n",
      "Batch: 959. Acc: 0.562899. Loss: 1.202888. Batch_acc: 0.564146. Batch_loss: 1.179566 \n",
      "Batch: 960. Acc: 0.562905. Loss: 1.202896. Batch_acc: 0.568312. Batch_loss: 1.210543 \n",
      "Batch: 961. Acc: 0.562899. Loss: 1.202910. Batch_acc: 0.557217. Batch_loss: 1.215466 \n",
      "Batch: 962. Acc: 0.562898. Loss: 1.202916. Batch_acc: 0.561485. Batch_loss: 1.208989 \n",
      "Batch: 963. Acc: 0.562904. Loss: 1.202900. Batch_acc: 0.568451. Batch_loss: 1.187626 \n",
      "Batch: 964. Acc: 0.562928. Loss: 1.202809. Batch_acc: 0.586267. Batch_loss: 1.115132 \n",
      "Batch: 965. Acc: 0.562921. Loss: 1.202797. Batch_acc: 0.556845. Batch_loss: 1.190949 \n",
      "Batch: 966. Acc: 0.562912. Loss: 1.202809. Batch_acc: 0.553529. Batch_loss: 1.215101 \n",
      "Batch: 967. Acc: 0.562920. Loss: 1.202799. Batch_acc: 0.570535. Batch_loss: 1.193455 \n",
      "Batch: 968. Acc: 0.562927. Loss: 1.202761. Batch_acc: 0.570046. Batch_loss: 1.165655 \n",
      "Batch: 969. Acc: 0.562937. Loss: 1.202749. Batch_acc: 0.571590. Batch_loss: 1.191657 \n",
      "Batch: 970. Acc: 0.562925. Loss: 1.202809. Batch_acc: 0.552119. Batch_loss: 1.261245 \n",
      "Batch: 971. Acc: 0.562926. Loss: 1.202822. Batch_acc: 0.563879. Batch_loss: 1.215019 \n",
      "Batch: 972. Acc: 0.562935. Loss: 1.202818. Batch_acc: 0.571596. Batch_loss: 1.198751 \n",
      "Batch: 973. Acc: 0.562971. Loss: 1.202754. Batch_acc: 0.597920. Batch_loss: 1.140001 \n",
      "Batch: 974. Acc: 0.562940. Loss: 1.202817. Batch_acc: 0.533220. Batch_loss: 1.263644 \n",
      "Batch: 975. Acc: 0.562936. Loss: 1.202790. Batch_acc: 0.558807. Batch_loss: 1.176481 \n",
      "Batch: 976. Acc: 0.562934. Loss: 1.202798. Batch_acc: 0.561760. Batch_loss: 1.210738 \n",
      "Batch: 977. Acc: 0.562936. Loss: 1.202783. Batch_acc: 0.564117. Batch_loss: 1.187695 \n",
      "Batch: 978. Acc: 0.562931. Loss: 1.202809. Batch_acc: 0.558640. Batch_loss: 1.228069 \n",
      "Batch: 979. Acc: 0.562928. Loss: 1.202819. Batch_acc: 0.559191. Batch_loss: 1.212996 \n",
      "Batch: 980. Acc: 0.562922. Loss: 1.202828. Batch_acc: 0.557995. Batch_loss: 1.211491 \n",
      "Batch: 981. Acc: 0.562908. Loss: 1.202868. Batch_acc: 0.548444. Batch_loss: 1.242859 \n",
      "Batch: 982. Acc: 0.562919. Loss: 1.202813. Batch_acc: 0.573371. Batch_loss: 1.149675 \n",
      "Batch: 983. Acc: 0.562924. Loss: 1.202797. Batch_acc: 0.568005. Batch_loss: 1.186710 \n",
      "Batch: 984. Acc: 0.562913. Loss: 1.202833. Batch_acc: 0.552077. Batch_loss: 1.237225 \n",
      "Batch: 985. Acc: 0.562900. Loss: 1.202858. Batch_acc: 0.550000. Batch_loss: 1.228745 \n",
      "Batch: 986. Acc: 0.562903. Loss: 1.202859. Batch_acc: 0.565493. Batch_loss: 1.204300 \n",
      "Batch: 987. Acc: 0.562891. Loss: 1.202869. Batch_acc: 0.551546. Batch_loss: 1.211941 \n",
      "Batch: 988. Acc: 0.562896. Loss: 1.202866. Batch_acc: 0.567749. Batch_loss: 1.200634 \n",
      "Batch: 989. Acc: 0.562896. Loss: 1.202875. Batch_acc: 0.562785. Batch_loss: 1.211046 \n",
      "Batch: 990. Acc: 0.562892. Loss: 1.202900. Batch_acc: 0.558488. Batch_loss: 1.229116 \n",
      "Batch: 991. Acc: 0.562906. Loss: 1.202835. Batch_acc: 0.577100. Batch_loss: 1.137889 \n",
      "Batch: 992. Acc: 0.562918. Loss: 1.202816. Batch_acc: 0.574860. Batch_loss: 1.184646 \n",
      "Batch: 993. Acc: 0.562935. Loss: 1.202778. Batch_acc: 0.579753. Batch_loss: 1.164231 \n",
      "Batch: 994. Acc: 0.562944. Loss: 1.202754. Batch_acc: 0.572153. Batch_loss: 1.179475 \n",
      "Batch: 995. Acc: 0.562945. Loss: 1.202788. Batch_acc: 0.564012. Batch_loss: 1.237824 \n",
      "Batch: 996. Acc: 0.562944. Loss: 1.202761. Batch_acc: 0.561921. Batch_loss: 1.176061 \n",
      "Batch: 997. Acc: 0.562950. Loss: 1.202762. Batch_acc: 0.568594. Batch_loss: 1.203372 \n",
      "Batch: 998. Acc: 0.562962. Loss: 1.202719. Batch_acc: 0.575145. Batch_loss: 1.159547 \n",
      "Batch: 999. Acc: 0.562974. Loss: 1.202682. Batch_acc: 0.574011. Batch_loss: 1.166448 \n",
      "Batch: 1000. Acc: 0.562946. Loss: 1.202737. Batch_acc: 0.534911. Batch_loss: 1.258063 \n",
      "Batch: 1001. Acc: 0.562913. Loss: 1.202832. Batch_acc: 0.530694. Batch_loss: 1.297674 \n",
      "Batch: 1002. Acc: 0.562922. Loss: 1.202805. Batch_acc: 0.572000. Batch_loss: 1.175201 \n",
      "Batch: 1003. Acc: 0.562910. Loss: 1.202823. Batch_acc: 0.550115. Batch_loss: 1.221331 \n",
      "Batch: 1004. Acc: 0.562908. Loss: 1.202827. Batch_acc: 0.561424. Batch_loss: 1.207310 \n",
      "Checkpointing on batch: 1004. Accuracy: 0.5629082071213942. Loss per char: 1.2028274818422546. Time: 1627226154.512718\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 14, 19, 18, 20, 22, 19,  1, 12,  1,\n",
      "        17, 15, 17, 26, 24, 18, 25, 21, 20, 26, 18, 23, 32,  3,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1005. Acc: 0.562889. Loss: 1.202853. Batch_acc: 0.543581. Batch_loss: 1.228885 \n",
      "Batch: 1006. Acc: 0.562904. Loss: 1.202819. Batch_acc: 0.577752. Batch_loss: 1.168883 \n",
      "Batch: 1007. Acc: 0.562903. Loss: 1.202830. Batch_acc: 0.562134. Batch_loss: 1.213872 \n",
      "Batch: 1008. Acc: 0.562929. Loss: 1.202758. Batch_acc: 0.588503. Batch_loss: 1.130935 \n",
      "Batch: 1009. Acc: 0.562934. Loss: 1.202736. Batch_acc: 0.567851. Batch_loss: 1.179811 \n",
      "Batch: 1010. Acc: 0.562967. Loss: 1.202645. Batch_acc: 0.595817. Batch_loss: 1.112237 \n",
      "Batch: 1011. Acc: 0.562973. Loss: 1.202607. Batch_acc: 0.569067. Batch_loss: 1.163572 \n",
      "Batch: 1012. Acc: 0.562956. Loss: 1.202639. Batch_acc: 0.546831. Batch_loss: 1.234471 \n",
      "Batch: 1013. Acc: 0.562959. Loss: 1.202639. Batch_acc: 0.566038. Batch_loss: 1.202247 \n",
      "Batch: 1014. Acc: 0.562932. Loss: 1.202690. Batch_acc: 0.535383. Batch_loss: 1.254953 \n",
      "Batch: 1015. Acc: 0.562945. Loss: 1.202659. Batch_acc: 0.575381. Batch_loss: 1.172174 \n",
      "Batch: 1016. Acc: 0.562928. Loss: 1.202667. Batch_acc: 0.545877. Batch_loss: 1.210047 \n",
      "Batch: 1017. Acc: 0.562920. Loss: 1.202689. Batch_acc: 0.554118. Batch_loss: 1.226229 \n",
      "Batch: 1018. Acc: 0.562910. Loss: 1.202730. Batch_acc: 0.552419. Batch_loss: 1.244144 \n",
      "Batch: 1019. Acc: 0.562910. Loss: 1.202736. Batch_acc: 0.563265. Batch_loss: 1.209587 \n",
      "Batch: 1020. Acc: 0.562914. Loss: 1.202703. Batch_acc: 0.566743. Batch_loss: 1.168747 \n",
      "Batch: 1021. Acc: 0.562915. Loss: 1.202717. Batch_acc: 0.564478. Batch_loss: 1.216629 \n",
      "Batch: 1022. Acc: 0.562927. Loss: 1.202691. Batch_acc: 0.575358. Batch_loss: 1.177047 \n",
      "Batch: 1023. Acc: 0.562920. Loss: 1.202685. Batch_acc: 0.555229. Batch_loss: 1.195816 \n",
      "Batch: 1024. Acc: 0.562922. Loss: 1.202657. Batch_acc: 0.564873. Batch_loss: 1.174862 \n",
      "Batch: 1025. Acc: 0.562910. Loss: 1.202692. Batch_acc: 0.550437. Batch_loss: 1.239312 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1026. Acc: 0.562898. Loss: 1.202747. Batch_acc: 0.550691. Batch_loss: 1.258374 \n",
      "Batch: 1027. Acc: 0.562913. Loss: 1.202691. Batch_acc: 0.577753. Batch_loss: 1.146821 \n",
      "Batch: 1028. Acc: 0.562919. Loss: 1.202677. Batch_acc: 0.568927. Batch_loss: 1.188177 \n",
      "Batch: 1029. Acc: 0.562912. Loss: 1.202696. Batch_acc: 0.555621. Batch_loss: 1.222238 \n",
      "Batch: 1030. Acc: 0.562924. Loss: 1.202670. Batch_acc: 0.575618. Batch_loss: 1.175821 \n",
      "Batch: 1031. Acc: 0.562931. Loss: 1.202647. Batch_acc: 0.570012. Batch_loss: 1.179568 \n",
      "Batch: 1032. Acc: 0.562920. Loss: 1.202659. Batch_acc: 0.552059. Batch_loss: 1.214209 \n",
      "Batch: 1033. Acc: 0.562910. Loss: 1.202685. Batch_acc: 0.552041. Batch_loss: 1.230113 \n",
      "Batch: 1034. Acc: 0.562892. Loss: 1.202749. Batch_acc: 0.543981. Batch_loss: 1.268781 \n",
      "Batch: 1035. Acc: 0.562886. Loss: 1.202755. Batch_acc: 0.556838. Batch_loss: 1.209355 \n",
      "Batch: 1036. Acc: 0.562893. Loss: 1.202720. Batch_acc: 0.570375. Batch_loss: 1.166339 \n",
      "Batch: 1037. Acc: 0.562879. Loss: 1.202749. Batch_acc: 0.548885. Batch_loss: 1.233091 \n",
      "Batch: 1038. Acc: 0.562884. Loss: 1.202733. Batch_acc: 0.567630. Batch_loss: 1.185710 \n",
      "Batch: 1039. Acc: 0.562884. Loss: 1.202730. Batch_acc: 0.562854. Batch_loss: 1.200258 \n",
      "Batch: 1040. Acc: 0.562883. Loss: 1.202749. Batch_acc: 0.562356. Batch_loss: 1.222410 \n",
      "Batch: 1041. Acc: 0.562868. Loss: 1.202783. Batch_acc: 0.546884. Batch_loss: 1.238410 \n",
      "Batch: 1042. Acc: 0.562854. Loss: 1.202844. Batch_acc: 0.547237. Batch_loss: 1.268277 \n",
      "Batch: 1043. Acc: 0.562849. Loss: 1.202849. Batch_acc: 0.557517. Batch_loss: 1.208444 \n",
      "Batch: 1044. Acc: 0.562841. Loss: 1.202867. Batch_acc: 0.554983. Batch_loss: 1.221623 \n",
      "Batch: 1045. Acc: 0.562855. Loss: 1.202835. Batch_acc: 0.576815. Batch_loss: 1.170081 \n",
      "Batch: 1046. Acc: 0.562868. Loss: 1.202829. Batch_acc: 0.576397. Batch_loss: 1.196216 \n",
      "Batch: 1047. Acc: 0.562864. Loss: 1.202827. Batch_acc: 0.559122. Batch_loss: 1.200750 \n",
      "Batch: 1048. Acc: 0.562839. Loss: 1.202863. Batch_acc: 0.536571. Batch_loss: 1.240121 \n",
      "Batch: 1049. Acc: 0.562840. Loss: 1.202848. Batch_acc: 0.564460. Batch_loss: 1.187250 \n",
      "Batch: 1050. Acc: 0.562872. Loss: 1.202804. Batch_acc: 0.595252. Batch_loss: 1.157948 \n",
      "Batch: 1051. Acc: 0.562863. Loss: 1.202834. Batch_acc: 0.554169. Batch_loss: 1.234006 \n",
      "Batch: 1052. Acc: 0.562875. Loss: 1.202802. Batch_acc: 0.574456. Batch_loss: 1.169287 \n",
      "Batch: 1053. Acc: 0.562875. Loss: 1.202810. Batch_acc: 0.563626. Batch_loss: 1.211897 \n",
      "Batch: 1054. Acc: 0.562884. Loss: 1.202791. Batch_acc: 0.571855. Batch_loss: 1.181398 \n",
      "Batch: 1055. Acc: 0.562883. Loss: 1.202743. Batch_acc: 0.562356. Batch_loss: 1.152076 \n",
      "Batch: 1056. Acc: 0.562884. Loss: 1.202736. Batch_acc: 0.563460. Batch_loss: 1.195786 \n",
      "Batch: 1057. Acc: 0.562879. Loss: 1.202786. Batch_acc: 0.557461. Batch_loss: 1.255024 \n",
      "Batch: 1058. Acc: 0.562890. Loss: 1.202765. Batch_acc: 0.574857. Batch_loss: 1.180427 \n",
      "Batch: 1059. Acc: 0.562887. Loss: 1.202786. Batch_acc: 0.559931. Batch_loss: 1.224950 \n",
      "Batch: 1060. Acc: 0.562891. Loss: 1.202783. Batch_acc: 0.567248. Batch_loss: 1.200571 \n",
      "Batch: 1061. Acc: 0.562889. Loss: 1.202794. Batch_acc: 0.560188. Batch_loss: 1.213928 \n",
      "Batch: 1062. Acc: 0.562894. Loss: 1.202781. Batch_acc: 0.568501. Batch_loss: 1.188923 \n",
      "Batch: 1063. Acc: 0.562887. Loss: 1.202804. Batch_acc: 0.555490. Batch_loss: 1.227358 \n",
      "Batch: 1064. Acc: 0.562882. Loss: 1.202847. Batch_acc: 0.556851. Batch_loss: 1.249176 \n",
      "Batch: 1065. Acc: 0.562899. Loss: 1.202824. Batch_acc: 0.580887. Batch_loss: 1.178400 \n",
      "Batch: 1066. Acc: 0.562893. Loss: 1.202827. Batch_acc: 0.556962. Batch_loss: 1.206290 \n",
      "Batch: 1067. Acc: 0.562915. Loss: 1.202775. Batch_acc: 0.585951. Batch_loss: 1.147552 \n",
      "Batch: 1068. Acc: 0.562906. Loss: 1.202781. Batch_acc: 0.553561. Batch_loss: 1.209623 \n",
      "Batch: 1069. Acc: 0.562911. Loss: 1.202761. Batch_acc: 0.568663. Batch_loss: 1.179730 \n",
      "Batch: 1070. Acc: 0.562907. Loss: 1.202786. Batch_acc: 0.558601. Batch_loss: 1.229986 \n",
      "Batch: 1071. Acc: 0.562900. Loss: 1.202819. Batch_acc: 0.554900. Batch_loss: 1.239689 \n",
      "Batch: 1072. Acc: 0.562926. Loss: 1.202742. Batch_acc: 0.590520. Batch_loss: 1.120469 \n",
      "Batch: 1073. Acc: 0.562928. Loss: 1.202742. Batch_acc: 0.565167. Batch_loss: 1.203193 \n",
      "Batch: 1074. Acc: 0.562926. Loss: 1.202727. Batch_acc: 0.561294. Batch_loss: 1.186238 \n",
      "Batch: 1075. Acc: 0.562940. Loss: 1.202717. Batch_acc: 0.577009. Batch_loss: 1.192542 \n",
      "Batch: 1076. Acc: 0.562950. Loss: 1.202647. Batch_acc: 0.573212. Batch_loss: 1.128703 \n",
      "Batch: 1077. Acc: 0.562965. Loss: 1.202619. Batch_acc: 0.579629. Batch_loss: 1.172925 \n",
      "Batch: 1078. Acc: 0.562940. Loss: 1.202670. Batch_acc: 0.534706. Batch_loss: 1.258961 \n",
      "Batch: 1079. Acc: 0.562937. Loss: 1.202637. Batch_acc: 0.559701. Batch_loss: 1.166595 \n",
      "Batch: 1080. Acc: 0.562956. Loss: 1.202586. Batch_acc: 0.583478. Batch_loss: 1.147760 \n",
      "Batch: 1081. Acc: 0.562935. Loss: 1.202638. Batch_acc: 0.539766. Batch_loss: 1.259561 \n",
      "Batch: 1082. Acc: 0.562947. Loss: 1.202602. Batch_acc: 0.576790. Batch_loss: 1.163833 \n",
      "Batch: 1083. Acc: 0.562933. Loss: 1.202632. Batch_acc: 0.547028. Batch_loss: 1.235280 \n",
      "Batch: 1084. Acc: 0.562936. Loss: 1.202639. Batch_acc: 0.566764. Batch_loss: 1.210368 \n",
      "Batch: 1085. Acc: 0.562946. Loss: 1.202618. Batch_acc: 0.573666. Batch_loss: 1.178871 \n",
      "Batch: 1086. Acc: 0.562970. Loss: 1.202571. Batch_acc: 0.589522. Batch_loss: 1.152468 \n",
      "Batch: 1087. Acc: 0.562975. Loss: 1.202532. Batch_acc: 0.568195. Batch_loss: 1.160109 \n",
      "Batch: 1088. Acc: 0.562980. Loss: 1.202518. Batch_acc: 0.568207. Batch_loss: 1.187649 \n",
      "Batch: 1089. Acc: 0.563007. Loss: 1.202455. Batch_acc: 0.591241. Batch_loss: 1.135554 \n",
      "Batch: 1090. Acc: 0.563007. Loss: 1.202443. Batch_acc: 0.563668. Batch_loss: 1.189433 \n",
      "Batch: 1091. Acc: 0.563003. Loss: 1.202412. Batch_acc: 0.558367. Batch_loss: 1.168422 \n",
      "Batch: 1092. Acc: 0.563006. Loss: 1.202381. Batch_acc: 0.565984. Batch_loss: 1.168840 \n",
      "Batch: 1093. Acc: 0.563016. Loss: 1.202361. Batch_acc: 0.574297. Batch_loss: 1.180518 \n",
      "Batch: 1094. Acc: 0.563032. Loss: 1.202360. Batch_acc: 0.581161. Batch_loss: 1.201262 \n",
      "Batch: 1095. Acc: 0.563027. Loss: 1.202393. Batch_acc: 0.556772. Batch_loss: 1.239303 \n",
      "Batch: 1096. Acc: 0.563036. Loss: 1.202363. Batch_acc: 0.572650. Batch_loss: 1.169837 \n",
      "Batch: 1097. Acc: 0.563046. Loss: 1.202338. Batch_acc: 0.574074. Batch_loss: 1.173948 \n",
      "Batch: 1098. Acc: 0.563020. Loss: 1.202401. Batch_acc: 0.533694. Batch_loss: 1.275347 \n",
      "Batch: 1099. Acc: 0.563007. Loss: 1.202425. Batch_acc: 0.548591. Batch_loss: 1.228030 \n",
      "Batch: 1100. Acc: 0.562989. Loss: 1.202482. Batch_acc: 0.542955. Batch_loss: 1.265372 \n",
      "Batch: 1101. Acc: 0.562978. Loss: 1.202512. Batch_acc: 0.551841. Batch_loss: 1.234656 \n",
      "Batch: 1102. Acc: 0.562986. Loss: 1.202490. Batch_acc: 0.572002. Batch_loss: 1.178982 \n",
      "Batch: 1103. Acc: 0.562972. Loss: 1.202513. Batch_acc: 0.547072. Batch_loss: 1.227165 \n",
      "Batch: 1104. Acc: 0.562980. Loss: 1.202508. Batch_acc: 0.571678. Batch_loss: 1.197193 \n",
      "Batch: 1105. Acc: 0.562988. Loss: 1.202500. Batch_acc: 0.571679. Batch_loss: 1.193210 \n",
      "Batch: 1106. Acc: 0.562974. Loss: 1.202535. Batch_acc: 0.548049. Batch_loss: 1.241813 \n",
      "Batch: 1107. Acc: 0.562961. Loss: 1.202559. Batch_acc: 0.547689. Batch_loss: 1.230280 \n",
      "Batch: 1108. Acc: 0.562960. Loss: 1.202588. Batch_acc: 0.562392. Batch_loss: 1.234478 \n",
      "Batch: 1109. Acc: 0.562977. Loss: 1.202549. Batch_acc: 0.582367. Batch_loss: 1.158804 \n",
      "Batch: 1110. Acc: 0.562973. Loss: 1.202542. Batch_acc: 0.557955. Batch_loss: 1.194637 \n",
      "Batch: 1111. Acc: 0.562967. Loss: 1.202548. Batch_acc: 0.556532. Batch_loss: 1.209524 \n",
      "Batch: 1112. Acc: 0.562958. Loss: 1.202561. Batch_acc: 0.552710. Batch_loss: 1.217023 \n",
      "Batch: 1113. Acc: 0.562962. Loss: 1.202547. Batch_acc: 0.566743. Batch_loss: 1.187126 \n",
      "Batch: 1114. Acc: 0.562954. Loss: 1.202573. Batch_acc: 0.554701. Batch_loss: 1.232357 \n",
      "Batch: 1115. Acc: 0.562956. Loss: 1.202576. Batch_acc: 0.564794. Batch_loss: 1.206197 \n",
      "Batch: 1116. Acc: 0.562948. Loss: 1.202585. Batch_acc: 0.553828. Batch_loss: 1.212536 \n",
      "Batch: 1117. Acc: 0.562951. Loss: 1.202574. Batch_acc: 0.566533. Batch_loss: 1.190470 \n",
      "Batch: 1118. Acc: 0.562952. Loss: 1.202584. Batch_acc: 0.563497. Batch_loss: 1.213989 \n",
      "Batch: 1119. Acc: 0.562942. Loss: 1.202607. Batch_acc: 0.551380. Batch_loss: 1.229018 \n",
      "Batch: 1120. Acc: 0.562953. Loss: 1.202578. Batch_acc: 0.575042. Batch_loss: 1.170360 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1121. Acc: 0.562945. Loss: 1.202572. Batch_acc: 0.554329. Batch_loss: 1.196311 \n",
      "Batch: 1122. Acc: 0.562937. Loss: 1.202564. Batch_acc: 0.554015. Batch_loss: 1.192962 \n",
      "Batch: 1123. Acc: 0.562955. Loss: 1.202494. Batch_acc: 0.583381. Batch_loss: 1.124739 \n",
      "Batch: 1124. Acc: 0.562970. Loss: 1.202444. Batch_acc: 0.579493. Batch_loss: 1.145724 \n",
      "Batch: 1125. Acc: 0.562952. Loss: 1.202489. Batch_acc: 0.542578. Batch_loss: 1.253065 \n",
      "Batch: 1126. Acc: 0.562961. Loss: 1.202455. Batch_acc: 0.572816. Batch_loss: 1.164491 \n",
      "Batch: 1127. Acc: 0.562947. Loss: 1.202463. Batch_acc: 0.547424. Batch_loss: 1.211703 \n",
      "Batch: 1128. Acc: 0.562984. Loss: 1.202372. Batch_acc: 0.603933. Batch_loss: 1.102448 \n",
      "Batch: 1129. Acc: 0.562993. Loss: 1.202341. Batch_acc: 0.572964. Batch_loss: 1.168401 \n",
      "Batch: 1130. Acc: 0.563009. Loss: 1.202322. Batch_acc: 0.581246. Batch_loss: 1.180794 \n",
      "Batch: 1131. Acc: 0.562983. Loss: 1.202365. Batch_acc: 0.534002. Batch_loss: 1.248979 \n",
      "Batch: 1132. Acc: 0.563001. Loss: 1.202311. Batch_acc: 0.583051. Batch_loss: 1.142383 \n",
      "Batch: 1133. Acc: 0.563024. Loss: 1.202280. Batch_acc: 0.589474. Batch_loss: 1.166848 \n",
      "Batch: 1134. Acc: 0.563020. Loss: 1.202232. Batch_acc: 0.559024. Batch_loss: 1.147897 \n",
      "Batch: 1135. Acc: 0.563028. Loss: 1.202192. Batch_acc: 0.571266. Batch_loss: 1.158135 \n",
      "Batch: 1136. Acc: 0.563044. Loss: 1.202148. Batch_acc: 0.580754. Batch_loss: 1.152922 \n",
      "Batch: 1137. Acc: 0.563022. Loss: 1.202182. Batch_acc: 0.537874. Batch_loss: 1.242035 \n",
      "Batch: 1138. Acc: 0.563003. Loss: 1.202247. Batch_acc: 0.541210. Batch_loss: 1.275352 \n",
      "Batch: 1139. Acc: 0.563003. Loss: 1.202219. Batch_acc: 0.562748. Batch_loss: 1.171692 \n",
      "Batch: 1140. Acc: 0.563014. Loss: 1.202189. Batch_acc: 0.576232. Batch_loss: 1.167280 \n",
      "Batch: 1141. Acc: 0.563002. Loss: 1.202208. Batch_acc: 0.548503. Batch_loss: 1.224277 \n",
      "Batch: 1142. Acc: 0.563002. Loss: 1.202184. Batch_acc: 0.563469. Batch_loss: 1.174927 \n",
      "Batch: 1143. Acc: 0.563003. Loss: 1.202195. Batch_acc: 0.563520. Batch_loss: 1.215266 \n",
      "Batch: 1144. Acc: 0.563005. Loss: 1.202212. Batch_acc: 0.565533. Batch_loss: 1.221430 \n",
      "Batch: 1145. Acc: 0.563010. Loss: 1.202208. Batch_acc: 0.568927. Batch_loss: 1.196896 \n",
      "Batch: 1146. Acc: 0.563013. Loss: 1.202181. Batch_acc: 0.566027. Batch_loss: 1.171786 \n",
      "Batch: 1147. Acc: 0.563025. Loss: 1.202149. Batch_acc: 0.576638. Batch_loss: 1.166439 \n",
      "Batch: 1148. Acc: 0.563014. Loss: 1.202196. Batch_acc: 0.549330. Batch_loss: 1.259390 \n",
      "Batch: 1149. Acc: 0.563026. Loss: 1.202172. Batch_acc: 0.576858. Batch_loss: 1.174855 \n",
      "Batch: 1150. Acc: 0.562998. Loss: 1.202227. Batch_acc: 0.531854. Batch_loss: 1.264388 \n",
      "Batch: 1151. Acc: 0.563008. Loss: 1.202216. Batch_acc: 0.574419. Batch_loss: 1.189736 \n",
      "Batch: 1152. Acc: 0.563032. Loss: 1.202169. Batch_acc: 0.589744. Batch_loss: 1.148247 \n",
      "Batch: 1153. Acc: 0.563053. Loss: 1.202118. Batch_acc: 0.586895. Batch_loss: 1.144268 \n",
      "Batch: 1154. Acc: 0.563049. Loss: 1.202144. Batch_acc: 0.559371. Batch_loss: 1.232954 \n",
      "Batch: 1155. Acc: 0.563058. Loss: 1.202129. Batch_acc: 0.572905. Batch_loss: 1.183913 \n",
      "Batch: 1156. Acc: 0.563055. Loss: 1.202131. Batch_acc: 0.559976. Batch_loss: 1.205525 \n",
      "Batch: 1157. Acc: 0.563056. Loss: 1.202139. Batch_acc: 0.563205. Batch_loss: 1.210490 \n",
      "Batch: 1158. Acc: 0.563082. Loss: 1.202070. Batch_acc: 0.594345. Batch_loss: 1.122177 \n",
      "Batch: 1159. Acc: 0.563081. Loss: 1.202071. Batch_acc: 0.561823. Batch_loss: 1.203389 \n",
      "Batch: 1160. Acc: 0.563109. Loss: 1.201999. Batch_acc: 0.594195. Batch_loss: 1.118852 \n",
      "Batch: 1161. Acc: 0.563122. Loss: 1.201964. Batch_acc: 0.579314. Batch_loss: 1.161359 \n",
      "Batch: 1162. Acc: 0.563121. Loss: 1.201966. Batch_acc: 0.561147. Batch_loss: 1.203766 \n",
      "Batch: 1163. Acc: 0.563117. Loss: 1.201971. Batch_acc: 0.558738. Batch_loss: 1.208817 \n",
      "Batch: 1164. Acc: 0.563125. Loss: 1.201928. Batch_acc: 0.572759. Batch_loss: 1.150572 \n",
      "Batch: 1165. Acc: 0.563137. Loss: 1.201916. Batch_acc: 0.576531. Batch_loss: 1.188069 \n",
      "Batch: 1166. Acc: 0.563136. Loss: 1.201957. Batch_acc: 0.561694. Batch_loss: 1.253166 \n",
      "Batch: 1167. Acc: 0.563155. Loss: 1.201900. Batch_acc: 0.584736. Batch_loss: 1.136721 \n",
      "Batch: 1168. Acc: 0.563156. Loss: 1.201861. Batch_acc: 0.564233. Batch_loss: 1.157686 \n",
      "Batch: 1169. Acc: 0.563154. Loss: 1.201843. Batch_acc: 0.561201. Batch_loss: 1.180551 \n",
      "Batch: 1170. Acc: 0.563155. Loss: 1.201846. Batch_acc: 0.564058. Batch_loss: 1.205657 \n",
      "Batch: 1171. Acc: 0.563152. Loss: 1.201828. Batch_acc: 0.560234. Batch_loss: 1.180031 \n",
      "Batch: 1172. Acc: 0.563150. Loss: 1.201802. Batch_acc: 0.560658. Batch_loss: 1.172366 \n",
      "Batch: 1173. Acc: 0.563138. Loss: 1.201829. Batch_acc: 0.548986. Batch_loss: 1.233755 \n",
      "Batch: 1174. Acc: 0.563152. Loss: 1.201782. Batch_acc: 0.580197. Batch_loss: 1.146218 \n",
      "Batch: 1175. Acc: 0.563143. Loss: 1.201810. Batch_acc: 0.552291. Batch_loss: 1.235629 \n",
      "Batch: 1176. Acc: 0.563135. Loss: 1.201838. Batch_acc: 0.552955. Batch_loss: 1.234534 \n",
      "Batch: 1177. Acc: 0.563140. Loss: 1.201851. Batch_acc: 0.569330. Batch_loss: 1.218158 \n",
      "Batch: 1178. Acc: 0.563136. Loss: 1.201887. Batch_acc: 0.558480. Batch_loss: 1.244388 \n",
      "Batch: 1179. Acc: 0.563125. Loss: 1.201925. Batch_acc: 0.549596. Batch_loss: 1.246572 \n",
      "Batch: 1180. Acc: 0.563137. Loss: 1.201914. Batch_acc: 0.577881. Batch_loss: 1.189111 \n",
      "Batch: 1181. Acc: 0.563121. Loss: 1.201966. Batch_acc: 0.543728. Batch_loss: 1.263347 \n",
      "Batch: 1182. Acc: 0.563105. Loss: 1.202017. Batch_acc: 0.543818. Batch_loss: 1.264475 \n",
      "Batch: 1183. Acc: 0.563103. Loss: 1.202003. Batch_acc: 0.560838. Batch_loss: 1.186164 \n",
      "Batch: 1184. Acc: 0.563107. Loss: 1.201978. Batch_acc: 0.567753. Batch_loss: 1.172121 \n",
      "Batch: 1185. Acc: 0.563124. Loss: 1.201943. Batch_acc: 0.583140. Batch_loss: 1.160875 \n",
      "Batch: 1186. Acc: 0.563148. Loss: 1.201890. Batch_acc: 0.591373. Batch_loss: 1.139965 \n",
      "Batch: 1187. Acc: 0.563184. Loss: 1.201824. Batch_acc: 0.604703. Batch_loss: 1.124915 \n",
      "Batch: 1188. Acc: 0.563198. Loss: 1.201784. Batch_acc: 0.580139. Batch_loss: 1.154638 \n",
      "Batch: 1189. Acc: 0.563221. Loss: 1.201724. Batch_acc: 0.590361. Batch_loss: 1.130160 \n",
      "Batch: 1190. Acc: 0.563216. Loss: 1.201756. Batch_acc: 0.556845. Batch_loss: 1.240296 \n",
      "Batch: 1191. Acc: 0.563210. Loss: 1.201776. Batch_acc: 0.556684. Batch_loss: 1.224966 \n",
      "Batch: 1192. Acc: 0.563208. Loss: 1.201779. Batch_acc: 0.560892. Batch_loss: 1.205059 \n",
      "Batch: 1193. Acc: 0.563210. Loss: 1.201754. Batch_acc: 0.565856. Batch_loss: 1.172905 \n",
      "Batch: 1194. Acc: 0.563216. Loss: 1.201754. Batch_acc: 0.569468. Batch_loss: 1.202000 \n",
      "Batch: 1195. Acc: 0.563220. Loss: 1.201754. Batch_acc: 0.569016. Batch_loss: 1.200812 \n",
      "Batch: 1196. Acc: 0.563219. Loss: 1.201763. Batch_acc: 0.561850. Batch_loss: 1.212930 \n",
      "Batch: 1197. Acc: 0.563238. Loss: 1.201742. Batch_acc: 0.585764. Batch_loss: 1.176618 \n",
      "Batch: 1198. Acc: 0.563250. Loss: 1.201696. Batch_acc: 0.577829. Batch_loss: 1.147048 \n",
      "Batch: 1199. Acc: 0.563251. Loss: 1.201719. Batch_acc: 0.564470. Batch_loss: 1.228965 \n",
      "Batch: 1200. Acc: 0.563279. Loss: 1.201675. Batch_acc: 0.597440. Batch_loss: 1.147601 \n",
      "Batch: 1201. Acc: 0.563281. Loss: 1.201688. Batch_acc: 0.564924. Batch_loss: 1.216712 \n",
      "Batch: 1202. Acc: 0.563294. Loss: 1.201683. Batch_acc: 0.579851. Batch_loss: 1.195996 \n",
      "Batch: 1203. Acc: 0.563280. Loss: 1.201711. Batch_acc: 0.545402. Batch_loss: 1.236246 \n",
      "Batch: 1204. Acc: 0.563285. Loss: 1.201710. Batch_acc: 0.569517. Batch_loss: 1.200122 \n",
      "Batch: 1205. Acc: 0.563297. Loss: 1.201695. Batch_acc: 0.577528. Batch_loss: 1.184510 \n",
      "Batch: 1206. Acc: 0.563288. Loss: 1.201720. Batch_acc: 0.552460. Batch_loss: 1.232351 \n",
      "Batch: 1207. Acc: 0.563310. Loss: 1.201670. Batch_acc: 0.589685. Batch_loss: 1.141439 \n",
      "Batch: 1208. Acc: 0.563311. Loss: 1.201660. Batch_acc: 0.564863. Batch_loss: 1.189636 \n",
      "Batch: 1209. Acc: 0.563291. Loss: 1.201709. Batch_acc: 0.537879. Batch_loss: 1.261376 \n",
      "Batch: 1210. Acc: 0.563277. Loss: 1.201730. Batch_acc: 0.546903. Batch_loss: 1.228478 \n",
      "Batch: 1211. Acc: 0.563278. Loss: 1.201708. Batch_acc: 0.564452. Batch_loss: 1.174723 \n",
      "Batch: 1212. Acc: 0.563272. Loss: 1.201702. Batch_acc: 0.555942. Batch_loss: 1.194397 \n",
      "Batch: 1213. Acc: 0.563276. Loss: 1.201704. Batch_acc: 0.567368. Batch_loss: 1.204054 \n",
      "Batch: 1214. Acc: 0.563292. Loss: 1.201681. Batch_acc: 0.583333. Batch_loss: 1.173670 \n",
      "Batch: 1215. Acc: 0.563302. Loss: 1.201653. Batch_acc: 0.574899. Batch_loss: 1.168243 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1216. Acc: 0.563308. Loss: 1.201652. Batch_acc: 0.570281. Batch_loss: 1.200721 \n",
      "Batch: 1217. Acc: 0.563299. Loss: 1.201671. Batch_acc: 0.553155. Batch_loss: 1.223748 \n",
      "Batch: 1218. Acc: 0.563329. Loss: 1.201576. Batch_acc: 0.598412. Batch_loss: 1.087555 \n",
      "Batch: 1219. Acc: 0.563344. Loss: 1.201538. Batch_acc: 0.582293. Batch_loss: 1.156237 \n",
      "Batch: 1220. Acc: 0.563346. Loss: 1.201500. Batch_acc: 0.565545. Batch_loss: 1.154702 \n",
      "Batch: 1221. Acc: 0.563340. Loss: 1.201523. Batch_acc: 0.555492. Batch_loss: 1.229556 \n",
      "Batch: 1222. Acc: 0.563346. Loss: 1.201512. Batch_acc: 0.570845. Batch_loss: 1.187849 \n",
      "Batch: 1223. Acc: 0.563360. Loss: 1.201472. Batch_acc: 0.580022. Batch_loss: 1.154562 \n",
      "Batch: 1224. Acc: 0.563371. Loss: 1.201435. Batch_acc: 0.576744. Batch_loss: 1.155582 \n",
      "Batch: 1225. Acc: 0.563355. Loss: 1.201458. Batch_acc: 0.544084. Batch_loss: 1.230125 \n",
      "Batch: 1226. Acc: 0.563349. Loss: 1.201460. Batch_acc: 0.555426. Batch_loss: 1.203972 \n",
      "Batch: 1227. Acc: 0.563356. Loss: 1.201433. Batch_acc: 0.572515. Batch_loss: 1.167617 \n",
      "Batch: 1228. Acc: 0.563358. Loss: 1.201395. Batch_acc: 0.565092. Batch_loss: 1.154356 \n",
      "Batch: 1229. Acc: 0.563374. Loss: 1.201375. Batch_acc: 0.582822. Batch_loss: 1.178162 \n",
      "Batch: 1230. Acc: 0.563378. Loss: 1.201343. Batch_acc: 0.568976. Batch_loss: 1.160473 \n",
      "Batch: 1231. Acc: 0.563375. Loss: 1.201339. Batch_acc: 0.559412. Batch_loss: 1.196534 \n",
      "Batch: 1232. Acc: 0.563384. Loss: 1.201316. Batch_acc: 0.573854. Batch_loss: 1.173555 \n",
      "Batch: 1233. Acc: 0.563386. Loss: 1.201307. Batch_acc: 0.566477. Batch_loss: 1.190644 \n",
      "Batch: 1234. Acc: 0.563397. Loss: 1.201293. Batch_acc: 0.576788. Batch_loss: 1.182832 \n",
      "Batch: 1235. Acc: 0.563395. Loss: 1.201297. Batch_acc: 0.560633. Batch_loss: 1.206789 \n",
      "Batch: 1236. Acc: 0.563386. Loss: 1.201281. Batch_acc: 0.552601. Batch_loss: 1.180904 \n",
      "Batch: 1237. Acc: 0.563404. Loss: 1.201233. Batch_acc: 0.586028. Batch_loss: 1.141837 \n",
      "Batch: 1238. Acc: 0.563411. Loss: 1.201211. Batch_acc: 0.571183. Batch_loss: 1.174200 \n",
      "Batch: 1239. Acc: 0.563399. Loss: 1.201248. Batch_acc: 0.548627. Batch_loss: 1.247160 \n",
      "Batch: 1240. Acc: 0.563399. Loss: 1.201255. Batch_acc: 0.564351. Batch_loss: 1.210238 \n",
      "Batch: 1241. Acc: 0.563415. Loss: 1.201237. Batch_acc: 0.582336. Batch_loss: 1.178256 \n",
      "Batch: 1242. Acc: 0.563417. Loss: 1.201213. Batch_acc: 0.566382. Batch_loss: 1.172168 \n",
      "Batch: 1243. Acc: 0.563445. Loss: 1.201151. Batch_acc: 0.598067. Batch_loss: 1.124452 \n",
      "Batch: 1244. Acc: 0.563442. Loss: 1.201160. Batch_acc: 0.559551. Batch_loss: 1.211910 \n",
      "Batch: 1245. Acc: 0.563434. Loss: 1.201171. Batch_acc: 0.553529. Batch_loss: 1.215539 \n",
      "Batch: 1246. Acc: 0.563441. Loss: 1.201136. Batch_acc: 0.571750. Batch_loss: 1.159310 \n",
      "Batch: 1247. Acc: 0.563434. Loss: 1.201141. Batch_acc: 0.555046. Batch_loss: 1.207076 \n",
      "Batch: 1248. Acc: 0.563432. Loss: 1.201131. Batch_acc: 0.560571. Batch_loss: 1.188504 \n",
      "Batch: 1249. Acc: 0.563438. Loss: 1.201116. Batch_acc: 0.570290. Batch_loss: 1.182990 \n",
      "Batch: 1250. Acc: 0.563417. Loss: 1.201166. Batch_acc: 0.538022. Batch_loss: 1.262623 \n",
      "Batch: 1251. Acc: 0.563426. Loss: 1.201146. Batch_acc: 0.573770. Batch_loss: 1.176755 \n",
      "Batch: 1252. Acc: 0.563406. Loss: 1.201186. Batch_acc: 0.538726. Batch_loss: 1.251551 \n",
      "Batch: 1253. Acc: 0.563392. Loss: 1.201223. Batch_acc: 0.545349. Batch_loss: 1.247586 \n",
      "Batch: 1254. Acc: 0.563394. Loss: 1.201225. Batch_acc: 0.566761. Batch_loss: 1.203167 \n",
      "Batch: 1255. Acc: 0.563363. Loss: 1.201310. Batch_acc: 0.522024. Batch_loss: 1.311709 \n",
      "Checkpointing on batch: 1255. Accuracy: 0.5633625373337482. Loss per char: 1.201309674933695. Time: 1627226334.7338634\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 85, 73, 70,  1, 69, 74, 71, 71, 70,\n",
      "        83, 70, 79, 68, 70,  1, 67, 70, 85, 88, 70, 70, 79,  1, 14, 17, 15, 18,\n",
      "        19, 19, 21, 20, 23, 20,  1, 66, 79, 69,  1, 14, 18, 25, 15, 24, 20, 22,\n",
      "        19, 32,  3], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1256. Acc: 0.563348. Loss: 1.201346. Batch_acc: 0.545350. Batch_loss: 1.246706 \n",
      "Batch: 1257. Acc: 0.563363. Loss: 1.201285. Batch_acc: 0.582056. Batch_loss: 1.126348 \n",
      "Batch: 1258. Acc: 0.563377. Loss: 1.201255. Batch_acc: 0.580609. Batch_loss: 1.163819 \n",
      "Batch: 1259. Acc: 0.563394. Loss: 1.201203. Batch_acc: 0.584430. Batch_loss: 1.136696 \n",
      "Batch: 1260. Acc: 0.563397. Loss: 1.201193. Batch_acc: 0.567207. Batch_loss: 1.187720 \n",
      "Batch: 1261. Acc: 0.563402. Loss: 1.201187. Batch_acc: 0.569452. Batch_loss: 1.193802 \n",
      "Batch: 1262. Acc: 0.563414. Loss: 1.201175. Batch_acc: 0.578403. Batch_loss: 1.185841 \n",
      "Batch: 1263. Acc: 0.563414. Loss: 1.201172. Batch_acc: 0.564103. Batch_loss: 1.197608 \n",
      "Batch: 1264. Acc: 0.563416. Loss: 1.201170. Batch_acc: 0.564946. Batch_loss: 1.198381 \n",
      "Batch: 1265. Acc: 0.563419. Loss: 1.201168. Batch_acc: 0.567105. Batch_loss: 1.198518 \n",
      "Batch: 1266. Acc: 0.563421. Loss: 1.201175. Batch_acc: 0.567122. Batch_loss: 1.210185 \n",
      "Batch: 1267. Acc: 0.563433. Loss: 1.201147. Batch_acc: 0.577728. Batch_loss: 1.166868 \n",
      "Batch: 1268. Acc: 0.563416. Loss: 1.201202. Batch_acc: 0.542155. Batch_loss: 1.272362 \n",
      "Batch: 1269. Acc: 0.563414. Loss: 1.201216. Batch_acc: 0.559671. Batch_loss: 1.218708 \n",
      "Batch: 1270. Acc: 0.563420. Loss: 1.201209. Batch_acc: 0.571594. Batch_loss: 1.192579 \n",
      "Batch: 1271. Acc: 0.563424. Loss: 1.201202. Batch_acc: 0.568421. Batch_loss: 1.191613 \n",
      "Batch: 1272. Acc: 0.563438. Loss: 1.201159. Batch_acc: 0.581756. Batch_loss: 1.146787 \n",
      "Batch: 1273. Acc: 0.563441. Loss: 1.201145. Batch_acc: 0.567291. Batch_loss: 1.183626 \n",
      "Batch: 1274. Acc: 0.563470. Loss: 1.201091. Batch_acc: 0.599202. Batch_loss: 1.133665 \n",
      "Batch: 1275. Acc: 0.563474. Loss: 1.201055. Batch_acc: 0.569367. Batch_loss: 1.155954 \n",
      "Batch: 1276. Acc: 0.563465. Loss: 1.201072. Batch_acc: 0.551664. Batch_loss: 1.223629 \n",
      "Batch: 1277. Acc: 0.563467. Loss: 1.201081. Batch_acc: 0.565020. Batch_loss: 1.211898 \n",
      "Batch: 1278. Acc: 0.563474. Loss: 1.201052. Batch_acc: 0.573589. Batch_loss: 1.163678 \n",
      "Batch: 1279. Acc: 0.563485. Loss: 1.201032. Batch_acc: 0.577596. Batch_loss: 1.175399 \n",
      "Batch: 1280. Acc: 0.563472. Loss: 1.201054. Batch_acc: 0.546902. Batch_loss: 1.228901 \n",
      "Batch: 1281. Acc: 0.563476. Loss: 1.201035. Batch_acc: 0.568537. Batch_loss: 1.176404 \n",
      "Batch: 1282. Acc: 0.563475. Loss: 1.201028. Batch_acc: 0.561605. Batch_loss: 1.192664 \n",
      "Batch: 1283. Acc: 0.563456. Loss: 1.201073. Batch_acc: 0.539044. Batch_loss: 1.258635 \n",
      "Batch: 1284. Acc: 0.563456. Loss: 1.201047. Batch_acc: 0.563396. Batch_loss: 1.168086 \n",
      "Batch: 1285. Acc: 0.563450. Loss: 1.201073. Batch_acc: 0.556571. Batch_loss: 1.234532 \n",
      "Batch: 1286. Acc: 0.563457. Loss: 1.201061. Batch_acc: 0.571346. Batch_loss: 1.185948 \n",
      "Batch: 1287. Acc: 0.563441. Loss: 1.201094. Batch_acc: 0.543039. Batch_loss: 1.243557 \n",
      "Batch: 1288. Acc: 0.563431. Loss: 1.201120. Batch_acc: 0.550454. Batch_loss: 1.233470 \n",
      "Batch: 1289. Acc: 0.563431. Loss: 1.201130. Batch_acc: 0.564390. Batch_loss: 1.213488 \n",
      "Batch: 1290. Acc: 0.563438. Loss: 1.201102. Batch_acc: 0.572110. Batch_loss: 1.164754 \n",
      "Batch: 1291. Acc: 0.563432. Loss: 1.201107. Batch_acc: 0.556189. Batch_loss: 1.206731 \n",
      "Batch: 1292. Acc: 0.563422. Loss: 1.201138. Batch_acc: 0.549856. Batch_loss: 1.240822 \n",
      "Batch: 1293. Acc: 0.563434. Loss: 1.201140. Batch_acc: 0.579157. Batch_loss: 1.204673 \n",
      "Batch: 1294. Acc: 0.563422. Loss: 1.201162. Batch_acc: 0.547104. Batch_loss: 1.229147 \n",
      "Batch: 1295. Acc: 0.563423. Loss: 1.201161. Batch_acc: 0.565882. Batch_loss: 1.200521 \n",
      "Batch: 1296. Acc: 0.563411. Loss: 1.201215. Batch_acc: 0.546999. Batch_loss: 1.270422 \n",
      "Batch: 1297. Acc: 0.563410. Loss: 1.201200. Batch_acc: 0.563192. Batch_loss: 1.181259 \n",
      "Batch: 1298. Acc: 0.563385. Loss: 1.201270. Batch_acc: 0.531232. Batch_loss: 1.291303 \n",
      "Batch: 1299. Acc: 0.563384. Loss: 1.201255. Batch_acc: 0.561932. Batch_loss: 1.182256 \n",
      "Batch: 1300. Acc: 0.563391. Loss: 1.201213. Batch_acc: 0.572581. Batch_loss: 1.146487 \n",
      "Batch: 1301. Acc: 0.563417. Loss: 1.201152. Batch_acc: 0.596980. Batch_loss: 1.120750 \n",
      "Batch: 1302. Acc: 0.563416. Loss: 1.201158. Batch_acc: 0.562175. Batch_loss: 1.209159 \n",
      "Batch: 1303. Acc: 0.563417. Loss: 1.201159. Batch_acc: 0.564236. Batch_loss: 1.202644 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1304. Acc: 0.563432. Loss: 1.201096. Batch_acc: 0.583007. Batch_loss: 1.121602 \n",
      "Batch: 1305. Acc: 0.563447. Loss: 1.201031. Batch_acc: 0.583001. Batch_loss: 1.117312 \n",
      "Batch: 1306. Acc: 0.563448. Loss: 1.201026. Batch_acc: 0.564311. Batch_loss: 1.194467 \n",
      "Batch: 1307. Acc: 0.563439. Loss: 1.201054. Batch_acc: 0.552179. Batch_loss: 1.236631 \n",
      "Batch: 1308. Acc: 0.563444. Loss: 1.201052. Batch_acc: 0.569014. Batch_loss: 1.199242 \n",
      "Batch: 1309. Acc: 0.563451. Loss: 1.201031. Batch_acc: 0.572493. Batch_loss: 1.173247 \n",
      "Batch: 1310. Acc: 0.563475. Loss: 1.200949. Batch_acc: 0.594624. Batch_loss: 1.098561 \n",
      "Batch: 1311. Acc: 0.563470. Loss: 1.200984. Batch_acc: 0.555944. Batch_loss: 1.247347 \n",
      "Batch: 1312. Acc: 0.563472. Loss: 1.200962. Batch_acc: 0.566015. Batch_loss: 1.171964 \n",
      "Batch: 1313. Acc: 0.563466. Loss: 1.200990. Batch_acc: 0.556078. Batch_loss: 1.238022 \n",
      "Batch: 1314. Acc: 0.563458. Loss: 1.201021. Batch_acc: 0.552431. Batch_loss: 1.242382 \n",
      "Batch: 1315. Acc: 0.563449. Loss: 1.201053. Batch_acc: 0.551665. Batch_loss: 1.243386 \n",
      "Batch: 1316. Acc: 0.563454. Loss: 1.201018. Batch_acc: 0.570696. Batch_loss: 1.155505 \n",
      "Batch: 1317. Acc: 0.563455. Loss: 1.201030. Batch_acc: 0.564045. Batch_loss: 1.215523 \n",
      "Batch: 1318. Acc: 0.563440. Loss: 1.201056. Batch_acc: 0.544023. Batch_loss: 1.236135 \n",
      "Batch: 1319. Acc: 0.563451. Loss: 1.201046. Batch_acc: 0.577217. Batch_loss: 1.187279 \n",
      "Batch: 1320. Acc: 0.563466. Loss: 1.201004. Batch_acc: 0.583995. Batch_loss: 1.146473 \n",
      "Batch: 1321. Acc: 0.563462. Loss: 1.201017. Batch_acc: 0.557405. Batch_loss: 1.218768 \n",
      "Batch: 1322. Acc: 0.563466. Loss: 1.201006. Batch_acc: 0.568797. Batch_loss: 1.186148 \n",
      "Batch: 1323. Acc: 0.563457. Loss: 1.201003. Batch_acc: 0.552230. Batch_loss: 1.197403 \n",
      "Batch: 1324. Acc: 0.563472. Loss: 1.200969. Batch_acc: 0.583284. Batch_loss: 1.154857 \n",
      "Batch: 1325. Acc: 0.563489. Loss: 1.200930. Batch_acc: 0.586247. Batch_loss: 1.148814 \n",
      "Batch: 1326. Acc: 0.563486. Loss: 1.200928. Batch_acc: 0.560023. Batch_loss: 1.197839 \n",
      "Batch: 1327. Acc: 0.563471. Loss: 1.200940. Batch_acc: 0.542775. Batch_loss: 1.216390 \n",
      "Batch: 1328. Acc: 0.563475. Loss: 1.200917. Batch_acc: 0.568528. Batch_loss: 1.170946 \n",
      "Batch: 1329. Acc: 0.563481. Loss: 1.200927. Batch_acc: 0.572005. Batch_loss: 1.214212 \n",
      "Batch: 1330. Acc: 0.563507. Loss: 1.200860. Batch_acc: 0.597365. Batch_loss: 1.112730 \n",
      "Batch: 1331. Acc: 0.563518. Loss: 1.200827. Batch_acc: 0.579526. Batch_loss: 1.156507 \n",
      "Batch: 1332. Acc: 0.563507. Loss: 1.200830. Batch_acc: 0.548148. Batch_loss: 1.205328 \n",
      "Batch: 1333. Acc: 0.563497. Loss: 1.200853. Batch_acc: 0.550114. Batch_loss: 1.231357 \n",
      "Batch: 1334. Acc: 0.563507. Loss: 1.200806. Batch_acc: 0.577907. Batch_loss: 1.136462 \n",
      "Batch: 1335. Acc: 0.563490. Loss: 1.200839. Batch_acc: 0.539849. Batch_loss: 1.245181 \n",
      "Batch: 1336. Acc: 0.563491. Loss: 1.200835. Batch_acc: 0.565020. Batch_loss: 1.196640 \n",
      "Batch: 1337. Acc: 0.563507. Loss: 1.200785. Batch_acc: 0.585549. Batch_loss: 1.133437 \n",
      "Batch: 1338. Acc: 0.563494. Loss: 1.200807. Batch_acc: 0.545141. Batch_loss: 1.229969 \n",
      "Batch: 1339. Acc: 0.563498. Loss: 1.200784. Batch_acc: 0.569613. Batch_loss: 1.169917 \n",
      "Batch: 1340. Acc: 0.563511. Loss: 1.200727. Batch_acc: 0.581128. Batch_loss: 1.124746 \n",
      "Batch: 1341. Acc: 0.563488. Loss: 1.200766. Batch_acc: 0.531755. Batch_loss: 1.253171 \n",
      "Batch: 1342. Acc: 0.563501. Loss: 1.200721. Batch_acc: 0.580645. Batch_loss: 1.141119 \n",
      "Batch: 1343. Acc: 0.563505. Loss: 1.200716. Batch_acc: 0.569016. Batch_loss: 1.193509 \n",
      "Batch: 1344. Acc: 0.563504. Loss: 1.200730. Batch_acc: 0.562144. Batch_loss: 1.219860 \n",
      "Batch: 1345. Acc: 0.563474. Loss: 1.200818. Batch_acc: 0.523478. Batch_loss: 1.320194 \n",
      "Batch: 1346. Acc: 0.563467. Loss: 1.200836. Batch_acc: 0.552885. Batch_loss: 1.226140 \n",
      "Batch: 1347. Acc: 0.563491. Loss: 1.200774. Batch_acc: 0.596351. Batch_loss: 1.118196 \n",
      "Batch: 1348. Acc: 0.563501. Loss: 1.200750. Batch_acc: 0.576525. Batch_loss: 1.167322 \n",
      "Batch: 1349. Acc: 0.563515. Loss: 1.200709. Batch_acc: 0.582947. Batch_loss: 1.146052 \n",
      "Batch: 1350. Acc: 0.563540. Loss: 1.200637. Batch_acc: 0.595305. Batch_loss: 1.105094 \n",
      "Batch: 1351. Acc: 0.563556. Loss: 1.200616. Batch_acc: 0.586246. Batch_loss: 1.173528 \n",
      "Batch: 1352. Acc: 0.563558. Loss: 1.200602. Batch_acc: 0.565760. Batch_loss: 1.181792 \n",
      "Batch: 1353. Acc: 0.563573. Loss: 1.200571. Batch_acc: 0.583620. Batch_loss: 1.158190 \n",
      "Batch: 1354. Acc: 0.563567. Loss: 1.200595. Batch_acc: 0.555687. Batch_loss: 1.233924 \n",
      "Batch: 1355. Acc: 0.563550. Loss: 1.200635. Batch_acc: 0.540845. Batch_loss: 1.254079 \n",
      "Batch: 1356. Acc: 0.563536. Loss: 1.200653. Batch_acc: 0.543870. Batch_loss: 1.225821 \n",
      "Batch: 1357. Acc: 0.563539. Loss: 1.200643. Batch_acc: 0.567073. Batch_loss: 1.186649 \n",
      "Batch: 1358. Acc: 0.563531. Loss: 1.200656. Batch_acc: 0.553561. Batch_loss: 1.218792 \n",
      "Batch: 1359. Acc: 0.563551. Loss: 1.200632. Batch_acc: 0.590989. Batch_loss: 1.168147 \n",
      "Batch: 1360. Acc: 0.563543. Loss: 1.200644. Batch_acc: 0.553382. Batch_loss: 1.215276 \n",
      "Batch: 1361. Acc: 0.563537. Loss: 1.200657. Batch_acc: 0.555118. Batch_loss: 1.219014 \n",
      "Batch: 1362. Acc: 0.563529. Loss: 1.200709. Batch_acc: 0.551684. Batch_loss: 1.271054 \n",
      "Batch: 1363. Acc: 0.563543. Loss: 1.200669. Batch_acc: 0.582668. Batch_loss: 1.146758 \n",
      "Batch: 1364. Acc: 0.563543. Loss: 1.200648. Batch_acc: 0.564311. Batch_loss: 1.172926 \n",
      "Batch: 1365. Acc: 0.563560. Loss: 1.200594. Batch_acc: 0.586599. Batch_loss: 1.127149 \n",
      "Batch: 1366. Acc: 0.563562. Loss: 1.200587. Batch_acc: 0.566454. Batch_loss: 1.191665 \n",
      "Batch: 1367. Acc: 0.563566. Loss: 1.200569. Batch_acc: 0.568080. Batch_loss: 1.175969 \n",
      "Batch: 1368. Acc: 0.563574. Loss: 1.200529. Batch_acc: 0.575100. Batch_loss: 1.146524 \n",
      "Batch: 1369. Acc: 0.563565. Loss: 1.200537. Batch_acc: 0.550351. Batch_loss: 1.211905 \n",
      "Batch: 1370. Acc: 0.563571. Loss: 1.200523. Batch_acc: 0.572609. Batch_loss: 1.180667 \n",
      "Batch: 1371. Acc: 0.563602. Loss: 1.200444. Batch_acc: 0.605610. Batch_loss: 1.093190 \n",
      "Batch: 1372. Acc: 0.563588. Loss: 1.200501. Batch_acc: 0.544268. Batch_loss: 1.277500 \n",
      "Batch: 1373. Acc: 0.563582. Loss: 1.200514. Batch_acc: 0.555428. Batch_loss: 1.217706 \n",
      "Batch: 1374. Acc: 0.563597. Loss: 1.200462. Batch_acc: 0.584712. Batch_loss: 1.130096 \n",
      "Batch: 1375. Acc: 0.563590. Loss: 1.200469. Batch_acc: 0.553057. Batch_loss: 1.209348 \n",
      "Batch: 1376. Acc: 0.563610. Loss: 1.200409. Batch_acc: 0.591814. Batch_loss: 1.119498 \n",
      "Batch: 1377. Acc: 0.563613. Loss: 1.200397. Batch_acc: 0.566474. Batch_loss: 1.183223 \n",
      "Batch: 1378. Acc: 0.563620. Loss: 1.200376. Batch_acc: 0.573847. Batch_loss: 1.171257 \n",
      "Batch: 1379. Acc: 0.563610. Loss: 1.200389. Batch_acc: 0.550118. Batch_loss: 1.219239 \n",
      "Batch: 1380. Acc: 0.563606. Loss: 1.200391. Batch_acc: 0.557085. Batch_loss: 1.203115 \n",
      "Batch: 1381. Acc: 0.563605. Loss: 1.200399. Batch_acc: 0.563030. Batch_loss: 1.210541 \n",
      "Batch: 1382. Acc: 0.563606. Loss: 1.200389. Batch_acc: 0.565343. Batch_loss: 1.187414 \n",
      "Batch: 1383. Acc: 0.563592. Loss: 1.200418. Batch_acc: 0.544218. Batch_loss: 1.238998 \n",
      "Batch: 1384. Acc: 0.563584. Loss: 1.200441. Batch_acc: 0.552419. Batch_loss: 1.233196 \n",
      "Batch: 1385. Acc: 0.563576. Loss: 1.200440. Batch_acc: 0.551862. Batch_loss: 1.198762 \n",
      "Batch: 1386. Acc: 0.563568. Loss: 1.200462. Batch_acc: 0.552860. Batch_loss: 1.230655 \n",
      "Batch: 1387. Acc: 0.563576. Loss: 1.200440. Batch_acc: 0.574812. Batch_loss: 1.170067 \n",
      "Batch: 1388. Acc: 0.563598. Loss: 1.200413. Batch_acc: 0.594737. Batch_loss: 1.161818 \n",
      "Batch: 1389. Acc: 0.563620. Loss: 1.200357. Batch_acc: 0.594002. Batch_loss: 1.123219 \n",
      "Batch: 1390. Acc: 0.563649. Loss: 1.200297. Batch_acc: 0.604096. Batch_loss: 1.117258 \n",
      "Batch: 1391. Acc: 0.563654. Loss: 1.200299. Batch_acc: 0.569942. Batch_loss: 1.203472 \n",
      "Batch: 1392. Acc: 0.563655. Loss: 1.200287. Batch_acc: 0.564678. Batch_loss: 1.182890 \n",
      "Batch: 1393. Acc: 0.563678. Loss: 1.200203. Batch_acc: 0.594789. Batch_loss: 1.087244 \n",
      "Batch: 1394. Acc: 0.563675. Loss: 1.200200. Batch_acc: 0.559331. Batch_loss: 1.197094 \n",
      "Batch: 1395. Acc: 0.563690. Loss: 1.200156. Batch_acc: 0.584351. Batch_loss: 1.139992 \n",
      "Batch: 1396. Acc: 0.563693. Loss: 1.200138. Batch_acc: 0.567865. Batch_loss: 1.175198 \n",
      "Batch: 1397. Acc: 0.563702. Loss: 1.200096. Batch_acc: 0.576068. Batch_loss: 1.141695 \n",
      "Batch: 1398. Acc: 0.563712. Loss: 1.200092. Batch_acc: 0.577881. Batch_loss: 1.194758 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1399. Acc: 0.563707. Loss: 1.200108. Batch_acc: 0.556391. Batch_loss: 1.223362 \n",
      "Batch: 1400. Acc: 0.563714. Loss: 1.200100. Batch_acc: 0.573844. Batch_loss: 1.189043 \n",
      "Batch: 1401. Acc: 0.563715. Loss: 1.200093. Batch_acc: 0.565217. Batch_loss: 1.189826 \n",
      "Batch: 1402. Acc: 0.563728. Loss: 1.200055. Batch_acc: 0.581639. Batch_loss: 1.146948 \n",
      "Batch: 1403. Acc: 0.563733. Loss: 1.200024. Batch_acc: 0.571591. Batch_loss: 1.156373 \n",
      "Batch: 1404. Acc: 0.563730. Loss: 1.200042. Batch_acc: 0.558980. Batch_loss: 1.226849 \n",
      "Batch: 1405. Acc: 0.563715. Loss: 1.200081. Batch_acc: 0.543054. Batch_loss: 1.254149 \n",
      "Batch: 1406. Acc: 0.563729. Loss: 1.200035. Batch_acc: 0.582673. Batch_loss: 1.137018 \n",
      "Batch: 1407. Acc: 0.563729. Loss: 1.200024. Batch_acc: 0.563793. Batch_loss: 1.184266 \n",
      "Batch: 1408. Acc: 0.563739. Loss: 1.199988. Batch_acc: 0.577778. Batch_loss: 1.149889 \n",
      "Batch: 1409. Acc: 0.563729. Loss: 1.200007. Batch_acc: 0.549971. Batch_loss: 1.225489 \n",
      "Batch: 1410. Acc: 0.563719. Loss: 1.200026. Batch_acc: 0.548611. Batch_loss: 1.228042 \n",
      "Batch: 1411. Acc: 0.563711. Loss: 1.200038. Batch_acc: 0.552784. Batch_loss: 1.216325 \n",
      "Batch: 1412. Acc: 0.563701. Loss: 1.200049. Batch_acc: 0.548961. Batch_loss: 1.215948 \n",
      "Batch: 1413. Acc: 0.563701. Loss: 1.200068. Batch_acc: 0.563218. Batch_loss: 1.227355 \n",
      "Batch: 1414. Acc: 0.563709. Loss: 1.200057. Batch_acc: 0.575740. Batch_loss: 1.185044 \n",
      "Batch: 1415. Acc: 0.563709. Loss: 1.200049. Batch_acc: 0.563443. Batch_loss: 1.188984 \n",
      "Batch: 1416. Acc: 0.563711. Loss: 1.200024. Batch_acc: 0.567164. Batch_loss: 1.163823 \n",
      "Batch: 1417. Acc: 0.563721. Loss: 1.200017. Batch_acc: 0.577082. Batch_loss: 1.190937 \n",
      "Batch: 1418. Acc: 0.563728. Loss: 1.200021. Batch_acc: 0.574127. Batch_loss: 1.204940 \n",
      "Batch: 1419. Acc: 0.563727. Loss: 1.200017. Batch_acc: 0.562607. Batch_loss: 1.194795 \n",
      "Batch: 1420. Acc: 0.563725. Loss: 1.200017. Batch_acc: 0.560510. Batch_loss: 1.199278 \n",
      "Batch: 1421. Acc: 0.563742. Loss: 1.199975. Batch_acc: 0.587042. Batch_loss: 1.142174 \n",
      "Batch: 1422. Acc: 0.563760. Loss: 1.199931. Batch_acc: 0.589641. Batch_loss: 1.138610 \n",
      "Batch: 1423. Acc: 0.563767. Loss: 1.199921. Batch_acc: 0.574212. Batch_loss: 1.185795 \n",
      "Batch: 1424. Acc: 0.563771. Loss: 1.199910. Batch_acc: 0.569005. Batch_loss: 1.183496 \n",
      "Batch: 1425. Acc: 0.563764. Loss: 1.199929. Batch_acc: 0.553348. Batch_loss: 1.227312 \n",
      "Batch: 1426. Acc: 0.563762. Loss: 1.199950. Batch_acc: 0.561033. Batch_loss: 1.229786 \n",
      "Batch: 1427. Acc: 0.563774. Loss: 1.199932. Batch_acc: 0.581081. Batch_loss: 1.174660 \n",
      "Batch: 1428. Acc: 0.563813. Loss: 1.199826. Batch_acc: 0.617697. Batch_loss: 1.050948 \n",
      "Batch: 1429. Acc: 0.563812. Loss: 1.199822. Batch_acc: 0.562536. Batch_loss: 1.194937 \n",
      "Batch: 1430. Acc: 0.563815. Loss: 1.199812. Batch_acc: 0.568528. Batch_loss: 1.184899 \n",
      "Batch: 1431. Acc: 0.563808. Loss: 1.199816. Batch_acc: 0.554266. Batch_loss: 1.205664 \n",
      "Batch: 1432. Acc: 0.563812. Loss: 1.199793. Batch_acc: 0.568513. Batch_loss: 1.166293 \n",
      "Batch: 1433. Acc: 0.563811. Loss: 1.199797. Batch_acc: 0.562753. Batch_loss: 1.206087 \n",
      "Batch: 1434. Acc: 0.563807. Loss: 1.199803. Batch_acc: 0.558219. Batch_loss: 1.207859 \n",
      "Batch: 1435. Acc: 0.563800. Loss: 1.199814. Batch_acc: 0.554085. Batch_loss: 1.216502 \n",
      "Batch: 1436. Acc: 0.563812. Loss: 1.199785. Batch_acc: 0.581197. Batch_loss: 1.157764 \n",
      "Batch: 1437. Acc: 0.563807. Loss: 1.199792. Batch_acc: 0.556189. Batch_loss: 1.209953 \n",
      "Batch: 1438. Acc: 0.563816. Loss: 1.199764. Batch_acc: 0.576444. Batch_loss: 1.160384 \n",
      "Batch: 1439. Acc: 0.563806. Loss: 1.199795. Batch_acc: 0.548881. Batch_loss: 1.245677 \n",
      "Batch: 1440. Acc: 0.563827. Loss: 1.199740. Batch_acc: 0.593894. Batch_loss: 1.119348 \n",
      "Batch: 1441. Acc: 0.563833. Loss: 1.199710. Batch_acc: 0.572732. Batch_loss: 1.158159 \n",
      "Batch: 1442. Acc: 0.563843. Loss: 1.199694. Batch_acc: 0.577867. Batch_loss: 1.176418 \n",
      "Batch: 1443. Acc: 0.563852. Loss: 1.199674. Batch_acc: 0.577212. Batch_loss: 1.170597 \n",
      "Batch: 1444. Acc: 0.563857. Loss: 1.199671. Batch_acc: 0.571006. Batch_loss: 1.195737 \n",
      "Batch: 1445. Acc: 0.563848. Loss: 1.199680. Batch_acc: 0.550575. Batch_loss: 1.211982 \n",
      "Batch: 1446. Acc: 0.563839. Loss: 1.199694. Batch_acc: 0.551664. Batch_loss: 1.220600 \n",
      "Batch: 1447. Acc: 0.563826. Loss: 1.199706. Batch_acc: 0.544118. Batch_loss: 1.216383 \n",
      "Batch: 1448. Acc: 0.563822. Loss: 1.199705. Batch_acc: 0.558493. Batch_loss: 1.198405 \n",
      "Batch: 1449. Acc: 0.563831. Loss: 1.199689. Batch_acc: 0.576424. Batch_loss: 1.177234 \n",
      "Batch: 1450. Acc: 0.563829. Loss: 1.199689. Batch_acc: 0.560962. Batch_loss: 1.199119 \n",
      "Batch: 1451. Acc: 0.563843. Loss: 1.199636. Batch_acc: 0.583978. Batch_loss: 1.125692 \n",
      "Batch: 1452. Acc: 0.563852. Loss: 1.199610. Batch_acc: 0.577120. Batch_loss: 1.162699 \n",
      "Batch: 1453. Acc: 0.563856. Loss: 1.199612. Batch_acc: 0.568807. Batch_loss: 1.202245 \n",
      "Batch: 1454. Acc: 0.563866. Loss: 1.199590. Batch_acc: 0.578706. Batch_loss: 1.168394 \n",
      "Batch: 1455. Acc: 0.563871. Loss: 1.199580. Batch_acc: 0.571264. Batch_loss: 1.183955 \n",
      "Batch: 1456. Acc: 0.563855. Loss: 1.199590. Batch_acc: 0.540383. Batch_loss: 1.215031 \n",
      "Batch: 1457. Acc: 0.563848. Loss: 1.199605. Batch_acc: 0.554108. Batch_loss: 1.221334 \n",
      "Batch: 1458. Acc: 0.563849. Loss: 1.199587. Batch_acc: 0.565415. Batch_loss: 1.173826 \n",
      "Batch: 1459. Acc: 0.563852. Loss: 1.199583. Batch_acc: 0.568051. Batch_loss: 1.192441 \n",
      "Batch: 1460. Acc: 0.563845. Loss: 1.199607. Batch_acc: 0.553155. Batch_loss: 1.234926 \n",
      "Batch: 1461. Acc: 0.563848. Loss: 1.199624. Batch_acc: 0.568813. Batch_loss: 1.224478 \n",
      "Batch: 1462. Acc: 0.563837. Loss: 1.199641. Batch_acc: 0.548039. Batch_loss: 1.224540 \n",
      "Batch: 1463. Acc: 0.563852. Loss: 1.199601. Batch_acc: 0.585591. Batch_loss: 1.141316 \n",
      "Batch: 1464. Acc: 0.563857. Loss: 1.199550. Batch_acc: 0.571182. Batch_loss: 1.125367 \n",
      "Batch: 1465. Acc: 0.563869. Loss: 1.199509. Batch_acc: 0.581073. Batch_loss: 1.138812 \n",
      "Batch: 1466. Acc: 0.563879. Loss: 1.199488. Batch_acc: 0.579338. Batch_loss: 1.168927 \n",
      "Batch: 1467. Acc: 0.563886. Loss: 1.199446. Batch_acc: 0.572630. Batch_loss: 1.138857 \n",
      "Batch: 1468. Acc: 0.563899. Loss: 1.199430. Batch_acc: 0.583724. Batch_loss: 1.176269 \n",
      "Batch: 1469. Acc: 0.563904. Loss: 1.199403. Batch_acc: 0.571676. Batch_loss: 1.159698 \n",
      "Batch: 1470. Acc: 0.563903. Loss: 1.199402. Batch_acc: 0.563073. Batch_loss: 1.197302 \n",
      "Batch: 1471. Acc: 0.563910. Loss: 1.199374. Batch_acc: 0.573988. Batch_loss: 1.158049 \n",
      "Batch: 1472. Acc: 0.563915. Loss: 1.199367. Batch_acc: 0.571106. Batch_loss: 1.188841 \n",
      "Batch: 1473. Acc: 0.563921. Loss: 1.199350. Batch_acc: 0.572732. Batch_loss: 1.175668 \n",
      "Batch: 1474. Acc: 0.563918. Loss: 1.199376. Batch_acc: 0.559654. Batch_loss: 1.236900 \n",
      "Batch: 1475. Acc: 0.563924. Loss: 1.199380. Batch_acc: 0.571853. Batch_loss: 1.205954 \n",
      "Batch: 1476. Acc: 0.563920. Loss: 1.199390. Batch_acc: 0.559109. Batch_loss: 1.213772 \n",
      "Batch: 1477. Acc: 0.563921. Loss: 1.199387. Batch_acc: 0.565389. Batch_loss: 1.194415 \n",
      "Batch: 1478. Acc: 0.563918. Loss: 1.199392. Batch_acc: 0.559606. Batch_loss: 1.207984 \n",
      "Batch: 1479. Acc: 0.563909. Loss: 1.199398. Batch_acc: 0.549614. Batch_loss: 1.207716 \n",
      "Batch: 1480. Acc: 0.563908. Loss: 1.199419. Batch_acc: 0.562057. Batch_loss: 1.231807 \n",
      "Batch: 1481. Acc: 0.563914. Loss: 1.199399. Batch_acc: 0.572576. Batch_loss: 1.169203 \n",
      "Batch: 1482. Acc: 0.563917. Loss: 1.199393. Batch_acc: 0.568391. Batch_loss: 1.191791 \n",
      "Batch: 1483. Acc: 0.563903. Loss: 1.199448. Batch_acc: 0.542472. Batch_loss: 1.281290 \n",
      "Batch: 1484. Acc: 0.563907. Loss: 1.199433. Batch_acc: 0.571104. Batch_loss: 1.177897 \n",
      "Batch: 1485. Acc: 0.563917. Loss: 1.199417. Batch_acc: 0.578216. Batch_loss: 1.175096 \n",
      "Batch: 1486. Acc: 0.563918. Loss: 1.199441. Batch_acc: 0.564894. Batch_loss: 1.234877 \n",
      "Batch: 1487. Acc: 0.563921. Loss: 1.199440. Batch_acc: 0.569177. Batch_loss: 1.198241 \n",
      "Batch: 1488. Acc: 0.563937. Loss: 1.199414. Batch_acc: 0.586437. Batch_loss: 1.161939 \n",
      "Batch: 1489. Acc: 0.563943. Loss: 1.199422. Batch_acc: 0.573923. Batch_loss: 1.211897 \n",
      "Batch: 1490. Acc: 0.563939. Loss: 1.199422. Batch_acc: 0.556659. Batch_loss: 1.199677 \n",
      "Batch: 1491. Acc: 0.563946. Loss: 1.199432. Batch_acc: 0.575072. Batch_loss: 1.213868 \n",
      "Batch: 1492. Acc: 0.563960. Loss: 1.199401. Batch_acc: 0.584580. Batch_loss: 1.152884 \n",
      "Batch: 1493. Acc: 0.563957. Loss: 1.199393. Batch_acc: 0.559064. Batch_loss: 1.188281 \n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Batch: 1494. Acc: 0.563969. Loss: 1.199354. Batch_acc: 0.582115. Batch_loss: 1.141438 \n",
      "Batch: 1495. Acc: 0.563968. Loss: 1.199342. Batch_acc: 0.561611. Batch_loss: 1.181935 \n",
      "Batch: 1496. Acc: 0.563966. Loss: 1.199349. Batch_acc: 0.562315. Batch_loss: 1.208739 \n",
      "Batch: 1497. Acc: 0.563977. Loss: 1.199318. Batch_acc: 0.579279. Batch_loss: 1.153160 \n",
      "Batch: 1498. Acc: 0.563965. Loss: 1.199352. Batch_acc: 0.546416. Batch_loss: 1.251270 \n",
      "Batch: 1499. Acc: 0.563985. Loss: 1.199298. Batch_acc: 0.593096. Batch_loss: 1.121101 \n",
      "Batch: 1500. Acc: 0.563983. Loss: 1.199312. Batch_acc: 0.560838. Batch_loss: 1.219624 \n",
      "Batch: 1501. Acc: 0.563989. Loss: 1.199306. Batch_acc: 0.573079. Batch_loss: 1.190048 \n",
      "Batch: 1502. Acc: 0.563992. Loss: 1.199286. Batch_acc: 0.568493. Batch_loss: 1.168851 \n",
      "Batch: 1503. Acc: 0.563983. Loss: 1.199308. Batch_acc: 0.549970. Batch_loss: 1.234282 \n",
      "Batch: 1504. Acc: 0.564002. Loss: 1.199264. Batch_acc: 0.592825. Batch_loss: 1.133488 \n",
      "Batch: 1505. Acc: 0.564003. Loss: 1.199268. Batch_acc: 0.565639. Batch_loss: 1.205043 \n",
      "Batch: 1506. Acc: 0.564015. Loss: 1.199218. Batch_acc: 0.581911. Batch_loss: 1.125828 \n",
      "Checkpointing on batch: 1506. Accuracy: 0.5640154831732944. Loss per char: 1.1992184311718237. Time: 1627226514.484936\n",
      "Last question is tensor([ 2, 56, 73, 66, 85,  1, 74, 84,  1, 26, 17, 22, 25, 25, 20, 18, 17, 20,\n",
      "        23,  1, 12,  1, 17, 15, 24, 18, 26, 32,  3,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
      "         0,  0], device='cuda:0')\n",
      "Removing existing model file at checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth\n",
      "Starting checkpoint save of checkpoints\\add_or_sub-2021-07-25_latest_checkpoint.pth...\n",
      "Final saved model size: 530790651\n",
      "Batch: 1507. Acc: 0.564028. Loss: 1.199183. Batch_acc: 0.582141. Batch_loss: 1.146544 \n",
      "Batch: 1508. Acc: 0.564037. Loss: 1.199143. Batch_acc: 0.577940. Batch_loss: 1.139371 \n",
      "Batch: 1509. Acc: 0.564037. Loss: 1.199139. Batch_acc: 0.564193. Batch_loss: 1.192956 \n",
      "Batch: 1510. Acc: 0.564051. Loss: 1.199121. Batch_acc: 0.585057. Batch_loss: 1.172541 \n",
      "Batch: 1511. Acc: 0.564035. Loss: 1.199144. Batch_acc: 0.540618. Batch_loss: 1.234077 \n",
      "Batch: 1512. Acc: 0.564019. Loss: 1.199183. Batch_acc: 0.539397. Batch_loss: 1.257390 \n",
      "Batch: 1513. Acc: 0.564013. Loss: 1.199205. Batch_acc: 0.554850. Batch_loss: 1.232703 \n",
      "Batch: 1514. Acc: 0.564024. Loss: 1.199184. Batch_acc: 0.580758. Batch_loss: 1.167257 \n",
      "Batch: 1515. Acc: 0.564004. Loss: 1.199235. Batch_acc: 0.532640. Batch_loss: 1.277264 \n",
      "Batch: 1516. Acc: 0.564008. Loss: 1.199206. Batch_acc: 0.570763. Batch_loss: 1.153993 \n",
      "Batch: 1517. Acc: 0.564003. Loss: 1.199194. Batch_acc: 0.556054. Batch_loss: 1.182344 \n",
      "Batch: 1518. Acc: 0.563977. Loss: 1.199243. Batch_acc: 0.523754. Batch_loss: 1.274289 \n",
      "Batch: 1519. Acc: 0.563984. Loss: 1.199225. Batch_acc: 0.575358. Batch_loss: 1.172887 \n",
      "Batch: 1520. Acc: 0.563977. Loss: 1.199243. Batch_acc: 0.553643. Batch_loss: 1.225359 \n",
      "Batch: 1521. Acc: 0.563976. Loss: 1.199252. Batch_acc: 0.562110. Batch_loss: 1.212986 \n",
      "Batch: 1522. Acc: 0.563968. Loss: 1.199268. Batch_acc: 0.551803. Batch_loss: 1.223450 \n",
      "Batch: 1523. Acc: 0.563954. Loss: 1.199294. Batch_acc: 0.543124. Batch_loss: 1.239162 \n",
      "Batch: 1524. Acc: 0.563950. Loss: 1.199289. Batch_acc: 0.556625. Batch_loss: 1.192110 \n",
      "Batch: 1525. Acc: 0.563940. Loss: 1.199310. Batch_acc: 0.550366. Batch_loss: 1.231412 \n",
      "Batch: 1526. Acc: 0.563934. Loss: 1.199315. Batch_acc: 0.553818. Batch_loss: 1.205941 \n",
      "Batch: 1527. Acc: 0.563930. Loss: 1.199317. Batch_acc: 0.557930. Batch_loss: 1.202265 \n",
      "Batch: 1528. Acc: 0.563953. Loss: 1.199269. Batch_acc: 0.598416. Batch_loss: 1.128242 \n",
      "Batch: 1529. Acc: 0.563943. Loss: 1.199304. Batch_acc: 0.548667. Batch_loss: 1.253442 \n",
      "Batch: 1530. Acc: 0.563943. Loss: 1.199325. Batch_acc: 0.563657. Batch_loss: 1.230348 \n",
      "Batch: 1531. Acc: 0.563945. Loss: 1.199302. Batch_acc: 0.567139. Batch_loss: 1.165023 \n",
      "Batch: 1532. Acc: 0.563940. Loss: 1.199311. Batch_acc: 0.556851. Batch_loss: 1.213689 \n",
      "Batch: 1533. Acc: 0.563946. Loss: 1.199312. Batch_acc: 0.572183. Batch_loss: 1.200636 \n",
      "Batch: 1534. Acc: 0.563944. Loss: 1.199327. Batch_acc: 0.561725. Batch_loss: 1.223742 \n",
      "Batch: 1535. Acc: 0.563945. Loss: 1.199331. Batch_acc: 0.564223. Batch_loss: 1.204730 \n",
      "Batch: 1536. Acc: 0.563936. Loss: 1.199353. Batch_acc: 0.550814. Batch_loss: 1.232749 \n",
      "Batch: 1537. Acc: 0.563951. Loss: 1.199339. Batch_acc: 0.586382. Batch_loss: 1.178207 \n",
      "Batch: 1538. Acc: 0.563941. Loss: 1.199365. Batch_acc: 0.549654. Batch_loss: 1.239431 \n",
      "Batch: 1539. Acc: 0.563936. Loss: 1.199361. Batch_acc: 0.554917. Batch_loss: 1.193501 \n",
      "Batch: 1540. Acc: 0.563944. Loss: 1.199349. Batch_acc: 0.577326. Batch_loss: 1.179631 \n",
      "Batch: 1541. Acc: 0.563945. Loss: 1.199351. Batch_acc: 0.564685. Batch_loss: 1.203614 \n",
      "Batch: 1542. Acc: 0.563945. Loss: 1.199354. Batch_acc: 0.565116. Batch_loss: 1.202773 \n",
      "Batch: 1543. Acc: 0.563958. Loss: 1.199318. Batch_acc: 0.583765. Batch_loss: 1.143786 \n",
      "Batch: 1544. Acc: 0.563956. Loss: 1.199323. Batch_acc: 0.560934. Batch_loss: 1.207230 \n",
      "Batch: 1545. Acc: 0.563942. Loss: 1.199370. Batch_acc: 0.541618. Batch_loss: 1.274564 \n",
      "Batch: 1546. Acc: 0.563933. Loss: 1.199383. Batch_acc: 0.549799. Batch_loss: 1.218396 \n",
      "Batch: 1547. Acc: 0.563943. Loss: 1.199343. Batch_acc: 0.579499. Batch_loss: 1.137090 \n",
      "Batch: 1548. Acc: 0.563942. Loss: 1.199343. Batch_acc: 0.561916. Batch_loss: 1.199876 \n",
      "Batch: 1549. Acc: 0.563951. Loss: 1.199323. Batch_acc: 0.579007. Batch_loss: 1.168133 \n",
      "Batch: 1550. Acc: 0.563956. Loss: 1.199309. Batch_acc: 0.571676. Batch_loss: 1.177673 \n",
      "Batch: 1551. Acc: 0.563938. Loss: 1.199353. Batch_acc: 0.535032. Batch_loss: 1.268109 \n",
      "Batch: 1552. Acc: 0.563947. Loss: 1.199332. Batch_acc: 0.578855. Batch_loss: 1.166184 \n",
      "Batch: 1553. Acc: 0.563955. Loss: 1.199318. Batch_acc: 0.575058. Batch_loss: 1.177636 \n",
      "Batch: 1554. Acc: 0.563945. Loss: 1.199335. Batch_acc: 0.548894. Batch_loss: 1.226451 \n",
      "Batch: 1555. Acc: 0.563953. Loss: 1.199328. Batch_acc: 0.577146. Batch_loss: 1.187794 \n",
      "Batch: 1556. Acc: 0.563944. Loss: 1.199351. Batch_acc: 0.548683. Batch_loss: 1.235633 \n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\JESS~1\\AppData\\Local\\Temp/ipykernel_12040/99078756.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m     log_interval=100)\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\PC2\\TorchDemo\\hs-math-nlp\\model_process.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(name, model, training_data, optimizer, device, epochs, validation_data, tb, log_interval, interpolate_interval, interpolate_data, start_epoch, start_batch, total_loss, n_char_total, n_char_correct, run_batches, best_valid_accu, best_valid_loss, best_interpolate_accu, best_interpolate_loss, run_max_batches, extrapolate_data, checkpoint, lr, warmup_lr, warmup_interval, smoothing)\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mwarmup_lr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarmup_lr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m             \u001b[0mwarmup_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mwarmup_interval\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m             \u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m         )\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PC2\\TorchDemo\\hs-math-nlp\\model_process.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, name, training_data, optimizer, device, epoch, tb, log_interval, max_batches, run_batch_count, start_batch, total_loss, n_char_total, n_char_correct, lr, warmup_lr, warmup_interval, smoothing)\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[0mpred_as\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_qs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_qs_pos\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_as_pos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 239\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_performance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgold_as\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msmoothing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msmoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\PC2\\TorchDemo\\hs-math-nlp\\loss.py\u001b[0m in \u001b[0;36mcompute_performance\u001b[1;34m(pred, gold, smoothing, log)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mnon_pad_mask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgold\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mne\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConstants\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPAD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpred_max\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meq\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mn_correct\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_correct\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmasked_select\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnon_pad_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_correct\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {
    "scrolled": true,
    "tags": [
     "outputPrepend"
    ]
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Los test se realizaron en los cuadernos pruebasPrimerModelo y pruebasSegundoModelo\n",
    "\n",
    "Esto es solo una muestr ade lo que podemos ejecutar"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_process.predict_single(\"Solve 5*w + 3 = -2 for w.\", model, device, n_best=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_process.predict_single(\"Solve 212 = 56*z - 12 for z.\", model, device, n_best=1)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "model_process.predict_single(\"Solve 2514*m = 2508*m - 24 for m.\", model, device, n_best=1)\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mathematics_dataset_transformer.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "interpreter": {
   "hash": "f2af42a63cc7d68e489f56292c3c9bd50be64ca32158c5e1ba92e8c017e2a89f"
  },
  "kernelspec": {
   "display_name": "Python (torch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}